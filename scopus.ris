TY  - JOUR
AU  - Lee, K.H.
AU  - Lee, R.W.
AU  - Kwon, Y.E.
TI  - Validation of a Deep Learning Chest X-ray Interpretation Model: Integrating Large-Scale AI and Large Language Models for Comparative Analysis with ChatGPT
PY  - 2024
T2  - Diagnostics
VL  - 14
IS  - 1
C7  - 90
DO  - 10.3390/diagnostics14010090
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85181938442&doi=10.3390%2fdiagnostics14010090&partnerID=40&md5=850f471e7dfccfc4fd7ce1bbc19a1974
AD  - Department of Radiology, College of Medicine, Inha University, Incheon, 22212, South Korea
AB  - This study evaluates the diagnostic accuracy and clinical utility of two artificial intelligence (AI) techniques: Kakao Brain Artificial Neural Network for Chest X-ray Reading (KARA-CXR), an assistive technology developed using large-scale AI and large language models (LLMs), and ChatGPT, a well-known LLM. The study was conducted to validate the performance of the two technologies in chest X-ray reading and explore their potential applications in the medical imaging diagnosis domain. The study methodology consisted of randomly selecting 2000 chest X-ray images from a single institution’s patient database, and two radiologists evaluated the readings provided by KARA-CXR and ChatGPT. The study used five qualitative factors to evaluate the readings generated by each model: accuracy, false findings, location inaccuracies, count inaccuracies, and hallucinations. Statistical analysis showed that KARA-CXR achieved significantly higher diagnostic accuracy compared to ChatGPT. In the ‘Acceptable’ accuracy category, KARA-CXR was rated at 70.50% and 68.00% by two observers, while ChatGPT achieved 40.50% and 47.00%. Interobserver agreement was moderate for both systems, with KARA at 0.74 and GPT4 at 0.73. For ‘False Findings’, KARA-CXR scored 68.00% and 68.50%, while ChatGPT scored 37.00% for both observers, with high interobserver agreements of 0.96 for KARA and 0.97 for GPT4. In ‘Location Inaccuracy’ and ‘Hallucinations’, KARA-CXR outperformed ChatGPT with significant margins. KARA-CXR demonstrated a non-hallucination rate of 75%, which is significantly higher than ChatGPT’s 38%. The interobserver agreement was high for KARA (0.91) and moderate to high for GPT4 (0.85) in the hallucination category. In conclusion, this study demonstrates the potential of AI and large-scale language models in medical imaging and diagnostics. It also shows that in the chest X-ray domain, KARA-CXR has relatively higher accuracy than ChatGPT. © 2023 by the authors.
KW  - ChatGPT
KW  - chest X-ray
KW  - KARA-CXR
KW  - LLM
PB  - Multidisciplinary Digital Publishing Institute (MDPI)
SN  - 20754418 (ISSN)
LA  - English
J2  - Diagn.
M3  - Article
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 1; Correspondence Address: R.W. Lee; Department of Radiology, College of Medicine, Inha University, Incheon, 22212, South Korea; email: rowoon2@hanmail.net
ER  -

TY  - JOUR
AU  - Saka, A.
AU  - Taiwo, R.
AU  - Saka, N.
AU  - Salami, B.A.
AU  - Ajayi, S.
AU  - Akande, K.
AU  - Kazemi, H.
TI  - GPT models in construction industry: Opportunities, limitations, and a use case validation
PY  - 2024
T2  - Developments in the Built Environment
VL  - 17
C7  - 100300
DO  - 10.1016/j.dibe.2023.100300
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85180528081&doi=10.1016%2fj.dibe.2023.100300&partnerID=40&md5=93186972b12f97a10feae5fe49fd8c1d
AD  - School of Built Environment, Engineering and Computing, Leeds Beckett University, United Kingdom
AD  - Department of Building and Real Estate, Hong Kong Polytechnic University, Hong Kong
AD  - Cardiff School of Management, Cardiff Metropolitan University (Llandaff Campus), United Kingdom
AD  - OVO Energy, United Kingdom
AB  - Large Language Models (LLMs) trained on large data sets came into prominence in 2018 after Google introduced BERT. Subsequently, different LLMs such as GPT models from OpenAI have been released. These models perform well on diverse tasks and have been gaining widespread applications in fields such as business and education. However, little is known about the opportunities and challenges of using LLMs in the construction industry. Thus, this study aims to assess GPT models in the construction industry. A critical review, expert discussion and case study validation are employed to achieve the study's objectives. The findings revealed opportunities for GPT models throughout the project lifecycle. The challenges of leveraging GPT models are highlighted and a use case prototype is developed for materials selection and optimization. The findings of the study would be of benefit to researchers, practitioners and stakeholders, as it presents research vistas for LLMs in the construction industry. © 2023 The Authors
KW  - Artificial intelligence
KW  - ChatGPT
KW  - Generative AI
KW  - GPT
KW  - LLMs
KW  - Artificial intelligence
KW  - Life cycle
KW  - Case-studies
KW  - ChatGPT
KW  - Critical review
KW  - Generative AI
KW  - Google+
KW  - GPT
KW  - In-field
KW  - Language model
KW  - Large datasets
KW  - Large language model
KW  - Construction industry
PB  - Elsevier Ltd
SN  - 26661659 (ISSN)
LA  - English
J2  - Dev. Built. Environ.
M3  - Review
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 2; Correspondence Address: S. Ajayi; School of Built Environment, Engineering and Computing, Leeds Beckett University, United Kingdom; email: s.ajayi@leedsbeckett.ac.uk
ER  -

TY  - JOUR
AU  - Infante, A.
AU  - Gaudino, S.
AU  - Orsini, F.
AU  - Del Ciello, A.
AU  - Gullì, C.
AU  - Merlino, B.
AU  - Natale, L.
AU  - Iezzi, R.
AU  - Sala, E.
TI  - Large language models (LLMs) in the evaluation of emergency radiology reports: performance of ChatGPT-4, Perplexity, and Bard
PY  - 2024
T2  - Clinical Radiology
VL  - 79
IS  - 2
SP  - 102
EP  - 106
DO  - 10.1016/j.crad.2023.11.011
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85179835062&doi=10.1016%2fj.crad.2023.11.011&partnerID=40&md5=3b5f3434ba318a5fd57bcfcacb7c32cb
AD  - ARC Advanced Radiology Center (ARC), Department of Oncological Radiotherapy, and Hematology, Fondazione Policlinico Universitario Agostino Gemelli IRCCS, Rome, Italy
AD  - Università Cattolica del Sacro Cuore, Facoltà di Medicina e Chirurgia, Rome, Italy
KW  - Humans
KW  - Radiography
KW  - Radiology
KW  - Article
KW  - bard
KW  - ChatGPT
KW  - computer assisted tomography
KW  - controlled study
KW  - diagnostic accuracy
KW  - diagnostic test accuracy study
KW  - emergency care
KW  - histogram
KW  - human
KW  - large language model
KW  - major clinical study
KW  - perplexity
KW  - predictive value
KW  - preliminary data
KW  - radiology
KW  - sensitivity and specificity
KW  - radiography
PB  - W.B. Saunders Ltd
SN  - 00099260 (ISSN)
C2  - 38087683
LA  - English
J2  - Clin. Radiol.
M3  - Article
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 0; Correspondence Address: A. Infante; ARC Advanced Radiology Center (ARC), Department of Oncological Radiotherapy, and Hematology, Fondazione Policlinico Universitario Agostino Gemelli IRCCS, Rome, Largo Agostino Gemelli, number 8, Italy; email: amato.infante@policlinicogemelli.it; CODEN: CLRAA
ER  -

TY  - JOUR
AU  - Fisher, A.D.
AU  - Fisher, G.
TI  - Evaluating performance of custom GPT in anesthesia practice
PY  - 2024
T2  - Journal of Clinical Anesthesia
VL  - 93
C7  - 111371
DO  - 10.1016/j.jclinane.2023.111371
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85181112005&doi=10.1016%2fj.jclinane.2023.111371&partnerID=40&md5=51ac4b728bff539f7375150ebca54a86
AD  - Medical University of South Carolina, Department of Anesthesia and Perioperative Medicine, 167 Ashley Avenue, Suite 301, Charleston, 29464, SC, United States
KW  - Anesthesia
KW  - Anesthesiology
KW  - Humans
KW  - anesthesia
KW  - anesthesiologist
KW  - artificial intelligence
KW  - ChatGPT
KW  - data interpretation
KW  - human
KW  - knowledge base
KW  - Letter
KW  - natural language processing
KW  - practice guideline
KW  - anesthesiology
PB  - Elsevier Inc.
SN  - 09528180 (ISSN)
C2  - 38154443
LA  - English
J2  - J. Clin. Anesth.
M3  - Letter
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 0; Correspondence Address: A.D. Fisher; Medical University of South Carolina, Department of Anesthesia and Perioperative Medicine, Charleston, 167 Ashley Avenue, Suite 301, MSC 912, 29464, United States; email: Fisheran@musc.edu; CODEN: JCLBE
ER  -

TY  - JOUR
AU  - Cheng, Y.-Z.
AU  - Lai, T.-H.
AU  - Chien, T.-W.
AU  - Chou, W.
TI  - Evaluating cluster analysis techniques in ChatGPT versus R-language with visualizations of author collaborations and keyword cooccurrences on articles in the Journal of Medicine (Baltimore) 2023 Bibliometric analysis
PY  - 2023
T2  - Medicine (United States)
VL  - 102
IS  - 49
C7  - e36154
DO  - 10.1097/MD.0000000000036154
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85179638717&doi=10.1097%2fMD.0000000000036154&partnerID=40&md5=41402c8fec44486b3a7630ca7192abd4
AD  - Department of Emergency Medicine, Chi-Mei Medical Center, Tainan, Taiwan
AD  - Grade Two in Senior High School, National Tainan Second Senior High School, Tainan, Taiwan
AD  - Department of Medical Research, Chi-Mei Medical Center, Tainan, Taiwan
AD  - Department of Physical Medicine and Rehabilitation, Chiali Chi-Mei Hospital, Tainan, Taiwan
AD  - Department of Physical Medicine and Rehabilitation, Chung San Medical University Hospital, Taichung, Taiwan
AB  - Background: Analyses of author collaborations and keyword co-occurrences are frequently used in bibliographic research. However, no studies have introduced a straightforward yet effective approach, such as utilizing ChatGPT with Code Interpreter (ChatGPT_CI) or the R language, for creating cluster-oriented networks. This research aims to compare cluster analysis methods in ChatGPT_CI and R, visualize country-specific author collaborations, and then demonstrate the most effective approach. Methods: The research focused on articles and review pieces from Medicine (Baltimore) published in 2023. By August 20, 2023, we had gathered metadata for 1976 articles using the Web of Science core collections. The efficiency and effectiveness of cluster displays between ChatGPT_CI and R were compared by evaluating their time consumption. The best method was then employed to present a series of visualizations of country-specific author collaborations, rooted in social network and cluster analyses. Visualization techniques incorporating network charts, chord diagrams, circle bar plots, circle packing plots, heat dendrograms, dendrograms, and word clouds were demonstrated. We further highlighted the research profiles of 2 prolific authors using timeline visuals. Results: The research findings include that (1) the most active contributors were China, Nanjing Medical University (China), the Medical School Department, and Dr Chou from Taiwan when considering countries, institutions, departments, and individual authors, respectively; (2) the highest cited articles originated from Medicine (Baltimore) accounting for 4.53%: New England Journal of Medicine, PLOS ONE, LANCET, and The Journal of the American Medical Association, with respective contributions of 3.25%, 2.7%, 2.52%, and 1.54%; (3) visual cluster analysis in R proved to be more efficient and effective than ChatGPT_CI, reducing the time taken from 1 hour to just 3 minutes; (4) 7 cluster-focused networks were crafted using R on a custom platform; and (5) the research trajectories of 2 prominent authors (Dr Brin from the United States and Dr Chow from Taiwan) and articles themes in Medicine 2023 were depicted using timeline visuals. Conclusions: This research highlighted the efficient and effective methods for conducting cluster analyses of author collaborations using R. For future related studies, such as keyword co-occurrence analysis, R is recommended as a viable alternative for bibliographic research. Copyright © 2023 the Author(s). Published by Wolters Kluwer Health, Inc.
KW  - author collaborations
KW  - chatGPT with Code Interpreter
KW  - cluster analysis
KW  - country-specific author collaborations
KW  - R language
KW  - Bibliometrics
KW  - China
KW  - Cluster Analysis
KW  - Humans
KW  - Medicine
KW  - Publications
KW  - United States
KW  - bibliometrics
KW  - China
KW  - cluster analysis
KW  - human
KW  - medicine
KW  - publication
KW  - United States
PB  - Lippincott Williams and Wilkins
SN  - 00257974 (ISSN)
C2  - 38065864
LA  - English
J2  - Medicine
M3  - Article
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 0; Correspondence Address: W. Chou; Chi Mei Medical Center (Chiali Branch), Tainan City, No. 90, Chia-Li Rd., Chiali District, 722, Taiwan; email: smilewilly@mail.chimei.org.tw; CODEN: MEDIA
ER  -

TY  - JOUR
AU  - Benirschke, R.C.
AU  - Wodskow, J.
AU  - Prasai, K.
AU  - Freeman, A.
AU  - Lee, J.M.
AU  - Groth, J.
TI  - Assessment of a large language model's utility in helping pathology professionals answer general knowledge pathology questions
PY  - 2024
T2  - American Journal of Clinical Pathology
VL  - 161
IS  - 1
SP  - 42
EP  - 48
DO  - 10.1093/ajcp/aqad106
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85181761206&doi=10.1093%2fajcp%2faqad106&partnerID=40&md5=36161287d0aef628da5ca637d25a44a9
AD  - Department of Pathology and Laboratory Medicine, NorthShore University HealthSystem, Evanston, IL, United States
AD  - Department of Pathology, University of Chicago Pritzker School of Medicine, Chicago, IL, United States
AB  - Objectives: To assess the utility and performance of the large language model ChatGPT 4.0 regarding accuracy, completeness, and its potential as a time-saving tool for pathologists and laboratory directors. Methods: A deidentified database of questions previously sent to pathology residents from health care providers was used as a source of general knowledge-Type pathology questions. These questions were submitted to the large language model and the responses graded by subject matter experts in different pathology subspecialties. The grading criteria assessed accuracy, completeness, and the potential time savings for helping the pathologist craft the response. Results: Overall, respondents thought that most of the answers would take less than 5 minutes of additional work to be used (85%). Accuracy and completeness for the 61 questions was high, with 98% of responses being at least "completely or mostly accurate"and 82% of responses "containing all relevant information."Of the respondents, 97% stated that the response would have "zero or near-zero potential for medical harm,"and all thought the tool had potential to save time in constructing answers to health care providers' queries. Performance was similar in both Anatomic Pathology (AP) and Clinical Pathology (CP), with the only exception being some relevant information was excluded in 46% of AP answers vs only 10% in CP (P <. 01). Conclusions: ChatGPT version 4.0 gave responses that were predominantly accurate and complete for general knowledge-Type pathology questions. With further research and when reviewed by a pathologist or laboratorian, this could facilitate its use as a pathologist's aid in answering questions from health care providers. © 2023 The Author(s). Published by Oxford University Press on behalf of American Society for Clinical Pathology. All rights reserved.
KW  - Databases, Factual
KW  - Health Personnel
KW  - Humans
KW  - Language
KW  - Pathologists
KW  - Pathology, Clinical
KW  - accuracy
KW  - Article
KW  - automation
KW  - biocompatibility
KW  - ChatGPT
KW  - data base
KW  - health care personnel
KW  - health care utilization
KW  - human
KW  - knowledge
KW  - large language model
KW  - learning
KW  - medical error
KW  - pathologist
KW  - questionnaire
KW  - scientific literature
KW  - total quality management
KW  - factual database
KW  - health care personnel
KW  - language
KW  - pathology
PB  - Oxford University Press
SN  - 00029173 (ISSN)
C2  - 37658808
LA  - English
J2  - Am. J. Clin. Pathol.
M3  - Article
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 1; Correspondence Address: R.C. Benirschke; Department of Pathology and Laboratory Medicine, NorthShore University HealthSystem, Evanston, United States; email: RBenirschke@northshore.org; CODEN: AJCPA
ER  -

TY  - JOUR
AU  - Toyama, Y.
AU  - Harigai, A.
AU  - Abe, M.
AU  - Nagano, M.
AU  - Kawabata, M.
AU  - Seki, Y.
AU  - Takase, K.
TI  - Performance evaluation of ChatGPT, GPT-4, and Bard on the official board examination of the Japan Radiology Society
PY  - 2024
T2  - Japanese Journal of Radiology
VL  - 42
IS  - 2
SP  - 201
EP  - 207
DO  - 10.1007/s11604-023-01491-2
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85173965217&doi=10.1007%2fs11604-023-01491-2&partnerID=40&md5=6aaf897121e0c7af19485ec313830c11
AD  - Department of Diagnostic Radiology, Tohoku University Hospital, 1-1 Seiryo-Machi, Aoba-Ku, Sendai, 980-8575, Japan
AD  - Department of Radiology, Tohoku Medical and Pharmaceutical University, Sendai, Japan
AD  - Department of Diagnostic Radiology, Tohoku University Graduate School of Medicine, Sendai, Japan
AD  - School of Medicine, Tohoku University, Sendai, Japan
AD  - Department of Radiation Oncology, Tohoku University Hospital, Sendai, Japan
AB  - Purpose: Herein, we assessed the accuracy of large language models (LLMs) in generating responses to questions in clinical radiology practice. We compared the performance of ChatGPT, GPT-4, and Google Bard using questions from the Japan Radiology Board Examination (JRBE). Materials and methods: In total, 103 questions from the JRBE 2022 were used with permission from the Japan Radiological Society. These questions were categorized by pattern, required level of thinking, and topic. McNemar’s test was used to compare the proportion of correct responses between the LLMs. Fisher’s exact test was used to assess the performance of GPT-4 for each topic category. Results: ChatGPT, GPT-4, and Google Bard correctly answered 40.8% (42 of 103), 65.0% (67 of 103), and 38.8% (40 of 103) of the questions, respectively. GPT-4 significantly outperformed ChatGPT by 24.2% (p < 0.001) and Google Bard by 26.2% (p < 0.001). In the categorical analysis by level of thinking, GPT-4 correctly answered 79.7% of the lower-order questions, which was significantly higher than ChatGPT or Google Bard (p < 0.001). The categorical analysis by question pattern revealed GPT-4’s superiority over ChatGPT (67.4% vs. 46.5%, p = 0.004) and Google Bard (39.5%, p < 0.001) in the single-answer questions. The categorical analysis by topic revealed that GPT-4 outperformed ChatGPT (40%, p = 0.013) and Google Bard (26.7%, p = 0.004). No significant differences were observed between the LLMs in the categories not mentioned above. The performance of GPT-4 was significantly better in nuclear medicine (93.3%) than in diagnostic radiology (55.8%; p < 0.001). GPT-4 also performed better on lower-order questions than on higher-order questions (79.7% vs. 45.5%, p < 0.001). Conclusion: ChatGPTplus based on GPT-4 scored 65% when answering Japanese questions from the JRBE, outperforming ChatGPT and Google Bard. This highlights the potential of using LLMs to address advanced clinical questions in the field of radiology in Japan. © 2023, The Author(s).
KW  - Bard
KW  - ChatGPT
KW  - GPT-4
KW  - Japan Radiology Society
KW  - Humans
KW  - Japan
KW  - Nuclear Medicine
KW  - Radiography
KW  - article
KW  - ChatGPT
KW  - controlled study
KW  - human
KW  - human experiment
KW  - Japan
KW  - nuclear medicine
KW  - radiodiagnosis
KW  - thinking
KW  - Japan
KW  - nuclear medicine
KW  - radiography
PB  - Springer
SN  - 18671071 (ISSN)
C2  - 37792149
LA  - English
J2  - Jpn. J. Rad.
M3  - Article
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 2; Correspondence Address: Y. Toyama; Department of Diagnostic Radiology, Tohoku University Hospital, Sendai, 1-1 Seiryo-Machi, Aoba-Ku, 980-8575, Japan; email: ytoyama0818@gmail.com
ER  -

TY  - JOUR
AU  - Baladrón, C.
AU  - Sevilla, T.
AU  - Carrasco-Moraleja, M.
AU  - Gómez-Salvador, I.
AU  - Peral-Oliveira, J.
AU  - San Román, J.A.
TI  - Assessing the accuracy of ChatGPT as a decision support tool in cardiology
ST  - Evaluación de la fiabilidad de ChatGPT como herramienta de soporte a la toma de decisiones en cardiología
PY  - 2024
T2  - Revista Espanola de Cardiologia
DO  - 10.1016/j.recesp.2023.11.014
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85183038893&doi=10.1016%2fj.recesp.2023.11.014&partnerID=40&md5=5ea1e44e9f07779c65579c9351cfbc41
AD  - Servicio de Cardiología, Hospital Clínico Universitario de Valladolid, Valladolid, Spain
AD  - Centro de Investigación Biomédica en Red de Enfermedades Cardiovasculares (CIBERCV), Spain
PB  - Ediciones Doyma, S.L.
SN  - 03008932 (ISSN)
LA  - English
J2  - Rev. Esp. Cardiol.
M3  - Article
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 0; Correspondence Address: T. Sevilla; Servicio de Cardiología, Hospital Clínico Universitario de Valladolid, Valladolid, Spain; email: tereseru@gmail.com; CODEN: RCDOA
ER  -

TY  - JOUR
AU  - Onder, C.E.
AU  - Koc, G.
AU  - Gokbulut, P.
AU  - Taskaldiran, I.
AU  - Kuskonmaz, S.M.
TI  - Evaluation of the reliability and readability of ChatGPT-4 responses regarding hypothyroidism during pregnancy
PY  - 2024
T2  - Scientific Reports
VL  - 14
IS  - 1
C7  - 243
DO  - 10.1038/s41598-023-50884-w
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85181232664&doi=10.1038%2fs41598-023-50884-w&partnerID=40&md5=6c0d24496ef4876306affbee48727a38
AD  - Department of Endocrinology and Metabolic Diseases, Ankara Training and Research Hospital, Ankara, Turkey
AB  - Hypothyroidism is characterized by thyroid hormone deficiency and has adverse effects on both pregnancy and fetal health. Chat Generative Pre-trained Transformer (ChatGPT) is a large language model trained with a very large database from many sources. Our study was aimed to evaluate the reliability and readability of ChatGPT-4 answers about hypothyroidism in pregnancy. A total of 19 questions were created in line with the recommendations in the latest guideline of the American Thyroid Association (ATA) on hypothyroidism in pregnancy and were asked to ChatGPT-4. The reliability and quality of the responses were scored by two independent researchers using the global quality scale (GQS) and modified DISCERN tools. The readability of ChatGPT was assessed used Flesch Reading Ease (FRE) Score, Flesch-Kincaid grade level (FKGL), Gunning Fog Index (GFI), Coleman-Liau Index (CLI), and Simple Measure of Gobbledygook (SMOG) tools. No misleading information was found in any of the answers. The mean mDISCERN score of the responses was 30.26 ± 3.14; the median GQS score was 4 (2–4). In terms of reliability, most of the answers showed moderate (78.9%) followed by good (21.1%) reliability. In the readability analysis, the median FRE was 32.20 (13.00–37.10). The years of education required to read the answers were mostly found at the university level [9 (47.3%)]. Although ChatGPT-4 has significant potential, it can be used as an auxiliary information source for counseling by creating a bridge between patients and clinicians about hypothyroidism in pregnancy. Efforts should be made to improve the reliability and readability of ChatGPT. © 2024, The Author(s).
KW  - Choline O-Acetyltransferase
KW  - Comprehension
KW  - Female
KW  - Health Literacy
KW  - Humans
KW  - Hypothyroidism
KW  - Internet
KW  - Pregnancy
KW  - Reading
KW  - Reproducibility of Results
KW  - United States
KW  - choline acetyltransferase
KW  - comprehension
KW  - female
KW  - health literacy
KW  - human
KW  - hypothyroidism
KW  - Internet
KW  - pregnancy
KW  - reading
KW  - reproducibility
KW  - United States
PB  - Nature Research
SN  - 20452322 (ISSN)
C2  - 38167988
LA  - English
J2  - Sci. Rep.
M3  - Article
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 0; Correspondence Address: C.E. Onder; Department of Endocrinology and Metabolic Diseases, Ankara Training and Research Hospital, Ankara, Turkey; email: drcagatayonder@gmail.com
ER  -

TY  - JOUR
AU  - Hoang, N.S.
TI  - How Automation and ChatGPT Will Affect Competency Definitions and Assessment Tools
PY  - 2024
T2  - Academic Medicine
VL  - 99
IS  - 1
SP  - 8
EP  - 9
DO  - 10.1097/ACM.0000000000005483
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85181161647&doi=10.1097%2fACM.0000000000005483&partnerID=40&md5=583ab1c2fd1cb858baa0a50cc70fd884
AD  - David Geffen School of Medicine, University of California, Los Angeles, Los Angeles, CA, United States
PB  - Wolters Kluwer Health
SN  - 10402446 (ISSN)
C2  - 37890076
LA  - English
J2  - Acad. Med.
M3  - Letter
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 0; Correspondence Address: N.S. Hoang; David Geffen School of Medicine, University of California, Los Angeles, Los Angeles, United States; email: dannyhoangn@gmail.com; CODEN: ACMEE
ER  -

TY  - JOUR
AU  - Chen, T.C.
AU  - Couldwell, M.W.
AU  - Singer, J.
AU  - Singer, A.
AU  - Koduri, L.
AU  - Kaminski, E.
AU  - Nguyen, K.
AU  - Multala, E.
AU  - Dumont, A.S.
AU  - Wang, A.
TI  - Assessing the clinical reasoning of ChatGPT for mechanical thrombectomy in patients with stroke
PY  - 2024
T2  - Journal of NeuroInterventional Surgery
C7  - jnis-2023-021163
DO  - 10.1136/jnis-2023-021163
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85183414995&doi=10.1136%2fjnis-2023-021163&partnerID=40&md5=a4a6e40c24f30763c6d9eceed96cf9bd
AD  - Tulane University School of Medicine, New Orleans, LA, United States
AD  - Department of Neurological Surgery, Tulane University School of Medicine, New Orleans, 70112, LA, United States
AB  - Background: Artificial intelligence (AI) has become a promising tool in medicine. ChatGPT, a large language model AI Chatbot, shows promise in supporting clinical practice. We assess the potential of ChatGPT as a clinical reasoning tool for mechanical thrombectomy in patients with stroke. Methods: An internal validation of the abilities of ChatGPT was first performed using artificially created patient scenarios before assessment of real patient scenarios from the medical center's stroke database. All patients with large vessel occlusions who underwent mechanical thrombectomy at Tulane Medical Center between January 1, 2022 and December 31, 2022 were included in the study. The performance of ChatGPT in evaluating which patients should undergo mechanical thrombectomy was compared with the decisions made by board-certified stroke neurologists and neurointerventionalists. The interpretation skills, clinical reasoning, and accuracy of ChatGPT were analyzed. Results: 102 patients with large vessel occlusions underwent mechanical thrombectomy. ChatGPT agreed with the physician's decision whether or not to pursue thrombectomy in 54.3% of the cases. ChatGPT had mistakes in 8.8% of the cases, consisting of mathematics, logic, and misinterpretation errors. In the internal validation phase, ChatGPT was able to provide nuanced clinical reasoning and was able to perform multi-step thinking, although with an increased rate of making mistakes. Conclusion: ChatGPT shows promise in clinical reasoning, including the ability to factor a patient's underlying comorbidities when considering mechanical thrombectomy. However, ChatGPT is prone to errors as well and should not be relied on as a sole decision-making tool in its present form, but it has potential to assist clinicians with more efficient work flow.  © 2024 Author(s). Published by BMJ.
KW  - Stroke
KW  - Thrombectomy
PB  - BMJ Publishing Group
SN  - 17598478 (ISSN)
C2  - 38184368
LA  - English
J2  - J. Neurointervent. Surg.
M3  - Article
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 0; Correspondence Address: A. Wang; Department of Neurological Surgery, Tulane University School of Medicine, New Orleans, 70112, United States; email: awang15@tulane.edu
ER  -

TY  - JOUR
AU  - Lu, Q.
AU  - Yao, Y.
AU  - Xiao, L.
AU  - Yuan, M.
AU  - Wang, J.
AU  - Zhu, X.
TI  - Can ChatGPT effectively complement teacher assessment of undergraduate students’ academic writing?
PY  - 2024
T2  - Assessment and Evaluation in Higher Education
DO  - 10.1080/02602938.2024.2301722
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85182206846&doi=10.1080%2f02602938.2024.2301722&partnerID=40&md5=6dd8dea96d1330fffb787cfcc1835cc7
AD  - Zhejiang University, Hangzhou, China
AD  - The Hong Kong Polytechnic University, Hong Kong
AD  - Mudanjiang Normal University, Mudanjiang, China
AB  - The integration of ChatGPT as a supplementary tool for writing instruction has gained traction. However, uncertainties persist regarding how ChatGPT complements teacher assessment and the overall effectiveness of this combined approach. To address this, we conducted a mixed-methods investigation involving 46 undergraduate students from a research university in southern China, engaging them in a Chinese academic writing task. The intraclass correlation coefficient results revealed ChatGPT’s efficiency in scoring students’ writing, showing moderate to good consistency with teacher evaluations. A paired sample t-test unveiled significant differences in feedback quantity and types between ChatGPT and teacher assessments. Drawing from both interview data and quantitative findings, the study uncovers three ways in which ChatGPT complements teacher assessment, benefiting students with various writing proficiency levels: (1) fostering deeper comprehension of teacher assessments among students, (2) encouraging students to make judgments regarding feedback, and (3) promoting independent thinking about revisions. This study contributes to a more comprehensive understanding of the role of ChatGPT within the context of a combined assessment approach. It underscores that certain inherent weaknesses in ChatGPT’s functioning can paradoxically lead to favorable outcomes. By shedding light on the synergy between ChatGPT and teacher assessments, this research seeks to inform and enhance writing instruction in higher education. © 2024 Informa UK Limited, trading as Taylor & Francis Group.
KW  - academic writing
KW  - ChatGPT
KW  - teacher assessment
PB  - Routledge
SN  - 02602938 (ISSN)
LA  - English
J2  - Assess. Eval. High. Educ.
M3  - Article
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 0; Correspondence Address: X. Zhu; The Hong Kong Polytechnic University, Hong Kong; email: xinhua.zhu@polyu.edu.hk
ER  -

TY  - JOUR
AU  - Razdan, S.
AU  - Valenzuela, R.J.
TI  - Response to commentary on: assessing ChatGPT’s ability to answer questions pertaining to erectile dysfunction: can our patients trust it?
PY  - 2024
T2  - International Journal of Impotence Research
DO  - 10.1038/s41443-024-00823-8
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85182662979&doi=10.1038%2fs41443-024-00823-8&partnerID=40&md5=df667f9357fba56b9dd53d3567a9d011
AD  - Department of Urology, Icahn School of Medicine at Mount Sinai Hospital, New York, 10029, NY, United States
PB  - Springer Nature
SN  - 09559930 (ISSN)
LA  - English
J2  - Int. J. Impotence Res.
M3  - Note
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 0; Correspondence Address: S. Razdan; Department of Urology, Icahn School of Medicine at Mount Sinai Hospital, New York, 10029, United States; email: shirinrazdan1@gmail.com; CODEN: IJIRF
ER  -

TY  - CONF
AU  - Ni, Z.
AU  - Qian, Y.
AU  - Vaillant, P.
AU  - Jaulent, M.-C.
AU  - Bousquet, C.
TI  - Assessing ChatGPT's Performance in Health Fact-Checking: Performance, Biases, and Risks
PY  - 2024
T2  - Communications in Computer and Information Science
VL  - 1957 CCIS
SP  - 403
EP  - 408
DO  - 10.1007/978-3-031-49212-9_50
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85180150795&doi=10.1007%2f978-3-031-49212-9_50&partnerID=40&md5=4285628185cc2b63f2849b89780e8e21
AD  - School of Information Management, Wuhan University, Wuhan, China
AD  - Laboratoire d’Informatique Médicale et d’Ingénierie des Connaissances en eSanté (LIMICS), Sorbonne Université, Inserm, Paris, France
AB  - The increasing use of ChatGPT by the general public has prompted us to assess ChatGPT's performance in health fact-checking and uncover potential biases and risks arising from its utilization. In this study, we employed two publicly accessible datasets to evaluate ChatGPT's performance. We utilized BERTopic for clustering health claims into topics and subsequently employed the gpt-3.5-turbo API for fact-checking these claims. ChatGPT's performance was appraised on multi-class (False, Mixture, Mostly-False, Mostly-True, True) and binary (True, False) levels, with a thorough analysis of its performance across various topics. ChatGPT achieved a F1-score of 0.54 and 0.64 in the multi-class task and 0.88 and 0.85 in the binary task on the two datasets, respectively. In most health topics (e.g., vaccines, Covid-19), ChatGPT's F1-score exceeded 0.8, except for specific topics, such as novel or contentious cancer treatments, which yielded a F1-score below 0.6. We scrutinized the erroneous fact-checking labels and explanations provided by ChatGPT, revealing that it may produce inaccurate results for claims with misleading intent, inaccurate information, emerging research findings, or contentious health knowledge. © 2024, The Author(s), under exclusive license to Springer Nature Switzerland AG.
KW  - Health information retrieval
KW  - Large language model
KW  - Misinformation
KW  - Risk assessment
KW  - Clusterings
KW  - F1 scores
KW  - General publics
KW  - Health information retrieval
KW  - Health informations
KW  - Language model
KW  - Large language model
KW  - Misinformation
KW  - Performance
KW  - Publicly accessible
KW  - Health risks
A2  - Stephanidis C.
A2  - Antona M.
A2  - Ntoa S.
A2  - Salvendy G.
PB  - Springer Science and Business Media Deutschland GmbH
SN  - 18650929 (ISSN); 978-303149211-2 (ISBN)
LA  - English
J2  - Commun. Comput. Info. Sci.
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 0; Correspondence Address: Z. Ni; School of Information Management, Wuhan University, Wuhan, China; email: jennie_n@whu.edu.cn; Conference name: 25th International Conference on Human-Computer Interaction, HCII 2023; Conference date: 23 July 2023 through 28 July 2023; Conference code: 305169
ER  -

TY  - JOUR
AU  - Liu, D.
AU  - Zhang, B.
AU  - Liu, J.
AU  - Li, H.
AU  - Song, L.
AU  - Zhang, G.
TI  - Assessing protein model quality based on deep graph coupled networks using protein language model
PY  - 2024
T2  - Briefings in Bioinformatics
VL  - 25
IS  - 1
C7  - bbad420
DO  - 10.1093/bib/bbad420
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85178494943&doi=10.1093%2fbib%2fbbad420&partnerID=40&md5=f62aea90d0b1ae7d6023faf565af37e1
AD  - College of Information Engineering, Zhejiang University of Technology, China
AD  - Researcher of Ai in the BioMap, China
AD  - Chief Scientist of Ai in the BioMap, Mbzuai, United Arab Emirates
AB  - Model quality evaluation is a crucial part of protein structural biology. How to distinguish high-quality models from low-quality models, and to assess which high-quality models have relatively incorrect regions for improvement, are remain a challenge. More importantly, the quality assessment of multimer models is a hot topic for structure prediction. In this study, we propose GraphCPLMQA, a novel approach for evaluating residue-level model quality that combines graph coupled networks and embeddings from protein language models. The GraphCPLMQA consists of a graph encoding module and a transform-based convolutional decoding module. In encoding module, the underlying relational representations of sequence and high-dimensional geometry structure are extracted by protein language models with Evolutionary Scale Modeling. In decoding module, the mapping connection between structure and quality is inferred by the representations and low-dimensional features. Specifically, the triangular location and residue level contact order features are designed to enhance the association between the local structure and the overall topology. Experimental results demonstrate that GraphCPLMQA using single-sequence embedding achieves the best performance compared with the CASP15 residue-level interface evaluation methods among 9108 models in the local residue interface test set of CASP15 multimers. In CAMEO blind test (20 May 2022 to 13 August 2022), GraphCPLMQA ranked first compared with other servers (https://www.cameo3d.org/quality-estimation). GraphCPLMQA also outperforms state-of-the-art methods on 19, 035 models in CASP13 and CASP14 monomer test set.  © 2023 The Author(s). Published by Oxford University Press.
KW  - graph neural network
KW  - multimer model evaluation
KW  - protein language model
KW  - protein model evaluation
KW  - Computational Biology
KW  - Language
KW  - Neural Networks, Computer
KW  - Proteins
KW  - protein
KW  - artificial neural network
KW  - bioinformatics
KW  - chemistry
KW  - language
KW  - procedures
PB  - Oxford University Press
SN  - 14675463 (ISSN)
C2  - 38018909
LA  - English
J2  - Brief. Bioinform.
M3  - Article
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 0; Correspondence Address: H. Li; BioMap, Beijing, 100038, China; email: lihui@biomap.com; L. Song; BioMap, Mbzuai, Beijing, 100038, China; email: songle@biomap.com; G. Zhang; College of Information Engineering, Zhejiang University of Technology, Hangzhou, 310023, China; email: zgj@zjut.edu.cn
ER  -

TY  - CONF
AU  - Al Mouatamid, Y.
AU  - Zahir, J.
AU  - Bonnin, M.
AU  - Mousannif, H.
TI  - Assessing Ocean s Legal Protection Using AI: A New Dataset and a BERT-Based Classifier
PY  - 2023
T2  - Frontiers in Artificial Intelligence and Applications
VL  - 379
SP  - 263
EP  - 268
DO  - 10.3233/FAIA230972
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85181173521&doi=10.3233%2fFAIA230972&partnerID=40&md5=a34265becfdb3933200aa656fcd7ab96
AD  - Lisi Laboratory, Cadi Ayyad University, Marrakesh, Morocco
AD  - Ummisco, Ird France Nord, Bondy, F-93143, France
AD  - Ird, Univ Brest, Cnrs, Ifremer, Lemar, Plouzane, F-29280, France
AD  - Univ Brest, Lemar, Plouzane, F-29280, France
AB  - This paper aims to address the challenge of using artificial intelligence for empirical legal studies. We introduce a new annotated dataset on French marine environmental law dealing with definitions, bans, sanctions, and controls on living (turtles and seabirds) and non-living (plastic bags and straws) subjects. The annotation has been produced by law students and validated by a legal expert. Based on the developed dataset, we train a CamemBERT-based classifier which accurately predicts the class of a given legal article according to the pre-defined classes within the dataset we have created. The proposed training set and the resulting trained model provide a better interpretation and accessibility of legal texts to specialists and the general public, based on findings from legal studies and on natural language processing techniques.  © 2023 The Authors.
KW  - CamemBERT
KW  - Classification
KW  - datasets
KW  - empirical legal studies
KW  - Machine learning
KW  - marine environmental law
KW  - Environmental regulations
KW  - Learning algorithms
KW  - Machine learning
KW  - Natural language processing systems
KW  - Plastic containers
KW  - Annotated datasets
KW  - CamemBERT
KW  - Dataset
KW  - Empirical legal study
KW  - Environmental law
KW  - Legal experts
KW  - Legal protection
KW  - Machine-learning
KW  - Marine environmental law
KW  - Plastic bags
KW  - Classification (of information)
A2  - Sileno G.
A2  - Spanakis J.
A2  - van Dijck G.
PB  - IOS Press BV
SN  - 09226389 (ISSN); 978-164368472-7 (ISBN)
LA  - English
J2  - Front. Artif. Intell. Appl.
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 0; Correspondence Address: Y. Al Mouatamid; Lisi Laboratory, Cadi Ayyad University, Marrakesh, Morocco; email: youssef.almouatamid@univ-brest.fr; Conference name: 36th International Conference on Legal Knowledge and Information Systems, JURIX 2023; Conference date: 18 December 2023 through 20 December 2023; Conference code: 195587
ER  -

TY  - CONF
AU  - Sobania, D.
AU  - Geiger, A.
AU  - Callan, J.
AU  - Brownlee, A.
AU  - Hanna, C.
AU  - Moussa, R.
AU  - López, M.Z.
AU  - Petke, J.
AU  - Sarro, F.
TI  - Evaluating Explanations for Software Patches Generated by Large Language Models
PY  - 2024
T2  - Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)
VL  - 14415 LNCS
SP  - 147
EP  - 152
DO  - 10.1007/978-3-031-48796-5_12
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85180532579&doi=10.1007%2f978-3-031-48796-5_12&partnerID=40&md5=0f04921e8e9bd7049965907203ce56f0
AD  - Johannes Gutenberg University Mainz, Mainz, Germany
AD  - University College London, London, United Kingdom
AD  - University of Stirling, Stirling, United Kingdom
AB  - Large language models (LLMs) have recently been integrated in a variety of applications including software engineering tasks. In this work, we study the use of LLMs to enhance the explainability of software patches. In particular, we evaluate the performance of GPT 3.5 in explaining patches generated by the search-based automated program repair system ARJA-e for 30 bugs from the popular Defects4J benchmark. We also investigate the performance achieved when explaining the corresponding patches written by software developers. We find that on average 84% of the LLM explanations for machine-generated patches were correct and 54% were complete for the studied categories in at least 1 out of 3 runs. Furthermore, we find that the LLM generates more accurate explanations for machine-generated patches than for human-written ones. © 2024, The Author(s), under exclusive license to Springer Nature Switzerland AG.
KW  - AI Explainability
KW  - Genetic Improvement
KW  - Large Language Models
KW  - Program Repair
KW  - Software Patches
KW  - Application programs
KW  - Computational linguistics
KW  - Program debugging
KW  - Repair
KW  - AI explainability
KW  - Engineering tasks
KW  - Genetic improvements
KW  - Language model
KW  - Large language model
KW  - Performance
KW  - Program repair
KW  - Repair system
KW  - Search-based
KW  - Software patches
KW  - Benchmarking
A2  - Arcaini P.
A2  - Yue T.
A2  - Fredericks E.M.
PB  - Springer Science and Business Media Deutschland GmbH
SN  - 03029743 (ISSN); 978-303148795-8 (ISBN)
LA  - English
J2  - Lect. Notes Comput. Sci.
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 0; Correspondence Address: D. Sobania; Johannes Gutenberg University Mainz, Mainz, Germany; email: dsobania@uni-mainz.de; Conference name: 15th International Symposium on Search-Based Software Engineering, SSBSE 2023; Conference date: 8 December 2023 through 8 December 2023; Conference code: 305359
ER  -

TY  - JOUR
AU  - Tirumala, A.K.G.
AU  - Mishra, S.
AU  - Trivedi, N.
AU  - Shivakumar, D.
AU  - Singh, A.
AU  - Shariff, S.
TI  - A cross-sectional study to assess response generated by ChatGPT and ChatSonic to patient queries about Epilepsy
PY  - 2024
T2  - Telematics and Informatics Reports
VL  - 13
C7  - 100110
DO  - 10.1016/j.teler.2023.100110
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85180449629&doi=10.1016%2fj.teler.2023.100110&partnerID=40&md5=fa10dae8e0f8375e32c2145788647472
AD  - Davao Medical School Foundation, Inc, Philippines
AD  - Deanery of Clinical Sciences, College of Medicine and Veterinary Medicine, The University of Edinburgh, Edinburgh, United Kingdom
AD  - Medical College Baroda, The M.S University, Vadodara, India
AD  - Kamineni Academy of Medical Sciences and Research Centre, India
AD  - Clinical Sciences, Spartan Health Sciences University, Saint Lucia
AD  - Yerevan State Medical University, Armenia
AB  - Objective: This article presents a study comparing the responses of two AI chatbots, ChatGPT and ChatSonic, regarding inquiries about epilepsy. Overall, ChatGPT and ChatSonic are very similar in terms of their capabilities and limitations and they are the most widely used AI software. However, there are some key differences, such as their training data, supported languages, and pricing model. The study aims to assess the potential application of AI in patient counseling and decision-making regarding epilepsy treatment. Methods: The study categorized the inquiries of patients about epilepsy into two groups: patient counseling and judgment. Ten questions were formulated within these categories. Two specialized doctors evaluated the reliability and accuracy of the chatbot replies using the Global Quality Scale (GQS) and a modified version of the DISCERN score. Results: The median value for GQS of 4.5 was given by Evaluator JC, and a median value for GQS of 4.0 was given by Evaluator VV. Furthermore, a median for RS of 5.0 was given by Evaluator JC, and a median for RS of 4.0 was given by Evaluator VV. The GQS data from Evaluators JC and VV have a Spearman correlation coefficient of -0.531, indicating an inversely proportional association, and a p-value of 0.016, indicating a statistically significant relationship between the variables. However, the correlation coefficient of RS between data by Evaluator JC and Evaluator VV is 0.368 which indicates the correlation is a directly proportional relationship, with a p-value of 0.110 which is not statistically significant, does not establish a relation between the variables. Weighted Kappa was used to study the agreement between the data. With a weighted kappa value of -0.318 and a 95 %CI of -0.570, -0.065 was obtained for GQS. This can help reject the null hypothesis indicating that the values by the Evaluator JC and Evaluator VV are statistically significant and has a negative agreement. However, a weighted kappa value of 0.1327 with a 95 %CI of -0.093, 0.359 obtained for RS, fails to reject the null hypothesis indicating that the values by the Evaluator JC and Evaluator VV are not significant and no agreement exists between the Evaluators. The results of this study suggest that both ChatGPT and ChatSonic have the potential to be valuable tools for epilepsy patients and their healthcare providers. However, it is important to note that the two evaluators had better agreement on the GQS scores than on the RS scores, suggesting that the GQS may be a more reliable measure of the quality of chatbot responses. Conclusion: The findings underscore the importance of collaboration among policymakers, healthcare professionals, and AI designers to ensure appropriate and safe utilization of AI chatbots in the healthcare domain. While AI chatbots can provide valuable information, it is crucial to acknowledge their limitations, including reliance on the training data and occasional factual errors. The study highlights the need for further testing and validation of AI language models in the management of epilepsy as it concludes. © 2023 The Authors
KW  - ChatGPT
KW  - Epilepsy
KW  - Global reliability score
KW  - Patient behaviour
PB  - Elsevier B.V.
SN  - 27725030 (ISSN)
LA  - English
J2  - Telemat. Inform. Rep.
M3  - Article
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 0; Correspondence Address: S. Shariff; Yerevan State Medical University, Armenia; email: sanobarshariff@gmail.com
ER  -

TY  - JOUR
AU  - Abi-Rafeh, J.
AU  - Mroueh, V.J.
AU  - Bassiri-Tehrani, B.
AU  - Marks, J.
AU  - Kazan, R.
AU  - Nahai, F.
TI  - Complications Following Body Contouring: Performance Validation of Bard, a Novel AI Large Language Model, in Triaging and Managing Postoperative Patient Concerns
PY  - 2024
T2  - Aesthetic Plastic Surgery
DO  - 10.1007/s00266-023-03819-9
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85182990304&doi=10.1007%2fs00266-023-03819-9&partnerID=40&md5=5cf27c91c85f5d82e9789779989b437c
AD  - Division of Plastic, Reconstructive, and Aesthetic Surgery, McGill University Health Centre, Montreal, QC, Canada
AD  - Brigham and Women’s Hospital, Harvard Medical School, Boston Massachusetts, United States
AD  - Private Practice, New York, NY, United States
AD  - Manhattan Eye, Ear, and Throat Hospital, New York, NY, United States
AD  - Department of Surgery, Emory University, Atlanta, GA, United States
AB  - Introduction: Large language models (LLM) have revolutionized the way humans interact with artificial intelligence (AI) technology, with marked potential for applications in esthetic surgery. The present study evaluates the performance of Bard, a novel LLM, in identifying and managing postoperative patient concerns for complications following body contouring surgery. Methods: The American Society of Plastic Surgeons’ website was queried to identify and simulate all potential postoperative complications following body contouring across different acuities and severity. Bard’s accuracy was assessed in providing a differential diagnosis, soliciting a history, suggesting a most-likely diagnosis, appropriate disposition, treatments/interventions to begin from home, and red-flag signs/symptoms indicating deterioration, or requiring urgent emergency department (ED) presentation. Results: Twenty-two simulated body contouring complications were examined. Overall, Bard demonstrated a 59% accuracy in listing relevant diagnoses on its differentials, with a 52% incidence of incorrect or misleading diagnoses. Following history-taking, Bard demonstrated an overall accuracy of 44% in identifying the most-likely diagnosis, and a 55% accuracy in suggesting the indicated medical dispositions. Helpful treatments/interventions to begin from home were suggested with a 40% accuracy, whereas red-flag signs/symptoms, indicating deterioration, were shared with a 48% accuracy. A detailed analysis of performance, stratified according to latency of postoperative presentation (<48hours, 48hours–1month, or >1month postoperatively), and according to acuity and indicated medical disposition, is presented herein. Conclusions: Despite promising potential of LLMs and AI in healthcare-related applications, Bard’s performance in the present study significantly falls short of accepted clinical standards, thus indicating a need for further research and development prior to adoption. Level of Evidence IV: This journal requires that authors assign a level of evidence to each article. For a full description of these Evidence-Based Medicine ratings, please refer to the Table of Contents or the online Instructions to Authors www.springer.com/00266 . © 2024, Springer Science+Business Media, LLC, part of Springer Nature and International Society of Aesthetic Plastic Surgery.
KW  - Artificial intelligence
KW  - Body contouring
KW  - Complications
PB  - Springer
SN  - 0364216X (ISSN)
LA  - English
J2  - Aesthet. Plast. Surg.
M3  - Article
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 0; Correspondence Address: F. Nahai; Department of Surgery, Emory University, Atlanta, United States; email: nahaimd@aol.com; CODEN: APSUD
ER  -

TY  - JOUR
AU  - Huang, X.
AU  - Estau, D.
AU  - Liu, X.
AU  - Yu, Y.
AU  - Qin, J.
AU  - Li, Z.
TI  - Evaluating the performance of ChatGPT in clinical pharmacy: A comparative study of ChatGPT and clinical pharmacists
PY  - 2024
T2  - British Journal of Clinical Pharmacology
VL  - 90
IS  - 1
SP  - 232
EP  - 238
DO  - 10.1111/bcp.15896
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85170657916&doi=10.1111%2fbcp.15896&partnerID=40&md5=16b41a265ab2061a234e5e1538d1acec
AD  - Department of Pharmacy, Peking University Third Hospital, Beijing, China
AD  - Department of Pharmaceutical Management and Clinical Pharmacy, College of Pharmacy, Peking University, Beijing, China
AD  - Department of Cardiology and Institute of Vascular Medicine, Peking University Third Hospital, Beijing Key Laboratory of Cardiovascular Receptors Research, Key Laboratory of Cardiovascular Molecular Biology and Regulatory Peptides, Ministry of Health, State Key Laboratory of Vascular Homeostasis and Remodeling, Peking University, Beijing, China
AB  - Aims: To evaluate the performance of chat generative pretrained transformer (ChatGPT) in key domains of clinical pharmacy practice, including prescription review, patient medication education, adverse drug reaction (ADR) recognition, ADR causality assessment and drug counselling. Methods: Questions and clinical pharmacist's answers were collected from real clinical cases and clinical pharmacist competency assessment. ChatGPT's responses were generated by inputting the same question into the ‘New Chat’ box of ChatGPT Mar 23 Version. Five licensed clinical pharmacists independently rated these answers on a scale of 0 (Completely incorrect) to 10 (Completely correct). The mean scores of ChatGPT and clinical pharmacists were compared using a paired 2-tailed Student's t-test. The text content of the answers was also descriptively summarized together. Results: The quantitative results indicated that ChatGPT was excellent in drug counselling (ChatGPT: 8.77 vs. clinical pharmacist: 9.50, P =.0791) and weak in prescription review (5.23 vs. 9.90, P =.0089), patient medication education (6.20 vs. 9.07, P =.0032), ADR recognition (5.07 vs. 9.70, P =.0483) and ADR causality assessment (4.03 vs. 9.73, P =.023). The capabilities and limitations of ChatGPT in clinical pharmacy practice were summarized based on the completeness and accuracy of the answers. ChatGPT revealed robust retrieval, information integration and dialogue capabilities. It lacked medicine-specific datasets as well as the ability for handling advanced reasoning and complex instructions. Conclusions: While ChatGPT holds promise in clinical pharmacy practice as a supplementary tool, the ability of ChatGPT to handle complex problems needs further improvement and refinement. © 2023 British Pharmacological Society.
KW  - ChatGPT
KW  - clinical pharmacy
KW  - Clinical Competence
KW  - Drug-Related Side Effects and Adverse Reactions
KW  - Humans
KW  - Pharmacists
KW  - Pharmacy
KW  - Pharmacy Service, Hospital
KW  - adverse drug reaction
KW  - Article
KW  - causality
KW  - ChatGPT
KW  - clinical pharmacist
KW  - clinical pharmacy
KW  - comparative study
KW  - controlled study
KW  - counseling
KW  - data accuracy
KW  - data completeness
KW  - data integration
KW  - human
KW  - information retrieval
KW  - patient education
KW  - pharmacy practice
KW  - prescription
KW  - quantitative analysis
KW  - reasoning
KW  - adverse drug reaction
KW  - clinical competence
KW  - hospital pharmacy
KW  - pharmacist
KW  - pharmacy (shop)
PB  - John Wiley and Sons Inc
SN  - 03065251 (ISSN)
C2  - 37626010
LA  - English
J2  - Br. J. Clin. Pharmacol.
M3  - Article
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 1; Correspondence Address: Z. Li; Department of Pharmacy, Peking University Third Hospital, Beijing, No.49 Huayuan North Road, Haidian District, 100191, China; email: lizijian@bjmu.edu.cn; CODEN: BCPHB
ER  -

TY  - JOUR
AU  - Naser, M.Z.
AU  - Ross, B.
AU  - Ogle, J.
AU  - Kodur, V.
AU  - Hawileh, R.
AU  - Abdalla, J.
AU  - Thai, H.-T.
TI  - Evaluating the Performance of Artificial Intelligence Chatbots and Large Language Models in the FE and PE Structural Exams
PY  - 2024
T2  - Practice Periodical on Structural Design and Construction
VL  - 29
IS  - 2
C7  - 02524001
DO  - 10.1061/PPSCFX.SCENG-1369
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85182780051&doi=10.1061%2fPPSCFX.SCENG-1369&partnerID=40&md5=cfb9ef132b17011f082e61f2b415ba7f
AD  - School of Civil and Environmental Engineering and Earth Sciences, Clemson Univ., Clemson, 29631, SC, United States
AD  - Artificial Intelligence Research Institute for Science and Engineering (AIRISE), Clemson Univ., Clemson, 29631, SC, United States
AD  - Dept. of Civil and Environmental Engineering, Michigan State Univ., East Lansing, 48824, MI, United States
AD  - Dept. of Civil Engineering, American Univ. of Sharjah, Sharjah, 26666, United Arab Emirates
AD  - Dept. of Infrastructure Engineering, Univ. of Melbourne, Parkville, Melbourne, 3052, VIC, Australia
PB  - American Society of Civil Engineers (ASCE)
SN  - 10840680 (ISSN)
LA  - English
J2  - Pract Period Struct Des Constr
M3  - Note
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 0; Correspondence Address: M.Z. Naser; School of Civil and Environmental Engineering and Earth Sciences, Clemson Univ., Clemson, 29631, United States; email: mznaser@clemson.edu; CODEN: PPSCF
ER  -

TY  - JOUR
AU  - Yeo, Y.H.
AU  - Yang, J.D.
TI  - Correspondence on Letter regarding “Assessing the performance of ChatGPT in answering questions regarding cirrhosis and hepatocellular carcinoma”
PY  - 2024
T2  - Clinical and Molecular Hepatology
VL  - 30
IS  - 1
SP  - 124
EP  - 125
DO  - 10.3350/cmh.2023.0470
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85181653767&doi=10.3350%2fcmh.2023.0470&partnerID=40&md5=39eda5803eccfe72bca994652b64f693
AD  - Karsh Division of Gastroenterology and Hepatology, Cedars-Sinai Medical Center, Los Angeles, CA, United States
AD  - Samuel Oschin Comprehensive Cancer Institute, Cedars-Sinai Medical Center, Los Angeles, CA, United States
AD  - Comprehensive Transplant Center, Cedars-Sinai Medical Center, Los Angeles, CA, United States
KW  - Artificial intelligence
KW  - Health literacy
KW  - Non-alcoholic fatty liver disease
KW  - artificial intelligence
KW  - ChatGPT
KW  - fatty liver
KW  - health literacy
KW  - human
KW  - large language model
KW  - Letter
KW  - liver cell carcinoma
KW  - liver cirrhosis
KW  - patient education
KW  - recall
PB  - Korean Association for the Study of the Liver
SN  - 22872728 (ISSN)
C2  - 37957812
LA  - English
J2  - Clin. Mol. Hepatol.
M3  - Letter
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 0; Correspondence Address: J.D. Yang; Karsh Division of Gastroenterology and Hepatology, Samuel Oschin Comprehensive Cancer Institute, Comprehensive Transplant Center, Cedars-Sinai Medical Center, Los Angeles, 8700 Beverly Blvd., 90048, United States; email: judong.yang@cshs.org
ER  -

TY  - JOUR
AU  - May, M.
AU  - Körner-Riffard, K.
AU  - Kollitsch, L.
TI  - Can ChatGPT Realistically and Reproducibly Assess the Difficulty Level of Written Questions in the In-Service Assessment of the European Board of Urology? [Urology, 2023 Jul;177:29-33. doi: 10.1016/j.urology.2023.05.010]
PY  - 2024
T2  - Urology
VL  - 183
SP  - 302
EP  - 303
DO  - 10.1016/j.urology.2023.09.036
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85178197818&doi=10.1016%2fj.urology.2023.09.036&partnerID=40&md5=fecd88015151ca373d2069ad43913175
AD  - Department of Urology, St. Elisabeth Hospital Straubing, Brothers of Mercy Hospital, Straubing, Germany
AD  - Department of Urology, Caritas St. Josef Medical Centre, University of Regensburg, Regensburg, Germany
AD  - Department of Urology and Andrology, Klinik Donaustadt, Vienna, Austria
KW  - Humans
KW  - Urology
KW  - artificial intelligence
KW  - certification
KW  - ChatGPT
KW  - correlation coefficient
KW  - correlational study
KW  - digital technology
KW  - European
KW  - human
KW  - large language model
KW  - Letter
KW  - medical society
KW  - multiple choice test
KW  - reproducibility
KW  - urologist
KW  - urology
PB  - Elsevier Inc.
SN  - 00904295 (ISSN)
C2  - 37838001
LA  - English
J2  - Urology
M3  - Letter
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 1; Correspondence Address: M. May; Department of Urology, St. Elisabeth Hospital Straubing, Brothers of Mercy Hospital, Straubing, Germany; email: matthias.may@klinikum-straubing.de; CODEN: URGYA
ER  -

TY  - JOUR
AU  - Daungsupawong, H.
AU  - Wiwanitkit, V.
TI  - Comment on “Credibility of ChatGPT in the assessment of obesity in type 2 diabetes according to the guidelines”
PY  - 2024
T2  - International Journal of Obesity
VL  - 48
IS  - 2
SP  - 288
DO  - 10.1038/s41366-023-01437-8
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85179362873&doi=10.1038%2fs41366-023-01437-8&partnerID=40&md5=29adc836b185f1d27e403b23b03c9377
AD  - Private Academic Consultant, Phonhong, Laos
AD  - Chandigarh University, Mohali, India
PB  - Springer Nature
SN  - 03070565 (ISSN)
C2  - 38081927
LA  - English
J2  - Int. J. Obes.
M3  - Letter
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 0; Correspondence Address: H. Daungsupawong; Private Academic Consultant, Phonhong, Laos; email: hinpetchdaung@gmail.com; CODEN: IJOBD
ER  -

TY  - JOUR
AU  - Lapp, E.C.
AU  - Lapp, L.W.P.
TI  - Evaluating ChatGPT as a viable research tool for typological investigations of cultural heritage artefacts—Roman clay oil lamps
PY  - 2024
T2  - Archaeometry
DO  - 10.1111/arcm.12937
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85181439297&doi=10.1111%2farcm.12937&partnerID=40&md5=92447d9c0b4009fc33da1aa8686f460a
AD  - Community College of Baltimore County, Baltimore, MD, United States
AD  - Baltimore Polytechnic Institute, Baltimore, MD, United States
AB  - This study evaluates the current viability of ChatGPT as a research tool in lychnology, a discipline of archaeology focusing on the study of light use and lamps in antiquity. Prompts applicable to a common cultural heritage artifact group—the Roman clay oil lamp—were entered in ChatGPT to test its capabilities in compiling, categorizing, describing, and identifying lamp types, and to assess how accurate, detailed, and knowledgeable its responses would be. © 2024 The Authors. Archaeometry © 2024 University of Oxford.
KW  - archaeometry
KW  - artificial intelligence
KW  - chatbot
KW  - ChatGPT
KW  - computer
KW  - cultural heritage artefact
KW  - lychnology
KW  - machine learning
KW  - neural networks
KW  - Roman lamps
PB  - John Wiley and Sons Inc
SN  - 0003813X (ISSN)
LA  - English
J2  - Archaeometry
M3  - Article
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 0; Correspondence Address: E.C. Lapp; Community College of Baltimore County, Baltimore, United States; email: eric.lapp@verizon.net
ER  -

TY  - JOUR
AU  - Saif, N.
AU  - Khan, S.U.
AU  - Shaheen, I.
AU  - Alotaibi, A.
AU  - Alnfiai, M.M.
AU  - Arif, M.
TI  - Chat-GPT; validating Technology Acceptance Model (TAM) in education sector via ubiquitous learning mechanism
PY  - 2024
T2  - Computers in Human Behavior
VL  - 154
C7  - 108097
DO  - 10.1016/j.chb.2023.108097
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85182271397&doi=10.1016%2fj.chb.2023.108097&partnerID=40&md5=87bbb44e98d1f1d37eb0180c36148b7e
AD  - Institute of Management Sciences, University of Science and Technology Bannu, Pakistan
AD  - Department of Computer Science & IT, University of Lakki Marwat, Pakistan
AD  - University of Kotli AJK, Pakistan
AD  - Department of Information Science, College of Humanities and Social Sciences, King Saud University, Saudi Arabia
AD  - Department of Information Technology, College of Computers and Information Technology, Taif University, Taif, 21944, Saudi Arabia
AD  - Department of Computer Engineering, Gachon University, Seongnam-si, 13120, South Korea
AB  - The current study aims to establish a connection between students' behavioral concerns, namely stress and anxiety, related to the completion of academic tasks, and their integration of technology using the Technology Acceptance Model (TAM) through the utilization of Chat-GPT via ubiquitous learning (UL) procedure. To achieve this objective, data was collected from 156 students studying management science who were engaged in their final year research projects or internship reports from selected universities in Pakistan. The gathered data underwent analysis through Structural Equation Modeling (SEM) using Smart PLS software. The findings reveal a significant relationship: students' stress contributes to the emergence of anxiety, which in turn motivates the adoption of technology-assisted solutions, specifically Chat-GPT, to efficiently complete assigned tasks within deadlines working through any device from anywhere. Consequently, the perceived ease of use and usefulness associated with Chat-GPT's AI-generated text contribute to shaping students' favorable attitudes toward utilizing Chat-GPT and also play a role in reducing their stress levels. Furthermore, the study confirms that the development of a positive attitude in students acts as a driving force, compelling them to engage with Chat-GPT through ubiquitous learning (UL) procedure, ultimately resulting in increased actual usage of Chat-GPT. This pattern, in turn, contributes to stress and anxiety reduction among management science students. The study's outcomes corroborate the TAM model, which aligns with the social exchange process, demonstrating its applicability within the context of the educational setup in management sciences and its potential to enhance the learning experiences of researchers. © 2024 Elsevier Ltd
KW  - Chat-GPT
KW  - Higher education
KW  - Management sciences students
KW  - TAM
KW  - Ubiquitous learning (UL) procedure
KW  - Education computing
KW  - Engineering education
KW  - Learning systems
KW  - 'current
KW  - Chat-GPT
KW  - Education sectors
KW  - High educations
KW  - Learning mechanism
KW  - Learning procedures
KW  - Management science student
KW  - Technology acceptance model
KW  - Ubiquitous learning
KW  - Ubiquitous learning  procedure
KW  - Students
PB  - Elsevier Ltd
SN  - 07475632 (ISSN)
LA  - English
J2  - Comput. Hum. Behav.
M3  - Article
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 0; Correspondence Address: M. Arif; Department of Computer Engineering, Gachon University, Seongnam-si, 13120, South Korea; email: mohammadarif911@gachon.ac.kr; CODEN: CHBEE
ER  -

TY  - JOUR
AU  - Biswas, S.
AU  - Logan, N.S.
AU  - Davies, L.N.
AU  - Sheppard, A.L.
AU  - Wolffsohn, J.S.
TI  - Authors' Reply: Assessing the utility of ChatGPT as an artificial intelligence-based large language model for information to answer questions on myopia
PY  - 2024
T2  - Ophthalmic and Physiological Optics
VL  - 44
IS  - 1
SP  - 233
EP  - 234
DO  - 10.1111/opo.13227
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85168912530&doi=10.1111%2fopo.13227&partnerID=40&md5=41c9b6471fc90ad11acb03277b42b31b
AD  - School of Optometry, College of Health and Life Sciences, Aston University, Birmingham, United Kingdom
PB  - John Wiley and Sons Inc
SN  - 02755408 (ISSN)
C2  - 37635297
LA  - English
J2  - Ophthalmic Physiol. Opt.
M3  - Letter
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 3; Correspondence Address: S. Biswas; School of Optometry, College of Health and Life Sciences, Aston University, Birmingham, United Kingdom; email: s.biswas2@aston.ac.uk; CODEN: OPOPD
ER  -

TY  - JOUR
AU  - Gritti, M.N.
AU  - AlTurki, H.
AU  - Farid, P.
AU  - Morgan, C.T.
TI  - Progression of an Artificial Intelligence Chatbot (ChatGPT) for Pediatric Cardiology Educational Knowledge Assessment
PY  - 2024
T2  - Pediatric Cardiology
VL  - 45
IS  - 2
SP  - 309
EP  - 313
DO  - 10.1007/s00246-023-03385-6
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85181258989&doi=10.1007%2fs00246-023-03385-6&partnerID=40&md5=8f685267999fcb85731f9d8ef7c87271
AD  - Division of Cardiology, The Labatt Family Heart Centre, The Hospital for Sick Children, 555 University Ave, Toronto, M5G 1X8, ON, Canada
AD  - Department of Pediatrics, University of Toronto, Toronto, ON, Canada
AD  - Department of Pediatrics, The Hospital for Sick Children, Toronto, ON, Canada
AD  - Schulich School of Medicine and Dentistry, University of Western Ontario, London, ON, Canada
AB  - Artificial intelligence chatbots, like ChatGPT, have become powerful tools that are disrupting how humans interact with technology. The potential uses within medicine are vast. In medical education, these chatbots have shown improvements, in a short time span, in generalized medical examinations. We evaluated the overall performance and improvement between ChatGPT 3.5 and 4.0 in a test of pediatric cardiology knowledge. ChatGPT 3.5 and ChatGPT 4.0 were used to answer text-based multiple-choice questions derived from a Pediatric Cardiology Board Review textbook. Each chatbot was given an 88 question test, subcategorized into 11 topics. We excluded questions with modalities other than text (sound clips or images). Statistical analysis was done using an unpaired two-tailed t-test. Of the same 88 questions, ChatGPT 4.0 answered 66% of the questions correctly (n = 58/88) which was significantly greater (p < 0.0001) than ChatGPT 3.5, which only answered 38% (33/88). The ChatGPT 4.0 version also did better on each subspeciality topic as compared to ChatGPT 3.5. While acknowledging that ChatGPT does not yet offer subspecialty level knowledge in pediatric cardiology, the performance in pediatric cardiology educational assessments showed a considerable improvement in a short period of time between ChatGPT 3.5 and 4.0. © 2024, Crown.
KW  - Artificial intelligence
KW  - ChatGPT
KW  - Education
KW  - Natural language processing
KW  - Pediatric Cardiology
KW  - article
KW  - artificial intelligence
KW  - artificial intelligence chatbot
KW  - chatbot
KW  - ChatGPT
KW  - child
KW  - education
KW  - female
KW  - human
KW  - knowledge
KW  - major clinical study
KW  - medical education
KW  - medical examination
KW  - multiple choice test
KW  - natural language processing
KW  - pediatric cardiology
PB  - Springer
SN  - 01720643 (ISSN)
C2  - 38170274
LA  - English
J2  - Pediatr. Cardiol.
M3  - Article
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 0; Correspondence Address: M.N. Gritti; Division of Cardiology, The Labatt Family Heart Centre, The Hospital for Sick Children, Toronto, 555 University Ave, M5G 1X8, Canada; email: michael.gritti@sickkids.ca; CODEN: PECAD
ER  -

TY  - JOUR
AU  - Schafer, M.
AU  - Nadi, S.
AU  - Eghbali, A.
AU  - Tip, F.
TI  - An Empirical Evaluation of Using Large Language Models for Automated Unit Test Generation
PY  - 2024
T2  - IEEE Transactions on Software Engineering
VL  - 50
IS  - 1
SP  - 85
EP  - 105
DO  - 10.1109/TSE.2023.3334955
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85179087505&doi=10.1109%2fTSE.2023.3334955&partnerID=40&md5=99993a045589554365e391e9eeda26fb
AD  - GitHub, Kidlington, OX5 1AY, United Kingdom
AD  - University of Alberta, Edmonton, T6G 2E8, AB, Canada
AD  - University of Stuttgart, Baden-Württemberg, Stuttgart, 70569, Germany
AD  - Northeastern University, Boston, 02115, MA, United States
AB  - Unit tests play a key role in ensuring the correctness of software. However, manually creating unit tests is a laborious task, motivating the need for automation. Large Language Models (LLMs) have recently been applied to various aspects of software development, including their suggested use for automated generation of unit tests, but while requiring additional training or few-shot learning on examples of existing tests. This paper presents a large-scale empirical evaluation on the effectiveness of LLMs for automated unit test generation without requiring additional training or manual effort. Concretely, we consider an approach where the LLM is provided with prompts that include the signature and implementation of a function under test, along with usage examples extracted from documentation. Furthermore, if a generated test fails, our approach attempts to generate a new test that fixes the problem by re-prompting the model with the failing test and error message. We implement our approach in TestPilot, an adaptive LLM-based test generation tool for JavaScript that automatically generates unit tests for the methods in a given project's API. We evaluate TestPilot using OpenAI's gpt3.5-turbo LLM on 25 npm packages with a total of 1,684 API functions. The generated tests achieve a median statement coverage of 70.2% and branch coverage of 52.8%. In contrast, the state-of-the feedback-directed JavaScript test generation technique, Nessie, achieves only 51.3% statement coverage and 25.6% branch coverage. Furthermore, experiments with excluding parts of the information included in the prompts show that all components contribute towards the generation of effective test suites. We also find that 92.8% of TestPilot's generated tests have ≤≤ 50% similarity with existing tests (as measured by normalized edit distance), with none of them being exact copies. Finally, we run TestPilot with two additional LLMs, OpenAI's older code-cushman-002 LLM and StarCoder, an LLM for which the training process is publicly documented. Overall, we observed similar results with the former (68.2% median statement coverage), and somewhat worse results with the latter (54.0% median statement coverage), suggesting that the effectiveness of the approach is influenced by the size and training set of the LLM, but does not fundamentally depend on the specific model.  © 1976-2012 IEEE.
KW  - JavaScript
KW  - language models
KW  - Test generation
KW  - Application programming interfaces (API)
KW  - Codes (symbols)
KW  - Computational linguistics
KW  - Electronic mail
KW  - Function evaluation
KW  - High level languages
KW  - Software design
KW  - Software testing
KW  - Code
KW  - Documentation
KW  - Javascript
KW  - Language model
KW  - Software
KW  - Source-coding
KW  - Statement coverage
KW  - Test generations
KW  - Test pattern generator
KW  - Unit tests
KW  - Automation
PB  - Institute of Electrical and Electronics Engineers Inc.
SN  - 00985589 (ISSN)
LA  - English
J2  - IEEE Trans Software Eng
M3  - Article
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 0; Correspondence Address: M. Schafer; GitHub, Kidlington, OX5 1AY, United Kingdom; email: max-schaefer@github.com; CODEN: IESED
ER  -

TY  - CONF
AU  - Balse, R.
AU  - Kumar, V.
AU  - Prasad, P.
AU  - Warriem, J.M.
TI  - Evaluating the Quality of LLM-Generated Explanations for Logical Errors in CS1 Student Programs
PY  - 2023
T2  - ACM International Conference Proceeding Series
SP  - 49
EP  - 54
DO  - 10.1145/3627217.3627233
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85180412902&doi=10.1145%2f3627217.3627233&partnerID=40&md5=690164605e4c6f05d45053720968d1cf
AD  - Bs Programme in Data Science and Applications, Indian Institute of Technology Madras, Tamil Nadu, Chennai, India
AD  - Indian Institute of Science, Karnataka, Bangalore, India
AD  - School of Computing and Data Sciences, Flame University, Maharashtra, Pune, India
AD  - National Programme on Technology Enhanced Learning (NPTEL), Bs Programme in Data Science and Applications, Indian Institute of Technology Madras, Tamil Nadu, Chennai, India
AB  - When students in CS1 (Introductory Programming) write erroneous code, course staff can use automated tools to provide various types of helpful feedback. In this paper, we focus on syntactically correct student code containing logical errors. Tools that explain logical errors typically require course staff to invest greater effort than tools that detect such errors. To reduce this effort, prior work has investigated the use of Large Language Models (LLMs) such as GPT-3 to generate explanations. Unfortunately, these explanations can be incomplete or incorrect, and therefore unhelpful if presented to students directly. Nevertheless, LLM-generated explanations may be of adequate quality for Teaching Assistants (TAs) to efficiently craft helpful explanations on their basis. We evaluate the quality of explanations generated by an LLM (GPT-3.5-turbo) in two ways, for 30 buggy student solutions across 6 code-writing problems. First, in a study with 5 undergraduate TAs, we compare TA perception of LLM-generated and peer-generated explanation quality. TAs were unaware which explanations were LLM-generated, but they found them to be comparable in quality to peer-generated explanations. Second, we performed a detailed manual analysis of LLM-generated explanations for all 30 buggy solutions. We found at least one incorrect statement in 15/30 explanations (50%). However, in 28/30 cases (93%), the LLM-generated explanation correctly identified at least one logical error. Our results suggest that for large CS1 courses, TAs with adequate training to detect erroneous statements may be able to extract value from such explanations. © 2023 ACM.
KW  - Explanation
KW  - GPT-3.5-Turbo
KW  - Large language models (LLMs)
KW  - Logical Errors
KW  - Python Programming
KW  - Computational linguistics
KW  - Education computing
KW  - Errors
KW  - Quality control
KW  - Automated tools
KW  - Explanation
KW  - GPT-3.5-turbo
KW  - Introductory programming
KW  - Language model
KW  - Large language model
KW  - Logical errors
KW  - Python programming
KW  - Student project
KW  - Teaching assistants
KW  - Students
A2  - Babu C.
A2  - Goel N.
A2  - Karkare A.
PB  - Association for Computing Machinery
SN  - 979-840070840-4 (ISBN)
LA  - English
J2  - ACM Int. Conf. Proc. Ser.
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 0; Conference name: 16th Annual Compute Conference, COMPUTE 2023; Conference date: 9 December 2023 through 11 December 2023; Conference code: 195596
ER  -

TY  - JOUR
AU  - Ebrahimian, M.
AU  - Behnam, B.
AU  - Ghayebi, N.
AU  - Sobhrakhshankhah, E.
TI  - ChatGPT in Iranian medical licensing examination: Evaluating the diagnostic accuracy and decision-making capabilities of an AI-based model
PY  - 2023
T2  - BMJ Health and Care Informatics
VL  - 30
IS  - 1
C7  - e100815
DO  - 10.1136/bmjhci-2023-100815
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85179650503&doi=10.1136%2fbmjhci-2023-100815&partnerID=40&md5=dec0dc2b933a022f1c9915c4c18259ea
AD  - Pediatric Surgery Research Center, Research Institute for Children's Health, Shahid Beheshti University of Medical Sciences, Tehran, Iran
AD  - Gastrointestinal and Liver Disease Research Center, Iran University of Medical Sciences, Tehran, Iran
AD  - School of Medicine, Shahid Beheshti University of Medical Sciences, Tehran, Iran
AB  - Introduction Large language models such as ChatGPT have gained popularity for their ability to generate comprehensive responses to human queries. In the field of medicine, ChatGPT has shown promise in applications ranging from diagnostics to decision-making. However, its performance in medical examinations and its comparison to random guessing have not been extensively studied. Methods This study aimed to evaluate the performance of ChatGPT in the preinternship examination, a comprehensive medical assessment for students in Iran. The examination consisted of 200 multiple-choice questions categorised into basic science evaluation, diagnosis and decision-making. GPT-4 was used, and the questions were translated to English. A statistical analysis was conducted to assess the performance of ChatGPT and also compare it with a random test group. Results The results showed that ChatGPT performed exceptionally well, with 68.5% of the questions answered correctly, significantly surpassing the pass mark of 45%. It exhibited superior performance in decision-making and successfully passed all specialties. Comparing ChatGPT to the random test group, ChatGPT's performance was significantly higher, demonstrating its ability to provide more accurate responses and reasoning. Conclusion This study highlights the potential of ChatGPT in medical licensing examinations and its advantage over random guessing. However, it is important to note that ChatGPT still falls short of human physicians in terms of diagnostic accuracy and decision-making capabilities. Caution should be exercised when using ChatGPT, and its results should be verified by human experts to ensure patient safety and avoid potential errors in the medical field.  © 2023 BMJ Publishing Group. All rights reserved.
KW  - Artificial intelligence
KW  - Decision Making, Computer-Assisted
KW  - Neural Networks, Computer
KW  - Artificial Intelligence
KW  - Humans
KW  - Iran
KW  - Patient Safety
KW  - Physicians
KW  - Research Design
KW  - Article
KW  - basic science
KW  - ChatGPT
KW  - diagnostic accuracy
KW  - English (language)
KW  - GPT-4
KW  - human
KW  - Iran
KW  - licence
KW  - medical decision making
KW  - medical education
KW  - medical student
KW  - multiple choice test
KW  - artificial intelligence
KW  - methodology
KW  - patient safety
KW  - physician
PB  - BMJ Publishing Group
SN  - 26321009 (ISSN)
C2  - 38081765
LA  - English
J2  - BMJ Heal. care inf.
M3  - Article
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 0; Correspondence Address: M. Ebrahimian; Pediatric Surgery Research Center, Research Institute for Children's Health, Shahid Beheshti University of Medical Sciences, Tehran, Iran; email: manoochehrebrahimian@gmail.com
ER  -

TY  - JOUR
AU  - Shay, D.
AU  - Kumar, B.
AU  - Redaelli, S.
AU  - von Wedel, D.
AU  - Liu, M.
AU  - Dershwitz, M.
AU  - Schaefer, M.S.
AU  - Beam, A.
TI  - Could ChatGPT-4 pass an anaesthesiology board examination? Follow-up assessment of a comprehensive set of board examination practice questions
PY  - 2024
T2  - British Journal of Anaesthesia
VL  - 132
IS  - 1
SP  - 172
EP  - 174
DO  - 10.1016/j.bja.2023.10.025
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85180191745&doi=10.1016%2fj.bja.2023.10.025&partnerID=40&md5=62c15000fe52dc8034580a6a83cb67fb
AD  - Department of Epidemiology, Harvard T.H. Chan School of Public Health, Boston, MA, United States
AD  - The CAUSALab, Harvard T.H. Chan School of Public Health, Boston, MA, United States
AD  - Department of Anesthesia, Critical Care and Pain Medicine, Beth Israel Deaconess Medical Center, Harvard Medical School, Boston, MA, United States
AD  - Center for Anesthesia Research Excellence (CARE), Beth Israel Deaconess Medical Center, Harvard Medical School, Boston, MA, United States
AD  - School of Medicine and Surgery, University of Milano-Bicocca, Milan, Italy
AD  - Department of Anesthesiology & Perioperative Medicine, University of Massachusetts Chan Medical School, Worcester, MA, United States
AD  - Department of Anesthesiology, Duesseldorf University Hospital, Duesseldorf, Germany
KW  - artificial intelligence
KW  - board examination
KW  - ChatGPT
KW  - GPT-4
KW  - large language models
KW  - medical knowledge
KW  - multiple-choice questions
KW  - specialty qualifications
KW  - Anesthesiology
KW  - Follow-Up Studies
KW  - Humans
KW  - anesthesiologist
KW  - anesthesiology
KW  - artificial intelligence
KW  - certification
KW  - ChatGPT
KW  - clinical reasoning
KW  - follow up
KW  - human
KW  - Letter
KW  - licensing
KW  - medical education
KW  - multiple choice test
PB  - Elsevier Ltd
SN  - 00070912 (ISSN)
C2  - 37996275
LA  - English
J2  - Br. J. Anaesth.
M3  - Letter
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 0; Correspondence Address: A. Beam; Department of Epidemiology, Harvard T.H. Chan School of Public Health, Boston, United States; email: andrew_beam@hms.harvard.edu; CODEN: BJANA
ER  -

TY  - CONF
AU  - Feng, T.H.
AU  - Denny, P.
AU  - Wünsche, B.C.
AU  - Luxton-Reilly, A.
AU  - Hooper, S.
TI  - More Than Meets the AI: Evaluating the performance of GPT-4 on Computer Graphics assessment questions
PY  - 2024
T2  - ACM International Conference Proceeding Series
SP  - 182
EP  - 191
DO  - 10.1145/3636243.3636263
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85182943874&doi=10.1145%2f3636243.3636263&partnerID=40&md5=a6b80c8f564b55ee08a753a8e7cdb599
AD  - University of Auckland, Auckland, New Zealand
AB  - Recent studies have showcased the exceptional performance of LLMs (Large Language Models) on assessment questions across various discipline areas. This can be helpful if used to support the learning process, for example by enabling students to quickly generate and contrast alternative solution approaches. However, concerns about student over-reliance and inappropriate use of LLMs in education are common. Understanding the capabilities of LLMs is essential for instructors to make informed decisions on question choices for learning and assessment tasks. In CS (Computer Science), previous evaluations of LLMs have focused on CS1 and CS2 questions, and little is known about how well LLMs perform for assessment questions in upper-level CS courses such as CG (Computer Graphics), which covers a wide variety of concepts and question types. To address this gap, we compiled a dataset of past assessment questions used in a final-year undergraduate course about introductory CG, and evaluated the performance of GPT-4 on this dataset. We also classified assessment questions and evaluated the performance of GPT-4 for different types of questions. We found that the performance tended to be best for simple mathematical questions, and worst for questions requiring creative thinking, and those with complex descriptions and/or images. We share our benchmark dataset with the community and provide new insights into the capabilities of GPT-4 in the context of CG courses. We highlight opportunities for teaching staff to improve student learning by guiding the use of LLMs for CG questions, and inform decisions around question choices for assessment tasks. © 2024 Copyright held by the owner/author(s). Publication rights licensed to ACM.
KW  - Artificial Intelligence
KW  - Assessment
KW  - Computer Graphics
KW  - Computing Education
KW  - Evaluation
KW  - GPT-4
KW  - Large Language Models
KW  - Computational linguistics
KW  - Computer graphics
KW  - Education computing
KW  - Learning systems
KW  - Alternative solutions
KW  - Assessment
KW  - Assessment tasks
KW  - Computing education
KW  - Evaluation
KW  - GPT-4
KW  - Language model
KW  - Large language model
KW  - Learning process
KW  - Performance
KW  - Students
PB  - Association for Computing Machinery
SN  - 979-840071619-5 (ISBN)
LA  - English
J2  - ACM Int. Conf. Proc. Ser.
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 0; Conference name: 26th Australasian Computing Education Conference, ACE 2024 - Held in conjunction with Australasian Computer Science Week; Conference date: 30 January 2024 through 1 February 2024; Conference code: 196191
ER  -

TY  - JOUR
AU  - Nakaura, T.
AU  - Yoshida, N.
AU  - Kobayashi, N.
AU  - Shiraishi, K.
AU  - Nagayama, Y.
AU  - Uetani, H.
AU  - Kidoh, M.
AU  - Hokamura, M.
AU  - Funama, Y.
AU  - Hirai, T.
TI  - Preliminary assessment of automated radiology report generation with generative pre-trained transformers: comparing results to radiologist-generated reports
PY  - 2024
T2  - Japanese Journal of Radiology
VL  - 42
IS  - 2
SP  - 190
EP  - 200
DO  - 10.1007/s11604-023-01487-y
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85171285372&doi=10.1007%2fs11604-023-01487-y&partnerID=40&md5=e55a91de711c08290525f8db70ee5a30
AD  - Department of Diagnostic Radiology, Graduate School of Medical Sciences, Kumamoto University, 1-1-1 Honjo, Chuo-ku, Kumamoto-shi, Kumamoto, 860-8556, Japan
AD  - Department of Medical Physics, Faculty of Life Sciences, Kumamoto University, Honjo 1-1-1, Kumamoto, 860-8556, Japan
AB  - Purpose: In this preliminary study, we aimed to evaluate the potential of the generative pre-trained transformer (GPT) series for generating radiology reports from concise imaging findings and compare its performance with radiologist-generated reports. Methods: This retrospective study involved 28 patients who underwent computed tomography (CT) scans and had a diagnosed disease with typical imaging findings. Radiology reports were generated using GPT-2, GPT-3.5, and GPT-4 based on the patient’s age, gender, disease site, and imaging findings. We calculated the top-1, top-5 accuracy, and mean average precision (MAP) of differential diagnoses for GPT-2, GPT-3.5, GPT-4, and radiologists. Two board-certified radiologists evaluated the grammar and readability, image findings, impression, differential diagnosis, and overall quality of all reports using a 4-point scale. Results: Top-1 and Top-5 accuracies for the different diagnoses were highest for radiologists, followed by GPT-4, GPT-3.5, and GPT-2, in that order (Top-1: 1.00, 0.54, 0.54, and 0.21, respectively; Top-5: 1.00, 0.96, 0.89, and 0.54, respectively). There were no significant differences in qualitative scores about grammar and readability, image findings, and overall quality between radiologists and GPT-3.5 or GPT-4 (p > 0.05). However, qualitative scores of the GPT series in impression and differential diagnosis scores were significantly lower than those of radiologists (p < 0.05). Conclusions: Our preliminary study suggests that GPT-3.5 and GPT-4 have the possibility to generate radiology reports with high readability and reasonable image findings from very short keywords; however, concerns persist regarding the accuracy of impressions and differential diagnoses, thereby requiring verification by radiologists. © 2023, The Author(s).
KW  - Computed tomography
KW  - Deep learning
KW  - Generative pre-trained transformer
KW  - Large language model
KW  - Radiology report
KW  - Humans
KW  - Radiography
KW  - Radiologists
KW  - Radiology
KW  - Retrospective Studies
KW  - Tomography, X-Ray Computed
KW  - adolescent
KW  - adult
KW  - age distribution
KW  - aged
KW  - Article
KW  - child
KW  - clinical article
KW  - clinical assessment
KW  - clinical evaluation
KW  - computer assisted tomography
KW  - data quality
KW  - data visualization
KW  - diagnostic accuracy
KW  - differential diagnosis
KW  - female
KW  - generative pretrained transformer
KW  - human
KW  - hypophysis adenoma
KW  - liver hemangioma
KW  - male
KW  - middle aged
KW  - preliminary data
KW  - qualitative analysis
KW  - quantitative analysis
KW  - radiologist
KW  - renal angiomyolipoma
KW  - retrospective study
KW  - sex difference
KW  - radiography
KW  - radiologist
KW  - radiology
KW  - x-ray computed tomography
PB  - Springer
SN  - 18671071 (ISSN)
C2  - 37713022
LA  - English
J2  - Jpn. J. Rad.
M3  - Article
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 0; Correspondence Address: T. Nakaura; Department of Diagnostic Radiology, Graduate School of Medical Sciences, Kumamoto University, Kumamoto-shi, Kumamoto, 1-1-1 Honjo, Chuo-ku, 860-8556, Japan; email: kff00712@nifty.com
ER  -

TY  - JOUR
AU  - Suárez, A.
AU  - Díaz-Flores García, V.
AU  - Algar, J.
AU  - Gómez Sánchez, M.
AU  - Llorente de Pedro, M.
AU  - Freire, Y.
TI  - Unveiling the ChatGPT phenomenon: Evaluating the consistency and accuracy of endodontic question answers
PY  - 2024
T2  - International Endodontic Journal
VL  - 57
IS  - 1
SP  - 108
EP  - 113
DO  - 10.1111/iej.13985
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85173726812&doi=10.1111%2fiej.13985&partnerID=40&md5=1328d132b8fd440ca65abd82f55b1a60
AD  - Department of Pre-Clinic Dentistry, School of Biomedical Sciences, Universidad Europea de Madrid, Madrid, Spain
AD  - Department of Clinical Dentistry, School of Biomedical Sciences, Universidad Europea de Madrid, Madrid, Spain
AB  - Aim: Chatbot Generative Pre-trained Transformer (ChatGPT) is a generative artificial intelligence (AI) software based on large language models (LLMs), designed to simulate human conversations and generate novel content based on the training data it has been exposed to. The aim of this study was to evaluate the consistency and accuracy of ChatGPT-generated answers to clinical questions in endodontics, compared to answers provided by human experts. Methodology: Ninety-one dichotomous (yes/no) questions were designed and categorized into three levels of difficulty. Twenty questions were randomly selected from each difficulty level. Sixty answers were generated by ChatGPT for each question. Two endodontic experts independently answered the 60 questions. Statistical analysis was performed using the SPSS program to calculate the consistency and accuracy of the answers generated by ChatGPT compared to the experts. Confidence intervals (95%) and standard deviations were used to estimate variability. Results: The answers generated by ChatGPT showed high consistency (85.44%). No significant differences in consistency were found based on question difficulty. In terms of answer accuracy, ChatGPT achieved an average accuracy of 57.33%. However, significant differences in accuracy were observed based on question difficulty, with lower accuracy for easier questions. Conclusions: Currently, ChatGPT is not capable of replacing dentists in clinical decision-making. As ChatGPT's performance improves through deep learning, it is expected to become more useful and effective in the field of endodontics. However, careful attention and ongoing evaluation are needed to ensure its accuracy, reliability and safety in endodontics. © 2023 The Authors. International Endodontic Journal published by John Wiley & Sons Ltd on behalf of British Endodontic Society.
KW  - artificial intelligence
KW  - chatbot
KW  - ChatGPT
KW  - dentistry
KW  - endodontics
KW  - large language models
KW  - Artificial Intelligence
KW  - Clinical Decision-Making
KW  - Dental Care
KW  - Humans
KW  - Reproducibility of Results
KW  - Software
KW  - artificial intelligence
KW  - clinical decision making
KW  - dental procedure
KW  - human
KW  - reproducibility
KW  - software
PB  - John Wiley and Sons Inc
SN  - 01432885 (ISSN)
C2  - 37814369
LA  - English
J2  - Int. Endod. J.
M3  - Article
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 1; Correspondence Address: V. Díaz-Flores García; Department of Pre-Clinic Dentistry, School of Biomedical Sciences, Universidad Europea de Madrid, Villaviciosa de Odón, Calle Tajo s/n, Madrid, 28670, Spain; email: victor.diaz-flores@universidadeuropea.es; CODEN: IENJE
ER  -

TY  - JOUR
AU  - Lee, Y.-Q.
AU  - Chen, C.-T.
AU  - Chen, C.-C.
AU  - Lee, C.-H.
AU  - Chen, P.
AU  - Wu, C.-S.
AU  - Dai, H.-J.
TI  - Unlocking the Secrets Behind Advanced Artificial Intelligence Language Models in Deidentifying Chinese-English Mixed Clinical Text: Development and Validation Study
PY  - 2024
T2  - Journal of medical Internet research
VL  - 26
SP  - e48443
DO  - 10.2196/48443
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85183509740&doi=10.2196%2f48443&partnerID=40&md5=8d2dea3a9143386dfd8cf6972540c5e0
AD  - Dialogue System Technical Department, Asustek Computer Inc, Taipei, Taiwan
AD  - Intelligent System Laboratory, Department of Electrical Engineering, College of Electrical Engineering and Computer Science, National Kaohsiung University of Science and Technology, Kaohsiung, Taiwan
AD  - Department of Bioinformatics and Medical Engineering, Asia University, Taichung, Taiwan
AD  - Center for Precision Health Research, Asia University, Taichung, Taiwan
AD  - Electromagnetic Sensing Control and AI Computing System Laboratory, Department of Electrical Engineering, College of Electrical Engineering and Computer Science, National Kaohsiung University of Science and Technology, Kaohsiung, Taiwan
AD  - Knowledge Discovery and Data Mining Lab, Department of Electrical Engineering, College of Electrical Engineering and Computer Science, National Kaohsiung University of Science and Technology, Kaohsiung, Taiwan
AD  - Department of Chemical Engineering, Feng Chia University, Taichung, Taiwan
AD  - National Center for Geriatrics and Welfare Research, National Health Research Institutes, Taiwan
AD  - National Institute of Cancer Research, National Health Research Institutes, Tainan, Taiwan
AD  - School of Post-Baccalaureate Medicine, College of Medicine, Kaohsiung Medical University, Kaohsiung, Taiwan
AD  - Center for Big Data Research, Kaohsiung Medical University, Kaohsiung, Taiwan
AB  - BACKGROUND: The widespread use of electronic health records in the clinical and biomedical fields makes the removal of protected health information (PHI) essential to maintain privacy. However, a significant portion of information is recorded in unstructured textual forms, posing a challenge for deidentification. In multilingual countries, medical records could be written in a mixture of more than one language, referred to as code mixing. Most current clinical natural language processing techniques are designed for monolingual text, and there is a need to address the deidentification of code-mixed text. OBJECTIVE: The aim of this study was to investigate the effectiveness and underlying mechanism of fine-tuned pretrained language models (PLMs) in identifying PHI in the code-mixed context. Additionally, we aimed to evaluate the potential of prompting large language models (LLMs) for recognizing PHI in a zero-shot manner. METHODS: We compiled the first clinical code-mixed deidentification data set consisting of text written in Chinese and English. We explored the effectiveness of fine-tuned PLMs for recognizing PHI in code-mixed content, with a focus on whether PLMs exploit naming regularity and mention coverage to achieve superior performance, by probing the developed models' outputs to examine their decision-making process. Furthermore, we investigated the potential of prompt-based in-context learning of LLMs for recognizing PHI in code-mixed text. RESULTS: The developed methods were evaluated on a code-mixed deidentification corpus of 1700 discharge summaries. We observed that different PHI types had preferences in their occurrences within the different types of language-mixed sentences, and PLMs could effectively recognize PHI by exploiting the learned name regularity. However, the models may exhibit suboptimal results when regularity is weak or mentions contain unknown words that the representations cannot generate well. We also found that the availability of code-mixed training instances is essential for the model's performance. Furthermore, the LLM-based deidentification method was a feasible and appealing approach that can be controlled and enhanced through natural language prompts. CONCLUSIONS: The study contributes to understanding the underlying mechanism of PLMs in addressing the deidentification process in the code-mixed context and highlights the significance of incorporating code-mixed training instances into the model training phase. To support the advancement of research, we created a manipulated subset of the resynthesized data set available for research purposes. Based on the compiled data set, we found that the LLM-based deidentification method is a feasible approach, but carefully crafted prompts are essential to avoid unwanted output. However, the use of such methods in the hospital setting requires careful consideration of data security and privacy concerns. Further research could explore the augmentation of PLMs and LLMs with external knowledge to improve their strength in recognizing rare PHI. ©You-Qian Lee, Ching-Tai Chen, Chien-Chang Chen, Chung-Hong Lee, Peitsz Chen, Chi-Shin Wu, Hong-Jie Dai. Originally published in the Journal of Medical Internet Research (https://www.jmir.org), 25.01.2024.
KW  - ChatGPT
KW  - code mixing
KW  - deidentification
KW  - electronic health record
KW  - large language model
KW  - pretrained language model
KW  - article
KW  - artificial intelligence
KW  - ChatGPT
KW  - Chinese
KW  - controlled study
KW  - decision making
KW  - electric potential
KW  - electronic health record
KW  - human
KW  - information security
KW  - Internet
KW  - language model
KW  - large language model
KW  - medical information
KW  - medical record
KW  - natural language processing
KW  - privacy
KW  - validation study
SN  - 14388871 (ISSN)
C2  - 38271060
LA  - English
J2  - J Med Internet Res
M3  - Article
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 0
ER  -

TY  - CONF
AU  - He, C.
AU  - Li, C.
AU  - Han, T.
AU  - Shen, L.
TI  - Assessing and Enhancing LLMs: A Physics and History Dataset and One-More-Check Pipeline Method
PY  - 2024
T2  - Communications in Computer and Information Science
VL  - 1967 CCIS
SP  - 504
EP  - 517
DO  - 10.1007/978-981-99-8178-6_38
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85180155022&doi=10.1007%2f978-981-99-8178-6_38&partnerID=40&md5=69af043cbd01a6e8dc7a31631c9641db
AD  - Shanghai Jiao Tong University, Shanghai, China
AB  - Large language models(LLMs) demonstrate significant capabilities in traditional natural language processing(NLP) tasks and many examinations. However, there are few evaluations in regard to specific subjects in the Chinese educational context. This study, focusing on secondary physics and history, explores the potential and limitations of LLMs in Chinese education. Our contributions are as follows: a PH dataset is established, which concludes secondary school physics and history in Chinese, comprising thousands of multiple-choice questions; an evaluation on three prevalent LLMs: ChatGPT, GPT-3, ChatGLM on our PH dataset is made; a new prompt method called One-More-Check(OMC) is proposed to enhance the logical reasoning capacity of LLMs; finally, three LLMs are set to attend an actual secondary history exam. Our findings suggest that our OMC method improves the performance of LLMs on logical reasoning and LLMs underperform average level of age-appropriate students on the exam of history. All datasets, code and evaluation results are available at https://github.com/hcffffff/PH-dataset-OMC. © 2024, The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd.
KW  - Chain-of-Thought
KW  - Intelligent Education
KW  - Large Language Model
KW  - NLP Application
KW  - Computational linguistics
KW  - Natural language processing systems
KW  - Chain-of-thought
KW  - Educational context
KW  - Intelligent educations
KW  - Language model
KW  - Language processing
KW  - Large language model
KW  - Logical reasoning
KW  - Natural language processing applications
KW  - Natural languages
KW  - Pipeline methods
KW  - Large dataset
A2  - Luo B.
A2  - Cheng L.
A2  - Wu Z.-G.
A2  - Li H.
A2  - Li C.
PB  - Springer Science and Business Media Deutschland GmbH
SN  - 18650929 (ISSN); 978-981998177-9 (ISBN)
LA  - English
J2  - Commun. Comput. Info. Sci.
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 0; Correspondence Address: L. Shen; Shanghai Jiao Tong University, Shanghai, China; email: lpshen@sjtu.edu.cn; Conference name: 30th International Conference on Neural Information Processing, ICONIP 2023; Conference date: 20 November 2023 through 23 November 2023; Conference code: 304439
ER  -

TY  - JOUR
AU  - Kim, S.
AU  - Tariq, S.
AU  - Heo, S.
AU  - Yoo, C.
TI  - Interpretable attention-based multi-encoder transformer based QSPR model for assessing toxicity and environmental impact of chemicals
PY  - 2024
T2  - Chemosphere
VL  - 350
C7  - 141086
DO  - 10.1016/j.chemosphere.2023.141086
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85182516580&doi=10.1016%2fj.chemosphere.2023.141086&partnerID=40&md5=a9c1bd66d32152911bd8a9bfb35cbcad
AD  - Integrated Engineering, Dept. of Environmental Science and Engineering, College of Engineering, Kyung Hee University, 1732 Deogyeong-daero, Giheung-gu, Gyeonggi-do, Yongin-si, 17104, South Korea
AB  - The rising demand from consumer goods and pharmaceutical industry is driving a fast expansion of newly developed chemicals. The conventional toxicity testing of unknown chemicals is expensive, time-consuming, and raises ethical concerns. The quantitative structure–property relationship (QSPR) is an efficient computational method because it saves time, resources, and animal experimentation. Advances in machine learning have improved chemical analysis in QSPR studies, but the real-world application of machine learning-based QSPR studies was limited by the unexplainable ‘black box’ feature of the machine learnings. In this study, multi-encoder structure-to-toxicity (S2T)-transformer based QSPR model was developed to estimate the properties of polychlorinated biphenyls (PCBs) and endocrine disrupting chemicals (EDCs). Simplified molecular input line entry systems (SMILES) and molecular descriptors calculated by the Dragon 6 software, were simultaneously considered as input of QSPR model. Furthermore, an attention-based framework is proposed to describe the relationship between the molecular structure and toxicity of hazardous chemicals. The S2T-transformer model achieved the highest R2 scores of 0.918, 0.856, and 0.907 for logarithm of octanol-water partition coefficient (Log KOW), octanol-air partition coefficient (Log KOA), and bioconcentration factor (Log BCF) estimation of PCBs, respectively. Moreover, the attention weights were able to properly interpret the lateral (meta, para) chlorination associated with PCBs toxicity and environmental impact. © 2023 Elsevier Ltd
KW  - Attention mechanism
KW  - Molecular descriptor
KW  - Multi-encoder transformer structure
KW  - Quantitative structure-activity/property relationship
KW  - SMILES
KW  - Endocrine disrupters
KW  - Machine learning
KW  - Organic pollutants
KW  - Toxicity
KW  - endocrine disruptor
KW  - iodate
KW  - octanol
KW  - polychlorinated biphenyl
KW  - water
KW  - Attention mechanisms
KW  - Entry system
KW  - Molecular descriptors
KW  - Multi-encoder transformer structure
KW  - Property
KW  - Quantitative structure activity
KW  - Quantitative structure-activity/property relationship
KW  - Quantitative structure-property relationship models
KW  - Simplified molecular input line entry system
KW  - Transformer structure
KW  - bioaccumulation
KW  - endocrine disruptor
KW  - environmental impact
KW  - molecular analysis
KW  - numerical model
KW  - partition coefficient
KW  - PCB
KW  - quantitative analysis
KW  - toxicity
KW  - animal experiment
KW  - article
KW  - bioconcentration factor
KW  - chemical analysis
KW  - chemical structure
KW  - chlorination
KW  - controlled study
KW  - drug toxicity
KW  - environmental impact
KW  - facial expression
KW  - machine learning
KW  - nonhuman
KW  - partition coefficient
KW  - quantitative structure property relation
KW  - software
KW  - toxicity testing
KW  - Polychlorinated biphenyls
PB  - Elsevier Ltd
SN  - 00456535 (ISSN)
C2  - 38163464
LA  - English
J2  - Chemosphere
M3  - Article
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 0; Correspondence Address: C. Yoo; Integrated Engineering, Dept. of Environmental Science and Engineering, College of Engineering, Kyung Hee University, Yongin-si, 1732 Deogyeong-daero, Giheung-gu, Gyeonggi-do, 17104, South Korea; email: ckyoo@khu.ac.kr; CODEN: CMSHA
ER  -

TY  - JOUR
AU  - Janopaul-Naylor, J.R.
AU  - Koo, A.
AU  - Qian, D.C.
AU  - McCall, N.S.
AU  - Liu, Y.
AU  - Patel, S.A.
TI  - Physician Assessment of ChatGPT and Bing Answers to American Cancer Society's Questions to Ask about Your Cancer
PY  - 2024
T2  - American Journal of Clinical Oncology: Cancer Clinical Trials
VL  - 47
IS  - 1
SP  - 17
EP  - 21
DO  - 10.1097/COC.0000000000001050
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85181088199&doi=10.1097%2fCOC.0000000000001050&partnerID=40&md5=583b10d2dfb37d4f14212887de66a978
AD  - Department of Radiation Oncology, Emory University, United States
AD  - Department of Radiation Oncology, Memorial Sloan Kettering Cancer Center
AD  - Department of Biostatistics and Bioinformatics, Rollins School of Public Health, Emory University, United States
AB  - Objectives: Artificial intelligence (AI) chatbots are a new, publicly available tool for patients to access health care-related information with unknown reliability related to cancer-related questions. This study assesses the quality of responses to common questions for patients with cancer. Methods: From February to March 2023, we queried chat generative pretrained transformer (ChatGPT) from OpenAI and Bing AI from Microsoft questions from the American Cancer Society's recommended "Questions to Ask About Your Cancer" customized for all stages of breast, colon, lung, and prostate cancer. Questions were, in addition, grouped by type (prognosis, treatment, or miscellaneous). The quality of AI chatbot responses was assessed by an expert panel using the validated DISCERN criteria. Results: Of the 117 questions presented to ChatGPT and Bing, the average score for all questions were 3.9 and 3.2, respectively (P < 0.001) and the overall DISCERN scores were 4.1 and 4.4, respectively. By disease site, the average score for ChatGPT and Bing, respectively, were 3.9 and 3.6 for prostate cancer (P = 0.02), 3.7 and 3.3 for lung cancer (P < 0.001), 4.1 and 2.9 for breast cancer (P < 0.001), and 3.8 and 3.0 for colorectal cancer (P < 0.001). By type of question, the average score for ChatGPT and Bing, respectively, were 3.6 and 3.4 for prognostic questions (P = 0.12), 3.9 and 3.1 for treatment questions (P < 0.001), and 4.2 and 3.3 for miscellaneous questions (P = 0.001). For 3 responses (3%) by ChatGPT and 18 responses (15%) by Bing, at least one panelist rated them as having serious or extensive shortcomings. Conclusions: AI chatbots provide multiple opportunities for innovating health care. This analysis suggests a critical need, particularly around cancer prognostication, for continual refinement to limit misleading counseling, confusion, and emotional distress to patients and families. © 2024 Lippincott Williams and Wilkins. All rights reserved.
KW  - artificial intelligence
KW  - ChatGPT
KW  - health literacy
KW  - patient information
KW  - American Cancer Society
KW  - Artificial Intelligence
KW  - Humans
KW  - Male
KW  - Physicians
KW  - Prostatic Neoplasms
KW  - Reproducibility of Results
KW  - United States
KW  - Article
KW  - artificial intelligence
KW  - artificial intelligence chatbot
KW  - breast cancer
KW  - cancer patient
KW  - cancer prognosis
KW  - cancer staging
KW  - ChatGPT
KW  - colorectal cancer
KW  - controlled study
KW  - cross-sectional study
KW  - female
KW  - human
KW  - lung cancer
KW  - male
KW  - malignant neoplasm
KW  - non profit organization
KW  - physician
KW  - prostate cancer
KW  - physician
KW  - prostate tumor
KW  - reproducibility
KW  - United States
PB  - Lippincott Williams and Wilkins
SN  - 02773732 (ISSN)
C2  - 37823708
LA  - English
J2  - Am. J. Clin. Oncol. Cancer Clin. Trials
M3  - Article
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 1; Correspondence Address: J.R. Janopaul-Naylor; Memorial Sloan Kettering Cancer Center, New York, 1275 York Ave, 10065, United States; email: janopaj@mskcc.org; CODEN: AJCOD
ER  -

TY  - JOUR
AU  - Dang, R.
AU  - Hanba, C.
TI  - A large language model's assessment of methodology reporting in head and neck surgery
PY  - 2024
T2  - American Journal of Otolaryngology - Head and Neck Medicine and Surgery
VL  - 45
IS  - 2
C7  - 104145
DO  - 10.1016/j.amjoto.2023.104145
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85179823343&doi=10.1016%2fj.amjoto.2023.104145&partnerID=40&md5=63e51dd5fd2cd8f9fb07bebccd8fb06c
AD  - Maxillofacial Oncology and Reconstructive Surgery, Department of Oral and Maxillofacial surgery, Boston Medical Center, Boston, MA, United States
AD  - Department of Head and Neck Surgery, The University of Texas MD Anderson Cancer Center, Houston, TX, United States
AB  - Objective: The aim of this study was to assess the ability of a Large Language Model - ChatGPT 3.5 to appraise the quality of scientific methodology reporting in head and neck specific scientific literature. Methods: Authors asked ChatGPT 3.5 to create a grading system for scientific reporting of research methods. The language model produced a system with a max of 60 points. Individual scores were provided for Study Design and Description, Data Collection and Measurement, Statistical Analysis, Ethical Considerations, and Overall Clarity and Transparency. Twenty articles were selected at random from The American Head and Neck Society's (AHNS) fellowship curriculum 2.0 for interrogation and each ‘Methods’ section was input into ChatGPT 3.5 for scoring. Analysis of variance (ANOVA) was performed between different scoring categories and a post-hoc tukey HSD test was performed. Results: Twenty articles were assessed, eight were categorized as very good and nine as good based on cumulative score. Lowest mean score was noted with category of statistical analysis (Mean = 0.49, SD = 0.02). On ANOVA a significant difference between means of the different scoring categories was noted, F(4, 95) = 13.4, p ≤ 0.05. On post-hoc Tukey HSD test, mean scores for categories of data collection (Mean = 0.58, SD = 0.06) and statistical analysis (Mean = 0.49, SD = 0.02) were significantly lower when compared to other categories. Conclusion: This article showcases the feasibility of employing a large language model such as ChatGPT 3.5 to assess the methods sections in head and neck academic writing. Level of evidence: 4 © 2023 Elsevier Inc.
KW  - AI
KW  - ChatGPT
KW  - Head and neck
KW  - Large language model
KW  - analysis of variance
KW  - Article
KW  - artificial intelligence
KW  - ChatGPT
KW  - cohort analysis
KW  - comparative study
KW  - curriculum
KW  - data collection method
KW  - data interpretation
KW  - feasibility study
KW  - head and neck surgery
KW  - human
KW  - large language model
KW  - measurement
KW  - medical literature
KW  - medical research
KW  - medical society
KW  - methodology
KW  - post hoc analysis
KW  - publication
KW  - quality control
KW  - research ethics
KW  - scoring system
KW  - statistical analysis
KW  - study design
KW  - treatment outcome
PB  - W.B. Saunders
SN  - 01960709 (ISSN)
LA  - English
J2  - Am. J. Otolaryngol. Head Neck Med. Surg.
M3  - Article
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 0; Correspondence Address: C. Hanba; Head and Neck Surgical Oncology, Department of Otolaryngology, MD Anderson, Cancer Center, Houston, 1515 Holcombe Blvd, 77030, United States; email: curtis.j.hanba@gmail.com; CODEN: AJOTD
ER  -

TY  - CONF
AU  - Kwan, C.C.L.
TI  - Exploring ChatGPT-Generated Assessment Scripts of Probability and Engineering Statistics from Bloom’s Taxonomy
PY  - 2024
T2  - Communications in Computer and Information Science
VL  - 1974 CCIS
SP  - 275
EP  - 286
DO  - 10.1007/978-981-99-8255-4_24
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85177183243&doi=10.1007%2f978-981-99-8255-4_24&partnerID=40&md5=835c652ef878c79b2ccc7252cec5e270
AD  - Department of Civil and Environmental Engineering, The Hong Kong Polytechnic University, Hong Kong
AB  - Subject Instructors, class teachers, and educational practitioners always devote much time to preparing assessment scripts, suggested solutions, and marking schemes such as mid-term and final examination scripts for assessing students’ learning and performance as well as measuring their achievements of the subject learning outcomes. With precise prompts, ChatGPT seems to be able to work as an assistant to them in education, generating responses and deliverables in a quite structured and almost instant manner. In this paper, a ChatGPT-generated assessment script with its marking scheme and suggested solution of Probability and Engineering Statistics is explored based on Bloom’s Taxonomy. It is found that the ChatGPT-generated assessment script is partially complete and one of the multiple-choice questions is incorrect. The total score of the assessment script is not consistent with that of its marking scheme. Its suggested solution to one of the questions is missing. In addition, there are many application-oriented questions but few analysis-based questions and no evaluation-based question at all in the assessment script as per Bloom’s Taxonomy. Overall, ChatGPT-generated assessment scripts should further be reviewed and refined by educational practitioners to ascertain different levels of difficulty of questions which are in good alignment with the subject curriculum and the subject learning outcomes. © 2024, The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd.
KW  - Bloom’s taxonomy
KW  - ChatGPT
KW  - learning outcome
KW  - probability and engineering statistics
KW  - subject curriculum
KW  - Blooms (metal)
KW  - Curricula
KW  - Engineering education
KW  - Bloom’s taxonomy
KW  - ChatGPT
KW  - Engineering statistics
KW  - Final examinations
KW  - Learning outcome
KW  - Probability statistic
KW  - Student learning
KW  - Student performance
KW  - Subject curriculum
KW  - Teachers'
KW  - Taxonomies
A2  - Cheung S.K.S.
A2  - Wang F.L.
A2  - Li K.C.
A2  - Paoprasert N.
A2  - Charnsethikul P.
A2  - Phusavat K.
PB  - Springer Science and Business Media Deutschland GmbH
SN  - 18650929 (ISSN); 978-981998254-7 (ISBN)
LA  - English
J2  - Commun. Comput. Info. Sci.
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 0; Correspondence Address: C.C.L. Kwan; Department of Civil and Environmental Engineering, The Hong Kong Polytechnic University, Hong Kong; email: ceclkwan@polyu.edu.hk; Conference name: 6th International Conference on Technology in Education, ICTE 2023; Conference date: 19 December 2023 through 21 December 2023; Conference code: 303729
ER  -

TY  - JOUR
AU  - Bower, M.
AU  - Torrington, J.
AU  - Lai, J.W.M.
AU  - Petocz, P.
AU  - Alfano, M.
TI  - How should we change teaching and assessment in response to increasingly powerful generative Artificial Intelligence? Outcomes of the ChatGPT teacher survey
PY  - 2024
T2  - Education and Information Technologies
DO  - 10.1007/s10639-023-12405-0
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85183446406&doi=10.1007%2fs10639-023-12405-0&partnerID=40&md5=52aa9ef85a3cff221f06a128cf4a370b
AD  - Macquarie School of Education, Macquarie University, Sydney, 2109, NSW, Australia
AD  - Graduate Research Academy, Macquarie University, Sydney, 2109, NSW, Australia
AD  - Department of Philosophy, Macquarie University, Sydney, 2109, NSW, Australia
AB  - There has been widespread media commentary about the potential impact of generative Artificial Intelligence (AI) such as ChatGPT on the Education field, but little examination at scale of how educators believe teaching and assessment should change as a result of generative AI. This mixed methods study examines the views of educators (n = 318) from a diverse range of teaching levels, experience levels, discipline areas, and regions about the impact of AI on teaching and assessment, the ways that they believe teaching and assessment should change, and the key motivations for changing their practices. The majority of teachers felt that generative AI would have a major or profound impact on teaching and assessment, though a sizeable minority felt it would have a little or no impact. Teaching level, experience, discipline area, region, and gender all significantly influenced perceived impact of generative AI on teaching and assessment. Higher levels of awareness of generative AI predicted higher perceived impact, pointing to the possibility of an ‘ignorance effect’. Thematic analysis revealed the specific curriculum, pedagogy, and assessment changes that teachers feel are needed as a result of generative AI, which centre around learning with AI, higher-order thinking, ethical values, a focus on learning processes and face-to-face relational learning. Teachers were most motivated to change their teaching and assessment practices to increase the performance expectancy of their students and themselves. We conclude by discussing the implications of these findings in a world with increasingly prevalent AI. © 2024, The Author(s).
KW  - Artificial Intelligence
KW  - ChatGPT
KW  - Generative AI
KW  - Motivation
KW  - Teacher beliefs
PB  - Springer
SN  - 13602357 (ISSN)
LA  - English
J2  - Educ. Inf. Technol.
M3  - Article
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 0; Correspondence Address: J.W.M. Lai; Macquarie School of Education, Macquarie University, Sydney, 2109, Australia; email: jennifer.lai@mq.edu.au
ER  -

TY  - CONF
AU  - Perez Sanpablo, A.I.
AU  - Arquer Ruiz, M.C.
AU  - Meneses Peñaloza, A.
AU  - Rodriguez Reyes, G.
AU  - Quiñones Uriostegui, I.
AU  - Anaya Campos, L.E.
TI  - Development and Evaluation of a Diagnostic Exam for Undergraduate Biomedical Engineering Students Using GPT Language Model-Based Virtual Agents
PY  - 2024
T2  - IFMBE Proceedings
VL  - 96
SP  - 128
EP  - 136
DO  - 10.1007/978-3-031-46933-6_14
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85177234498&doi=10.1007%2f978-3-031-46933-6_14&partnerID=40&md5=5200bba6714d9a7ff104f5fa10ac0f35
AD  - Biomedical Engineering Department, La Salle University, Cuauhtemoc, Mexico City, 06140, Mexico
AD  - Laboratory of Motion Analysis and Rehabilitation Engineering, National Institute of Rehabilitation, Tlalpan, Mexico City, 14389, Mexico
AD  - Pediatric Rehabilitation Department, National Institute of Rehabilitation, Tlalpan, Mexico City, 14389, Mexico
AD  - Technological Research Department, National Institute of Rehabilitation, Tlalpan, Mexico City, 14389, Mexico
AB  - The creation of a diagnostic exam for biomedical engineering undergraduate students using virtual agents based on GPT language models is analyzed in this work. Thirty-nine eighth-semester students answered a 20-question exam generated by ChatGPT-3 covering the topics of acquisition, amplification, processing, and visualization of biomedical signals encompassing different levels of thinking according to the taxonomy of Bloom, including the application, analysis, and evaluation levels. Three academic experts assessed the quality of the questions based on clarity, relevance, level of thinking, and difficulty. Also, difficulty and discrimination indexes and Rasch analysis were calculated. Students obtained an average grade of 5.91, with a standard deviation of 1.39 points. Subject reliability was 0.599, and the p-value for the fit of the model of Rasch was 0.017. High correlations between some questions were observed. Based on their difficulty, a few questions could be considered irrelevant. The Wright competency map showed a good distribution on the ability scale with some redundancies and gaps. In conclusion, virtual agents have great potential to create diagnosis exams in biomedical engineering. However, it is necessary to consider their limitations and conduct a rigorous evaluation of the quality and reliability of the questions generated. © 2024, The Author(s), under exclusive license to Springer Nature Switzerland AG.
KW  - artificial intelligence
KW  - biomedical engineering
KW  - ChatGPT-3
KW  - education
KW  - teaching
KW  - Bioinformatics
KW  - Computational linguistics
KW  - E-learning
KW  - Education computing
KW  - Engineering education
KW  - Quality control
KW  - Agent based
KW  - Analysis and evaluation
KW  - Application analysis
KW  - Biomedical signal
KW  - ChatGPT-3
KW  - Engineering undergraduates
KW  - Language model
KW  - Model-based OPC
KW  - Undergraduate students
KW  - Virtual agent
KW  - Students
A2  - Flores Cuautle J.d.
A2  - Benítez-Mata B.
A2  - Salido-Ruiz R.A.
A2  - Vélez-Pérez H.A.
A2  - Alonso-Silverio G.A.
A2  - Dorantes-Méndez G.
A2  - Mejía-Rodríguez A.R.
A2  - Zúñiga-Aguilar E.
A2  - Hierro-Gutiérrez E.D.
PB  - Springer Science and Business Media Deutschland GmbH
SN  - 16800737 (ISSN); 978-303146932-9 (ISBN)
LA  - English
J2  - IFMBE Proc.
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 0; Correspondence Address: A.I. Perez Sanpablo; Biomedical Engineering Department, La Salle University, Mexico City, Cuauhtemoc, 06140, Mexico; email: albperez@inr.gob.mx; Conference name: 46th Mexican Conference on Biomedical Engineering, CNIB 2023; Conference date: 2 November 2023 through 4 November 2023; Conference code: 303959
ER  -

TY  - JOUR
AU  - Aryadoust, V.
AU  - Zakaria, A.
AU  - Jia, Y.
TI  - Investigating the affordances of OpenAI's large language model in developing listening assessments
PY  - 2024
T2  - Computers and Education: Artificial Intelligence
VL  - 6
C7  - 100204
DO  - 10.1016/j.caeai.2024.100204
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85182607841&doi=10.1016%2fj.caeai.2024.100204&partnerID=40&md5=b31bb69055ee8c52d61f5d3171ac94e5
AD  - National Institute of Education, Nanyang Technological University, Singapore
AB  - To address the complexity and high costs of developing listening tests for test-takers of varying proficiency levels, this study investigates the capabilities of an OpenAI's large language model, ChatGPT 4, in developing listening assessments. Employing prompt engineering and fine-tuning of prompts, the study specifically focuses on creating listening scripts and test items using ChatGPT 4 for test-takers across a spectrum of proficiency levels (academic, low, intermediate, and advanced). For comparability, the 24 topics of these scripts were selected from topics found in academic listening tests. We conducted two types of analyses to evaluate the quality of the output. First, we performed linguistic analyses of the scripts using Coh-Metrix and Text Inspector to determine if the scripts varied linguistically as required by the prompts. Second, we analyzed topic variation and the degree of overlap in the test items. Results indicated that while ChatGPT 4 reliably produced scripts with significant textual variations, the test items generated were often long and exhibited semantic overlaps among options. This effect was also influenced by the topic. We discuss the ethical complexities that arise from the use of generative artificial intelligence (AI), and how generative AI (GenAI) can potentially benefit practitioners and researchers in language assessment, while recognizing its limitations. © 2024 The Author(s)
KW  - Artificial intelligence (AI)
KW  - ChatGPT 4
KW  - Fine-tuning of prompts
KW  - Generative AI (GenAI)
KW  - Large language model
KW  - Listening assessment
KW  - Listening scripts
KW  - Prompt engineering
KW  - Test creation
KW  - Test items
KW  - Artificial intelligence
KW  - Computational linguistics
KW  - Artificial intelligence
KW  - ChatGPT 4
KW  - Fine tuning
KW  - Fine-tuning of prompt
KW  - Generative artificial intelligence
KW  - Language model
KW  - Large language model
KW  - Listening assessment
KW  - Listening script
KW  - Prompt engineering
KW  - Test creation
KW  - Test item
KW  - Semantics
PB  - Elsevier B.V.
SN  - 2666920X (ISSN)
LA  - English
J2  - Comput. Educ.
M3  - Article
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 0; Correspondence Address: V. Aryadoust; National Institute of Education, Nanyang Technological University, Singapore; email: Vahid.aryadoust@nie.edu.sg
ER  -

TY  - JOUR
AU  - Fahy, S.
AU  - Oehme, S.
AU  - Milinkovic, D.
AU  - Jung, T.
AU  - Bartek, B.
TI  - Assessment of Quality and Readability of Information Provided by ChatGPT in Relation to Anterior Cruciate Ligament Injury
PY  - 2024
T2  - Journal of Personalized Medicine
VL  - 14
IS  - 1
C7  - 104
DO  - 10.3390/jpm14010104
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85183102467&doi=10.3390%2fjpm14010104&partnerID=40&md5=3cd96feb1701fff7bdabff67134ef7aa
AD  - Centrum für Muskuloskeletale Chirurgie, Charité Universitätsmedizin, Berlin, 10117, Germany
AB  - The aim of our study was to evaluate the potential role of Artificial Intelligence tools like ChatGPT in patient education. To do this, we assessed both the quality and readability of information provided by ChatGPT 3.5 and 4 in relation to Anterior Cruciate Ligament (ACL) injury and treatment. ChatGPT 3.5 and 4 were used to answer common patient queries relating to ACL injuries and treatment. The quality of the information was assessed using the DISCERN criteria. Readability was assessed with the use of seven readability formulae: the Flesch–Kincaid Reading Grade Level, the Flesch Reading Ease Score, the Raygor Estimate, the SMOG, the Fry, the FORCAST, and the Gunning Fog. The mean reading grade level (RGL) was compared with the recommended 8th-grade reading level, the mean RGL among adults in America. The perceived quality and mean RGL of answers given by both ChatGPT 3.5 and 4 was also compared. Both ChatGPT 3.5 and 4 yielded DISCERN scores suggesting “good” quality of information, with ChatGPT 4 slightly outperforming 3.5. However, readability levels for both versions significantly exceeded the average 8th-grade reading level for American patients. ChatGPT 3.5 had a mean RGL of 18.08, while the mean RGL of ChatGPT 4 was 17.9, exceeding the average American reading grade level by 10.08 grade levels and 9.09 grade levels, respectively. While ChatGPT can provide both reliable and good quality information on ACL injuries and treatment options, the readability of the content may limit its utility. Additionally, the consistent lack of source citation represents a significant area of concern for patients and clinicians alike. If AI is to play a role in patient education, it must reliably produce information which is accurate, easily comprehensible, and clearly sourced. © 2024 by the authors.
KW  - ACL reconstruction surgery (ACL-R)
KW  - anterior cruciate ligament (ACL)
KW  - artificial intelligence (AI)
KW  - ChatGPT
KW  - DISCERN criteria
KW  - health literacy
KW  - natural language processing
KW  - orthopaedic injuries
KW  - patient education materials (PEMS)
KW  - readability
KW  - adult
KW  - anterior cruciate ligament injury
KW  - anterior cruciate ligament reconstruction
KW  - Article
KW  - artificial intelligence
KW  - ChatGPT
KW  - controlled study
KW  - human
KW  - interrater reliability
KW  - natural language processing
KW  - patient education
KW  - reading
KW  - reliability
PB  - Multidisciplinary Digital Publishing Institute (MDPI)
SN  - 20754426 (ISSN)
LA  - English
J2  - J. Pers. Med.
M3  - Article
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 0; Correspondence Address: S. Fahy; Centrum für Muskuloskeletale Chirurgie, Charité Universitätsmedizin, Berlin, 10117, Germany; email: stephen.fahy@charite.de
ER  -

TY  - JOUR
AU  - Zhang, Y.
AU  - Wu, L.
AU  - Mu, Z.
AU  - Ren, L.
AU  - Chen, Y.
AU  - Liu, H.
AU  - Xu, L.
AU  - Wang, Y.
AU  - Wang, Y.
AU  - Cheng, S.
AU  - Tham, Y.C.
AU  - Sheng, B.
AU  - Wong, T.Y.
AU  - Ji, H.
TI  - Letter 2 regarding “Assessing the performance of ChatGPT in answering questions regarding cirrhosis and hepatocellular carcinoma”
PY  - 2024
T2  - Clinical and Molecular Hepatology
VL  - 30
IS  - 1
SP  - 113
EP  - 117
DO  - 10.3350/cmh.2023.0440
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85181933329&doi=10.3350%2fcmh.2023.0440&partnerID=40&md5=afef775859fa6dcba66d3e1db04711ab
AD  - Department of Endocrinology and Metabolic Hepatology, The Affiliated Hospital of Qingdao University, Qingdao, China
AD  - Department of Gastroenterology and Hepatology, Shanghai East Hospital, Tongji University, Shanghai, China
AD  - Department of Gastroenterology and Hepatology, The Affiliated Hospital of Qingdao University, Qingdao, China
AD  - Shandong Provincial Key Laboratory of Metabolic Diseases and Qingdao Key Laboratory of Gout, the Affiliated Hospital of Qingdao University, Qingdao, China
AD  - Department of Infectious Disease and Hepatology, The Affiliated Hospital of Qingdao University, Qingdao, China
AD  - Beijing Key Laboratory of Ophthalmology and Visual Sciences, Beijing Tongren Eye Center, Beijing Institute of Ophthalmology, Beijing Tongren Hospital, Capital Medical University, Beijing, China
AD  - Department of Cardiology, Smidt Heart Institute, Cedars-Sinai Medical Center, Los Angeles, CA, United States
AD  - Yong Loo Lin School of Medicine, National University of Singapore, Singapore
AD  - Singapore Eye Research Institute, Singapore National Eye Center, Singapore
AD  - Department of Computer Science and Engineering, Shanghai JiaoTong University, Shanghai, China
AD  - Tsinghua Medicine, Tsinghua University, Beijing, China
AD  - Department of Internal Medicine, Beijing Tsinghua Changgung Hospital, Beijing, China
KW  - Artificial intelligence
KW  - Natural language processing
KW  - Non-alcoholic fatty liver disease
KW  - Patient education as topic
KW  - answering question
KW  - artificial intelligence
KW  - assessment of humans
KW  - ChatGPT
KW  - fatty liver
KW  - follow up
KW  - global health
KW  - human
KW  - large language model
KW  - Letter
KW  - lifestyle modification
KW  - liver cell carcinoma
KW  - liver cirrhosis
KW  - liver disease
KW  - metabolic fatty liver
KW  - natural language processing
KW  - nonalcoholic fatty liver
KW  - risk factor
KW  - steatohepatitis
PB  - Korean Association for the Study of the Liver
SN  - 22872728 (ISSN)
C2  - 37946373
LA  - English
J2  - Clin. Mol. Hepatol.
M3  - Letter
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 0; Correspondence Address: T.Y. Wong; Tsinghua Medicine, Tsinghua University, Beijing, Haidian District, 100084, China; email: wongtienyin@tsinghua.edu.cn; H. Ji; Tsinghua Medicine, Tsinghua University, Beijing, Haidian District, 100084, China; email: hongweijicn@gmail.com
ER  -

TY  - CONF
AU  - Jin, W.
AU  - Zhao, B.
AU  - Liu, G.
TI  - Exploring the Capability of ChatGPT for Cross-Linguistic Agricultural Document Classification: Investigation and Evaluation
PY  - 2024
T2  - Communications in Computer and Information Science
VL  - 1965 CCIS
SP  - 220
EP  - 237
DO  - 10.1007/978-981-99-8145-8_18
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85178645750&doi=10.1007%2f978-981-99-8145-8_18&partnerID=40&md5=c26d5174c566c0f506ba0830a25d1957
AD  - School of Information and Communications Engineering, Xi’an Jiaotong University, Innovation Harbour, Shaanxi, Xi’an, China
AB  - In the sustainable smart agriculture era, a vast amount of agricultural knowledge is available on the internet, making it necessary to explore effective document classification techniques for enhanced accessibility and efficiency. Over the past few years, fine-tuning strategies based on pre-trained language models (PLMs) have gained popularity as mainstream deep learning approaches, showcasing impressive performance. However, these approaches face several challenges, including a limited availability of training data, poor domain transferability, lack of model interpretability, and the challenges in deploying large models. Inspired by ChatGPT’s significant success, we investigate its capability and utilization in the field of agricultural information processing. We explore various attempts to maximize ChatGPT’s potential, including various prompting construction strategies, ChatGPT question-answering (Q &A) inference, and intermediate answer alignment technique. Our preliminary comparative study demonstrates that ChatGPT effectively addresses research challenges and bottlenecks, positioning it as an ideal solution for agricultural document classification. This findings encourage the development of a general-purpose agricultural document processing paradigm. Our preliminary study also indicates the trend towards achieving Artificial General Intelligence (AGI) for sustainable smart agriculture in the future. Code is available on Github (https://github.com/albert-jin/agricultural_textual_classification_ChatGPT ). © 2024, The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd.
KW  - Agricultural document classification
KW  - ChatGPT
KW  - Natural language processing
KW  - Very large language model
KW  - Agriculture
KW  - Classification (of information)
KW  - Deep learning
KW  - HTTP
KW  - Information retrieval systems
KW  - Natural language processing systems
KW  - Agricultural document classification
KW  - ChatGPT
KW  - Classification technique
KW  - Document Classification
KW  - Language model
KW  - Language processing
KW  - Natural language processing
KW  - Natural languages
KW  - Smart agricultures
KW  - Very large language model
KW  - Computational linguistics
A2  - Luo B.
A2  - Cheng L.
A2  - Wu Z.-G.
A2  - Li H.
A2  - Li C.
PB  - Springer Science and Business Media Deutschland GmbH
SN  - 18650929 (ISSN); 978-981998144-1 (ISBN)
LA  - English
J2  - Commun. Comput. Info. Sci.
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 0; Correspondence Address: W. Jin; School of Information and Communications Engineering, Xi’an Jiaotong University, Innovation Harbour, Xi’an, Shaanxi, China; email: weiqiangjin@stu.xjtu.edu.cn; Conference name: 30th International Conference on Neural Information Processing, ICONIP 2023; Conference date: 20 November 2023 through 23 November 2023; Conference code: 304439
ER  -

TY  - CONF
AU  - Rana, T.
AU  - Saraswat, D.
AU  - Gaind, A.
AU  - Singla, R.
AU  - Chhabra, A.
TI  - A BERT Classifier Approach for Evaluation of Fake News Dissemination
PY  - 2024
T2  - Communications in Computer and Information Science
VL  - 1930
SP  - 171
EP  - 184
DO  - 10.1007/978-3-031-48781-1_14
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85180632761&doi=10.1007%2f978-3-031-48781-1_14&partnerID=40&md5=72347fc61db7be3868ceb01e809cd592
AD  - Chandigarh College of Engineering and Technology, Sector-26, Chandigarh, 160019, India
AB  - The intake of information via media has changed from newspapers to social networking sites as technology has evolved. Accessibility and availability are two important aspects that have led to this trend in media usage. Users share thousands of posts, articles, and videos as the internet penetration grows. These postings are done on a variety of social networking sites such as Facebook, Instagram, YouTube, Twitter, and others. It is now widely acknowledged that disinformation may often create tensions and has a substantial impact in the country. Stemming the tide of false news articles via social networking sites and the Internet is critical. This problem has indeed been handled in this study using various algorithmic approaches that could help us to control this type of hazardous thing. Including the findings, a contrast of how various classification functions are offered. This article gives a thorough assessment of numerous fake news detection strategies employed by various other authors, databases they had engaged with, and the multiple analytical people were using to evaluate the effectiveness of their respective algorithms. This research analyses the troubles and challenges of detecting this type of news. This article examines documents from 2017 through 2022, as well as various fake news detecting tools. This study provides a complete evaluation of present and past studies on false news recognition leveraging various ML and DL models. In this research work, BERT Classifier has been used which uses a deep learning technique and has the highest accuracy of all the methods described. © The Author(s), under exclusive license to Springer Nature Switzerland AG 2024.
KW  - and classification models
KW  - Artificial Intelligence
KW  - BERT
KW  - Deep learning
KW  - Fake news
KW  - Machine learning
KW  - Regression
KW  - Deep learning
KW  - Fake detection
KW  - Learning systems
KW  - Social sciences computing
KW  - And classification model
KW  - BERT
KW  - Classification models
KW  - Deep learning
KW  - Facebook
KW  - Fake news
KW  - Machine-learning
KW  - Media usage
KW  - Regression
KW  - Social-networking
KW  - Social networking (online)
A2  - Challa R.K.
A2  - Mathew L.
A2  - Kumar A.
A2  - Kalra M.
A2  - Saini G.
A2  - Sharma K.
A2  - Aujla G.S.
A2  - Shimi S.L.
A2  - Shimi S.L.
PB  - Springer Science and Business Media Deutschland GmbH
SN  - 18650929 (ISSN); 978-303148780-4 (ISBN)
LA  - English
J2  - Commun. Comput. Info. Sci.
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 0; Correspondence Address: D. Saraswat; Chandigarh College of Engineering and Technology, Chandigarh, Sector-26, 160019, India; email: falsesaraswatdarshan@gmail.com; Conference name: 1st International Conference on Artificial Intelligence of Things, ICAIoT 2023; Conference date: 30 March 2023 through 31 March 2023; Conference code: 305739
ER  -

TY  - JOUR
AU  - Saibene, A.M.
AU  - Allevi, F.
AU  - Calvo-Henriquez, C.
AU  - Maniaci, A.
AU  - Mayo-Yáñez, M.
AU  - Paderno, A.
AU  - Vaira, L.A.
AU  - Felisati, G.
AU  - Craig, J.R.
TI  - Reliability of large language models in managing odontogenic sinusitis clinical scenarios: a preliminary multidisciplinary evaluation
PY  - 2024
T2  - European Archives of Oto-Rhino-Laryngology
DO  - 10.1007/s00405-023-08372-4
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85181759067&doi=10.1007%2fs00405-023-08372-4&partnerID=40&md5=495c72818b6fededf59fb4ff4009c947
AD  - Otolaryngology Unit, Santi Paolo E Carlo Hospital, Department of Health Sciences, Università Degli Studi Di Milano, Milan, Italy
AD  - Maxillofacial Surgery Unit, Santi Paolo E Carlo Hospital, Department of Health Sciences, Università Degli Studi Di Milano, Milan, Italy
AD  - Service of Otolaryngology, Rhinology Unit, Hospital Complex at the University of Santiago de Compostela, Santiago de Compostela, A Coruña, Spain
AD  - Department of Medical, Surgical Sciences and Advanced Technologies G.F. Ingrassia, University of Catania, Catania, Italy
AD  - Otorhinolaryngology, Head and Neck Surgery Department, Complexo Hospitalario Universitario A Coruña (CHUAC), Galicia, A Coruña, Spain
AD  - Department of Otorhinolaryngology, Head and Neck Surgery, University of Brescia, Brescia, Italy
AD  - Maxillofacial Surgery Operative Unit, Department of Medicine, Surgery and Pharmacy, University of Sassari, Sassari, Italy
AD  - Biomedical Science PhD School, Biomedical Science Department, University of Sassari, Sassari, Italy
AD  - Department of Otolaryngology-Head and Neck Surgery, Henry Ford Health, Detroit, MI, United States
AB  - Purpose: This study aimed to evaluate the utility of large language model (LLM) artificial intelligence tools, Chat Generative Pre-Trained Transformer (ChatGPT) versions 3.5 and 4, in managing complex otolaryngological clinical scenarios, specifically for the multidisciplinary management of odontogenic sinusitis (ODS). Methods: A prospective, structured multidisciplinary specialist evaluation was conducted using five ad hoc designed ODS-related clinical scenarios. LLM responses to these scenarios were critically reviewed by a multidisciplinary panel of eight specialist evaluators (2 ODS experts, 2 rhinologists, 2 general otolaryngologists, and 2 maxillofacial surgeons). Based on the level of disagreement from panel members, a Total Disagreement Score (TDS) was calculated for each LLM response, and TDS comparisons were made between ChatGPT3.5 and ChatGPT4, as well as between different evaluators. Results: While disagreement to some degree was demonstrated in 73/80 evaluator reviews of LLMs’ responses, TDSs were significantly lower for ChatGPT4 compared to ChatGPT3.5. Highest TDSs were found in the case of complicated ODS with orbital abscess, presumably due to increased case complexity with dental, rhinologic, and orbital factors affecting diagnostic and therapeutic options. There were no statistically significant differences in TDSs between evaluators’ specialties, though ODS experts and maxillofacial surgeons tended to assign higher TDSs. Conclusions: LLMs like ChatGPT, especially newer versions, showed potential for complimenting evidence-based clinical decision-making, but substantial disagreement was still demonstrated between LLMs and clinical specialists across most case examples, suggesting they are not yet optimal in aiding clinical management decisions. Future studies will be important to analyze LLMs’ performance as they evolve over time. © 2024, The Author(s).
KW  - Artificial intelligence
KW  - Chronic rhinosinusitis
KW  - Computer-assisted diagnosis
KW  - Dental implant
KW  - Maxillary sinusitis
KW  - Oroantral fistula
PB  - Springer Science and Business Media Deutschland GmbH
SN  - 09374477 (ISSN)
LA  - English
J2  - Eur. Arch. Oto-Rhino-Laryngol.
M3  - Article
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 0; Correspondence Address: A.M. Saibene; Otolaryngology Unit, Santi Paolo E Carlo Hospital, Department of Health Sciences, Università Degli Studi Di Milano, Milan, Italy; email: alberto.saibene@unimi.it; CODEN: EAOTE
ER  -

TY  - JOUR
AU  - Leypold, T.
AU  - Schäfer, B.
AU  - Boos, A.
AU  - Beier, J.P.
TI  - Can AI Think Like a Plastic Surgeon? Evaluating GPT-4's Clinical Judgment in Reconstructive Procedures of the Upper Extremity
PY  - 2023
T2  - Plastic and Reconstructive Surgery - Global Open
VL  - 11
IS  - 12
SP  - E5471
DO  - 10.1097/GOX.0000000000005471
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85180066985&doi=10.1097%2fGOX.0000000000005471&partnerID=40&md5=d7577aca42062b994407ce1f917aad2a
AD  - Department of Plastic Surgery, Hand Surgery-Burn Center, University Hospital RWTH Aachen, Aachen, Germany
AB  - This study delves into the potential application of OpenAI's Generative Pretrained Transformer 4 (GPT-4) in plastic surgery, with a particular focus on procedures involving the hand and arm. GPT-4, a cutting-edge artificial intelligence (AI) model known for its advanced chat interface, was tested on nine surgical scenarios of varying complexity. To optimize the performance of GPT-4, prompt engineering techniques were used to guide the model's responses and improve the relevance and accuracy of its output. A panel of expert plastic surgeons evaluated the responses using a Likert scale to assess the model's performance, based on five distinct criteria. Each criterion was scored on a scale of 1 to 5, with 5 representing the highest possible score. GPT-4 demonstrated a high level of performance, achieving an average score of 4.34 across all cases, consistent across different complexities. The study highlights the ability of GPT-4 to understand and respond to complicated surgical scenarios. However, the study also identifies potential areas for improvement. These include refining the prompts used to elicit responses from the model and providing targeted training with specialized, up-to-date sources. This study demonstrates a new approach to exploring large language models and highlights potential future applications of AI. These could improve patient care, refine surgical outcomes, and even change the way we approach complex clinical scenarios in plastic surgery. However, the intrinsic limitations of AI in its current state, together with the potential ethical considerations and the inherent uncertainty of unanticipated issues, serve to reiterate the indispensable role and unparalleled value of human plastic surgeons. © 2023 Lippincott Williams and Wilkins. All rights reserved.
PB  - Lippincott Williams and Wilkins
SN  - 21697574 (ISSN)
LA  - English
J2  - Plast. Reconstr. Surg., Glob. Open
M3  - Article
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 0; Correspondence Address: T. Leypold; Department of Plastic Surgery, Hand Surgery-Burn Center, University Hospital RWTH Aachen, Aachen, Pauwelsstraße 30, 52074, Germany; email: tleypold@ukaachen.de
ER  -

TY  - JOUR
AU  - Wei, K.
AU  - Fritz, C.
AU  - Rajasekaran, K.
TI  - Answering head and neck cancer questions: An assessment of ChatGPT responses
PY  - 2024
T2  - American Journal of Otolaryngology - Head and Neck Medicine and Surgery
VL  - 45
IS  - 1
C7  - 104085
DO  - 10.1016/j.amjoto.2023.104085
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85173822939&doi=10.1016%2fj.amjoto.2023.104085&partnerID=40&md5=f944ff01c4c7dd4f7e277030fcba42a3
AD  - Department of Otorhinolaryngology – Head and Neck Surgery, University of Pennsylvania, Philadelphia, PA, United States
AD  - Leonard Davis Institute of Health Economics, University of Pennsylvania, Philadelphia, PA, United States
AB  - Purpose: To examine and compare ChatGPT versus Google websites in answering common head and neck cancer questions. Materials and methods: Commonly asked questions about head and neck cancer were obtained and inputted into both ChatGPT-4 and Google search engine. For each question, the ChatGPT response and first website search result were compiled and examined. Content quality was assessed by independent reviewers using standardized grading criteria and the modified Ensuring Quality Information for Patients (EQIP) tool. Readability was determined using the Flesch reading ease scale. Results: In total, 49 questions related to head and neck cancer were included. Google sources were on average significantly higher quality than ChatGPT responses (4.2 vs 3.6, p = 0.005). According to the EQIP tool, Google and ChatGPT had on average similar response rates per criterion (24.4 vs 20.5, p = 0.09) while Google had a significantly higher average score per question than ChatGPT (13.8 vs 11.7, p < 0.001) According to the Flesch reading ease scale, ChatGPT and Google sources were both considered similarly difficult to read (33.1 vs 37.0, p = 0.180) and at a college level (14.3 vs 14.2, p = 0.820.) Conclusion: ChatGPT responses were as challenging to read as Google sources, but poorer quality due to decreased reliability and accuracy in answering questions. Though promising, ChatGPT in its current form should not be considered dependable. Google sources are a preferred resource for patient educational materials. © 2023 Elsevier Inc.
KW  - Artificial intelligence
KW  - Chatgpt
KW  - Common questions
KW  - Head and neck cancer
KW  - Patient education
KW  - Head and Neck Neoplasms
KW  - Humans
KW  - Reproducibility of Results
KW  - Search Engine
KW  - adult
KW  - Article
KW  - artificial intelligence
KW  - awareness
KW  - ChatGPT
KW  - controlled study
KW  - head and neck cancer
KW  - human
KW  - interrater reliability
KW  - patient education
KW  - reading
KW  - reliability
KW  - search engine
KW  - head and neck tumor
KW  - reproducibility
PB  - W.B. Saunders
SN  - 01960709 (ISSN)
C2  - 37844413
LA  - English
J2  - Am. J. Otolaryngol. Head Neck Med. Surg.
M3  - Article
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 0; Correspondence Address: K. Rajasekaran; Philadelphia, 800 Walnut St, 18th Floor, 19107, United States; email: Karthik.rajasekaran@pennmedicine.upenn.edu; CODEN: AJOTD
ER  -

TY  - JOUR
AU  - Suárez, A.
AU  - Jiménez, J.
AU  - Llorente de Pedro, M.
AU  - Andreu-Vázquez, C.
AU  - Díaz-Flores García, V.
AU  - Gómez Sánchez, M.
AU  - Freire, Y.
TI  - Beyond the Scalpel: Assessing ChatGPT's potential as an auxiliary intelligent virtual assistant in oral surgery
PY  - 2024
T2  - Computational and Structural Biotechnology Journal
VL  - 24
SP  - 46
EP  - 52
DO  - 10.1016/j.csbj.2023.11.058
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85179123620&doi=10.1016%2fj.csbj.2023.11.058&partnerID=40&md5=86cd61eacbc28df4c7d780cf29547aeb
AD  - Department of Pre-Clinic Dentistry, Faculty of Biomedical and Health Sciences, Universidad Europea de Madrid, Calle Tajo s/n, Villaviciosa de Odón, Madrid, 28670, Spain
AD  - Department of Clinic Dentistry, Faculty of Biomedical and Health Sciences, Universidad Europea de Madrid, Calle Tajo s/n, Villaviciosa de Odón, Madrid, 28670, Spain
AD  - Department of Veterinary Medicine, Faculty of Biomedical and Health Sciences, Universidad Europea de Madrid, Calle Tajo s/n, Villaviciosa de Odón, Madrid, 28670, Spain
AB  - AI has revolutionized the way we interact with technology. Noteworthy advances in AI algorithms and large language models (LLM) have led to the development of natural generative language (NGL) systems such as ChatGPT. Although these LLM can simulate human conversations and generate content in real time, they face challenges related to the topicality and accuracy of the information they generate. This study aimed to assess whether ChatGPT-4 could provide accurate and reliable answers to general dentists in the field of oral surgery, and thus explore its potential as an intelligent virtual assistant in clinical decision making in oral surgery. Thirty questions related to oral surgery were posed to ChatGPT4, each question repeated 30 times. Subsequently, a total of 900 responses were obtained. Two surgeons graded the answers according to the guidelines of the Spanish Society of Oral Surgery, using a three-point Likert scale (correct, partially correct/incomplete, and incorrect). Disagreements were arbitrated by an experienced oral surgeon, who provided the final grade Accuracy was found to be 71.7%, and consistency of the experts' grading across iterations, ranged from moderate to almost perfect. ChatGPT-4, with its potential capabilities, will inevitably be integrated into dental disciplines, including oral surgery. In the future, it could be considered as an auxiliary intelligent virtual assistant, though it would never replace oral surgery experts. Proper training and verified information by experts will remain vital to the implementation of the technology. More comprehensive research is needed to ensure the safe and successful application of AI in oral surgery. © 2023 The Authors
KW  - Artificial Intelligence
KW  - Chatbot
KW  - ChatGPT
KW  - Dentistry
KW  - Large language models
KW  - Natural generative language
KW  - Open AI
KW  - Oral surgery
KW  - Computational linguistics
KW  - Decision making
KW  - Dentistry
KW  - Grading
KW  - AI algorithms
KW  - Chatbots
KW  - ChatGPT
KW  - Language model
KW  - Large language model
KW  - Natural generative language
KW  - Open AI
KW  - Oral surgery
KW  - Real- time
KW  - Virtual assistants
KW  - algorithm
KW  - Article
KW  - ChatGPT
KW  - clinical decision making
KW  - data availability
KW  - dentist
KW  - disruptive technology
KW  - human
KW  - medical practice
KW  - open ended questionnaire
KW  - oral surgery
KW  - practice guideline
KW  - Surgery
PB  - Elsevier B.V.
SN  - 20010370 (ISSN)
LA  - English
J2  - Comput. Struct. Biotechnol. J.
M3  - Article
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 0; Correspondence Address: V. Díaz-Flores García; Department of Pre-Clinic Dentistry, School of Biomedical Sciences, Universidad Europea de Madrid, Madrid, Calle Tajo s/n, Villaviciosa de Odón, 28670, Spain; email: victor.diaz-flores@universidadeuropea.es
ER  -

TY  - JOUR
AU  - Ozgor, F.
AU  - Caglar, U.
AU  - Halis, A.
AU  - Cakir, H.
AU  - Aksu, U.C.
AU  - Ayranci, A.
AU  - Sarilar, O.
TI  - Urological Cancers and ChatGPT: Assessing the Quality of Information and Possible Risks for Patients
PY  - 2024
T2  - Clinical Genitourinary Cancer
DO  - 10.1016/j.clgc.2023.12.017
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85183531725&doi=10.1016%2fj.clgc.2023.12.017&partnerID=40&md5=bf26e23d095f347165c353bdf6d2d077
AD  - Department of Urology, Haseki Training and Research Hospital, Istanbul, Turkey
AD  - Department of Urology, Fulya Acibadem Hospital, Istanbul, Turkey
AB  - Introduction: OpenAI has created ChatGPT, an artificial intelligence language model that has gained considerable recognition for its capacity to produce text responses resembling human language. Consequently, this study seeks to evaluate the effectiveness of ChatGPT's responses in addressing publicly accessible queries related to prostate, kidney, bladder, and testicular cancers. Material and Methods: A comprehensive compilation of frequently asked questions (FAQs) pertaining to prostate, bladder, kidney, and testicular cancers was gathered from diverse sources. Additionally, the recommendations outlined in the European Association of Urology (EAU) 2023 Guideline Oncology were consulted. The chosen questions for evaluation were presented to the ChatGPT 4.0 premium version. The quality of ChatGPT responses was appraised using the global quality score (GQS). Each ChatGPT response was independently reviewed by a panel of physicians, who assigned a GQS score to assess its overall quality. Results: For prostate cancer, 64.6% of the questions had a GQS score of 5, compared to 62.9 % for bladder, 68.1% for kidney, and 63.9% for testicular cancers, whereas none of the responses had a GQS score of 1. Meanwhile, the category with the lowest proportion of responses, with a GQS score of 5 for each disease, was prognosis and follow-up. The mean GQS score of the answers given to EAU guideline questions was statistically significantly lower than the average score of the answers given to FAQs. Conclusion: ChatGPT is a valuable tool for addressing general inquiries regarding urological cancers, boasting commendable accuracy rates. Nonetheless, its performance in responding to questions aligned with the EAU guideline was deemed unsatisfactory. © 2024 Elsevier Inc.
KW  - Artificial intelligence
KW  - ChatGPT
KW  - Global quality score
KW  - Information sources
KW  - Urooncology
PB  - Elsevier Inc.
SN  - 15587673 (ISSN)
C2  - 38246831
LA  - English
J2  - Clin. Genitourin. Cancer
M3  - Article
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 0; Correspondence Address: F. Ozgor; Istanbul, Ugur Mumcu Mahallesi, Belediye Sokak, No:7 Sultangazi, Turkey; email: md.farukozgor@gmail.com
ER  -

TY  - JOUR
AU  - Kollitsch, L.
AU  - Eredics, K.
AU  - Marszalek, M.
AU  - Rauchenwald, M.
AU  - Brookman-May, S.D.
AU  - Burger, M.
AU  - Körner-Riffard, K.
AU  - May, M.
TI  - How does artificial intelligence master urological board examinations? A comparative analysis of different Large Language Models’ accuracy and reliability in the 2022 In-Service Assessment of the European Board of Urology
PY  - 2024
T2  - World Journal of Urology
VL  - 42
IS  - 1
C7  - 20
DO  - 10.1007/s00345-023-04749-6
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85181876750&doi=10.1007%2fs00345-023-04749-6&partnerID=40&md5=535902b836a46885b9aa6d65f3278455
AD  - Department of Urology and Andrology, Klinik Donaustadt, Vienna, Austria
AD  - Department of Urology, Paracelsus Medical University, Salzburg, Austria
AD  - European Board of Urology, Arnhem, Netherlands
AD  - Department of Urology, University of Munich, LMU, Munich, Germany
AD  - Johnson and Johnson Innovative Medicine, Research and Development, Spring House, PA, United States
AD  - Department of Urology, Caritas St. Josef Medical Centre, University of Regensburg, Regensburg, Germany
AD  - Department of Urology, St. Elisabeth Hospital Straubing, Brothers of Mercy Hospital, Straubing, Germany
AB  - Purpose: This study is a comparative analysis of three Large Language Models (LLMs) evaluating their rate of correct answers (RoCA) and the reliability of generated answers on a set of urological knowledge-based questions spanning different levels of complexity. Methods: ChatGPT-3.5, ChatGPT-4, and Bing AI underwent two testing rounds, with a 48-h gap in between, using the 100 multiple-choice questions from the 2022 European Board of Urology (EBU) In-Service Assessment (ISA). For conflicting responses, an additional consensus round was conducted to establish conclusive answers. RoCA was compared across various question complexities. Ten weeks after the consensus round, a subsequent testing round was conducted to assess potential knowledge gain and improvement in RoCA, respectively. Results: Over three testing rounds, ChatGPT-3.5 achieved RoCa scores of 58%, 62%, and 59%. In contrast, ChatGPT-4 achieved RoCA scores of 63%, 77%, and 77%, while Bing AI yielded scores of 81%, 73%, and 77%, respectively. Agreement rates between rounds 1 and 2 were 84% (κ = 0.67, p < 0.001) for ChatGPT-3.5, 74% (κ = 0.40, p < 0.001) for ChatGPT-4, and 76% (κ = 0.33, p < 0.001) for BING AI. In the consensus round, ChatGPT-4 and Bing AI significantly outperformed ChatGPT-3.5 (77% and 77% vs. 59%, both p = 0.010). All LLMs demonstrated decreasing RoCA scores with increasing question complexity (p < 0.001). In the fourth round, no significant improvement in RoCA was observed across all three LLMs. Conclusions: The performance of the tested LLMs in addressing urological specialist inquiries warrants further refinement. Moreover, the deficiency in response reliability contributes to existing challenges related to their current utility for educational purposes. © 2024, The Author(s), under exclusive licence to Springer-Verlag GmbH Germany, part of Springer Nature.
KW  - AI
KW  - BING AI
KW  - ChatGPT-3.5
KW  - ChatGPT-4
KW  - EBU
KW  - ISA
KW  - LLM
KW  - Medical exam
KW  - Pass mark
KW  - Urology exam
KW  - Artificial Intelligence
KW  - Humans
KW  - Language
KW  - Physical Examination
KW  - Reproducibility of Results
KW  - Urology
KW  - artificial intelligence
KW  - human
KW  - language
KW  - physical examination
KW  - reproducibility
KW  - urology
PB  - Springer Science and Business Media Deutschland GmbH
SN  - 07244983 (ISSN)
C2  - 38197996
LA  - English
J2  - World J. Urol.
M3  - Article
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 0; Correspondence Address: M. May; Department of Urology, St. Elisabeth Hospital Straubing, Brothers of Mercy Hospital, Straubing, Germany; email: matthias.may@klinikum-straubing.de
ER  -

TY  - JOUR
AU  - Wiwanitkit, S.
AU  - Wiwanitkit, V.
TI  - Correspondence on “evaluation of ChatGPT pathology knowledge using board-style questions”
PY  - 2024
T2  - Journal of Stomatology, Oral and Maxillofacial Surgery
VL  - 125
IS  - 5
C7  - 101758
DO  - 10.1016/j.jormas.2023.101758
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85181816457&doi=10.1016%2fj.jormas.2023.101758&partnerID=40&md5=87be0a1dd48060f65a7f5bd9bdb91867
AD  - Private Academic and Editorial Consultant, 17 Bangkhae, Bangkok, 101160, Thailand
AD  - Department of Research Analytics, Saveetha Dental College and Hospitals, Saveetha Institute of Medical and Technical Sciences, Saveetha University, India
PB  - Elsevier Masson s.r.l.
SN  - 24687855 (ISSN)
LA  - English
J2  - J. Stomatol. Oral. Max. Surg.
M3  - Letter
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 0; Correspondence Address: S. Wiwanitkit; Private Academic and Editorial Consultant, Bangkok, 17 Bangkhae, 101160, Thailand; email: somsriwiwan@hotmail.com
ER  -

TY  - JOUR
AU  - Morishita, M.
AU  - Fukuda, H.
AU  - Muraoka, K.
AU  - Nakamura, T.
AU  - Hayashi, M.
AU  - Yoshioka, I.
AU  - Ono, K.
AU  - Awano, S.
TI  - Evaluating GPT-4V's performance in the Japanese national dental examination: A challenge explored
PY  - 2024
T2  - Journal of Dental Sciences
DO  - 10.1016/j.jds.2023.12.007
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85181141956&doi=10.1016%2fj.jds.2023.12.007&partnerID=40&md5=b06e8fe282dc30b2691b7c24c836d777
AD  - Division of Clinical Education Development and Research, Department of Oral Function, Kyushu Dental University, Kitakyushu, Japan
AD  - Health Information Management Office, Kyushu Dental University Hospital, Kitakyushu, Japan
AD  - Division of Maxillofacial Surgery, Department of Physical Function, Kyushu Dental University, Kitakyushu, Japan
AD  - Division of Periodontology, Department of Oral Function, Kyushu Dental University, Kitakyushu, Japan
AD  - Administration Department, Kyushu Dental University Hospital, Kitakyushu, Japan
AD  - Division of Oral Medicine, Department of Physical Function, Kitakyushu, Japan
AD  - Division of Physiology, Department of Health Promotion, Kyushu Dental University, Kitakyushu, Japan
AB  - Background/purpose: Rapid advancements in AI technology have led to significant interest in its application across various fields, including medicine and dentistry. This study aimed to assess the capabilities of ChatGPT-4V with image recognition in answering image-based questions from the Japanese National Dental Examination (JNDE) to explore its potential as an educational support tool for dental students. Materials and methods: The dataset used questions from the JNDE, which was conducted in January 2023, with a focus on image-related queries. ChatGPT-4V was utilized, and standardized prompts, question texts, and images were input. Data and statistical analyses were conducted using Qlik Sense® and GraphPad Prism. Results: The overall correct response rate of ChatGPT-4V for image-based JNDE questions was 35.0 %. The correct response rates were 57.1 % for compulsory questions, 43.6 % for general questions, and 28.6 % for clinical practical questions. In specialties like Dental Anesthesiology and Endodontics, ChatGPT-4V achieved correct response rates above 70 %, while response rates for Orthodontics and Oral Surgery were lower. A higher number of images in questions was correlated with lower accuracy, suggesting an impact of the number of images on correct and incorrect responses. Conclusion: While innovative, ChatGPT-4V's image recognition feature exhibited limitations, especially in handling image-intensive and complex clinical practical questions, and is not yet fully suitable as an educational support tool for dental students at its current stage. Further technological refinement and re-evaluation with a broader dataset are recommended. © 2023 Association for Dental Sciences of the Republic of China
KW  - ChatGPT-4V
KW  - Image recognition
KW  - Medical image analysis
KW  - National dental examination
PB  - Association for Dental Sciences of the Republic of China
SN  - 19917902 (ISSN)
LA  - English
J2  - J. Dent. Sci.
M3  - Article
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 0; Correspondence Address: M. Morishita; Kyushu Dental University, Division of Clinical Education Development and Research, Department of Oral Function, Kitakyushu, 2-6-1 Manazuru, Kokurakita, 803-8580, Japan; email: r08morishita@fa.kyu-dent.ac.jp
ER  -

TY  - JOUR
AU  - Cakir, H.
AU  - Caglar, U.
AU  - Yildiz, O.
AU  - Meric, A.
AU  - Ayranci, A.
AU  - Ozgor, F.
TI  - Evaluating the performance of ChatGPT in answering questions related to urolithiasis
PY  - 2024
T2  - International Urology and Nephrology
VL  - 56
IS  - 1
SP  - 17
EP  - 21
DO  - 10.1007/s11255-023-03773-0
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85169587232&doi=10.1007%2fs11255-023-03773-0&partnerID=40&md5=65582ef39457d5dd526342e3bb7c3a2d
AD  - Department of Urology, Fulya Acibadem Hospital, Istanbul, Sisli, Turkey
AD  - Department of Urology, Haseki Training and Research Hospital, Istanbul, Turkey
AB  - Purpose: ChatGPT is an artificial intelligence (AI) program with natural language processing. We analyzed ChatGPT’s knowledge about urolithiasis whether it can be used to inform patients about urolithiasis. Methods: Frequently asked questions (FAQs) about urolithiasis on the websites of urological associations and hospitals were analyzed. Also, strong recommendation-level information was gathered from the urolithiasis section of the European Association of Urology (EAU) 2022 Guidelines. All questions were asked in order in ChatGPT August 3rd version. All answers were evaluated separately by two specialist urologists and scored between 1 and 4, where 1: completely correct, 2: correct but inadequate, 3: a mix of correct and misleading information, and 4: completely incorrect. Results: Of the FAQs, 94.6% were answered completely correctly. No question was answered completely incorrectly. All questions about general, diagnosis, and ureteral stones were graded as 1. Of the 60 questions prepared according to the EAU guideline recommendations, 50 (83.3%) were evaluated as grade 1, and 8 (13.3%) and 2 (3.3%) as grade 3. All questions related to general, diagnostic, renal calculi, ureteral calculi, and metabolic evaluation received the same answer the second time they were asked. Conclusion: Our findings demonstrated that ChatGPT accurately and satisfactorily answered more than 95% of the questions about urolithiasis. We conclude that applying ChatGPT in urology clinics under the supervision of urologists can help patients and their families to have better understanding on urolithiasis diagnosis and treatment. © 2023, The Author(s), under exclusive licence to Springer Nature B.V.
KW  - Artificial intelligence
KW  - ChatGPT
KW  - Patient knowledge
KW  - Urolithiasis
KW  - Artificial Intelligence
KW  - Hospitals
KW  - Humans
KW  - Kidney Calculi
KW  - Ureteral Calculi
KW  - Urolithiasis
KW  - Article
KW  - attitude to illness
KW  - ChatGPT
KW  - data accuracy
KW  - data analysis
KW  - health education
KW  - human
KW  - Internet
KW  - medical information
KW  - medical society
KW  - metabolic parameters
KW  - nephrolithiasis
KW  - practice guideline
KW  - satisfaction
KW  - ureter stone
KW  - urolithiasis
KW  - urologist
KW  - artificial intelligence
KW  - hospital
KW  - nephrolithiasis
KW  - ureter stone
KW  - urolithiasis
PB  - Springer Science and Business Media B.V.
SN  - 03011623 (ISSN)
C2  - 37658948
LA  - English
J2  - Int. Urol. Nephrol.
M3  - Article
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 3; Correspondence Address: H. Cakir; Department of Urology, Fulya Acibadem Hospital, Sisli, Istanbul, Turkey; email: hakancakirmd@gmail.com; CODEN: IURNA
ER  -

TY  - JOUR
AU  - Revercomb, L.
AU  - Patel, A.M.
AU  - Choudhry, H.S.
AU  - Filimonov, A.
TI  - Performance of ChatGPT in Otolaryngology knowledge assessment
PY  - 2024
T2  - American Journal of Otolaryngology - Head and Neck Medicine and Surgery
VL  - 45
IS  - 1
C7  - 104082
DO  - 10.1016/j.amjoto.2023.104082
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85174212959&doi=10.1016%2fj.amjoto.2023.104082&partnerID=40&md5=2649e08f5fdc83edc18a89cda32239a8
AD  - Department of Otolaryngology – Head and Neck Surgery, Rutgers New Jersey Medical School, Newark, NJ, United States
KW  - Artificial intelligence
KW  - Board certification examination
KW  - ChatGPT
KW  - Medical education
KW  - ChatGPT
KW  - examination
KW  - human
KW  - knowledge
KW  - Letter
KW  - multiple choice test
KW  - otorhinolaryngology
PB  - W.B. Saunders
SN  - 01960709 (ISSN)
C2  - 37862879
LA  - English
J2  - Am. J. Otolaryngol. Head Neck Med. Surg.
M3  - Letter
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 0; Correspondence Address: A. Filimonov; Rutgers New Jersey Medical School, Newark, 185 S Orange Ave, 07103, United States; email: andreyf@njms.rutgers.edu; CODEN: AJOTD
ER  -

TY  - JOUR
AU  - Cai, X.
AU  - Lai, H.
AU  - Wang, X.
AU  - Wang, L.
AU  - Liu, W.
AU  - Wang, Y.
AU  - Wang, Z.
AU  - Cao, D.
AU  - Zeng, X.
TI  - Comprehensive evaluation of molecule property prediction with ChatGPT
PY  - 2024
T2  - Methods
VL  - 222
SP  - 133
EP  - 141
DO  - 10.1016/j.ymeth.2024.01.004
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85182904163&doi=10.1016%2fj.ymeth.2024.01.004&partnerID=40&md5=b0cfd770ae9878fdf6334c5a089ba041
AD  - Department of Computer Science, Hunan University, China
AD  - Tencent AI Lab, China
AD  - University of Tsukuba, Japan
AD  - Xiangya School of Pharmaceutical Sciences, Central South University, China
AB  - The versatility of ChatGPT in performing a diverse range of tasks has elicited considerable interest on its potential applications within professional fields. Taking drug discovery as a testbed, this paper provides a comprehensive evaluation of ChatGPT's ability on molecule property prediction. The study focuses on three aspects: 1) Effects of different prompt settings, where we investigate the impact of varying prompts on the prediction outcomes of ChatGPT; 2) Comprehensive evaluation on molecule property prediction, where we conduct a comprehensive evaluation on 53 ADMET-related endpoints; 3) Analysis of ChatGPT's potential and limitations, where we make comparisons with models tailored for molecule property prediction, thus gaining a more accurate understanding of ChatGPT's capabilities and limitations in this area. Through comprehensive evaluation, we find that 1) With appropriate prompt settings, ChatGPT can attain satisfactory prediction outcomes that are competitive with specialized models designed for those tasks. 2) Prompt settings significantly affect ChatGPT's performance. Among all prompt settings, the strategy of selecting examples in few-shot has the greatest impact on results. Scaffold sampling greatly outperforms random sampling. 3) The capacity of ChatGPT to accomplish high-precision predictions is significantly influenced by the quality of examples provided, which may constrain its practical applicability in real-world scenarios. This work highlights ChatGPT's potential and limitations on molecule property prediction, which we hope can inspire future design and evaluation of Large Language Models within scientific domains. © 2024 Elsevier Inc.
KW  - ChatGPT
KW  - Evaluation
KW  - Few-shot
KW  - Molecule property prediction
KW  - Prompt
PB  - Academic Press Inc.
SN  - 10462023 (ISSN)
C2  - 38242382
LA  - English
J2  - Methods
M3  - Article
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 0; Correspondence Address: X. Cai; Department of Computer Science, Hunan University, China; email: dalecai@hnu.edu.cn; CODEN: MTHDE
ER  -

TY  - CONF
AU  - Nguyen, D.-V.
AU  - Nguyen, Q.-N.
TI  - Evaluating the Symbol Binding Ability of Large Language Models for Multiple-Choice Questions in Vietnamese General Education
PY  - 2023
T2  - ACM International Conference Proceeding Series
SP  - 379
EP  - 386
DO  - 10.1145/3628797.3628837
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85180548212&doi=10.1145%2f3628797.3628837&partnerID=40&md5=eaa80a6ba1ca31ba6e354e715473f6b7
AD  - University of Information Technology, Ho Chi Minh City, Viet Nam
AD  - Vietnam National University, Ho Chi Minh City, Viet Nam
AB  - In this paper, we evaluate the ability of large language models (LLMs) to perform multiple choice symbol binding (MCSB) for multiple choice question answering (MCQA) tasks in zero-shot, one-shot, and few-shot settings. We focus on Vietnamese, with fewer challenging MCQA datasets than in English. The two existing datasets, ViMMRC 1.0 and ViMMRC 2.0, focus on literature. Recent research in Vietnamese natural language processing (NLP) has focused on the Vietnamese National High School Graduation Examination (VNHSGE) from 2019 to 2023 to evaluate ChatGPT. However, these studies have mainly focused on how ChatGPT solves the VNHSGE step by step. We aim to create a novel and high-quality dataset by providing structured guidelines for typing LaTeX formulas for mathematics, physics, chemistry, and biology. This dataset can be used to evaluate the MCSB ability of LLMs and smaller language models (LMs) because it is typed in a strict LaTeX style. We determine the most probable character answer (A, B, C, or D) based on context, instead of finding the answer step by step as in previous Vietnamese works. This reduces computational costs and accelerates the evaluation of LLMs. Our evaluation of six well-known LLMs, namely BLOOMZ-7.1B-MT, LLaMA-2-7B, LLaMA-2-70B, GPT-3, GPT-3.5, and GPT-4.0, on the ViMMRC 1.0 and ViMMRC 2.0 benchmarks and our proposed dataset shows promising results on the MCSB ability of LLMs for Vietnamese. The dataset is available1 for research purposes only.  © 2023 ACM.
KW  - Analysis of Language Models
KW  - Language Modeling
KW  - Multiple Choice Question Answering
KW  - Multiple Choice Symbol Binding
KW  - Computational linguistics
KW  - Natural language processing systems
KW  - Petroleum reservoir evaluation
KW  - Zero-shot learning
KW  - Analyse of language model
KW  - Binding abilities
KW  - Language model
KW  - Multiple choice
KW  - Multiple choice question answering
KW  - Multiple choice symbol binding
KW  - Multiple-choice questions
KW  - Question Answering
KW  - Vietnamese
KW  - Modeling languages
PB  - Association for Computing Machinery
SN  - 979-840070891-6 (ISBN)
LA  - English
J2  - ACM Int. Conf. Proc. Ser.
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 0; Conference name: 12th International Symposium on Information and Communication Technology, SOICT 2023; Conference date: 7 December 2023 through 8 December 2023; Conference code: 195401
ER  -

TY  - JOUR
AU  - Herrmann-Werner, A.
AU  - Festl-Wietek, T.
AU  - Holderried, F.
AU  - Herschbach, L.
AU  - Griewatz, J.
AU  - Masters, K.
AU  - Zipfel, S.
AU  - Mahling, M.
TI  - Assessing ChatGPT's Mastery of Bloom's Taxonomy Using Psychosomatic Medicine Exam Questions: Mixed-Methods Study
PY  - 2024
T2  - Journal of Medical Internet Research
VL  - 26
IS  - 1
C7  - e52113
DO  - 10.2196/52113
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85183224105&doi=10.2196%2f52113&partnerID=40&md5=0bb89fbd1ef18bc48868aaf4422563f3
AD  - Tübingen Institute for Medical Education, Faculty of Medicine, University of Tübingen, Tübingen, Germany
AD  - Department of Psychosomatic Medicine and Psychotherapy, University Hospital Tübingen, Tübingen, Germany
AD  - University Department of Anesthesiology and Intensive Care Medicine, University Hospital Tübingen, Tübingen, Germany
AD  - Medical Education and Informatics Department, College of Medicine and Health Sciences, Sultan Qaboos University, Muscat, Oman
AD  - Department of Diabetology, Endocrinology, Nephrology, Section of Nephrology and Hypertension, University Hospital Tübingen, Tübingen, Germany
AD  - Tübingen Institute for Medical Education, Faculty of Medicine, University of Tübingen, Elfriede-Aulhorn-Strasse 10, Tübingen, 72076, Germany
AB  - Background: Large language models such as GPT-4 (Generative Pre-trained Transformer 4) are being increasingly used in medicine and medical education. However, these models are prone to “hallucinations” (ie, outputs that seem convincing while being factually incorrect). It is currently unknown how these errors by large language models relate to the different cognitive levels defined in Bloom's taxonomy. Objective: This study aims to explore how GPT-4 performs in terms of Bloom's taxonomy using psychosomatic medicine exam questions. Methods: We used a large data set of psychosomatic medicine multiple-choice questions (N=307) with real-world results derived from medical school exams. GPT-4 answered the multiple-choice questions using 2 distinct prompt versions: detailed and short. The answers were analyzed using a quantitative approach and a qualitative approach. Focusing on incorrectly answered questions, we categorized reasoning errors according to the hierarchical framework of Bloom's taxonomy. Results: GPT-4's performance in answering exam questions yielded a high success rate: 93% (284/307) for the detailed prompt and 91% (278/307) for the short prompt. Questions answered correctly by GPT-4 had a statistically significant higher difficulty than questions answered incorrectly (P = .002 for the detailed prompt and P < .001 for the short prompt). Independent of the prompt, GPT-4's lowest exam performance was 78.9% (15/19), thereby always surpassing the “pass” threshold. Our qualitative analysis of incorrect answers, based on Bloom's taxonomy, showed that errors were primarily in the “remember” (29/68) and “understand” (23/68) cognitive levels; specific issues arose in recalling details, understanding conceptual relationships, and adhering to standardized guidelines. Conclusions: GPT-4 demonstrated a remarkable success rate when confronted with psychosomatic medicine multiple-choice exam questions, aligning with previous findings. When evaluated through Bloom's taxonomy, our data revealed that GPT-4 occasionally ignored specific facts (remember), provided illogical reasoning (understand), or failed to apply concepts to a new situation (apply). These errors, which were confidently presented, could be attributed to inherent model biases and the tendency to generate outputs that maximize likelihood. © 2024 Journal of Medical Internet Research. All rights reserved.
KW  - answer
KW  - artificial intelligence
KW  - assessment
KW  - Bloom's taxonomy
KW  - ChatGPT
KW  - classification
KW  - error
KW  - exam
KW  - examination
KW  - generative
KW  - Generative Pre-trained Transformer 4
KW  - GPT-4
KW  - language model
KW  - learning outcome
KW  - LLM
KW  - MCQ
KW  - medical education
KW  - medical exam
KW  - multiple-choice question
KW  - natural language processing
KW  - NLP
KW  - psychosomatic
KW  - question
KW  - response
KW  - taxonomy
KW  - Aminosalicylic Acid
KW  - Education, Medical
KW  - Humans
KW  - Medicine
KW  - Psychosomatic Medicine
KW  - Research Design
KW  - aminosalicylic acid
KW  - human
KW  - medical education
KW  - medicine
KW  - methodology
KW  - psychosomatics
PB  - JMIR Publications Inc.
SN  - 14388871 (ISSN)
C2  - 38261378
LA  - English
J2  - J. Med. Internet Res.
M3  - Article
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 0
ER  -

TY  - CONF
AU  - Huang, C.-W.
AU  - Coleman, M.
AU  - Gachago, D.
AU  - Van Belle, J.-P.
TI  - Using ChatGPT to Encourage Critical AI Literacy Skills and for Assessment in Higher Education
PY  - 2024
T2  - Communications in Computer and Information Science
VL  - 1862
SP  - 105
EP  - 118
DO  - 10.1007/978-3-031-48536-7_8
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85181979460&doi=10.1007%2f978-3-031-48536-7_8&partnerID=40&md5=a5c9c4cbc5ee4fc413f391fd4cff84c5
AD  - University of Cape Town, Rondebosch, South Africa
AB  - Generative AI is about to radically transform the way intellectual and creative work is being done. Since the release of ChatGPT in late 2022, the potential impact of generative AI tools on higher education has been intensively debated. ChatGPT can generate well-formulated human-like text passages and conversations that is often, but not always, of a surprisingly high quality. This paper reports on an early experiment to explore ways in which ChatGPT can be used in the higher education context. The experiment involved a written assignment which required postgraduate Information Systems students to formulate a critique of the outputs of ChatGPT to a specific question in Information Systems project management. The paper investigates the level of criticality that the students demonstrated in working with ChatGPT and assessing the quality of its outputs. It further explores the claim that ChatGPT can be used to generate rubrics and assess students’ assignments by asking ChatGPT to produce a rubric for critical thinking and assess the students’ assignments against the rubric produced. The findings indicate that students perceive the ChatGPT produced responses as generally accurate, although they tend to lack depth, with some key information omitted, produced biased responses and have limitations with academic writing conventions. The rubric that ChatGPT produced for assessing critical thinking is lacking in certain areas and the reliability of using it as an assessment tool is questionable given the inconsistency in the results. Overall, the paper concludes that while ChatGPT and other text generative AI can be useful learning and teaching companions for both students and lectures, human expertise and judgement is needed in working with ChatGPT. © 2024, The Author(s), under exclusive license to Springer Nature Switzerland AG.
KW  - AI in Education
KW  - ChatGPT
KW  - Generative AI
KW  - ICT in Education
KW  - Teaching Tools
KW  - Artificial intelligence
KW  - Information management
KW  - Information systems
KW  - Information use
KW  - Project management
KW  - AI in education
KW  - ChatGPT
KW  - Creative work
KW  - Critical thinking
KW  - Generative AI
KW  - High educations
KW  - ICT in education
KW  - Intellectual works
KW  - Student assignments
KW  - Teaching tools
KW  - Students
A2  - Van Rensburg H.E.
A2  - Drevin L.
A2  - Drevin G.R.
A2  - Snyman D.P.
PB  - Springer Science and Business Media Deutschland GmbH
SN  - 18650929 (ISSN); 978-303148535-0 (ISBN)
LA  - English
J2  - Commun. Comput. Info. Sci.
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 0; Correspondence Address: J.-P. Van Belle; University of Cape Town, Rondebosch, South Africa; email: jean-paul.vanbelle@uct.ac.za; Conference name: 52nd Annual Conference of the Southern African Computer Lecturers Association, SACLA 2023; Conference date: 19 July 2023 through 21 July 2023; Conference code: 306179
ER  -

TY  - JOUR
AU  - Meltzer, P.
AU  - Lambourne, J.G.
AU  - Grandi, D.
TI  - What's in a Name? Evaluating Assembly-Part Semantic Knowledge in Language Models Through User-Provided Names in Computer Aided Design Files
PY  - 2024
T2  - Journal of Computing and Information Science in Engineering
VL  - 24
IS  - 1
C7  - 011002
DO  - 10.1115/1.4062454
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85175295969&doi=10.1115%2f1.4062454&partnerID=40&md5=a475a8c1fb4fed2fe13f3f16e87d5cb0
AD  - Autodesk Research, London, WC2R 0QE, United Kingdom
AD  - Autodesk Research, San Francisco, 94105, CA, United States
AB  - Semantic knowledge of part-part and part-whole relationships in assemblies is useful for a variety of tasks from searching design repositories to the construction of engineering knowledge bases. In this work, we propose that the natural language names designers use in computer aided design (CAD) software are a valuable source of such knowledge, and that large language models (LLMs) contain useful domain-specific information for working with this data as well as other CAD and engineering-related tasks. In particular, we extract and clean a large corpus of natural language part, feature, and document names and use this to quantitatively demonstrate that a pre-trained language model can outperform numerous benchmarks on three self-supervised tasks, without ever having seen this data before. Moreover, we show that fine-tuning on the text data corpus further boosts the performance on all tasks, thus demonstrating the value of the text data which until now has been largely ignored. We also identify key limitations to using LLMs with text data alone, and our findings provide a strong motivation for further work into multi-modal text-geometry models. To aid and encourage further work in this area we make all our data and code publicly available.  © 2023 by ASME.
KW  - Artificial intelligence
KW  - big data and analytics
KW  - computer aided design
KW  - data driven engineering
KW  - machine learning for engineering applications
KW  - Big data
KW  - Computational linguistics
KW  - Computer aided instruction
KW  - Machine learning
KW  - Semantics
KW  - Big data and analytic
KW  - Computer-aided design
KW  - Data driven
KW  - Data driven engineering
KW  - Engineering applications
KW  - Language model
KW  - Machine learning for engineering application
KW  - Machine-learning
KW  - Semantics knowledge
KW  - Text data
KW  - Computer aided design
PB  - American Society of Mechanical Engineers (ASME)
SN  - 15309827 (ISSN)
LA  - English
J2  - J. Comput. Inf. Sci. Eng.
M3  - Article
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 0; Correspondence Address: J.G. Lambourne; Autodesk Research, London, WC2R 0QE, United Kingdom; email: joseph.lambourne@autodesk.com
ER  -

TY  - JOUR
AU  - Beaulieu-Jones, B.R.
AU  - Berrigan, M.T.
AU  - Shah, S.
AU  - Marwaha, J.S.
AU  - Lai, S.-L.
AU  - Brat, G.A.
TI  - Evaluating capabilities of large language models: Performance of GPT-4 on surgical knowledge assessments
PY  - 2024
T2  - Surgery (United States)
DO  - 10.1016/j.surg.2023.12.014
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85183568584&doi=10.1016%2fj.surg.2023.12.014&partnerID=40&md5=ea94287112b526bd9a2f1ae13f400f8f
AD  - Department of Surgery, Beth Israel Deaconess Medical Center, Boston, MA, United States
AD  - Department of Biomedical Informatics, Harvard Medical School, Boston, MA, United States
AD  - Geisinger Commonwealth School of Medicine, Scranton, PA, United States
AD  - Division of Colorectal Surgery, National Taiwan University Hospital, Taipei, Taiwan
AB  - Background: Artificial intelligence has the potential to dramatically alter health care by enhancing how we diagnose and treat disease. One promising artificial intelligence model is ChatGPT, a general-purpose large language model trained by OpenAI. ChatGPT has shown human-level performance on several professional and academic benchmarks. We sought to evaluate its performance on surgical knowledge questions and assess the stability of this performance on repeat queries. Methods: We evaluated the performance of ChatGPT-4 on questions from the Surgical Council on Resident Education question bank and a second commonly used surgical knowledge assessment, referred to as Data-B. Questions were entered in 2 formats: open-ended and multiple-choice. ChatGPT outputs were assessed for accuracy and insights by surgeon evaluators. We categorized reasons for model errors and the stability of performance on repeat queries. Results: A total of 167 Surgical Council on Resident Education and 112 Data-B questions were presented to the ChatGPT interface. ChatGPT correctly answered 71.3% and 67.9% of multiple choice and 47.9% and 66.1% of open-ended questions for Surgical Council on Resident Education and Data-B, respectively. For both open-ended and multiple-choice questions, approximately two-thirds of ChatGPT responses contained nonobvious insights. Common reasons for incorrect responses included inaccurate information in a complex question (n = 16, 36.4%), inaccurate information in a fact-based question (n = 11, 25.0%), and accurate information with circumstantial discrepancy (n = 6, 13.6%). Upon repeat query, the answer selected by ChatGPT varied for 36.4% of questions answered incorrectly on the first query; the response accuracy changed for 6/16 (37.5%) questions. Conclusion: Consistent with findings in other academic and professional domains, we demonstrate near or above human-level performance of ChatGPT on surgical knowledge questions from 2 widely used question banks. ChatGPT performed better on multiple-choice than open-ended questions, prompting questions regarding its potential for clinical application. Unique to this study, we demonstrate inconsistency in ChatGPT responses on repeat queries. This finding warrants future consideration including efforts at training large language models to provide the safe and consistent responses required for clinical application. Despite near or above human-level performance on question banks and given these observations, it is unclear whether large language models such as ChatGPT are able to safely assist clinicians in providing care. © 2023 Elsevier Inc.
PB  - Elsevier Inc.
SN  - 00396060 (ISSN)
C2  - 38246839
LA  - English
J2  - Surgery
M3  - Article
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 0; Correspondence Address: G.A. Brat; Department of Surgery, Beth Israel Deaconess Medical Center, Department of Biomedical Informatics, Harvard Medical School, Boston, 110 Francis Street, Suite 2G, 02215, United States; email: bbeaulieujones@gmail.com; CODEN: SURGA
ER  -

TY  - JOUR
AU  - Ali, K.
AU  - Barhom, N.
AU  - Tamimi, F.
AU  - Duggal, M.
TI  - ChatGPT—A double-edged sword for healthcare education? Implications for assessments of dental students
PY  - 2024
T2  - European Journal of Dental Education
VL  - 28
IS  - 1
SP  - 206
EP  - 211
DO  - 10.1111/eje.12937
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85167367205&doi=10.1111%2feje.12937&partnerID=40&md5=a4f857ed9f541479790928af2abdf218
AD  - College of Dental Medicine QU Health, Qatar University, Doha, Qatar
AB  - Introduction: Open-source generative artificial intelligence (AI) applications are fast-transforming access to information and allow students to prepare assignments and offer quite accurate responses to a wide range of exam questions which are routinely used in assessments of students across the board including undergraduate dental students. This study aims to evaluate the performance of Chat Generative Pre-trained Transformer (ChatGPT), a generative AI-based application, on a wide range of assessments used in contemporary healthcare education and discusses the implications for undergraduate dental education. Materials and Methods: This was an exploratory study investigating the accuracy of ChatGPT to attempt a range of recognised assessments in healthcare education curricula. A total of 50 independent items encompassing 50 different learning outcomes (n = 10 per item) were developed by the research team. These included 10 separate items based on each of the five commonly used question formats including multiple-choice questions (MCQs); short-answer questions (SAQs); short essay questions (SEQs); single true/false questions; and fill in the blanks items. Chat GPT was used to attempt each of these 50 questions. In addition, ChatGPT was used to generate reflective reports based on multisource feedback; research methodology; and critical appraisal of the literature. Results: ChatGPT application provided accurate responses to majority of knowledge-based assessments based on MCQs, SAQs, SEQs, true/false and fill in the blanks items. However, it was only able to answer text-based questions and did not allow processing of questions based on images. Responses generated to written assignments were also satisfactory apart from those for critical appraisal of literature. Word count was the key limitation observed in outputs generated by the free version of ChatGPT. Conclusion: Notwithstanding their current limitations, generative AI-based applications have the potential to revolutionise virtual learning. Instead of treating it as a threat, healthcare educators need to adapt teaching and assessments in medical and dental education to the benefits of the learners while mitigating against dishonest use of AI-based technology. © 2023 The Authors. European Journal of Dental Education published by John Wiley & Sons Ltd.
KW  - artificial intelligence
KW  - ChatGPT
KW  - dental education
KW  - education technology
KW  - machine learning
KW  - Artificial Intelligence
KW  - Curriculum
KW  - Education, Dental
KW  - Humans
KW  - Learning
KW  - Students, Dental
KW  - article
KW  - artificial intelligence
KW  - clinical article
KW  - dental education
KW  - dental student
KW  - education
KW  - exploratory research
KW  - human
KW  - human experiment
KW  - learning
KW  - machine learning
KW  - multiple choice test
KW  - teaching
KW  - curriculum
KW  - dental education
PB  - John Wiley and Sons Inc
SN  - 13965883 (ISSN)
C2  - 37550893
LA  - English
J2  - Eur. J. Dent. Educ.
M3  - Article
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 2; Correspondence Address: K. Ali; College of Dental Medicine QU Health, Qatar University, Doha, Qatar; email: ali.kamran@qu.edu.qa
ER  -

TY  - JOUR
AU  - Han, Y.
AU  - Choudhry, H.S.
AU  - Simon, M.E.
AU  - Katt, B.M.
TI  - ChatGPT's Performance on the Hand Surgery Self-Assessment Exam: A Critical Analysis
PY  - 2024
T2  - Journal of Hand Surgery Global Online
DO  - 10.1016/j.jhsg.2023.11.014
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85181803149&doi=10.1016%2fj.jhsg.2023.11.014&partnerID=40&md5=001fe8e356f36d22b1b779efefc289e3
AD  - Rutgers Robert Wood Johnson Medical School, New Brunswick, NJ, United States
AD  - Rutgers New Jersey Medical School, Newark, NJ, United States
AB  - Purpose: To assess the performance of Chat Generative Pre-Trained Transformer (ChatGPT) when answering self-assessment exam questions in hand surgery and to compare correct results for text-only questions to those for questions that included images. Methods: This study used 10 self-assessment exams from 2004 to 2013 provided by the American Society for Surgery of the Hand (ASSH). ChatGPT's performance on text-only questions and image-based questions was compared. The primary outcomes were ChatGPT's total score, score on text-only questions, and score on image-based questions. The secondary outcomes were the proportion of questions for which ChatGPT provided additional explanations, the length of those elaborations, and the number of questions for which ChatGPT provided answers with certainty. Results: Out of 1,583 questions, ChatGPT answered 573 (36.2%) correct. ChatGPT performed better on text-only questions than image-based questions. Out of 1,127 text-only questions, ChatGPT answered 442 (39.2%) correctly. Out of the 456 image-based questions, it answered 131 (28.7%) correctly. There was no difference between the proportion of elaborations among text-only and image-based questions. Although there was no difference between the length of elaborations for questions ChatGPT got correct and incorrect, the length of elaborations provided for image-based questions were longer than those provided for text-only questions. Out of 1,441 confident answers, 548 (38.0%) were correct; out of 142 unconfident answers, 25 (17.6%) were correct. Conclusions: ChatGPT performed poorly on the ASSH self-assessment exams from 2004 to 2013. It performed better on text-only questions. Even with its highest score of 42% for the year 2012, the AI platform would not have received continuing medical education credit from ASSH or the American Board of Surgery. Even when only considering questions without images, ChatGPT's high score of 44% correct would not have “passed” the examination. Clinical relevance: At this time, medical professionals, trainees, and patients should use ChatGPT with caution as the program has not yet developed proficiency with hand subspecialty knowledge. © 2023 The Authors
KW  - AI
KW  - Certification
KW  - ChatGPT
KW  - Education
KW  - Self-assessment
PB  - Elsevier Inc.
SN  - 25895141 (ISSN)
LA  - English
J2  - J. Hand Surg. Glob. Online
M3  - Article
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 0; Correspondence Address: B.M. Katt; Department of Orthopaedic Surgery, Rutgers Robert Wood Johnson Medical School, 125 Paterson St., New Brunswick, 08901, United States; email: briankatt@gmail.com
ER  -

TY  - JOUR
AU  - Hwang, G.
AU  - Lee, D.Y.
AU  - Seol, S.
AU  - Jung, J.
AU  - Choi, Y.
AU  - Her, E.S.
AU  - An, M.H.
AU  - Park, R.W.
TI  - Assessing the potential of ChatGPT for psychodynamic formulations in psychiatry: An exploratory study
PY  - 2024
T2  - Psychiatry Research
VL  - 331
C7  - 115655
DO  - 10.1016/j.psychres.2023.115655
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85179120885&doi=10.1016%2fj.psychres.2023.115655&partnerID=40&md5=ffb7ea1db1ee9fe24ec4fccb0660d13d
AD  - Department of Biomedical Informatics, Ajou University School of Medicine, Suwon, South Korea
AD  - Department of Medical Sciences, Graduate School of Ajou University, Suwon, South Korea
AD  - Department of Biomedical Sciences, Ajou University Graduate School of Medicine, Suwon, South Korea
AD  - Department of Child and Adolescent Psychiatry, Seoul Metropolitan Eunpyeong Hospital, Seoul, South Korea
AD  - Armed Forces Yangju Hospital, Yang-ju, South Korea
AD  - Ajou Big Tree Psychiatric Clinic, Suwon, South Korea
AB  - Although there were several attempts to apply ChatGPT (Generative Pre-Trained Transformer) to medicine, little is known about therapeutic applications in psychiatry. In this exploratory study, we aimed to evaluate the characteristics and appropriateness of the psychodynamic formulations created by ChatGPT. Along with a case selected from the psychoanalytic literature, input prompts were designed to include different levels of background knowledge. These included naïve prompts, keywords created by ChatGPT, keywords created by psychiatrists, and psychodynamic concepts from the literature. The psychodynamic formulations generated from the different prompts were evaluated by five psychiatrists from different institutions. We next conducted further tests in which instructions on the use of different psychodynamic models were added to the input prompts. The models used were ego psychology, self-psychology, and object relations. The results from naïve prompts and psychodynamic concepts were rated as appropriate by most raters. The psychodynamic concept prompt output was rated the highest. Interrater agreement was statistically significant. The results from the tests using instructions in different psychoanalytic theories were also rated as appropriate by most raters. They included key elements of the psychodynamic formulation and suggested interpretations similar to the literature. These findings suggest potential of ChatGPT for use in psychiatry. © 2023
KW  - ChatGPT
KW  - Psychiatry
KW  - Psychoanalysis
KW  - Psychodynamic formulations
KW  - Humans
KW  - Psychiatry
KW  - Psychoanalysis
KW  - Article
KW  - ChatGPT
KW  - ego psychology
KW  - exploratory research
KW  - human
KW  - interrater reliability
KW  - object relation
KW  - psychiatry
KW  - psychoanalysis
KW  - psychodynamic formulation
KW  - psychodynamics
KW  - self psychology
KW  - statistical significance
KW  - psychoanalysis
PB  - Elsevier Ireland Ltd
SN  - 01651781 (ISSN)
C2  - 38056130
LA  - English
J2  - Psychiatry Res.
M3  - Article
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 1; Correspondence Address: R.W. Park; Department of Biomedical Informatics, Ajou University School of Medicine, Suwon, South Korea; email: veritas@ajou.ac.kr; CODEN: PSRSD
ER  -

TY  - CONF
AU  - Ronanki, K.
AU  - Cabrero-Daniel, B.
AU  - Berger, C.
TI  - ChatGPT as a Tool for User Story Quality Evaluation: Trustworthy Out of the Box?
PY  - 2024
T2  - Lecture Notes in Business Information Processing
VL  - 489 LNBIP
SP  - 173
EP  - 181
DO  - 10.1007/978-3-031-48550-3_17
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85181984259&doi=10.1007%2f978-3-031-48550-3_17&partnerID=40&md5=625695241fbeaa175d610f19a1d49386
AD  - University of Gothenburg, Gothenburg, Sweden
AB  - In Agile software development, user stories play a vital role in capturing and conveying end-user needs, prioritizing features, and facilitating communication and collaboration within development teams. However, automated methods for evaluating user stories require training in NLP tools and can be time-consuming to develop and integrate. This study explores using ChatGPT for user story quality evaluation and compares its performance with an existing benchmark. Our study shows that ChatGPT’s evaluation aligns well with human evaluation, and we propose a “best of three” strategy to improve its output stability. We also discuss the concept of trustworthiness in AI and its implications for non-experts using ChatGPT’s unprocessed outputs. Our research contributes to understanding the reliability and applicability of Generative AI in user story evaluation and offers recommendations for future research. © 2024, The Author(s).
KW  - Agile
KW  - ChatGPT
KW  - Quality
KW  - User Stories
KW  - Artificial intelligence
KW  - Benchmarking
KW  - Conveying
KW  - Petroleum reservoir evaluation
KW  - Software design
KW  - Agile
KW  - Agile software development
KW  - ChatGPT
KW  - Communication and collaborations
KW  - Development teams
KW  - End-users
KW  - Quality
KW  - Quality evaluation
KW  - User need
KW  - User stories
KW  - Quality control
A2  - Kruchten P.
A2  - Gregory P.
PB  - Springer Science and Business Media Deutschland GmbH
SN  - 18651348 (ISSN); 978-303148549-7 (ISBN)
LA  - English
J2  - Lect. Notes Bus. Inf. Process.
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 0; Correspondence Address: K. Ronanki; University of Gothenburg, Gothenburg, Sweden; email: krishna.ronanki@gu.se; Conference name: workshops presented at 23rd International Conferences on Agile Software Development, XP 2022 and 24th International Conferences on Agile Software Development, XP 2023; Conference date: 13 June 2022 through 16 June 2022; Conference code: 306449
ER  -

TY  - JOUR
AU  - Abeysekera, I.
TI  - ChatGPT and academia on accounting assessments
PY  - 2024
T2  - Journal of Open Innovation: Technology, Market, and Complexity
VL  - 10
IS  - 1
C7  - 100213
DO  - 10.1016/j.joitmc.2024.100213
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85183548550&doi=10.1016%2fj.joitmc.2024.100213&partnerID=40&md5=5a85f7cd8c68fea16ac8c8c0b5d8a7f3
AD  - Charles Darwin University, Darwin, 0800, NT, Australia
AB  - ChatGPT is considered a risk and an opportunity for academia. An area of threat in contemporary settings is whether it can become a student agent for assessments in academia. This study determines how ChatGPT can become a human agent for students on two financial accounting course units, multiple choice question assessments. The study provided five numerical-based and five narrative-based multiple choice questions. There were ten questions for the Introductory Financial Accounting and 10 for the Advanced Financial Accounting course units. ChatGPT received one question at a time requesting a solution. In the Introductory Financial Accounting section, ChatGPT produced incorrect answers because it incorrectly assumed the underlying assumptions contained in those questions. In Advanced Financial Accounting, ChatGPT presented incorrect answers because of the complexity of the task contained in those questions. ChatGPT demonstrated similar competencies in providing solutions to numerical-based and narrative-based questions. ChatGPT obtained the correct answers to sit in the 80th percentile in the Introductory Financial Accounting course unit assessment and the 50th percentile in the Advanced Financial course unit assessment. ChatGPT4 showed improved performance, with the 90th percentile for Introductory Financial Accounting and the 70th percentile for Advanced Financial Accounting. The findings indicate that the knowledge construct requires reflective thinking with ChatGPT in the ecosystem, and what is assumed and assessable knowledge must be revisited. © 2024 The Authors
KW  - Academia
KW  - Accounting
KW  - Assessments
KW  - ChatGPT
KW  - Multiple Choice Questions
KW  - Sustainable Development Goals of the United Nations
PB  - Elsevier B.V.
SN  - 21998531 (ISSN)
LA  - English
J2  - J. Open Innov.: Technol. Mark. Complex.
M3  - Article
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 0; Correspondence Address: I. Abeysekera; Discipline of Accounting and Finance, Charles Darwin University, Darwin, 0800, Australia; email: indraabeysekera@gmail.com
ER  -

TY  - JOUR
AU  - Lilli, S.
TI  - ChatGPT-4 and Italian Dialects: Assessing Linguistic Competence
ST  - ChatGPT-4 e i dialetti italiani. Una valutazione della competenza linguistica
PY  - 2023
T2  - Umanistica Digitale
VL  - 2023
IS  - 16
SP  - 235
EP  - 263
DO  - 10.6092/issn.2532-8816/18221
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85179662232&doi=10.6092%2fissn.2532-8816%2f18221&partnerID=40&md5=b91c34a9a42461369caf64443b44f0bc
AD  - Department of Literary Studies, Philosophical Studies and History of Art, University of Rome “Tor Vergata”, Rome, Italy
AB  - The purpose of this study is to evaluate ChatGPT-4’s language proficiency in Italian dialects. At the outset, it is clarified what is meant by ‘language ability’ within the context of Large Language Models. This involves identifying the tasks that ChatGPT might face in real-world scenarios, from which we can derive inferential assumptions regarding its linguistic ability. The skills identified, which served as foundation for test design, include comprehension and translation, dialect recognition, analysis of the distinctive features, error detection, text production, interaction, theoretical background, and self-assessment. The tests were crafted to mimic situations requiring these competencies, trying to emulate authentic ChatGPT-User interactions. The results highlight ChatGPT’s excellent prowess in understanding and recognizing Italian dialects and their subvarieties, and a robust background and awareness of its own knowledge. However, the model exhibits significant gaps in analytical skills and struggles with text production and interactive tasks, suggesting superior passive linguistic capabilities compared to active ones. © 2023, University of Bologna Department of Classical and Italian Philology, Alma Mater Studiorum. All rights reserved.
KW  - ChatGPT
KW  - Italian Dialects
KW  - Language Abilities
KW  - Language Testing
KW  - LLMs
KW  - Machine Translation
PB  - University of Bologna Department of Classical and Italian Philology, Alma Mater Studiorum
SN  - 25328816 (ISSN)
LA  - English
J2  - Umanistica. Digit.
M3  - Article
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 0; Correspondence Address: S. Lilli; Department of Literary Studies, Philosophical Studies and History of Art, University of Rome “Tor Vergata”, Rome, Italy; email: silvialilli@hotmail.it
ER  -

TY  - JOUR
AU  - Daungsupawong, H.
AU  - Wiwanitkit, V.
TI  - Letter 1 regarding “Assessing the performance of ChatGPT in answering questions regarding cirrhosis and hepatocellular carcinoma”
PY  - 2024
T2  - Clinical and Molecular Hepatology
VL  - 30
IS  - 1
SP  - 111
EP  - 112
DO  - 10.3350/cmh.2023.0394
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85181656604&doi=10.3350%2fcmh.2023.0394&partnerID=40&md5=849e6fa9daff9c5fe78fd78dcb463a96
AD  - Private Academic Consultant, Phonhong, Laos
AD  - Research Center, Chandigarh University, Mohali, India
AD  - Department of Biological Science, Joseph Ayobabalola University, Ikeji-Arakeji, Nigeria
KW  - AI
KW  - ChatGPT
KW  - Cirrhosis
KW  - Hetocellular carcinoma
KW  - Liver
KW  - algorithm
KW  - ChatGPT
KW  - decision making
KW  - emotional support
KW  - human
KW  - knowledge
KW  - Letter
KW  - liver cell carcinoma
KW  - liver cirrhosis
KW  - patient care
KW  - practice guideline
KW  - preventive medicine
KW  - questionnaire
KW  - training
PB  - Korean Association for the Study of the Liver
SN  - 22872728 (ISSN)
C2  - 37828840
LA  - English
J2  - Clin. Mol. Hepatol.
M3  - Letter
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 0; Correspondence Address: H. Daungsupawong; Private Academic Consultant, Phonhong, 10000, Laos; email: hinpetchdaung@gmail.com; V. Wiwanitkit; Research Center, Chandigarh University, Mohali, Punjab, 140413, India; email: wviroj@yahoo.com
ER  -

TY  - JOUR
AU  - Paslı, S.
AU  - Şahin, A.S.
AU  - Beşer, M.F.
AU  - Topçuoğlu, H.
AU  - Yadigaroğlu, M.
AU  - İmamoğlu, M.
TI  - Assessing the precision of artificial intelligence in emergency department triage decisions: Insights from a study with ChatGPT
PY  - 2024
T2  - American Journal of Emergency Medicine
VL  - 78
SP  - 170
EP  - 175
DO  - 10.1016/j.ajem.2024.01.037
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85183497851&doi=10.1016%2fj.ajem.2024.01.037&partnerID=40&md5=3c11ac7de94eed05194dfd3a91fbb070
AD  - Karadeniz Technical University, Faculty of Medicine, Department of Emergency Medicine, Trabzon, Turkey
AD  - Çarşamba State Hospital, Emergency Department, Samsun, Turkey
AD  - Business & Decision Life Sciences, Brussels, Belgium
AD  - Siirt Education & Research Hospital, Department of Emergency Medicine, Siirt, Turkey
AD  - Samsun University, Faculty of Medicine, Department of Emergency Medicine, Samsun, Turkey
AB  - Background: The rise in emergency department presentations globally poses challenges for efficient patient management. To address this, various strategies aim to expedite patient management. Artificial intelligence's (AI) consistent performance and rapid data interpretation extend its healthcare applications, especially in emergencies. The introduction of a robust AI tool like ChatGPT, based on GPT-4 developed by OpenAI, can benefit patients and healthcare professionals by improving the speed and accuracy of resource allocation. This study examines ChatGPT's capability to predict triage outcomes based on local emergency department rules. Methods: This study is a single-center prospective observational study. The study population consists of all patients who presented to the emergency department with any symptoms and agreed to participate. The study was conducted on three non-consecutive days for a total of 72 h. Patients' chief complaints, vital parameters, medical history and the area to which they were directed by the triage team in the emergency department were recorded. Concurrently, an emergency medicine physician inputted the same data into previously trained GPT-4, according to local rules. According to this data, the triage decisions made by GPT-4 were recorded. In the same process, an emergency medicine specialist determined where the patient should be directed based on the data collected, and this decision was considered the gold standard. Accuracy rates and reliability for directing patients to specific areas by the triage team and GPT-4 were evaluated using Cohen's kappa test. Furthermore, the accuracy of the patient triage process performed by the triage team and GPT-4 was assessed by receiver operating characteristic (ROC) analysis. Statistical analysis considered a value of p < 0.05 as significant. Results: The study was carried out on 758 patients. Among the participants, 416 (54.9%) were male and 342 (45.1%) were female. Evaluating the primary endpoints of our study - the agreement between the decisions of the triage team, GPT-4 decisions in emergency department triage, and the gold standard - we observed almost perfect agreement both between the triage team and the gold standard and between GPT-4 and the gold standard (Cohen's Kappa 0.893 and 0.899, respectively; p < 0.001 for each). Conclusion: Our findings suggest GPT-4 possess outstanding predictive skills in triaging patients in an emergency setting. GPT-4 can serve as an effective tool to support the triage process. © 2024 Elsevier Inc.
KW  - Artificial intelligence
KW  - Chatbot
KW  - ChatGPT
KW  - Emergency department
KW  - Triage
PB  - W.B. Saunders
SN  - 07356757 (ISSN)
LA  - English
J2  - Am. J. Emerg. Med.
M3  - Article
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 0; Correspondence Address: S. Paslı; Karadeniz Technical University, Department of Emergency Medicine, Trabzon, 61080, Turkey; email: drsinanpasli@gmail.com; CODEN: AJEME
ER  -

TY  - JOUR
AU  - Patnaik, S.S.
AU  - Hoffmann, U.
TI  - Quantitative evaluation of ChatGPT versus Bard responses to anaesthesia-related queries
PY  - 2024
T2  - British Journal of Anaesthesia
VL  - 132
IS  - 1
SP  - 169
EP  - 171
DO  - 10.1016/j.bja.2023.09.030
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85178182857&doi=10.1016%2fj.bja.2023.09.030&partnerID=40&md5=052affa9d1126f5076c70cf4acb417bb
AD  - Department of Anesthesiology and Pain Management, The University of Texas Southwestern Medical Center, Dallas, TX, United States
KW  - analytics
KW  - artificial intelligence
KW  - Bard
KW  - ChatGPT
KW  - communication
KW  - perioperative
KW  - preoperative evaluation
KW  - Anesthesia
KW  - Anesthesiology
KW  - Humans
KW  - anesthesia
KW  - artificial intelligence
KW  - ChatGPT
KW  - human
KW  - large language model
KW  - Letter
KW  - quantitative study
KW  - anesthesiology
PB  - Elsevier Ltd
SN  - 00070912 (ISSN)
C2  - 37945414
LA  - English
J2  - Br. J. Anaesth.
M3  - Letter
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 0; Correspondence Address: S.S. Patnaik; Department of Anesthesiology and Pain Management, The University of Texas Southwestern Medical Center, Dallas, United States; email: sourav.patnaik@utsouthwestern.edu; CODEN: BJANA
ER  -

TY  - JOUR
AU  - Jain, N.
AU  - Gottlich, C.
AU  - Fisher, J.
AU  - Campano, D.
AU  - Winston, T.
TI  - Assessing ChatGPT’s orthopedic in-service training exam performance and applicability in the field
PY  - 2024
T2  - Journal of Orthopaedic Surgery and Research
VL  - 19
IS  - 1
C7  - 27
DO  - 10.1186/s13018-023-04467-0
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85181259093&doi=10.1186%2fs13018-023-04467-0&partnerID=40&md5=f882bd8e2b4442a1466481aa684d4ea7
AD  - Department of Orthopedic Surgery, Texas Tech University Health Sciences Center Lubbock, 3601 4th St, Lubbock, 79430, TX, United States
AB  - Background: ChatGPT has gained widespread attention for its ability to understand and provide human-like responses to inputs. However, few works have focused on its use in Orthopedics. This study assessed ChatGPT’s performance on the Orthopedic In-Service Training Exam (OITE) and evaluated its decision-making process to determine whether adoption as a resource in the field is practical. Methods: ChatGPT’s performance on three OITE exams was evaluated through inputting multiple choice questions. Questions were classified by their orthopedic subject area. Yearly, OITE technical reports were used to gauge scores against resident physicians. ChatGPT’s rationales were compared with testmaker explanations using six different groups denoting answer accuracy and logic consistency. Variables were analyzed using contingency table construction and Chi-squared analyses. Results: Of 635 questions, 360 were useable as inputs (56.7%). ChatGPT-3.5 scored 55.8%, 47.7%, and 54% for the years 2020, 2021, and 2022, respectively. Of 190 correct outputs, 179 provided a consistent logic (94.2%). Of 170 incorrect outputs, 133 provided an inconsistent logic (78.2%). Significant associations were found between test topic and correct answer (p = 0.011), and type of logic used and tested topic (p = < 0.001). Basic Science and Sports had adjusted residuals greater than 1.96. Basic Science and correct, no logic; Basic Science and incorrect, inconsistent logic; Sports and correct, no logic; and Sports and incorrect, inconsistent logic; had adjusted residuals greater than 1.96. Conclusions: Based on annual OITE technical reports for resident physicians, ChatGPT-3.5 performed around the PGY-1 level. When answering correctly, it displayed congruent reasoning with testmakers. When answering incorrectly, it exhibited some understanding of the correct answer. It outperformed in Basic Science and Sports, likely due to its ability to output rote facts. These findings suggest that it lacks the fundamental capabilities to be a comprehensive tool in Orthopedic Surgery in its current form. Level of Evidence: II. © 2023, The Author(s).
KW  - ChatGPT
KW  - General Orthopedics
KW  - Machine Learning
KW  - OITE
KW  - Resident Education
KW  - Humans
KW  - Orthopedic Procedures
KW  - Orthopedics
KW  - Sports
KW  - human
KW  - orthopedic surgery
KW  - orthopedics
KW  - sport
PB  - BioMed Central Ltd
SN  - 1749799X (ISSN)
C2  - 38167093
LA  - English
J2  - J. Orthop. Surg. Res.
M3  - Article
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 0; Correspondence Address: N. Jain; Department of Orthopedic Surgery, Texas Tech University Health Sciences Center Lubbock, Lubbock, 3601 4th St, 79430, United States; email: Neil.Jain@ttuhsc.edu
ER  -

TY  - JOUR
AU  - Li, X.
AU  - Henriksson, A.
AU  - Duneld, M.
AU  - Nouri, J.
AU  - Wu, Y.
TI  - Evaluating Embeddings from Pre-Trained Language Models and Knowledge Graphs for Educational Content Recommendation
PY  - 2024
T2  - Future Internet
VL  - 16
IS  - 1
C7  - 12
DO  - 10.3390/fi16010012
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85183383290&doi=10.3390%2ffi16010012&partnerID=40&md5=231bde85581487531725e5cab3b471df
AD  - Department of Computer and Systems Sciences, Stockholm University, NOD-Huset, Borgarfjordsgatan 12, Stockholm, 16455, Sweden
AB  - Educational content recommendation is a cornerstone of AI-enhanced learning. In particular, to facilitate navigating the diverse learning resources available on learning platforms, methods are needed for automatically linking learning materials, e.g., in order to recommend textbook content based on exercises. Such methods are typically based on semantic textual similarity (STS) and the use of embeddings for text representation. However, it remains unclear what types of embeddings should be used for this task. In this study, we carry out an extensive empirical evaluation of embeddings derived from three different types of models: (i) static embeddings trained using a concept-based knowledge graph, (ii) contextual embeddings from a pre-trained language model, and (iii) contextual embeddings from a large language model (LLM). In addition to evaluating the models individually, various ensembles are explored based on different strategies for combining two models in an early vs. late fusion fashion. The evaluation is carried out using digital textbooks in Swedish for three different subjects and two types of exercises. The results show that using contextual embeddings from an LLM leads to superior performance compared to the other models, and that there is no significant improvement when combining these with static embeddings trained using a knowledge graph. When using embeddings derived from a smaller language model, however, it helps to combine them with knowledge graph embeddings. The performance of the best-performing model is high for both types of exercises, resulting in a mean Recall@3 of 0.96 and 0.95 and a mean MRR of 0.87 and 0.86 for quizzes and study questions, respectively, demonstrating the feasibility of using STS based on text embeddings for educational content recommendation. The ability to link digital learning materials in an unsupervised manner—relying only on readily available pre-trained models—facilitates the development of AI-enhanced learning. © 2023 by the authors.
KW  - AI-enhanced learning
KW  - educational content recommendation
KW  - ensemble embeddings
KW  - knowledge graph embeddings
KW  - natural language processing
KW  - pre-trained language models
KW  - text similarity
KW  - textual semantic search
KW  - Computational linguistics
KW  - Graph embeddings
KW  - Natural language processing systems
KW  - Semantics
KW  - Textbooks
KW  - AI-enhanced learning
KW  - Content recommendations
KW  - Educational content recommendation
KW  - Educational contents
KW  - Embeddings
KW  - Enhanced learning
KW  - Ensemble embedding
KW  - Graph embeddings
KW  - Knowledge graph embedding
KW  - Knowledge graphs
KW  - Language model
KW  - Language processing
KW  - Natural language processing
KW  - Natural languages
KW  - Pre-trained language model
KW  - Semantic search
KW  - Text similarity
KW  - Textual semantic search
KW  - Knowledge graph
PB  - Multidisciplinary Digital Publishing Institute (MDPI)
SN  - 19995903 (ISSN)
LA  - English
J2  - Future Internet
M3  - Article
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 0; Correspondence Address: A. Henriksson; Department of Computer and Systems Sciences, Stockholm University, Stockholm, NOD-Huset, Borgarfjordsgatan 12, 16455, Sweden; email: aronhen@dsv.su.se
ER  -

TY  - JOUR
AU  - Wang, G.
AU  - Zhuo, N.
AU  - Liu, Z.
TI  - Doctor versus artificial intelligence: patient and physician evaluation of large language model responses to rheumatology patient questions: comment on the article by Ye et al
PY  - 2024
T2  - Arthritis and Rheumatology
DO  - 10.1002/art.42799
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85183393004&doi=10.1002%2fart.42799&partnerID=40&md5=c6d73ba8a41da50c1e87eb82046cb726
AD  - The Second Affiliated Hospital of Soochow University, Suzhou, China
AD  - The Affiliated Suzhou Hospital of Nanjing Medical University, Suzhou Municipal Hospital, Suzhou, China
PB  - John Wiley and Sons Inc
SN  - 23265191 (ISSN)
LA  - English
J2  - Arthritis Rheum.
M3  - Letter
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 0; Correspondence Address: Z. Liu; The Second Affiliated Hospital of Soochow University, Suzhou, China; email: zcliurheu@suda.edu.cn
ER  -

TY  - JOUR
AU  - Al Qurashi, A.A.
AU  - Albalawi, I.A.S.
AU  - Halawani, I.R.
AU  - Asaad, A.H.
AU  - Al Dwehji, A.M.O.
AU  - Almusa, H.A.
AU  - Alharbi, R.I.
AU  - Alobaidi, H.A.
AU  - Alarki, S.M.K.Z.
AU  - Aljindan, F.K.
TI  - Can a Machine Ace the Test? Assessing GPT-4.0's Precision in Plastic Surgery Board Examinations
PY  - 2023
T2  - Plastic and Reconstructive Surgery - Global Open
VL  - 11
IS  - 12
SP  - E5448
DO  - 10.1097/GOX.0000000000005448
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85180591490&doi=10.1097%2fGOX.0000000000005448&partnerID=40&md5=beb8fe43daa74201e3e682818d578925
AD  - College of Medicine, King Saud Bin Abdulaziz University for Health Sciences, The National Guards, Jeddah, Saudi Arabia
AD  - King Abdullah International Medical Research Center, Jeddah, Saudi Arabia
AD  - Division of Plastic Surgery, Department of Surgery, McGill University, Montreal, Canada
AD  - Faculty of Medicine, Tabuk University, Tabuk, Saudi Arabia
AD  - Faculty of Medicine, King Abdulaziz University, Jeddah, Saudi Arabia
AD  - Alfaisal University, College of Medicine, Riyadh, Saudi Arabia
AD  - College of Medicine, Batterjee Medical College, Jeddah, Saudi Arabia
AD  - College of Medicine, King Saud University, Riyadh, Saudi Arabia
AD  - Department of Plastic Surgery, King Abdullah Medical City, Makkah, Saudi Arabia
AB  - Background: As artificial intelligence makes rapid inroads across various fields, its value in medical education is becoming increasingly evident. This study evaluates the performance of the GPT-4.0 large language model in responding to plastic surgery board examination questions and explores its potential as a learning tool. Methods: We used a selection of 50 questions from 19 different chapters of a widely-used plastic surgery reference. Responses generated by the GPT-4.0 model were assessed based on four parameters: accuracy, clarity, completeness, and conciseness. Correlation analyses were conducted to ascertain the relationship between these parameters and the overall performance of the model. Results: GPT-4.0 showed a strong performance with high mean scores for accuracy (2.88), clarity (3.00), completeness (2.88), and conciseness (2.92) on a three-point scale. Completeness of the model's responses was significantly correlated with accuracy (P < 0.0001), whereas no significant correlation was found between accuracy and clarity or conciseness. Performance variability across different chapters indicates potential limitations of the model in dealing with certain complex topics in plastic surgery. Conclusions: The GPT-4.0 model exhibits considerable potential as an auxiliary tool for preparation for plastic surgery board examinations. Despite a few identified limitations, the generally high scores on key parameters suggest the model's ability to provide responses that are accurate, clear, complete, and concise. Future research should focus on enhancing the performance of artificial intelligence models in complex medical topics, further improving their applicability in medical education. © 2023 Lippincott Williams and Wilkins. All rights reserved.
PB  - Lippincott Williams and Wilkins
SN  - 21697574 (ISSN)
LA  - English
J2  - Plast. Reconstr. Surg., Glob. Open
M3  - Article
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 0; Correspondence Address: I.A.S. Albalawi; College of Medicine, Tabuk University, Tabuk, Saudi Arabia; email: ebrahimzzz43@gmail.com
ER  -

TY  - JOUR
AU  - Akrout, M.
AU  - Cirone, K.D.
AU  - Vender, R.
TI  - Evaluation of Vision LLMs GTP-4V and LLaVA for the Recognition of Features Characteristic of Melanoma
PY  - 2024
T2  - Journal of Cutaneous Medicine and Surgery
DO  - 10.1177/12034754231220934
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85181518344&doi=10.1177%2f12034754231220934&partnerID=40&md5=9c702915743e9177053508c866efe4fb
AD  - Department of Computer Science, University of Toronto, Toronto, ON, Canada
AD  - AIP Labs, Budapest, Hungary
AD  - Schulich School of Medicine and Dentistry, Western University, London, ON, Canada
AD  - Department of Medicine, McMaster University, Hamilton, ON, Canada
AD  - Dermatrials Research Inc, Hamilton, ON, Canada
KW  - ABCDE guidelines for melanoma
KW  - artificial intelligence
KW  - melanoma features
KW  - multimodal large language models
PB  - SAGE Publications Inc.
SN  - 12034754 (ISSN)
LA  - English
J2  - J. Cutaneous Med. Surg.
M3  - Letter
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 0; Correspondence Address: R. Vender; Department of Medicine, McMaster University, Hamilton, Canada; email: ron.vender@me.com; CODEN: JCMSF
ER  -

TY  - JOUR
AU  - Curry, N.
AU  - Baker, P.
AU  - Brookes, G.
TI  - Generative AI for corpus approaches to discourse studies: A critical evaluation of ChatGPT
PY  - 2024
T2  - Applied Corpus Linguistics
VL  - 4
IS  - 1
C7  - 100082
DO  - 10.1016/j.acorp.2023.100082
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85181239389&doi=10.1016%2fj.acorp.2023.100082&partnerID=40&md5=d15badd9a27209037af84dc545945e73
AD  - Manchester Metropolitan University, United Kingdom
AD  - Lancaster University, United Kingdom
AB  - This paper explores the potential of generative artificial intelligence technology, specifically ChatGPT, for advancing corpus approaches to discourse studies. The contribution of artificial intelligence technologies to linguistics research has been transformational, both in the contexts of corpus linguistics and discourse analysis. However, shortcomings in the efficacy of such technologies for conducting automated qualitative analysis have limited their utility for corpus approaches to discourse studies. Acknowledging that new technologies in data analysis can replace and supplement existing approaches, and in view of the potential affordances of ChatGPT for automated qualitative analysis, this paper presents three replication case studies designed to investigate the applicability of ChatGPT for supporting automated qualitative analysis within studies using corpus approaches to discourse analysis. The findings indicate that, generally, ChatGPT performs reasonably well when semantically categorising keywords; however, as the categorisation is based on decontextualised keywords, the categories can appear quite generic, limiting the value of such an approach for analysing corpora representing specialised genres and/or contexts. For concordance analysis, ChatGPT performs poorly, as the results include false inferences about the concordance lines and, at times, modifications of the input data. Finally, for function-to-form analysis, ChatGPT also performs poorly, as it fails to identify and analyse direct and indirect questions. Overall, the results raise questions about the affordances of ChatGPT for supporting automated qualitative analysis within corpus approaches to discourse studies, signalling issues of repeatability and replicability, ethical challenges surrounding data integrity, and the challenges associated with using non-deterministic technology for empirical linguistic research. © 2023 The Author(s)
KW  - ChatGPT
KW  - Corpus linguistics
KW  - Discourse analysis
KW  - Generative AI
KW  - Qualitative analysis
PB  - Elsevier Inc.
SN  - 26667991 (ISSN)
LA  - English
J2  - Appl. Corpus Linguist.
M3  - Article
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 0; Correspondence Address: G. Brookes; Lancaster University, United Kingdom; email: g.brookes@lancaster.ac.uk
ER  -

TY  - JOUR
AU  - Zhao, P.
AU  - Song, Y.
AU  - Wang, S.
AU  - Xue, J.-H.
AU  - Zhao, S.
AU  - Liao, Q.
AU  - Yang, W.
TI  - VPCFormer: A transformer-based multi-view finger vein recognition model and a new benchmark
PY  - 2024
T2  - Pattern Recognition
VL  - 148
C7  - 110170
DO  - 10.1016/j.patcog.2023.110170
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85179008367&doi=10.1016%2fj.patcog.2023.110170&partnerID=40&md5=2f90999017f9fb1df0d2c0d300534acd
AD  - Department of Electronic Engineering, Tsinghua University, China
AD  - Shenzhen International Graduate School, Tsinghua University, China
AD  - Department of Statistical Science, University College London, United Kingdom
AD  - School of Computer Science, Guangdong University of Technology, China
AB  - In the past decade, finger vein authentication garners significant interest. However, most existing databases and algorithms predominantly focused on single-view finger vein recognition. The current projection of vein patterns actually maps a 3D network topology into a 2D plane, which inevitably leads to 3D feature loss and topological ambiguity in 2D images. Additionally, single-view based methods are sensitive to finger rotation and translation in practical applications. So far, there are currently few dedicated studies and public databases on multi-view finger vein recognition. To address these issues, we first establish a benchmark for future research by constructing the multi-view finger vein database, named Tsinghua Multi-View Finger Vein-3 Views (THUMVFV-3V) Database, which is collected over two sessions. THUMVFV-3V provides three types of Regions of Interest (ROIs) and includes unified preprocessing operations, catering to the majority of existing methods. Furthermore, we propose a novel Transformer-based model named Vein Pattern Constrained Transformer (VPCFormer) for multi-view finger vein recognition, primarily composed of multiple Vein Pattern Constrained Encoders (VPC-Encoders) and Neighborhood-Perspective Modules (NPMs). Specifically, the VPC-Encoder incorporates a novel Vein Pattern Attention Module (VPAM) and an Integrative Feed-Forward Network (IFFN). Motivated by the fact that the strong correlations veins exhibit across different views, we devise the VPAM. Assisted by a vein mask, VPAM is meticulously designed to exclusively extract intra- and inter-view dependencies between vein patterns. Further, we propose IFFN to efficiently aggregate the preceding attention and contextual information of VPAM. In addition, the NPM is utilized to capture the correlations within a single view, enhancing the final multi-view finger vein representation. Extensive experiments demonstrate the superiority of our VPCFormer. The THUMVFV-3V database is available at https://github.com/Pengyang233/THUMVFV-3V-Database. © 2023
KW  - Attention mechanism
KW  - Database
KW  - Multi-view finger vein recognition
KW  - Transformer
KW  - Palmprint recognition
KW  - Signal encoding
KW  - Topology
KW  - Attention mechanisms
KW  - Feed-forward network
KW  - Finger vein
KW  - Finger-vein recognition
KW  - Multi-view finger vein recognition
KW  - Multi-views
KW  - Neighbourhood
KW  - Recognition models
KW  - Transformer
KW  - Vein pattern
KW  - Database systems
PB  - Elsevier Ltd
SN  - 00313203 (ISSN)
LA  - English
J2  - Pattern Recogn.
M3  - Article
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 0; Correspondence Address: W. Yang; Shenzhen International Graduate School, Tsinghua University, China; email: yangelwm@163.com; CODEN: PTNRA
ER  -

TY  - JOUR
AU  - Nanji, K.
AU  - Yu, C.W.
AU  - Wong, T.Y.
AU  - Sivaprasad, S.
AU  - Steel, D.H.
AU  - Wykoff, C.C.
AU  - Chaudhary, V.
TI  - Evaluation of postoperative ophthalmology patient instructions from ChatGPT and Google Search
PY  - 2024
T2  - Canadian Journal of Ophthalmology
VL  - 59
IS  - 1
SP  - e69
EP  - e71
DO  - 10.1016/j.jcjo.2023.10.001
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85177643420&doi=10.1016%2fj.jcjo.2023.10.001&partnerID=40&md5=ec26d142793a2cfbef16339c49527123
AD  - Department of Surgery, Division of Ophthalmology, McMaster University, Hamilton, ON, Canada
AD  - Department of Health Research Methods, Evidence and Impact, McMaster University, Hamilton, ON, Canada
AD  - Singapore Eye Research Institute, Singapore National Eye Centre, Singapore, Singapore
AD  - Tsinghua Medicine, Tsinghua University, Beijing, China
AD  - Moorfields Eye Hospital, NIHR Moorfields Biomedical Research Centre, London, United Kingdom
AD  - Bioscience Institute, Newcastle University, Newcastle Upon Tyne, United Kingdom
AD  - Sunderland Eye Infirmary, Sunderland, United Kingdom
AD  - Retina Consultants of Texas and Blanton Eye Institute, Houston Methodist Hospital, Houston, TX, United States
PB  - Elsevier B.V.
SN  - 00084182 (ISSN)
C2  - 37884271
LA  - English
J2  - Can. J. Ophthalmol.
M3  - Letter
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 0; Correspondence Address: K. Nanji; Hamilton Regional Eye Institute, St. Joseph's Healthcare Hamilton King Campus, Hamilton, 2757 King Street East, L8G 5E4, Canada; email: Keean.Nanji@medportal.ca; CODEN: CAJOB
ER  -

TY  - JOUR
AU  - Fikri, E.
TI  - The Utility of ChatGPT in Diabetic Retinopathy Risk Assessment: A Comparative Study with Clinical Diagnosis [Letter]
PY  - 2024
T2  - Clinical Ophthalmology
VL  - 18
SP  - 127
EP  - 128
DO  - 10.2147/OPTH.S457160
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85183021075&doi=10.2147%2fOPTH.S457160&partnerID=40&md5=fe03ca82f3c0591a4b6ac7440f81df69
AD  - Department of Environmental Health, Poltekkes Kemenkes Bandung, Bandung, Indonesia
AD  - Center of Excellence on Utilization of Local Material for Health Improvement, Bandung Health Polytechnic, Bandung, Indonesia
KW  - algorithm
KW  - biochemical analysis
KW  - ChatGPT
KW  - clinical feature
KW  - clinical practice
KW  - comparative study
KW  - controlled study
KW  - data protection
KW  - diabetic patient
KW  - diabetic retinopathy
KW  - diagnostic accuracy
KW  - diagnostic test accuracy study
KW  - health care personnel
KW  - human
KW  - information security
KW  - Letter
KW  - ophthalmology
KW  - prediction
KW  - privacy
KW  - reliability
KW  - risk assessment
KW  - sample size
KW  - sensitivity and specificity
PB  - Dove Medical Press Ltd
SN  - 11775467 (ISSN)
LA  - English
J2  - Clin. Ophthalmol.
M3  - Letter
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 0; Correspondence Address: E. Fikri; Department of Environmental Health, Poltekkes Kemenkes Bandung, Bandung, Jl.Pajajaran 56,, Jawa Barat, Indonesia; email: elandafikri@yahoo.com
ER  -

TY  - CONF
AU  - Mudgal, P.
AU  - Wouhaybi, R.
TI  - An Assessment of ChatGPT on Log Data
PY  - 2024
T2  - Communications in Computer and Information Science
VL  - 1946 CCIS
SP  - 148
EP  - 169
DO  - 10.1007/978-981-99-7587-7_13
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85177179104&doi=10.1007%2f978-981-99-7587-7_13&partnerID=40&md5=ade3ee38971532955a7bbe8728041efb
AD  - Intel Corporation, Hillsboro, 97124, OR, United States
AB  - Recent development of large language models (LLMs), such as ChatGPT has been widely applied to a wide range of software engineering tasks. Many papers have reported their analysis on the potential advantages and limitations of ChatGPT for writing code, summarization, text generation, etc. However, the analysis of the current state of ChatGPT for log processing has received little attention. Logs generated by large-scale software systems are complex and hard to understand. Despite their complexity, they provide crucial information for subject matter experts to understand the system status and diagnose problems of the systems. In this paper, we investigate the current capabilities of ChatGPT to perform several interesting tasks on log data, while also trying to identify its main shortcomings. Our findings show that the performance of the current version of ChatGPT for log processing is limited, with a lack of consistency in responses and scalability issues. We also outline our views on how we perceive the role of LLMs in the log processing discipline and possible next steps to improve the current capabilities of ChatGPT and the future LLMs in this area. We believe our work can contribute to future academic research to address the identified issues. © 2024, The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd.
KW  - ChatGPT
KW  - deep learning
KW  - large language model
KW  - log analysis
KW  - log analysis using LLM
KW  - log data
KW  - log processing
KW  - machine learning
KW  - Computational linguistics
KW  - Data handling
KW  - Software engineering
KW  - Well logging
KW  - ChatGPT
KW  - Deep learning
KW  - Language model
KW  - Large language model
KW  - Log analyse using large language model
KW  - Log analysis
KW  - Log data
KW  - Log processing
KW  - Machine-learning
KW  - Deep learning
A2  - Zhao F.
A2  - Miao D.
PB  - Springer Science and Business Media Deutschland GmbH
SN  - 18650929 (ISSN); 978-981997586-0 (ISBN)
LA  - English
J2  - Commun. Comput. Info. Sci.
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 0; Correspondence Address: P. Mudgal; Intel Corporation, Hillsboro, 97124, United States; email: priyanka.mudgal@intel.com; Conference name: 1st International Conference on AI-generated Content, AIGC 2023; Conference date: 25 August 2023 through 26 August 2023; Conference code: 303829
ER  -

TY  - JOUR
AU  - Tariq, R.
AU  - Malik, S.
AU  - Khanna, S.
TI  - Evolving Landscape of Large Language Models: An Evaluation of ChatGPT and Bard in Answering Patient Queries on Colonoscopy
PY  - 2024
T2  - Gastroenterology
VL  - 166
IS  - 1
SP  - 220
EP  - 221
DO  - 10.1053/j.gastro.2023.08.033
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85179490182&doi=10.1053%2fj.gastro.2023.08.033&partnerID=40&md5=84df8a61eb11ad941d5247fa33724847
AD  - Division of Gastroenterology and Hepatology, Mayo Clinic, Rochester, Minnesota, United States
AD  - Department of Internal Medicine, Rochester General Hospital, Rochester, New York, United States
KW  - Colonoscopy
KW  - Humans
KW  - artificial intelligence
KW  - ChatGPT
KW  - colonoscopy
KW  - gastroenterologist
KW  - human
KW  - knowledge
KW  - large language model
KW  - Letter
PB  - W.B. Saunders
SN  - 00165085 (ISSN)
C2  - 37634736
LA  - English
J2  - Gastroenterology
M3  - Letter
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 1; CODEN: GASTA
ER  -

TY  - JOUR
AU  - Soto-Chávez, M.J.
AU  - Bustos, M.M.
AU  - Fernández-Ávila, D.G.
AU  - Muñoz, O.M.
TI  - Evaluation of information provided to patients by ChatGPT about chronic diseases in Spanish language
PY  - 2024
T2  - Digital Health
VL  - 10
DO  - 10.1177/20552076231224603
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85181654211&doi=10.1177%2f20552076231224603&partnerID=40&md5=9a40870d9aca039cc7b16e9e615b9630
AD  - Department of Internal Medicine, Pontificia Universidad Javeriana, Bogotá, Colombia
AD  - Department of Internal Medicine, Hospital Universitario San Ignacio, Bogotá, Colombia
AD  - Rheumatology Unit, Hospital Universitario San Ignacio, Bogotá, Colombia
AB  - Introduction: Artificial intelligence has presented exponential growth in medicine. The ChatGPT language model has been highlighted as a possible source of patient information. This study evaluates the reliability and readability of ChatGPT-generated patient information on chronic diseases in Spanish. Methods: Questions frequently asked by patients on the internet about diabetes mellitus, heart failure, rheumatoid arthritis (RA), chronic kidney disease (CKD), and systemic lupus erythematosus (SLE) were submitted to ChatGPT. Reliability was assessed by rating responses as (1) comprehensive, (2) correct but inadequate, (3) some correct and some incorrect, (4) completely incorrect, and divided between “good” (1 and 2) and “bad” (3 and 4). Readability was evaluated with the adapted Flesch and Szigriszt formulas. Results: And 71.67% of the answers were “good,” with none qualified as “completely incorrect.” Better reliability was observed in questions on diabetes and RA versus heart failure (p = 0.02). In readability, responses were “moderately difficult” (54.73, interquartile range (IQR) 51.59–58.58), with better results for CKD (median 56.1, IQR 53.5–59.1) and RA (56.4, IQR 53.7–60.7), than for heart failure responses (median 50.6, IQR 46.3–53.8). Conclusion: Our study suggests that the ChatGPT tool can be a reliable source of information in spanish for patients with chronic diseases with different reliability for some of them, however, it needs to improve the readability of its answers to be recommended as a useful tool for patients. © The Author(s) 2024.
KW  - Artificial intelligence
KW  - ChatGPT
KW  - chronic diseases
KW  - readability
KW  - reliability
PB  - SAGE Publications Inc.
SN  - 20552076 (ISSN)
LA  - English
J2  - Digit. Health
M3  - Article
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 0; Correspondence Address: M.J. Soto-Chávez; Department of Internal Medicine, Pontificia Universidad Javeriana, Bogotá, Colombia; email: msotoc@javeriana.edu.co
ER  -

TY  - JOUR
AU  - Kim, H.-W.
AU  - Shin, D.-H.
AU  - Kim, J.
AU  - Lee, G.-H.
AU  - Cho, J.W.
TI  - Assessing the performance of ChatGPT's responses to questions related to epilepsy: A cross-sectional study on natural language processing and medical information retrieval
PY  - 2024
T2  - Seizure
VL  - 114
SP  - 1
EP  - 8
DO  - 10.1016/j.seizure.2023.11.013
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85180545519&doi=10.1016%2fj.seizure.2023.11.013&partnerID=40&md5=4e595036fcb5a63d95ba83d26759d583
AD  - Department of Neurology, Pusan National University Yangsan Hospital, 50612 Geumoro 20, Yangsan, South Korea
AD  - Department of Neurology, Pusan National University Hospital, Busan, South Korea
AD  - Pusan National University School of Medicine, Research Institute for Convergence of Biomedical Science and Technology, Yangsan, South Korea
AB  - Background: Epilepsy is a neurological condition marked by frequent seizures and various cognitive and psychological effects. Reliable information is essential for effective treatment. Natural language processing models like ChatGPT are increasingly used in healthcare for information access and data analysis, making it crucial to assess their accuracy. Objective: This study aimed to investigate the accuracy of ChatGPT in providing educational information related to epilepsy. Methods: We compared the answers from ChatGPT-4 and ChatGPT-3.5 to 57 common epilepsy questions based on the Korean Epilepsy Society's "Epilepsy Patient and Caregiver Guide." Two epileptologists reviewed the responses, with a third serving as an arbiter in cases of disagreement. Results: Out of 57 questions, 40 responses from ChatGPT-4 had "sufficient educational value," 16 were "correct but inadequate," and one was "mixed with correct and incorrect" information. No answers were entirely incorrect. GPT-4 generally outperformed GPT-3.5 and was often on par with or better than the official guide. Conclusions: ChatGPT-4 shows promise as a tool for delivering reliable epilepsy-related information and could help alleviate the educational burden on healthcare professionals. Further research is needed to explore the benefits and limitations of using such models in medical contexts. © 2023
KW  - Artificial intelligence
KW  - ChatGPT
KW  - Epilepsy
KW  - Natural language processing
KW  - Cross-Sectional Studies
KW  - Educational Status
KW  - Epilepsy
KW  - Humans
KW  - Information Storage and Retrieval
KW  - Natural Language Processing
KW  - cross-sectional study
KW  - educational status
KW  - epilepsy
KW  - human
KW  - information retrieval
KW  - natural language processing
PB  - W.B. Saunders Ltd
SN  - 10591311 (ISSN)
C2  - 38007922
LA  - English
J2  - Seizure
M3  - Article
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 1; Correspondence Address: J.W. Cho; Department of Neurology, Pusan National University Yangsan Hospital, Yangsan, 50612 Geumoro 20, South Korea; email: sleepcho@pusan.ac.kr; CODEN: SEIZE
ER  -

TY  - JOUR
AU  - Taloni, A.
AU  - Scorcia, V.
AU  - Giannaccare, G.
TI  - Modern threats in academia: evaluating plagiarism and artificial intelligence detection scores of ChatGPT
PY  - 2024
T2  - Eye (Basingstoke)
VL  - 38
IS  - 2
SP  - 397
EP  - 400
DO  - 10.1038/s41433-023-02678-7
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85166573696&doi=10.1038%2fs41433-023-02678-7&partnerID=40&md5=b092f5789216734fbdcf490f2ada7995
AD  - Department of Ophthalmology, University Magna Graecia of Catanzaro, Catanzaro, Italy
KW  - academia
KW  - Article
KW  - artificial intelligence
KW  - ChatGPT
KW  - human
KW  - medical research
KW  - meta analysis (topic)
KW  - plagiarism
KW  - randomized controlled trial (topic)
KW  - systematic review (topic)
PB  - Springer Nature
SN  - 0950222X (ISSN)
C2  - 37532832
LA  - English
J2  - Eye
M3  - Article
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 2; Correspondence Address: G. Giannaccare; Department of Ophthalmology, University Magna Graecia of Catanzaro, Catanzaro, Italy; email: giuseppe.giannaccare@unicz.it; CODEN: EYEEE
ER  -

TY  - CONF
AU  - Jury, B.
AU  - Lorusso, A.
AU  - Leinonen, J.
AU  - Denny, P.
AU  - Luxton-Reilly, A.
TI  - Evaluating LLM-generated Worked Examples in an Introductory Programming Course
PY  - 2024
T2  - ACM International Conference Proceeding Series
SP  - 77
EP  - 86
DO  - 10.1145/3636243.3636252
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85182919169&doi=10.1145%2f3636243.3636252&partnerID=40&md5=4ed254304c941a5b8aa854b27b4030b0
AD  - University of Auckland, Auckland, New Zealand
AB  - Worked examples, which illustrate the process for solving a problem step-by-step, are a well-established pedagogical technique that has been widely studied in computing classrooms. However, creating high-quality worked examples is very time-intensive for educators, and thus learners tend not to have access to a broad range of such examples. The recent emergence of powerful large language models (LLMs), which appear capable of generating high-quality human-like content, may offer a solution. Separate strands of recent work have shown that LLMs can accurately generate code suitable for a novice audience, and that they can generate high-quality explanations of code. Therefore, LLMs may be well suited to creating a broad range of worked examples, overcoming the bottleneck of manual effort that is currently required. In this work, we present a novel tool, 'WorkedGen', which uses an LLM to generate interactive worked examples. We evaluate this tool with both an expert assessment of the content, and a user study involving students in a first-year Python programming course (n = ~400). We find that prompt chaining and one-shot learning are useful strategies for op-timising the output of an LLM when producing worked examples. Our expert analysis suggests that LLMs generate clear explanations, and our classroom deployment revealed that students find the LLM-generated worked examples useful for their learning. We propose several avenues for future work, including investigating WorkedGen's value in a range of programming languages, and with more complex questions suitable for more advanced courses. © 2024 Copyright held by the owner/author(s). Publication rights licensed to ACM.
KW  - chat-GPT
KW  - computing education
KW  - CS1
KW  - GPT-3.5
KW  - large language models
KW  - LLM
KW  - worked examples
KW  - Computational linguistics
KW  - Curricula
KW  - Education computing
KW  - Chat-GPT
KW  - Computing education
KW  - GPT-3.5
KW  - High quality
KW  - Introductory programming course
KW  - Language model
KW  - Large language model
KW  - Worked examples
KW  - Students
PB  - Association for Computing Machinery
SN  - 979-840071619-5 (ISBN)
LA  - English
J2  - ACM Int. Conf. Proc. Ser.
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 0; Conference name: 26th Australasian Computing Education Conference, ACE 2024 - Held in conjunction with Australasian Computer Science Week; Conference date: 30 January 2024 through 1 February 2024; Conference code: 196191
ER  -

TY  - JOUR
AU  - Sievert, M.
AU  - Conrad, O.
AU  - Mueller, S.K.
AU  - Rupp, R.
AU  - Balk, M.
AU  - Richter, D.
AU  - Mantsopoulos, K.
AU  - Iro, H.
AU  - Koch, M.
TI  - Risk stratification of thyroid nodules: Assessing the suitability of ChatGPT for text-based analysis
PY  - 2024
T2  - American Journal of Otolaryngology - Head and Neck Medicine and Surgery
VL  - 45
IS  - 2
C7  - 104144
DO  - 10.1016/j.amjoto.2023.104144
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85181975534&doi=10.1016%2fj.amjoto.2023.104144&partnerID=40&md5=4b2cede42d1a70bd4c9a3799bd7ff853
AD  - Department of Otorhinolaryngology, Head and Neck Surgery, Friedrich Alexander University of Erlangen–Nuremberg, Erlangen University Hospital, Germany
AB  - Purpose: Accurate risk stratification of thyroid nodules is essential for optimal patient management. This study aimed to assess the suitability of ChatGPT for risk stratification of thyroid nodules using a text-based evaluation. Methods: A dataset was compiled comprising 50 anonymized clinical reports and associated risk assessments for thyroid nodules. The Chat Generative Pre-trained Transformer (ChatGPT) was used to classify sonographic patterns in accordance with the Thyroid Imaging Reporting and Data System (TI-RADS). The model's performance was assessed using various criteria, including sensitivity, specificity, and accuracy. A comparative analysis was conducted, evaluating the model against investigator-based risk stratification as well as histology. Results: With an overall agreement rate of 42 % in comparison with examiner-based evaluation (TI-RADS 1–5), the results show that ChatGPT has moderate potential for predicting the risk of malignancy in thyroid nodules using text-based reports. The chatbot model achieved a sensitivity of 86.7 %, a specificity of 10.7 %, and an overall accuracy of 68 % when distinguishing between low-risk (TI-RADS 2 and 3) and high-risk (TI-RADS 4 and 5) categories. Interrater reliability was calculated with a Cohen's kappa of 0.686. Conclusion: This study highlights the potential of ChatGPT in assisting clinicians with risk stratification of thyroid nodules. The results suggest that ChatGPT can facilitate personalized treatment decisions, although the agreement rate is still low. Further research and validation studies are necessary to establish the clinical applicability and generalizability of ChatGPT in routine practice. The integration of ChatGPT into clinical workflows has the potential to enhance thyroid nodule risk assessment and improve patient care. © 2023 Elsevier Inc.
KW  - AI
KW  - ChatGPT
KW  - Risk stratification
KW  - Thyroid nodules
KW  - Ultrasound
KW  - adult
KW  - aged
KW  - Article
KW  - cancer risk
KW  - ChatGPT
KW  - clinical article
KW  - cohort analysis
KW  - controlled study
KW  - diagnostic accuracy
KW  - diagnostic test accuracy study
KW  - echography
KW  - female
KW  - generative pretrained transformer
KW  - hemithyroidectomy
KW  - histopathology
KW  - human
KW  - human tissue
KW  - interrater reliability
KW  - male
KW  - middle aged
KW  - needle biopsy
KW  - patient care
KW  - pilot study
KW  - prediction
KW  - risk assessment
KW  - sensitivity and specificity
KW  - thyroid imaging reporting and data system
KW  - thyroid nodule
KW  - thyroid papillary carcinoma
KW  - total thyroidectomy
KW  - very elderly
KW  - young adult
PB  - W.B. Saunders
SN  - 01960709 (ISSN)
C2  - 38113774
LA  - English
J2  - Am. J. Otolaryngol. Head Neck Med. Surg.
M3  - Article
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 0; Correspondence Address: O. Conrad; Erlangen University Hospital, Germany; email: olafmconrad@gmail.com; CODEN: AJOTD
ER  -

TY  - JOUR
AU  - Andrade, A.F.
AU  - Costa, E.G.
AU  - Souza, J.P.C.
AU  - Andrade, F.L.M.
AU  - Araujo, J.F.
TI  - Evaluation of computational models for electromagnetic force calculation in transformer windings using finite-element method
PY  - 2024
T2  - International Journal of Electrical Power and Energy Systems
VL  - 156
C7  - 109744
DO  - 10.1016/j.ijepes.2023.109744
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85182445267&doi=10.1016%2fj.ijepes.2023.109744&partnerID=40&md5=c91a2205abd8d328dd701a5d246db7ee
AD  - FELCS - Federal University of Rio Grande do Norte (UFRN), Currais Novos, RN, Brazil
AD  - CEEI - Federal University of Campina Grande (UFCG), Campina Grande, PB, Brazil
AD  - Applied Sciences Department, Université du Québec à Chicoutimi, Chicoutimi, QC, Canada
AD  - Federal Institute of Paraíba (IFPB), PB, Patos, Brazil
AB  - Computer simulations are currently one of the most used methods on transformer's short circuit analysis. For them to be effective, an accurate characterization of the transformer core and geometric representation of windings is essential. Hence, this work investigated the influence of core characterization and different geometric representations on magnetic flux density (MFD) and electromagnetic forces (EF) calculated during short circuits. A comparative study using simulations based on the finite-element method (FEM) were carried out for a 180 MVA transformer model. First, the influence of the nonlinear characteristic of the core B-H curve on EF was analyzed. Then, three two-dimensional (2D) axisymmetric and one three-dimensional (3D) representations were compared. Results indicate there is no significant difference in EF with a core represented by a constant value of permeability. Also, 2D-axisymmetric geometric representations underestimate radial forces and diverge significantly on axial forces in comparison with the 3D representation. Differences up to 99% between the calculated total axial forces were obtained for the analyzed cases. In addition, representations with greater level of detail result in magnetic force density up to 5.5 times greater than that obtained with the simplified representation. © 2023 The Authors
KW  - Electromagnetic force
KW  - Finite-element method
KW  - Power transformer
KW  - Short-circuit
KW  - Transformer windings
KW  - Computational electromagnetics
KW  - Geometry
KW  - Power transformers
KW  - Timing circuits
KW  - Transformer windings
KW  - Winding
KW  - Axial forces
KW  - Axisymmetric
KW  - Comparatives studies
KW  - Computational modelling
KW  - Electromagnetic force calculations
KW  - Electromagnetic forces
KW  - Geometric representation
KW  - Short circuit analysis
KW  - Transformer core
KW  - Transformers winding
KW  - Finite element method
PB  - Elsevier Ltd
SN  - 01420615 (ISSN)
LA  - English
J2  - Int J Electr Power Energy Syst
M3  - Article
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 0; Correspondence Address: A.F. Andrade; FELCS - Federal University of Rio Grande do Norte (UFRN), Currais Novos, RN, Brazil; email: arthur.andrade@ufrn.br; CODEN: IEPSD
ER  -

TY  - JOUR
AU  - Tsoutsanis, P.
AU  - Tsoutsanis, A.
TI  - Evaluation of Large language model performance on the Multi-Specialty Recruitment Assessment (MSRA) exam
PY  - 2024
T2  - Computers in Biology and Medicine
VL  - 168
C7  - 107794
DO  - 10.1016/j.compbiomed.2023.107794
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85178656421&doi=10.1016%2fj.compbiomed.2023.107794&partnerID=40&md5=5c9759853638face517eb3f0b834089b
AD  - Northern Care Alliance NHS Foundation Trust, Rochdale Eye Unit, Rochdale infirmary, Greater Manchester, United Kingdom
AD  - Department of Education, University of Oxford, Oxford, United Kingdom
AD  - Department of Informatics, Technical University of Munich, Munich, Germany
AB  - Introduction: AI-powered platforms have gained prominence in medical education and training, offering diverse applications from surgical performance assessment to exam preparation. This research paper examines the capabilities of Large Language Models (LLMs), including Llama 2, Google Bard, Bing Chat, and ChatGPT-3.5, in answering multiple-choice questions of the Clinical Problem Solving (CPS) paper of the Multi-Specialty Recruitment Assessment (MSRA) exam. Methods: Using a dataset of 100 CPS questions from ten subject categories, we assessed the LLMs' performance against medical doctors preparing for the exam. Results: Results showed that Bing Chat outperformed all other LLMs and even surpassed human users from the Qbank question bank. Conversely, Llama 2's performance was inferior to human users. Google Bard and ChatGPT 3.5 did not exhibit statistically significant differences in correct response rates compared to human candidates. Pairwise comparisons demonstrated Bing Chat's significant superiority over Llama 2, Google Bard, and ChatGPT 3.5. However, no significant differences were found between Llama 2 and Google Bard, Llama 2, and ChatGPT-3.5, and Google Bard and ChatGPT-3.5. Discussion: Freely available LLMs have already demonstrated that they can perform as well or even outperform human users in answering MSRA exam questions. Bing Chat emerged as a particularly strong performer. The study also highlights the potential for enhancing LLMs' medical knowledge acquisition through tailored fine-tuning. Medical knowledge tailored LLMs such as Med-PaLM, have already shown promising results. Conclusion: We provided valuable insights into LLMs' competence in answering medical MCQs and their potential integration into medical education and assessment processes. © 2023 Elsevier Ltd
KW  - Artificial intelligence
KW  - Large language models
KW  - Medical education
KW  - Medical exam
KW  - Animals
KW  - Camelids, New World
KW  - Education, Medical
KW  - Humans
KW  - Language
KW  - Medicine
KW  - Problem Solving
KW  - Computational linguistics
KW  - Medical education
KW  - Clinical problems
KW  - Education and training
KW  - Google+
KW  - Human users
KW  - Language model
KW  - Large language model
KW  - Medical exam
KW  - Medical knowledge
KW  - Modeling performance
KW  - Problem-solving
KW  - Article
KW  - artificial intelligence
KW  - ChatGPT
KW  - comparative study
KW  - confidence interval
KW  - large language model
KW  - learning
KW  - medical education
KW  - multiple choice test
KW  - post hoc analysis
KW  - problem solving
KW  - Student t test
KW  - animal
KW  - human
KW  - language
KW  - medicine
KW  - New World camelid
KW  - Clinical research
PB  - Elsevier Ltd
SN  - 00104825 (ISSN)
C2  - 38043471
LA  - English
J2  - Comput. Biol. Med.
M3  - Article
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 0; Correspondence Address: P. Tsoutsanis; Northern Care Alliance NHS Foundation Trust, Rochdale Eye Unit, Rochdale infirmary, Greater Manchester, United Kingdom; email: tpanos02@gmail.com; CODEN: CBMDA
ER  -

TY  - JOUR
AU  - Chen, K.
AU  - Shao, A.
AU  - Burapacheep, J.
AU  - Li, Y.
TI  - Conversational AI and equity through assessing GPT-3’s communication with diverse social groups on contentious topics
PY  - 2024
T2  - Scientific Reports
VL  - 14
IS  - 1
C7  - 1561
DO  - 10.1038/s41598-024-51969-w
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85182669883&doi=10.1038%2fs41598-024-51969-w&partnerID=40&md5=cc712d15beb99fca0dab5737bd029aff
AD  - Department of Life Sciences Communication, University of Wisconsin-Madison, Madison, United States
AD  - Department of Computer Science, Stanford University, Stanford, United States
AD  - Department of Computer Sciences, University of Wisconsin-Madison, Madison, United States
AB  - Autoregressive language models, which use deep learning to produce human-like texts, have surged in prevalence. Despite advances in these models, concerns arise about their equity across diverse populations. While AI fairness is discussed widely, metrics to measure equity in dialogue systems are lacking. This paper presents a framework, rooted in deliberative democracy and science communication studies, to evaluate equity in human–AI communication. Using it, we conducted an algorithm auditing study to examine how GPT-3 responded to different populations who vary in sociodemographic backgrounds and viewpoints on crucial science and social issues: climate change and the Black Lives Matter (BLM) movement. We analyzed 20,000 dialogues with 3290 participants differing in gender, race, education, and opinions. We found a substantively worse user experience among the opinion minority groups (e.g., climate deniers, racists) and the education minority groups; however, these groups changed attitudes toward supporting BLM and climate change efforts much more compared to other social groups after the chat. GPT-3 used more negative expressions when responding to the education and opinion minority groups. We discuss the social-technological implications of our findings for a conversational AI system that centralizes diversity, equity, and inclusion. © 2024, The Author(s).
KW  - Artificial Intelligence
KW  - Attitude
KW  - Communication
KW  - Humans
KW  - Minority Groups
KW  - Social Group
KW  - artificial intelligence
KW  - attitude
KW  - human
KW  - interpersonal communication
KW  - minority group
KW  - social group
PB  - Nature Research
SN  - 20452322 (ISSN)
C2  - 38238474
LA  - English
J2  - Sci. Rep.
M3  - Article
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 0; Correspondence Address: K. Chen; Department of Life Sciences Communication, University of Wisconsin-Madison, Madison, United States; email: kchen67@wisc.edu
ER  -

TY  - JOUR
AU  - Mannstadt, I.
AU  - Mehta, B.
TI  - Large language models and the future of rheumatology: Assessing impact and emerging opportunities
PY  - 2024
T2  - Current Opinion in Rheumatology
VL  - 36
IS  - 1
SP  - 46
EP  - 51
DO  - 10.1097/BOR.0000000000000981
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85178498648&doi=10.1097%2fBOR.0000000000000981&partnerID=40&md5=4fd992570d04b433bb62f4cb6ea31f83
AD  - Weill Cornell Medicine, United States
AD  - Hospital for Special Surgery, New York, NY, United States
AB  - Purpose of reviewLarge language models (LLMs) have grown rapidly in size and capabilities as more training data and compute power has become available. Since the release of ChatGPT in late 2022, there has been growing interest and exploration around potential applications of LLM technology. Numerous examples and pilot studies demonstrating the capabilities of these tools have emerged across several domains. For rheumatology professionals and patients, LLMs have the potential to transform current practices in medicine.Recent findingsRecent studies have begun exploring capabilities of LLMs that can assist rheumatologists in clinical practice, research, and medical education, though applications are still emerging. In clinical settings, LLMs have shown promise in assist healthcare professionals enabling more personalized medicine or generating routine documentation like notes and letters. Challenges remain around integrating LLMs into clinical workflows, accuracy of the LLMs and ensuring patient data confidentiality. In research, early experiments demonstrate LLMs can offer analysis of datasets, with quality control as a critical piece. Lastly, LLMs could supplement medical education by providing personalized learning experiences and integration into established curriculums.SummaryAs these powerful tools continue evolving at a rapid pace, rheumatology professionals should stay informed on how they may impact the field. © 2024 Lippincott Williams and Wilkins. All rights reserved.
KW  - artificial intelligence
KW  - clinical practice
KW  - clinical research
KW  - ethics
KW  - medical education
KW  - Dietary Supplements
KW  - Humans
KW  - Language
KW  - Precision Medicine
KW  - Rheumatologists
KW  - Rheumatology
KW  - artificial intelligence
KW  - ChatGPT
KW  - clinical practice
KW  - clinical research
KW  - curriculum
KW  - health care personnel
KW  - human
KW  - language model
KW  - large language model
KW  - medical education
KW  - patient coding
KW  - personalized medicine
KW  - pilot study
KW  - quality control
KW  - Review
KW  - dietary supplement
KW  - language
KW  - rheumatologist
KW  - rheumatology
PB  - Lippincott Williams and Wilkins
SN  - 10408711 (ISSN)
C2  - 37729050
LA  - English
J2  - Curr. Opin. Rheumatol.
M3  - Review
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 1; Correspondence Address: B. Mehta; New York, 535 East 70th Street, 10021, United States; email: drbellamehta@gmail.com; CODEN: CORHE
ER  -

TY  - JOUR
AU  - Choudhary, A.
AU  - Arora, A.
TI  - Assessment of bidirectional transformer encoder model and attention based bidirectional LSTM language models for fake news detection
PY  - 2024
T2  - Journal of Retailing and Consumer Services
VL  - 76
C7  - 103545
DO  - 10.1016/j.jretconser.2023.103545
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85169591111&doi=10.1016%2fj.jretconser.2023.103545&partnerID=40&md5=b9d3b03813f7b1eee70f17a05741cd98
AD  - Department of Computer Science and Engineering & Information Technology, Jaypee Institute of Information and Technology, Uttar Pradesh, Noida, India
AB  - Fake news arouses to be untrue with the point of deceiving it openly which is now viewed as the greatest threat to society by cultivating the political division and doubts in government. Since this kind of news is disseminated in sheer volume through social media, driving the improvement of strategies for the recognizable proof of false news is necessary. Therefore, this study focuses on text analytics to derive the hidden properties of stylistic content to detect fake and real news. An erudite literature study of fake news detection diverted towards issues such as attention, context, and parallelization. In this same direction, the assessment evaluates the sequential memory-based deep learning model in comparison to the parallel memory-based deep learning model. For sequential, Long Short-Term Memory (LSTM), Bi-Directional LSTM, and Attention-based Bi-directional LSTM are taken into consideration. Besides, for parallel, the transformer-based BERT model is examined. To identify the efficacy of applied approaches, four datasets are taken from diverse domains such as political news, entertainment news, satire news, conspiracy news, and global pandemic news. The experimental analysis of real-world information demonstrates that the pre-trained transformer encoder-based BERT model outperforms with a quite significant margin of improvement. Also, as inspected Attention-based Bi-directional approach provides state-of-the-art results with good training accuracy. © 2023 Elsevier Ltd
KW  - Attention
KW  - BERT
KW  - Bi-directional LSTM
KW  - Fake news
KW  - Language model
KW  - Transformer
KW  - accuracy assessment
KW  - detection method
KW  - information and communication technology
KW  - information management
KW  - literature review
KW  - machine learning
KW  - mass media
KW  - social media
PB  - Elsevier Ltd
SN  - 09696989 (ISSN)
LA  - English
J2  - J. Retail. Consum. Serv.
M3  - Article
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 0; Correspondence Address: A. Choudhary; Department of Computer Science and Engineering & Information Technology, Jaypee Institute of Information and Technology, Noida, Uttar Pradesh, India; email: anshika.ch412@gmail.com
ER  -

TY  - JOUR
AU  - Chen, L.
AU  - Li, H.
AU  - Su, Y.
AU  - Yang, Z.
AU  - He, Z.
AU  - Wang, D.
AU  - Li, J.J.
AU  - Xing, D.
TI  - Using A Google Web Search Analysis to Assess the Utility of ChatGPT in Stem Cell Therapy
PY  - 2024
T2  - Stem Cells Translational Medicine
VL  - 13
IS  - 1
SP  - 60
EP  - 68
DO  - 10.1093/stcltm/szad074
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85182326423&doi=10.1093%2fstcltm%2fszad074&partnerID=40&md5=39bcc6aba29146075f5934e96730e032
AD  - Arthritis Clinic and Research Center, Peking University People’s Hospital, Peking University, Beijing, China
AD  - School of Biomedical Engineering, Faculty of Engineering & IT, University of Technology Sydney, Sydney, NSW, Australia
AB  - Objective: Since its introduction, the use of ChatGPT has increased significantly for medically related purposes. However, current research has not captured its applications in providing information on stem cell therapy. To address this gap, the present study compared the effectiveness of ChatGPT to Google in answering medical questions related to stem cell therapy. Methods: The search term “stem cell therapy” was used to perform a Google web search, and the top 20 frequently asked questions along with answers were recorded together with relevant website sources. Of these questions, the top 10 questions were separately entered into ChatGPT, and the answers and the sources were recorded. Then, the following statement was entered into ChatGPT: “Do a Google search with the search term ‘stem cell therapy’ and record 20 common questions related to the search term.” After obtaining these questions, each question was separately entered into ChatGPT for an answer and source. Results: A majority of the top 20 questions provided by Google were related to fact, whereas a majority of the questions provided by ChatGPT were related to policy. The answer sources used by Google were mostly drawn from medical practice, while those used by ChatGPT were mostly drawn from academic information. Conclusion: Compared to Google, ChatGPT exhibits stronger capabilities in promoting awareness of stem cell therapy. ChatGPT has the ability to eliminate misleading information by providing accurate and reliable answers. However, the responses provided by ChatGPT are still general in nature and cannot substitute academic sources for providing specialized knowledge. © The Author(s) 2023.
KW  - ChatGPT
KW  - Google
KW  - stem cell therapy
KW  - utility
KW  - web search
KW  - Search Engine
KW  - Stem Cell Transplantation
KW  - Article
KW  - awareness
KW  - cell therapy
KW  - ChatGPT
KW  - doctor patient relationship
KW  - drug cost
KW  - education
KW  - government
KW  - graft failure
KW  - human
KW  - information
KW  - Internet
KW  - kidney transplantation
KW  - life expectancy
KW  - longevity
KW  - medical practice
KW  - mesenchymal stem cell
KW  - mitigation
KW  - neural stem cell
KW  - outcome assessment
KW  - pain
KW  - patient education
KW  - policy
KW  - regenerative medicine
KW  - search engine
KW  - social media
KW  - stem cell
KW  - stem cell transplantation
KW  - utility value
PB  - Oxford University Press
SN  - 21576564 (ISSN)
C2  - 37936506
LA  - English
J2  - Stem Cells Transl. Med.
M3  - Article
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 0; Correspondence Address: D. Xing; Arthritis Clinic and Research Center, Peking University People’s Hospital, Peking University, Beijing, 100044, China; email: xingdan@bjmu.edu.cn; J.J. Li; School of Biomedical Engineering, Faculty of Engineering & IT, University of Technology Sydney, Sydney, 2007, Australia; email: Jiaojiao.Li@uts.edu.au
ER  -

TY  - JOUR
AU  - Barlas, T.
AU  - Altinova, A.E.
AU  - Akturk, M.
AU  - Toruner, F.B.
TI  - Credibility of ChatGPT in the assessment of obesity in type 2 diabetes according to the guidelines
PY  - 2024
T2  - International Journal of Obesity
VL  - 48
IS  - 2
SP  - 271
EP  - 275
DO  - 10.1038/s41366-023-01410-5
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85176549956&doi=10.1038%2fs41366-023-01410-5&partnerID=40&md5=cf21939ec203cfb678c2324a57ea84ee
AD  - Department of Endocrinology and Metabolism, Gazi University Faculty of Medicine, Ankara, Turkey
AB  - Background: The Chat Generative Pre-trained Transformer (ChatGPT) allows students, researchers, and patients in the medical field to access information easily and has gained attention nowadays. We aimed to evaluate the credibility of ChatGPT according to the guidelines for the assessment of obesity in type 2 diabetes (T2D), which is one of the major concerns of this century. Materials and method: In this cross-sectional non-human subject study, experienced endocrinologists posed 20 questions to ChatGPT in subsections, which were assessments and different treatment options for obesity according to the American Diabetes Association and American Association of Clinical Endocrinology guidelines. The responses of ChatGPT were classified into four categories: compatible, compatible but insufficient, partially incompatible and incompatible with the guidelines. Results: ChatGPT demonstrated a systematic approach to answering questions and recommended consulting a healthcare provider to receive personalized advice based on the specific health needs and circumstances of patients. The compatibility of ChatGPT with the guidelines was 100% in the assessment of obesity in type 2 diabetes; however, it was lower in the therapy sections, which included nutritional, medical, and surgical approaches to weight loss. Furthermore, ChatGPT required additional prompts for responses that were evaluated as “compatible but insufficient” to provide all the information in the guidelines. Conclusion: The assessment and management of obesity in T2D are highly individualized. Despite ChatGPT’s comprehensive and understandable responses, it should not be used as a substitute for healthcare professionals’ patient-centered approach. © 2023, The Author(s), under exclusive licence to Springer Nature Limited.
PB  - Springer Nature
SN  - 03070565 (ISSN)
C2  - 37951982
LA  - English
J2  - Int. J. Obes.
M3  - Article
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 1; Correspondence Address: T. Barlas; Department of Endocrinology and Metabolism, Gazi University Faculty of Medicine, Ankara, Turkey; email: drtugbabarlas@gmail.com; CODEN: IJOBD
ER  -

TY  - JOUR
AU  - Giuffrè, M.
AU  - You, K.
AU  - Shung, D.L.
TI  - Evaluating ChatGPT in Medical Contexts: The Imperative to Guard Against Hallucinations and Partial Accuracies
PY  - 2024
T2  - Clinical Gastroenterology and Hepatology
DO  - 10.1016/j.cgh.2023.09.035
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85182663809&doi=10.1016%2fj.cgh.2023.09.035&partnerID=40&md5=dc5e36fefbf5efb892db6597bb3d410b
AD  - Section of Digestive Diseases, Department of Internal Medicine, Yale School of Medicine, Yale University, New Haven, Connecticut, United States
AD  - Department of Mathematics, Baruch College, City University of New York, New York, New York, United States
PB  - W.B. Saunders
SN  - 15423565 (ISSN)
C2  - 37863408
LA  - English
J2  - Clin. Gastroenterol. Hepatol.
M3  - Letter
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 0; CODEN: CGHLA
ER  -

TY  - JOUR
AU  - Rabbani, N.
AU  - Brown, C.
AU  - Bedgood, M.
AU  - Goldstein, R.L.
AU  - Carlson, J.L.
AU  - Pageler, N.M.
AU  - Morse, K.E.
TI  - Evaluation of a Large Language Model to Identify Confidential Content in Adolescent Encounter Notes
PY  - 2024
T2  - JAMA Pediatrics
DO  - 10.1001/jamapediatrics.2023.6032
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85182882856&doi=10.1001%2fjamapediatrics.2023.6032&partnerID=40&md5=531d988ffbcce2a70fa792737123fedd
AD  - Department of Pediatrics, Stanford University, Palo Alto, CA, United States
AD  - Information Services, Lucile Packard Children's Hospital, Palo Alto, CA, United States
AD  - Department of Emergency and Transport Medicine, Children's Hospital Los Angeles, Los Angeles, CA, United States
PB  - American Medical Association
SN  - 21686203 (ISSN)
LA  - English
J2  - JAMA Pediatr.
M3  - Article
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 0; Correspondence Address: N. Rabbani; Department of Pediatrics, Stanford University, School of Medicine, Palo Alto, 453 Quarry Rd, MC 5660, 94304, United States; email: nrabbani@stanford.edu
ER  -

TY  - JOUR
AU  - Ray, P.P.
AU  - Majumder, P.
TI  - Evaluating the Limitations of ChatGPT in Generating Competent Radiology Reports for Distal Radius Fractures
PY  - 2024
T2  - Current Problems in Diagnostic Radiology
VL  - 53
IS  - 1
SP  - 166
EP  - 167
DO  - 10.1067/j.cpradiol.2023.10.010
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85177031327&doi=10.1067%2fj.cpradiol.2023.10.010&partnerID=40&md5=83aa976afa06545c54b07ec481f5c86c
AD  - Sikkim University, India
AD  - Maulana Abul Kalam Azad University of Technology, India
KW  - Follow-Up Studies
KW  - Humans
KW  - Radiography
KW  - Radiology
KW  - Wrist Fractures
KW  - artificial intelligence
KW  - ChatGPT
KW  - clinical assessment
KW  - clinical evaluation
KW  - clinical practice
KW  - comparative study
KW  - distal radius fracture
KW  - evidence based practice
KW  - health care personnel
KW  - human
KW  - Letter
KW  - medical terminology
KW  - patient care
KW  - radiodiagnosis
KW  - radiologist
KW  - radiology
KW  - workflow
KW  - follow up
KW  - radiography
KW  - wrist fracture
PB  - Elsevier Inc.
SN  - 03630188 (ISSN)
C2  - 37925239
LA  - English
J2  - Curr. Probl. Diagn. Radiol.
M3  - Letter
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 0; Correspondence Address: P.P. Ray; Sikkim University, India; email: ppray@cus.ac.in; CODEN: CPDRD
ER  -

TY  - JOUR
AU  - Zack, T.
AU  - Lehman, E.
AU  - Suzgun, M.
AU  - Rodriguez, J.A.
AU  - Celi, L.A.
AU  - Gichoya, J.
AU  - Jurafsky, D.
AU  - Szolovits, P.
AU  - Bates, D.W.
AU  - Abdulnour, R.-E.E.
AU  - Butte, A.J.
AU  - Alsentzer, E.
TI  - Assessing the potential of GPT-4 to perpetuate racial and gender biases in health care: a model evaluation study
PY  - 2024
T2  - The Lancet Digital Health
VL  - 6
IS  - 1
SP  - e12
EP  - e22
DO  - 10.1016/S2589-7500(23)00225-X
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85180347404&doi=10.1016%2fS2589-7500%2823%2900225-X&partnerID=40&md5=512470e0e5e6932e9c95e349c4287dd9
AD  - Bakar Computational Health Sciences Institute, University of California San Francisco, San Francisco, CA, United States
AD  - Helen Diller Family Comprehensive Cancer Center, University of California San Francisco, San Francisco, CA, United States
AD  - Computer Science and Artificial Intelligence Laboratory, Massachusetts Institute of Technology, Cambridge, MA, United States
AD  - Laboratory for Computational Physiology, Massachusetts Institute of Technology, Cambridge, MA, United States
AD  - Department of Computer Science, Stanford University, Stanford, CA, United States
AD  - Stanford Law School, Stanford University, Stanford, CA, United States
AD  - Department of Linguistics, Stanford University, Stanford, CA, United States
AD  - Division of General Internal Medicine, Brigham and Women's Hospital, Boston, MA, United States
AD  - Division of Pulmonary and Critical Care Medicine, Brigham and Women's Hospital, Boston, MA, United States
AD  - Division of Pulmonary, Critical Care and Sleep Medicine, Beth Israel Deaconess Medical Center, Boston, MA, United States
AD  - Department of Biostatistics, Harvard T H Chan School of Public Health, Boston, MA, United States
AD  - Department of Health Policy and Management, Harvard T H Chan School of Public Health, Boston, MA, United States
AD  - Department of Radiology, Emory University, Atlanta, GA, United States
AD  - Harvard Medical School, Boston, MA, United States
AD  - Center for Data-Driven Insights and Innovation, University of California, Office of the President, Oakland, CA, United States
AB  - Background: Large language models (LLMs) such as GPT-4 hold great promise as transformative tools in health care, ranging from automating administrative tasks to augmenting clinical decision making. However, these models also pose a danger of perpetuating biases and delivering incorrect medical diagnoses, which can have a direct, harmful impact on medical care. We aimed to assess whether GPT-4 encodes racial and gender biases that impact its use in health care. Methods: Using the Azure OpenAI application interface, this model evaluation study tested whether GPT-4 encodes racial and gender biases and examined the impact of such biases on four potential applications of LLMs in the clinical domain—namely, medical education, diagnostic reasoning, clinical plan generation, and subjective patient assessment. We conducted experiments with prompts designed to resemble typical use of GPT-4 within clinical and medical education applications. We used clinical vignettes from NEJM Healer and from published research on implicit bias in health care. GPT-4 estimates of the demographic distribution of medical conditions were compared with true US prevalence estimates. Differential diagnosis and treatment planning were evaluated across demographic groups using standard statistical tests for significance between groups. Findings: We found that GPT-4 did not appropriately model the demographic diversity of medical conditions, consistently producing clinical vignettes that stereotype demographic presentations. The differential diagnoses created by GPT-4 for standardised clinical vignettes were more likely to include diagnoses that stereotype certain races, ethnicities, and genders. Assessment and plans created by the model showed significant association between demographic attributes and recommendations for more expensive procedures as well as differences in patient perception. Interpretation: Our findings highlight the urgent need for comprehensive and transparent bias assessments of LLM tools such as GPT-4 for intended use cases before they are integrated into clinical care. We discuss the potential sources of these biases and potential mitigation strategies before clinical implementation. Funding: Priscilla Chan and Mark Zuckerberg. © 2024 The Author(s). Published by Elsevier Ltd. This is an Open Access article under the CC BY 4.0 license
KW  - Clinical Decision-Making
KW  - Delivery of Health Care
KW  - Diagnosis, Differential
KW  - Education, Medical
KW  - Female
KW  - Health Facilities
KW  - Humans
KW  - Male
KW  - Clinical research
KW  - Decision making
KW  - Encoding (symbols)
KW  - Health care
KW  - Medical education
KW  - Population statistics
KW  - Administrative tasks
KW  - Application interfaces
KW  - Clinical decision making
KW  - Differential diagnosis
KW  - Evaluation study
KW  - Gender bias
KW  - Language model
KW  - Medical conditions
KW  - Model evaluation
KW  - Racial bias
KW  - angiography
KW  - Article
KW  - Asian
KW  - Black person
KW  - Caucasian
KW  - Chlamydia infection
KW  - clinical article
KW  - controlled study
KW  - demography
KW  - diagnostic reasoning
KW  - differential diagnosis
KW  - exercise test
KW  - female
KW  - gender bias
KW  - generative pretrained transformer
KW  - health care
KW  - Hispanic
KW  - human
KW  - Human immunodeficiency virus infection
KW  - male
KW  - medical education
KW  - mononucleosis
KW  - patient assessment
KW  - patient attitude
KW  - patient referral
KW  - pharyngitis
KW  - prevalence
KW  - racism
KW  - streptococcal pharyngitis
KW  - syphilis
KW  - treatment planning
KW  - United States
KW  - viral pharyngitis
KW  - clinical decision making
KW  - health care delivery
KW  - health care facility
KW  - medical education
KW  - Diagnosis
PB  - Elsevier Ltd
SN  - 25897500 (ISSN)
C2  - 38123252
LA  - English
J2  - Lancet Digit. Heal.
M3  - Article
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 2; Correspondence Address: E. Alsentzer; Division of General Internal Medicine, Brigham and Women's Hospital, Boston, 02115, United States; email: ealsentzer@bwh.harvard.edu
ER  -

TY  - JOUR
AU  - Abi-Rafeh, J.
AU  - Hanna, S.
AU  - Bassiri-Tehrani, B.
AU  - Kazan, R.
AU  - Nahai, F.
TI  - Erratum: Correction: Complications Following Facelift and Neck Lift: Implementation and Assessment of Large Language Model and Artificial Intelligence (ChatGPT) Performance Across 16 Simulated Patient Presentations (Aesthetic plastic surgery (2023) 47 6 (2407-2414))
PY  - 2023
T2  - Aesthetic plastic surgery
VL  - 47
IS  - 6
SP  - 2911
DO  - 10.1007/s00266-023-03790-5
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85179339508&doi=10.1007%2fs00266-023-03790-5&partnerID=40&md5=216fdfaf1bd23c6d418ad112e2aee708
AD  - Division of Plastic, Reconstructive, Aesthetic Surgery, McGill University Health Centre, Montreal, QC, Canada
AD  - Manhattan Eye, Ear and Throat Hospital, New York, NY, USA
AD  - Private Practice, Atlanta, GA, United States
AD  - Division of Plastic and Reconstructive Surgery, University of Pittsburgh, Pittsburgh, PA, United States
AD  - Department of Surgery, Emory University, Atlanta, GA, United States
KW  - plastic
KW  - artificial intelligence
KW  - ChatGPT
KW  - complication
KW  - erratum
KW  - human
KW  - large language model
KW  - neck
KW  - plastic surgery
KW  - rhytidoplasty
KW  - simulation
SN  - 14325241 (ISSN)
C2  - 38078915
LA  - English
J2  - Aesthetic Plast Surg
M3  - Erratum
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 0
ER  -

TY  - JOUR
AU  - Bergman, E.
AU  - Gerdina, A.M.
AU  - Mol, P.G.M.
AU  - Westman, G.
TI  - A full-document analysis of the semantic relation between European Public Assessment Reports and EMA guidelines using a BERT language model
PY  - 2023
T2  - PLoS ONE
VL  - 18
IS  - 12 December
C7  - e0294560
DO  - 10.1371/journal.pone.0294560
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85179901574&doi=10.1371%2fjournal.pone.0294560&partnerID=40&md5=630b3c23534304308630b6c03790c588
AD  - Swedish Medical Products Agency, Uppsala, Sweden
AD  - Dutch Medicines Evaluation Board, Utrecht, Netherlands
AD  - Department of Clinical Pharmacy and Pharmacology, University Medical Center Groningen, University of Groningen, Groningen, Netherlands
AD  - Department of Medical Sciences, Uppsala University, Uppsala, Sweden
AB  - In the European Union, the Committee for Medicinal Products for Human Use of the European Medicines Agency (EMA) develop guidelines to guide drug development, supporting development of efficacious and safe medicines. A European Public Assessment Report (EPAR) is published for every medicine application that has been granted or refused marketing authorisation within the EU. In this work, we study the use of text embeddings and similarity metrics to investigate the semantic similarity between EPARs and EMA guidelines. All 1024 EPARs for initial marketing authorisations from 2008 to 2022 was compared to the 669 current EMA scientific guidelines. Documents were converted to plain text and split into overlapping chunks, generating 265,757 EPAR and 27,649 guideline text chunks. Using a Sentence BERT language model, the chunks were transformed into embeddings and fed into an in-house piecewise matching algorithm to estimate the full-document semantic distance. In an analysis of the document distance scores and product characteristics using a linear regression model, EPARs of anti-virals for systemic use (ATC code J05) and antihemorrhagic medicines (B02) present with statistically significant lower overall semantic distance to guidelines compared to other therapeutic areas, also when adjusting for product age and EPAR length. In conclusion, we believe our approach provides meaningful insight into the interplay between EMA scientific guidelines and the assessment made during regulatory review, and could potentially be used to answer more specific questions such as which therapeutic areas could benefit from additional regulatory guidance. © 2023 Bergman et al. This is an open access article distributed under the terms of the Creative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.
KW  - Document Analysis
KW  - Drug Approval
KW  - Drug Development
KW  - European Union
KW  - Humans
KW  - Semantics
KW  - biosimilar agent
KW  - blood clotting factor 8 plus von Willebrand factor
KW  - daridorexant
KW  - drospirenone plus estetrol
KW  - elasomeran
KW  - ibacovavec
KW  - immunomodulating agent
KW  - memantine
KW  - miglustat
KW  - nirmatrelvir plus ritonavir
KW  - nvx-cov2373 vaccine
KW  - recombinant blood clotting factor 8
KW  - remdesivir
KW  - setmelanotide
KW  - tozinameran
KW  - vaxzevria
KW  - Alzheimer disease
KW  - antiviral activity
KW  - Article
KW  - coronavirus disease 2019
KW  - document analysis
KW  - drug development
KW  - European Medicines Agency
KW  - European Union
KW  - hemophilia A
KW  - human
KW  - language model
KW  - linear regression analysis
KW  - obesity
KW  - practice guideline
KW  - regression model
KW  - ulcerative colitis
KW  - document analysis
KW  - drug approval
KW  - European Union
KW  - semantics
PB  - Public Library of Science
SN  - 19326203 (ISSN)
C2  - 38100432
LA  - English
J2  - PLoS ONE
M3  - Article
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 0; Correspondence Address: G. Westman; Swedish Medical Products Agency, Uppsala, Sweden; email: gabriel.westman@lakemedelsverket.se; CODEN: POLNC
ER  -

TY  - JOUR
AU  - Frosolini, A.
AU  - Franz, L.
AU  - Benedetti, S.
AU  - Vaira, L.A.
AU  - de Filippis, C.
AU  - Gennaro, P.
AU  - Marioni, G.
AU  - Gabriele, G.
TI  - Assessing the accuracy of ChatGPT references in head and neck and ENT disciplines
PY  - 2023
T2  - European Archives of Oto-Rhino-Laryngology
VL  - 280
IS  - 11
SP  - 5129
EP  - 5133
DO  - 10.1007/s00405-023-08205-4
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85169906469&doi=10.1007%2fs00405-023-08205-4&partnerID=40&md5=61505ff54369f27a9f25d6887e94a025
AD  - Department of Maxillo-Facial Surgery, Policlinico Le Scotte, University of Siena, Siena, Italy
AD  - Phoniatris and Audiology Unit, Department of Neuroscience DNS, University of Padova, Treviso, Italy
AD  - Artificial Intelligence in Medicine and Innovation in Clinical Research and Methodology (PhD Program), Department of Clinical and Experimental Sciences, University of Brescia, Brescia, Italy
AD  - Maxillofacial Surgery Operative Unit, Department of Medicine, Surgery and Pharmacy, University of Sassari, Sassari, Italy
AD  - PhD School of Biomedical Sciences, Department of Biomedical Sciences, University of Sassari, Sassari, Italy
AB  - Purpose: ChatGPT has gained popularity as a web application since its release in 2022. While artificial intelligence (AI) systems’ potential in scientific writing is widely discussed, their reliability in reviewing literature and providing accurate references remains unexplored. This study examines the reliability of references generated by ChatGPT language models in the Head and Neck field. Methods: Twenty clinical questions were generated across different Head and Neck disciplines, to prompt ChatGPT versions 3.5 and 4.0 to produce texts on the assigned topics. The generated references were categorized as “true,” “erroneous,” or “inexistent” based on congruence with existing records in scientific databases. Results: ChatGPT 4.0 outperformed version 3.5 in terms of reference reliability. However, both versions displayed a tendency to provide erroneous/non-existent references. Conclusions: It is crucial to address this challenge to maintain the reliability of scientific literature. Journals and institutions should establish strategies and good-practice principles in the evolving landscape of AI-assisted scientific writing. © 2023, The Author(s), under exclusive licence to Springer-Verlag GmbH Germany, part of Springer Nature.
KW  - AI
KW  - Artificial intelligence
KW  - Chat-GPT
KW  - Head and neck surgery
KW  - Maxillofacial
KW  - Artificial Intelligence
KW  - Databases, Factual
KW  - Head
KW  - Humans
KW  - Neck
KW  - Reproducibility of Results
KW  - article
KW  - artificial intelligence
KW  - ChatGPT
KW  - head and neck surgery
KW  - human
KW  - human experiment
KW  - reliability
KW  - scientific literature
KW  - writing
KW  - factual database
KW  - head
KW  - neck
KW  - reproducibility
PB  - Springer Science and Business Media Deutschland GmbH
SN  - 09374477 (ISSN)
C2  - 37679532
LA  - English
J2  - Eur. Arch. Oto-Rhino-Laryngol.
M3  - Article
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 3; Correspondence Address: A. Frosolini; Department of Maxillo-Facial Surgery, Policlinico Le Scotte, University of Siena, Siena, Italy; email: andreafrosolini@gmail.com; CODEN: EAOTE
ER  -

TY  - JOUR
AU  - Souza, F.C.
AU  - Nogueira, R.F.
AU  - Lotufo, R.A.
TI  - BERT models for Brazilian Portuguese: Pretraining, evaluation and tokenization analysis
PY  - 2023
T2  - Applied Soft Computing
VL  - 149
C7  - 110901
DO  - 10.1016/j.asoc.2023.110901
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85174897127&doi=10.1016%2fj.asoc.2023.110901&partnerID=40&md5=13d700f3623f4e62474dc32b114fbafe
AD  - School of Electrical and Computer Engineering - UNICAMP, Cidade Universitária, SP, Campinas, 13083-852, Brazil
AD  - University of Waterloo, 200 University Ave W, Waterloo, N2L 3G1, ON, Canada
AD  - Neuralmind Inteligência Artificial, Cidade Universitária, SP, Campinas, 13083-898, Brazil
AB  - Recent advances in language representation using neural networks have made it viable to transfer the learned internal states of large pretrained language models (LMs) to downstream natural language processing (NLP) tasks. This transfer learning approach improves the overall performance on many tasks and is highly beneficial when labeled data is scarce, making pretrained LMs valuable resources specially for languages with few annotated training examples. In this work, we train BERT (Bidirectional Encoder Representations from Transformers) models for Brazilian Portuguese, which we nickname BERTimbau. We evaluate our models on three downstream NLP tasks: sentence textual similarity, recognizing textual entailment, and named entity recognition. Our models improve the state-of-the-art in all of these tasks, outperforming Multilingual BERT and confirming the effectiveness of large pretrained LMs for Portuguese. We release our models to the community hoping to provide strong baselines for future NLP research: https://github.com/neuralmind-ai/portuguese-bert. © 2023 Elsevier B.V.
KW  - BERT
KW  - Language model
KW  - Named entity recognition
KW  - Recognizing textual entailment
KW  - Sentence textual similarity
KW  - Computational linguistics
KW  - Text processing
KW  - Bidirectional encoder representation from transformer
KW  - Down-stream
KW  - Language model
KW  - Language processing
KW  - Named entity recognition
KW  - Natural languages
KW  - Recognizing textual entailments
KW  - Sentence textual similarity
KW  - Textual similarities
KW  - Transformer modeling
KW  - Natural language processing systems
PB  - Elsevier Ltd
SN  - 15684946 (ISSN)
LA  - English
J2  - Appl. Soft Comput.
M3  - Article
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 0; Correspondence Address: F.C. Souza; Neuralmind Inteligência Artificial, Cidade Universitária, Campinas, SP, 13083-898, Brazil; email: fabiocapsouza@gmail.com
ER  -

TY  - JOUR
AU  - Barallat, J.
AU  - Gómez, C.
AU  - Sancho-Cerro, A.
TI  - AI, diabetes and getting lost in translation: A multilingual evaluation of Bing with ChatGPT focused in HbA1c
PY  - 2023
T2  - Clinical Chemistry and Laboratory Medicine
VL  - 61
IS  - 11
SP  - E222
EP  - E224
DO  - 10.1515/cclm-2023-0295
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85159041648&doi=10.1515%2fcclm-2023-0295&partnerID=40&md5=adac61b7dd6d8177832e66c41edf9fa9
AD  - Biochemistry Department, LCMN, Germans Trias i Pujol University Hospital, Badalona, Spain
KW  - artificial intelligence
KW  - Bing
KW  - ChatGPT
KW  - diabetes
KW  - evaluation of new products
KW  - HbA<sub>1c</sub>
KW  - Artificial Intelligence
KW  - Diabetes Mellitus
KW  - Humans
KW  - hemoglobin A1c
KW  - artificial intelligence
KW  - ChatGPT
KW  - clinical laboratory
KW  - diabetes mellitus
KW  - health care personnel
KW  - human
KW  - impaired glucose tolerance
KW  - Letter
KW  - multilingualism
KW  - search engine
KW  - artificial intelligence
KW  - diabetes mellitus
PB  - Walter de Gruyter GmbH
SN  - 14346621 (ISSN)
C2  - 37155932
LA  - English
J2  - Clin. Chem. Lab. Med.
M3  - Letter
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 0; Correspondence Address: J. Barallat; Biochemistry Department, LCMN, Germans Trias i Pujol University Hospital, Badalona, 08916, Spain; email: jbarallat@gmail.com; CODEN: CCLMF
ER  -

TY  - JOUR
AU  - Zhang, W.
AU  - Jiang, J.
AU  - Li, B.
AU  - Shen, S.
AU  - Lu, Y.
AU  - Tao, Y.
AU  - Fan, L.
TI  - Residual Lifetime Evaluation of Power Transformers Based on Data Fusion and Wiener Model
PY  - 2023
T2  - IEEE Transactions on Power Delivery
VL  - 38
IS  - 6
SP  - 4189
EP  - 4201
DO  - 10.1109/TPWRD.2023.3305732
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85169663510&doi=10.1109%2fTPWRD.2023.3305732&partnerID=40&md5=8acb14376621871f6fce281df8a19a7b
AD  - Jiangsu Key Laboratory of New Energy Generation and Power Conversion, Nanjing University of Aeronautics and Astronautics, Nanjing, 211106, China
AD  - State Grid Anyang Power SupplyCompany, Anyang, 455000, China
AD  - College of Engineering,Mathematics and Physical Sciences, University of Exeter, Exeter, EX4 4PY, United Kingdom
AD  - State Grid Jiangsu Electric Power Company Ltd. Research Institute, Nanjing, 211103, China
AD  - Hangzhou Qianjiang Electric Group Company,Ltd., Hangzhou, 311243, China
AB  - Accurate assessment of Remaining Useful Lifetime (RUL) of power transformers plays an essential role in improving the reliability of power grid while reducing operating costs. A dynamical RUL prediction technique is proposed in this article through analyzing the individual difference by multi-dimensional fusion of condition monitoring data. Firstly, the on-site Dissolved Gas Analysis (DGA) measurements and the calculated Degree of Polymerization (DP) are fused with the method of Analytic Hierarchy Process (AHP) and Variable Weight Principle (VWP) to construct the power transformer Life Correlation Index (LCI). Secondly, the parameters of Wiener model are updated iteratively by Bayesian rule and Expectation Maximization (EM) algorithm, to obtain the distribution and prediction of residual transformer lifetime. The residual lifetimes of four 500 kV power transformers in operation are calculated, and the predicted remaining lifetimes are 24.73 years, 30.66 years, 2.79 years, and 0.07 years, respectively. The effectiveness and reliability are demonstrated by the worst transformer case with the predicted RUL of 0.07 years, in which a short circuit fault of that transformer happened immediately after power-off maintenance. In particular, this method is able to predict the residual lifetime of transformers in a dynamic way, which provides significant practical implications for the assessment management of power transformers.  © 2023 IEEE.
KW  - asset management
KW  - data fusion
KW  - remaining useful lifetime
KW  - Transformer
KW  - variable weight principle
KW  - Wiener model
KW  - Analytic hierarchy process
KW  - Condition based maintenance
KW  - Condition monitoring
KW  - Data fusion
KW  - Degradation
KW  - Electric power distribution
KW  - Forecasting
KW  - Iterative methods
KW  - Maximum principle
KW  - Operating costs
KW  - Assets management
KW  - Index
KW  - Oil
KW  - Oil insulations
KW  - Power transformer insulation
KW  - Remaining useful lifetime
KW  - Transformer
KW  - Useful lifetime
KW  - Variable weight
KW  - Variable weight principle
KW  - Wiener models
KW  - Power transformers
PB  - Institute of Electrical and Electronics Engineers Inc.
SN  - 08858977 (ISSN)
LA  - English
J2  - IEEE Trans Power Delivery
M3  - Article
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 0; Correspondence Address: J. Jiang; Jiangsu Key Laboratory of New Energy Generation and Power Conversion, Nanjing University of Aeronautics and Astronautics, Nanjing, 211106, China; email: jiangjun0628@163.com; CODEN: ITPDE
ER  -

TY  - JOUR
AU  - Danesh, A.
AU  - Pazouki, H.
AU  - Danesh, K.
AU  - Danesh, F.
AU  - Danesh, A.
TI  - The performance of artificial intelligence language models in board-style dental knowledge assessment: A preliminary study on ChatGPT
PY  - 2023
T2  - Journal of the American Dental Association
VL  - 154
IS  - 11
SP  - 970
EP  - 974
DO  - 10.1016/j.adaj.2023.07.016
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85170426979&doi=10.1016%2fj.adaj.2023.07.016&partnerID=40&md5=5f96d45d91e04cd686bb562b77efcfd1
AB  - Background: Although Chat Generative Pre-trained Transformer (ChatGPT) (OpenAI) may be an appealing educational resource for students, the chatbot responses can be subject to misinformation. This study was designed to evaluate the performance of ChatGPT on a board-style multiple-choice dental knowledge assessment to gauge its capacity to output accurate dental content and in turn the risk of misinformation associated with use of the chatbot as an educational resource by dental students. Methods: ChatGPT3.5 and ChatGPT4 were asked questions obtained from 3 different sources: INBDE Bootcamp, ITDOnline, and a list of board-style questions provided by the Joint Commission on National Dental Examinations. Image-based questions were excluded, as ChatGPT only takes text-based inputs. The mean performance across 3 trials was reported for each model. Results: ChatGPT3.5 and ChatGPT4 answered 61.3% and 76.9% of the questions correctly on average, respectively. A 2-tailed t test was used to compare 2 independent sample means, and a 2-tailed χ2 test was used to compare 2 sample proportions. A P value less than .05 was considered to be statistically significant. Conclusion: ChatGPT3.5 did not perform sufficiently well on the board-style knowledge assessment. ChatGPT4, however, displayed a competent ability to output accurate dental content. Future research should evaluate the proficiency of emerging models of ChatGPT in dentistry to assess its evolving role in dental education. Practical Implications: Although ChatGPT showed an impressive ability to output accurate dental content, our findings should encourage dental students to incorporate ChatGPT to supplement their existing learning program instead of using it as their primary learning resource. © 2023 American Dental Association
KW  - Artificial intelligence
KW  - ChatGPT
KW  - dental board examination
KW  - dental education
KW  - dentistry
KW  - Integrated National Board Dental Examination
KW  - Artificial Intelligence
KW  - Educational Status
KW  - Humans
KW  - Language
KW  - artificial intelligence
KW  - educational status
KW  - human
KW  - language
PB  - American Dental Association
SN  - 00028177 (ISSN)
C2  - 37676187
LA  - English
J2  - J. Am. Dent. Assoc.
M3  - Article
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 2; Correspondence Address: A. Danesh; Department of Periodontology, College of Dental Medicine, Nova Southeastern University, Davie, 3050 S University Dr, 33314, United States; email: Ad2900@mynsu.nova.edu
ER  -

TY  - JOUR
AU  - Antaki, F.
AU  - Touma, S.
AU  - Milad, D.
AU  - El-Khoury, J.
AU  - Duval, R.
TI  - Evaluating the Performance of ChatGPT in Ophthalmology: An Analysis of Its Successes and Shortcomings
PY  - 2023
T2  - Ophthalmology Science
VL  - 3
IS  - 4
C7  - 100324
DO  - 10.1016/j.xops.2023.100324
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85163557911&doi=10.1016%2fj.xops.2023.100324&partnerID=40&md5=35b88d52174cc6588e212cc6387648c9
AD  - Department of Ophthalmology, Université de Montréal, Montréal, QC, Canada
AD  - Centre Universitaire d'Ophtalmologie (CUO), Hôpital Maisonneuve-Rosemont, CIUSSS de l'Est-de-l’Île-de-Montréal, Montréal, QC, Canada
AD  - Department of Ophthalmology, Centre Hospitalier de l'Université de Montréal (CHUM), Montréal, QC, Canada
AD  - The CHUM School of Artificial Intelligence in Healthcare (SAIH), Centre Hospitalier de l'Université de Montréal (CHUM), Montréal, QC, Canada
AB  - Purpose: Foundation models are a novel type of artificial intelligence algorithms, in which models are pretrained at scale on unannotated data and fine-tuned for a myriad of downstream tasks, such as generating text. This study assessed the accuracy of ChatGPT, a large language model (LLM), in the ophthalmology question-answering space. Design: Evaluation of diagnostic test or technology. Participants: ChatGPT is a publicly available LLM. Methods: We tested 2 versions of ChatGPT (January 9 “legacy” and ChatGPT Plus) on 2 popular multiple choice question banks commonly used to prepare for the high-stakes Ophthalmic Knowledge Assessment Program (OKAP) examination. We generated two 260-question simulated exams from the Basic and Clinical Science Course (BCSC) Self-Assessment Program and the OphthoQuestions online question bank. We carried out logistic regression to determine the effect of the examination section, cognitive level, and difficulty index on answer accuracy. We also performed a post hoc analysis using Tukey's test to decide if there were meaningful differences between the tested subspecialties. Main Outcome Measures: We reported the accuracy of ChatGPT for each examination section in percentage correct by comparing ChatGPT's outputs with the answer key provided by the question banks. We presented logistic regression results with a likelihood ratio (LR) chi-square. We considered differences between examination sections statistically significant at a P value of < 0.05. Results: The legacy model achieved 55.8% accuracy on the BCSC set and 42.7% on the OphthoQuestions set. With ChatGPT Plus, accuracy increased to 59.4% ± 0.6% and 49.2% ± 1.0%, respectively. Accuracy improved with easier questions when controlling for the examination section and cognitive level. Logistic regression analysis of the legacy model showed that the examination section (LR, 27.57; P = 0.006) followed by question difficulty (LR, 24.05; P < 0.001) were most predictive of ChatGPT's answer accuracy. Although the legacy model performed best in general medicine and worst in neuro-ophthalmology (P < 0.001) and ocular pathology (P = 0.029), similar post hoc findings were not seen with ChatGPT Plus, suggesting more consistent results across examination sections. Conclusion: ChatGPT has encouraging performance on a simulated OKAP examination. Specializing LLMs through domain-specific pretraining may be necessary to improve their performance in ophthalmic subspecialties. Financial Disclosure(s): Proprietary or commercial disclosure may be found after the references. © 2023 American Academy of Ophthalmology
KW  - Artificial intelligence
KW  - ChatGPT
KW  - Generative Pretrained Transformer
KW  - Medical education
KW  - Ophthalmology
KW  - accreditation
KW  - Article
KW  - artificial intelligence
KW  - cognition
KW  - eye disease
KW  - general practice
KW  - logistic regression analysis
KW  - measurement accuracy
KW  - measurement repeatability
KW  - neuroophthalmology
KW  - ophthalmology
KW  - post hoc analysis
PB  - Elsevier Inc.
SN  - 26669145 (ISSN)
LA  - English
J2  - Ophthalmol. Sci.
M3  - Article
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 62; Correspondence Address: R. Duval; Montréal, 5415 Boulevard de l'Assomption, H1T 2M4, Canada; email: renaud.duval@gmail.com
ER  -

TY  - JOUR
AU  - Zhang, Y.-Z.
AU  - Bai, Z.
AU  - Imoto, S.
TI  - Investigation of the BERT model on nucleotide sequences with non-standard pre-training and evaluation of different k-mer embeddings
PY  - 2023
T2  - Bioinformatics
VL  - 39
IS  - 10
C7  - btad617
DO  - 10.1093/bioinformatics/btad617
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85175357489&doi=10.1093%2fbioinformatics%2fbtad617&partnerID=40&md5=b8c46719ceaeb06dd924edc67cd1948c
AD  - Division of Health Medical Intelligence, Human Genome Center, The Institute of Medical Science, The University of Tokyo, Minato-ku, Tokyo, 108-8639, Japan
AB  - Motivation: In recent years, pre-training with the transformer architecture has gained significant attention. While this approach has led to notable performance improvements across a variety of downstream tasks, the underlying mechanisms by which pre-training models influence these tasks, particularly in the context of biological data, are not yet fully elucidated. Results: In this study, focusing on the pre-training on nucleotide sequences, we decompose a pre-training model of Bidirectional Encoder Representations from Transformers (BERT) into its embedding and encoding modules to analyze what a pre-trained model learns from nucleotide sequences. Through a comparative study of non-standard pre-training at both the data and model levels, we find that a typical BERT model learns to capture overlapping-consistent k-mer embeddings for its token representation within its embedding module. Interestingly, using the k-mer embeddings pre-trained on random data can yield similar performance in downstream tasks, when compared with those using the k-mer embeddings pre-trained on real biological sequences. We further compare the learned k-mer embeddings with other established k-mer representations in downstream tasks of sequence-based functional prediction. Our experimental results demonstrate that the dense representation of k-mers learned from pre-training can be used as a viable alternative to one-hot encoding for representing nucleotide sequences. Furthermore, integrating the pre-trained k-mer embeddings with simpler models can achieve competitive performance in two typical downstream tasks.  © 2023 The Author(s). Published by Oxford University Press.
KW  - Base Sequence
KW  - Software
KW  - article
KW  - comparative study
KW  - controlled study
KW  - nonhuman
KW  - nucleotide sequence
KW  - prediction
KW  - training
KW  - nucleotide sequence
KW  - software
PB  - Oxford University Press
SN  - 13674803 (ISSN)
C2  - 37815839
LA  - English
J2  - Bioinformatics
M3  - Article
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 1; Correspondence Address: Y.-Z. Zhang; Division of Health Medical Intelligence, Human Genome Center, The Institute of Medical Science, The University of Tokyo, Tokyo, Shirokanedai 4-6-1, Minato-ku, 108-8639, Japan; email: yaozhong@ims.u-tokyo.ac.jp; S. Imoto; Division of Health Medical Intelligence, Human Genome Center, The Institute of Medical Science, The University of Tokyo, Tokyo, Shirokanedai 4-6-1, Minato-ku, 108-8639, Japan; email: imoto@hgc.jp; CODEN: BOINF
ER  -

TY  - JOUR
AU  - Lynch, C.J.
AU  - Jensen, E.J.
AU  - Zamponi, V.
AU  - O’Brien, K.
AU  - Frydenlund, E.
AU  - Gore, R.
TI  - A Structured Narrative Prompt for Prompting Narratives from Large Language Models: Sentiment Assessment of ChatGPT-Generated Narratives and Real Tweets
PY  - 2023
T2  - Future Internet
VL  - 15
IS  - 12
C7  - 375
DO  - 10.3390/fi15120375
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85180546873&doi=10.3390%2ffi15120375&partnerID=40&md5=160fdb7748d6530bf544e05a5d19c754
AD  - Virginia, Modeling, Analysis, and Simulation Center, Old Dominion University, 1030 University Blv, d., Suffolk, 23435, VA, United States
AD  - Computational Modeling and Simulation Engineering Department, Old Dominion University, Norfolk, 23508, VA, United States
AB  - Large language models (LLMs) excel in providing natural language responses that sound authoritative, reflect knowledge of the context area, and can present from a range of varied perspectives. Agent-based models and simulations consist of simulated agents that interact within a simulated environment to explore societal, social, and ethical, among other, problems. Simulated agents generate large volumes of data and discerning useful and relevant content is an onerous task. LLMs can help in communicating agents’ perspectives on key life events by providing natural language narratives. However, these narratives should be factual, transparent, and reproducible. Therefore, we present a structured narrative prompt for sending queries to LLMs, we experiment with the narrative generation process using OpenAI’s ChatGPT, and we assess statistically significant differences across 11 Positive and Negative Affect Schedule (PANAS) sentiment levels between the generated narratives and real tweets using chi-squared tests and Fisher’s exact tests. The narrative prompt structure effectively yields narratives with the desired components from ChatGPT. In four out of forty-four categories, ChatGPT generated narratives which have sentiment scores that were not discernibly different, in terms of statistical significance (alpha level (Formula presented.)), from the sentiment expressed in real tweets. Three outcomes are provided: (1) a list of benefits and challenges for LLMs in narrative generation; (2) a structured prompt for requesting narratives of an LLM chatbot based on simulated agents’ information; (3) an assessment of statistical significance in the sentiment prevalence of the generated narratives compared to real tweets. This indicates significant promise in the utilization of LLMs for helping to connect a simulated agent’s experiences with real people. © 2023 by the authors.
KW  - ChatGPT
KW  - large language models
KW  - narrative generation
KW  - natural language generation
KW  - prompt design
KW  - prompt engineering
KW  - simulation
KW  - structured prompt
KW  - Autonomous agents
KW  - Computational linguistics
KW  - Natural language processing systems
KW  - Simulation platform
KW  - ChatGPT
KW  - Language model
KW  - Large language model
KW  - Narrative generation
KW  - Natural language generation
KW  - Prompt design
KW  - Prompt engineering
KW  - Simulated agents
KW  - Simulation
KW  - Structured prompt
KW  - Computational methods
PB  - Multidisciplinary Digital Publishing Institute (MDPI)
SN  - 19995903 (ISSN)
LA  - English
J2  - Future Internet
M3  - Article
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 1; Correspondence Address: C.J. Lynch; Virginia, Modeling, Analysis, and Simulation Center, Old Dominion University, Suffolk, 1030 University Blv, d., 23435, United States; email: cjlynch@odu.edu
ER  -

TY  - JOUR
AU  - Caglar, U.
AU  - Yildiz, O.
AU  - Meric, A.
AU  - Ayranci, A.
AU  - Yusuf, R.
AU  - Sarilar, O.
AU  - Ozgor, F.
TI  - Evaluating the performance of ChatGPT in answering questions related to benign prostate hyperplasia and prostate cancer
PY  - 2023
T2  - Minerva Urology and Nephrology
VL  - 75
IS  - 6
SP  - 729
EP  - 733
DO  - 10.23736/S2724-6051.23.05450-2
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85180801508&doi=10.23736%2fS2724-6051.23.05450-2&partnerID=40&md5=760cfda02cc9bf25cbb5d4d1656fb1af
AD  - Department of Urology, Haseki Training and Research Hospital, Istanbul, Turkey
AB  - BACKGROUND: The aim of this study was to evaluate the accuracy and reproducibility of ChatGPT’s answers to frequently asked questions about benign prostate hyperplasia (BPH) and prostate cancer. METHODS: Frequently asked questions on the websites of urology associations, hospitals, and social media about prostate cancer and BPH were evaluated. Also, strong recommendation-level data were noted in the recommendations tables of the European Urology Association (EAU) 2022 Guidelines on Prostate Cancer and Management of Non-neurogenic Male Lower Urinary Tract Symptoms sections. All questions were asked in order in ChatGPT Mar 23 Version. All answers were evaluated separately by two specialist urologists and scored between 1-4. RESULTS: Forty questions about BPH and 86 questions about prostate cancer were included in the study. The answers to all BPH-related questions resulted in 90.0% completely correct. This rate for questions about prostate cancer was 94.2%. The completely correct rate in the questions prepared according to the strong recommendations of the EAU guideline was 77.8% for BPH and 76.2% for prostate cancer. The similarity rates of the answers to the repeated questions were 90.0% and 93% for questions related to BPH and prostate cancer, respectively. CONCLUSIONS: ChatGPT has given satisfactory answers to questions about BPH and prostate cancer. Although it has limitations, it can be predicted that it will take an important place in the health sector in the future, as it is a constantly evolving platform. ChatGPT was able to provide helpful information about BPH and prostate cancer, although it is not perfect. It is constantly getting better, and may become an important resource in the healthcare field in the future. © 2023 EDIZIONI MINERVA MEDICA.
KW  - Artificial intelligence
KW  - Health literacy
KW  - Patient medication knowledge
KW  - Prostatic hyperplasia
KW  - Prostatic neoplasms
KW  - Humans
KW  - Hyperplasia
KW  - Male
KW  - Prostate
KW  - Prostatic Hyperplasia
KW  - Prostatic Neoplasms
KW  - Reproducibility of Results
KW  - Article
KW  - ChatGPT
KW  - diagnostic accuracy
KW  - European Association of Urology
KW  - human
KW  - lower urinary tract symptom
KW  - male
KW  - medical society
KW  - prostate cancer
KW  - prostate hypertrophy
KW  - questionnaire
KW  - reproducibility
KW  - social media
KW  - hyperplasia
KW  - prostate
KW  - prostate hypertrophy
KW  - prostate tumor
KW  - reproducibility
PB  - Edizioni Minerva Medica
SN  - 27246051 (ISSN)
C2  - 38126285
LA  - English
J2  - Minerva Urol. Nephrol.
M3  - Article
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 0; Correspondence Address: U. Caglar; Haseki Training and Research Hospital, Uğur Mumcu, Istanbul, No:7. Sultangazi/Istanbul, 34265, Turkey; email: ufukcglr@gmail.com
ER  -

TY  - JOUR
AU  - Song, H.
AU  - Xia, Y.
AU  - Luo, Z.
AU  - Liu, H.
AU  - Song, Y.
AU  - Zeng, X.
AU  - Li, T.
AU  - Zhong, G.
AU  - Li, J.
AU  - Chen, M.
AU  - Zhang, G.
AU  - Xiao, B.
TI  - Evaluating the Performance of Different Large Language Models on Health Consultation and Patient Education in Urolithiasis
PY  - 2023
T2  - Journal of Medical Systems
VL  - 47
IS  - 1
C7  - 125
DO  - 10.1007/s10916-023-02021-3
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85177733374&doi=10.1007%2fs10916-023-02021-3&partnerID=40&md5=56253d9cf8a5815aae962f2a5d3d1217
AD  - Department of Urology, Beijing Tsinghua Changgung Hospital, School of Clinical Medicine, Tsinghua University, 168 Litang Rd, Beijing, 102218, China
AD  - Institute of Urology, School of Clinical Medicine, Tsinghua University, Beijing, 102218, China
AD  - Department of Urology, Zhongda Hospital, Southeast University, 87 Dingjiaqiao, Nanjing, 210009, China
AD  - School of Medicine, Southeast University, Nanjing, 210009, China
AD  - Department of Urology, Sheng Jing Hospital of China Medical University, Shenyang, 110000, China
AB  - Objectives: To evaluate the effectiveness of four large language models (LLMs) (Claude, Bard, ChatGPT4, and New Bing) that have large user bases and significant social attention, in the context of medical consultation and patient education in urolithiasis. Materials and methods: In this study, we developed a questionnaire consisting of 21 questions and 2 clinical scenarios related to urolithiasis. Subsequently, clinical consultations were simulated for each of the four models to assess their responses to the questions. Urolithiasis experts then evaluated the model responses in terms of accuracy, comprehensiveness, ease of understanding, human care, and clinical case analysis ability based on a predesigned 5-point Likert scale. Visualization and statistical analyses were then employed to compare the four models and evaluate their performance. Results: All models yielded satisfying performance, except for Bard, who failed to provide a valid response to Question 13. Claude consistently scored the highest in all dimensions compared with the other three models. ChatGPT4 ranked second in accuracy, with a relatively stable output across multiple tests, but shortcomings were observed in empathy and human caring. Bard exhibited the lowest accuracy and overall performance. Claude and ChatGPT4 both had a high capacity to analyze clinical cases of urolithiasis. Overall, Claude emerged as the best performer in urolithiasis consultations and education. Conclusion: Claude demonstrated superior performance compared with the other three in urolithiasis consultation and education. This study highlights the remarkable potential of LLMs in medical health consultations and patient education, although professional review, further evaluation, and modifications are still required. © 2023, The Author(s), under exclusive licence to Springer Science+Business Media, LLC, part of Springer Nature.
KW  - Artificial intelligence
KW  - ChatGPT
KW  - Health consultation
KW  - Large language model
KW  - Urolithiasis
KW  - Educational Status
KW  - Humans
KW  - Language
KW  - Patient Education as Topic
KW  - Referral and Consultation
KW  - Urolithiasis
KW  - Article
KW  - artificial intelligence
KW  - Bard
KW  - ChatGPT
KW  - ChatGPT4
KW  - Claude
KW  - clinical effectiveness
KW  - comparative study
KW  - consultation
KW  - controlled study
KW  - data accuracy
KW  - data visualization
KW  - electronic consultation
KW  - human
KW  - large language model
KW  - Likert scale
KW  - New Bing
KW  - patient education
KW  - questionnaire
KW  - single blind procedure
KW  - urolithiasis
KW  - educational status
KW  - language
KW  - patient referral
PB  - Springer
SN  - 01485598 (ISSN)
C2  - 37999899
LA  - English
J2  - J. Med. Syst.
M3  - Article
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 0; Correspondence Address: B. Xiao; Department of Urology, Beijing Tsinghua Changgung Hospital, School of Clinical Medicine, Tsinghua University, Beijing, 168 Litang Rd, 102218, China; email: beidaxiaobo@163.com; G. Zhang; Department of Urology, Zhongda Hospital, Southeast University, Nanjing, 87 Dingjiaqiao, 210009, China; email: zgy0879@qq.com; CODEN: JMSYD
ER  -

TY  - JOUR
AU  - Škorić, M.
AU  - Utvić, M.
AU  - Stanković, R.
TI  - Transformer-Based Composite Language Models for Text Evaluation and Classification
PY  - 2023
T2  - Mathematics
VL  - 11
IS  - 22
C7  - 4660
DO  - 10.3390/math11224660
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85178097513&doi=10.3390%2fmath11224660&partnerID=40&md5=49ec22364228ae945ae39344cc74cb77
AD  - Faculty of Mining and Geology, University of Belgrade, Djusina 7, Belgrade, 11120, Serbia
AD  - Faculty of Philology, University of Belgrade, Studentski Trg 3, Belgrade, 11000, Serbia
AB  - Parallel natural language processing systems were previously successfully tested on the tasks of part-of-speech tagging and authorship attribution through mini-language modeling, for which they achieved significantly better results than independent methods in the cases of seven European languages. The aim of this paper is to present the advantages of using composite language models in the processing and evaluation of texts written in arbitrary highly inflective and morphology-rich natural language, particularly Serbian. A perplexity-based dataset, the main asset for the methodology assessment, was created using a series of generative pre-trained transformers trained on different representations of the Serbian language corpus and a set of sentences classified into three groups (expert translations, corrupted translations, and machine translations). The paper describes a comparative analysis of calculated perplexities in order to measure the classification capability of different models on two binary classification tasks. In the course of the experiment, we tested three standalone language models (baseline) and two composite language models (which are based on perplexities outputted by all three standalone models). The presented results single out a complex stacked classifier using a multitude of features extracted from perplexity vectors as the optimal architecture of composite language models for both tasks. © 2023 by the authors.
KW  - composite structures
KW  - language modeling
KW  - language models
KW  - machine learning
KW  - Serbian language
KW  - text classification
PB  - Multidisciplinary Digital Publishing Institute (MDPI)
SN  - 22277390 (ISSN)
LA  - English
J2  - Mathematics
M3  - Article
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 0; Correspondence Address: R. Stanković; Faculty of Mining and Geology, University of Belgrade, Belgrade, Djusina 7, 11120, Serbia; email: ranka.stankovic@rgf.bg.ac.rs
ER  -

TY  - JOUR
AU  - Cadiente, A.
AU  - Chen, J.
AU  - Nguyen, J.
AU  - Sadeghi-Nejad, H.
AU  - Billah, M.
TI  - Artificial Intelligence on the Exam Table: ChatGPT's Advancement in Urology Self-assessment
PY  - 2023
T2  - Urology Practice
VL  - 10
IS  - 6
SP  - 521
EP  - 523
DO  - 10.1097/UPJ.0000000000000446
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85180268127&doi=10.1097%2fUPJ.0000000000000446&partnerID=40&md5=d90b35a675a4fbf98af1de7b71ade6f6
AD  - Hackensack Meridian School of Medicine, Nutley, NJ, United States
AD  - Department of Urology, Hackensack University, Medical Center, Hackensack, NJ, United States
AD  - Department of Urology, NYU, Grossman School of Medicine, New York, NY, United States
KW  - artificial intelligence
KW  - education, medical, continuing
KW  - natural language processing
KW  - urology
KW  - artificial intelligence
KW  - ChatGPT
KW  - diagnostic accuracy
KW  - Editorial
KW  - human
KW  - large language model
KW  - medical education
KW  - natural language processing
KW  - self evaluation
KW  - urology
PB  - Lippincott Williams and Wilkins
SN  - 23520779 (ISSN)
LA  - English
J2  - Urol. Pract.
M3  - Editorial
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 0; Correspondence Address: A. Cadiente; Hackensack Meridian School of Medicine, Nutley, 123 Metro Blvd1, 07110, United States; email: angelo.cadiente@hmhn.org
ER  -

TY  - JOUR
AU  - Caglar, U.
AU  - Yildiz, O.
AU  - Fırat Ozervarli, M.
AU  - Aydin, R.
AU  - Sarilar, O.
AU  - Ozgor, F.
AU  - Ortac, M.
TI  - Assessing the Performance of Chat Generative Pretrained Transformer (ChatGPT) in Answering Andrology-Related Questions
PY  - 2023
T2  - Urology Research and Practice
VL  - 49
IS  - 6
SP  - 365
EP  - 369
DO  - 10.5152/tud.2023.23171
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85178961031&doi=10.5152%2ftud.2023.23171&partnerID=40&md5=2ac726eb670d433c04416df48655a851
AD  - Department of Urology, Haseki Training and Research Hospital, Istanbul, Turkey
AD  - Department of Urology, Istanbul University, Istanbul School of Medicine, Istanbul, Turkey
AB  - Objective: The internet and social media have become primary sources of health information, with men frequently turning to these platforms before seeking professional help. Chat generative pretrained transformer (ChatGPT), an artificial intelligence model developed by OpenAI, has gained popularity as a natural language processing program. The present study evaluated the accuracy and reproducibility of ChatGPT's responses to andrology-related questions. Methods: The study analyzed frequently asked andrology questions from health forums, hospital websites, and social media platforms like YouTube and Instagram. Questions were categorized into topics like male hypogonadism, erectile dysfunction, etc. The European Association of Urology (EAU) guideline recommendations were also included. These questions were input into ChatGPT, and responses were evaluated by 3 experienced urologists who scored them on a scale of 1 to 4. Results: Out of 136 evaluated questions, 108 met the criteria. Of these, 87.9% received correct and adequate answers, 9.3% were correct but insufficient, and 3 responses contained both correct and incorrect information. No question was answered completely wrong. The highest correct answer rates were for disorders of ejaculation, penile curvature, and male hypogonadism. The EAU guideline-based questions achieved a correctness rate of 86.3%. The reproducibility of the answers was over 90%. Conclusion: The study found that ChatGPT provided accurate and reliable answers to over 80% of andrology-related questions. While limitations exist, such as potential out-dated data and inability to understand emotional aspects, ChatGPT's potential in the health-care sector is promising. Collaborating with health-care professionals during artificial intelligence model development could enhance its reliability. © Author(s).
KW  - Andrology
KW  - artificial intelligence
KW  - information sources
PB  - AVES
SN  - 29801478 (ISSN)
LA  - English
J2  - Urol. Res. Pract.
M3  - Article
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 1; Correspondence Address: U. Caglar; Department of Urology, Haseki Training and Research Hospital, Istanbul, Turkey; email: ufukcglr@gmail.com
ER  -

TY  - JOUR
AU  - Kleebayoon, A.
AU  - Wiwanitkit, V.
TI  - Assessing ChatGPT's ability to pass the FRCS orthopaedic part A exam: Correspondence
PY  - 2023
T2  - Surgeon
VL  - 21
IS  - 5
SP  - e301
DO  - 10.1016/j.surge.2023.08.005
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85171180569&doi=10.1016%2fj.surge.2023.08.005&partnerID=40&md5=6661ba5e4884d34dd6a8b1acd1051a40
AD  - Private Academic Consultant, Samraong, Cambodia
AD  - DY Patil Vidhyapeeth, Pune, India
AD  - Joesph Ayobabalola University, Ikeji-Arakeji, Nigeria
KW  - Humans
KW  - Orthopedics
KW  - human
KW  - orthopedics
PB  - Elsevier Ltd
SN  - 1479666X (ISSN)
C2  - 37633756
LA  - English
J2  - Surgeon
M3  - Letter
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 0; Correspondence Address: A. Kleebayoon; Private Academic Consultant, Samraong, Cambodia; email: amnuaykleebai@gmail.com; CODEN: SURGB
ER  -

TY  - JOUR
AU  - Trager, M.H.
AU  - Queen, D.
AU  - Bordone, L.A.
AU  - Geskin, L.J.
AU  - Samie, F.H.
TI  - Assessing ChatGPT responses to common patient queries regarding basal cell carcinoma
PY  - 2023
T2  - Archives of Dermatological Research
VL  - 315
IS  - 10
SP  - 2979
EP  - 2981
DO  - 10.1007/s00403-023-02705-3
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85170070674&doi=10.1007%2fs00403-023-02705-3&partnerID=40&md5=9f1d87c88c67f1ed6b90015b4aaa23f0
AD  - Department of Dermatology, Columbia University Irving Medical Center, Herbert Irving Pavilion, 12th Floor, New York, 10032, NY, United States
KW  - Artificial intelligence
KW  - Basal cell carcinoma
KW  - ChatGPT
KW  - Carcinoma, Basal Cell
KW  - Humans
KW  - Skin Neoplasms
KW  - basal cell carcinoma
KW  - cancer diagnosis
KW  - cancer localization
KW  - cancer patient
KW  - cancer prevention
KW  - cancer radiotherapy
KW  - cancer risk
KW  - cancer size
KW  - cancer surgery
KW  - ChatGPT
KW  - cryotherapy
KW  - cutaneous melanoma
KW  - dermatitis
KW  - dermatologist
KW  - eczema
KW  - epidermis
KW  - human
KW  - Letter
KW  - papule
KW  - risk factor
KW  - sun exposure
KW  - sunburn
KW  - superficial basal cell carcinoma
KW  - topical treatment
KW  - treatment outcome
KW  - ultraviolet radiation
KW  - basal cell carcinoma
KW  - skin tumor
PB  - Institute for Ionics
SN  - 03403696 (ISSN)
C2  - 37668714
LA  - English
J2  - Arch. Dermatol. Res.
M3  - Letter
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 0; Correspondence Address: F.H. Samie; Department of Dermatology, Columbia University Irving Medical Center, New York, Herbert Irving Pavilion, 12th Floor, 10032, United States; email: fs2614@cumc.columbia.edu; CODEN: ADMFA
ER  -

TY  - CONF
AU  - Zhang, C.
AU  - Sun, B.
AU  - Yu, X.
AU  - Xie, Z.
AU  - Zheng, W.
AU  - Iskra, K.A.
AU  - Beckman, P.
AU  - Tao, D.
TI  - Benchmarking and In-depth Performance Study of Large Language Models on Habana Gaudi Processors
PY  - 2023
T2  - ACM International Conference Proceeding Series
SP  - 1759
EP  - 1766
DO  - 10.1145/3624062.3624257
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85178168631&doi=10.1145%2f3624062.3624257&partnerID=40&md5=d25f28da60b2b800581d2ede5cd904f0
AD  - Indiana University, Bloomington, IN, United States
AD  - Stevens Institute of Technology, Hoboken, NJ, United States
AD  - Argonne National Lab, Lemont, IL, United States
AB  - Transformer models have achieved remarkable success in various machine learning tasks but suffer from high computational complexity and resource requirements. The quadratic complexity of the self-attention mechanism further exacerbates these challenges when dealing with long sequences and large datasets. Specialized AI hardware accelerators, such as the Habana GAUDI architecture, offer a promising solution to tackle these issues. GAUDI features a Matrix Multiplication Engine (MME) and a cluster of fully programmable Tensor Processing Cores (TPC). This paper explores the untapped potential of using GAUDI processors to accelerate Transformer-based models, addressing key challenges in the process. Firstly, we provide a comprehensive performance comparison between the MME and TPC components, illuminating their relative strengths and weaknesses. Secondly, we explore strategies to optimize MME and TPC utilization, offering practical insights to enhance computational efficiency. Thirdly, we evaluate the performance of Transformers on GAUDI, particularly in handling long sequences and uncovering performance bottlenecks. Lastly, we evaluate the end-to-end performance of two Transformer-based large language models (LLM) on GAUDI. The contributions of this work encompass practical insights for practitioners and researchers alike. We delve into GAUDI's capabilities for Transformers through systematic profiling, analysis, and optimization exploration. Our study bridges a research gap and offers a roadmap for optimizing Transformer-based model training on the GAUDI architecture. © 2023 ACM.
KW  - Computational efficiency
KW  - Computational linguistics
KW  - Large dataset
KW  - Language model
KW  - Learning tasks
KW  - Long sequences
KW  - Machine-learning
KW  - MAtrix multiplication
KW  - Performance study
KW  - Processing core
KW  - Quadratic complexity
KW  - Resource requirements
KW  - Transformer modeling
KW  - Benchmarking
PB  - Association for Computing Machinery
SN  - 979-840070785-8 (ISBN)
LA  - English
J2  - ACM Int. Conf. Proc. Ser.
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 0; Conference name: 2023 International Conference on High Performance Computing, Network, Storage, and Analysis, SC Workshops 2023; Conference date: 12 November 2023 through 17 November 2023; Conference code: 194341
ER  -

TY  - JOUR
AU  - Lim, B.
AU  - Seth, I.
AU  - Dooreemeah, D.
AU  - Lee, C.H.A.
TI  - Delving into New Frontiers: assessing ChatGPT’s proficiency in revealing uncharted dimensions of general surgery and pinpointing innovations for future advancements
PY  - 2023
T2  - Langenbeck's Archives of Surgery
VL  - 408
IS  - 1
C7  - 446
DO  - 10.1007/s00423-023-03173-z
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85177875282&doi=10.1007%2fs00423-023-03173-z&partnerID=40&md5=e2034eeb846a429e4a6829ada817d193
AD  - Department of Surgery, Peninsula Health, Melbourne, 3199, VIC, Australia
AD  - Central Clinical School at Monash University, The Alfred Centre, 99 Commercial Rd, Melbourne, 3004, VIC, Australia
AD  - Department of Surgery, Bendigo Hospital, 3550, VIC, Australia
AB  - Purpose: The advent of artificial intelligence (AI) has significantly influenced various medical domains, including general surgery. This research aims to assess ChatGPT, an AI language model, in its ability to shed light on the historical facets of general surgery and pinpoint opportunities for innovation. Methods: A series of 7 pertinent questions on field of general surgery was posed to ChatGPT. The AI-generated responses were meticulously examined for their relevance, accuracy, and novelty. Additionally, the study explored the AI’s ability to recognize knowledge gaps and propose inventive solutions. Expert general surgeons and general surgical residents possessing comprehensive research experience assessed ChatGPT’s answers by comparing them to established guidelines and existing literature. Results: ChatGPT presented information that was relevant and accurate, albeit superficial. However, it exhibited convergent thinking and was unable to produce truly groundbreaking ideas to transform general surgery. Instead, it pointed to current popular trends with significant potential for further development. It failed to provide references when prompted and even created references that could not be verified in exhibiting databases. Conclusion: While ChatGPT demonstrated a comprehensive understanding of existing general surgical knowledge and the capacity to generate relevant, evidence-based material, it displayed limitations in producing truly groundbreaking concepts or discoveries beyond current knowledge. These results highlight the necessity of enhancing AI-driven models to facilitate the emergence of new insights and promote synergistic, human-AI partnerships for expediting advancements within the general surgery domain. © 2023, The Author(s), under exclusive licence to Springer-Verlag GmbH Germany, part of Springer Nature.
KW  - Artificial intelligence
KW  - ChatGPT
KW  - General surgery
KW  - Innovation
KW  - Artificial Intelligence
KW  - Databases, Factual
KW  - Humans
KW  - Surgeons
KW  - antibiotic agent
KW  - fluorouracil
KW  - folinic acid
KW  - infusion fluid
KW  - oxaliplatin
KW  - adjuvant chemotherapy
KW  - adjuvant therapy
KW  - appendicitis
KW  - Article
KW  - artificial intelligence
KW  - asepsis
KW  - blood transfusion
KW  - cauterization
KW  - ChatGPT
KW  - colon cancer
KW  - general surgery
KW  - human
KW  - laparoscopic surgery
KW  - machine learning
KW  - minimally invasive surgery
KW  - organ transplantation
KW  - robot assisted surgery
KW  - telemedicine
KW  - artificial intelligence
KW  - factual database
KW  - surgeon
PB  - Springer Science and Business Media Deutschland GmbH
SN  - 14352443 (ISSN)
C2  - 37999815
LA  - English
J2  - Langenbeck's Arch. Surg.
M3  - Article
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 0; Correspondence Address: B. Lim; Department of Surgery, Melbourne, Peninsula Health, 3199, Australia; email: lim.bryan58@gmail.com; CODEN: LASUF
ER  -

TY  - JOUR
AU  - Rao, A.
AU  - Kim, J.
AU  - Kamineni, M.
AU  - Pang, M.
AU  - Lie, W.
AU  - Dreyer, K.J.
AU  - Succi, M.D.
TI  - Evaluating GPT as an Adjunct for Radiologic Decision Making: GPT-4 Versus GPT-3.5 in a Breast Imaging Pilot
PY  - 2023
T2  - Journal of the American College of Radiology
VL  - 20
IS  - 10
SP  - 990
EP  - 997
DO  - 10.1016/j.jacr.2023.05.003
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85163874328&doi=10.1016%2fj.jacr.2023.05.003&partnerID=40&md5=26ea943e83b50a6466ccf40cc6ce0477
AD  - Harvard Medical School, Boston, Massachusetts, United States
AD  - Medically Engineered Solutions in Healthcare, Innovation in Operations Research Center, Massachusetts General Hospital, Boston, Massachusetts, United States
AD  - Harvard Medical School, Boston, Massachusetts; Medically Engineered Solutions in Healthcare, Innovation in Operations Research Center, Massachusetts General Hospital, Boston, Massachusetts; Department of Radiology, Massachusetts General Hospital, Boston, Massachusetts; and Chief Data Science Officer and Chief Imaging Information Officer for Mass General Brigham, Boston, Massachusetts, United States
AD  - Harvard Medical School, Boston, Massachusetts; Medically Engineered Solutions in Healthcare, Innovation in Operations Research Center and Associate Chair of Innovation & Commercialization, Mass General Brigham Enterprise Radiology; Executive Director, MESH Incubator. Massachusetts General Hospital, Boston, Massachusetts; and Department of Radiology, Massachusetts General Hospital, Boston, Massachusetts, United States
AB  - Objective: Despite rising popularity and performance, studies evaluating the use of large language models for clinical decision support are lacking. Here, we evaluate ChatGPT (Generative Pre-trained Transformer)-3.5 and GPT-4’s (OpenAI, San Francisco, California) capacity for clinical decision support in radiology via the identification of appropriate imaging services for two important clinical presentations: breast cancer screening and breast pain. Methods: We compared ChatGPT's responses to the ACR Appropriateness Criteria for breast pain and breast cancer screening. Our prompt formats included an open-ended (OE) and a select all that apply (SATA) format. Scoring criteria evaluated whether proposed imaging modalities were in accordance with ACR guidelines. Three replicate entries were conducted for each prompt, and the average of these was used to determine final scores. Results: Both ChatGPT-3.5 and ChatGPT-4 achieved an average OE score of 1.830 (out of 2) for breast cancer screening prompts. ChatGPT-3.5 achieved a SATA average percentage correct of 88.9%, compared with ChatGPT-4’s average percentage correct of 98.4% for breast cancer screening prompts. For breast pain, ChatGPT-3.5 achieved an average OE score of 1.125 (out of 2) and a SATA average percentage correct of 58.3%, as compared with an average OE score of 1.666 (out of 2) and a SATA average percentage correct of 77.7%. Discussion: Our results demonstrate the eventual feasibility of using large language models like ChatGPT for radiologic decision making, with the potential to improve clinical workflow and responsible use of radiology services. More use cases and greater accuracy are necessary to evaluate and implement such tools. © 2023 American College of Radiology
KW  - AI
KW  - breast imaging
KW  - ChatGPT
KW  - clinical decision making
KW  - clinical decision support
KW  - Breast Neoplasms
KW  - Decision Making
KW  - Female
KW  - Humans
KW  - Mastodynia
KW  - Radiology
KW  - N-hydroxysuccinimide S-acetylthioacetate
KW  - Article
KW  - breast cancer
KW  - breast magnetic resonance imaging
KW  - cancer screening
KW  - ChatGPT
KW  - clinical decision making
KW  - controlled study
KW  - decision making
KW  - decision support system
KW  - feed forward neural network
KW  - female
KW  - human
KW  - mastalgia
KW  - nuclear magnetic resonance imaging
KW  - radiology
KW  - self concept
KW  - breast tumor
KW  - diagnostic imaging
KW  - mastalgia
KW  - radiology
PB  - Elsevier B.V.
SN  - 15461440 (ISSN)
C2  - 37356806
LA  - English
J2  - J. Am. Coll. Radiol.
M3  - Article
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 18; Correspondence Address: M.D. Succi; Massachusetts General Hospital, Department of Radiology, Boston, 55 Fruit Street, 02114, United States; email: msucci@mgh.harvard.edu
ER  -

TY  - JOUR
AU  - Ariyaratne, S.
AU  - Iyengar, K.P.
AU  - Nischal, N.
AU  - Babu, N.C.
AU  - Botchu, R.
TI  - Authors’ response to the Letter to the Editor: Re-evaluating the role of AI in scientific writing: a critical analysis on ChatGPT
PY  - 2023
T2  - Skeletal Radiology
VL  - 52
IS  - 12
SP  - 2489
DO  - 10.1007/s00256-023-04405-5
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85165203727&doi=10.1007%2fs00256-023-04405-5&partnerID=40&md5=2e0521c1bd2fcfd34d14618e98cc1525
AD  - Department of Musculoskeletal Radiology, The Royal Orthopedic Hospital, Bristol Road South, Northfield, Birmingham, United Kingdom
AD  - Department of Orthopedics, Southport and Ormskirk Hospital, Southport, United Kingdom
AD  - Department of Radiology, Holy Family Hospital, New Delhi, India
AD  - Department of Radiology, Srinivas Institute of Medical Sciences & Research Centre, Mukka, Mangalore, India
KW  - artificial intelligence
KW  - author
KW  - awareness
KW  - ChatGPT
KW  - data analysis
KW  - information processing
KW  - interpersonal communication
KW  - language model
KW  - Letter
KW  - medical research
KW  - plagiarism
KW  - publication
KW  - publishing
KW  - sample size
KW  - scientific literature
KW  - scientific writing
KW  - writing
PB  - Springer Science and Business Media Deutschland GmbH
SN  - 03642348 (ISSN)
C2  - 37462695
LA  - English
J2  - Skelet. Radiol.
M3  - Letter
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 0; Correspondence Address: R. Botchu; Department of Musculoskeletal Radiology, The Royal Orthopedic Hospital, Birmingham, Bristol Road South, Northfield, United Kingdom; email: drbrajesh@yahoo.com; CODEN: SKRAD
ER  -

TY  - JOUR
AU  - Leu, B.
AU  - Serițan, G.
AU  - Enache, B.
TI  - A NEW HYBRID MODEL TO EVALUATE THE LOSS OF LIFE OF POWER TRANSFORMERS
PY  - 2023
T2  - Revue Roumaine des Sciences Techniques Serie Electrotechnique et Energetique
VL  - 68
IS  - 3
SP  - 277
EP  - 282
DO  - 10.59277/RRST-EE.2023.68.3.5
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85175248017&doi=10.59277%2fRRST-EE.2023.68.3.5&partnerID=40&md5=f48276bc2faa2468d72a01a2c3bfc441
AD  - Transelectrica, Technical, Energy Efficiency and New Technologies Division, Romania
AD  - Faculty of Electrical Engineering, Politehnica University of Bucharest, Romania
AB  - Following the thermal model for assessing the degradation of transformer units, as advocated by IEEE and IEC standards, existing literature posits that the transformers do not exhibit significant aging at hot-spot temperatures below 90°C. Contrary to this prevailing understanding, the current study demonstrates that when using a model based on insulation resistance measurements, discernible aging of transformers occurs even at these lower hot-spot temperature thresholds. Consequently, this paper introduces a novel evaluative hybrid model for transformer degradation, designed to be applicable across the entire range of hot-spot operational temperatures. © 2023, Publishing House of the Romanian Academy. All rights reserved.
KW  - Aging
KW  - Insulation resistance model
KW  - Loss of life
KW  - Thermal model
KW  - Transformers
PB  - Publishing House of the Romanian Academy
SN  - 00354066 (ISSN)
LA  - English
J2  - Rev. Rom. Sci. Tech. Ser. Electrotech. Energ.
M3  - Article
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 0
ER  -

TY  - CONF
AU  - Maiorino, A.
AU  - Padgett, Z.
AU  - Wang, C.
AU  - Yakubovskiy, M.
AU  - Jiang, P.
TI  - Application and Evaluation of Large Language Models for the Generation of Survey Questions
PY  - 2023
T2  - International Conference on Information and Knowledge Management, Proceedings
SP  - 5244
EP  - 5245
DO  - 10.1145/3583780.3615506
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85178101395&doi=10.1145%2f3583780.3615506&partnerID=40&md5=a2962d054eb81375da1a0b4acf87d5e4
AD  - SurveyMonkey, Milan, Italy
AD  - SurveyMonkey, Gaithersburg, MD, United States
AD  - SurveyMonkey, Ottawa, Canada
AD  - SurveyMonkey Bellevue, Washington, United States
AD  - SurveyMonkey, San Mateo, CA, United States
AB  - Generative Language Models have shown promising results in various domains, and some of the most successful applications are related to "concept expansion", which is the task of generating extensive text based on concise instructions provided through a "seed" prompt. In this presentation we will discuss the recent work conducted by the Data Science team at SurveyMonkey, where we have recently introduced a new feature that harnesses Generative AI models to streamline the survey design process. With this feature users can effortlessly initiate this process by specifying their desired objectives through a prompt, allowing them to automate the creation of surveys that include the critical aspects they wish to investigate. We will share our findings regarding some of the challenges encountered during the development of this feature. These include techniques for conditioning the model outputs, integrating generated text with industry-standard questions, fine-tuning Language Models using semi-synthetic Data Generation techniques, and more. Moreover, we will showcase the Evaluation Methodology that we have developed to measure the quality of the generated surveys across several dimensions. This evaluation process is crucial in ensuring that the generated surveys align well with user expectations and serve their intended purpose effectively. Our goal is to demonstrate the promising potential of Generative Language Models in the context of Survey Research, and we believe that sharing our learnings on these challenges and how we addressed them will be useful for practitioners working with Language Models on similar problems. © 2023 Copyright held by the owner/author(s).
KW  - Generative AI
KW  - Survey Research
KW  - Text Evaluation
KW  - Computational linguistics
KW  - Petroleum reservoir evaluation
KW  - Concept expansions
KW  - Design-process
KW  - Fine tuning
KW  - Generative AI
KW  - Industry standards
KW  - Language model
KW  - Model outputs
KW  - Survey design
KW  - Survey research
KW  - Text evaluation
KW  - Quality control
PB  - Association for Computing Machinery
SN  - 979-840070124-5 (ISBN)
LA  - English
J2  - Int Conf Inf Knowledge Manage
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 0; Conference name: 32nd ACM International Conference on Information and Knowledge Management, CIKM 2023; Conference date: 21 October 2023 through 25 October 2023; Conference code: 193792
ER  -

TY  - JOUR
AU  - Di, H.
AU  - Wen, Y.
TI  - Evaluating the Effectiveness of Artificial Intelligenceepowered Large Language Models Application in Disseminating Appropriate and Readable Health Information in Urology. Letter.
PY  - 2023
T2  - Journal of Urology
VL  - 210
IS  - 5
SP  - 735
EP  - 736
DO  - 10.1097/JU.0000000000003655
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85174830202&doi=10.1097%2fJU.0000000000003655&partnerID=40&md5=2fb4c345a152ad5156115c692448db27
AD  - Department of Pediatrics, Xuzhou Medical University, Xuzhou, China
AD  - Evidence-Based Medicine Research Center, Xuzhou Medical University, Xuzhou, China
AD  - Department of Pediatric Urology, The Affiliated Xuzhou Children’s Hospital of Xuzhou Medical University, Xuzhou, China
KW  - artificial intelligence
KW  - ChatGPT
KW  - human
KW  - large language model
KW  - Letter
KW  - medical information
KW  - urology
PB  - Wolters Kluwer Health
SN  - 00225347 (ISSN)
C2  - 37610000
LA  - English
J2  - J. Urol.
M3  - Letter
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 1; Correspondence Address: Y. Wen; Department of Pediatrics, Xuzhou Medical University, Xuzhou, 221004, China; email: 13270223278@163.com; CODEN: JOURA
ER  -

TY  - JOUR
AU  - Tang, L.
AU  - Sun, Z.
AU  - Idnay, B.
AU  - Nestor, J.G.
AU  - Soroush, A.
AU  - Elias, P.A.
AU  - Xu, Z.
AU  - Ding, Y.
AU  - Durrett, G.
AU  - Rousseau, J.F.
AU  - Weng, C.
AU  - Peng, Y.
TI  - Evaluating large language models on medical evidence summarization
PY  - 2023
T2  - npj Digital Medicine
VL  - 6
IS  - 1
C7  - 158
DO  - 10.1038/s41746-023-00896-7
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85168711933&doi=10.1038%2fs41746-023-00896-7&partnerID=40&md5=3850742d3824cfe49a7b4c106a29c110
AD  - School of Information, The University of Texas at Austin, Austin, TX, United States
AD  - Department of Population Health Sciences, Weill Cornell Medicine, New York, NY, United States
AD  - Department of Biomedical Informatics, Columbia University, New York, NY, United States
AD  - Department of Medicine, Columbia University, New York, NY, United States
AD  - Department of Medicine, Massachusetts General Hospital, Boston, MA, United States
AD  - Department of Computer Science, The University of Texas at Austin, Austin, TX, United States
AD  - Departments of Population Health and Neurology, Dell Medical School, The University of Texas at Austin, Austin, TX, United States
AD  - Department of Neurology, University of Texas Southwestern Medical Center, Dallas, TX, United States
AB  - Recent advances in large language models (LLMs) have demonstrated remarkable successes in zero- and few-shot performance on various downstream tasks, paving the way for applications in high-stakes domains. In this study, we systematically examine the capabilities and limitations of LLMs, specifically GPT-3.5 and ChatGPT, in performing zero-shot medical evidence summarization across six clinical domains. We conduct both automatic and human evaluations, covering several dimensions of summary quality. Our study demonstrates that automatic metrics often do not strongly correlate with the quality of summaries. Furthermore, informed by our human evaluations, we define a terminology of error types for medical evidence summarization. Our findings reveal that LLMs could be susceptible to generating factually inconsistent summaries and making overly convincing or uncertain statements, leading to potential harm due to misinformation. Moreover, we find that models struggle to identify the salient information and are more error-prone when summarizing over longer textual contexts. © 2023, Springer Nature Limited.
KW  - Computational linguistics
KW  - Zero-shot learning
KW  - Automatic evaluation
KW  - Automatic metrics
KW  - Down-stream
KW  - Error prones
KW  - Error types
KW  - Human evaluation
KW  - Language model
KW  - Performance
KW  - Potential harm
KW  - Textual contexts
KW  - article
KW  - human
KW  - human experiment
KW  - language
KW  - misinformation
KW  - nomenclature
KW  - Quality control
PB  - Nature Research
SN  - 23986352 (ISSN)
LA  - English
J2  - npj Digit. Med.
M3  - Article
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 4; Correspondence Address: Y. Peng; Department of Population Health Sciences, Weill Cornell Medicine, New York, United States; email: yip4002@med.cornell.edu; C. Weng; Department of Biomedical Informatics, Columbia University, New York, United States; email: cw2384@cumc.columbia.edu; J.F. Rousseau; Departments of Population Health and Neurology, Dell Medical School, The University of Texas at Austin, Austin, United States; email: justin.rousseau@utsouthwestern.edu
ER  -

TY  - JOUR
AU  - Han, Y.
AU  - Tian, Y.
AU  - Yu, L.
AU  - Gao, Y.
TI  - Economic system forecasting based on temporal fusion transformers: Multi-dimensional evaluation and cross-model comparative analysis
PY  - 2023
T2  - Neurocomputing
VL  - 552
C7  - 126500
DO  - 10.1016/j.neucom.2023.126500
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85164717200&doi=10.1016%2fj.neucom.2023.126500&partnerID=40&md5=4d37591fc9ce537202c34d32af84f9f9
AD  - School of Economics and Management, Harbin Institute of Technology, Shenzhen, 518055, China
AD  - Business School, University of Shanghai for Science and Technology, Shanghai, 200093, China
AD  - Beijing Tengjing Research Institute of Big Data Application Technology, Beijing, 100010, China
AD  - School of Public Policy and Management, Tsinghua University, Beijing, 100084, China
AB  - Although helpful in reducing the uncertainty associated with economic activities, economic forecasting often suffers from low accuracy. Recognizing the high compatibility between deep learning and the nonlinear characteristics of socioeconomic systems, in this paper, we introduce state-of-the-art temporal fusion transformers (TFTs) into the field of economic system forecasting and predict the performance of the Chinese macroeconomic system. Based on an extended analysis of gross final product (GFP) and the intertemporal dynamic relationship between demand-side indicators and output indicators, we establish a scientific economic forecasting framework. To summarize the forecasting characteristics of the TFT algorithm, we compare its one-step and three-step modeling effects in forecasting output indicators with a series of representative benchmark models. According to our proposed four-dimensional evaluation system, the forecasts for China's macroeconomic system provided by the TFT model have obvious advantages in terms of overall stability, forecasting efficiency, reduction of numerical and timing errors, direction accuracy, and turning point accuracy. The forecast results show that China's economy faces a risk of slowing growth in the post-pandemic period. © 2023 Elsevier B.V.
KW  - Cross-model comparative analysis
KW  - Economic system forecasting
KW  - Gross final product
KW  - Multi-dimensional evaluation
KW  - Temporal fusion transformers
KW  - Deep learning
KW  - Economic analysis
KW  - Comparative analyzes
KW  - Cross model
KW  - Cross-model comparative analyse
KW  - Economic forecasting
KW  - Economic system
KW  - Economic system forecasting
KW  - Evaluation models
KW  - Gross final product
KW  - Multi-dimensional evaluations
KW  - Temporal fusion transformer
KW  - accuracy
KW  - algorithm
KW  - Article
KW  - benchmarking
KW  - China
KW  - clinical evaluation
KW  - comparative study
KW  - decision making
KW  - deep learning
KW  - forecasting
KW  - pandemic
KW  - socioeconomics
KW  - temporal analysis
KW  - temporal fusion transformer
KW  - Forecasting
PB  - Elsevier B.V.
SN  - 09252312 (ISSN)
LA  - English
J2  - Neurocomputing
M3  - Article
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 1; Correspondence Address: Y. Gao; School of Public Policy and Management, Tsinghua University, Beijing, 100084, China; email: gao_yuning@tsinghua.edu.cn; CODEN: NRCGE
ER  -

TY  - JOUR
AU  - Saad, A.
AU  - Iyengar, K.P.
AU  - Kurisunkal, V.
AU  - Botchu, R.
TI  - Assessing ChatGPT's ability to pass the FRCS orthopaedic part A exam: A critical analysis
PY  - 2023
T2  - Surgeon
VL  - 21
IS  - 5
SP  - 263
EP  - 266
DO  - 10.1016/j.surge.2023.07.001
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85166647675&doi=10.1016%2fj.surge.2023.07.001&partnerID=40&md5=447b563fbd9903532c0ee308550b7b23
AD  - Department of Orthopedics, Royal Orthopedic Hospital, Birmingham, United Kingdom
AD  - Department of Orthopedics, Southport and Ormskirk Hospital NHS Trust, Southport, United Kingdom
AD  - Department of Orthopedic Oncology, Royal Orthopedic Hospital, Birmingham, United Kingdom
AD  - Department of Musculoskeletal Radiology, Royal Orthopedic Hospital, Birmingham, United Kingdom
AB  - AI technology has made significant advancements in recent years, with the notable development of ChatGPT in November 2022. Users have observed evidence of deductive reasoning, logical thinking, and coherent thought in ChatGPT's responses. This study aimed to determine if ChatGPT has the capability to pass the Orthopaedic Fellow of the Royal College of Surgeons (FRCS Orth) Part A exam. Methods: To assess ChatGPT4's ability to pass the Orthopaedic FRCS Orth Part A exam, a study was conducted using 240 mock FRCS Orth Part A questions. The study evaluated the accuracy of ChatGPT's answers and the response time for each question. Descriptive statistics were employed to analyse the chatbot's performance. Results: The evaluation revealed that ChatGPT4 achieved an overall score of 67.5% on Part A of the exam. However, ChatGPT4 did not meet the overall pass mark required for the FRCS Orth Part A exam. Conclusion: This study demonstrates that ChatGPT was unable to pass the FRCS Orthopaedic examination. Several factors contributed to this outcome, including the lack of critical or high-order thinking abilities, limited clinical expertise, and the inability to meet the rigorous requirements of the exam. © 2023 Royal College of Surgeons of Edinburgh (Scottish charity number SC005317) and Royal College of Surgeons in Ireland
KW  - Artificial intelligence (AI)
KW  - ChatGPT
KW  - FRCS orthopaedics
KW  - Medical exams
KW  - Humans
KW  - Orthopedics
KW  - Physical Examination
KW  - Surgeons
KW  - human
KW  - orthopedics
KW  - physical examination
KW  - surgeon
PB  - Elsevier Ltd
SN  - 1479666X (ISSN)
C2  - 37517980
LA  - English
J2  - Surgeon
M3  - Article
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 2; Correspondence Address: R. Botchu; Department of Musculoskeletal Radiology, The Royal Orthopedic Hospital Bristol Road South Northfield, Birmingham, United Kingdom; email: drbrajesh@yahoo.com; CODEN: SURGB
ER  -

TY  - CONF
AU  - Jin, P.
AU  - Zhang, S.
AU  - Ma, M.
AU  - Li, H.
AU  - Kang, Y.
AU  - Li, L.
AU  - Liu, Y.
AU  - Qiao, B.
AU  - Zhang, C.
AU  - Zhao, P.
AU  - He, S.
AU  - Sarro, F.
AU  - Dang, Y.
AU  - Rajmohan, S.
AU  - Lin, Q.
AU  - Zhang, D.
TI  - Assess and Summarize: Improve Outage Understanding with Large Language Models
PY  - 2023
T2  - ESEC/FSE 2023 - Proceedings of the 31st ACM Joint Meeting European Software Engineering Conference and Symposium on the Foundations of Software Engineering
SP  - 1657
EP  - 1668
DO  - 10.1145/3611643.3613891
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85179432420&doi=10.1145%2f3611643.3613891&partnerID=40&md5=134c0867381b1fad0c6f4c400e1425ed
AD  - Nankai University, China
AD  - Microsoft, China
AD  - Peking University, China
AD  - University College London, United Kingdom
AD  - Microsoft, United States
AB  - Cloud systems have become increasingly popular in recent years due to their flexibility and scalability. Each time cloud computing applications and services hosted on the cloud are affected by a cloud outage, users can experience slow response times, connection issues or total service disruption, resulting in a significant negative business impact. Outages are usually comprised of several concurring events/source causes, and therefore understanding the context of outages is a very challenging yet crucial first step toward mitigating and resolving outages. In current practice, on-call engineers with in-depth domain knowledge, have to manually assess and summarize outages when they happen, which is time-consuming and labor-intensive. In this paper, we first present a large-scale empirical study investigating the way on-call engineers currently deal with cloud outages at Microsoft, and then present and empirically validate a novel approach (dubbed Oasis) to help the engineers in this task. Oasis is able to automatically assess the impact scope of outages as well as to produce human-readable summarization. Specifically, Oasis first assesses the impact scope of an outage by aggregating relevant incidents via multiple techniques. Then, it generates a human-readable summary by leveraging fine-tuned large language models like GPT-3.x. The impact assessment component of Oasis was introduced in Microsoft over three years ago, and it is now widely adopted, while the outage summarization component has been recently introduced, and in this article we present the results of an empirical evaluation we carried out on 18 real-world cloud systems as well as a human-based evaluation with outage owners. The results obtained show that Oasis can effectively and efficiently summarize outages, and lead Microsoft to deploy its first prototype which is currently under experimental adoption by some of the incident teams. © 2023 ACM.
KW  - Cloud Systems
KW  - Large Language Model
KW  - Outage Understanding
KW  - Domain Knowledge
KW  - Engineers
KW  - Petroleum reservoir evaluation
KW  - Cloud systems
KW  - Cloud-computing
KW  - Computing applications
KW  - Computing services
KW  - Human-readable
KW  - Language model
KW  - Large language model
KW  - MicroSoft
KW  - Outage understanding
KW  - Service disruptions
KW  - Computational linguistics
A2  - Chandra S.
A2  - Blincoe K.
A2  - Tonella P.
PB  - Association for Computing Machinery, Inc
SN  - 979-840070327-0 (ISBN)
LA  - English
J2  - ESEC/FSE - Proc. ACM Jt. Meet. Eur. Softw. Eng. Conf. Symp. Found. Softw. Eng.
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 1; Correspondence Address: Q. Lin; Microsoft, China; email: qlin@microsoft.com; Conference name: 31st ACM Joint Meeting European Software Engineering Conference and Symposium on the Foundations of Software Engineering, ESEC/FSE 2023; Conference date: 3 December 2023 through 9 December 2023; Conference code: 195093
ER  -

TY  - CONF
AU  - Ilagan, J.B.
AU  - Ilagan, J.R.
TI  - A prototype of a chatbot for evaluating and refining student startup ideas using a large language model
PY  - 2023
T2  - 31st International Conference on Computers in Education, ICCE 2023 - Proceedings
VL  - 2
SP  - 2
EP  - 7
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85181766561&partnerID=40&md5=92f4aed61eea4297a13c39e39b69eb55
AD  - Ateneo de Manila University, Philippines
AB  - Assessing the soundness of business models is a critical skill for aspiring entrepreneurs and is an essential part of entrepreneurship education. However, evaluating business models can be time-consuming, costly, and subjective. This study describes the design and the prototype of a chatbot as a conversational intelligent tutoring system that assesses and gives feedback on business model soundness using natural language processing techniques and GPT-3.5, a large language model (LLM) trained by OpenAI, to help student co-founders learn and refine their startup ideas. Our method involves indexing articles and rubrics for evaluating technology startup pitches by extracting word embeddings via the OpenAI API. The chatbot accepts descriptions of startup businesses from student co-founders through a Telegram chatbot, and these are formatted as prompts and then fed into GPT-3.5. The responses are formulated by GPT-3 based on another set of prompts instructing the bot to give feedback from three virtual panelists: 1) a harsh judge, 2) a neutral expert, and 3) an optimistic investor. © 2023 Asia-Pacific Society for Computers in Education.
KW  - business model
KW  - chatbot
KW  - conversational intelligent tutoring system
KW  - GPT
KW  - large language model
KW  - LLM
KW  - simulation
KW  - startup panelist
KW  - startups
KW  - Computational linguistics
KW  - Computer aided instruction
KW  - Education computing
KW  - Natural language processing systems
KW  - Business models
KW  - Chatbots
KW  - Conversational intelligent tutoring system
KW  - GPT
KW  - Intelligent tutoring
KW  - Language model
KW  - Large language model
KW  - Simulation
KW  - Startup
KW  - Startup panelist
KW  - Tutoring system
KW  - Students
A2  - Shih J.-L.
A2  - Kashihara A.
A2  - Chen W.
A2  - Chen W.
A2  - Ogata H.
A2  - Baker R.
A2  - Chang B.
A2  - Dianati S.
A2  - Madathil J.
A2  - Yousef A.M.F.
A2  - Yang Y.
A2  - Zarzour H.
PB  - Asia-Pacific Society for Computers in Education
SN  - 978-626968902-6 (ISBN)
LA  - English
J2  - Int. Conf. Comput. Educ., ICCE - Proc.
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 0; Correspondence Address: J.B. Ilagan; Ateneo de Manila University, Philippines; email: jbilagan@ateneo.edu; Conference name: 31st International Conference on Computers in Education, ICCE 2023; Conference date: 4 December 2023 through 8 December 2023; Conference code: 195491
ER  -

TY  - JOUR
AU  - Hermann, C.E.
AU  - Patel, J.M.
AU  - Boyd, L.
AU  - Growdon, W.B.
AU  - Aviki, E.
AU  - Stasenko, M.
TI  - Let's chat about cervical cancer: Assessing the accuracy of ChatGPT responses to cervical cancer questions
PY  - 2023
T2  - Gynecologic Oncology
VL  - 179
SP  - 164
EP  - 168
DO  - 10.1016/j.ygyno.2023.11.008
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85177488163&doi=10.1016%2fj.ygyno.2023.11.008&partnerID=40&md5=611892aa2f896ab4372371126d477130
AD  - New York University Langone Health, Department of Obstetrics and Gynecology, Division of Gynecologic Oncology, New York, NY, United States
AD  - New York University Langone Health Long Island, Department of Obstetrics and Gynecology, Division of Gynecologic Oncology, Mineola, NY, United States
AB  - Objective: To quantify the accuracy of ChatGPT in answering commonly asked questions pertaining to cervical cancer prevention, diagnosis, treatment, and survivorship/quality-of-life (QOL). Methods: ChatGPT was queried with 64 questions adapted from professional society websites and the authors' clinical experiences. The answers were scored by two attending Gynecologic Oncologists according to the following scale: 1) correct and comprehensive, 2) correct but not comprehensive, 3) some correct, some incorrect, and 4) completely incorrect. Scoring discrepancies were resolved by additional reviewers as needed. The proportion of responses earning each score were calculated overall and within each question category. Results: ChatGPT provided correct and comprehensive answers to 34 (53.1%) questions, correct but not comprehensive answers to 19 (29.7%) questions, partially incorrect answers to 10 (15.6%) questions, and completely incorrect answers to 1 (1.6%) question. Prevention and survivorship/QOL had the highest proportion of “correct” scores (scores of 1 or 2) at 22/24 (91.7%) and 15/16 (93.8%), respectively. ChatGPT performed less well in the treatment category, with 15/21 (71.4%) correct scores. It performed the worst in the diagnosis category with only 1/3 (33.3%) correct scores. Conclusion: ChatGPT accurately answers questions about cervical cancer prevention, survivorship, and QOL. It performs less accurately for cervical cancer diagnosis and treatment. Further development of this immensely popular large language model should include physician input before it can be utilized as a tool for Gynecologists or recommended as a patient resource for information on cervical cancer diagnosis and treatment. © 2023 Elsevier Inc.
KW  - Artificial Intelligence
KW  - Cervical cancer
KW  - Cervical dysplasia
KW  - ChatGPT
KW  - HPV vaccination
KW  - Female
KW  - Humans
KW  - Income
KW  - Oncologists
KW  - Physicians
KW  - Quality of Life
KW  - Uterine Cervical Neoplasms
KW  - Human papilloma virus vaccine
KW  - tisotumab vedotin
KW  - accuracy
KW  - Article
KW  - cancer diagnosis
KW  - cancer prevention
KW  - cancer therapy
KW  - ChatGPT
KW  - female
KW  - gynecologic oncologist
KW  - human
KW  - medical society
KW  - personal experience
KW  - quality of life
KW  - survivorship
KW  - uterine cervix cancer
KW  - income
KW  - oncologist
KW  - physician
KW  - quality of life
KW  - uterine cervix tumor
PB  - Academic Press Inc.
SN  - 00908258 (ISSN)
C2  - 37988948
LA  - English
J2  - Gynecol. Oncol.
M3  - Article
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 0; Correspondence Address: C.E. Hermann; NYU Langone Health, Department of OBGYN, Division of Gynecologic Oncology, New York, 240 E 38th St, 20th Floor, 10016, United States; email: catherine.e.hermann@gmail.com; CODEN: GYNOA
ER  -

TY  - JOUR
AU  - Najafali, D.
AU  - Dorafshar, A.H.
TI  - Commentary on: Evaluating Chatbot Efficacy for Answering Frequently Asked Questions in Plastic Surgery: A ChatGPT Case Study Focused on Breast Augmentation
PY  - 2023
T2  - Aesthetic Surgery Journal
VL  - 43
IS  - 10
SP  - 1136
EP  - 1138
DO  - 10.1093/asj/sjad186
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85171392787&doi=10.1093%2fasj%2fsjad186&partnerID=40&md5=2b48a5cf7456d971acccdc2d1d7f4d36
AD  - Carle Illinois College of Medicine, University of Illinois Urbana-Champaign, Urbana, IL, United States
AD  - Division of Plastic and Reconstructive Surgery, Rush University Medical Center, Chicago, IL, United States
KW  - Humans
KW  - Mammaplasty
KW  - Plastic Surgery Procedures
KW  - Surgery, Plastic
KW  - anaplastic large cell lymphoma
KW  - artificial intelligence
KW  - artificial intelligence chatbot
KW  - breast augmentation
KW  - breast implant associated anaplastic large cell lymphoma
KW  - ChatGPT
KW  - human
KW  - major clinical study
KW  - medical informatics
KW  - Note
KW  - online system
KW  - patient education
KW  - plastic surgeon
KW  - plastic surgery
KW  - postoperative complication
KW  - reoperation
KW  - surgical risk
KW  - breast reconstruction
PB  - Oxford University Press
SN  - 1090820X (ISSN)
C2  - 37287210
LA  - English
J2  - Aesthet. Surg. J.
M3  - Note
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 2; Correspondence Address: A.H. Dorafshar; Division of Plastic and Reconstructive Surgery, Rush University Medical Center, Chicago, 60612, United States; email: amir_dorafshar@rush.edu; CODEN: ASJEB
ER  -

TY  - JOUR
AU  - Ray, P.P.
TI  - Re-evaluating the role of AI in scientific writing: a critical analysis on ChatGPT
PY  - 2023
T2  - Skeletal Radiology
VL  - 52
IS  - 12
SP  - 2487
EP  - 2488
DO  - 10.1007/s00256-023-04404-6
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85164949908&doi=10.1007%2fs00256-023-04404-6&partnerID=40&md5=744630c85aece6f578f359a1e62ac8bf
AD  - Department of Computer Applications, Sikkim University, 6th Mile, PO-Tadong, Sikkim, Gangtok, 737102, India
KW  - artificial intelligence
KW  - ChatGPT
KW  - Letter
KW  - scientific literature
KW  - writing
PB  - Springer Science and Business Media Deutschland GmbH
SN  - 03642348 (ISSN)
C2  - 37458781
LA  - English
J2  - Skelet. Radiol.
M3  - Letter
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 0; Correspondence Address: P.P. Ray; Department of Computer Applications, Sikkim University, Gangtok, 6th Mile, PO-Tadong, Sikkim, 737102, India; email: ppray@cus.ac.in; CODEN: SKRAD
ER  -

TY  - CONF
AU  - York, E.
TI  - Evaluating ChatGPT: Generative AI in UX Design and Web Development Pedagogy
PY  - 2023
T2  - Proceedings of the 41st International Conference on Design of Communication, SIGDOC 2023
SP  - 197
EP  - 201
DO  - 10.1145/3615335.3623035
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85178268868&doi=10.1145%2f3615335.3623035&partnerID=40&md5=d5f5f80c86b44637e36fc219f8b6e686
AD  - Clarkson University, United States
AB  - The advent of widely-Accessible generative AI tools and their rapid adoption across industry and education is necessitating large-scale revisions to user experience design and web development pedagogies and curricula, a process that will take some time. This report describes a series of initial experiments using generative AI tools as a student or junior designer or web developer might, sometimes naïvely and sometimes in more sophisticated ways, to complete beginner-level and advanced projects. The report evaluates how ChatGPT performs across three categories of prompts (brainstorming, design, and coding) and assesses the quality of the outputs in order to inform the research design of a larger, ongoing interdisciplinary study in its initial phases and to document the results for instructors or senior members of design and development teams to aid them in assessing the fitness of generative AI for user experience design and web development production.  © 2023 ACM.
KW  - Artificial Intelligence
KW  - Pedagogy
KW  - User experience (UX) design
KW  - Web development
KW  - Curricula
KW  - Web Design
KW  - Design development
KW  - Experience webs
KW  - Large-scales
KW  - Pedagogy
KW  - Three categories
KW  - User experience (UX) design
KW  - User experience design
KW  - Users' experiences
KW  - Web developers
KW  - Web development
KW  - User experience
PB  - Association for Computing Machinery, Inc
SN  - 979-840070336-2 (ISBN)
LA  - English
J2  - Proc. Int. Conf. Des. Commun., SIGDOC
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 0; Correspondence Address: E. York; Clarkson University, United States; email: eyork@clarkson.edu; Conference name: 41st International Conference on Design of Communication, SIGDOC 2023; Conference date: 26 October 2023 through 28 October 2023; Conference code: 193967
ER  -

TY  - JOUR
AU  - Yin, J.
AU  - Dash, S.
AU  - Gounley, J.
AU  - Wang, F.
AU  - Tourassi, G.
TI  - Evaluation of pre-training large language models on leadership-class supercomputers
PY  - 2023
T2  - Journal of Supercomputing
VL  - 79
IS  - 18
SP  - 20747
EP  - 20768
DO  - 10.1007/s11227-023-05479-7
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85162003669&doi=10.1007%2fs11227-023-05479-7&partnerID=40&md5=fd84850f19d9296c2f585b3297d7fdc5
AD  - Oak Ridge National Laboratory, Oak Ridge, TN, United States
AB  - Large language models (LLMs) have arisen rapidly to the center stage of artificial intelligence as the foundation models applicable to many downstream learning tasks. However, how to effectively build, train, and serve such models for many high-stake and first-principle-based scientific use cases are both of great interests and of great challenges. Moreover, pre-training LLMs with billions or even trillions of parameters can be prohibitively expensive not just for academic institutions, but also for well-funded industrial and government labs. Furthermore, the energy cost and the environmental impact of developing LLMs must be kept in mind. In this work, we conduct a first-of-its-kind performance analysis to understand the time and energy cost of pre-training LLMs on the Department of Energy (DOE)’s leadership-class supercomputers. Employing state-of-the-art distributed training techniques, we evaluate the computational performance of various parallelization approaches at scale for a range of model sizes, and establish a projection model for the cost of full training. Our findings provide baseline results, best practices, and heuristics for pre-training such large models that should be valuable to HPC community at large. We also offer insights and optimization strategies for using the first exascale computing system, Frontier, to train models of the size of GPT-3 and beyond. © 2023, The Author(s), under exclusive licence to Springer Science+Business Media, LLC, part of Springer Nature.
KW  - AI foundation model
KW  - Distributed training
KW  - Performance analysis
KW  - Computational linguistics
KW  - Cost benefit analysis
KW  - Environmental impact
KW  - AI foundation model
KW  - Distributed training
KW  - Down-stream
KW  - Energy cost
KW  - First principles
KW  - Foundation models
KW  - Language model
KW  - Learning tasks
KW  - Performances analysis
KW  - Pre-training
KW  - Supercomputers
PB  - Springer
SN  - 09208542 (ISSN)
LA  - English
J2  - J Supercomput
M3  - Article
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 0; Correspondence Address: J. Yin; Oak Ridge National Laboratory, Oak Ridge, United States; email: yinj@ornl.gov; CODEN: JOSUE
ER  -

TY  - JOUR
AU  - Plevris, V.
AU  - Papazafeiropoulos, G.
AU  - Jiménez Rios, A.
TI  - Chatbots Put to the Test in Math and Logic Problems: A Comparison and Assessment of ChatGPT-3.5, ChatGPT-4, and Google Bard
PY  - 2023
T2  - AI (Switzerland)
VL  - 4
IS  - 4
SP  - 949
EP  - 969
DO  - 10.3390/ai4040048
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85180275467&doi=10.3390%2fai4040048&partnerID=40&md5=5586c5be25e52745bd6797698882e2b1
AD  - Department of Civil and Environmental Engineering, Qatar University, Doha P.O. Box 2713, Qatar
AD  - School of Civil Engineering, National Technical University of Athens, Athens, 15780, Greece
AD  - Department of Built Environment, Oslo Metropolitan University, Oslo, 0166, Norway
AB  - In an age where artificial intelligence is reshaping the landscape of education and problem solving, our study unveils the secrets behind three digital wizards, ChatGPT-3.5, ChatGPT-4, and Google Bard, as they engage in a thrilling showdown of mathematical and logical prowess. We assess the ability of the chatbots to understand the given problem, employ appropriate algorithms or methods to solve it, and generate coherent responses with correct answers. We conducted our study using a set of 30 questions. These questions were carefully crafted to be clear, unambiguous, and fully described using plain text only. Each question has a unique and well-defined correct answer. The questions were divided into two sets of 15: Set A consists of “Original” problems that cannot be found online, while Set B includes “Published” problems that are readily available online, often with their solutions. Each question was presented to each chatbot three times in May 2023. We recorded and analyzed their responses, highlighting their strengths and weaknesses. Our findings indicate that chatbots can provide accurate solutions for straightforward arithmetic, algebraic expressions, and basic logic puzzles, although they may not be consistently accurate in every attempt. However, for more complex mathematical problems or advanced logic tasks, the chatbots’ answers, although they appear convincing, may not be reliable. Furthermore, consistency is a concern as chatbots often provide conflicting answers when presented with the same question multiple times. To evaluate and compare the performance of the three chatbots, we conducted a quantitative analysis by scoring their final answers based on correctness. Our results show that ChatGPT-4 performs better than ChatGPT-3.5 in both sets of questions. Bard ranks third in the original questions of Set A, trailing behind the other two chatbots. However, Bard achieves the best performance, taking first place in the published questions of Set B. This is likely due to Bard’s direct access to the internet, unlike the ChatGPT chatbots, which, due to their designs, do not have external communication capabilities. © 2023 by the authors.
KW  - AI
KW  - chatbot
KW  - ChatGPT
KW  - Google Bard
KW  - GPT-3.5
KW  - GPT-4
KW  - logic
KW  - mathematics
PB  - Multidisciplinary Digital Publishing Institute (MDPI)
SN  - 26732688 (ISSN)
LA  - English
J2  - AI.
M3  - Article
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 1; Correspondence Address: A. Jiménez Rios; Department of Built Environment, Oslo Metropolitan University, Oslo, 0166, Norway; email: alejand@oslomet.no
ER  -

TY  - CONF
AU  - Cai, W.
AU  - Huang, L.
AU  - Zou, Z.
TI  - RoboAuditor: Goal-Oriented Robotic System for Assessing Energy-intensive Indoor Appliance via Visual Language Models
PY  - 2023
T2  - BuildSys 2023 - Proceedings of the10th ACM International Conference on Systems for Energy-Efficient Buildings, Cities, and Transportation
SP  - 130
EP  - 139
DO  - 10.1145/3600100.3623739
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85179518953&doi=10.1145%2f3600100.3623739&partnerID=40&md5=64c2695462e0727522d20b66832f484f
AD  - The University of British Columbia, Vancouver, BC, Canada
AB  - Energy auditing is a crucial step in building retrofitting to enhance building energy efficiency. However, auditing tasks, such as profiling energy-consuming appliances in buildings, rely heavily on human inspectors, resulting in a time- and capital-intensive process. To this end, we propose an autonomous robotic system, dubbed RoboAuditor, for identifying and localizing energy-intensive appliances in buildings given text queries from humans. RoboAuditor utilizes visual language models to predict relevance scores between text queries and observed images for goal selection in robot navigation. It then automatically identifies and localizes queried appliances while self-navigating with efficient navigational strategies. For evaluation, we deploy the proposed robotic system on a wheeled robot equipped with an RGB-D camera and run auditing tests in 12 residential buildings in 3D simulation. These buildings exhibit diverse room counts, appliance quantities, and navigable areas, and they all feature energy-intensive appliances, such as air conditioners, heaters, dishwashers, and refrigerators. We conduct two groups of experiments: the first group uses the relevance score, and the second serves as a control group without the relevance score. Results demonstrate that RoboAuditor detects queried appliances and accurately localizes their positions in buildings with an average success rate of 68.05%, showing a significant margin of 6.8% higher than the control group.  © 2023 ACM.
KW  - deep learning
KW  - Energy auditing
KW  - robotics
KW  - visual-language model
KW  - Air conditioning
KW  - Computational linguistics
KW  - Deep learning
KW  - Energy efficiency
KW  - Robots
KW  - Visual languages
KW  - Control groups
KW  - Deep learning
KW  - Energy
KW  - Energy auditing
KW  - Goal-oriented
KW  - In-buildings
KW  - Relevance score
KW  - Robotic systems
KW  - Text query
KW  - Visual language model
KW  - Buildings
PB  - Association for Computing Machinery, Inc
SN  - 979-840070230-3 (ISBN)
LA  - English
J2  - BuildSys - Proc. the ACM Int. Conf. Syst. Energy-Effic. Build., Cities, Transp.
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 0; Conference name: 10th ACM International Conference on Systems for Energy-Efficient Buildings, Cities, and Transportation, BuildSys 2023; Conference date: 15 November 2023 through 16 November 2023; Conference code: 194666
ER  -

TY  - CONF
AU  - Singh, D.
AU  - Nishane, I.
AU  - Rajendran, R.
TI  - Catalyzing Python Learning: Assessing an LLM-based Conversational Agent
PY  - 2023
T2  - 31st International Conference on Computers in Education, ICCE 2023 - Proceedings
VL  - 2
SP  - 932
EP  - 934
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85181771042&partnerID=40&md5=e6a14e9f1db81e6ebccba63764d7cd1e
AD  - IDPET, Indian Institute of Technology, Bombay, India
AB  - The rapid rise of digital learning platforms has ushered in an era of educational transformation. While these platforms offer the advantage of scalability, they often fall short in facilitating meaningful interaction, which is pivotal for effective learning. Addressing this concern, our study introduces PyGuru 2.0, an innovative online learning environment for Python programming that aligns with the ICAP framework with an advanced conversational agent. We further investigate the interactions between students and a chatbot, employing a qualitative approach to comprehensively explore the diverse ways in which students interact with the chatbot. The interaction categories encompass a wide spectrum, including code assistance, error resolution, and conceptual explanation. In future, we plan to further elaborate on this coding scheme and see its impact on students’ learning outcomes. © 2023 Asia-Pacific Society for Computers in Education.
KW  - Chatbot
KW  - ChatGPT
KW  - ICAP
KW  - PyGuru
KW  - Python Programming
KW  - Computer aided instruction
KW  - E-learning
KW  - High level languages
KW  - Python
KW  - Chatbots
KW  - ChatGPT
KW  - Conversational agents
KW  - Digital-learning
KW  - Effective learning
KW  - ICAP
KW  - Learning platform
KW  - Online learning environment
KW  - Pyguru
KW  - Python programming
KW  - Students
A2  - Shih J.-L.
A2  - Kashihara A.
A2  - Chen W.
A2  - Chen W.
A2  - Ogata H.
A2  - Baker R.
A2  - Chang B.
A2  - Dianati S.
A2  - Madathil J.
A2  - Yousef A.M.F.
A2  - Yang Y.
A2  - Zarzour H.
PB  - Asia-Pacific Society for Computers in Education
SN  - 978-626968902-6 (ISBN)
LA  - English
J2  - Int. Conf. Comput. Educ., ICCE - Proc.
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 0; Correspondence Address: D. Singh; IDPET, Indian Institute of Technology, Bombay, India; email: daeveshsingh@iitb.ac.in; Conference name: 31st International Conference on Computers in Education, ICCE 2023; Conference date: 4 December 2023 through 8 December 2023; Conference code: 195491
ER  -

TY  - JOUR
AU  - Lahat, A.
AU  - Shachar, E.
AU  - Avidan, B.
AU  - Shatz, Z.
AU  - Glicksberg, B.S.
AU  - Klang, E.
TI  - Evaluating the use of large language model in identifying top research questions in gastroenterology
PY  - 2023
T2  - Scientific Reports
VL  - 13
IS  - 1
C7  - 4164
DO  - 10.1038/s41598-023-31412-2
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85150103801&doi=10.1038%2fs41598-023-31412-2&partnerID=40&md5=0822e5fdb1392aca2d6cc947b3031fe1
AD  - Department of Gastroenterology, Chaim Sheba Medical Center, Affiliated to Tel Aviv University, Tel Aviv, Israel
AD  - Hasso Plattner Institute for Digital Health, Icahn School of Medicine at Mount Sinai, New York, NY, United States
AD  - The Sami Sagol AI Hub, ARC Innovation Center, Chaim Sheba Medical Center, Affiliated to Tel-Aviv University, Tel Aviv, Israel
AB  - The field of gastroenterology (GI) is constantly evolving. It is essential to pinpoint the most pressing and important research questions. To evaluate the potential of chatGPT for identifying research priorities in GI and provide a starting point for further investigation. We queried chatGPT on four key topics in GI: inflammatory bowel disease, microbiome, Artificial Intelligence in GI, and advanced endoscopy in GI. A panel of experienced gastroenterologists separately reviewed and rated the generated research questions on a scale of 1–5, with 5 being the most important and relevant to current research in GI. chatGPT generated relevant and clear research questions. Yet, the questions were not considered original by the panel of gastroenterologists. On average, the questions were rated 3.6 ± 1.4, with inter-rater reliability ranging from 0.80 to 0.98 (p < 0.001). The mean grades for relevance, clarity, specificity, and originality were 4.9 ± 0.1, 4.6 ± 0.4, 3.1 ± 0.2, 1.5 ± 0.4, respectively. Our study suggests that Large Language Models (LLMs) may be a useful tool for identifying research priorities in the field of GI, but more work is needed to improve the novelty of the generated research questions. © 2023, The Author(s).
KW  - Artificial Intelligence
KW  - Gastroenterologists
KW  - Gastroenterology
KW  - Humans
KW  - Inflammatory Bowel Diseases
KW  - Reproducibility of Results
KW  - artificial intelligence
KW  - gastroenterologist
KW  - gastroenterology
KW  - human
KW  - inflammatory bowel disease
KW  - reproducibility
PB  - Nature Research
SN  - 20452322 (ISSN)
C2  - 36914821
LA  - English
J2  - Sci. Rep.
M3  - Article
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 23; Correspondence Address: A. Lahat; Department of Gastroenterology, Chaim Sheba Medical Center, Affiliated to Tel Aviv University, Tel Aviv, Israel; email: zokadi@gmail.com
ER  -

TY  - JOUR
AU  - Grm, K.
TI  - Evaluating the capabilities of large language models using machine learning tasks at inference-time
ST  - Vrednotenje sposobnosti velikih jezikovnih modelov z nalogami strojnega učenja v času sklepanja
PY  - 2023
T2  - Elektrotehniski Vestnik/Electrotechnical Review
VL  - 90
IS  - 5
SP  - 247
EP  - 253
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85182401440&partnerID=40&md5=07e4079e768bc77428b7d54dd3bda9b3
AD  - Univerza v Ljubljani, Fakulteta za Elektrotehniko, Tržaška cesta 25, Ljubljana, 1000, Slovenia
AB  - Machine learning is the domain of algorithms capable of learning from data to improve their performance on a task or set of tasks. Common machine learning tasks include classification, regression, and generative modelling. The most common modern example of machine learners in practical use is deep neural networks coupled with an extrinsic optimizer such as stochastic gradient descent. Recently, scaled-up large language models have shown increasing capabilities of in-context meta-learning, which has been used to improve their performance on language tasks through few-shot learning. In this paper, we show that pre-trained large language models can act as machine learners with regard to in-context data, without using extrinsic optimization tools or weight updates. By evaluating the language models' inference time machine learning abilities on synthetic or appropriately transformed datasets, we conclusively show that they're able to model complex relationships between data in the input context. This implies that inference-time machine learning tasks represent a meaningful capability evaluation task for large language models. © 2023 Electrotechnical Society of Slovenia. All rights reserved.
KW  - evaluation methodology
KW  - language models
KW  - machine learning
KW  - Computational linguistics
KW  - Deep neural networks
KW  - Gradient methods
KW  - Learning systems
KW  - Optimization
KW  - Stochastic models
KW  - Classification models
KW  - Classification regression
KW  - Evaluation methodologies
KW  - In contexts
KW  - Language model
KW  - Learning tasks
KW  - Machine learners
KW  - Machine-learning
KW  - Performance
KW  - Time machine
KW  - Stochastic systems
PB  - Electrotechnical Society of Slovenia
SN  - 00135852 (ISSN)
LA  - Slovenian
J2  - Elektroteh Vestn Electrotech Rev
M3  - Article
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 0; Correspondence Address: K. Grm; Univerza v Ljubljani, Fakulteta za Elektrotehniko, Ljubljana, Tržaška cesta 25, 1000, Slovenia; email: klemen.grm@fe.uni-lj.si; CODEN: ELVEA
ER  -

TY  - JOUR
AU  - Lukac, S.
AU  - Dayan, D.
AU  - Fink, V.
AU  - Leinert, E.
AU  - Hartkopf, A.
AU  - Veselinovic, K.
AU  - Janni, W.
AU  - Rack, B.
AU  - Pfister, K.
AU  - Heitmeir, B.
AU  - Ebner, F.
TI  - Evaluating ChatGPT as an adjunct for the multidisciplinary tumor board decision-making in primary breast cancer cases
PY  - 2023
T2  - Archives of Gynecology and Obstetrics
VL  - 308
IS  - 6
SP  - 1831
EP  - 1844
DO  - 10.1007/s00404-023-07130-5
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85164959009&doi=10.1007%2fs00404-023-07130-5&partnerID=40&md5=33f7e5e0e050575395e48cf4e7299953
AD  - Department of Gynecology and Obstetrics, University Hospital Ulm, Prittwitzstr. 43, Ulm, 89075, Germany
AD  - Gynäkologische Gemeinschaftspraxis Freising & Moosburg, Munich, Germany
AB  - Background: As the available information about breast cancer is growing every day, the decision-making process for the therapy is getting more complex. ChatGPT as a transformer-based language model possesses the ability to write scientific articles and pass medical exams. But is it able to support the multidisciplinary tumor board (MDT) in the planning of the therapy of patients with breast cancer? Material and Methods: We performed a pilot study on 10 consecutive cases of breast cancer patients discussed in MDT at our department in January 2023. Included were patients with a primary diagnosis of early breast cancer. The recommendation of MDT was compared with the recommendation of the ChatGPT for particular patients and the clinical score of the agreement was calculated. Results: Results showed that ChatGPT provided mostly general answers regarding chemotherapy, breast surgery, radiation therapy, chemotherapy, and antibody therapy. It was able to identify risk factors for hereditary breast cancer and point out the elderly patient indicated for chemotherapy to evaluate the cost/benefit effect. ChatGPT wrongly identified the patient with Her2 1 + and 2 + (FISH negative) as in need of therapy with an antibody and called endocrine therapy “hormonal treatment”. Conclusions: Support of artificial intelligence by finding individualized and personalized therapy for our patients in the time of rapidly expanding amount of information is looking for the ways in the clinical routine. ChatGPT has the potential to find its spot in clinical medicine, but the current version is not able to provide specific recommendations for the therapy of patients with primary breast cancer. © 2023, The Author(s).
KW  - Artificial intelligence
KW  - Breast cancer
KW  - ChatGPT
KW  - Multidisciplinary tumor board
KW  - Aged
KW  - Antibodies
KW  - Artificial Intelligence
KW  - Breast Neoplasms
KW  - Female
KW  - Humans
KW  - Oncogenes
KW  - Pilot Projects
KW  - aromatase inhibitor
KW  - selective estrogen receptor modulator
KW  - antibody
KW  - adult
KW  - age
KW  - aged
KW  - Article
KW  - breast cancer
KW  - breast surgery
KW  - cancer chemotherapy
KW  - cancer hormone therapy
KW  - cancer immunotherapy
KW  - cancer patient
KW  - cancer radiotherapy
KW  - cancer risk
KW  - ChatGPT
KW  - clinical article
KW  - collaborative care team
KW  - controlled study
KW  - cost benefit analysis
KW  - ductal breast carcinoma in situ
KW  - hereditary breast cancer
KW  - human
KW  - medical decision making
KW  - middle aged
KW  - multidisciplinary tumor board
KW  - pilot study
KW  - risk factor
KW  - treatment planning
KW  - very elderly
KW  - artificial intelligence
KW  - breast tumor
KW  - female
KW  - oncogene
PB  - Springer Science and Business Media Deutschland GmbH
SN  - 09320067 (ISSN)
C2  - 37458761
LA  - English
J2  - Arch. Gynecol. Obstet.
M3  - Article
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 6; Correspondence Address: S. Lukac; Department of Gynecology and Obstetrics, University Hospital Ulm, Ulm, Prittwitzstr. 43, 89075, Germany; email: stefanlukacjr@gmail.com; CODEN: AGOBE
ER  -

TY  - JOUR
AU  - Campbell, D.J.
AU  - Estephan, L.E.
AU  - Mastrolonardo, E.V.
AU  - Amin, D.R.
AU  - Huntley, C.T.
AU  - Boon, M.S.
TI  - Evaluating ChatGPT responses on obstructive sleep apnea for patient education
PY  - 2023
T2  - Journal of Clinical Sleep Medicine
VL  - 19
IS  - 12 December
SP  - 1989
EP  - 1995
DO  - 10.5664/jcsm.10728
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85172189067&doi=10.5664%2fjcsm.10728&partnerID=40&md5=b5d1d451e9f4dc0457a8f6e791120353
AD  - Department of Otolaryngology - Head and Neck Surgery, Thomas Jefferson University Hospitals, Philadelphia, PA, United States
AB  - Study Objectives: We evaluated the quality of ChatGPT responses to questions on obstructive sleep apnea for patient education and assessed how prompting the chatbot influences correctness, estimated grade level, and references of answers. Methods: ChatGPT was queried 4 times with 24 identical questions. Queries differed by initial prompting: no prompting, patient-friendly prompting, physician-level prompting, and prompting for statistics/references. Answers were scored on a hierarchical scale: incorrect, partially correct, correct, correct with either statistic or referenced citation (“correct+"), or correct with both a statistic and citation (“perfect”). Flesch-Kincaid grade level and citation publication years were recorded for answers. Proportions of responses at incremental score thresholds were compared by prompt type using chi-squared analysis. The relationship between prompt type and grade level was assessed using analysis of variance. Results: Across all prompts (n = 96 questions), 69 answers (71.9%) were at least correct. Proportions of responses that were at least partially correct (P = .387) or correct (P = .453) did not differ by prompt; responses that were at least correct+ (P < .001) or perfect (P < .001) did. Statistics/references prompting provided 74/77 (96.1%) references. Responses from patient-friendly prompting had a lower mean grade level (12.45 ± 2.32) than no prompting (14.15 ± 1.59), physician-level prompting (14.27 ± 2.09), and statistics/references prompting (15.00 ± 2.26) (P < .0001). Conclusions: ChatGPToverall provides appropriate answers to most questions on obstructive sleep apnea regardless of prompting. While prompting decreases response grade level, all responses remained above accepted recommendations for presenting medical information to patients. Given ChatGPT’s rapid implementation, sleep experts may seek to further scrutinize its medical literacy and utility for patients. © 2023 American Academy of Sleep Medicine. All rights reserved.
KW  - artificial intelligence
KW  - obstructive sleep apnea
KW  - patient education
KW  - sleep surgery
KW  - Humans
KW  - Patient Education as Topic
KW  - Physicians
KW  - Sleep
KW  - Sleep Apnea, Obstructive
KW  - Software
KW  - Article
KW  - ChatGPT
KW  - human
KW  - patient education
KW  - sleep apnea syndromes
KW  - patient education
KW  - physician
KW  - sleep
KW  - sleep apnea syndromes
KW  - software
PB  - American Academy of Sleep Medicine
SN  - 15509389 (ISSN)
C2  - 37485676
LA  - English
J2  - J. Clin. Sleep Med.
M3  - Article
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 4; Correspondence Address: D.J. Campbell; Department of Otolaryngology - Head and Neck Surgery, Thomas Jefferson University Hospitals, Philadelphia, 925 Chestnut St., Floor 6, 19107, United States; email: djc024@jefferson.edu
ER  -

TY  - JOUR
AU  - Cascella, M.
AU  - Montomoli, J.
AU  - Bellini, V.
AU  - Bignami, E.
TI  - Evaluating the Feasibility of ChatGPT in Healthcare: An Analysis of Multiple Clinical and Research Scenarios
PY  - 2023
T2  - Journal of Medical Systems
VL  - 47
IS  - 1
C7  - 33
DO  - 10.1007/s10916-023-01925-4
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85149502323&doi=10.1007%2fs10916-023-01925-4&partnerID=40&md5=94fb59edc052eb03b543137fa152ae5a
AD  - Department of Anesthesia and Critical Care, Istituto Nazionale Tumori - IRCCS, Fondazione Pascale, Via Mariano Semmola, 53, Naples, 80131, Italy
AD  - Department of Anesthesia and Intensive Care, Infermi Hospital, AUSL Romagna, Viale Settembrini 2, Rimini, 47923, Italy
AD  - Anesthesiology, Critical Care and Pain Medicine Division, Department of Medicine and Surgery, University of Parma, Viale Gramsci 14, Parma, 43126, Italy
AB  - This paper aims to highlight the potential applications and limits of a large language model (LLM) in healthcare. ChatGPT is a recently developed LLM that was trained on a massive dataset of text for dialogue with users. Although AI-based language models like ChatGPT have demonstrated impressive capabilities, it is uncertain how well they will perform in real-world scenarios, particularly in fields such as medicine where high-level and complex thinking is necessary. Furthermore, while the use of ChatGPT in writing scientific articles and other scientific outputs may have potential benefits, important ethical concerns must also be addressed. Consequently, we investigated the feasibility of ChatGPT in clinical and research scenarios: (1) support of the clinical practice, (2) scientific production, (3) misuse in medicine and research, and (4) reasoning about public health topics. Results indicated that it is important to recognize and promote education on the appropriate use and potential pitfalls of AI-based LLMs in medicine. © 2023, The Author(s).
KW  - Artificial intelligence
KW  - ChatGPT
KW  - Clinical resaerch
KW  - Medicine
KW  - Delivery of Health Care
KW  - Educational Status
KW  - Feasibility Studies
KW  - Health Status
KW  - Humans
KW  - Language
KW  - article
KW  - artificial intelligence
KW  - clinical practice
KW  - education
KW  - feasibility study
KW  - human
KW  - human experiment
KW  - language
KW  - public health
KW  - reasoning
KW  - thinking
KW  - writing
KW  - educational status
KW  - feasibility study
KW  - health care delivery
KW  - health status
KW  - language
PB  - Springer
SN  - 01485598 (ISSN)
C2  - 36869927
LA  - English
J2  - J. Med. Syst.
M3  - Article
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 169; Correspondence Address: E. Bignami; Anesthesiology, Critical Care and Pain Medicine Division, Department of Medicine and Surgery, University of Parma, Parma, Viale Gramsci 14, 43126, Italy; email: elenagiovanna.bignami@unipr.it; CODEN: JMSYD
ER  -

TY  - CONF
AU  - Ma, Z.
AU  - Pan, M.
AU  - Wu, W.
AU  - Cheng, K.
AU  - Zhang, J.
AU  - Huang, S.
AU  - Chen, J.
TI  - Food-500 Cap: A Fine-Grained Food Caption Benchmark for Evaluating Vision-Language Models
PY  - 2023
T2  - MM 2023 - Proceedings of the 31st ACM International Conference on Multimedia
SP  - 5674
EP  - 5685
DO  - 10.1145/3581783.3611994
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85179551997&doi=10.1145%2f3581783.3611994&partnerID=40&md5=f22cd4a351817270501869edf6a0654d
AD  - National Key Laboratory for Novel Software Technology, Nanjing University, Nanjing, China
AB  - Vision-language models (VLMs) have shown impressive performance in substantial downstream multi-modal tasks. However, only comparing the fine-tuned performance on downstream tasks leads to the poor interpretability of VLMs, which is adverse to their future improvement. Several prior works have identified this issue and used various probing methods under a zero-shot setting to detect VLMs' limitations, but they all examine VLMs using general datasets instead of specialized ones. In practical applications, VLMs are usually applied to specific scenarios, such as e-commerce and news fields, so the generalization of VLMs in specific domains should be given more attention. In this paper, we comprehensively investigate the capabilities of popular VLMs in a specific field, the food domain. To this end, we build a food caption dataset, Food-500 Cap, which contains 24,700 food images with 494 categories. Each image is accompanied by a detailed caption, including fine-grained attributes of food, such as the ingredient, shape, and color. We also provide a culinary culture taxonomy that classifies each food category based on its geographic origin in order to better analyze the performance differences of VLM in different regions. Experiments on our proposed datasets demonstrate that popular VLMs underperform in the food domain compared with their performance in the general domain. Furthermore, our research reveals severe bias in VLMs' ability to handle food items from different geographic regions. We adopt diverse probing methods and evaluate nine VLMs belonging to different architectures to verify the aforementioned observations. We hope that our study will bring researchers' attention to VLM's limitations when applying them to the domain of food or culinary cultures, and spur further investigations to address this issue. © 2023 ACM.
KW  - evaluation
KW  - food benchmark
KW  - vision-language models
KW  - Computational linguistics
KW  - Down-stream
KW  - Evaluation
KW  - Fine grained
KW  - Food benchmark
KW  - Future improvements
KW  - Interpretability
KW  - Language model
KW  - Multi-modal
KW  - Performance
KW  - Vision-language model
KW  - Zero-shot learning
PB  - Association for Computing Machinery, Inc
SN  - 979-840070108-5 (ISBN)
LA  - English
J2  - MM - Proc. ACM Int. Conf. Multimed.
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 0; Correspondence Address: J. Zhang; National Key Laboratory for Novel Software Technology, Nanjing University, Nanjing, China; email: zjb@nju.edu.cn; S. Huang; National Key Laboratory for Novel Software Technology, Nanjing University, Nanjing, China; email: huangsj@nju.edu.cn; Conference name: 31st ACM International Conference on Multimedia, MM 2023; Conference date: 29 October 2023 through 3 November 2023; Conference code: 194105
ER  -

TY  - JOUR
AU  - Rosoł, M.
AU  - Gąsior, J.S.
AU  - Łaba, J.
AU  - Korzeniewski, K.
AU  - Młyńczak, M.
TI  - Evaluation of the performance of GPT-3.5 and GPT-4 on the Polish Medical Final Examination
PY  - 2023
T2  - Scientific Reports
VL  - 13
IS  - 1
C7  - 20512
DO  - 10.1038/s41598-023-46995-z
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85177645235&doi=10.1038%2fs41598-023-46995-z&partnerID=40&md5=6b6e66ac767bb87fa8e4e58018953378
AD  - Faculty of Mechatronics, Institute of Metrology and Biomedical Engineering, Warsaw University of Technology, Boboli 8 Street, Warsaw, 02-525, Poland
AD  - Department of Pediatric Cardiology and General Pediatrics, Medical University of Warsaw, Warsaw, Poland
AB  - The study aimed to evaluate the performance of two Large Language Models (LLMs): ChatGPT (based on GPT-3.5) and GPT-4 with two temperature parameter values, on the Polish Medical Final Examination (MFE). The models were tested on three editions of the MFE from: Spring 2022, Autumn 2022, and Spring 2023 in two language versions—English and Polish. The accuracies of both models were compared and the relationships between the correctness of answers with the answer’s metrics were investigated. The study demonstrated that GPT-4 outperformed GPT-3.5 in all three examinations regardless of the language used. GPT-4 achieved mean accuracies of 79.7% for both Polish and English versions, passing all MFE versions. GPT-3.5 had mean accuracies of 54.8% for Polish and 60.3% for English, passing none and 2 of 3 Polish versions for temperature parameter equal to 0 and 1 respectively while passing all English versions regardless of the temperature parameter value. GPT-4 score was mostly lower than the average score of a medical student. There was a statistically significant correlation between the correctness of the answers and the index of difficulty for both models. The overall accuracy of both models was still suboptimal and worse than the average for medical students. This emphasizes the need for further improvements in LLMs before they can be reliably deployed in medical settings. These findings suggest an increasing potential for the usage of LLMs in terms of medical education. © 2023, The Author(s).
KW  - alanine aminotransferase
KW  - article
KW  - autumn
KW  - benchmarking
KW  - ChatGPT
KW  - diagnosis
KW  - human
KW  - large language model
KW  - major clinical study
KW  - medical education
KW  - medical student
KW  - spring
KW  - temperature
PB  - Nature Research
SN  - 20452322 (ISSN)
C2  - 37993519
LA  - English
J2  - Sci. Rep.
M3  - Article
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 0; Correspondence Address: M. Rosoł; Faculty of Mechatronics, Institute of Metrology and Biomedical Engineering, Warsaw University of Technology, Warsaw, Boboli 8 Street, 02-525, Poland; email: maciej.rosol.dokt@pw.edu.pl
ER  -

TY  - JOUR
AU  - Ishaaq, N.
AU  - Sohail, S.S.
TI  - Correspondence on “Assessing the Accuracy of Responses by the Language Model ChatGPT to Questions Regarding Bariatric Surgery”
PY  - 2023
T2  - Obesity Surgery
VL  - 33
IS  - 12
SP  - 4159
DO  - 10.1007/s11695-023-06875-x
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85173755501&doi=10.1007%2fs11695-023-06875-x&partnerID=40&md5=5bb359b6987e607b15ef875f0e6351ab
AD  - Department of Computer Science and Engineering, SEST, Jamia Hamdard, New Delhi, India
KW  - Bariatric Surgery
KW  - Humans
KW  - Obesity, Morbid
KW  - bariatric surgery
KW  - ChatGPT
KW  - data accuracy
KW  - human
KW  - language
KW  - Letter
KW  - patient autonomy
KW  - patient education
KW  - morbid obesity
PB  - Springer
SN  - 09608923 (ISSN)
C2  - 37801239
LA  - English
J2  - Obes. Surg.
M3  - Letter
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 0; Correspondence Address: N. Ishaaq; Department of Computer Science and Engineering, SEST, New Delhi, Jamia Hamdard, India; email: namriaishaaq@gmail.com; CODEN: OBSUE
ER  -

TY  - JOUR
AU  - Zalzal, H.G.
AU  - Cheng, J.
AU  - Shah, R.K.
TI  - Evaluating the Current Ability of ChatGPT to Assist in Professional Otolaryngology Education
PY  - 2023
T2  - OTO Open
VL  - 7
IS  - 4
C7  - e94
DO  - 10.1002/oto2.94
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85177676242&doi=10.1002%2foto2.94&partnerID=40&md5=d999f95eb39932983e905aaee2edea99
AD  - Division of Otolaryngology–Head and Neck Surgery, Children's National Hospital, Washington, DC, United States
AD  - Quality, Safety, Analytics, Children's National Hospital, Washington, DC, United States
AB  - Objective: To quantify ChatGPT's concordance with expert Otolaryngologists when posed with high-level questions that require blending rote memorization and critical thinking. Study Design: Cross-sectional survey. Setting: OpenAI's ChatGPT-3.5 Platform. Methods: Two board-certified otolaryngologists (HZ, RS) input 2 sets of 30 text-based questions (open-ended and single-answer multiple-choice) into the ChatGPT-3.5 model. Responses were rated on a scale (correct, partially correct, incorrect) by each Otolaryngologist working simultaneously with the AI model. Interrater agreement percentage was based on binomial distribution for calculating the 95% confidence intervals and performing significance tests. Statistical significance was defined as P <.05 for 2-sided tests. Results: In testing open-ended questions, the ChatGPT model had 56.7% of initially answering questions with complete accuracy, and 86.7% chance of answer with some accuracy (corrected agreement = 80.1%; P <.001). For repeat questions, ChatGPT improved to 73.3% with complete accuracy and 96.7% with some accuracy (corrected agreement = 88.8%; P <.001). For multiple-choice questions, the ChatGPT model performed substantially worse (43.3% correct). Conclusion: ChatGPT currently does not provide reliably accurate responses to sophisticated questions in Otolaryngology. Professional societies must be aware of the potential of this tool and prevent unscrupulous use during test-taking situations and consider guidelines for clinical scenarios. Expert clinical oversight is still necessary for myriad use cases (eg, hallucination). © 2023 The Authors. OTO Open published by Wiley Periodicals LLC on behalf of American Academy of Otolaryngology–Head and Neck Surgery Foundation.
KW  - artificial intelligence
KW  - ChatGPT
KW  - continuing medical education
KW  - large language model
KW  - machine learning
KW  - maintenance of certification
KW  - OpenAI
PB  - John Wiley and Sons Inc
SN  - 2473974X (ISSN)
LA  - English
J2  - OTP Open
M3  - Article
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 0; Correspondence Address: H.G. Zalzal; Division of Otolaryngology, Children's National Medical Center, Washington, 111 Michigan Avenue, NW Suite 3W-800, 20010, United States; email: hzalzal@cnmc.org
ER  -

TY  - JOUR
AU  - Yun, J.Y.
AU  - Kim, D.J.
AU  - Lee, N.
AU  - Kim, E.K.
TI  - A comprehensive evaluation of ChatGPT consultation quality for augmentation mammoplasty: A comparative analysis between plastic surgeons and laypersons
PY  - 2023
T2  - International Journal of Medical Informatics
VL  - 179
C7  - 105219
DO  - 10.1016/j.ijmedinf.2023.105219
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85172710878&doi=10.1016%2fj.ijmedinf.2023.105219&partnerID=40&md5=748c1f36ce2aa71acea9cafb26760980
AD  - Department of Plastic and Reconstructive Surgery, Busan Paik Hospital, Inje University School of Medicine, Busan, South Korea
AD  - Department of Plastic Surgery, Asan Medical Center, University of Ulsan College of Medicine, Seoul, South Korea
AB  - Objectives: ChatGPT has gained significant popularity as a source of healthcare information among the general population. Evaluating the quality of chatbot responses is crucial, requiring comprehensive and qualitative analysis. This study aims to assess the answers provided by ChatGPT during hypothetical breast augmentation consultations across various categories and depths. The evaluation involves the utilization of validated tools and a comparison of scores between plastic surgeons and laypersons. Methods: A panel consisting of five plastic surgeons and five laypersons evaluated ChatGPT's responses to 25 questions spanning consultation, procedure, recovery, and sentiment categories. The DISCERN and PEMAT tools were employed to assess the responses, while emotional context was examined through ten specific questions. Additionally, readability was measured using the Flesch Reading Ease score. Qualitative analysis was performed to identify the overall strengths and weaknesses. Results: Plastic surgeons generally scored lower than laypersons across most domains. Scores for each evaluation domain varied by category, with the consultation category demonstrating lower scores in terms of DISCERN reliability, information quality, and DISCERN score. Plastic surgeons assigned significantly lower overall quality ratings to the procedure category compared to other question categories. They also gave lower emotion scores in the procedure category compared to laypersons. The depth of the questions did not impact the scoring. Conclusions: Existing health information evaluation tools may not be entirely suitable for comprehensively evaluating the quality of individual responses generated by ChatGPT. Consequently, the development and implementation of appropriate evaluation tools to assess the appropriateness and quality of AI consultations are necessary. © 2023 The Authors
KW  - Artificial intelligence
KW  - Consumer health information
KW  - Health literacy
KW  - Internet
KW  - Artificial intelligence
KW  - Chatbots
KW  - Comparative analyzes
KW  - Comprehensive analysis
KW  - Comprehensive evaluation
KW  - Consumer health information
KW  - Evaluation tool
KW  - General population
KW  - Health literacy
KW  - Plastic surgeons
KW  - Qualitative analysis
KW  - article
KW  - artificial intelligence
KW  - breast augmentation
KW  - ChatGPT
KW  - consultation
KW  - consumer health information
KW  - controlled study
KW  - data quality
KW  - emotion
KW  - health literacy
KW  - human
KW  - human experiment
KW  - Internet
KW  - layperson
KW  - plastic surgeon
KW  - qualitative analysis
KW  - reading
KW  - reliability
KW  - Quality control
PB  - Elsevier Ireland Ltd
SN  - 13865056 (ISSN)
LA  - English
J2  - Int. J. Med. Informatics
M3  - Article
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 0; Correspondence Address: E.K. Kim; Department of Plastic Surgery, Asan Medical Center, University of Ulsan College of Medicine, Seoul, Olympic-ro 43gil, Songpa-gu, 05505, South Korea; email: nicekek@korea.com; CODEN: IJMIF
ER  -

TY  - JOUR
AU  - Sun, H.
AU  - Zhang, K.
AU  - Lan, W.
AU  - Gu, Q.
AU  - Jiang, G.
AU  - Yang, X.
AU  - Qin, W.
AU  - Han, D.
TI  - An AI Dietitian for Type 2 Diabetes Mellitus Management Based on Large Language and Image Recognition Models: Preclinical Concept Validation Study
PY  - 2023
T2  - Journal of medical Internet research
VL  - 25
SP  - e51300
DO  - 10.2196/51300
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85176459221&doi=10.2196%2f51300&partnerID=40&md5=ddc73f5fe319d36af55ac61e3d6ef188
AD  - School of Life Science, Beijing University of Chinese Medicine, Beijing, China
AD  - Department of Pediatrics, Peking University Shenzhen Hospital, Shenzhen, China
AB  - BACKGROUND: Nutritional management for patients with diabetes in China is a significant challenge due to the low supply of registered clinical dietitians. To address this, an artificial intelligence (AI)-based nutritionist program that uses advanced language and image recognition models was created. This program can identify ingredients from images of a patient's meal and offer nutritional guidance and dietary recommendations. OBJECTIVE: The primary objective of this study is to evaluate the competence of the models that support this program. METHODS: The potential of an AI nutritionist program for patients with type 2 diabetes mellitus (T2DM) was evaluated through a multistep process. First, a survey was conducted among patients with T2DM and endocrinologists to identify knowledge gaps in dietary practices. ChatGPT and GPT 4.0 were then tested through the Chinese Registered Dietitian Examination to assess their proficiency in providing evidence-based dietary advice. ChatGPT's responses to common questions about medical nutrition therapy were compared with expert responses by professional dietitians to evaluate its proficiency. The model's food recommendations were scrutinized for consistency with expert advice. A deep learning-based image recognition model was developed for food identification at the ingredient level, and its performance was compared with existing models. Finally, a user-friendly app was developed, integrating the capabilities of language and image recognition models to potentially improve care for patients with T2DM. RESULTS: Most patients (182/206, 88.4%) demanded more immediate and comprehensive nutritional management and education. Both ChatGPT and GPT 4.0 passed the Chinese Registered Dietitian examination. ChatGPT's food recommendations were mainly in line with best practices, except for certain foods like root vegetables and dry beans. Professional dietitians' reviews of ChatGPT's responses to common questions were largely positive, with 162 out of 168 providing favorable reviews. The multilabel image recognition model evaluation showed that the Dino V2 model achieved an average F1 score of 0.825, indicating high accuracy in recognizing ingredients. CONCLUSIONS: The model evaluations were promising. The AI-based nutritionist program is now ready for a supervised pilot study. ©Haonan Sun, Kai Zhang, Wei Lan, Qiufeng Gu, Guangxiang Jiang, Xue Yang, Wanli Qin, Dongran Han. Originally published in the Journal of Medical Internet Research (https://www.jmir.org), 09.11.2023.
KW  - AI
KW  - artificial intelligence
KW  - ChatGPT
KW  - deep learning
KW  - diabetes
KW  - diabetic
KW  - diet
KW  - dietary
KW  - dietician
KW  - digital health
KW  - food
KW  - GPT 4.0
KW  - image recognition
KW  - ingredient recognition
KW  - language model
KW  - machine learning
KW  - meal
KW  - meals
KW  - medical nutrition therapy
KW  - natural language processing
KW  - NLP
KW  - nutrition
KW  - nutritional
KW  - recommendation
KW  - Artificial Intelligence
KW  - Diabetes Mellitus, Type 2
KW  - Humans
KW  - Language
KW  - Meals
KW  - Nutritionists
KW  - Pilot Projects
KW  - artificial intelligence
KW  - dietitian
KW  - human
KW  - language
KW  - meal
KW  - non insulin dependent diabetes mellitus
KW  - pilot study
SN  - 14388871 (ISSN)
C2  - 37943581
LA  - English
J2  - J Med Internet Res
M3  - Article
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 0
ER  -

TY  - JOUR
AU  - Li, K.
TI  - From ID:ti0005 the Shaw Bot to ChatGPT An ID:ti0010 Assessment of ChatGPT and Recommendations for Improvement
PY  - 2023
T2  - SHAW
VL  - 43
IS  - 2
SP  - 260
EP  - 281
DO  - 10.5325/shaw.43.2.0260
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85179044120&doi=10.5325%2fshaw.43.2.0260&partnerID=40&md5=d666fd9496680bdaa4a3bef90aab2d6c
AB  - This article assesses the signifi cance of ChatGPT - Chat Generative Pre-trained Transformer as a new tool for Shaw Studies, and provides recommendations to the Beta version. Released on 30 November 2022, ChatGPT has reached 100 million monthly users already in just two months. The potential impact of ChatGPT on Shaw Studies should be reckoned with. To assess this impact of ChatGPT, this article will regard ChatGPT by comparing it to the Shaw Bot developed in-house by our Sagittarius Literature Digitizing project on Bernard Shaw. Basing on the experience gathered when the Shaw Bot was created in the Sagittarius Digitizing Program on Bernard Shaw, this article recognizes the cutting-edge technologies of ChatGPT, and how that can potentially suggest strategic directions to revamp Shaw Studies and performances. At the same time, before ChatGPT becomes a trustworthy tool for Shaw Studies, some bugs have to be fixed.  © 2023 The Pennsylvania State University.
KW  - artifi cial generative intelligence
KW  - Bernard Shaw
KW  - Chatbot
KW  - ChatGPT
KW  - theater
PB  - Penn State University Press
SN  - 07415842 (ISSN)
LA  - English
J2  - SHAW
M3  - Article
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 0
ER  -

TY  - JOUR
AU  - Madrid-García, A.
AU  - Rosales-Rosado, Z.
AU  - Freites-Nuñez, D.
AU  - Pérez-Sancristóbal, I.
AU  - Pato-Cour, E.
AU  - Plasencia-Rodríguez, C.
AU  - Cabeza-Osorio, L.
AU  - Abasolo-Alcázar, L.
AU  - León-Mateos, L.
AU  - Fernández-Gutiérrez, B.
AU  - Rodríguez-Rodríguez, L.
TI  - Harnessing ChatGPT and GPT-4 for evaluating the rheumatology questions of the Spanish access exam to specialized medical training
PY  - 2023
T2  - Scientific Reports
VL  - 13
IS  - 1
C7  - 22129
DO  - 10.1038/s41598-023-49483-6
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85179668958&doi=10.1038%2fs41598-023-49483-6&partnerID=40&md5=ffaabd029fdafe3629373421adc92531
AD  - Grupo de Patología Musculoesquelética, Hospital Clínico San Carlos, Instituto de Investigación Sanitaria del Hospital Clínico San Carlos (IdISSC), Prof. Martin Lagos S/N, Madrid, 28040, Spain
AD  - Reumatología, Hospital Universitario La Paz-IdiPaz, Paseo de La Castellana, 261, Madrid, 28046, Spain
AD  - Medicina Interna, Hospital Universitario del Henares, Avenida de Marie Curie, 0, Madrid, 28822, Spain
AD  - Facultad de Medicina, Universidad Francisco de Vitoria, Carretera Pozuelo, Km 1800, Madrid, 28223, Spain
AD  - Facultad de Medicina, Universidad Complutense de Madrid, Madrid, Spain
AB  - The emergence of large language models (LLM) with remarkable performance such as ChatGPT and GPT-4, has led to an unprecedented uptake in the population. One of their most promising and studied applications concerns education due to their ability to understand and generate human-like text, creating a multitude of opportunities for enhancing educational practices and outcomes. The objective of this study is twofold: to assess the accuracy of ChatGPT/GPT-4 in answering rheumatology questions from the access exam to specialized medical training in Spain (MIR), and to evaluate the medical reasoning followed by these LLM to answer those questions. A dataset, RheumaMIR, of 145 rheumatology-related questions, extracted from the exams held between 2010 and 2023, was created for that purpose, used as a prompt for the LLM, and was publicly distributed. Six rheumatologists with clinical and teaching experience evaluated the clinical reasoning of the chatbots using a 5-point Likert scale and their degree of agreement was analyzed. The association between variables that could influence the models’ accuracy (i.e., year of the exam question, disease addressed, type of question and genre) was studied. ChatGPT demonstrated a high level of performance in both accuracy, 66.43%, and clinical reasoning, median (Q1–Q3), 4.5 (2.33–4.67). However, GPT-4 showed better performance with an accuracy score of 93.71% and a median clinical reasoning value of 4.67 (4.5–4.83). These findings suggest that LLM may serve as valuable tools in rheumatology education, aiding in exam preparation and supplementing traditional teaching methods. © 2023, The Author(s).
KW  - Biological Transport
KW  - Educational Status
KW  - Humans
KW  - Hydrolases
KW  - Language
KW  - Rheumatology
KW  - hydrolase
KW  - educational status
KW  - human
KW  - language
KW  - rheumatology
KW  - transport at the cellular level
PB  - Nature Research
SN  - 20452322 (ISSN)
C2  - 38092821
LA  - English
J2  - Sci. Rep.
M3  - Article
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 0; Correspondence Address: A. Madrid-García; Grupo de Patología Musculoesquelética, Hospital Clínico San Carlos, Instituto de Investigación Sanitaria del Hospital Clínico San Carlos (IdISSC), Madrid, Prof. Martin Lagos S/N, 28040, Spain; email: alfredo.madrid@salud.madrid.org
ER  -

TY  - JOUR
AU  - Liu, B.
AU  - Takahashi, Y.
AU  - Fujiwara, K.
AU  - Imamori, S.
TI  - Stray Loss Evaluation of Power Transformers Using Simplified Air-Core Model With Tank and Frame
PY  - 2023
T2  - IEEE Transactions on Magnetics
VL  - 59
IS  - 11
C7  - 8401606
DO  - 10.1109/TMAG.2023.3288893
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85163760580&doi=10.1109%2fTMAG.2023.3288893&partnerID=40&md5=c8558b762bd3d6ea48ec88abd836a4f2
AD  - Doshisha University, Department of Electrical Engineering, Kyotanabe, 610-0394, Japan
AD  - Fuji Electric Co., Ltd., Advanced Technology Laboratory, Hino, 191-8502, Japan
AB  - This article reports stray loss generated in tanks, frames, and shields of a power transformer, and the shielding effect is qualitatively discussed for its design optimization. First, simplified transformer models composed of an air-core coil, a tank/frame, and a magnetic shield are newly proposed to reproduce stray loss generated in practical oil-filled power transformers. Then, accurate methods of measuring the stray loss in the proposed models were examined. The accuracy of the stray loss estimation based on a finite-element method was verified by comparing it with the measurement results.  © 2023 IEEE.
KW  - Finite-element method
KW  - iron loss
KW  - magnetic shield
KW  - power transformer
KW  - stray loss
KW  - structural steel
KW  - Copper
KW  - Iron
KW  - Power transformers
KW  - Tanks (containers)
KW  - Winding
KW  - Air-core
KW  - Atmospheric modeling
KW  - Core model
KW  - Design optimization
KW  - Iron loss
KW  - Loss measurement
KW  - Magnetic shield
KW  - Shielding effect
KW  - Stray loss
KW  - Structural steels
KW  - Finite element method
PB  - Institute of Electrical and Electronics Engineers Inc.
SN  - 00189464 (ISSN)
LA  - English
J2  - IEEE Trans Magn
M3  - Article
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 0; Correspondence Address: Y. Takahashi; Doshisha University, Department of Electrical Engineering, Kyotanabe, 610-0394, Japan; email: ytakahashi@mail.doshisha.ac.jp; CODEN: IEMGA
ER  -

TY  - JOUR
AU  - Humar, P.
AU  - Asaad, M.
AU  - Bengur, F.B.
AU  - Nguyen, V.
TI  - ChatGPT Is Equivalent to First-Year Plastic Surgery Residents: Evaluation of ChatGPT on the Plastic Surgery In-Service Examination
PY  - 2023
T2  - Aesthetic Surgery Journal
VL  - 43
IS  - 12
SP  - NP1085
EP  - NP1089
DO  - 10.1093/asj/sjad130
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85165621034&doi=10.1093%2fasj%2fsjad130&partnerID=40&md5=8440da768f210688567b9a885bca7e5f
AD  - University of Pittsburgh School of Medicine, Pittsburgh, PA, United States
AD  - University of Pittsburgh Medical Center, Pittsburgh, PA, United States
AD  - Department of Plastic Surgery, University of Pittsburgh, Pittsburgh, PA, United States
AB  - Background: ChatGPT is an artificial intelligence language model developed and released by OpenAI (San Francisco, CA) in late 2022. Objectives: The aim of this study was to evaluate the performance of ChatGPT on the Plastic Surgery In-Service Examination and to compare it to residents' performance nationally. Methods: The Plastic Surgery In-Service Examinations from 2018 to 2022 were used as a question source. For each question, the stem and all multiple-choice options were imported into ChatGPT. The 2022 examination was used to compare the performance of ChatGPT to plastic surgery residents nationally. Results: In total, 1129 questions were included in the final analysis and ChatGPT answered 630 (55.8%) of these correctly. ChatGPT scored the highest on the 2021 exam (60.1%) and on the comprehensive section (58.7%). There were no significant differences regarding questions answered correctly among exam years or among the different exam sections. ChatGPT answered 57% of questions correctly on the 2022 exam. When compared to the performance of plastic surgery residents in 2022, ChatGPT would rank in the 49th percentile for first-year integrated plastic surgery residents, 13th percentile for second-year residents, 5th percentile for third- and fourth-year residents, and 0th percentile for fifth- and sixth-year residents. Conclusions: ChatGPT performs at the level of a first-year resident on the Plastic Surgery In-Service Examination. However, it performed poorly when compared with residents in more advanced years of training. Although ChatGPT has many undeniable benefits and potential uses in the field of healthcare and medical education, it will require additional research to assess its efficacy. © The Author(s) 2023. Published by Oxford University Press on behalf of The Aesthetic Society. All rights reserved.
KW  - Artificial Intelligence
KW  - Humans
KW  - Physical Examination
KW  - Surgery, Plastic
KW  - Article
KW  - ChatGPT
KW  - cohort analysis
KW  - comparative study
KW  - human
KW  - in service training
KW  - multiple choice test
KW  - performance
KW  - plastic surgery
KW  - residency education
KW  - resident
KW  - surgical training
KW  - artificial intelligence
KW  - physical examination
PB  - Oxford University Press
SN  - 1090820X (ISSN)
C2  - 37140001
LA  - English
J2  - Aesthet. Surg. J.
M3  - Article
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 20; Correspondence Address: M. Asaad; Department of Plastic Surgery, University of Pittsburgh Medical Center, Scaife Hall, Pittsburgh, 3550 Terrace Street, Suite 6B, 15261, United States; email: asaadm@upmc.edu; CODEN: ASJEB
ER  -

TY  - JOUR
AU  - Chen, T.C.
AU  - Multala, E.
AU  - Kearns, P.
AU  - Delashaw, J.
AU  - Dumont, A.
AU  - Maraganore, D.
AU  - Wang, A.
TI  - Assessment of ChatGPT’s performance on neurology written board examination questions
PY  - 2023
T2  - BMJ Neurology Open
VL  - 5
IS  - 2
C7  - e000530
DO  - 10.1136/bmjno-2023-000530
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85177455219&doi=10.1136%2fbmjno-2023-000530&partnerID=40&md5=cbd9d5db2ced0e444a9126dace8572f4
AD  - Tulane University School of Medicine, New Orleans, LA, United States
AB  - Background and objectives ChatGPT has shown promise in healthcare. To assess the utility of this novel tool in healthcare education, we evaluated ChatGPT’s performance in answering neurology board exam questions. Methods Neurology board-style examination questions were accessed from BoardVitals, a commercial neurology question bank. ChatGPT was provided a full question prompt and multiple answer choices. First attempts and additional attempts up to three tries were given to ChatGPT to select the correct answer. A total of 560 questions (14 blocks of 40 questions) were used, although any image-based questions were disregarded due to ChatGPT’s inability to process visual input. The artificial intelligence (AI) answers were then compared with human user data provided by the question bank to gauge its performance. Results Out of 509 eligible questions over 14 question blocks, ChatGPT correctly answered 335 questions (65.8%) on the first attempt/iteration and 383 (75.3%) over three attempts/iterations, scoring at approximately the 26th and 50th percentiles, respectively. The highest performing subjects were pain (100%), epilepsy & seizures (85%) and genetic (82%) while the lowest performing subjects were imaging/diagnostic studies (27%), critical care (41%) and cranial nerves (48%). Discussion This study found that ChatGPT performed similarly to its human counterparts. The accuracy of the AI increased with multiple attempts and performance fell within the expected range of neurology resident learners. This study demonstrates ChatGPT’s potential in processing specialised medical information. Future studies would better define the scope to which AI would be able to integrate into medical decision making. © Author(s) (or their employer(s)) 2023.
KW  - Article
KW  - artificial intelligence
KW  - certification
KW  - ChatGPT
KW  - cranial nerve
KW  - diagnostic imaging
KW  - epilepsy
KW  - genetics
KW  - health education
KW  - human
KW  - intensive care
KW  - medical information
KW  - multiple choice test
KW  - neurology
KW  - pain
KW  - pattern recognition
KW  - performance
KW  - resident
KW  - seizure
KW  - translating (language)
PB  - BMJ Publishing Group
SN  - 26326140 (ISSN)
LA  - English
J2  - BMJ Neurol. Open
M3  - Article
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 1; Correspondence Address: A. Wang; Tulane University School of Medicine, New Orleans, United States; email: awang15@tulane.edu
ER  -

TY  - JOUR
AU  - Maroteau, G.
AU  - An, J.-S.
AU  - Murgier, J.
AU  - Hulet, C.
AU  - Ollivier, M.
AU  - Ferreira, A.
TI  - Evaluation of the impact of large language learning models on articles submitted to Orthopaedics & Traumatology: Surgery & Research (OTSR): A significant increase in the use of artificial intelligence in 2023
PY  - 2023
T2  - Orthopaedics and Traumatology: Surgery and Research
VL  - 109
IS  - 8
C7  - 103720
DO  - 10.1016/j.otsr.2023.103720
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85175331851&doi=10.1016%2fj.otsr.2023.103720&partnerID=40&md5=007dc3827bd878ae4888cc44b26d68f6
AD  - Unité Inserm Comète 1075, Department of Orthopaedics and Traumatology, Caen University Hospital, avenue Cote-de-Nacre, Caen, 14000, France
AD  - Tokyo Medical and Dental University, 1 Chome-5-45 Yushima, Tokyo, Bunkyo City, 113-8510, Japan
AD  - Service de chirurgie orthopédique, clinique Aguiléra, 21, rue de l'Estagnas, Biarritz, 64200, France
AD  - Institute of Movement and Locomotion, Department of Orthopaedics and Traumatology, Sainte-Marguerite Hospital, BP 29, 270, boulevard Sainte-Marguerite, Marseille, 13274, France
AD  - Aix-Marseille Unit, Institute for Locomotion, Department of Orthopaedics and Traumatology, CNRS, ISM, Sainte-Marguerite Hospital, AP–HM, Marseille, France
AB  - Introduction: There has been an unprecedented rise is the use of artificial intelligence (AI) amongst medical fields. Recently, a dialogue agent called ChatGPT (Generative Pre-trained Transformer) has grown in popularity through its use of large language models (LLM) to clearly and precisely generate text on demand. However, the impact of AI on the creation of scientific articles is remains unknown. A retrospective study was carried out with the aim of answering the following questions: identify the presence of text generated by LLM before and after the increased usage of ChatGPT in articles submitted in OTSR; determine if the type of article, the year of submission, and the country of origin, influenced the proportion of text generated, at least in part by AI. Material and methods: A total of 390 English articles were submitted to OTSR in January, February and March 2022 (n = 204) and over the same months of 2023 (n = 186) were analyzed. All articles were analyzed using the ZeroGPT tool, which provides an assumed rate of AI use expressed as a percentage. A comparison of the average rate of AI use was carried out between the articles submitted in 2022 and 2023. This comparison was repeated keeping only the articles with the highest percentage of suspected AI use (greater than 10 and 20%). A secondary analysis was carried out to identify risk factors for AI use. Results: The average percentage of suspected LLM use in the entire cohort was 11% ± 6, with 160 articles (41.0%) having a suspected AI rate greater than 10% and 61 (15.6%) with an assumed AI rate greater than 20%. A comparison between articles submitted in 2022 and 2023 revealed a significant increase in the use of these tools after the launch of ChatGPT 3.5 (9.4% in 2022 and 12.6% in 2023 [p = 0.004]). The number of articles with suspected AI rates of greater than 10 and 20% were significantly higher in 2023: >10%: 71 articles (34.8%) versus 89 articles (47.8%) (p = 0.008) and >20%: 21 articles (10.3%) versus 40 articles (21.5%) (p = 0.002). A risk factor analysis for LLLM use, demonstrated that authors of Asian geographic origin, and the submission year 2023 were associated with a higher rate of suspected AI use. An AI rate >20% was associated to Asian geographical origin with an odds ratio of 1.79 (95% CI: 1.03–3.11) (p = 0.029), while the year of submission being 2023 had an odds ratio of 1.7 (95% CI: 1.1–2.5) (p = 0.02). Conclusion: This study highlights a significant increase in the use of LLM in the writing of articles submitted to the OTSR journal after the launch of ChatGPT 3.5. The increasing use of these models raises questions about originality and plagiarism in scientific research. AI offers creative opportunities but also raises ethical and methodological challenges. Level of evidence: III; case control study. © 2023 Elsevier Masson SAS
KW  - Artificial intelligence
KW  - Chatbot
KW  - ChatGPT
KW  - Large language learning models
KW  - Scientific article
KW  - Artificial Intelligence
KW  - Case-Control Studies
KW  - Humans
KW  - Language
KW  - Orthopedics
KW  - Retrospective Studies
KW  - Traumatology
KW  - article
KW  - artificial intelligence
KW  - case control study
KW  - ChatGPT
KW  - controlled study
KW  - geographic origin
KW  - human
KW  - human experiment
KW  - language development
KW  - major clinical study
KW  - orthopedics
KW  - plagiarism
KW  - retrospective study
KW  - risk factor
KW  - secondary analysis
KW  - traumatology
KW  - writing
KW  - artificial intelligence
KW  - language
PB  - Elsevier Masson s.r.l.
SN  - 18770568 (ISSN)
C2  - 37866509
LA  - English
J2  - Orthop. Traumatol.: Surg. Res.
M3  - Article
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 2; Correspondence Address: A. Ferreira; Unité Inserm Comète 1075, Department of Orthopaedics and Traumatology, Caen University Hospital, Caen, avenue Cote-de-Nacre, 14000, France; email: alexandreferreira0891@gmail.com
ER  -

TY  - JOUR
AU  - Davis, R.
AU  - Eppler, M.
AU  - Ayo-Ajibola, O.
AU  - Loh-Doyle, J.C.
AU  - Nabhani, J.
AU  - Samplaski, M.
AU  - Gill, I.
AU  - Cacciamani, G.E.
TI  - Evaluating the Effectiveness of Artificial Intelligence-powered Large Language Models Application in Disseminating Appropriate and Readable Health Information in Urology
PY  - 2023
T2  - The Journal of urology
VL  - 210
IS  - 4
SP  - 688
EP  - 694
DO  - 10.1097/JU.0000000000003615
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85170294600&doi=10.1097%2fJU.0000000000003615&partnerID=40&md5=79fdab25ad4b4cf433637e04fcb0444d
AD  - USC Institute of Urology, Catherine and Joseph Aresty Department of Urology, Keck School of Medicine, University of Southern California, Los Angeles, CA, United States
AD  - AI Center at USC Urology, USC Institute of Urology, University of Southern California, Los Angeles, CA, United States
AB  - PURPOSE: The Internet is a ubiquitous source of medical information, and natural language processors are gaining popularity as alternatives to traditional search engines. However, suitability of their generated content for patients is not well understood. We aimed to evaluate the appropriateness and readability of natural language processor-generated responses to urology-related medical inquiries. MATERIALS AND METHODS: Eighteen patient questions were developed based on Google Trends and were used as inputs in ChatGPT. Three categories were assessed: oncologic, benign, and emergency. Questions in each category were either treatment or sign/symptom-related questions. Three native English-speaking Board-Certified urologists independently assessed appropriateness of ChatGPT outputs for patient counseling using accuracy, comprehensiveness, and clarity as proxies for appropriateness. Readability was assessed using the Flesch Reading Ease and Flesh-Kincaid Reading Grade Level formulas. Additional measures were created based on validated tools and assessed by 3 independent reviewers. RESULTS: Fourteen of 18 (77.8%) responses were deemed appropriate, with clarity having the most 4 and 5 scores (P = .01). There was no significant difference in appropriateness of the responses between treatments and symptoms or between different categories of conditions. The most common reason from urologists for low scores was responses lacking information-sometimes vital information. The mean (SD) Flesch Reading Ease score was 35.5 (SD=10.2) and the mean Flesh-Kincaid Reading Grade Level score was 13.5 (1.74). Additional quality assessment scores showed no significant differences between different categories of conditions. CONCLUSIONS: Despite impressive capabilities, natural language processors have limitations as sources of medical information. Refinement is crucial before adoption for this purpose.
KW  - artificial intelligence
KW  - communication
KW  - health
KW  - signs and symptoms
KW  - therapeutics
KW  - urology
KW  - Artificial Intelligence
KW  - Comprehension
KW  - Health Literacy
KW  - Humans
KW  - Internet
KW  - Language
KW  - Urology
KW  - artificial intelligence
KW  - comprehension
KW  - health literacy
KW  - human
KW  - Internet
KW  - language
KW  - urology
PB  - NLM (Medline)
SN  - 15273792 (ISSN)
C2  - 37428117
LA  - English
J2  - J Urol
M3  - Article
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 9
ER  -

TY  - JOUR
AU  - Brin, D.
AU  - Sorin, V.
AU  - Vaid, A.
AU  - Soroush, A.
AU  - Glicksberg, B.S.
AU  - Charney, A.W.
AU  - Nadkarni, G.
AU  - Klang, E.
TI  - Comparing ChatGPT and GPT-4 performance in USMLE soft skill assessments
PY  - 2023
T2  - Scientific Reports
VL  - 13
IS  - 1
C7  - 16492
DO  - 10.1038/s41598-023-43436-9
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85173017508&doi=10.1038%2fs41598-023-43436-9&partnerID=40&md5=7ccef95aacf40423c0a8f4dd78743e0e
AD  - Department of Diagnostic Imaging, Chaim Sheba Medical Center, Ramat Gan, Israel
AD  - Faculty of Medicine, Tel-Aviv University, Tel-Aviv, Israel
AD  - The Charles Bronfman Institute of Personalized Medicine, Icahn School of Medicine at Mount Sinai, New York, NY, United States
AD  - Division of Data-Driven and Digital Medicine (D3M), Icahn School of Medicine at Mount Sinai, New York, NY, United States
AD  - Hasso Plattner Institute for Digital Health, Icahn School of Medicine at Mount Sinai, New York, NY, United States
AD  - Division of Data-Driven and Digital Medicine (D3M), The Charles Bronfman Institute of Personalized Medicine, Icahn School of Medicine at Mount Sinai, New York, NY, United States
AB  - The United States Medical Licensing Examination (USMLE) has been a subject of performance study for artificial intelligence (AI) models. However, their performance on questions involving USMLE soft skills remains unexplored. This study aimed to evaluate ChatGPT and GPT-4 on USMLE questions involving communication skills, ethics, empathy, and professionalism. We used 80 USMLE-style questions involving soft skills, taken from the USMLE website and the AMBOSS question bank. A follow-up query was used to assess the models’ consistency. The performance of the AI models was compared to that of previous AMBOSS users. GPT-4 outperformed ChatGPT, correctly answering 90% compared to ChatGPT’s 62.5%. GPT-4 showed more confidence, not revising any responses, while ChatGPT modified its original answers 82.5% of the time. The performance of GPT-4 was higher than that of AMBOSS's past users. Both AI models, notably GPT-4, showed capacity for empathy, indicating AI's potential to meet the complex interpersonal, ethical, and professional demands intrinsic to the practice of medicine. © 2023, Springer Nature Limited.
KW  - Artificial Intelligence
KW  - Empathy
KW  - Medicine
KW  - Mental Processes
KW  - artificial intelligence
KW  - empathy
KW  - medicine
KW  - mental function
PB  - Nature Research
SN  - 20452322 (ISSN)
C2  - 37779171
LA  - English
J2  - Sci. Rep.
M3  - Article
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 5; Correspondence Address: D. Brin; Department of Diagnostic Imaging, Chaim Sheba Medical Center, Ramat Gan, Israel; email: dannabrin@gmail.com
ER  -

TY  - JOUR
AU  - Elkhatat, A.M.
TI  - Evaluating the authenticity of ChatGPT responses: a study on text-matching capabilities
PY  - 2023
T2  - International Journal for Educational Integrity
VL  - 19
IS  - 1
C7  - 15
DO  - 10.1007/s40979-023-00137-0
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85167414589&doi=10.1007%2fs40979-023-00137-0&partnerID=40&md5=b2a4fdc16270ac4c63cd31c5cac9ff58
AD  - Department of Chemical Engineering, Qatar University, PO Box 2713, Doha, Qatar
AB  - Academic plagiarism is a pressing concern in educational institutions. With the emergence of artificial intelligence (AI) chatbots, like ChatGPT, potential risks related to cheating and plagiarism have increased. This study aims to investigate the authenticity capabilities of ChatGPT models 3.5 and 4 in generating novel, coherent, and accurate responses that evade detection by text-matching software. The repeatability and reproducibility of both models were analyzed, showing that the generation of responses remains consistent. However, a two-sample t-test revealed insufficient evidence to support a statistically significant difference between the text-matching percentages of both models. Several strategies are proposed to address the challenges posed by AI integration in academic contexts; one probable solution is to promote self-transcendent ideals by implementing honor codes. It is also necessary to consider the restricted knowledge base of AI language models like GPT and address any inaccuracies in generated references. Additionally, designing assignments that extract data from imaged sources and integrating oral discussions into the evaluation process can mitigate the challenges posed by AI integration. However, educators should carefully consider the practical constraints and explore alternative assessment methods to prevent academic misconduct while reaping the benefits of these strategies. © 2023, The Author(s).
KW  - Academic integrity
KW  - Artificial intelligence
KW  - ChatGPT
KW  - Plagiarisim
PB  - BioMed Central Ltd
SN  - 18332595 (ISSN)
LA  - English
J2  - Int.  J.  Educ. Integr.
M3  - Article
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 2; Correspondence Address: A.M. Elkhatat; Department of Chemical Engineering, Qatar University, Doha, PO Box 2713, Qatar; email: ahmed.elkhatat@qu.edu.qa
ER  -

TY  - JOUR
AU  - Nastasi, A.J.
AU  - Courtright, K.R.
AU  - Halpern, S.D.
AU  - Weissman, G.E.
TI  - A vignette-based evaluation of ChatGPT’s ability to provide appropriate and equitable medical advice across care contexts
PY  - 2023
T2  - Scientific Reports
VL  - 13
IS  - 1
C7  - 17885
DO  - 10.1038/s41598-023-45223-y
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85174525261&doi=10.1038%2fs41598-023-45223-y&partnerID=40&md5=4f845881f465a987f7b656340c3c38f1
AD  - Department of Emergency Medicine, University of Pennsylvania, 3400 Spruce Street, Philadelphia, 19104, PA, United States
AD  - Perelman School of Medicine, Palliative and Advanced Illness Research (PAIR) Center, University of Pennsylvania, Philadelphia, PA, United States
AD  - Division of Pulmonary, Allergy, & Critical Care Medicine, Perelman School of Medicine, University of Pennsylvania, Philadelphia, PA, United States
AD  - Perelman School of Medicine, Leonard Davis Institute of Health Economics, University of Pennsylvania, Philadelphia, PA, United States
AD  - Perelman School of Medicine, Penn Palliative Care Program, University of Pennsylvania, Philadelphia, PA, United States
AD  - Perelman School of Medicine, Penn Institute for Biomedical Informatics, University of Pennsylvania, Philadelphia, PA, United States
AB  - ChatGPT is a large language model trained on text corpora and reinforced with human supervision. Because ChatGPT can provide human-like responses to complex questions, it could become an easily accessible source of medical advice for patients. However, its ability to answer medical questions appropriately and equitably remains unknown. We presented ChatGPT with 96 advice-seeking vignettes that varied across clinical contexts, medical histories, and social characteristics. We analyzed responses for clinical appropriateness by concordance with guidelines, recommendation type, and consideration of social factors. Ninety-three (97%) responses were appropriate and did not explicitly violate clinical guidelines. Recommendations in response to advice-seeking questions were completely absent (N = 34, 35%), general (N = 18, 18%), or specific (N = 44, 46%). 53 (55%) explicitly considered social factors like race or insurance status, which in some cases changed clinical recommendations. ChatGPT consistently provided background information in response to medical questions but did not reliably offer appropriate and personalized medical advice. © 2023, Springer Nature Limited.
KW  - Female
KW  - Humans
KW  - Insurance Coverage
KW  - Language
KW  - Social Factors
KW  - Uterus
KW  - female
KW  - human
KW  - insurance
KW  - language
KW  - social aspect
KW  - uterus
PB  - Nature Research
SN  - 20452322 (ISSN)
C2  - 37857839
LA  - English
J2  - Sci. Rep.
M3  - Article
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 0; Correspondence Address: A.J. Nastasi; Department of Emergency Medicine, University of Pennsylvania, Philadelphia, 3400 Spruce Street, 19104, United States; email: Anthony.Nastasi@pennmedicine.upenn.edu
ER  -

TY  - JOUR
AU  - Haman, M.
AU  - Školník, M.
AU  - Šubrt, T.
TI  - Leveraging ChatGPT for Human Behavior Assessment: Potential Implications for Mental Health Care
PY  - 2023
T2  - Annals of Biomedical Engineering
VL  - 51
IS  - 11
SP  - 2362
EP  - 2364
DO  - 10.1007/s10439-023-03269-z
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85161411652&doi=10.1007%2fs10439-023-03269-z&partnerID=40&md5=ae6fe5b64ba5bc9a95e52d0463022abf
AD  - Department of Humanities, Faculty of Economics and Management, Czech University of Life Sciences Prague, Kamýcká 129, Praha-Suchdol, 165 00, Czech Republic
AD  - Department of Systems Engineering, Faculty of Economics and Management, Czech University of Life Sciences Prague, Kamýcká 129, Praha-Suchdol, 165 00, Czech Republic
AB  - This letter explores the capability of AI, specifically OpenAI's ChatGPT, in interpreting human behavior and its potential implications for mental health care. Data were collected from the Reddit forum "AmItheAsshole" (AITA) to assess the congruence between AI's verdict and the collective human opinion on this platform. AITA, with its vast range of interpersonal situations, provides rich insights into human behavioral evaluation and perception. Two key research questions were addressed: the degree of alignment between ChatGPT's judgment and collective verdicts of Redditors, and the consistency of ChatGPT in evaluating the same AITA post repeatedly. The results exhibited a promising level of agreement between ChatGPT and human verdicts. It also demonstrated high consistency across repeated evaluations of the same posts. These findings hint at the significant potential of AI in mental health care provision, underscoring the importance of continued research and development in this field. © 2023, The Author(s) under exclusive licence to Biomedical Engineering Society.
KW  - Behavioral research
KW  - Degree of alignments
KW  - Human behaviors
KW  - Mental health
KW  - Research and development
KW  - Research questions
KW  - behavior assessment
KW  - human
KW  - human experiment
KW  - letter
KW  - mental health care
KW  - Health care
PB  - Springer
SN  - 00906964 (ISSN)
C2  - 37289368
LA  - English
J2  - Ann Biomed Eng
M3  - Letter
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 1; Correspondence Address: M. Haman; Department of Humanities, Faculty of Economics and Management, Czech University of Life Sciences Prague, Praha-Suchdol, Kamýcká 129, 165 00, Czech Republic; email: haman@pef.czu.cz; CODEN: ABMEC
ER  -

TY  - CONF
AU  - Yin, Z.
AU  - Li, D.
AU  - Goldberg, D.W.
TI  - Is ChatGPT a game changer for geocoding - a benchmark for geocoding address parsing techniques
PY  - 2023
T2  - GeoSearch 2023 - Proceedings of the 2nd ACM SIGSPATIAL International Workshop on Searching and Mining Large Collections of Geospatial Data
SP  - 36
EP  - 44
DO  - 10.1145/3615890.3628538
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85181812136&doi=10.1145%2f3615890.3628538&partnerID=40&md5=d56ffdb864651ff1b4a0c9fa72159c30
AD  - Texas A&m University, College Station, TX, United States
AB  - The remarkable success of GPT models across various tasks, including toponymy recognition motivates us to assess the performance of the GPT-3 model in the geocoding address parsing task. To ensure that the evaluation more accurately mirrors performance in real-world scenarios with diverse user input qualities and resolve the pressing need for a 'gold standard' evaluation dataset for geocoding systems, we introduce a benchmark dataset of low-quality address descriptions synthesized based on human input patterns mining from actual input logs of a geocoding system in production. This dataset has 21 different input errors and variations; contains over 239,000 address records that are uniquely selected from streets across all U.S. 50 states and D.C.; and consists of three subsets to be used as training, validation, and testing sets. Building on this, we train and gauge the performance of the GPT-3 model in extracting address components, contrasting its performance with transformer-based and LSTM-based models. The evaluation results indicate that Bidirectional LSTM-CRF model has achieved the best performance over these transformer-based models and GPT-3 model. Transformer-based models demonstrate very comparable results compared to the Bidirectional LSTM-CRF model. The GPT-3 model, though trailing in performance, showcases potential in the address parsing task with few-shot examples, exhibiting room for improvement with additional fine-tuning. We open source the code and data of this presented benchmark1 so that researchers can utilize it for future model development or extend it to evaluate similar tasks, such as document geocoding.  © 2023 Owner/Author(s).
KW  - address parsing
KW  - benchmark
KW  - geocoding
KW  - GPT
KW  - LLM
KW  - NER
KW  - Benchmarking
KW  - Open systems
KW  - Quality control
KW  - Statistical tests
KW  - Address parsing
KW  - Benchmark
KW  - Geo coding
KW  - Geocoding systems
KW  - GPT
KW  - LLM
KW  - Mirror performance
KW  - NER
KW  - Performance
KW  - Real-world scenario
KW  - Long short-term memory
A2  - Li H.
A2  - Cavallaro G.
A2  - Cavallaro G.
A2  - Heras D.B.
A2  - Lunga D.
A2  - Werner M.
A2  - Zufle A.
PB  - Association for Computing Machinery, Inc
SN  - 979-840070352-2 (ISBN)
LA  - English
J2  - GeoSearch - Proc. ACM SIGSPATIAL Int. Workshop Search. Min. Large Collections Geospat. Data
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 0; Conference name: 2nd ACM SIGSPATIAL International Workshop on Searching and Mining Large Collections of Geospatial Data, GeoSearch 2023; Conference code: 195644
ER  -

TY  - JOUR
AU  - Maroteau, G.
AU  - An, J.-S.
AU  - Murgier, J.
AU  - Hulet, C.
AU  - Ollivier, M.
AU  - Ferreira, A.
TI  - Evaluation of the impact of large language learning models on articles submitted to Orthopedics & Traumatology: Surgery & Research (OTSR): A significant increase in the use of artificial intelligence in 2023
ST  - Évaluation de l'impact des large language learning models sur les articles soumis à Orthopedics & Traumatology: Surgery & Research (OTSR) : une augmentation significative de l'utilisation de l'intelligence artificielle en 2023
PY  - 2023
T2  - Revue de Chirurgie Orthopedique et Traumatologique
VL  - 109
IS  - 8
SP  - 1090
EP  - 1095
DO  - 10.1016/j.rcot.2023.10.014
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85177800368&doi=10.1016%2fj.rcot.2023.10.014&partnerID=40&md5=3a80f65293acf5559cac8d99aee7f805
AD  - Department of Orthopedics and Traumatology, Unité Inserm Comète 1075, Caen University Hospital, avenue Côte-de-Nacre, Caen, 14000, France
AD  - Tokyo Medical and Dental University, 1, Chome-5-45 Yushima, Bunkyo City, Tokyo, 113-8510, Japan
AD  - Service de chirurgie orthopédique, clinique Aguiléra, 21, rue de l'Estagnas, Biarritz, 64200, France
AD  - Institute of movement and locomotion Department of Orthopedics and Traumatology, St Marguerite Hospital, 270, boulevard Sainte Marguerite, BP 29, Marseille, 13274, France
AD  - Aix Marseille Unit, APHM, CNRS, ISM, Department of Orthopedics and Traumatology, Sainte-Marguerite Hospital, Institute for Locomotion, Marseille, France
AB  - Introduction: L'essor de l'intelligence artificielle (IA) dans le secteur médical est incontestable. Récemment, un agent de dialogue nommé ChatGPT (generative pre-trained transformer) a été mis en lumière utilisant les large language learning models (LLLM) pour générer du texte de manière précise et claire sur demande. Cependant, l'impact de l'intelligence artificielle sur la création d'articles scientifiques n'est pas connu. Une étude rétrospective a été réalisée avec pour objectif de répondre aux questions suivantes : premièrement, identifier la présence de texte généré par LLLM avant et après la popularisation de ChatGPT dans les articles soumis dans OTSR ; deuxièmement, déterminer si le type d'article, l'année de soumission et le pays d'origine influençaient la proportion de texte généré au moins en partie par l'IA. Matériel et méthode: Un total de 390 articles soumis en anglais à OTSR en janvier, février et mars 2022 (n = 204) et sur les mêmes mois de 2023 (n = 186) ont été analysés. L'ensemble des articles a été analysé à l'aide de l'outil ZeroGPT, qui fournit un taux supposé d'utilisation d'IA exprimé en pourcentage. Une comparaison du taux moyen d'utilisation d'IA a été réalisée entre les articles soumis en 2022 et 2023. Cette comparaison a été répétée en conservant seulement les articles avec pourcentage d'utilisation supposée d'IA les plus importants (supérieur à 10% et 20%). Une analyse secondaire a été réalisée afin d'identifier les facteurs de risque de l'utilisation des IA. Résultats: Le pourcentage moyen d'utilisation suspectée de LLLM dans l'ensemble de la cohorte était de 11% ± 6, avec 160 articles (41,0%) présentant un taux d'IA supposé supérieur à 10% et 61 (15,6%) avec un taux d'IA supposé supérieur à 20%. Une comparaison entre les articles soumis en 2022 et 2023 a révélé une augmentation significative de l'utilisation de ces outils après le lancement de ChatGPT 3,5 (9,4% en 2022 et 12,6% en 2023 [p = 0,004]). Le nombre d'articles avec taux d'IA supposés supérieurs à 10% et 20% était significativement plus élevé en 2023 : > 10% : 71 articles soit 34,8% vs 89 articles soit 47,8% (p = 0,008) et > 20% : 21 articles soit 10,3% vs 40 articles soit 21,5% (p = 0,002). Une analyse des facteurs de risque de l'utilisation des LLLM a montré que l'origine géographique asiatique des auteurs et l'année de soumission 2023 étaient associées à un taux d'utilisation supposée d'IA plus élevé (taux d'IA > à 20% origine géographique asiatique : odds ratio [OR] = 1,79 [IC95% : 1,03-3,11] [p = 0,029] ; année de soumission : 2023 ; OR = 1,7 [IC95% :1,1-2,5] [p = 0,02]). Conclusion: Cette étude met en évidence une augmentation significative de l'utilisation des LLLM dans la rédaction des articles soumis à la revue OTSR après le lancement de ChatGPT 3,5. L'utilisation croissante de ces modèles pose des questions sur l'originalité et le plagiat dans la recherche scientifique. L'IA offre des opportunités créatives mais soulève également des défis éthiques et méthodologiques. Niveau de preuve: III ; étude cas témoin. © 2023 Elsevier Masson SAS
KW  - Article scientifique
KW  - Chatbot
KW  - ChatGPT
KW  - Grands modèles d''apprentissage de la langue
KW  - Intelligence artificielle
KW  - Article
KW  - artificial intelligence
KW  - case control study
KW  - ChatGPT
KW  - cohort analysis
KW  - computer language
KW  - controlled study
KW  - cross-sectional study
KW  - English (language)
KW  - geographic origin
KW  - human
KW  - information processing
KW  - language development
KW  - orthopedics
KW  - traumatology
KW  - univariate analysis
PB  - Elsevier Masson s.r.l.
SN  - 18770517 (ISSN)
LA  - English
J2  - Rev. Chir. Orthop. Traumatol.
M3  - Article
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 0; Correspondence Address: A. Ferreira; Department of Orthopedics and Traumatology, Unité Inserm Comète 1075, Caen University Hospital, Caen, avenue Côte-de-Nacre, 14000, France; email: alexandreferreira0891@gmail.com
ER  -

TY  - JOUR
AU  - Krittanawong, C.
AU  - Rodriguez, M.
AU  - Kaplin, S.
AU  - Tang, W.H.W.
TI  - Assessing the potential of ChatGPT for patient education in the cardiology clinic
PY  - 2023
T2  - Progress in Cardiovascular Diseases
VL  - 81
SP  - 109
EP  - 110
DO  - 10.1016/j.pcad.2023.10.002
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85175522882&doi=10.1016%2fj.pcad.2023.10.002&partnerID=40&md5=58f4fc5e02e3d2d2a72c4aa08efaf580
AD  - Cardiology Division, NYU Langone Health and NYU School of Medicine, New York, NY, United States
AD  - John T Milliken Department of Medicine, Division of Cardiovascular disease, Section of Advanced Heart Failure and Transplant, Barnes-Jewish Hospital/Washington University in St.Louis School of Medicine, United States
AD  - Department of Cardiovascular Medicine, Heart and Vascular Institute, Clinic, Cleveland, OH, United States
KW  - Cardiology
KW  - Humans
KW  - Patient Education as Topic
KW  - artificial intelligence
KW  - cardiology
KW  - ChatGPT
KW  - clinical practice
KW  - heart failure
KW  - human
KW  - Letter
KW  - patient education
KW  - patient satisfaction
KW  - patient triage
KW  - qualitative analysis
PB  - W.B. Saunders
SN  - 00330620 (ISSN)
C2  - 37832625
LA  - English
J2  - Prog. Cardiovasc. Dis.
M3  - Letter
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 1; Correspondence Address: C. Krittanawong; Cardiology Division, NYU Langone Health and NYU School of Medicine, New York, United States; email: chayakrit.krittanawong@va.gov; CODEN: PCVDA
ER  -

TY  - CONF
AU  - Cheong, M.
TI  - ChatGPT's Performance in Spreadsheets Modeling Assessments based on Revised Bloom's Taxonomy
PY  - 2023
T2  - 31st International Conference on Computers in Education, ICCE 2023 - Proceedings
VL  - 1
SP  - 308
EP  - 317
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85181536568&partnerID=40&md5=34cd69fd17a77040f9952c6531974799
AD  - School of Computing & Information Systems, Singapore Management University, Singapore
AB  - ChatGPT has taken the education scene by storm and caused uneasiness among educators. Mixed reactions were observed with some institutions banning it, while others embracing it with caution. This paper evaluates the performance of ChatGPT on solving spreadsheets modeling assessment questions with multiple test items categorized according to the revised Bloom's taxonomy, to discover the accuracy of the answers provided at each cognitive learning level. The insights obtained may be useful for educators to design future assessment questions which focus more on testing critical thinking skills to assess the students accordingly to achieve the intended learning outcomes, and we propose recommended actions on how to do so. Our proposed methodology can be applied to other course modules to achieve their respective insights for future assessment designs and actions. © 2023 Asia-Pacific Society for Computers in Education.
KW  - Assessments
KW  - ChatGPT
KW  - Performance Evaluation
KW  - Revised Bloom's Taxonomy
KW  - Spreadsheets Modeling
KW  - Blooms (metal)
KW  - Spreadsheets
KW  - Taxonomies
KW  - Assessment
KW  - Bloom taxonomies
KW  - ChatGPT
KW  - Future assessment
KW  - Model assessment
KW  - Multiple test
KW  - Performance
KW  - Performances evaluation
KW  - Revised bloom taxonomy
KW  - Spreadsheet models
KW  - Students
A2  - Shih J.-L.
A2  - Kashihara A.
A2  - Chen W.
A2  - Chen W.
A2  - Ogata H.
A2  - Baker R.
A2  - Chang B.
A2  - Dianati S.
A2  - Madathil J.
A2  - Yousef A.M.F.
A2  - Yang Y.
A2  - Zarzour H.
PB  - Asia-Pacific Society for Computers in Education
SN  - 978-626968901-9 (ISBN)
LA  - English
J2  - Int. Conf. Comput. Educ., ICCE - Proc.
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 0; Correspondence Address: M. Cheong; School of Computing & Information Systems, Singapore Management University, Singapore; email: michcheong@smu.edu.sg; Conference name: 31st International Conference on Computers in Education, ICCE 2023; Conference date: 4 December 2023 through 8 December 2023; Conference code: 195491
ER  -

TY  - JOUR
AU  - Nicula, B.
AU  - Dascalu, M.
AU  - Arner, T.
AU  - Balyan, R.
AU  - McNamara, D.S.
TI  - Automated Assessment of Comprehension Strategies from Self-Explanations Using LLMs
PY  - 2023
T2  - Information (Switzerland)
VL  - 14
IS  - 10
C7  - 567
DO  - 10.3390/info14100567
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85175009193&doi=10.3390%2finfo14100567&partnerID=40&md5=6c9fc86823ac1d2751d39f3ac80ef8a5
AD  - Computer Science and Engineering Department, National University of Science and Technology POLITEHNICA of Bucharest, 313 Splaiul Independentei, Bucharest, 060042, Romania
AD  - Academy of Romanian Scientists, Str. Ilfov, Nr. 3, Bucharest, 050044, Romania
AD  - Department of Psychology, Arizona State University, P.O. Box 871104, Tempe, 85287, AZ, United States
AD  - Math/CIS Department, SUNY Old Westbury, Old Westbury, 11568, NY, United States
AB  - Text comprehension is an essential skill in today’s information-rich world, and self-explanation practice helps students improve their understanding of complex texts. This study was centered on leveraging open-source Large Language Models (LLMs), specifically FLAN-T5, to automatically assess the comprehension strategies employed by readers while understanding Science, Technology, Engineering, and Mathematics (STEM) texts. The experiments relied on a corpus of three datasets (N = 11,833) with self-explanations annotated on 4 dimensions: 3 comprehension strategies (i.e., bridging, elaboration, and paraphrasing) and overall quality. Besides FLAN-T5, we also considered GPT3.5-turbo to establish a stronger baseline. Our experiments indicated that the performance improved with fine-tuning, having a larger LLM model, and providing examples via the prompt. Our best model considered a pretrained FLAN-T5 XXL model and obtained a weighted F1-score of 0.721, surpassing the 0.699 F1-score previously obtained using smaller models (i.e., RoBERTa). © 2023 by the authors.
KW  - language models
KW  - large language models
KW  - self-explanation
KW  - self-explanation strategies
KW  - Computational linguistics
KW  - Automated assessment
KW  - F1 scores
KW  - Language model
KW  - Large language model
KW  - Open-source
KW  - Self explanations
KW  - Self-explanation strategy
KW  - Text comprehensions
KW  - Students
PB  - Multidisciplinary Digital Publishing Institute (MDPI)
SN  - 20782489 (ISSN)
LA  - English
J2  - Information
M3  - Article
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 1; Correspondence Address: M. Dascalu; Computer Science and Engineering Department, National University of Science and Technology POLITEHNICA of Bucharest, Bucharest, 313 Splaiul Independentei, 060042, Romania; email: mihai.dascalu@upb.ro
ER  -

TY  - JOUR
AU  - Kocbek, P.
AU  - Fijačko, N.
AU  - Štiglic, G.
TI  - Evolution of ChatGPT evaluations in healthcare: Still at the beginning?
PY  - 2023
T2  - Resuscitation
VL  - 193
C7  - 110042
DO  - 10.1016/j.resuscitation.2023.110042
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85178287523&doi=10.1016%2fj.resuscitation.2023.110042&partnerID=40&md5=dac23507ed4a87baf7bdfd0dc24e79d8
AD  - University of Maribor, Faculty of Health Sciences, Maribor, Slovenia
AD  - Faculty of Medicine, University of Ljubljana, Ljubljana, Slovenia
AD  - ERC Research Net, Niels, Belgium
AD  - Maribor University Medical Centre, Maribor, Slovenia
AD  - University of Maribor, Faculty of Electrical Engineering and Computer Science, Maribor, Slovenia
AD  - University of Edinburgh, Usher Institute, Edinburgh, United Kingdom
KW  - accuracy
KW  - ChatGPT
KW  - evaluation study
KW  - health care
KW  - health services research
KW  - human
KW  - large language model
KW  - Letter
KW  - statistical bias
KW  - advanced cardiac life support
KW  - artificial intelligence
KW  - basic life support
KW  - drug administration
KW  - evolution
KW  - large language model
KW  - letter
PB  - Elsevier Ireland Ltd
SN  - 03009572 (ISSN)
C2  - 37952577
LA  - English
J2  - Resuscitation
M3  - Letter
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 0; Correspondence Address: N. Fijačko; University of Maribor, Faculty of Health Sciences, Maribor, Žitna ulica 15, 2000, Slovenia; email: nino.fijacko@um.si; CODEN: RSUSB
ER  -

TY  - JOUR
AU  - Seth, I.
AU  - Cox, A.
AU  - Xie, Y.
AU  - Bulloch, G.
AU  - Hunter-Smith, D.J.
AU  - Rozen, W.M.
AU  - Ross, R.J.
TI  - Evaluating Chatbot Efficacy for Answering Frequently Asked Questions in Plastic Surgery: A ChatGPT Case Study Focused on Breast Augmentation
PY  - 2023
T2  - Aesthetic Surgery Journal
VL  - 43
IS  - 10
SP  - 1126
EP  - 1135
DO  - 10.1093/asj/sjad140
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85163094269&doi=10.1093%2fasj%2fsjad140&partnerID=40&md5=9b7a1ec963430545dee300e89d4b6509
AD  - Department of Plastic Surgery, Peninsula Health, Melbourne, VIC, Australia
AD  - University of Melbourne, Victoria, Australia
AB  - Background: The integration of artificial intelligence (AI) and machine learning (ML) technologies into healthcare is transforming patient-practitioner interaction and could offer an additional platform for patient education and support. Objectives: This study investigated whether ChatGPT-4 could provide safe and up-to-date medical information about breast augmentation that is comparable to other patient information sources. Methods: ChatGPT-4 was asked to generate 6 commonly asked questions regarding breast augmentation and respond to them. Its responses were qualitatively evaluated by a panel of specialist plastic and reconstructive surgeons and reconciled with a literature search of 2 large medical databases for accuracy, informativeness, and accessibility. Results: ChatGPT-4 provided well-structured, grammatically accurate, and comprehensive responses to the questions posed; however, it was limited in providing personalized advice and sometimes generated inappropriate or outdated references. ChatGPT consistently encouraged engagement with a specialist for specific information. Conclusions: Although ChatGPT-4 showed promise as an adjunct tool in patient education regarding breast augmentation, there are areas requiring improvement. Additional advancements and software engineering are needed to enhance the reliability and applicability of AI-driven chatbots in patient education and support systems.  © 2023 The Author(s). Published by Oxford University Press on behalf of The Aesthetic Society. All rights reserved.
KW  - Artificial Intelligence
KW  - Humans
KW  - Mammaplasty
KW  - Reproducibility of Results
KW  - Software
KW  - Surgery, Plastic
KW  - adult
KW  - article
KW  - artificial intelligence
KW  - breast augmentation
KW  - ChatGPT
KW  - comparative effectiveness
KW  - human
KW  - medical information
KW  - patient education
KW  - patient information
KW  - plastic surgery
KW  - reliability
KW  - surgeon
KW  - breast reconstruction
KW  - reproducibility
KW  - software
PB  - Oxford University Press
SN  - 1090820X (ISSN)
C2  - 37158147
LA  - English
J2  - Aesthet. Surg. J.
M3  - Article
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 18; Correspondence Address: I. Seth; Central Clinical School at Monash University, The Alfred Centre, Melbourne, 99 Commercial Rd, 3004, Australia; email: ishithseth1@gmail.com; CODEN: ASJEB
ER  -

TY  - JOUR
AU  - Zirar, A.
TI  - Exploring the impact of language models, such as ChatGPT, on student learning and assessment
PY  - 2023
T2  - Review of Education
VL  - 11
IS  - 3
C7  - e3433
DO  - 10.1002/rev3.3433
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85175844331&doi=10.1002%2frev3.3433&partnerID=40&md5=b517bce16c0f8fbdcf14d94d7dbfaf28
AD  - Department of Management, Huddersfield Business School, University of Huddersfield, Huddersfield, United Kingdom
AB  - Recent developments in language models, such as ChatGPT, have sparked debate. These tools can help, for example, dyslexic people, to write formal emails from a prompt and can be used by students to generate assessed work. Proponents argue that language models enhance the student experience and academic achievement. Those concerned argue that language models impede student learning and call for a cautious approach to their adoption. This paper aims to provide insights into the role of language models in reshaping student learning and assessment in higher education. For that purpose, it probes the impact of language models, specifically ChatGPT, on student learning and assessment. It also explores the implications of language models in higher education settings, focusing on their effects on pedagogy and evaluation. Using the Scopus database, a search protocol was employed to identify 25 articles based on relevant keywords and selection criteria. The developed themes suggest that language models may alter how students learn and are assessed. While language models can provide information for problem-solving and critical thinking, reliance on them without critical evaluation adversely impacts student learning. Language models can also generate teaching and assessment material and evaluate student responses, but their role should be limited to ‘play a specific and defined role’. Integration of language models in student learning and assessment is only helpful if students and educators play an active and effective role in checking the generated material's validity, reliability and accuracy. Propositions and potential research questions are included to encourage future research. © 2023 The Authors. Review of Education published by John Wiley & Sons Ltd on behalf of British Educational Research Association.
KW  - ChatGPT
KW  - higher education
KW  - language models
KW  - review
KW  - student learning and assessment
KW  - synthesis
PB  - John Wiley and Sons Inc
SN  - 20496613 (ISSN)
LA  - English
J2  - Rev. Educ.
M3  - Article
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 0; Correspondence Address: A. Zirar; Department of Management, Huddersfield Business School, University of Huddersfield, Huddersfield, United Kingdom; email: a.zirar@hud.ac.uk
ER  -

TY  - JOUR
AU  - Lee, P.C.
AU  - Sharma, S.K.
AU  - Motaganahalli, S.
AU  - Huang, A.
TI  - Evaluating the Clinical Decision-Making Ability of Large Language Models Using MKSAP-19 Cardiology Questions
PY  - 2023
T2  - JACC: Advances
VL  - 2
IS  - 9
C7  - 100658
DO  - 10.1016/j.jacadv.2023.100658
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85180198596&doi=10.1016%2fj.jacadv.2023.100658&partnerID=40&md5=4f6702882a57ea0030e1d85d199ee3f3
PB  - Elsevier B.V.
SN  - 2772963X (ISSN)
LA  - English
J2  - JACC. Advances.
M3  - Article
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 0; Correspondence Address: P.C. Lee; Icahn School of Medicine at Mount Sinai, Cardiovascular Institute, New York, One Gustave L Levy Place, 10029, United States; email: dr.paul.c.lee@gmail.com
ER  -

TY  - JOUR
AU  - Meron, Y.
AU  - Tekmen Araci, Y.
TI  - Artificial intelligence in design education: evaluating ChatGPT as a virtual colleague for post-graduate course development
PY  - 2023
T2  - Design Science
VL  - 9
C7  - e30
DO  - 10.1017/dsj.2023.28
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85177830079&doi=10.1017%2fdsj.2023.28&partnerID=40&md5=d987c999712af17cf350406d9354c2f8
AD  - School of Architecture Design and Planning, University of Sydney, Sydney, NSW, Australia
AB  - This article explores the ability of ChatGPT to function as a virtual colleague in helping to design materials for higher education design students. Using a self-study methodology, two university educators attempted to collaborate with ChatGPT to create course materials targeted at higher education design students, before reflecting on its strengths and weaknesses during the process. Contextualising ChatGPT as the latest acute example of digital disruptors that design practices and processes have faced, the authors evaluated its current and potential threats and opportunities for the creation of design-focused learning content. The authors found that ChatGPT was a competent partner with regard to saving time, structuring textual content and documentation, and as a brainstorming tool. However, ChatGPT's weaknesses included content generation that was often generic, usually requiring much human prompting, cajoling, and manual editing to produce desirable outcomes. Overall, ChatGPT was found to excel at its stated functionality as a language model, with some potentially useful functionality for the creation of higher education design course materials and outlines, as well as limitations. The reflections discussed can be used to inform design educators who may want to work with ChatGPT when designing course materials. However, acknowledging limitations and potential ethical challenges, the authors' caution that educators may have to evaluate for themselves whether ChatGPT's potential advantages outweigh its disadvantages.  © The Author(s), 2023. Published by Cambridge University Press.
KW  - AI
KW  - ChatGPT
KW  - Course development
KW  - Design education
KW  - Virtual colleague
KW  - Curricula
KW  - Design
KW  - E-learning
KW  - Education computing
KW  - Artificial intelligence in designs
KW  - ChatGPT
KW  - Course development
KW  - Course material
KW  - Design Education
KW  - Design materials
KW  - Education designs
KW  - Graduate course
KW  - High educations
KW  - Virtual colleague
KW  - Students
PB  - Cambridge University Press
SN  - 20534701 (ISSN)
LA  - English
J2  - Des. Sci.
M3  - Article
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 0; Correspondence Address: Y. Meron; School of Architecture Design and Planning, University of Sydney, Sydney, Australia; email: yaron.meron@sydney.edu.au
ER  -

TY  - JOUR
AU  - Luykx, J.J.
AU  - Gerritse, F.
AU  - Habets, P.C.
AU  - Vinkers, C.H.
TI  - The performance of ChatGPT in generating answers to clinical questions in psychiatry: a two-layer assessment
PY  - 2023
T2  - World Psychiatry
VL  - 22
IS  - 3
SP  - 479
EP  - 480
DO  - 10.1002/wps.21145
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85171280763&doi=10.1002%2fwps.21145&partnerID=40&md5=d767551294b6ca006705efba1c51f352
AD  - Department of Psychiatry and Neuropsychology, School for Mental Health and Neuroscience, Maastricht University Medical Centre, Maastricht, Netherlands
AD  - Department of Psychiatry, UMC Utrecht Brain Center, University Medical Center Utrecht, Utrecht, Netherlands
AD  - Outpatient Second Opinion Clinic, GGNet Mental Health, Warnsveld, Netherlands
AD  - Department of Psychiatry, Tergooi MC, Hilversum, Netherlands
AD  - Department of Psychiatry and Anatomy & Neurosciences, Amsterdam University Medical Center, Vrije Universiteit Amsterdam, Amsterdam, Netherlands
AD  - Department of Internal Medicine, Leiden University Medical Center, Leiden, Netherlands
AD  - Amsterdam Public Health, Mental Health Program and Amsterdam Neuroscience, Mood, Anxiety, Psychosis, Sleep & Stress Program, Amsterdam, Netherlands
AD  - GGZ inGeest Mental Health Care, Amsterdam, Netherlands
KW  - artificial intelligence
KW  - ChatGPT
KW  - health education
KW  - human
KW  - large language model
KW  - Letter
KW  - medical education
KW  - psychiatry
KW  - questionnaire
KW  - scoring system
PB  - John Wiley and Sons Inc
SN  - 17238617 (ISSN)
LA  - English
J2  - World Psychiatry
M3  - Letter
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 1
ER  -

TY  - JOUR
AU  - Ray, P.P.
TI  - Letter to the Editor: A critical evaluation on the use of large language model for radiology research
PY  - 2023
T2  - European Radiology
VL  - 33
IS  - 12
SP  - 9462
EP  - 9463
DO  - 10.1007/s00330-023-10332-9
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85174293833&doi=10.1007%2fs00330-023-10332-9&partnerID=40&md5=1ecbdc15051ed2dc92981e55190fa32b
AD  - Department of Computer Applications, Sikkim University, Gangtok, India
KW  - Humans
KW  - Language
KW  - Radiography
KW  - Radiology
KW  - ChatGPT
KW  - cost benefit analysis
KW  - human
KW  - language
KW  - Letter
KW  - radiologist
KW  - radiology
KW  - language
KW  - radiography
PB  - Springer Science and Business Media Deutschland GmbH
SN  - 09387994 (ISSN)
C2  - 37848769
LA  - English
J2  - Eur. Radiol.
M3  - Letter
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 0; Correspondence Address: P.P. Ray; Department of Computer Applications, Sikkim University, Gangtok, India; email: ppray@cus.ac.in; CODEN: EURAE
ER  -

TY  - JOUR
AU  - Subrahmanyeswari, T.
AU  - Gantait, S.
AU  - Kamble, S.N.
AU  - Singh, S.
AU  - Bhattacharyya, S.
TI  - Radio-Sensitivity Assessment of In Vitro Tissues of Stevia (Stevia rebaudiana Bert.) for Induced Mutagenesis
PY  - 2023
T2  - Sugar Tech
VL  - 25
IS  - 6
SP  - 1520
EP  - 1530
DO  - 10.1007/s12355-023-01305-9
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85167716684&doi=10.1007%2fs12355-023-01305-9&partnerID=40&md5=91842b5d7294363f79bb2905d326cef3
AD  - Crop Research Unit (Genetics and Plant Breeding), Bidhan Chandra Krishi Viswavidyalaya, West Bengal, Mohanpur, Nadia, 741252, India
AD  - Plant Biotechnology and Secondary Metabolites Section, Nuclear Agriculture and Biotechnology Division, Bhabha Atomic Research Centre, Mumbai, 400 085, India
AD  - Homi Bhabha National Institute, Anushaktinagar, Mumbai, 400094, India
AB  - In vitro mutagenesis approach using gamma irradiation has its proven advantages over conventional breeding methods, since the same exhibits more potential for mutation induction (with desirable traits) with minimal negative effects, within a short time-span, in various plant species. Present study reports an assessment of sensitivity of stevia to gamma irradiation in order to optimize the irradiation doses [median lethal dose (LD50) and median growth reduction dose (GR50) along with LD25, LD75, GR25, and GR75] for induced mutagenesis. Nodal segments from in vitro-regenerated stevia shoots were exposed at six different doses of gamma irradiations (5, 10, 15, 20, 25, and 30 Gy). The irradiated nodal segments were then cultured on Murashige and Skoog basal medium supplemented with 1.5 mg/L meta-Topolin and 1 mg/L indole-3-butyric acid along with the control (non-treated) explants for 3 weeks to assess the effect of irradiation on multiple shoot–root formation. Upon exposure to different gamma ray doses from 5 to 30 Gy, a gradual and morphological trait-specific differential decline of in vitro growth was detected. The individual as well as the cumulative impact of gamma irradiation doses on the growth and development traits were assessed using hierarchical clustering heat map (based on ward distance matrix) and principal component analyses. In addition, based on the probit analysis on trends of gamma irradiation effect, the LD25, 50, 75 values were calculated to be 9.1, 18.2, and > 30 Gy, respectively. On the other hand, GR25, 50, 75 values were calculated to be in between 7.1–12.6 Gy, 15.8–21.3 Gy, and 25.5 to way beyond 30 Gy, respectively. On studying the response of all the in vitro growth traits, it was deduced that in order to induce desirable mutations and also to develop novel mutants with adequate survival rate, the optimum irradiation dose (from LD25, 50, 75 or GR25, 50, 75 values) should be calculated based on LD50/GR50, which was determined to be 15–20 Gy in stevia. Hence, this optimum dose can be utilized to produce a higher percentage of beneficial mutations, resulting in maximal desirable genetic diversity in M1V2 and its subsequent generations. © 2023, The Author(s), under exclusive licence to Society for Sugar Research & Promotion.
KW  - Gamma irradiation
KW  - GR<sub>25, 50, 75</sub>
KW  - LD<sub>25, 50, 75</sub>
KW  - Nodal segments
KW  - Probit analysis
KW  - Survival rate
PB  - Springer
SN  - 09721525 (ISSN)
LA  - English
J2  - Sugar Tech
M3  - Article
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 0; Correspondence Address: S. Gantait; Crop Research Unit (Genetics and Plant Breeding), Bidhan Chandra Krishi Viswavidyalaya, Mohanpur, Nadia, West Bengal, 741252, India; email: saikatgantait@yahoo.com; CODEN: STUEC
ER  -

TY  - CONF
AU  - Yusupov, D.
AU  - Artikbayev, N.
AU  - Kutbidinov, O.
AU  - Toshpulatov, N.
AU  - Babayev, A.
AU  - Matchonov, O.
AU  - Vokhidov, A.
TI  - Development of a simulation model for assessing the technical condition of transformers exploited in hydroelectric stations
PY  - 2023
T2  - E3S Web of Conferences
VL  - 434
C7  - 01026
DO  - 10.1051/e3sconf/202343401026
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85174626084&doi=10.1051%2fe3sconf%2f202343401026&partnerID=40&md5=5514db9a6a9dc9b2b2c64ffe0acc8ffc
AD  - Institute of Energy Problems, Academy of Sciences of the Republic of Uzbekistan, Tashkent, Uzbekistan
AD  - “Tashkent Institute of Irrigation and Agricultural Mechanization Engineers” National Research University, Tashkent, 100000, Uzbekistan
AD  - Joint Stock Company “Uzbekhydroenergo”, Tashkent, Uzbekistan
AD  - Tashkent State Transport University, Tashkent, Uzbekistan
AB  - Supplying consumers with continuous electricity is one of the urgent problems of today. The main part of electricity is produced by hydroelectric stations. The perfect operation of the main electrical equipment of hydroelectric power stations is related to the reliable operation of the electrical equipment in operation. The flawless operation of power transformers in operation at hydroelectric power stations is evaluated by their technical condition. The technical condition of power transformers is determined by their electrical and nonelectrical indicator values. In this article, a simulation model for determining the value of the technical condition of power transformers in operation at hydroelectric power stations using fuzzy logic has been developed. © The Authors, published by EDP Sciences. This is an open access article distributed under the terms of the Creative Commons Attribution License 4.0 (https://creativecommons.org/licenses/by/4.0/).
A2  - Tursunov O.
PB  - EDP Sciences
SN  - 25550403 (ISSN)
LA  - English
J2  - E3S Web Conf.
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 0; Correspondence Address: O. Kutbidinov; Tashkent State Transport University, Tashkent, Uzbekistan; email: odiljon.qutbidinov@bk.ru; Conference name: 4th International Conference on Energetics, Civil and Agricultural Engineering, ICECAE 2023; Conference date: 12 October 2023 through 14 October 2023; Conference code: 193343
ER  -

TY  - JOUR
AU  - Abi-Rafeh, J.
AU  - Hanna, S.
AU  - Bassiri-Tehrani, B.
AU  - Kazan, R.
AU  - Nahai, F.
TI  - Complications Following Facelift and Neck Lift: Implementation and Assessment of Large Language Model and Artificial Intelligence (ChatGPT) Performance Across 16 Simulated Patient Presentations
PY  - 2023
T2  - Aesthetic Plastic Surgery
VL  - 47
IS  - 6
SP  - 2407
EP  - 2414
DO  - 10.1007/s00266-023-03538-1
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85168586047&doi=10.1007%2fs00266-023-03538-1&partnerID=40&md5=56c9d3520a97eef01511ab694f782226
AD  - Division of Plastic, Reconstructive, and Aesthetic Surgery, McGill University Health Centre, Montreal, QC, Canada
AD  - Manhattan Eye, Ear and Throat Hospital, New York, NY, United States
AD  - Private Practice, Atlanta, GA, United States
AD  - Division of Plastic and Reconstructive Surgery, University of Pittsburgh, Pittsburgh, PA, United States
AD  - Plastic Surgery, Department of Surgery, Emory University, Atlanta, GA, United States
AB  - Introduction: ChatGPT represents a potential resource for patient guidance and education, with the possibility for quality improvement in healthcare delivery. The present study evaluates the role of ChatGPT as an interactive patient resource, and assesses its performance in identifying, triaging, and guiding patients with concerns of postoperative complications following facelift and neck lift surgery. Methods: Sixteen patient profiles were generated to simulate postoperative patient presentations, with complications of varying acuity and severity. ChatGPT was assessed for its accuracy in generating a differential diagnosis, soliciting a history, providing the most-likely diagnosis, the appropriate disposition, treatments/interventions to begin from home, and red-flag symptoms necessitating an urgent presentation to the emergency department. Results: Overall accuracy in providing a complete differential diagnosis in response to simulated presentations was 85%, with an accuracy of 88% in identifying the most-likely diagnosis after history-taking. However, appropriate patient dispositions were suggested in only 56% of cases. Relevant home treatments/interventions were suggested with an 82% accuracy, and red-flag symptoms with a 73% accuracy. A detailed analysis, stratified according to latency of postoperative presentation (<48 h, 48 h–1 week, or >1 week), and according to acuity of complications, is presented herein. Conclusions: ChatGPT overestimated the urgency of indicated patient dispositions in 44% of cases, concerning for potential unnecessary increase in healthcare resource utilization. Imperfect performance, and the tool’s tendency for overinclusion in its responses, risk increasing patient anxiety and straining physician-patient relationships. While artificial intelligence has great potential in triaging postoperative patient concerns, and improving efficiency and resource utilization, ChatGPT’s performance, in its current form, demonstrates a need for further refinement before its safe and effective implementation in facial aesthetic surgical practice. Level of Evidence IV: This journal requires that authors assign a level of evidence to each article. For a full description of these Evidence-Based Medicine ratings, please refer to the Table of Contents or the online Instructions to Authors www.springer.com/00266 . © 2023, Springer Science+Business Media, LLC, part of Springer Nature and International Society of Aesthetic Plastic Surgery.
KW  - Artificial intelligence
KW  - Complications
KW  - Facelift
KW  - Artificial Intelligence
KW  - Face
KW  - Humans
KW  - Neck
KW  - Postoperative Complications
KW  - Rhytidoplasty
KW  - artificial intelligence
KW  - face
KW  - human
KW  - neck
KW  - postoperative complication
KW  - rhytidoplasty
KW  - surgery
PB  - Springer
SN  - 0364216X (ISSN)
C2  - 37589944
LA  - English
J2  - Aesthet. Plast. Surg.
M3  - Article
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 1; Correspondence Address: F. Nahai; Plastic Surgery, Department of Surgery, Emory University, Atlanta, United States; email: nahaimd@aol.com; CODEN: APSUD
ER  -

TY  - JOUR
AU  - Kleebayoon, A.
AU  - Wiwanitkit, V.
TI  - ChatGPT and American College of Gastroenterology Self-Assessment Test: Comment
PY  - 2023
T2  - American Journal of Gastroenterology
VL  - 118
IS  - 12
SP  - 2305
EP  - 2306
DO  - 10.14309/ajg.0000000000002367
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85178501813&doi=10.14309%2fajg.0000000000002367&partnerID=40&md5=a4558e99c634a18504f2acc4f74d7654
AD  - Consultant Unit, Private Academic Consultant, Samraong, Cambodia
AD  - Research Center, Chandigarh University, Punjab, India
AD  - Depatment of Biological Science, Joesph Ayobabalola University, Ikeji-Arakeji, Nigeria
KW  - Gastroenterology
KW  - Gastrointestinal Tract
KW  - Humans
KW  - Self-Assessment
KW  - Societies, Medical
KW  - United States
KW  - artificial intelligence
KW  - ChatGPT
KW  - gastroenterology
KW  - human
KW  - Letter
KW  - medical education
KW  - plagiarism
KW  - self evaluation
KW  - gastrointestinal tract
KW  - medical society
KW  - self evaluation
KW  - United States
PB  - Wolters Kluwer Health
SN  - 00029270 (ISSN)
C2  - 38033227
LA  - English
J2  - Am. J. Gastroenterol.
M3  - Letter
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 1; CODEN: AJGAA
ER  -

TY  - JOUR
AU  - Zhao, M.
AU  - Meng, N.
AU  - Cheung, J.P.Y.
AU  - Yu, C.
AU  - Lu, P.
AU  - Zhang, T.
TI  - SpineHRformer: A Transformer-Based Deep Learning Model for Automatic Spine Deformity Assessment with Prospective Validation
PY  - 2023
T2  - Bioengineering
VL  - 10
IS  - 11
C7  - 1333
DO  - 10.3390/bioengineering10111333
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85177666144&doi=10.3390%2fbioengineering10111333&partnerID=40&md5=57f5afbc611421bec6a777df275ffcf2
AD  - Department of Orthopaedics and Traumatology, The University of Hong Kong, Hong Kong
AB  - The Cobb angle (CA) serves as the principal method for assessing spinal deformity, but manual measurements of the CA are time-consuming and susceptible to inter- and intra-observer variability. While learning-based methods, such as SpineHRNet+, have demonstrated potential in automating CA measurement, their accuracy can be influenced by the severity of spinal deformity, image quality, relative position of rib and vertebrae, etc. Our aim is to create a reliable learning-based approach that provides consistent and highly accurate measurements of the CA from posteroanterior (PA) X-rays, surpassing the state-of-the-art method. To accomplish this, we introduce SpineHRformer, which identifies anatomical landmarks, including the vertices of endplates from the 7th cervical vertebra (C7) to the 5th lumbar vertebra (L5) and the end vertebrae with different output heads, enabling the calculation of CAs. Within our SpineHRformer, a backbone HRNet first extracts multi-scale features from the input X-ray, while transformer blocks extract local and global features from the HRNet outputs. Subsequently, an output head to generate heatmaps of the endplate landmarks or end vertebra landmarks facilitates the computation of CAs. We used a dataset of 1934 PA X-rays with diverse degrees of spinal deformity and image quality, following an 8:2 ratio to train and test the model. The experimental results indicate that SpineHRformer outperforms SpineHRNet+ in landmark detection (Mean Euclidean Distance: 2.47 pixels vs. 2.74 pixels), CA prediction (Pearson correlation coefficient: 0.86 vs. 0.83), and severity grading (sensitivity: normal-mild; 0.93 vs. 0.74, moderate; 0.74 vs. 0.77, severe; 0.74 vs. 0.7). Our approach demonstrates greater robustness and accuracy compared to SpineHRNet+, offering substantial potential for improving the efficiency and reliability of CA measurements in clinical settings. © 2023 by the authors.
KW  - Cobb angle automatic measurement
KW  - end vertebrae detection
KW  - endplate detection
KW  - HRNet
KW  - transformer
PB  - Multidisciplinary Digital Publishing Institute (MDPI)
SN  - 23065354 (ISSN)
LA  - English
J2  - Bioeng.
M3  - Article
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 0; Correspondence Address: T. Zhang; Department of Orthopaedics and Traumatology, The University of Hong Kong, Hong Kong; email: tgzhang@hku.hk
ER  -

TY  - JOUR
AU  - Griewing, S.
AU  - Gremke, N.
AU  - Wagner, U.
AU  - Lingenfelder, M.
AU  - Kuhn, S.
AU  - Boekhoff, J.
TI  - Challenging ChatGPT 3.5 in Senology—An Assessment of Concordance with Breast Cancer Tumor Board Decision Making
PY  - 2023
T2  - Journal of Personalized Medicine
VL  - 13
IS  - 10
C7  - 1502
DO  - 10.3390/jpm13101502
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85175246847&doi=10.3390%2fjpm13101502&partnerID=40&md5=286780525d8999c464583ad842ea4270
AD  - Institute for Digital Medicine, University Hospital Marburg, Philipps-University Marburg, Baldingerstraße, Marburg, 35043, Germany
AD  - Department of Gynecology and Obstetrics, University Hospital Marburg, Philipps-University Marburg, Baldingerstraße, Marburg, 35043, Germany
AD  - Institute for Healthcare Management, Chair of General Business Administration, Philipps-University Marburg, Universitätsstraße 24, Marburg, 35037, Germany
AB  - With the recent diffusion of access to publicly available large language models (LLMs), common interest in generative artificial-intelligence-based applications for medical purposes has skyrocketed. The increased use of these models by tech-savvy patients for personal health issues calls for a scientific evaluation of whether LLMs provide a satisfactory level of accuracy for treatment decisions. This observational study compares the concordance of treatment recommendations from the popular LLM ChatGPT 3.5 with those of a multidisciplinary tumor board for breast cancer (MTB). The study design builds on previous findings by combining an extended input model with patient profiles reflecting patho- and immunomorphological diversity of primary breast cancer, including primary metastasis and precancerous tumor stages. Overall concordance between the LLM and MTB is reached for half of the patient profiles, including precancerous lesions. In the assessment of invasive breast cancer profiles, the concordance amounts to 58.8%. Nevertheless, as the LLM makes considerably fraudulent decisions at times, we do not identify the current development status of publicly available LLMs to be adequate as a support tool for tumor boards. Gynecological oncologists should familiarize themselves with the capabilities of LLMs in order to understand and utilize their potential while keeping in mind potential risks and limitations. © 2023 by the authors.
KW  - artificial intelligence
KW  - gynecology
KW  - large language models
KW  - oncology
KW  - tumor board
KW  - estrogen receptor
KW  - progesterone receptor
KW  - Article
KW  - artificial intelligence
KW  - breast cancer
KW  - cancer staging
KW  - cell proliferation
KW  - ChatGPT
KW  - computer model
KW  - decision making
KW  - genetic screening
KW  - gynecologic oncologist
KW  - gynecologist
KW  - gynecology
KW  - health care personnel
KW  - hormonal therapy
KW  - human
KW  - immunohistology
KW  - in situ hybridization
KW  - invasive breast cancer
KW  - large language model
KW  - metastasis
KW  - oncology
KW  - qualitative analysis
KW  - questionnaire
PB  - Multidisciplinary Digital Publishing Institute (MDPI)
SN  - 20754426 (ISSN)
LA  - English
J2  - J. Pers. Med.
M3  - Article
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 1; Correspondence Address: S. Griewing; Institute for Digital Medicine, University Hospital Marburg, Philipps-University Marburg, Marburg, Baldingerstraße, 35043, Germany; email: griewin4@staff.uni-marburg.de
ER  -

TY  - JOUR
AU  - Abu-Farha, R.
AU  - Fino, L.
AU  - Al-Ashwal, F.Y.
AU  - Zawiah, M.
AU  - Gharaibeh, L.
AU  - Harahsheh, M.M.
AU  - Darwish Elhajji, F.
TI  - Evaluation of community pharmacists’ perceptions and willingness to integrate ChatGPT into their pharmacy practice: A study from Jordan
PY  - 2023
T2  - Journal of the American Pharmacists Association
VL  - 63
IS  - 6
SP  - 1761
EP  - 1767.e2
DO  - 10.1016/j.japh.2023.08.020
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85171763450&doi=10.1016%2fj.japh.2023.08.020&partnerID=40&md5=cac450e208ef99f47188f8b760fc1161
AB  - Objectives: This study aimed to examine the extent of community pharmacists’ awareness of Chat Generative Pretraining Transformer (ChatGPT), their willingness to embark on this new development of artificial intelligence (AI) development, and barriers that face the incorporation of this nonconventional source of information into pharmacy practice. Methods: A cross-sectional study was conducted among community pharmacists in Jordanian cities between April 26, 2023, and May 10, 2023. Convenience and snowball sampling techniques were used to select study participants owing to resource and time constraints. The questionnaire was distributed by research assistants through popular social media platforms. Logistic regression analysis was used to assess predictors affecting their willingness to use this service in the future. Results: A total of 221 community pharmacists participated in the current study (response rate was not calculated because opt-in recruitment strategies were used). Remarkably, nearly half of the pharmacists (n = 107, 48.4%) indicated a willingness to incorporate the ChatGPT into their pharmacy practice. Nearly half of the pharmacists (n = 105, 47.5%) demonstrated a high perceived benefit score for ChatGPT, whereas approximately 37% of pharmacists (n = 81) expressed a high concern score about ChatGPT. More than 70% of pharmacists believed that ChatGPT lacked the ability to use human judgment and make complicated ethical judgments in its responses (n = 168). Finally, logistics regression analysis showed that pharmacists who had previous experience in using ChatGPT were more willing to integrate ChatGPT in their pharmacy practice than those with no previous experience in using ChatGPT (odds ratio 2.312, P = 0.035). Conclusion: Although pharmacists show a willingness to incorporate ChatGPT into their practice, especially those with previous experience, there are major concerns. These mainly revolve around the tool's ability to make human-like judgments and ethical decisions. These findings are crucial for the future development and integration of AI tools in pharmacy practice. © 2023 American Pharmacists Association®
KW  - Artificial Intelligence
KW  - Attitude of Health Personnel
KW  - Community Pharmacy Services
KW  - Cross-Sectional Studies
KW  - Humans
KW  - Jordan
KW  - Pharmacists
KW  - Pharmacy
KW  - Professional Role
KW  - adult
KW  - Article
KW  - ChatGPT
KW  - clinical decision making
KW  - community pharmacist
KW  - controlled study
KW  - cross-sectional study
KW  - female
KW  - human
KW  - Jordan
KW  - Jordanian
KW  - male
KW  - personal experience
KW  - pharmacist attitude
KW  - pharmacy practice
KW  - scientist
KW  - social media
KW  - artificial intelligence
KW  - health personnel attitude
KW  - Jordan
KW  - pharmacist
KW  - pharmacy (shop)
KW  - professional standard
PB  - Elsevier B.V.
SN  - 15443191 (ISSN)
C2  - 37648157
LA  - English
J2  - J. Am. Pharm. Assoc.
M3  - Article
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 1; Correspondence Address: R. Abu-Farha; Clinical Pharmacy and Therapeutics Department, Faculty of Pharmacy, Applied Science Private University, Amman, P.O. Box 11937, Jordan; email: r_abufarha@asu.edu.jo
ER  -

TY  - JOUR
AU  - Chen, J.
AU  - Cadiente, A.
AU  - Kasselman, L.J.
AU  - Pilkington, B.
TI  - Assessing the performance of ChatGPT in bioethics: a large language model's moral compass in medicine
PY  - 2023
T2  - Journal of Medical Ethics
VL  - 50
IS  - 2
SP  - 97
EP  - 101
DO  - 10.1136/jme-2023-109366
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85177995685&doi=10.1136%2fjme-2023-109366&partnerID=40&md5=0d606b267fc392d8268b9b824db70903
AD  - Hackensack Meridian School of Medicine, Nutley, NJ, United States
AD  - Research Institute, Hackensack Meridian Health, Edison, NJ, United States
AB  - Chat Generative Pre-Trained Transformer (ChatGPT) has been a growing point of interest in medical education yet has not been assessed in the field of bioethics. This study evaluated the accuracy of ChatGPT-3.5 (April 2023 version) in answering text-based, multiple choice bioethics questions at the level of US third-year and fourth-year medical students. A total of 114 bioethical questions were identified from the widely utilised question banks UWorld and AMBOSS. Accuracy, bioethical categories, difficulty levels, specialty data, error analysis and character count were analysed. We found that ChatGPT had an accuracy of 59.6%, with greater accuracy in topics surrounding death and patient-physician relationships and performed poorly on questions pertaining to informed consent. Of all the specialties, it performed best in paediatrics. Yet, certain specialties and bioethical categories were under-represented. Among the errors made, it tended towards content errors and application errors. There were no significant associations between character count and accuracy. Nevertheless, this investigation contributes to the ongoing dialogue on artificial intelligence's (AI) role in healthcare and medical education, advocating for further research to fully understand AI systems' capabilities and constraints in the nuanced field of medical bioethics.  © 2023 BMJ Publishing Group. All rights reserved.
KW  - Decision Making
KW  - Education
KW  - Ethics- Medical
KW  - Artificial Intelligence
KW  - Child
KW  - Education, Medical
KW  - Humans
KW  - Language
KW  - Medicine
KW  - Morals
KW  - artificial intelligence
KW  - child
KW  - human
KW  - language
KW  - medical education
KW  - medicine
KW  - morality
PB  - BMJ Publishing Group
SN  - 03066800 (ISSN)
C2  - 37973369
LA  - English
J2  - J. Med. Ethics
M3  - Article
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 2; Correspondence Address: J. Chen; Hackensack Meridian School of Medicine, Nutley, United States; email: jamie.chen@hmhn.org; CODEN: JMETD
ER  -

TY  - JOUR
AU  - Massey, P.A.
AU  - Montgomery, C.
AU  - Zhang, A.S.
TI  - Comparison of ChatGPT-3.5, ChatGPT-4, and Orthopaedic Resident Performance on Orthopaedic Assessment Examinations
PY  - 2023
T2  - The Journal of the American Academy of Orthopaedic Surgeons
VL  - 31
IS  - 23
SP  - 1173
EP  - 1179
DO  - 10.5435/JAAOS-D-23-00396
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85177103813&doi=10.5435%2fJAAOS-D-23-00396&partnerID=40&md5=57baf2648ec006f515dc800fd0e68a16
AD  - From the Department of Orthopaedic Surgery, Louisiana State University Health Sciences Center Shreveport, Shreveport, LA, United States
AB  - INTRODUCTION: Artificial intelligence (AI) programs have the ability to answer complex queries including medical profession examination questions. The purpose of this study was to compare the performance of orthopaedic residents (ortho residents) against Chat Generative Pretrained Transformer (ChatGPT)-3.5 and GPT-4 on orthopaedic assessment examinations. A secondary objective was to perform a subgroup analysis comparing the performance of each group on questions that included image interpretation versus text-only questions. METHODS: The ResStudy orthopaedic examination question bank was used as the primary source of questions. One hundred eighty questions and answer choices from nine different orthopaedic subspecialties were directly input into ChatGPT-3.5 and then GPT-4. ChatGPT did not have consistently available image interpretation, so no images were directly provided to either AI format. Answers were recorded as correct versus incorrect by the chatbot, and resident performance was recorded based on user data provided by ResStudy. RESULTS: Overall, ChatGPT-3.5, GPT-4, and ortho residents scored 29.4%, 47.2%, and 74.2%, respectively. There was a difference among the three groups in testing success, with ortho residents scoring higher than ChatGPT-3.5 and GPT-4 ( P < 0.001 and P < 0.001). GPT-4 scored higher than ChatGPT-3.5 ( P = 0.002). A subgroup analysis was performed by dividing questions into question stems without images and question stems with images. ChatGPT-3.5 was more correct (37.8% vs. 22.4%, respectively, OR = 2.1, P = 0.033) and ChatGPT-4 was also more correct (61.0% vs. 35.7%, OR = 2.8, P < 0.001), when comparing text-only questions versus questions with images. Residents were 72.6% versus 75.5% correct with text-only questions versus questions with images, with no significant difference ( P = 0.302). CONCLUSION: Orthopaedic residents were able to answer more questions accurately than ChatGPT-3.5 and GPT-4 on orthopaedic assessment examinations. GPT-4 is superior to ChatGPT-3.5 for answering orthopaedic resident assessment examination questions. Both ChatGPT-3.5 and GPT-4 performed better on text-only questions than questions with images. It is unlikely that GPT-4 or ChatGPT-3.5 would pass the American Board of Orthopaedic Surgery written examination. Copyright © 2023 The Author(s). Published by Wolters Kluwer Health, Inc. on behalf of the American Academy of Orthopaedic Surgeons.
KW  - Artificial Intelligence
KW  - Humans
KW  - Orthopedics
KW  - Physical Examination
KW  - Software
KW  - artificial intelligence
KW  - human
KW  - orthopedics
KW  - physical examination
KW  - software
SN  - 19405480 (ISSN)
C2  - 37671415
LA  - English
J2  - J Am Acad Orthop Surg
M3  - Article
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 1
ER  -

TY  - JOUR
AU  - Roberts, R.H.R.
AU  - Ali, S.R.
AU  - Hutchings, H.A.
AU  - Dobbs, T.D.
AU  - Whitaker, I.S.
TI  - Comparative study of ChatGPT and human evaluators on the assessment of medical literature according to recognised reporting standards
PY  - 2023
T2  - BMJ Health and Care Informatics
VL  - 30
IS  - 1
C7  - e100830
DO  - 10.1136/bmjhci-2023-100830
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85174641052&doi=10.1136%2fbmjhci-2023-100830&partnerID=40&md5=a1e938d683a19f07b5d19e818e74858f
AD  - Reconstructive Surgery and Regenerative Medicine Research Centre, Swansea University, Swansea, United Kingdom
AD  - Swansea University Medical School, Swansea University, Swansea, United Kingdom
AD  - Welsh Centre for Burns and Plastic Surgery, Morriston Hospital, Swansea, United Kingdom
AB  - Introduction Amid clinicians' challenges in staying updated with medical research, artificial intelligence (AI) tools like the large language model (LLM) ChatGPT could automate appraisal of research quality, saving time and reducing bias. This study compares the proficiency of ChatGPT3 against human evaluation in scoring abstracts to determine its potential as a tool for evidence synthesis. Methods We compared ChatGPT's scoring of implant dentistry abstracts with human evaluators using the Consolidated Standards of Reporting Trials for Abstracts reporting standards checklist, yielding an overall compliance score (OCS). Bland-Altman analysis assessed agreement between human and AI-generated OCS percentages. Additional error analysis included mean difference of OCS subscores, Welch's t-test and Pearson's correlation coefficient. Results Bland-Altman analysis showed a mean difference of 4.92% (95% CI 0.62%, 0.37%) in OCS between human evaluation and ChatGPT. Error analysis displayed small mean differences in most domains, with the highest in € conclusion' (0.764 (95% CI 0.186, 0.280)) and the lowest in € blinding' (0.034 (95% CI 0.818, 0.895)). The strongest correlations between were in € harms' (r=0.32, p<0.001) and € trial registration' (r=0.34, p=0.002), whereas the weakest were in € intervention' (r=0.02, p<0.001) and € objective' (r=0.06, p<0.001). Conclusion LLMs like ChatGPT can help automate appraisal of medical literature, aiding in the identification of accurately reported research. Possible applications of ChatGPT include integration within medical databases for abstract evaluation. Current limitations include the token limit, restricting its usage to abstracts. As AI technology advances, future versions like GPT4 could offer more reliable, comprehensive evaluations, enhancing the identification of high-quality research and potentially improving patient outcomes. © 2023 BMJ Publishing Group. All rights reserved.
KW  - Artificial intelligence
KW  - Medical Informatics
KW  - Artificial Intelligence
KW  - Biomedical Research
KW  - Checklist
KW  - Databases, Factual
KW  - Humans
KW  - Patient Compliance
KW  - analytical error
KW  - Article
KW  - ChatGPT
KW  - checklist
KW  - comparative study
KW  - controlled study
KW  - data accuracy
KW  - data extraction
KW  - evaluation study
KW  - human
KW  - medical literature
KW  - medical research
KW  - performance indicator
KW  - artificial intelligence
KW  - factual database
KW  - medical research
KW  - patient compliance
PB  - BMJ Publishing Group
SN  - 26321009 (ISSN)
C2  - 37827724
LA  - English
J2  - BMJ Heal. care inf.
M3  - Article
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 0; Correspondence Address: R.H.R. Roberts; Reconstructive Surgery and Regenerative Medicine Research Centre, Swansea University, Swansea, United Kingdom; email: 838272@swansea.ac.uk
ER  -

TY  - CONF
AU  - Mannam, S.S.
AU  - Subtirelu, R.
AU  - Chauhan, D.
AU  - Ahmad, H.S.
AU  - Matache, I.M.
AU  - Bryan, K.
AU  - Chitta, S.V.K.
AU  - Bathula, S.C.
AU  - Turlip, R.
AU  - Wathen, C.
AU  - Ghenbot, Y.
AU  - Ajmera, S.
AU  - Blue, R.
AU  - Chen, H.I.
AU  - Ali, Z.S.
AU  - Malhotra, N.
AU  - Srinivasan, V.
AU  - Ozturk, A.K.
AU  - Yoon, J.W.
TI  - Large Language Model-Based Neurosurgical Evaluation Matrix: A Novel Scoring Criteria to Assess the Efficacy of ChatGPT as an Educational Tool for Neurosurgery Board Preparation
PY  - 2023
T2  - World Neurosurgery
VL  - 180
SP  - e765
EP  - e773
DO  - 10.1016/j.wneu.2023.10.043
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85175692817&doi=10.1016%2fj.wneu.2023.10.043&partnerID=40&md5=2d1da5bc37642b721f5ffbfdcab8a3df
AD  - Department of Neurosurgery, Perelman School of Medicine at the University of Pennsylvania, Philadelphia, PA, United States
AD  - Department of Physiology, Faculty of Medicine, Carol Davila University of Medicine and Pharmacy, Bucharest, Romania
AB  - Introduction: Technological advancements are reshaping medical education, with digital tools becoming essential in all levels of training. Amidst this transformation, the study explores the potential of ChatGPT, an artificial intelligence model by OpenAI, in enhancing neurosurgical board education. The focus extends beyond technology adoption to its effective utilization, with ChatGPT's proficiency evaluated against practice questions from the Primary Neurosurgery Written Board Exam. Methods: Using the Congress of Neurologic Surgeons (CNS) Self-Assessment Neurosurgery (SANS) Exam Board Review Prep questions, we conducted 3 rounds of analysis with ChatGPT. We developed a novel ChatGPT Neurosurgical Evaluation Matrix (CNEM) to assess the output quality, accuracy, concordance, and clarity of ChatGPT's answers. Results: ChatGPT achieved spot-on accuracy for 66.7% of prompted questions, 59.4% of unprompted questions, and 63.9% of unprompted questions with a leading phrase. Stratified by topic, accuracy ranged from 50.0% (Vascular) to 78.8% (Neuropathology). In comparison to SANS explanations, ChatGPT output was considered better in 19.1% of questions, equal in 51.6%, and worse in 29.3%. Concordance analysis showed that 95.5% of unprompted ChatGPT outputs and 97.4% of unprompted outputs with a leading phrase were aligned. Conclusions: Our study evaluated the performance of ChatGPT in neurosurgical board education by assessing its accuracy, clarity, and concordance. The findings highlight the potential and challenges of integrating AI technologies like ChatGPT into medical and neurosurgical board education. Further research is needed to refine these tools and optimize their performance for enhanced medical education and patient care. © 2023 Elsevier Inc.
KW  - AI evaluation matrix
KW  - Artificial intelligence
KW  - ChatGPT
KW  - Medical education technology
KW  - Neurosurgical education
KW  - Artificial Intelligence
KW  - Educational Status
KW  - Humans
KW  - Language
KW  - Neurosurgery
KW  - Neurosurgical Procedures
KW  - adult
KW  - artificial intelligence
KW  - ChatGPT
KW  - comparative effectiveness
KW  - conference paper
KW  - education
KW  - human
KW  - medical education
KW  - neuropathology
KW  - neurosurgery
KW  - patient care
KW  - self evaluation
KW  - surgeon
KW  - artificial intelligence
KW  - educational status
KW  - language
PB  - Elsevier Inc.
SN  - 18788750 (ISSN)
C2  - 37839567
LA  - English
J2  - World Neurosurg.
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 0; Correspondence Address: J.W. Yoon; Department of Neurosurgery, Perelman School of Medicine at the University of Pennsylvania, Philadelphia, United States; email: jang.yoon@pennmedicine.upenn.edu
ER  -

TY  - JOUR
AU  - Jazi, A.H.D.
AU  - Mahjoubi, M.
AU  - Shahabi, S.
AU  - Alqahtani, A.R.
AU  - Haddad, A.
AU  - Pazouki, A.
AU  - Prasad, A.
AU  - Safadi, B.Y.
AU  - Chiappetta, S.
AU  - Taskin, H.E.
AU  - Billy, H.T.
AU  - Kasama, K.
AU  - Mahawar, K.
AU  - Gawdat, K.
AU  - Rheinwalt, K.P.
AU  - Miller, K.A.
AU  - Kow, L.
AU  - Neto, M.G.
AU  - Yang, W.
AU  - Palermo, M.
AU  - Ghanem, O.M.
AU  - Lainas, P.
AU  - Peterli, R.
AU  - Kassir, R.
AU  - Puy, R.V.
AU  - Da Silva Ribeiro, R.J.
AU  - Verboonen, S.
AU  - Pintar, T.
AU  - Shabbir, A.
AU  - Musella, M.
AU  - Kermansaravi, M.
TI  - Bariatric Evaluation Through AI: a Survey of Expert Opinions Versus ChatGPT-4 (BETA-SEOV)
PY  - 2023
T2  - Obesity Surgery
VL  - 33
IS  - 12
SP  - 3971
EP  - 3980
DO  - 10.1007/s11695-023-06903-w
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85174936088&doi=10.1007%2fs11695-023-06903-w&partnerID=40&md5=303230878b51d0652e36b57e0494b7dd
AD  - Department of Surgery, Minimally Invasive Surgery Research Center, Division of Minimally Invasive and Bariatric Surgery, School of Medicine, Rasool-E Akram Hospital, Iran University of Medical Sciences, Niyaesh Avenue, Sattar Khan Street, Tehran, Iran
AD  - Clinical Research Development Center, Najafabad Branch, Islamic Azad University, Najafabad, Iran
AD  - New Medical Center, Riyadh, Saudi Arabia
AD  - Gastrointestinal Metabolic and Bariatric Center, GBMC M, Jordan Hospital, Amman, Jordan
AD  - GI, Bariatric and Robotic Surgery Apollo Hospital, New Delhi, India
AD  - Surgical Services Aman Hospital, Doha, Qatar
AD  - Bariatric and Metabolic Surgery Unit, Ospedale Evangelico Betania, Naples, Italy
AD  - Department of General Surgery, Cerrahpaşa Medical Faculty, Istanbul University Cerrahpaşa, Istanbul, Turkey
AD  - Ventura Advanced Surgical Associates, Ventura, CA, United States
AD  - Weight Loss and Metabolic Surgery Center, Yotsuya Medical Cube, Tokyo, Japan
AD  - Sunderland Royal Hospital, Sunderland, United Kingdom
AD  - Ain Shams University Faculty of Medicine Department of General Surgery, Cairo, Egypt
AD  - Department of Bariatric, Metabolic and Plastic Surgery, St. Franziskus Hospital, Cologne, Germany
AD  - Dubai London Hospital, Dubai, United Arab Emirates
AD  - Department GI Surgery Flinders, University South Australia, Adelaide, Australia
AD  - Mohak Bariatric and Robotic Center, Indore, India
AD  - The First Affiliated Hospital of Jinan University, Guangzhou, China
AD  - Gastrointestinal and Bariatric Surgery, University of Buenos Aires, Buenos Aires, Argentina
AD  - Mayo Clinic, Rochester, MN, United States
AD  - Department of Digestive and Bariatric Surgery, Metropolitan Hospital, HEAL Academy, Athens, Greece
AD  - Deputy Head of Visceral Surgery and Head of Bariatric-Metabolic Surgery Clarunis, Department of Visceral Surgery, University Centre for Gastrointestinal and Liver Diseases St. Clara Hospital and University Hospital Basel, Basel, 4002, Switzerland
AD  - Digestive Surgery Unit, University Hospital of La Réunion -Félix Guyon Hospital, Saint-Denis, La Réunion, France
AD  - Head Endocrine-Metabolic and Bariatric Surgery Unit, Vall Hebron Barcelona Hospital Campus, Pg. De La Vall d’hebron, 119-129, Barcelona, 08035, Spain
AD  - General Surgery Department, Multidisciplinary Center for Obesity Treatment - Hospital Lusíadas Amadora, Amadora, Portugal
AD  - Obesity Goodbye Center, Tijuana, Mexico
AD  - UMC Ljubljana, Department of Abdominal Surgery and Medical Faculty, Ljubljana, Slovenia
AD  - National University of Singapore, Singapore, Singapore
AD  - Advanced Biomedical Sciences Department, “Federico II” University, Naples, Italy
AB  - Background: Recent advancements in artificial intelligence, such as OpenAI’s ChatGPT-4, are revolutionizing various sectors, including healthcare. This study investigates the use of ChatGPT-4 in identifying suitable candidates for bariatric surgery and providing surgical recommendations to improve decision-making in obesity treatment amid the global obesity epidemic. Methods: We devised ten patient scenarios, thoughtfully encompassing a spectrum that spans from uncomplicated cases to more complex ones. Our objective was to delve into the decision-making process regarding the recommendation of bariatric surgery. From July 29th to August 10th, 2023, we conducted a voluntary online survey involving thirty prominent bariatric surgeons, ensuring that there was no predetermined bias in the selection of a specific type of bariatric surgery. This survey was designed to collect their insights on these scenarios and gain a deeper understanding of their professional experience and background in the field of bariatric surgery. Additionally, we consulted ChatGPT-4 in two separate conversations to evaluate its alignment with expert opinions on bariatric surgery options. Results: In 40% of the scenarios, disparities were identified between the two conversations with ChatGPT-4. It matched expert opinions in 30% of cases. Differences were noted in cases like gastrointestinal metaplasia and gastric adenocarcinoma, but there was alignment with conditions like endometriosis and GERD. Conclusion: The evaluation of ChatGPT-4’s role in determining bariatric surgery suitability uncovered both potential and shortcomings. Its alignment with experts was inconsistent, and it often overlooked key factors, emphasizing human expertise’s value. Its current use requires caution, and further refinement is needed for clinical application. Graphical Abstract: [Figure not available: see fulltext.] © 2023, The Author(s), under exclusive licence to Springer Science+Business Media, LLC, part of Springer Nature.
KW  - Artificial Intelligence
KW  - Bariatric Evaluation
KW  - Bariatric Surgery
KW  - ChatGPT
KW  - Health Literacy
KW  - Language Learning Models
KW  - Artificial Intelligence
KW  - Bariatrics
KW  - Expert Testimony
KW  - Female
KW  - Humans
KW  - Obesity
KW  - Obesity, Morbid
KW  - amlodipine
KW  - hydroxymethylglutaryl coenzyme A reductase inhibitor
KW  - losartan
KW  - mesalazine
KW  - metformin
KW  - omeprazole
KW  - oral contraceptive agent
KW  - proton pump inhibitor
KW  - salazosulfapyridine
KW  - adult
KW  - anastomosis
KW  - Article
KW  - artificial intelligence
KW  - bariatric surgery
KW  - biliopancreatic bypass
KW  - case report
KW  - ChatGPT
KW  - clinical article
KW  - controlled study
KW  - Crohn disease
KW  - decision making
KW  - diabetes mellitus
KW  - dyslipidemia
KW  - endometriosis
KW  - eosinophil
KW  - female
KW  - gastroesophageal reflux
KW  - health literacy
KW  - health survey
KW  - Helicobacter infection
KW  - human
KW  - hypertension
KW  - intestinal metaplasia
KW  - language development
KW  - male
KW  - middle aged
KW  - obesity
KW  - personal experience
KW  - Roux-en-Y gastric bypass
KW  - sleeve gastrectomy
KW  - stomach adenocarcinoma
KW  - stomach antrum
KW  - stomach biopsy
KW  - surgical technique
KW  - artificial intelligence
KW  - bariatrics
KW  - expert witness
KW  - morbid obesity
KW  - obesity
PB  - Springer
SN  - 09608923 (ISSN)
C2  - 37889368
LA  - English
J2  - Obes. Surg.
M3  - Article
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 0; Correspondence Address: S. Shahabi; Department of Surgery, Minimally Invasive Surgery Research Center, Division of Minimally Invasive and Bariatric Surgery, School of Medicine, Rasool-E Akram Hospital, Iran University of Medical Sciences, Tehran, Niyaesh Avenue, Sattar Khan Street, Iran; email: shshahabi@yahoo.com; CODEN: OBSUE
ER  -

TY  - JOUR
AU  - Pfau, A.
AU  - Polio, C.
AU  - Xu, Y.
TI  - Exploring the potential of ChatGPT in assessing L2 writing accuracy for research purposes
PY  - 2023
T2  - Research Methods in Applied Linguistics
VL  - 2
IS  - 3
C7  - 100083
DO  - 10.1016/j.rmal.2023.100083
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85175199125&doi=10.1016%2fj.rmal.2023.100083&partnerID=40&md5=08cb4a5ee1a58bb17d35701db35175ab
AD  - Michigan State University, MI, United States
AD  - The University of California, Merced, CA, United States
AB  - This study investigates ChatGPT's potential for measuring linguistic accuracy in second language writing for research purposes. We processed 100 L2 essays across five proficiency levels with ChatGPT-4 and manually coded for precision and recall with regard to ChatGPT's identification of errors. Our findings indicate a strong correlation (ρ = 0.97 using one method and .94 using another method) between ChatGPT's error detection and human coding, although this correlation diminishes with lower proficiency levels. While ChatGPT infrequently misidentifies errors, it often underestimates the total error count. The study also highlights ChatGPT's limitations, such as the issue of consistency, and provides guidelines for future research applications. © 2023
PB  - Elsevier B.V.
SN  - 27727661 (ISSN)
LA  - English
J2  - Res. Method. Appl. Linguist.
M3  - Article
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 0; Correspondence Address: C. Polio; Michigan State University, United States; email: polio@msu.edu
ER  -

TY  - JOUR
AU  - Robledo, D.A.R.
AU  - Zara, C.G.
AU  - Montalbo, S.M.
AU  - Gayeta, N.E.
AU  - Gonzales, A.L.
AU  - Escarez, M.G.A.
AU  - Maalihan, E.D.
TI  - Development and Validation of a Survey Instrument on Knowledge, Attitude, and Practices (KAP) Regarding the Educational Use of ChatGPT among Preservice Teachers in the Philippines
PY  - 2023
T2  - International Journal of Information and Education Technology
VL  - 13
IS  - 10
SP  - 1582
EP  - 1590
DO  - 10.18178/ijiet.2023.13.10.1965
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85174229180&doi=10.18178%2fijiet.2023.13.10.1965&partnerID=40&md5=436eedde672609df1a3699dcb8697ad8
AD  - Graduate School of Science and Engineering, Center for Marine and Environmental Studies of Ehime University, Matsuyama City, Japan
AD  - College of Teacher Education of the Batangas State University, The National Engineering University (BatStateU-TNEU), Batangas City, Philippines
AB  - ChatGPT has gained popularity among Philippine educational institutions due to its versatility and usefulness in academic activities. However, educators have raised concerns about the ethical issues, academic dishonesty, and technology dependence associated with its use. This study aimed to develop and validate an instrument called KAP-CQ39 that assesses the knowledge, attitudes, and practices of preservice teachers regarding the use of ChatGPT. The study involved 4 experts, 12 independent evaluators, and 206 preservice teachers. The instrument underwent a series of assessments to establish quality, validity, and reliability, resulting in the final version of KAP-CQ39. Results showed that KAP-CQ39 has acceptable content validity (CVR and CVI values>0.78), face validity (IS>1.5), construct validity (chi-squared value of 897.564, df=577, p<0.001), and internal consistency (overall Cronbach coefficient=0.91). This proved that KAP-CQ39 can be a valuable tool for assessing the impact of ChatGPT on the Philippine educational system and can provide insights for educational policy makers regarding the use of artificial intelligence in education. © 2023 by the authors.
KW  - Artificial intelligence-based education
KW  - attitude
KW  - ChatGPT
KW  - knowledge
KW  - practices
PB  - International Journal of Information and Education Technology
SN  - 20103689 (ISSN)
LA  - English
J2  - Int. J. Inf.  Educ. Technol.
M3  - Article
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 1; Correspondence Address: D.A.R. Robledo; Graduate School of Science and Engineering, Center for Marine and Environmental Studies of Ehime University, Matsuyama City, Japan; email: j865001u@mails.cc.ehime-u.ac.jp
ER  -

TY  - JOUR
AU  - Huang, C.
AU  - Hong, D.
AU  - Chen, L.
AU  - Chen, X.
TI  - Assess the precision of ChatGPT's responses regarding systemic lupus erythematosus (SLE) inquiries
PY  - 2023
T2  - Skin Research and Technology
VL  - 29
IS  - 10
C7  - e13500
DO  - 10.1111/srt.13500
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85174630684&doi=10.1111%2fsrt.13500&partnerID=40&md5=38a50bdb6d0c7524058d8d732bb29e1b
AD  - Department of General Practice, The Second Affiliated Hospital of Fujian Medical University, Fujian, Quanzhou City, China
AD  - Department of Ultrasonography, The Second Affiliated Hospital of Fujian Medical University, Fujian, Quanzhou City, China
AD  - Department of Endocrinology, The Second Affiliated Hospital of Fujian Medical University, Fujian, Quanzhou City, China
KW  - Humans
KW  - Lupus Erythematosus, Systemic
KW  - Severity of Illness Index
KW  - antimalarial agent
KW  - glucocorticoid
KW  - hydroxychloroquine
KW  - immunomodulating agent
KW  - immunosuppressive agent
KW  - nonsteroid antiinflammatory agent
KW  - steroid
KW  - breast feeding
KW  - ChatGPT
KW  - conception
KW  - data accuracy
KW  - dietary intake
KW  - environmental factor
KW  - genetic disorder
KW  - human
KW  - immunosuppressive treatment
KW  - infection prevention
KW  - Letter
KW  - lupus erythematosus nephritis
KW  - medical information
KW  - medical information system
KW  - pathogenesis
KW  - patient
KW  - practice guideline
KW  - pregnancy
KW  - steroid therapy
KW  - symptom
KW  - systemic lupus erythematosus
KW  - treatment duration
KW  - vaccination
KW  - severity of illness index
PB  - John Wiley and Sons Inc
SN  - 0909752X (ISSN)
C2  - 37881050
LA  - English
J2  - Skin Res. Technol.
M3  - Letter
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 0; Correspondence Address: X. Chen; Department of General Practice, The Second Affiliated Hospital of Fujian Medical University, Quanzhou City, Fujian, 362000, China; email: chenxiaoqing202203@163.com; CODEN: SRTEF
ER  -

TY  - CONF
AU  - Meyers, P.
AU  - Han, A.
AU  - Grewal, R.
AU  - Potnis, M.
AU  - Stamper, J.
TI  - Focal: A Proposed Method of Leveraging LLMs for Automating Assessments
PY  - 2023
T2  - 31st International Conference on Computers in Education, ICCE 2023 - Proceedings
VL  - 2
SP  - 349
EP  - 358
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85181767164&partnerID=40&md5=166c9681982c73f247dd289313470960
AD  - Carnegie Mellon University, United States
AB  - In response to the growing need for frequent, high-quality assessments in the expanding field of online learning and the significant time burden their manual creation places on educators, this study proposes Focal, an end-to-end assessment generation pipeline. Focal employs large language models, notably Text-to-Text Transfer Transformers, fine-trained on diverse learning materials, to generate and evaluate pedagogically sound questions and their corresponding answers. The Focal pipeline is designed to integrate with Learning Management Systems, providing educators an automated means of creating assessments that align with their curriculum. This not only eases the task of creating and evaluating assessments but also frees educators to focus on other crucial responsibilities. The system is domain agnostic and its efficacy is continually improved by training and evaluating it using data from multiple subject areas. By automating the traditionally labor-intensive process of assessment production, Focal aims to increase efficiency in online education and enhance the learning experience for students. © 2023 Asia-Pacific Society for Computers in Education.
KW  - Assessment Generation
KW  - Large Language Models
KW  - Question Generation
KW  - Computational linguistics
KW  - E-learning
KW  - Learning systems
KW  - Pipelines
KW  - Assessment generation
KW  - End to end
KW  - High quality
KW  - Language model
KW  - Large language model
KW  - Learning management system
KW  - Learning materials
KW  - Online learning
KW  - Quality assessment
KW  - Question generation
KW  - Curricula
A2  - Shih J.-L.
A2  - Kashihara A.
A2  - Chen W.
A2  - Chen W.
A2  - Ogata H.
A2  - Baker R.
A2  - Chang B.
A2  - Dianati S.
A2  - Madathil J.
A2  - Yousef A.M.F.
A2  - Yang Y.
A2  - Zarzour H.
PB  - Asia-Pacific Society for Computers in Education
SN  - 978-626968902-6 (ISBN)
LA  - English
J2  - Int. Conf. Comput. Educ., ICCE - Proc.
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 0; Correspondence Address: J. Stamper; Carnegie Mellon University, United States; email: jstamper@cs.cmu.edu; Conference name: 31st International Conference on Computers in Education, ICCE 2023; Conference date: 4 December 2023 through 8 December 2023; Conference code: 195491
ER  -

TY  - JOUR
AU  - de Winter, J.C.F.
AU  - Dodou, D.
AU  - Stienen, A.H.A.
TI  - ChatGPT in Education: Empowering Educators through Methods for Recognition and Assessment
PY  - 2023
T2  - Informatics
VL  - 10
IS  - 4
C7  - 87
DO  - 10.3390/informatics10040087
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85180645994&doi=10.3390%2finformatics10040087&partnerID=40&md5=b7f2b11d61d58094f08e49ae5b3257c3
AD  - Department of Cognitive Robotics, Faculty of Mechanical Engineering, Delft University of Technology, Mekelweg 2, Delft, 2628 CD, Netherlands
AD  - Department of Biomechanical Engineering, Faculty of Mechanical Engineering, Delft University of Technology, Mekelweg 2, Delft, 2628 CD, Netherlands
AB  - ChatGPT is widely used among students, a situation that challenges educators. The current paper presents two strategies that do not push educators into a defensive role but can empower them. Firstly, we show, based on statistical analysis, that ChatGPT use can be recognized from certain keywords such as ‘delves’ and ‘crucial’. This insight allows educators to detect ChatGPT-assisted work more effectively. Secondly, we illustrate that ChatGPT can be used to assess texts written by students. The latter topic was presented in two interactive workshops provided to educators and educational specialists. The results of the workshops, where prompts were tested live, indicated that ChatGPT, provided a targeted prompt is used, is good at recognizing errors in texts but not consistent in grading. Ethical and copyright concerns were raised as well in the workshops. In conclusion, the methods presented in this paper may help fortify the teaching methods of educators. The computer scripts that we used for live prompting are available and enable educators to give similar workshops. © 2023 by the authors.
KW  - chatbot
KW  - education
KW  - student assessment
PB  - Multidisciplinary Digital Publishing Institute (MDPI)
SN  - 22279709 (ISSN)
LA  - English
J2  - Informatics
M3  - Article
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 0; Correspondence Address: J.C.F. de Winter; Department of Cognitive Robotics, Faculty of Mechanical Engineering, Delft University of Technology, Delft, Mekelweg 2, 2628 CD, Netherlands; email: j.c.f.dewinter@tudelft.nl
ER  -

TY  - JOUR
AU  - Huang, C.
AU  - Chen, L.
AU  - Huang, H.
AU  - Cai, Q.
AU  - Lin, R.
AU  - Wu, X.
AU  - Zhuang, Y.
AU  - Jiang, Z.
TI  - Evaluate the accuracy of ChatGPT’s responses to diabetes questions and misconceptions
PY  - 2023
T2  - Journal of Translational Medicine
VL  - 21
IS  - 1
C7  - 502
DO  - 10.1186/s12967-023-04354-6
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85165899606&doi=10.1186%2fs12967-023-04354-6&partnerID=40&md5=49f962300717ca8492391a1681f34d66
AD  - Department of Outpatient Electrocardiography, The Second Affiliated Hospital of Fujian Medical University, Fujian, Quanzhou, 362000, China
AD  - Department of Endocrinology, The Second Affiliated Hospital of Fujian Medical University, No. 950 Donghai Street, Fengze District, Fujian, Quanzhou, 362000, China
KW  - accuracy
KW  - artificial intelligence
KW  - Chat Generative Pre trained Transformer
KW  - deep learning
KW  - diabetes mellitus
KW  - glucose blood level
KW  - health care personnel
KW  - human
KW  - insulin resistance
KW  - Letter
KW  - obesity
KW  - remission
PB  - BioMed Central Ltd
SN  - 14795876 (ISSN)
C2  - 37495984
LA  - English
J2  - J. Transl. Med.
M3  - Letter
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 1; Correspondence Address: H. Huang; Department of Endocrinology, The Second Affiliated Hospital of Fujian Medical University, Quanzhou, No. 950 Donghai Street, Fengze District, Fujian, 362000, China; email: huibinhuang@aliyun.com
ER  -

TY  - JOUR
AU  - Venerito, V.
AU  - Puttaswamy, D.
AU  - Iannone, F.
AU  - Gupta, L.
TI  - Large language models and rheumatology: a comparative evaluation
PY  - 2023
T2  - The Lancet Rheumatology
VL  - 5
IS  - 10
SP  - e574
EP  - e578
DO  - 10.1016/S2665-9913(23)00216-3
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85171883818&doi=10.1016%2fS2665-9913%2823%2900216-3&partnerID=40&md5=1907720ab6186ffe150ba80f74920322
AD  - Department of Precision and Regenerative Medicine and Ionian Area-Rheumatology Unit, University of Bari Aldo Moro, Bari, Italy
AD  - Seth Gordhandhas Sunderdas Medical College and King Edward Memorial Hospital, Maharashtra, Mumbai, India
AD  - Department of Rheumatology, Royal Wolverhampton Hospitals NHS Trust, Wolverhampton, WV10 0QP, United Kingdom
AD  - Division of Musculoskeletal and Dermatological Sciences, Centre for Musculoskeletal Research, School of Biological Sciences, Faculty of Biology, Medicine and Health, Manchester Academic Health Science Centre The University of Manchester, Manchester, United Kingdom
AD  - Department of Rheumatology, City Hospital, Sandwell and West Birmingham Hospitals NHS Trust, Birmingham, United Kingdom
KW  - anamnesis
KW  - clinical practice
KW  - correlational study
KW  - differential diagnosis
KW  - education
KW  - electronic medical record
KW  - epidemiology
KW  - false negative result
KW  - general practitioner
KW  - human
KW  - imaging
KW  - infection
KW  - information security
KW  - laboratory test
KW  - language model
KW  - mucosal disease
KW  - Note
KW  - personalized medicine
KW  - physician
KW  - privacy
KW  - rheumatic disease
KW  - rheumatology
KW  - search engine
KW  - skin disease
KW  - treatment planning
PB  - Elsevier Ltd
SN  - 26659913 (ISSN)
LA  - English
J2  - Lancet Rheumat.
M3  - Note
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 3
ER  -

TY  - JOUR
AU  - Al-Dujaili, Z.
AU  - Omari, S.
AU  - Pillai, J.
AU  - Al Faraj, A.
TI  - Assessing the accuracy and consistency of ChatGPT in clinical pharmacy management: A preliminary analysis with clinical pharmacy experts worldwide
PY  - 2023
T2  - Research in Social and Administrative Pharmacy
VL  - 19
IS  - 12
SP  - 1590
EP  - 1594
DO  - 10.1016/j.sapharm.2023.08.012
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85170276076&doi=10.1016%2fj.sapharm.2023.08.012&partnerID=40&md5=3aeb853471579997a2c96bd6a40ce535
AD  - College of Pharmacy, American University of Iraq – Baghdad (AUIB), Baghdad, Iraq
AD  - Department of Epidemiology and Population Health, American University of Beirut (AUB), Beirut, Lebanon
AB  - Background: ChatGPT conversation system has ushered in a revolutionary new era of information retrieval and stands as one of the fastest-growing platforms. Clinical pharmacy, as a dynamic discipline, necessitates an advanced comprehension of drugs and diseases. The process of decision-making in clinical pharmacy demands accuracy and consistency in medical information, as it directly affects patient safety. Objective: The objective was to evaluate ChatGPT's accuracy and consistency in managing pharmacotherapy cases across multiple time points. Additionally, input was gathered from global clinical pharmacy experts, and the agreement between ChatGPT's responses and those of clinical pharmacy experts worldwide was assessed. Methods: A set of 20 cases of pharmacotherapy was entered into ChatGPT at three different time points. Reliability analysis was performed using inter-rater reliability to measure the accuracy of the output generated by ChatGPT at each time point. Test-retest reliability was performed to measure the consistency of the output generated by ChatGPT across the three time points. Pharmacy expert performance was evaluated, and the overall results were compared. Results: ChatGPT achieved a hit rate of 70.83% at week 1, 79.2% at week 3, and 75% at week 5. The percent agreement between weeks 1 and 3 was 79.2%, whereas it was 87.5% between weeks 3 and 5, and 83.3% between weeks 1 and 5. In contrast, accuracy rates among clinical pharmacy experts showed considerable variation according to their geographic location. The highest agreement between clinical pharmacist responses and ChatGPT responses was observed at the last time point examined. Conclusions: Overall, the analysis suggested that ChatGPT is capable of generating clinically relevant pharmaceutical information, albeit with some variation in accuracy and consistency. It should be noted that clinical pharmacy experts worldwide may provide varying degrees of accuracy depending on their expertise. This study highlights the potential of AI chatbots in clinical pharmacy. © 2023 Elsevier Inc.
KW  - AI chatbot
KW  - ChatGPT
KW  - Clinical pharmacy
KW  - Decision making
KW  - Pharmacotherapy
PB  - Elsevier Inc.
SN  - 15517411 (ISSN)
LA  - English
J2  - Res. Soc. Adm. Pharm.
M3  - Article
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 3; Correspondence Address: A. Al Faraj; College of Pharmacy, American University of Iraq – Baghdad (AUIB), Baghdad, Airport Road, 10023, Iraq; email: achraf.alfaraj@gmail.com
ER  -

TY  - JOUR
AU  - Choi, W.
TI  - Assessment of the capacity of ChatGPT as a self-learning tool in medical pharmacology: a study using MCQs
PY  - 2023
T2  - BMC Medical Education
VL  - 23
IS  - 1
C7  - 864
DO  - 10.1186/s12909-023-04832-x
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85176315707&doi=10.1186%2fs12909-023-04832-x&partnerID=40&md5=ed719be3c449821095cf8d4ea5a9d611
AD  - Department of Pharmacology, College of Medicine, Chungbuk National University, Chungbuk, Cheongju, 28644, South Korea
AB  - Background: ChatGPT is a large language model developed by OpenAI that exhibits a remarkable ability to simulate human speech. This investigation attempts to evaluate the potential of ChatGPT as a standalone self-learning tool, with specific attention on its efficacy in answering multiple-choice questions (MCQs) and providing credible rationale for its responses. Methods: The study used 78 test items from the Korean Comprehensive Basic Medical Sciences Examination (K-CBMSE) for years 2019 to 2021. 78 test items translated from Korean to English with four lead-in prompts per item resulted in a total of 312 MCQs. The MCQs were submitted to ChatGPT and the responses were analyzed for correctness, consistency, and relevance. Results: ChatGPT responded with an overall accuracy of 76.0%. Compared to its performance on recall and interpretation questions, the model performed poorly on problem-solving questions. ChatGPT offered correct rationales for 77.8% (182/234) of the responses, with errors primarily arising from faulty information and flawed reasoning. In terms of references, ChatGPT provided incorrect citations for 69.7% (191/274) of the responses. While the veracity of reference paragraphs could not be ascertained, 77.0% (47/61) were deemed pertinent and accurate with respect to the answer key. Conclusion: The current version of ChatGPT has limitations in accurately answering MCQs and generating correct and relevant rationales, particularly when it comes to referencing. To avoid possible threats such as spreading inaccuracies and decreasing critical thinking skills, ChatGPT should be used with supervision. © 2023, The Author(s).
KW  - ChatGPT
KW  - Large language model
KW  - Multiple-choice questions
KW  - Performance
KW  - Rationale
KW  - Referencing
KW  - Self-directed learning
KW  - Asian People
KW  - Humans
KW  - Language
KW  - Learning
KW  - Mental Recall
KW  - Problem Solving
KW  - article
KW  - ChatGPT
KW  - controlled study
KW  - critical thinking
KW  - human
KW  - human experiment
KW  - learning
KW  - multiple choice test
KW  - problem solving
KW  - reasoning
KW  - recall
KW  - self-directed learning
KW  - skill
KW  - Asian
KW  - language
KW  - problem solving
PB  - BioMed Central Ltd
SN  - 14726920 (ISSN)
C2  - 37957666
LA  - English
J2  - BMC Med. Educ.
M3  - Article
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 0; Correspondence Address: W. Choi; Department of Pharmacology, College of Medicine, Chungbuk National University, Cheongju, Chungbuk, 28644, South Korea; email: wchoi@chungbuk.ac.kr
ER  -

TY  - JOUR
AU  - Balas, M.
AU  - Wadden, J.J.
AU  - Hébert, P.C.
AU  - Mathison, E.
AU  - Warren, M.D.
AU  - Seavilleklein, V.
AU  - Wyzynski, D.
AU  - Callahan, A.
AU  - Crawford, S.A.
AU  - Arjmand, P.
AU  - Ing, E.B.
TI  - Exploring the potential utility of AI large language models for medical ethics: an expert panel evaluation of GPT-4
PY  - 2023
T2  - Journal of Medical Ethics
VL  - 50
IS  - 2
SP  - 90
EP  - 96
DO  - 10.1136/jme-2023-109549
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85177486287&doi=10.1136%2fjme-2023-109549&partnerID=40&md5=cf3fbaf3d45731491f21396d8c2729a3
AD  - Temerty Faculty of Medicine, University of Toronto, Toronto, ON, Canada
AD  - Centre for Clinical Ethics, Unity Health Toronto, Toronto, ON, Canada
AD  - Clinical Ethics, Scarborough Health Network, Scarborough, ON, Canada
AD  - Department of Family and Community Medicine, University of Toronto, Toronto, ON, Canada
AD  - Philosophy, University of Toronto, Toronto, ON, Canada
AD  - Bioethics, Dalhousie University, Halifax, NS, Canada
AD  - Clinical Ethics Service, Alberta Health Services, Edmonton, AB, Canada
AD  - Office of Health Ethics, London Health Sciences Centre, London, ON, Canada
AD  - Ethics Department, Ontario Shores Centre for Mental Health Sciences, Whitby, ON, Canada
AD  - Division of Vascular Surgery, Department of Surgery, University Health Network, Toronto, ON, Canada
AD  - Mississauga Retina Institute, Toronto, ON, Canada
AD  - Ophthalmology, University of Alberta, Edmonton, AB, Canada
AB  - Integrating large language models (LLMs) like GPT-4 into medical ethics is a novel concept, and understanding the effectiveness of these models in aiding ethicists with decision-making can have significant implications for the healthcare sector. Thus, the objective of this study was to evaluate the performance of GPT-4 in responding to complex medical ethical vignettes and to gauge its utility and limitations for aiding medical ethicists. Using a mixed-methods, cross-sectional survey approach, a panel of six ethicists assessed LLM-generated responses to eight ethical vignettes. The main outcomes measured were relevance, reasoning, depth, technical and non-technical clarity, as well as acceptability of GPT-4's responses. The readability of the responses was also assessed. Of the six metrics evaluating the effectiveness of GPT-4's responses, the overall mean score was 4.1/5. GPT-4 was rated highest in providing technical (4.7/5) and non-technical clarity (4.4/5), whereas the lowest rated metrics were depth (3.8/5) and acceptability (3.8/5). There was poor-to-moderate inter-rater reliability characterised by an intraclass coefficient of 0.54 (95% CI: 0.30 to 0.71). Based on panellist feedback, GPT-4 was able to identify and articulate key ethical issues but struggled to appreciate the nuanced aspects of ethical dilemmas and misapplied certain moral principles. This study reveals limitations in the ability of GPT-4 to appreciate the depth and nuanced acceptability of real-world ethical dilemmas, particularly those that require a thorough understanding of relational complexities and context-specific values. Ongoing evaluation of LLM capabilities within medical ethics remains paramount, and further refinement is needed before it can be used effectively in clinical settings.  © 2023 BMJ Publishing Group. All rights reserved.
KW  - Decision-making
KW  - Ethics- Medical
KW  - Information Technology
KW  - Cross-Sectional Studies
KW  - Ethicists
KW  - Ethics, Medical
KW  - Humans
KW  - Problem Solving
KW  - Reproducibility of Results
KW  - cross-sectional study
KW  - ethicist
KW  - human
KW  - medical ethics
KW  - problem solving
KW  - reproducibility
PB  - BMJ Publishing Group
SN  - 03066800 (ISSN)
C2  - 37945336
LA  - English
J2  - J. Med. Ethics
M3  - Article
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 0; Correspondence Address: M. Balas; Temerty Faculty of Medicine, University of Toronto, Toronto, Canada; email: 1michaelbalas@gmail.com; CODEN: JMETD
ER  -

TY  - JOUR
AU  - Cacciamani, G.
TI  - Evaluating the Effectiveness of Artificial Intelligenceepowered Large Language Models Application in Disseminating Appropriate and Readable Health Information in Urology. Reply.
PY  - 2023
T2  - Journal of Urology
VL  - 210
IS  - 5
SP  - 736
EP  - 737
DO  - 10.1097/JU.0000000000003656
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85171645396&doi=10.1097%2fJU.0000000000003656&partnerID=40&md5=4f6f3aa5b1f5efa8f8dd9940fc1be2f5
AD  - The Catherine and Joseph Aresty Department of Urology, USC Institute of Urology, Keck School of Medicine, University of Southern California, Los Angeles, CA, United States
AD  - AI Center at USC Urology, USC Institute of Urology, University of Southern California, Los Angeles, CA, United States
AD  - Department of Radiology, Keck School of Medicine, University of Southern California, Los Angeles, CA, United States
KW  - artificial intelligence
KW  - ChatGPT
KW  - clinical effectiveness
KW  - clinical practice
KW  - futurology
KW  - generalist medical artificial intelligence
KW  - human
KW  - information dissemination
KW  - large language model
KW  - Letter
KW  - medical information
KW  - urology
PB  - Wolters Kluwer Health
SN  - 00225347 (ISSN)
C2  - 37624687
LA  - English
J2  - J. Urol.
M3  - Letter
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 3; CODEN: JOURA
ER  -

TY  - JOUR
AU  - Mika, A.P.
AU  - Martin, J.R.
AU  - Engstrom, S.M.
AU  - Polkowski, G.G.
AU  - Wilson, J.M.
TI  - Assessing ChatGPT Responses to Common Patient Questions Regarding Total Hip Arthroplasty
PY  - 2023
T2  - Journal of Bone and Joint Surgery
VL  - 105
IS  - 19
SP  - 1519
EP  - 1526
DO  - 10.2106/JBJS.23.00209
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85173562673&doi=10.2106%2fJBJS.23.00209&partnerID=40&md5=c871ca60c1e162dbc7970e1438b434bc
AD  - Department of Orthopedic Surgery, Vanderbilt University Medical Center, Nashville, TN, United States
AB  - Background:The contemporary patient has access to numerous resources on common orthopaedic procedures before ever presenting for a clinical evaluation. Recently, artificial intelligence (AI)-driven chatbots have become mainstream, allowing patients to engage with interfaces that supply convincing, human-like responses to prompts. ChatGPT (OpenAI), a recently developed AI-based chat technology, is one such application that has garnered rapid growth in popularity. Given the likelihood that patients may soon call on this technology for preoperative education, we sought to determine whether ChatGPT could appropriately answer frequently asked questions regarding total hip arthroplasty (THA).Methods:Ten frequently asked questions regarding total hip arthroplasty were posed to the chatbot during a conversation thread, with no follow-up questions or repetition. Each response was analyzed for accuracy with use of an evidence-based approach. Responses were rated as "excellent response not requiring clarification," "satisfactory requiring minimal clarification," "satisfactory requiring moderate clarification," or "unsatisfactory requiring substantial clarification."Results:Of the responses given by the chatbot, only 1 received an "unsatisfactory" rating; 2 did not require any correction, and the majority required either minimal (4 of 10) or moderate (3 of 10) clarification. Although several responses required nuanced clarification, the chatbot's responses were generally unbiased and evidence-based, even for controversial topics.Conclusions:The chatbot effectively provided evidence-based responses to questions commonly asked by patients prior to THA. The chatbot presented information in a way that most patients would be able to understand. This resource may serve as a valuable clinical tool for patient education and understanding prior to orthopaedic consultation in the future. © 2023 Lippincott Williams and Wilkins. All rights reserved.
KW  - Arthroplasty, Replacement, Hip
KW  - Artificial Intelligence
KW  - Communication
KW  - Humans
KW  - Orthopedic Procedures
KW  - Orthopedics
KW  - adult
KW  - article
KW  - ChatGPT
KW  - consultation
KW  - conversation
KW  - follow up
KW  - human
KW  - patient education
KW  - preoperative education
KW  - total hip replacement
KW  - artificial intelligence
KW  - hip replacement
KW  - interpersonal communication
KW  - orthopedic surgery
KW  - orthopedics
PB  - Lippincott Williams and Wilkins
SN  - 00219355 (ISSN)
C2  - 37459402
LA  - English
J2  - J. Bone Jt. Surg.
M3  - Article
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 3; Correspondence Address: J.M. Wilson; Department of Orthopedic Surgery, Vanderbilt University Medical Center, Nashville, United States; email: jacobmwilson12@gmail.com; CODEN: JBJSA
ER  -

TY  - JOUR
AU  - Guillen-Grima, F.
AU  - Guillen-Aguinaga, S.
AU  - Guillen-Aguinaga, L.
AU  - Alas-Brun, R.
AU  - Onambele, L.
AU  - Ortega, W.
AU  - Montejo, R.
AU  - Aguinaga-Ontoso, E.
AU  - Barach, P.
AU  - Aguinaga-Ontoso, I.
TI  - Evaluating the Efficacy of ChatGPT in Navigating the Spanish Medical Residency Entrance Examination (MIR): Promising Horizons for AI in Clinical Medicine
PY  - 2023
T2  - Clinics and Practice
VL  - 13
IS  - 6
SP  - 1460
EP  - 1487
DO  - 10.3390/clinpract13060130
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85180716860&doi=10.3390%2fclinpract13060130&partnerID=40&md5=2aba15ab147e20fc2c11887e0eb9b272
AD  - Department of Health Sciences, Public University of Navarra, Pamplona, 31008, Spain
AD  - Healthcare Research Institute of Navarra (IdiSNA), Pamplona, 31008, Spain
AD  - Department of Preventive Medicine, Clinica Universidad de Navarra, Pamplona, 31008, Spain
AD  - CIBER in Epidemiology and Public Health (CIBERESP), Institute of Health Carlos III, Madrid, 46980, Spain
AD  - Department of Nursing, Kystad Helse-og Velferdssenter, Trondheim, 7026, Norway
AD  - School of Health Sciences, Catholic University of Central Africa, Yaoundé, 1100, Cameroon
AD  - Department of Surgery, Medical and Social Sciences, University of Alcala de Henares, Alcalá de Henares, 28871, Spain
AD  - Department of Obstetrics and Gynecology, Institute of Clinical Sciences, University of Gothenburg, Gothenburg, 413 46, Sweden
AD  - Department of Obstetrics and Gynecology, Sahlgrenska University Hospital, Gothenburg, 413 46, Sweden
AD  - Department of Sociosanitary Sciences, University of Murcia, Murcia, 30100, Spain
AD  - Jefferson College of Population Health, Philadelphia, 19107, PA, United States
AD  - School of Medicine, Thomas Jefferson University, Philadelphia, 19107, PA, United States
AD  - Interdisciplinary Research Institute for Health Law and Science, Sigmund Freud University, Vienna, 1020, Austria
AD  - Department of Surgery, Imperial College, London, SW7 2AZ, United Kingdom
AB  - The rapid progress in artificial intelligence, machine learning, and natural language processing has led to increasingly sophisticated large language models (LLMs) for use in healthcare. This study assesses the performance of two LLMs, the GPT-3.5 and GPT-4 models, in passing the MIR medical examination for access to medical specialist training in Spain. Our objectives included gauging the model’s overall performance, analyzing discrepancies across different medical specialties, discerning between theoretical and practical questions, estimating error proportions, and assessing the hypothetical severity of errors committed by a physician. Material and methods: We studied the 2022 Spanish MIR examination results after excluding those questions requiring image evaluations or having acknowledged errors. The remaining 182 questions were presented to the LLM GPT-4 and GPT-3.5 in Spanish and English. Logistic regression models analyzed the relationships between question length, sequence, and performance. We also analyzed the 23 questions with images, using GPT-4’s new image analysis capability. Results: GPT-4 outperformed GPT-3.5, scoring 86.81% in Spanish (p < 0.001). English translations had a slightly enhanced performance. GPT-4 scored 26.1% of the questions with images in English. The results were worse when the questions were in Spanish, 13.0%, although the differences were not statistically significant (p = 0.250). Among medical specialties, GPT-4 achieved a 100% correct response rate in several areas, and the Pharmacology, Critical Care, and Infectious Diseases specialties showed lower performance. The error analysis revealed that while a 13.2% error rate existed, the gravest categories, such as “error requiring intervention to sustain life” and “error resulting in death”, had a 0% rate. Conclusions: GPT-4 performs robustly on the Spanish MIR examination, with varying capabilities to discriminate knowledge across specialties. While the model’s high success rate is commendable, understanding the error severity is critical, especially when considering AI’s potential role in real-world medical practice and its implications for patient safety. © 2023 by the authors.
KW  - artificial intelligence
KW  - ChatGPT
KW  - GPT-3.5
KW  - GPT-4
KW  - image
KW  - large language model
KW  - machine learning
KW  - medical education
KW  - patient safety
KW  - quality of care
KW  - Article
KW  - artificial intelligence
KW  - ChatGPT
KW  - clinical medicine
KW  - computer assisted tomography
KW  - electrocardiogram
KW  - genealogy
KW  - health care quality
KW  - hospitalization
KW  - human
KW  - hysterosalpingography
KW  - image analysis
KW  - intensive care
KW  - interrater reliability
KW  - large language model
KW  - laryngoscopy
KW  - machine learning
KW  - medical education
KW  - medical examination
KW  - medical residency entrance examination
KW  - natural language processing
KW  - nuclear magnetic resonance imaging
KW  - patient safety
KW  - positron emission tomography-computed tomography
KW  - questionnaire
KW  - regression model
KW  - Spaniard
KW  - X ray
PB  - Multidisciplinary Digital Publishing Institute (MDPI)
SN  - 20397283 (ISSN)
LA  - English
J2  - Clin. Pract.
M3  - Article
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 1; Correspondence Address: F. Guillen-Grima; Department of Health Sciences, Public University of Navarra, Pamplona, 31008, Spain; email: f.guillen.grima@unavarra.es; I. Aguinaga-Ontoso; Department of Health Sciences, Public University of Navarra, Pamplona, 31008, Spain; email: ines.aguinaga@unavarra.es
ER  -

TY  - JOUR
AU  - Shen, K.
AU  - Kejriwal, M.
TI  - Quantifying confidence shifts in a BERT-based question answering system evaluated on perturbed instances
PY  - 2023
T2  - PLoS ONE
VL  - 18
IS  - 12 December
C7  - e0295925
DO  - 10.1371/journal.pone.0295925
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85180269281&doi=10.1371%2fjournal.pone.0295925&partnerID=40&md5=1beb291e4c9aa3e04254dbc172414789
AD  - Information Sciences Institute, University of Southern California, Marina del Rey, CA, United States
AB  - Recent work on transformer-based neural networks has led to impressive advances on multiple-choice natural language processing (NLP) problems, such as Question Answering (QA) and abductive reasoning. Despite these advances, there is limited work still on systematically evaluating such models in ambiguous situations where (for example) no correct answer exists for a given prompt among the provided set of choices. Such ambiguous situations are not infrequent in real world applications. We design and conduct an experimental study of this phenomenon using three probes that aim to 'confuse' the model by perturbing QA instances in a consistent and well-defined manner. Using a detailed set of results based on an established transformer-based multiple-choice QA system on two established benchmark datasets, we show that the model's confidence in its results is very different from that of an expected model that is 'agnostic' to all choices that are incorrect. Our results suggest that high performance on idealized QA instances should not be used to infer or extrapolate similarly high performance on more ambiguous instances. Auxiliary results suggest that the model may not be able to distinguish between these two situations with sufficient certainty. Stronger testing protocols and benchmarking may hence be necessary before such models are deployed in frontfacing systems or ambiguous decision making with significant human impact. Copyright:  © 2023 Shen, Kejriwal. This is an open access article distributed under the terms of the Creative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.
KW  - Humans
KW  - Information Storage and Retrieval
KW  - Natural Language Processing
KW  - Neural Networks, Computer
KW  - abductive reasoning
KW  - Agnostic
KW  - article
KW  - benchmarking
KW  - decision making
KW  - experimental study
KW  - human
KW  - multiple choice test
KW  - natural language processing
KW  - nerve cell network
KW  - open access publishing
KW  - artificial neural network
KW  - information retrieval
PB  - Public Library of Science
SN  - 19326203 (ISSN)
C2  - 38117790
LA  - English
J2  - PLoS ONE
M3  - Article
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 0; Correspondence Address: M. Kejriwal; Information Sciences Institute, University of Southern California, Marina del Rey, United States; email: kejriwal@isi.edu; CODEN: POLNC
ER  -

TY  - JOUR
AU  - Taloni, A.
AU  - Borselli, M.
AU  - Scarsi, V.
AU  - Rossi, C.
AU  - Coco, G.
AU  - Scorcia, V.
AU  - Giannaccare, G.
TI  - Comparative performance of humans versus GPT-4.0 and GPT-3.5 in the self-assessment program of American Academy of Ophthalmology
PY  - 2023
T2  - Scientific Reports
VL  - 13
IS  - 1
C7  - 18562
DO  - 10.1038/s41598-023-45837-2
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85175177401&doi=10.1038%2fs41598-023-45837-2&partnerID=40&md5=bd9c103af9e672ed9bf801993edd706c
AD  - Department of Ophthalmology, University Magna Graecia of Catanzaro, Catanzaro, Italy
AD  - Department of Clinical Sciences and Translational Medicine, University of Rome Tor Vergata, Rome, Italy
AD  - Department of Surgical Sciences, Eye Clinic, University of Cagliari, Via Università 40, Cagliari, 09124, Italy
AB  - To compare the performance of humans, GPT-4.0 and GPT-3.5 in answering multiple-choice questions from the American Academy of Ophthalmology (AAO) Basic and Clinical Science Course (BCSC) self-assessment program, available at https://www.aao.org/education/self-assessments . In June 2023, text-based multiple-choice questions were submitted to GPT-4.0 and GPT-3.5. The AAO provides the percentage of humans who selected the correct answer, which was analyzed for comparison. All questions were classified by 10 subspecialties and 3 practice areas (diagnostics/clinics, medical treatment, surgery). Out of 1023 questions, GPT-4.0 achieved the best score (82.4%), followed by humans (75.7%) and GPT-3.5 (65.9%), with significant difference in accuracy rates (always P < 0.0001). Both GPT-4.0 and GPT-3.5 showed the worst results in surgery-related questions (74.6% and 57.0% respectively). For difficult questions (answered incorrectly by > 50% of humans), both GPT models favorably compared to humans, without reaching significancy. The word count for answers provided by GPT-4.0 was significantly lower than those produced by GPT-3.5 (160 ± 56 and 206 ± 77 respectively, P < 0.0001); however, incorrect responses were longer (P < 0.02). GPT-4.0 represented a substantial improvement over GPT-3.5, achieving better performance than humans in an AAO BCSC self-assessment test. However, ChatGPT is still limited by inconsistency across different practice areas, especially when it comes to surgery. © 2023, The Author(s).
KW  - Academies and Institutes
KW  - Humans
KW  - Ophthalmology
KW  - Self-Assessment
KW  - article
KW  - ChatGPT
KW  - controlled study
KW  - education
KW  - human
KW  - human experiment
KW  - multiple choice test
KW  - ophthalmology
KW  - self evaluation
KW  - organization
KW  - self evaluation
PB  - Nature Research
SN  - 20452322 (ISSN)
C2  - 37899405
LA  - English
J2  - Sci. Rep.
M3  - Article
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 0; Correspondence Address: G. Giannaccare; Department of Surgical Sciences, Eye Clinic, University of Cagliari, Cagliari, Via Università 40, 09124, Italy; email: giuseppe.giannaccare@gmail.com
ER  -

TY  - JOUR
AU  - Bayne, T.
AU  - Williams, I.
TI  - The Turing test is not a good benchmark for thought in LLMs
PY  - 2023
T2  - Nature Human Behaviour
VL  - 7
IS  - 11
SP  - 1806
EP  - 1807
DO  - 10.1038/s41562-023-01710-w
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85177070851&doi=10.1038%2fs41562-023-01710-w&partnerID=40&md5=1276e63be923679cc6e1700113701227
AD  - Department of Philosophy, School of Philosophical, Historical and International Studies, Monash University, Melbourne, VIC, Australia
AD  - Brain, Mind and Consciousness Program, Canadian Institute for Advanced Research (CIFAR), Toronto, ON, Canada
AD  - Monash Centre for Consciousness & Contemplative Studies (M3CS), Monash University, Melbourne, VIC, Australia
KW  - Benchmarking
KW  - Humans
KW  - Models, Biological
KW  - benchmarking
KW  - biological model
KW  - human
PB  - Nature Research
SN  - 23973374 (ISSN)
C2  - 37985901
LA  - English
J2  - Nat. Hum. Behav.
M3  - Letter
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 0; Correspondence Address: T. Bayne; Department of Philosophy, School of Philosophical, Historical and International Studies, Monash University, Melbourne, Australia; email: timothy.bayne@monash.edu
ER  -

TY  - JOUR
AU  - López-Úbeda, P.
AU  - Martín-Noguerol, T.
AU  - Luna, A.
TI  - Reply to the letter to the editor: “A critical evaluation on the use of large language model for radiology research”
PY  - 2023
T2  - European Radiology
VL  - 33
IS  - 12
SP  - 9464
EP  - 9465
DO  - 10.1007/s00330-023-10333-8
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85174229197&doi=10.1007%2fs00330-023-10333-8&partnerID=40&md5=62ad29154cf57ed7a1dde652c1065c50
AD  - R+D+I Department, HT Medica, Jaén, Spain
AD  - MRI Unit, Radiology Department, HT Medica, Jaén, Spain
KW  - Humans
KW  - Language
KW  - Radiography
KW  - Radiology
KW  - artificial intelligence
KW  - decision support system
KW  - human
KW  - large language model
KW  - Letter
KW  - medical research
KW  - multidisciplinary team
KW  - radiology
KW  - language
KW  - radiography
PB  - Springer Science and Business Media Deutschland GmbH
SN  - 09387994 (ISSN)
C2  - 37845389
LA  - English
J2  - Eur. Radiol.
M3  - Letter
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 0; Correspondence Address: P. López-Úbeda; R+D+I Department, HT Medica, Jaén, Spain; email: p.lopez@htmedica.com; CODEN: EURAE
ER  -

TY  - CONF
AU  - Savelka, J.
TI  - Unlocking Practical Applications in Legal Domain: Evaluation of GPT for Zero-Shot Semantic Annotation of Legal Texts
PY  - 2023
T2  - 19th International Conference on Artificial Intelligence and Law, ICAIL 2023 - Proceedings of the Conference
SP  - 447
EP  - 451
DO  - 10.1145/3594536.3595161
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85177829432&doi=10.1145%2f3594536.3595161&partnerID=40&md5=f79b552235236cc2501f5d4099610665
AD  - Carnegie Mellon University, Pittsburgh, PA, United States
AB  - We evaluated the capability of a state-of-the-art generative pre-trained transformer (GPT) model to perform semantic annotation of short text snippets (one to few sentences) coming from legal documents of various types. Discussions of potential uses (e.g., document drafting, summarization) of this emerging technology in legal domain have intensified, but to date there has not been a rigorous analysis of these large language models’ (LLM) capacity in sentence-level semantic annotation of legal texts in zero-shot learning settings. Yet, this particular type of use could unlock many practical applications (e.g., in contract review) and research opportunities (e.g., in empirical legal studies). We fill the gap with this study. We examined if and how successfully the model can semantically annotate small batches of short text snippets (10–50) based exclusively on concise definitions of the semantic types. We found that the GPT model performs surprisingly well in zero-shot settings on diverse types of documents (F1 = .73 on a task involving court opinions, .86 for contracts, and .54 for statutes and regulations). These findings can be leveraged by legal scholars and practicing lawyers alike to guide their decisions in integrating LLMs in wide range of workflows involving semantic annotation of legal texts. © ICAIL 2023. All rights reserved.
KW  - adjudicatory decisions
KW  - contracts
KW  - generative pre-trained transformers
KW  - GPT
KW  - regulatory provisions
KW  - Semantic legal annotation
KW  - statutory
KW  - transfer learning
KW  - zero-shot
KW  - Laws and legislation
KW  - Learning systems
KW  - Zero-shot learning
KW  - Adjudicatory decision
KW  - Generative pre-trained transformer
KW  - Legal texts
KW  - Regulatory provision
KW  - Semantic annotations
KW  - Semantic legal annotation
KW  - Statutory
KW  - Transfer learning
KW  - Zero-shot
KW  - Semantics
PB  - Association for Computing Machinery, Inc
SN  - 979-840070197-9 (ISBN)
LA  - English
J2  - Int. Conf. Artif. Intel. Law, ICAIL - Proc. Conf.
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 3; Correspondence Address: J. Savelka; Carnegie Mellon University, Pittsburgh, United States; email: jsavelka@cs.cmu.edu; Conference name: 19th International Conference on Artificial Intelligence and Law, ICAIL 2023; Conference date: 19 June 2023 through 23 June 2023; Conference code: 193952
ER  -

TY  - CONF
AU  - Savelka, J.
AU  - Agarwal, A.
AU  - An, M.
AU  - Bogart, C.
AU  - Sakr, M.
TI  - Thrilled by Your Progress! Large Language Models (GPT-4) No Longer Struggle to Pass Assessments in Higher Education Programming Courses
PY  - 2023
T2  - ICER 2023 - Proceedings of the 2023 ACM Conference on International Computing Education Research V.1
SP  - 78
EP  - 92
DO  - 10.1145/3568813.3600142
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85169462375&doi=10.1145%2f3568813.3600142&partnerID=40&md5=a22f2eaaae3e1c62d039bc28390d525a
AD  - Carnegie Mellon University, Pittsburgh, PA, United States
AB  - This paper studies recent developments in large language models' (LLM) abilities to pass assessments in introductory and intermediate Python programming courses at the postsecondary level. The emergence of ChatGPT resulted in heated debates of its potential uses (e.g., exercise generation, code explanation) as well as misuses in programming classes (e.g., cheating). Recent studies show that while the technology performs surprisingly well on diverse sets of assessment instruments employed in typical programming classes the performance is usually not sufficient to pass the courses. The release of GPT-4 largely emphasized notable improvements in the capabilities related to handling assessments originally designed for human test-takers. This study is the necessary analysis in the context of this ongoing transition towards mature generative AI systems. Specifically, we report the performance of GPT-4, comparing it to the previous generations of GPT models, on three Python courses with assessments ranging from simple multiple-choice questions (no code involved) to complex programming projects with code bases distributed into multiple files (599 exercises overall). Additionally, we analyze the assessments that were not handled well by GPT-4 to understand the current limitations of the model, as well as its capabilities to leverage feedback provided by an auto-grader. We found that the GPT models evolved from completely failing the typical programming class' assessments (the original GPT-3) to confidently passing the courses with no human involvement (GPT-4). While we identified certain limitations in GPT-4's handling of MCQs and coding exercises, the rate of improvement across the recent generations of GPT models strongly suggests their potential to handle almost any type of assessment widely used in higher education programming courses. These findings could be leveraged by educators and institutions to adapt the design of programming assessments as well as to fuel the necessary discussions into how programming classes should be updated to reflect the recent technological developments. This study provides evidence that programming instructors need to prepare for a world in which there is an easy-to-use widely accessible technology that can be utilized by learners to collect passing scores, with no effort whatsoever, on what today counts as viable programming knowledge and skills assessments. © 2023 Owner/Author.
KW  - AI code generation
KW  - AlphaCode
KW  - ChatGPT
KW  - Codex
KW  - coding exercises
KW  - generative pre-trained transformers
KW  - GitHub Copilot
KW  - GPT
KW  - introductory and intermediate programming
KW  - MCQ
KW  - Multiple-choice question answering
KW  - programming knowledge assessment
KW  - Python course
KW  - Computational linguistics
KW  - Curricula
KW  - Education computing
KW  - Engineering education
KW  - High level languages
KW  - AI code generation
KW  - Alphacode
KW  - ChatGPT
KW  - Codegeneration
KW  - Codex
KW  - Coding exercise
KW  - Generative pre-trained transformer
KW  - Github copilot
KW  - GPT
KW  - Introductory and intermediate programming
KW  - Knowledge assessment
KW  - MCQ
KW  - Multiple-choice question answering
KW  - Multiple-choice questions
KW  - Programming knowledge
KW  - Programming knowledge assessment
KW  - Python course
KW  - Question Answering
KW  - Python
PB  - Association for Computing Machinery, Inc
SN  - 978-145039976-0 (ISBN)
LA  - English
J2  - ICER - Proc. ACM Conf. Int. Comput. Educ. Res. V.1
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 7; Conference name: 19th Annual ACM International Computing Education Research Conference, ICER 2023; Conference date: 7 August 2023 through 11 August 2023; Conference code: 192875
ER  -

TY  - JOUR
AU  - Shaikh, S.
AU  - Yayilgan, S.Y.
AU  - Klimova, B.
AU  - Pikhart, M.
TI  - Assessing the Usability of ChatGPT for Formal English Language Learning
PY  - 2023
T2  - European Journal of Investigation in Health, Psychology and Education
VL  - 13
IS  - 9
SP  - 1937
EP  - 1960
DO  - 10.3390/ejihpe13090140
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85172134082&doi=10.3390%2fejihpe13090140&partnerID=40&md5=71d588a1904288f63417e07e518f1748
AD  - Department of Information Security and Communication Technology (IIK), Norwegian University of Science and Technology (NTNU), Gjøvik, 2815, Norway
AD  - Department of Applied Linguistics, Faculty of Informatics and Management, University of Hradec Kralove, Rokitanskeho 62, 500 03, Czech Republic
AB  - Recently, the emerging technologies have been constantly shaping the education domain, especially the use of artificial intelligence (AI) for language learning, which has attracted significant attention. Many of the AI tools are being used for learning foreign languages, in both formal and informal ways. There are many studies that have explored the potential of the recent technology “ChatGPT” for education and learning languages, but none of the existing studies have conducted any exploratory study for assessing the usability of ChatGPT. This paper conducts an assessment for usability of ChatGPT for formal English language learning. The study uses a standard questionnaire-based approach to ask participants about their feedback for usefulness and effectiveness of ChatGPT. The participants were asked for their feedback after performing series of tasks related to formal English language learning with ChatGPT. A variety of student participants were selected for this study with diverse English language proficiency levels, education levels, and nationalities. The quantitative analysis of the participant responses shed light on their experience with regards to the usability of ChatGPT for performing different English language learning tasks such as conversation, writing, grammar, and vocabulary. The findings from this study are quite promising and indicate that ChatGPT is an effective tool to be used for formal English language learning. Overall, this study contributes to the fast-growing research domain on using emerging technologies for formal English language learning by conducting in-depth assessment of usability for ChatGPT in formal English language learning. © 2023 by the authors.
KW  - AI
KW  - chatbots
KW  - ChatGPT
KW  - English language
KW  - formal learning
KW  - language learning
KW  - usability testing
PB  - Multidisciplinary Digital Publishing Institute (MDPI)
SN  - 21748144 (ISSN)
LA  - English
J2  - Eur. J. Invest. Health. Psychol. Educ.
M3  - Article
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 4; Correspondence Address: M. Pikhart; Department of Applied Linguistics, Faculty of Informatics and Management, University of Hradec Kralove, Rokitanskeho 62, 500 03, Czech Republic; email: marcel.pikhart@uhk.cz
ER  -

TY  - JOUR
AU  - Wang, L.
AU  - Littler, T.
AU  - Liu, X.
TI  - Hybrid AI model for power transformer assessment using imbalanced DGA datasets
PY  - 2023
T2  - IET Renewable Power Generation
VL  - 17
IS  - 8
SP  - 1912
EP  - 1922
DO  - 10.1049/rpg2.12733
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85152775546&doi=10.1049%2frpg2.12733&partnerID=40&md5=550870997901bd5a85e778c3357fa24a
AD  - School of Electronics, Electrical Engineering and Computer Science, Queen's University Belfast, Belfast, United Kingdom
AB  - Artificial intelligence (AI) methods have been used widely in power transformer fault diagnosis with notable developments in solutions for big data problems. Training data is essential to accurately train AI models. The volume, scope and variety of data samples contribute significantly to the success and reliability of diagnostic outcomes. This paper provides a comprehensive review and comparison of different augmentation methods used to generate reliable data samples for minority and majority classes to balance the diversity and distribution of dissolved gas analysis (DGA) datasets. The augmentation method presented in this paper combines three common AI models—the Support Vector Machine (SVM), Decision Tree, and k-Nearest Neighbour (KNN)—to assess performance for diagnostic fault determination and classification, with comparator assessment using no data augmentation. Comparative analysis of the hybrid models uses evaluation metrics including accuracy, precision, recall, specificity, F-score, G-mean, and the area under receiver operation characteristic (Auc). Experimental results presented in this paper confirm that the data augmentation applied to AI models can resolve difficulties in imbalanced data distribution and provide significant improvements for fault diagnosis, particularly for minority classes. © 2023 The Authors. IET Renewable Power Generation published by John Wiley & Sons Ltd on behalf of The Institution of Engineering and Technology.
KW  - artificial intelligence
KW  - fault diagnosis
KW  - power transformers
KW  - Decision trees
KW  - Electric power distribution
KW  - Fault detection
KW  - Nearest neighbor search
KW  - Power transformers
KW  - Support vector machines
KW  - Artificial intelligence methods
KW  - Augmentation methods
KW  - Data augmentation
KW  - Data problems
KW  - Data sample
KW  - Dissolved gases analysis
KW  - Faults diagnosis
KW  - Hybrid artificial intelligences
KW  - Intelligence models
KW  - Power transformer fault diagnosis
KW  - Failure analysis
PB  - John Wiley and Sons Inc
SN  - 17521416 (ISSN)
LA  - English
J2  - IET. Renew. Power Gener.
M3  - Article
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 2; Correspondence Address: L. Wang; School of Electronics, Electrical Engineering and Computer Science, Queen's University Belfast, Belfast, United Kingdom; email: lwang15@qub.ac.uk
ER  -

TY  - JOUR
AU  - Ali, H.
TI  - Letter 1 regarding “Assessing the performance of ChatGPT in answering questions regarding cirrhosis and hepatocellular carcinoma”
PY  - 2023
T2  - Clinical and Molecular Hepatology
VL  - 29
IS  - 3
SP  - 813
EP  - 814
DO  - 10.3350/cmh.2023.0120
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85167848593&doi=10.3350%2fcmh.2023.0120&partnerID=40&md5=8b5acd579839b02bd431303775833d40
AD  - Department of Internal Medicine, ECU Health Medical Center, Greenville, 27834, NC, United States
KW  - Artificial intelligence
KW  - Cirrhosis
KW  - Decision making
KW  - Emotional support
KW  - Hepatocellular carcinoma
KW  - Medical informatics
KW  - artificial intelligence
KW  - caregiver
KW  - ChatGPT
KW  - clinical decision support system
KW  - cognition
KW  - decision making
KW  - emotional support
KW  - human
KW  - information
KW  - knowledge
KW  - Letter
KW  - liver cell carcinoma
KW  - liver cirrhosis
KW  - medical informatics
KW  - physician
PB  - Korean Association for the Study of the Liver
SN  - 22872728 (ISSN)
C2  - 37211355
LA  - English
J2  - Clin. Mol. Hepatol.
M3  - Letter
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 1; Correspondence Address: H. Ali; Department of Internal Medicine, ECU Health Medical Center, Greenville, 27834, United States; email: AliH20@ECU.EDU
ER  -

TY  - JOUR
AU  - Benuyenah, V.
TI  - Commentary: ChatGPT use in higher education assessment: Prospects and epistemic threats
PY  - 2023
T2  - Journal of Research in Innovative Teaching and Learning
VL  - 16
IS  - 1
SP  - 134
EP  - 135
DO  - 10.1108/JRIT-03-2023-097
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85152585454&doi=10.1108%2fJRIT-03-2023-097&partnerID=40&md5=8ef89224ce9f5a45fa4e6485cd415a56
AD  - Birmingham Business School, University of Birmingham, Birmingham, United Kingdom
PB  - Emerald Publishing
SN  - 23977604 (ISSN)
LA  - English
J2  - J. Res. Innov. Teach. Learn.
M3  - Note
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 15
ER  -

TY  - CONF
AU  - Balse, R.
AU  - Valaboju, B.
AU  - Singhal, S.
AU  - Warriem, J.M.
AU  - Prasad, P.
TI  - Investigating the Potential of GPT-3 in Providing Feedback for Programming Assessments
PY  - 2023
T2  - Annual Conference on Innovation and Technology in Computer Science Education, ITiCSE
VL  - 1
SP  - 292
EP  - 298
DO  - 10.1145/3587102.3588852
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85166190545&doi=10.1145%2f3587102.3588852&partnerID=40&md5=1aa1dbd22b8f1c61775ff3a307b2091d
AD  - BS Programme in Data Science and Applications, Indian Institute of Technology Madras, Tamil Nadu, Chennai, India
AD  - National Programme on Technology Enhanced Learning (NPTEL), BS Programme in Data Science and Applications, Indian Institute of Technology Madras, Tamil Nadu, Chennai, India
AD  - School of Computing and Data Sciences, FLAME University, Maharashtra, Pune, India
AB  - Recent advances in artificial intelligence have led to the development of large language models (LLMs), which are able to generate text, images, and source code based on prompts provided by humans. In this paper, we explore the capabilities of an LLM - OpenAI's GPT-3 model to provide feedback for student written code. Specifically, we examine the feasibility of GPT-3 to check, critique and suggest changes to code written by learners in an online programming exam of an undergraduate Python programming course. We collected 1211 student code submissions from 7 questions asked in a programming exam, and provided the GPT-3 model with separate prompts to check, critique and provide suggestions on these submissions. We found that there was a high variability in the accuracy of the model's feedback for student submissions. Across questions, the range for accurately checking the correctness of the code was between 57% to 79%, between 41% to 77% for accurately critiquing code, and between 32% and 93% for suggesting appropriate changes to the code. We also found instances where the model generated incorrect and inconsistent feedback. These findings suggest that models like GPT-3 currently cannot be 'directly' used to provide feedback to students for programming assessments.  © 2023 ACM.
KW  - evaluation
KW  - feedback
KW  - GPT-3
KW  - large language models (LLM)
KW  - python programming
KW  - Computational linguistics
KW  - Education computing
KW  - High level languages
KW  - Evaluation
KW  - GPT-3
KW  - Language model
KW  - Large language model
KW  - On-line programming
KW  - Programming course
KW  - Python programming
KW  - Source codes
KW  - Text images
KW  - Text sources
KW  - Students
PB  - Association for Computing Machinery
SN  - 1942647X (ISSN); 979-840070138-2 (ISBN)
LA  - English
J2  - Annu. Conf. Innov. Technol. Comput. Sci. Educ. ITiCSE
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 7; Correspondence Address: B. Valaboju; BS Programme in Data Science and Applications, Indian Institute of Technology Madras, Chennai, Tamil Nadu, India; email: valabojubharath@yahoo.com; S. Singhal; BS Programme in Data Science and Applications, Indian Institute of Technology Madras, Chennai, Tamil Nadu, India; email: singhalshreya201@gmail.com; Conference name: 28th Annual Conference on Innovation and Technology in Computer Science Education, ITiCSE 2023; Conference date: 8 July 2023 through 12 July 2023; Conference code: 190016
ER  -

TY  - JOUR
AU  - Zhang, H.
AU  - Li, L.
AU  - Li, C.
TI  - ChatGPT Performance Evaluation on Chinese Language and Risk Measures
ST  - ChatGPT 中文性能测评与风险应对
PY  - 2023
T2  - Data Analysis and Knowledge Discovery
VL  - 7
IS  - 3
SP  - 16
EP  - 25
DO  - 10.11925/infotech.2096-3467.2023.0214
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85167825076&doi=10.11925%2finfotech.2096-3467.2023.0214&partnerID=40&md5=137b1fe6fb840a86fdc0e2ae47ec64c1
AD  - School of Computer Science, Beijing Institute of Technology, Beijing, 100081, China
AB  - [Objective] This paper briefly introduces the main technical innovations of ChatGPT, and evaluates the performance of ChatGPT in Chinese on four tasks using nine datasets, analyzes the risk with ChatGPT and proposes our solutions. [Methods] ChatGPT and WeLM models were tested using the ChnSentiCorp dataset, and ChatGPT and ERNIE 3.0 Titan were tested using the EPRSTMT dataset, and it was found that ChatGPT did not differ much from the large domestic models in sentiment analysis tasks. The LCSTS and TTNews datasets were used to test the ChatGPT and WeLM models, and both ChatGPT outperformed the WeLM model; CMRC2018 and DRCD were used for extractive machine reading comprehension(MRC), and the C3 dataset was used for common sense MRC, and it was found that ERNIE 3.0 Titan outperformed ChatGPT in this task. WebQA and CKBQA were used to do Chinese closed-book quiz testing, and it was found that ChatGPT was prone to make factual errors in this task, and the domestic model outperformed ChatGPT. [Results] ChatGPT performed well on classic tasks of natural language processing, such as sentiment analysis with an accuracy rate of more than 85% and a higher probability of factual errors on closed-book questions. [Limitations] The error of evaluation score may be introduced in the process of converting discriminative tasks into generative ones. This paper only evaluated ChatGPT in zero-shot case, so it is not clear how it performs in other cases. ChatGPT may be updated iteratively in subsequent releases, and the profiling results may be time-sensitive. [Conclusions] ChatGPT is powerful but still has some drawbacks, for the large model of Chinese need to be national strategy oriented and pay attention to the limitations of the language model. © 2022 Food and Fermentation Industries. All rights reserved.
KW  - Artificial Intelligence
KW  - ChatGPT
KW  - Language Model
PB  - Chinese Academy of Sciences
SN  - 20963467 (ISSN)
LA  - Chinese
J2  - Data. Anal. Knowl. Discov.
M3  - Article
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 3; Correspondence Address: H. Zhang; School of Computer Science, Beijing Institute of Technology, Beijing, 100081, China; email: kevinzhang@bit.edu.cn
ER  -

TY  - JOUR
AU  - Kleebayoon, A.
AU  - Wiwanitkit, V.
TI  - Letter 2 regarding “Assessing the performance of ChatGPT in answering questions regarding cirrhosis and hepatocellular carcinoma”
PY  - 2023
T2  - Clinical and Molecular Hepatology
VL  - 29
IS  - 3
SP  - 815
EP  - 816
DO  - 10.3350/cmh.2023.0170
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85166010740&doi=10.3350%2fcmh.2023.0170&partnerID=40&md5=6131c4c2b6c0cb52ed823da37fb5b43a
AD  - Cambodia Samraong, Private Academic Consultant 222 Main Road, Samraong Commune, Samraong, 210308, Cambodia
AD  - Chandigarh University, Punjab, India
AD  - Joesph Ayobabalola University, Ikeji-Arakeji, Nigeria
KW  - Carcinoma
KW  - ChatGPT
KW  - Performance
KW  - Letter
KW  - liver cell carcinoma
KW  - liver cirrhosis
PB  - Korean Association for the Study of the Liver
SN  - 22872728 (ISSN)
C2  - 37221834
LA  - English
J2  - Clin. Mol. Hepatol.
M3  - Letter
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 2; Correspondence Address: A. Kleebayoon; Samraong, Cambodia Samraong, Private Academic Consultant 222 Main Road, Samraong Commune, 210308, Cambodia; email: amnuaykleebai@gmail.com
ER  -

TY  - JOUR
AU  - Rajput, S.K.
AU  - Dheer, D.K.
TI  - Impact of Solar Intensity on Photovoltaic-Generated Current Harmonics and Transformer Life: A Mathematical Model With Experimental Validation
PY  - 2023
T2  - Journal of Solar Energy Engineering, Transactions of the ASME
VL  - 145
IS  - 2
C7  - 021006
DO  - 10.1115/1.4055101
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85144375815&doi=10.1115%2f1.4055101&partnerID=40&md5=1bd459219cf2a2d74510c5a61355b0c8
AD  - Department of Electrical Engineering, National Institute of Technology Patna, Bihar, Patna, 800005, India
AD  - Department of Electrical Engineering, Madhav Institute of Technology and Science, MP, Gwalior, 474005, India
AB  - With the rising penetration of photovoltaic (PV) plants on low voltage distribution systems, the generation of current harmonics as well as its impact on transformer operation is a current concern. The present research work develops a mathematical relationship of solar intensity (I(t)) with PV-inverter-generated total harmonic distortion of current (THDi,inv.), and then uses IEEE recommendations to present the impact of THDi,inv. on the life of a three-phase distribution transformer (TPDT). The validation of the presented model is done by real-time data monitoring from a 100-kWp solar roof-top photovoltaic (SRTPV) system, integrated with an 11-kV grid supply through a 63-kVA TPDT in the composite environment of north India. According to the results, decreasing I(t) values from 857 W/m2 to 35 W/m2 raise THDi,inv. from 3.57% to 63.43%. It is also observed that the production of poor THDi,inv. is high in the winter season (daily average = 27.44%) in comparison to their values in the summer season (daily average = 15.21%). For I(t) values less than 315 W/m2, the generation of large THDi,inv. (above 15%) takes place and it increases the loss of life of TPDT by a factor of 6.0. Copyright © 2022 by ASME.
KW  - grid-connected solar rooftop PV system
KW  - hot spot temperature
KW  - solar intensity
KW  - three-phase distribution transformer life
KW  - total harmonic distortion of inverter produced current
KW  - Electric power distribution
KW  - Electric transformers
KW  - Harmonic analysis
KW  - Harmonic distortion
KW  - Solar power generation
KW  - Voltage distribution measurement
KW  - Wave filters
KW  - 'current
KW  - Distribution transformer
KW  - Grid-connected
KW  - Grid-connected solar rooftop photovoltaic system
KW  - Hotspot temperature
KW  - Hottest-spot temperatures
KW  - Phase distribution
KW  - Rooftop photovoltaic systems
KW  - Solar intensities
KW  - Three phase
KW  - Three phasis
KW  - Three-phase distribution transformer life
KW  - Total harmonic distortion of inverte produced current
KW  - Total harmonic distortions
KW  - Transformer life
KW  - Electric inverters
PB  - American Society of Mechanical Engineers (ASME)
SN  - 01996231 (ISSN)
LA  - English
J2  - J Sol Energy Eng Trans ASME
M3  - Article
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 2; Correspondence Address: D.K. Dheer; Department of Electrical Engineering, National Institute of Technology Patna, Patna, Bihar, 800005, India; email: dkdheer@nitp.ac.in; CODEN: JSEED
ER  -

TY  - JOUR
AU  - Wei, Q.
AU  - Cui, Y.
AU  - Wei, B.
AU  - Cheng, Q.
AU  - Xu, X.
TI  - Evaluating the performance of ChatGPT in differential diagnosis of neurodevelopmental disorders: A pediatricians-machine comparison
PY  - 2023
T2  - Psychiatry Research
VL  - 327
C7  - 115351
DO  - 10.1016/j.psychres.2023.115351
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85166012922&doi=10.1016%2fj.psychres.2023.115351&partnerID=40&md5=e7f09756e9fe288ecb4356cb417cb3a6
AD  - Department of Children's Healthcare, Children's Hospital of Chongqing Medical University, National Clinical Research Center for Child Health and Disorders, Ministry of Education Key Laboratory of Child Development and Disorders, China International Science and Technology Cooperation Base of Child Development and Critical Disorders, Chongqing Key Laboratory of Childhood Nutrition and Health, Chongqing, China
AD  - Department of Biostatistics and Bioinformatics, Emory University, Atlanta, GA, United States
AD  - Department of Global Statistics and Data Science, BeiGene USA Inc., San Mateo, CA, United States
AD  - Big Data Center for Children's Medical Care, Children's Hospital of Chongqing Medical University, Chongqing, China
KW  - Diagnosis, Differential
KW  - Humans
KW  - Neurodevelopmental Disorders
KW  - age
KW  - artificial intelligence
KW  - autism
KW  - Autism Behavior Checklist
KW  - ChatGPT software
KW  - clinical practice
KW  - decision making
KW  - developmental delay
KW  - developmental language disorder
KW  - diagnostic accuracy
KW  - diagnostic error
KW  - diagnostic imaging
KW  - differential diagnosis
KW  - Early Language Milestone Scale
KW  - family history
KW  - gender
KW  - Gesell Developmental Scale
KW  - growth
KW  - health care planning
KW  - human
KW  - language
KW  - Letter
KW  - machine
KW  - medical history
KW  - medical record
KW  - mental disease
KW  - mental health
KW  - Modified Checklist for Autism in Toddlers
KW  - overdiagnosis
KW  - pediatrician
KW  - scoring system
KW  - software
KW  - vignette
KW  - work experience
KW  - differential diagnosis
PB  - Elsevier Ireland Ltd
SN  - 01651781 (ISSN)
C2  - 37506587
LA  - English
J2  - Psychiatry Res.
M3  - Letter
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 2; Correspondence Address: Q. Cheng; Department of Children's Healthcare, Children's Hospital of Chongqing Medical University, No 136. Zhongshan 2nd Rd, Yuzhong District, Chongqing, 400014, China; email: chengqq@cqmu.edu.cn; X. Xu; Big Data Center for Children's Medical Care, Children's Hospital of Chongqing Medical University, No 136. Zhongshan 2nd Rd, Yuzhong District, Chongqing, 400014, China; email: ximing@hospital.cqmu.edu.cn; CODEN: PSRSD
ER  -

TY  - JOUR
AU  - Gao, F.
AU  - Wang, H.
AU  - Dang, R.
TI  - Interpretability analysis and model update research of a transient stability assessment model based on Transformer
ST  - 基于 Transformer 的暂态稳定评估模型的可解释性分析与模型更新研究
PY  - 2023
T2  - Dianli Xitong Baohu yu Kongzhi/Power System Protection and Control
VL  - 51
IS  - 17
SP  - 15
EP  - 25
DO  - 10.19783/j.cnki.pspc.230160
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85171891703&doi=10.19783%2fj.cnki.pspc.230160&partnerID=40&md5=e9a97471dbed4bbc340dbad1ed35de45
AD  - Key Laboratory of New Energy Generation and Power Conversion (Fuzhou University), Fuzhou, 350108, China
AD  - Shaanxi Aircraft Industry Limited Liability Company, Hanzhong, 723000, China
AB  - Deep learning algorithms have excellent performance in power system transient stability assessment, but the incomprehensibility of the assessment results and the uncontrollability of the decision-making process hinder their practical adoption by industry. A transient stability assessment model based on the Transformer encoder is proposed. The rules that the model focuses on and learns can be interpreted and analyzed by the attention weights of the features. Thus a model updating method is proposed which employs physical information in combination with interpretable results to guide model optimization. From the perspective of the loss function, the attention weight distribution of the model to the features is adjusted in a fine-tuned way to enhance the mining for the instability patterns. In the process of fine-tuning, an attention-guiding function is introduced to increase the attention weights to the key generators of specific instability patterns, so as to reduce the misclassification of specific instability patterns. In this way the overall prediction accuracy can be improved. The performance of the proposed method is verified on the IEEE39-bus system and the East China power grid system. © 2023 Power System Protection and Control Press. All rights reserved.
KW  - attention mechanism
KW  - interpretability
KW  - loss function
KW  - Transformer
KW  - transient stability assessment
KW  - Decision making
KW  - Electric power distribution
KW  - Electric power system protection
KW  - Learning algorithms
KW  - System stability
KW  - Transformer protection
KW  - Transients
KW  - Analysis and models
KW  - Assessment models
KW  - Attention mechanisms
KW  - Interpretability
KW  - Loss functions
KW  - Model updates
KW  - Model-based OPC
KW  - Performance
KW  - Transformer
KW  - Transient stability assessment
KW  - Deep learning
PB  - Power System Protection and Control Press
SN  - 16743415 (ISSN)
LA  - Chinese
J2  - Dianli Xitong Baohu yu Kongzhi
M3  - Article
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 1; Correspondence Address: H. Wang; Key Laboratory of New Energy Generation and Power Conversion (Fuzhou University), Fuzhou, 350108, China; email: 79749544@qq.com
ER  -

TY  - JOUR
AU  - Shay, D.
AU  - Kumar, B.
AU  - Bellamy, D.
AU  - Palepu, A.
AU  - Dershwitz, M.
AU  - Walz, J.M.
AU  - Schaefer, M.S.
AU  - Beam, A.
TI  - Assessment of ChatGPT success with specialty medical knowledge using anaesthesiology board examination practice questions
PY  - 2023
T2  - British Journal of Anaesthesia
VL  - 131
IS  - 2
SP  - e31
EP  - e34
DO  - 10.1016/j.bja.2023.04.017
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85164587256&doi=10.1016%2fj.bja.2023.04.017&partnerID=40&md5=473300d99a9aac588190d8844dfc279d
AD  - Department of Epidemiology, Harvard T.H. Chan School of Public Health, Boston, MA, United States
AD  - Department of Anesthesia, Critical Care and Pain Medicine, Beth Israel Deaconess Medical Center, Harvard Medical School, Boston, MA, United States
AD  - Center for Anesthesia Research Excellence, Beth Israel Deaconess Medical Center, Harvard Medical School, Boston, MA, United States
AD  - Department of Biostatistics, Harvard T.H. Chan School of Public Health, Boston, MA, United States
AD  - Harvard–MIT Health Sciences and Technology, Massachusetts Institute of Technology, Cambridge, MA, United States
AD  - Department of Anesthesiology & Perioperative Medicine, University of Massachusetts Chan Medical School, Worcester, MA, United States
AD  - Department of Anesthesiology, Dusseldorf University Hospital, Dusseldorf, Germany
KW  - artificial intelligence
KW  - board examination
KW  - ChatGPT
KW  - large language models
KW  - medical knowledge
KW  - multiple choice questions
KW  - specialty qualifications
KW  - Anesthesiology
KW  - Humans
KW  - accuracy
KW  - anesthesiology
KW  - clinical reasoning
KW  - comprehension
KW  - human
KW  - knowledge
KW  - Letter
KW  - multiple choice test
KW  - patient care
KW  - reasoning
PB  - Elsevier Ltd
SN  - 00070912 (ISSN)
C2  - 37210278
LA  - English
J2  - Br. J. Anaesth.
M3  - Letter
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 6; Correspondence Address: A. Beam; Department of Epidemiology, Harvard T.H. Chan School of Public Health, Boston, United States; email: andrew_beam@hms.harvard.edu; CODEN: BJANA
ER  -

TY  - JOUR
AU  - Berland, L.L.
AU  - Hardy, S.M.
TI  - Fighting Obsolescence: Professional Assessment in the Era of ChatGPT
PY  - 2023
T2  - Applied Radiology
VL  - 52
IS  - 3
SP  - 20
EP  - 23
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85160276817&partnerID=40&md5=93cbd6a4cfce6d31a2827148fa50a6ec
AD  - Department of Radiology, University of Alabama at Birmingham, Birmingham, AL, United States
AD  - Department of Radiology, Penn State Health Milton S. Hershey Medical Center, Hershey, PA, United States
KW  - clinical practice
KW  - deep learning
KW  - diagnostic radiologist
KW  - human
KW  - human characteristic
KW  - natural language processing
KW  - professional knowledge
KW  - radiology
KW  - Review
KW  - software
PB  - Anderson Publishing Ltd
SN  - 01609963 (ISSN)
LA  - English
J2  - Appl. Radiol.
M3  - Review
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 0; CODEN: ARDYA
ER  -

TY  - JOUR
AU  - Lee, J.-S.
TI  - Evaluating generative patent language models
PY  - 2023
T2  - World Patent Information
VL  - 72
C7  - 102173
DO  - 10.1016/j.wpi.2023.102173
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85147220778&doi=10.1016%2fj.wpi.2023.102173&partnerID=40&md5=a887c2e8c67885d7f741ffd71545c184
AD  - National Yang Ming Chiao Tung University (NYCU) School of Law, No. 1001, Daxue Rd., Hsinchu, 300093, Taiwan
AB  - Generative language models are promising for assisting human writing in various domains. This manuscript aims to build generative language models in the patent domain and evaluate model performance from a human-centric perspective. The perspective is to measure the ratio of keystrokes that can be saved by autocompletion based on generative patent language models. A higher ratio means a more effective model which can save more keystrokes. This metric can be used to benchmark model performance. The metric is keystroke-based and different from conventional machine-centric metrics that are token-based. In terms of model size, the largest model built in this manuscript is PatentGPT-J-6B, which is state-of-the-art in the patent domain. Based on the metric, it is found that the largest model is not necessarily the best for the human-centric metric. The finding means that keeping increasing model sizes in the patent domain might be unnecessary if the purpose is to assist human writing with autocompletion. Several patent language models are pre-trained from scratch in this research. The pre-trained models are released for future researchers. Several visualization tools are also provided. The importance of building a generative language model in the patent domain is its potential to facilitate creativity and innovations in the future. © 2023 The Author(s)
KW  - Deep learning
KW  - Natural language generation
KW  - Natural language processing
KW  - Patent text generation
PB  - Elsevier Ltd
SN  - 01722190 (ISSN)
LA  - English
J2  - World Pat. Inf.
M3  - Article
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 1; CODEN: WPAID
ER  -

TY  - JOUR
AU  - Agerri, R.
AU  - Agirre, E.
TI  - Lessons learned from the evaluation of Spanish Language Models
ST  - Conclusiones de la evaluación de Modelos del Lenguaje en Español
PY  - 2023
T2  - Procesamiento del Lenguaje Natural
IS  - 70
SP  - 157
EP  - 170
DO  - 10.26342/2023-70-13
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85153175827&doi=10.26342%2f2023-70-13&partnerID=40&md5=9e86e6ff923537c6c6e47b133aa3d175
AD  - HiTZ Center - Ixa, University of the Basque Country UPV/EHU, Spain
AB  - Given the impact of language models on the field of Natural Language Processing, a number of Spanish encoder-only masked language models (aka BERTs) have been trained and released. These models were developed either within large projects using very large private corpora or by means of smaller scale academic efforts leveraging freely available data. In this paper we present a comprehensive head-to-head comparison of language models for Spanish with the following results: (i) Previously ignored multilingual models from large companies fare better than monolingual models, substantially changing the evaluation landscape of language models in Spanish; (ii) Results across the monolingual models are not conclusive, with supposedly smaller and inferior models performing competitively. Based on these empirical results, we argue for the need of more research to understand the factors underlying them. In this sense, the effect of corpus size, quality and pre-training techniques need to be further investigated to be able to obtain Spanish monolingual models significantly better than the multilingual ones released by large private companies, specially in the face of rapid ongoing progress in the field. The recent activity in the development of language technology for Spanish is to be welcomed, but our results show that building language models remains an open, resource-heavy problem which requires to marry resources (monetary and/or computational) with the best research expertise and practice. ©2023 Sociedad Española para el Procesamiento del Lenguaje Natural.
KW  - Masked Language Models
KW  - Natural Language Processing
KW  - Sequence Labelling
KW  - Text Classification
PB  - Sociedad Espanola para el Procesamiento del Lenguaje Natural
SN  - 11355948 (ISSN)
LA  - English
J2  - Proces. Lenguaje Nat.
M3  - Article
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 1
ER  -

TY  - JOUR
AU  - Ferretti, S.
TI  - Hacking by the prompt: Innovative ways to utilize ChatGPT for evaluators
PY  - 2023
T2  - New Directions for Evaluation
VL  - 2023
IS  - 178-179
SP  - 73
EP  - 84
DO  - 10.1002/ev.20557
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85175990380&doi=10.1002%2fev.20557&partnerID=40&md5=6ae66334583007a405fafebace019cd8
AD  - Independent Evaluation Consultant, Rome, Italy
AB  - “Hacking by the prompt”—writing simple yet creative conversational instructions in ChatGPT's message window—revealed many valuable additions to the evaluator's toolbox for all stages of the evaluation process. This includes the production of terms of reference and proposals for the dissemination of final reports. ChatGPT does not come with an instruction book, so evaluators must experiment creatively to understand its potential. The surprising performance of ChatGPT leads to the question: will it eventually substitute for evaluators? By describing ChatGPT through four personality characteristics (pedantic, “I know it all,” meek, and “speech virtuoso”), this article provides case examples of the potential and pitfall of ChatGPT in transforming evaluation practice. Anthropomorphizing ChatGPT is debatable, but the result is clear: tongue-in-cheek personality characteristics helped hack ChatGPT more creatively while remaining aware of its challenges. This article combines practical ideas with deeper reflection on evaluation. It concludes that ChatGPT can substitute for evaluators when evaluations mostly focus on paperwork and conventional approaches “by the book” (an unfortunate trend in the sector). ChatGPT cannot substitute engagement with reality and critical thinking. Will ChatGPT then be a stimulus to rediscover the humanity and the reality we lost in processes?. © 2023 American Evaluation Association and Wiley Periodicals LLC.
PB  - John Wiley and Sons Inc
SN  - 10976736 (ISSN)
LA  - English
J2  - New Dir. Eval.
M3  - Article
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 3; Correspondence Address: S. Ferretti; Rome, Italy; email: silva.ferretti@gmail.com
ER  -

TY  - JOUR
AU  - McCoy, R.T.
AU  - Smolensky, P.
AU  - Linzen, T.
AU  - Gao, J.
AU  - Celikyilmaz, A.
TI  - How Much Do Language Models Copy From Their Training Data? Evaluating Linguistic Novelty in Text Generation Using RAVEN
PY  - 2023
T2  - Transactions of the Association for Computational Linguistics
VL  - 11
SP  - 652
EP  - 670
DO  - 10.1162/tacl_a_00567
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85168641105&doi=10.1162%2ftacl_a_00567&partnerID=40&md5=71b6c508652101203065782a4d7f970c
AD  - Princeton University, United States
AD  - Microsoft Research, United States
AD  - Johns Hopkins University, United States
AD  - New York University, United States
AD  - Meta AI, United States
AB  - Current language models can generate highquality text. Are they simply copying text they have seen before, or have they learned generalizable linguistic abstractions? To tease apart these possibilities, we introduce RAVEN, a suite of analyses for assessing the novelty of generated text, focusing on sequential structure (n-grams) and syntactic structure. We apply these analyses to four neural language models trained on English (an LSTM, a Transformer, Transformer-XL, and GPT-2). For local structure—e.g., individual dependencies— text generated with a standard sampling scheme is substantially less novel than our baseline of human-generated text from each model’s test set. For larger-scale structure— e.g., overall sentence structure—modelgenerated text is as novel or even more novel than the human-generated baseline, but models still sometimes copy substantially, in some cases duplicating passages over 1,000 words long from the training set. We also perform extensive manual analysis, finding evidence that GPT-2 uses both compositional and analogical generalization mechanisms and showing that GPT-2’s novel text is usuallywell-formed morphologically and syntactically but has reasonably frequent semantic issues (e.g., being self-contradictory). © 2023, MIT Press Journals. All rights reserved.
PB  - MIT Press Journals
SN  - 2307387X (ISSN)
LA  - English
J2  - Trans. Assoc. Comput. Linguist.
M3  - Article
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 4; Correspondence Address: R.T. McCoy; Princeton University, United States; email: tom.mccoy@princeton.edu
ER  -

TY  - JOUR
AU  - Amin, M.M.
AU  - Cambria, E.
AU  - Schuller, B.W.
TI  - Will Affective Computing Emerge From Foundation Models and General Artificial Intelligence? A First Evaluation of ChatGPT
PY  - 2023
T2  - IEEE Intelligent Systems
VL  - 38
IS  - 2
SP  - 15
EP  - 23
DO  - 10.1109/MIS.2023.3254179
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85157967700&doi=10.1109%2fMIS.2023.3254179&partnerID=40&md5=613f9411ed9caaea6652cabe1dcafc26
AD  - University of Augsburg, Augsburg, 86159, Germany
AD  - SyncPilot GmbH, Augsburg, 86156, Germany
AD  - Nanyang Technological University, 639798, Singapore
AD  - Imperial College London, London, SW7 2AZ, United Kingdom
AB  - ChatGPT has shown the potential of emerging general artificial intelligence capabilities, as it has demonstrated competent performance across many natural language processing tasks. In this work, we evaluate the capabilities of ChatGPT to perform text classification on three affective computing problems, namely, big-five personality prediction, sentiment analysis, and suicide tendency detection. We utilize three baselines, a robust language model (RoBERTa-base), a legacy word model with pretrained embeddings (Word2Vec), and a simple bag-of-words (BoW) baseline. Results show that the RoBERTa model trained for a specific downstream task generally has a superior performance. On the other hand, ChatGPT provides decent results and is relatively comparable to the Word2Vec and BoW baselines. ChatGPT further shows robustness against noisy data, where the Word2Vec model achieves worse results due to noise. Results indicate that ChatGPT is a good generalist model that is capable of achieving good results across various problems without any specialized training; however, it is not as good as a specialized model for a downstream task. © 2001-2011 IEEE.
KW  - Artificial intelligence
KW  - Classification (of information)
KW  - Information retrieval
KW  - Affective Computing
KW  - Bag of words
KW  - Big five
KW  - Down-stream
KW  - Foundation models
KW  - Language processing
KW  - Natural languages
KW  - Performance
KW  - Personality predictions
KW  - Text classification
KW  - Sentiment analysis
PB  - Institute of Electrical and Electronics Engineers Inc.
SN  - 15411672 (ISSN)
LA  - English
J2  - IEEE Intell. Syst.
M3  - Article
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 9; Correspondence Address: M.M. Amin; University of Augsburg, Augsburg, 86159, Germany; email: mostafa.mohamed@unia.de
ER  -

TY  - CONF
AU  - Ji, Y.
AU  - Gao, S.
TI  - Evaluating the Effectiveness of Large Language Models in Representing Textual Descriptions of Geometry and Spatial Relations
PY  - 2023
T2  - Leibniz International Proceedings in Informatics, LIPIcs
VL  - 277
C7  - 43
DO  - 10.4230/LIPIcs.GIScience.2023.43
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85172392306&doi=10.4230%2fLIPIcs.GIScience.2023.43&partnerID=40&md5=7a6500e31c27fcf710219830f271373b
AD  - GeoDS Lab, Department of Geography, University of Wisconsin-Madison, WI, United States
AB  - This research focuses on assessing the ability of large language models (LLMs) in representing geometries and their spatial relations. We utilize LLMs including GPT-2 and BERT to encode the well-known text (WKT) format of geometries and then feed their embeddings into classifiers and regressors to evaluate the effectiveness of the LLMs-generated embeddings for geometric attributes. The experiments demonstrate that while the LLMs-generated embeddings can preserve geometry types and capture some spatial relations (up to 73% accuracy), challenges remain in estimating numeric values and retrieving spatially related objects. This research highlights the need for improvement in terms of capturing the nuances and complexities of the underlying geospatial data and integrating domain knowledge to support various GeoAI applications using foundation models. © Yuhan Ji and Song Gao.
KW  - foundation models
KW  - GeoAI
KW  - LLMs
KW  - Computational linguistics
KW  - Domain Knowledge
KW  - Embeddings
KW  - Embeddings
KW  - Foundation models
KW  - GeoAI
KW  - Geometric attributes
KW  - Language model
KW  - Large language model
KW  - Research focus
KW  - Spatial relations
KW  - Text format
KW  - Textual description
KW  - Geometry
A2  - Beecham R.
A2  - Long J.A.
A2  - Smith D.
A2  - Zhao Q.
A2  - Wise S.
PB  - Schloss Dagstuhl- Leibniz-Zentrum fur Informatik GmbH, Dagstuhl Publishing
SN  - 18688969 (ISSN); 978-395977288-4 (ISBN)
LA  - English
J2  - Leibniz Int. Proc. Informatics, LIPIcs
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 0; Correspondence Address: ; ; Conference name: 12th International Conference on Geographic Information Science, GIScience 2023; Conference date: 12 September 2023 through 15 September 2023; Conference code: 192257
ER  -

TY  - JOUR
AU  - Fergus, S.
AU  - Botha, M.
AU  - Ostovar, M.
TI  - Evaluating Academic Answers Generated Using ChatGPT
PY  - 2023
T2  - Journal of Chemical Education
VL  - 100
IS  - 4
SP  - 1672
EP  - 1675
DO  - 10.1021/acs.jchemed.3c00087
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85151320966&doi=10.1021%2facs.jchemed.3c00087&partnerID=40&md5=cebcf1856a0c09ac3eff777a724aac48
AD  - School of Life and Medical Sciences, University of Hertfordshire, College Lane, Hatfield, AL10 9AB, United Kingdom
AB  - The integration of technology in education has become ever more prioritized since the COVID-19 pandemic. Chat Generative Pre-Trained Transformer (ChatGPT) is an artificial intelligence technology that generates conversational interactions to user prompts. The trained model can answer follow-up questions, admit its mistakes, challenge incorrect premises, and reject inappropriate requests. The functionality of ChatGPT in answering chemistry assessment questions requires investigation to ascertain its potential impact on learning and assessment. Two chemistry-focused modules in year 1 and year 2 of a pharmaceutical science program are used to study and evaluate ChatGPT-generated responses in relation to the end-of-year exam assessments. For questions that focused on knowledge and understanding with “describe” and “discuss” verbs, the ChatGPT generated responses. For questions that focused on application of knowledge and interpretation with nontext information, the ChatGPT technology reached a limitation. A further analysis of the quality of responses is reported in this study. ChatGPT is not considered a high-risk technology tool in relation to cheating. Similar to the COVID-19 disruption, ChatGPT is expected to provide a catalyst for educational discussions on academic integrity and assessment design. © 2023 The Authors. Published by American Chemical Society and Division of Chemical Education, Inc.
KW  - Applications of Chemistry
KW  - First-Year Undergraduate
KW  - General
KW  - Internet
KW  - Outreach
KW  - Public Understanding
KW  - Web-Based Learning
PB  - American Chemical Society
SN  - 00219584 (ISSN)
LA  - English
J2  - J Chem Educ
M3  - Article
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 40; Correspondence Address: S. Fergus; School of Life and Medical Sciences, University of Hertfordshire, Hatfield, College Lane, AL10 9AB, United Kingdom; email: s.fergus@herts.ac.uk; CODEN: JCEDA
ER  -

TY  - JOUR
AU  - Ji, H.
AU  - Zhu, Q.
AU  - Ma, T.
AU  - Cheng, Y.
AU  - Zhou, S.
AU  - Ren, W.
AU  - Huang, H.
AU  - He, W.
AU  - Ran, H.
AU  - Ruan, L.
AU  - Guo, Y.
AU  - Tian, J.
AU  - Chen, W.
AU  - Chen, L.
AU  - Wang, Z.
AU  - Zhou, Q.
AU  - Niu, L.
AU  - Zhang, W.
AU  - Yang, R.
AU  - Chen, Q.
AU  - Zhang, R.
AU  - Wang, H.
AU  - Li, L.
AU  - Liu, M.
AU  - Nie, F.
AU  - Zhou, A.
TI  - Development and validation of a transformer-based CAD model for improving the consistency of BI-RADS category 3–5 nodule classification among radiologists: a multiple center study
PY  - 2023
T2  - Quantitative Imaging in Medicine and Surgery
VL  - 13
IS  - 6
SP  - 3671
EP  - 3687
DO  - 10.21037/qims-22-1091
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85166429200&doi=10.21037%2fqims-22-1091&partnerID=40&md5=96af4f973b080f3084c6bb99f704c280
AD  - Department of Diagnostic Ultrasound, Beijing Tongren Hospital, Capital Medical University, Beijing, China
AD  - Department of Ultrasonography, Beijing Tiantan Hospital, Capital Medical University, Beijing, China
AD  - Department of Ultrasound, The Second Affiliated Hospital, Chongqing Medical University, Chongqing, China
AD  - Department of Medical Ultrasound, The First Affiliated Hospital, Xi’an Jiaotong University, Xi’an, China
AD  - Department of Ultrasound, The Southwest Hospital, Army Medical University, Chongqing, China
AD  - Department of Ultrasound, The Second Affiliated Hospital, Harbin Medical University, Harbin, China
AD  - Department of Ultrasound, The First Hospital, Shanxi Medical University, Taiyuan, China
AD  - Department of Ultrasound, The First Hospital, Peking University, Beijing, China
AD  - Department of Ultrasound, Diagnosis Center of Ultrasound, Hunan Province Cancer Hospital, Changsha, China
AD  - Department of Ultrasound, The Second Affiliated Hospital, Xi’an Jiaotong University, Xi’an, China
AD  - Department of Ultrasound, Cancer Hospital, National Cancer Center, Chinese Academy of Medical Sciences, Peking Union Medical College, Beijing, China
AD  - Department of Ultrasonography, The Third Affiliated Hospital, Guangxi Medical University, Nanning, China
AD  - Department of Ultrasound, The Frist Affiliated Hospital of Hebei North University, Zhangjiakou, China
AD  - Department of Ultrasound, Sichuan Provincial People’s Hospital, University of Electronic Science and Technology of China, Chengdu, China
AD  - Department of Ultrasound, The First Affiliated Hospital, Zhengzhou University, Zhengzhou, China
AD  - Department of Ultrasound, China-Japan Union Hospital, Jilin University, Changchun, China
AD  - Department of Ultrasound, Qilu Hospital of Shandong University, Qingdao, China
AD  - Department of Ultrasound Diagnosis, The Second Xiangya Hospital, Central South University, Changsha, China
AD  - Department of Ultrasound, Lanzhou University Second Hospital, Lanzhou, China
AD  - Department of Ultrasound, The First Affiliated Hospital, Nanchang University, Nanchang, China
AB  - Background: Significant differences exist in the classification outcomes for radiologists using ultrasonography-based Breast Imaging Reporting and Data Systems for diagnosing category 3–5 (BI-RADS 3–5) breast nodules, due to a lack of clear and distinguishing image features. Consequently, this retrospective study investigated the improvement of BI-RADS 3–5 classification consistency using a transformer-based computer-aided diagnosis (CAD) model. Methods: Independently, 5 radiologists performed BI-RADS annotations on 21,332 breast ultrasonographic images collected from 3,978 female patients from 20 clinical centers in China. All images were divided into training, validation, testing, and sampling sets. The trained transformer-based CAD model was then used to classify test images, for which sensitivity (SEN), specificity (SPE), accuracy (ACC), area under the curve (AUC), and calibration curve were evaluated. Variations in these metrics among the 5 radiologists were analyzed by referencing BI-RADS classification results for the sampling test set provided by CAD to determine whether classification consistency (the k value), SEN, SPE, and ACC could be improved. Results: After the training set (11,238 images) and validation set (2,996 images) were learned by the CAD model, the classification ACC of the CAD model applied to the test set (7,098 images) was 94.89% in category 3, 96.90% in category 4A, 95.49% in category 4B, 92.28% in category 4C, and 95.45% in category 5 nodules. Based on pathological results, the AUC of the CAD model was 0.924 and the predicted probability of CAD was a little higher than the actual probability in the calibration curve. After referencing BI-RADS classification results, the adjustments were made to 1,583 nodules, of which 905 were classified to a lower category and 678 to a higher category in the sampling test set. As a result, the ACC (72.41–82.65%), SEN (32.73–56.98%), and SPE (82.46–89.26%) of the classification by each radiologist were significantly improved on average, with the consistency (k values) in almost all of them increasing to >0.6. Conclusions: The radiologist’s classification consistency was markedly improved with almost all the k values increasing by a value greater than 0.6, and the diagnostic efficiency was also improved by approximately 24% (32.73% to 56.98%) and 7% (82.46% to 89.26%) for SEN and SPE, respectively, of the total classification on average. The transformer-based CAD model can help to improve the radiologist’s diagnostic efficacy and consistency with others in the classification of BI-RADS 3–5 nodules. © 2023 AME Publishing Company. All rights reserved.
KW  - Breast Imaging Reporting and Data Systems (BI-RADS)
KW  - computer-aided diagnosis (CAD)
KW  - transformers
KW  - ultrasound
KW  - adolescent
KW  - adult
KW  - aged
KW  - Article
KW  - benign breast tumor
KW  - breast abscess
KW  - breast cancer
KW  - breast imaging reporting and data system
KW  - breast papilloma
KW  - calibration
KW  - cancer staging
KW  - child
KW  - computer assisted diagnosis
KW  - controlled study
KW  - data consistency
KW  - diagnostic accuracy
KW  - diagnostic test accuracy study
KW  - ductal breast carcinoma in situ
KW  - echomammography
KW  - feature extraction
KW  - female
KW  - fibrocystic breast disease
KW  - granulomatous inflammation
KW  - human
KW  - invasive breast cancer
KW  - invasive lobular breast carcinoma
KW  - lymphadenopathy
KW  - major clinical study
KW  - medullary carcinoma of the breast
KW  - mucinous carcinoma of the breast
KW  - papillary carcinoma of the breast
KW  - process development
KW  - radiologist
KW  - retrospective study
KW  - sensitivity and specificity
KW  - validation process
PB  - AME Publishing Company
SN  - 22234292 (ISSN)
LA  - English
J2  - Quant. Imaging Med. Surg.
M3  - Article
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 0; Correspondence Address: Q. Zhu; Department of Diagnostic Ultrasound, Beijing Tongren Hospital, Capital Medial University, Beijing, 1 Dong-jiao-minxiang, Dongcheng District, 100730, China; email: qzhu@263.net; W. He; Department of Ultrasonography, Beijing Tiantan Hospital, Capital Medical University, Beijing, No. 119 West Section of South 4th Ring Road, Fengtai District, 100070, China; email: 168hewen@sina.com
ER  -

TY  - JOUR
AU  - White, A.D.
AU  - Hocky, G.M.
AU  - Gandhi, H.A.
AU  - Ansari, M.
AU  - Cox, S.
AU  - Wellawatte, G.P.
AU  - Sasmal, S.
AU  - Yang, Z.
AU  - Liu, K.
AU  - Singh, Y.
AU  - Peña Ccoa, W.J.
TI  - Assessment of chemistry knowledge in large language models that generate code
PY  - 2023
T2  - Digital Discovery
VL  - 2
IS  - 2
SP  - 368
EP  - 376
DO  - 10.1039/d2dd00087c
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85151691540&doi=10.1039%2fd2dd00087c&partnerID=40&md5=f7ae0f9aa806a6df573c88b44c3de6c6
AD  - Department of Chemical Engineering, University of Rochester, United States
AD  - Vial Health Technology, Inc., United States
AD  - Department of Chemistry, New York University, United States
AD  - Simons Center for Computational Physical Chemistry, New York University, United States
AD  - Department of Chemistry, University of Rochester, United States
AB  - In this work, we investigate the question: do code-generating large language models know chemistry? Our results indicate, mostly yes. To evaluate this, we introduce an expandable framework for evaluating chemistry knowledge in these models, through prompting models to solve chemistry problems posed as coding tasks. To do so, we produce a benchmark set of problems, and evaluate these models based on correctness of code by automated testing and evaluation by experts. We find that recent LLMs are able to write correct code across a variety of topics in chemistry and their accuracy can be increased by 30 percentage points via prompt engineering strategies, like putting copyright notices at the top of files. Our dataset and evaluation tools are open source which can be contributed to or built upon by future researchers, and will serve as a community resource for evaluating the performance of new models as they emerge. We also describe some good practices for employing LLMs in chemistry. The general success of these models demonstrates that their impact on chemistry teaching and research is poised to be enormous. © 2023 The Author(s). Published by the Royal Society of Chemistry.
PB  - Royal Society of Chemistry
SN  - 2635098X (ISSN)
LA  - English
J2  - Digit. Discov.
M3  - Article
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 12; Correspondence Address: A.D. White; Department of Chemical Engineering, University of Rochester, United States; email: andrew.white@rochester.edu; G.M. Hocky; Department of Chemistry, New York University, United States; email: hockyg@nyu.edu
ER  -

TY  - JOUR
AU  - Branum, C.
AU  - Schiavenato, M.
TI  - Can ChatGPT Accurately Answer a PICOT Question? Assessing AI Response to a Clinical Question
PY  - 2023
T2  - Nurse Educator
VL  - 48
IS  - 5
SP  - 231
EP  - 233
DO  - 10.1097/NNE.0000000000001436
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85168792426&doi=10.1097%2fNNE.0000000000001436&partnerID=40&md5=1b683614d2adace059b0510cc14da422
AD  - School of Nursing and Human Physiology, Gonzaga University, Spokane, WA, United States
AB  - Background: ChatGPT, an artificial intelligence (AI) text generator trained to predict correct words, can provide answers to questions but has shown mixed results in answering medical questions. Purpose: To assess the reliability and accuracy of ChatGPT in providing answers to a complex clinical question. Methods: A Population, Intervention, Comparison, Outcome, and Time (PICOT) formatted question was queried, along with a request for references. Full-text articles were reviewed to verify the accuracy of the evidence summary provided by the chatbot. Results: ChatGPT was unable to provide a certifiable response to a PICOT question. The references cited as evidence included incorrect journal information, and many study details summarized by ChatGPT proved to be patently false, including providing fabricated data. Conclusions: ChatGPT provides answers that appear legitimate but may be factually incorrect. The system is not transparent in how it gathers data to answer questions and sometimes fabricates information that looks plausible, making it an unreliable tool for clinical questions. © 2023 Lippincott Williams and Wilkins. All rights reserved.
KW  - artificial intelligence
KW  - ChatGPT
KW  - information literacy
KW  - information storage and retrieval
KW  - machine learning
KW  - natural language processing
KW  - Artificial Intelligence
KW  - Humans
KW  - Nursing Education Research
KW  - Reproducibility of Results
KW  - Software
KW  - article
KW  - artificial intelligence
KW  - ChatGPT
KW  - human
KW  - information literacy
KW  - information retrieval
KW  - machine learning
KW  - natural language processing
KW  - outcome assessment
KW  - nursing education
KW  - reproducibility
KW  - software
PB  - Lippincott Williams and Wilkins
SN  - 03633624 (ISSN)
C2  - 37130197
LA  - English
J2  - Nurse Educ.
M3  - Article
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 3; Correspondence Address: C. Branum; Foley Center Library, Gonzaga University, Spokane, Foley Library-AD Box 95, 502 E Boone Ave, 99258, United States; email: branum@gonzaga.edu
ER  -

TY  - JOUR
AU  - Ray, P.P.
TI  - The Need to Re-evaluate the Role of GPT-4 in Generating Radiology Reports
PY  - 2023
T2  - Radiology
VL  - 308
IS  - 2
C7  - e231696
DO  - 10.1148/RADIOL.231696
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85166392479&doi=10.1148%2fRADIOL.231696&partnerID=40&md5=d912d97a499af0de0f1781eb49c2f95a
AD  - Department of Computer Applications, Sikkim University, 6th Mile, PO-Tadong, Sikkim, Gangtok, 737102, India
KW  - Humans
KW  - Radiology
KW  - ChatGPT
KW  - diagnostic approach route
KW  - diagnostic imaging
KW  - efficacy parameters
KW  - evaluation study
KW  - evolution
KW  - futurology
KW  - GPT-4 model
KW  - intermethod comparison
KW  - Letter
KW  - machine learning
KW  - medical decision making
KW  - physician
KW  - radiologist
KW  - radiologist-generated impression
KW  - radiology
KW  - reporting and data system
KW  - human
PB  - Radiological Society of North America Inc.
SN  - 00338419 (ISSN)
C2  - 37526538
LA  - English
J2  - Radiology
M3  - Letter
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 0; Correspondence Address: P.P. Ray; Department of Computer Applications, Sikkim University, Gangtok, 6th Mile, PO-Tadong, Sikkim, 737102, India; email: ppray@cus.ac.in; CODEN: RADLA
ER  -

TY  - JOUR
AU  - Johnson, S.B.
AU  - King, A.J.
AU  - Warner, E.L.
AU  - Aneja, S.
AU  - Kann, B.H.
AU  - Bylund, C.L.
TI  - Using ChatGPT to evaluate cancer myths and misconceptions: artificial intelligence and cancer information
PY  - 2023
T2  - JNCI Cancer Spectrum
VL  - 7
IS  - 2
C7  - pkad015
DO  - 10.1093/jncics/pkad015
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85153536821&doi=10.1093%2fjncics%2fpkad015&partnerID=40&md5=9877415bbff3f0f1edaf334f94135b2d
AD  - Department of Radiation Oncology, University of Utah, School of Medicine, Huntsman Cancer Institute, Salt Lake City, UT, United States
AD  - Cancer Control and Population Sciences, Huntsman Cancer Institute, Salt Lake City, UT, United States
AD  - Department of Communication, University of Utah, Salt Lake City, UT, United States
AD  - College of Nursing, University of Utah, Salt Lake City, UT, United States
AD  - Center for Outcomes Research and Evaluation, Yale School of Medicine, New Haven, CT, United States
AD  - Department of Therapeutic Radiology, Yale School of Medicine, New Haven, CT, United States
AD  - Department of Radiation Oncology, Dana-Farber Cancer Institute, Brigham and Women's Hospital, Harvard Medical School, Boston, MA, United States
AD  - Department of Health Outcomes and Biomedical Informatics, University of Florida College of Medicine, Gainesville, FL, United States
AB  - Data about the quality of cancer information that chatbots and other artificial intelligence systems provide are limited. Here, we evaluate the accuracy of cancer information on ChatGPT compared with the National Cancer Institute's (NCI's) answers by using the questions on the “Common Cancer Myths and Misconceptions” web page. The NCI's answers and ChatGPT answers to each question were blinded, and then evaluated for accuracy (accurate: yes vs no). Ratings were evaluated independently for each question, and then compared between the blinded NCI and ChatGPT answers. Additionally, word count and Flesch-Kincaid readability grade level for each individual response were evaluated. Following expert review, the percentage of overall agreement for accuracy was 100% for NCI answers and 96.9% for ChatGPT outputs for questions 1 through 13 (Œ = -0.03, standard error = 0.08). There were few noticeable differences in the number of words or the readability of the answers from NCI or ChatGPT. Overall, the results suggest that ChatGPT provides accurate information about common cancer myths and misconceptions. © The Author(s) 2023. Published by Oxford University Press.
KW  - article
KW  - artificial intelligence
KW  - human
KW  - national health organization
KW  - reading
PB  - Oxford University Press
SN  - 25155091 (ISSN)
LA  - English
J2  - JNCI Cancer Spectr.
M3  - Article
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 58; Correspondence Address: S.B. Johnson; Department of Radiation Oncology, University of Utah Huntsman Cancer Institute, Salt Lake City, 1950 Circle of Hope Dr, 84112, United States; email: skyler.johnson@hci.utah.edu
ER  -

TY  - JOUR
AU  - Lahat, A.
AU  - Shachar, E.
AU  - Avidan, B.
AU  - Glicksberg, B.
AU  - Klang, E.
TI  - Evaluating the Utility of a Large Language Model in Answering Common Patients’ Gastrointestinal Health-Related Questions: Are We There Yet?
PY  - 2023
T2  - Diagnostics
VL  - 13
IS  - 11
C7  - 1950
DO  - 10.3390/diagnostics13111950
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85161786755&doi=10.3390%2fdiagnostics13111950&partnerID=40&md5=03a0b5f7ccc975c0ef5c7205ddb9fd54
AD  - Chaim Sheba Medical Center, Department of Gastroenterology, Affiliated to Tel Aviv University, Tel Aviv, 69978, Israel
AD  - Mount Sinai Clinical Intelligence Center, Icahn School of Medicine at Mount Sinai, New York, 10029, NY, United States
AD  - The Sami Sagol AI Hub, ARC Innovation Center, Chaim Sheba Medical Center, Affiliated to Tel-Aviv University, Tel Aviv, 69978, Israel
AB  - Background and aims: Patients frequently have concerns about their disease and find it challenging to obtain accurate Information. OpenAI’s ChatGPT chatbot (ChatGPT) is a new large language model developed to provide answers to a wide range of questions in various fields. Our aim is to evaluate the performance of ChatGPT in answering patients’ questions regarding gastrointestinal health. Methods: To evaluate the performance of ChatGPT in answering patients’ questions, we used a representative sample of 110 real-life questions. The answers provided by ChatGPT were rated in consensus by three experienced gastroenterologists. The accuracy, clarity, and efficacy of the answers provided by ChatGPT were assessed. Results: ChatGPT was able to provide accurate and clear answers to patients’ questions in some cases, but not in others. For questions about treatments, the average accuracy, clarity, and efficacy scores (1 to 5) were 3.9 ± 0.8, 3.9 ± 0.9, and 3.3 ± 0.9, respectively. For symptoms questions, the average accuracy, clarity, and efficacy scores were 3.4 ± 0.8, 3.7 ± 0.7, and 3.2 ± 0.7, respectively. For diagnostic test questions, the average accuracy, clarity, and efficacy scores were 3.7 ± 1.7, 3.7 ± 1.8, and 3.5 ± 1.7, respectively. Conclusions: While ChatGPT has potential as a source of information, further development is needed. The quality of information is contingent upon the quality of the online information provided. These findings may be useful for healthcare providers and patients alike in understanding the capabilities and limitations of ChatGPT. © 2023 by the authors.
KW  - chatbot
KW  - gastroenterology
KW  - medical information
KW  - natural language processing (NLP)
KW  - OpenAI’s ChatGPT
KW  - patients’ questions
KW  - Article
KW  - cancer staging
KW  - clinical assessment
KW  - clinical evaluation
KW  - consensus
KW  - diagnosis related group
KW  - diagnostic test
KW  - disease severity
KW  - gastroenterologist
KW  - gastroenterology
KW  - gastrointestinal cancer
KW  - gastrointestinal symptom
KW  - health care quality
KW  - health status
KW  - human
KW  - medical information
KW  - natural language processing
KW  - personal experience
KW  - questionnaire
KW  - standardization
KW  - symptom
KW  - therapy effect
KW  - ulcerative colitis
PB  - Multidisciplinary Digital Publishing Institute (MDPI)
SN  - 20754418 (ISSN)
LA  - English
J2  - Diagn.
M3  - Article
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 14; Correspondence Address: A. Lahat; Chaim Sheba Medical Center, Department of Gastroenterology, Affiliated to Tel Aviv University, Tel Aviv, 69978, Israel; email: zokadi@gmail.com
ER  -

TY  - JOUR
AU  - Zhang, F.
AU  - Nghiem, L.
AU  - Chen, Z.
TI  - Evaluating reservoir performance using a transformer based proxy model
PY  - 2023
T2  - Geoenergy Science and Engineering
VL  - 226
C7  - 211644
DO  - 10.1016/j.geoen.2023.211644
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85160007243&doi=10.1016%2fj.geoen.2023.211644&partnerID=40&md5=e4e724fa73597345c44d33d09823ff2a
AD  - University of Calgary and Computer Modelling Group Ltd, Canada
AD  - University of Calgary, Canada
AB  - In reservoir simulation, proxy models have been used to explore relationships between explanatory variables (e.g., porosity, permeability, well locations and constraints) and response variables (e.g., production rates and bottom hole pressure). Compared to traditional methods used in the proxy models such as capacitance-resistance model (CRM), and interwell numerical Simulation model (INSIM), deep learning methods such as Recurrent Neural Networks (RNNs) have achieved remarkable advancement in predicting reservoir production and assessing uncertainty. However, one limitation of the RNNs is that they are hard to parallelize, which makes their training process computationally expensive. In this paper, a Transformer based proxy model, which is effective in processing sequential data, is developed to accelerate learning and simulation processes. Different types of data are embedded and concatenated as input sequences including water injection, drilling decision, well position, porosity, and permeability. Incorporating additional important information like operational and geological data is found to improve the accuracy of simulation significantly compared to sole injection data input. The model based on a sequence-to-sequence architecture can also be extrapolated to a longer horizon. Both RNNs and Transformer models are used to compare the result accuracy and computation speed. It is found that the Transformer model can be four times faster than the RNNs model under the same order of accuracy. © 2023 Elsevier B.V.
KW  - Attention mechanisms
KW  - Deep Learning
KW  - Time series
KW  - Transformer
KW  - Waterflooding
KW  - Bottom hole pressure
KW  - Data handling
KW  - Learning systems
KW  - Numerical methods
KW  - Petroleum reservoir engineering
KW  - Porosity
KW  - Uncertainty analysis
KW  - Attention mechanisms
KW  - Deep learning
KW  - Explanatory variables
KW  - Proxy model
KW  - Recurrent neural network model
KW  - Reservoir performance
KW  - Reservoir-simulation
KW  - Times series
KW  - Transformer
KW  - Transformer modeling
KW  - artificial neural network
KW  - data processing
KW  - hydrocarbon reservoir
KW  - oil production
KW  - performance assessment
KW  - prediction
KW  - reservoir flooding
KW  - time series
KW  - uncertainty analysis
KW  - Recurrent neural networks
PB  - Elsevier B.V.
SN  - 29498910 (ISSN)
LA  - English
J2  - Geoenergy. Sci. Eng.
M3  - Article
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 1; Correspondence Address: F. Zhang; University of Calgary and Computer Modelling Group Ltd, Canada; email: feng.zhang1@ucalgary.ca
ER  -

TY  - JOUR
AU  - Kaneda, Y.
TI  - ChatGPT in infectious diseases: A practical evaluation and future considerations
PY  - 2023
T2  - New Microbes and New Infections
VL  - 54
C7  - 101166
DO  - 10.1016/j.nmni.2023.101166
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85165641108&doi=10.1016%2fj.nmni.2023.101166&partnerID=40&md5=87293f8227e0d4f4af5fae20f2fc2a74
AD  - School of Medicine, Hokkaido University, Hokkaido, Japan
KW  - ChatGPT
KW  - Infectious diseases
KW  - The Japanese association for infectious diseases
KW  - ChatGPT
KW  - communicable disease
KW  - infection
KW  - Letter
KW  - software
PB  - Elsevier Ltd
SN  - 20522975 (ISSN)
LA  - English
J2  - New Microbes New Infect.
M3  - Letter
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 0; Correspondence Address: Y. Kaneda; Hokkaido University School of Medicine, Sapporo, Kita-ku, Kita15, Nishi7, 0608638, Japan; email: nature271828@gmail.com
ER  -

TY  - JOUR
AU  - Sun, F.
AU  - Xu, H.
AU  - Meng, Y.
AU  - Lu, Z.
AU  - Gong, C.
TI  - BERT-based coupling evaluation of biological strategies in bio-inspired design
PY  - 2023
T2  - Expert Systems with Applications
VL  - 222
C7  - 119725
DO  - 10.1016/j.eswa.2023.119725
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85150827326&doi=10.1016%2fj.eswa.2023.119725&partnerID=40&md5=fb5920144701d46ba39e9023cd7af34b
AD  - College of Mechanical and Electrical Engineering, Harbin Engineering University, Heilongjiang, Harbin, 150001, China
AD  - College of Computer Science, Dalian University of Technology, Liaoning, Dalian, 116000, China
AD  - School of Economics and Management, Harbin Engineering University, Heilongjiang, Harbin, 150001, China
AB  - Searching for suitable biological strategies in bio-inspired design (BID) is the first problem that designers need to solve. Based on the biological strategy database of the AskNature, a natural language processing (NLP) method is applied to search for keywords related to design topics, and a multi-criteria coupled evaluation method is proposed for biological strategy. This paper firstly establishes the mapping relationship between BID topic and biological strategies through a NLP method-BERT. Then a coupled evaluation method is established based on the ordinal relation analysis and the deviation maximization method, highlighting the differences between biological strategies while considering the designer's preference. Finally, cases show the biological strategy coupling evaluation process. The results indicate that the proposed method is effective and efficient in biological strategy evaluation, which assists BID well. © 2023 Elsevier Ltd
KW  - BERT
KW  - Bio-inspired design
KW  - Biological strategy
KW  - Coupling evaluation
KW  - Biomimetics
KW  - Natural language processing systems
KW  - BERT
KW  - Bio-inspired designs
KW  - Biological strategy
KW  - Coupling evaluation
KW  - Evaluation methods
KW  - Language processing
KW  - Multi-criteria
KW  - Multi-Criterion
KW  - Natural languages
KW  - Processing method
KW  - Petroleum reservoir evaluation
PB  - Elsevier Ltd
SN  - 09574174 (ISSN)
LA  - English
J2  - Expert Sys Appl
M3  - Article
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 2; Correspondence Address: H. Xu; College of Mechanical and Electrical Engineering, Harbin Engineering University, Harbin, Heilongjiang, 150001, China; email: railway_dragon@sohu.com; CODEN: ESAPE
ER  -

TY  - JOUR
AU  - Munoz-Zuluaga, C.
AU  - Zhao, Z.
AU  - Wang, F.
AU  - Greenblatt, M.B.
AU  - Yang, H.S.
TI  - Assessing the Accuracy and Clinical Utility of ChatGPT in Laboratory Medicine
PY  - 2023
T2  - Clinical chemistry
VL  - 69
IS  - 8
SP  - 939
EP  - 940
DO  - 10.1093/clinchem/hvad058
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85166442750&doi=10.1093%2fclinchem%2fhvad058&partnerID=40&md5=b5c76d7af31503ab9f9fc24ffcd55d6b
AD  - Department of Pathology and Laboratory Medicine, Weill Cornell Medicine, NY, 10065, NY, United States
AD  - Department of Population Health Sciences, Weill Cornell Medicine, New York, NY, United States
AD  - Research Division, Hospital for Special Surgery, New York, NY, United States
PB  - NLM (Medline)
SN  - 15308561 (ISSN)
C2  - 37231970
LA  - English
J2  - Clin Chem
M3  - Article
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 9
ER  -

TY  - JOUR
AU  - Miao, J.
AU  - Thongprayoon, C.
AU  - Cheungpasitporn, W.
TI  - Assessing the Accuracy of ChatGPT on Core Questions in Glomerular Disease
PY  - 2023
T2  - Kidney International Reports
VL  - 8
IS  - 8
SP  - 1657
EP  - 1659
DO  - 10.1016/j.ekir.2023.05.014
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85161901737&doi=10.1016%2fj.ekir.2023.05.014&partnerID=40&md5=8d0fcf79e9510eb44a19ed4e06add15f
AD  - Division of Nephrology and Hypertension, Department of Medicine, Mayo Clinic, Rochester, MN, United States
KW  - accuracy
KW  - ChatGPT
KW  - concordance
KW  - glomerular disease
KW  - KSAP
KW  - NephSAP
KW  - electrolyte
KW  - acute kidney failure
KW  - Article
KW  - artificial intelligence
KW  - chat based generative pre trained transformers
KW  - chronic kidney failure
KW  - deep learning
KW  - end stage renal disease
KW  - glomerulopathy
KW  - human
KW  - hypertension
KW  - kidney disease
KW  - kidney transplantation
KW  - self evaluation
PB  - Elsevier Inc.
SN  - 24680249 (ISSN)
LA  - English
J2  - Kidney Intl. Rep.
M3  - Article
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 10; Correspondence Address: W. Cheungpasitporn; Division of Nephrology and Hypertension, Department of Medicine, Mayo Clinic, Rochester, United States; email: wcheungpasitporn@gmail.com
ER  -

TY  - CONF
AU  - Zhang, J.
AU  - Bao, K.
AU  - Zhang, Y.
AU  - Wang, W.
AU  - Feng, F.
AU  - He, X.
TI  - Is ChatGPT Fair for Recommendation? Evaluating Fairness in Large Language Model Recommendation
PY  - 2023
T2  - Proceedings  of the 17th ACM Conference on Recommender Systems, RecSys 2023
SP  - 993
EP  - 999
DO  - 10.1145/3604915.3608860
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85174544035&doi=10.1145%2f3604915.3608860&partnerID=40&md5=9244b7054715dd827c5971a5b9c09932
AD  - University of Science and Technology of China, China
AD  - National University of Singapore, Singapore
AB  - The remarkable achievements of Large Language Models (LLMs) have led to the emergence of a novel recommendation paradigm - Recommendation via LLM (RecLLM). Nevertheless, it is important to note that LLMs may contain social prejudices, and therefore, the fairness of recommendations made by RecLLM requires further investigation. To avoid the potential risks of RecLLM, it is imperative to evaluate the fairness of RecLLM with respect to various sensitive attributes on the user side. Due to the differences between the RecLLM paradigm and the traditional recommendation paradigm, it is problematic to directly use the fairness benchmark of traditional recommendation. To address the dilemma, we propose a novel benchmark called Fairness of Recommendation via LLM (FaiRLLM). This benchmark comprises carefully crafted metrics and a dataset that accounts for eight sensitive attributes1 in two recommendation scenarios: music and movies. By utilizing our FaiRLLM benchmark, we conducted an evaluation of ChatGPT and discovered that it still exhibits unfairness to some sensitive attributes when generating recommendations. Our code and dataset can be found at https://github.com/jizhi-zhang/FaiRLLM. © 2023 ACM.
KW  - Benchmark
KW  - Fairness
KW  - Large Language Models
KW  - Computational linguistics
KW  - Benchmark
KW  - Fairness
KW  - Language model
KW  - Large language model
KW  - Potential risks
KW  - Sensitive attribute
KW  - Recommender systems
PB  - Association for Computing Machinery, Inc
SN  - 979-840070241-9 (ISBN)
LA  - English
J2  - Proc. ACM Conf. Recommen. Syst., RecSys
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 4; Correspondence Address: F. Feng; University of Science and Technology of China, China; email: fulifeng93@gmail.com; X. He; University of Science and Technology of China, China; email: xiangnanhe@gmail.com; Conference name: 17th ACM Conference on Recommender Systems, RecSys 2023; Conference date: 18 September 2023 through 22 September 2023; Conference code: 192884
ER  -

TY  - JOUR
AU  - Kusunose, K.
AU  - Kashima, S.
AU  - Sata, M.
TI  - Evaluation of the Accuracy of ChatGPT in Answering Clinical Questions on the Japanese Society of Hypertension Guidelines
PY  - 2023
T2  - Circulation Journal
VL  - 87
IS  - 7
SP  - 1030
EP  - 1033
DO  - 10.1253/circj.CJ-23-0308
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85163091102&doi=10.1253%2fcircj.CJ-23-0308&partnerID=40&md5=444f59d8bdd6cb95d43d2c758d6eac87
AD  - Department of Cardiovascular Medicine, Tokushima University Hospital, Tokushima, Japan
AD  - Department of Cardiovascular Medicine, Nephrology, and Neurology, Graduate School of Medicine, University of the Ryukyus, Okinawa, Japan
AB  - Background: To assist healthcare providers in interpreting guidelines, clinical questions (CQ) are often included, but not always, which can make interpretation difficult for non-expert clinicians. We evaluated the ability of ChatGPT to accurately answer CQs on the Japanese Society of Hypertension Guidelines for the Management of Hypertension (JSH 2019). Methods and Results: We conducted an observational study using data from JSH 2019. The accuracy rate for CQs and limited evidence-based questions of the guidelines (Qs) were evaluated. ChatGPT demonstrated a higher accuracy rate for CQs than for Qs (80% vs. 36%, P value: 0.005). Conclusions: ChatGPT has the potential to be a valuable tool for clinicians in the management of hypertension. © 2023 Japanese Circulation Society. All rights reserved.
KW  - ChatGPT
KW  - Guidelines
KW  - Hypertension
KW  - Large language models
KW  - East Asian People
KW  - Health Personnel
KW  - Humans
KW  - Hypertension
KW  - Article
KW  - clinical question
KW  - cohort analysis
KW  - controlled study
KW  - diagnostic accuracy
KW  - diagnostic test accuracy study
KW  - human
KW  - Japanese society of hypertension guidelines
KW  - natural language processing
KW  - observational study
KW  - practice guideline
KW  - questionnaire
KW  - East Asian
KW  - health care personnel
KW  - hypertension
PB  - Japanese Circulation Society
SN  - 13469843 (ISSN)
C2  - 37286486
LA  - English
J2  - Circ. J.
M3  - Article
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 5; Correspondence Address: K. Kusunose; Department of Cardiovascular Medicine, Tokushima University Hospital, Tokushima, 2-50-1 Kuramoto, 770-8503, Japan; email: echo.cardio@gmail.com; CODEN: CJIOB
ER  -

TY  - JOUR
AU  - Yeo, Y.H.
AU  - Samaan, J.S.
AU  - Ng, W.H.
TI  - Correspondence on Letter 2 regarding “Assessing the performance of ChatGPT in answering questions regarding cirrhosis and hepatocellular carcinoma”
PY  - 2023
T2  - Clinical and Molecular Hepatology
VL  - 29
IS  - 3
SP  - 823
EP  - 824
DO  - 10.3350/cmh.2023.0182
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85167847280&doi=10.3350%2fcmh.2023.0182&partnerID=40&md5=36e29b796c33c6b09d4ee4509d7d0fe6
AD  - Karsh Division of Gastroenterology and Hepatology, Department of Medicine, Cedars-Sinai Medical Center, Los Angeles, 90048, CA, United States
AD  - Bristol Medical School, University of Bristol, Bristol, United Kingdom
KW  - Artificial intelligence
KW  - Communication barriers
KW  - Ethics
KW  - Medicine
KW  - Patient care
KW  - artificial intelligence
KW  - ChatGPT
KW  - decision making
KW  - health care
KW  - health care personnel
KW  - human
KW  - letter
KW  - Letter
KW  - liver cell carcinoma
KW  - liver cirrhosis
KW  - patient care
PB  - Korean Association for the Study of the Liver
SN  - 22872728 (ISSN)
C2  - 37254485
LA  - English
J2  - Clin. Mol. Hepatol.
M3  - Letter
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 0; Correspondence Address: Y.H. Yeo; Karsh Division of Gastroenterology and Hepatology, Department of Medicine, Cedars-Sinai Medical Center, Los Angeles, 90048, United States; email: Yeehui.yeo@cshs.org
ER  -

TY  - JOUR
AU  - Brie, P.
AU  - Burny, N.
AU  - Sluyters, A.
AU  - Vanderdonckt, J.
TI  - Evaluating a Large Language Model on Searching for GUI Layouts
PY  - 2023
T2  - Proceedings of the ACM on Human-Computer Interaction
VL  - 7
IS  - EICS
C7  - 178
DO  - 10.1145/3593230
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85163743748&doi=10.1145%2f3593230&partnerID=40&md5=496c3f7b5c9bd7306311f27a59070a8b
AD  - TeleportHQ, Calea Motilor, 84, Cluj-Napoca, 400370, Romania
AD  - Université Catholique de Louvain, Louvain Research Institute in Management and Organizations, Place des Doyens, 1, Louvain-la-Neuve, 1348, Belgium
AB  - The field of generative artificial intelligence has seen significant advancements in recent years with the advent of large language models, which have shown impressive results in software engineering tasks but not yet in engineering user interfaces. Thus, we raise a specific research question: would an LLM-based system be able to search for relevant GUI layouts? To address this question, we conducted a controlled study evaluating how Instigator, an LLM-based system for searching GUI layouts of web pages by generative pre-Trained training, would return GUI layouts that are relevant to a given instruction and what would be the user experience of (N =34) practitioners interacting with Instigator. Our results identify a very high similarity and a moderate correlation between the rankings of the GUI layouts generated by Instigator and the rankings of the practitioners with respect to their relevance to a given design instruction. We highlight the results obtained through thirteen UEQ+ scales that characterize the user experience of the practitioner with Instigator, which we use to discuss perspectives for improving such future tools.  © 2023 ACM.
KW  - generative pre-Training
KW  - gui design
KW  - gui layout
KW  - large language model
KW  - web pages
KW  - Computational linguistics
KW  - Graphical user interfaces
KW  - Software engineering
KW  - Engineering tasks
KW  - Generative pre-training
KW  - GUI designs
KW  - Gui layout
KW  - Language model
KW  - Large language model
KW  - Pre-training
KW  - Research questions
KW  - Users' experiences
KW  - Web-page
KW  - Websites
PB  - Association for Computing Machinery
SN  - 25730142 (ISSN)
LA  - English
J2  - Proc. ACM Hum. Comput. Interact.
M3  - Article
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 1
ER  -

TY  - CONF
AU  - Qureshi, B.
TI  - ChatGPT in Computer Science Curriculum Assessment: An analysis of Its Successes and Shortcomings
PY  - 2023
T2  - ACM International Conference Proceeding Series
SP  - 7
EP  - 13
DO  - 10.1145/3613944.3613946
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85182740180&doi=10.1145%2f3613944.3613946&partnerID=40&md5=0d3576a2278375bc7d19bd9e01cfa755
AD  - Department of Computer Science, Prince Sultan University, Riyadh, Saudi Arabia
AB  - The application of Artificial intelligence for teaching and learning in the academic sphere is a trending subject of interest in computing education. ChatGPT, as an AI-based tool, provides various advantages, such as heightened student involvement, cooperation, accessibility, and availability. This paper addresses the prospects and obstacles associated with utilizing ChatGPT as a tool for learning and assessment in undergraduate Computer Science curriculum in particular to teaching and learning fundamental programming courses. Students having completed the course work for a Data Structures and Algorithms (a sophomore-level course) participated in this study. Two groups of students were given programming challenges to solve within a short period of time. The control group (group A) had access to textbooks and notes of programming courses, however, no Internet access was provided. Group B students were given access to ChatGPT and were encouraged to use it to help solve the programming challenges. The challenge was conducted in a computer lab environment using Programming Contest Control (PC2) environment which is widely used in ACM International Collegiate Programming Contest (ICPC). Each team of students addresses the problem by writing executable code that satisfies a certain number of test cases. Student teams were scored based on their performance in terms of the number of successfully passed test cases. Results show that students using ChatGPT had an advantage in terms of earned scores, however, there were inconsistencies and inaccuracies in the submitted code consequently affecting the overall performance. After a thorough analysis, the paper's findings indicate that incorporating AI in higher education brings about various opportunities and challenges. Nonetheless, universities can efficiently manage these apprehensions by adopting a proactive and ethical stance toward the implementation of such tools.  © 2023 ACM.
KW  - Academic assessment
KW  - ChatGPT
KW  - Data Structures and Algorithms
KW  - programming concepts
KW  - Codes (symbols)
KW  - Computer programming
KW  - Curricula
KW  - Data structures
KW  - Education computing
KW  - Engineering education
KW  - Teaching
KW  - Academic assessment
KW  - ChatGPT
KW  - Computer science curricula
KW  - Curriculum assessment
KW  - Data structure and algorithm
KW  - Performance
KW  - Programming concepts
KW  - Programming course
KW  - Teaching and learning
KW  - Test case
KW  - Students
PB  - Association for Computing Machinery
SN  - 979-840070041-5 (ISBN)
LA  - English
J2  - ACM Int. Conf. Proc. Ser.
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 0; Correspondence Address: B. Qureshi; Department of Computer Science, Prince Sultan University, Riyadh, Saudi Arabia; email: qureshi@psu.edu.sa; Conference name: 9th International Conference on e-Society, e-Learning and e-Technologies, ICSLT 2023; Conference date: 9 June 2023 through 11 June 2023; Conference code: 196081
ER  -

TY  - JOUR
AU  - Wang, M.
AU  - He, J.
TI  - Shake table test and finite element model for evaluating seismic performance of 220 kV transformer-bushing systems
PY  - 2023
T2  - Earthquake Spectra
VL  - 39
IS  - 3
SP  - 1755
EP  - 1778
DO  - 10.1177/87552930231177089
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85163049519&doi=10.1177%2f87552930231177089&partnerID=40&md5=fcff1e2267ed1d3138294279e0fc4d49
AD  - Department of Civil Engineering, School of Naval Architecture, Ocean & Civil Engineering, Shanghai Jiao Tong University, Shanghai, China
AD  - Shanghai Key Laboratory for Digital Maintenance of Buildings and Infrastructure, Shanghai Jiao Tong University, Shanghai, China
AB  - To experimentally evaluate and numerically simulate seismic performance of 220 kV transformer-bushing systems, especially the bushings of the system, this study conducts a shake table test of a 1:2.5 reduced-scale 220 kV transformer-bushing system model and develops a three-dimensional finite element model for the system model based on the experimental results. The test shows that the bending flexibility of the cover plate of the transformer tank significantly influences the seismic responses of the bushings mounted on the tank and the ground motion amplification factors related to the bushings. In addition, the test also reveals that seismic performance in the x and y directions of the bushings are distinct from each other. The numerical simulation of the seismic responses of the system model shows that the developed finite element model is reasonable enough considering complexity of the system model and, moreover, can be extended to simulate seismic performance of the high-voltage transformer-bushing systems, including the 220 kV transformer-bushing systems. © The Author(s) 2023.
KW  - 220 kV power transformers
KW  - finite element model
KW  - seismic performance
KW  - shake table test
KW  - transformer-bushing systems
KW  - Bushings
KW  - Electric transformer testing
KW  - Finite element method
KW  - Seismic response
KW  - Seismic waves
KW  - Tanks (containers)
KW  - 220 kv power transformer
KW  - Finite element modelling (FEM)
KW  - Model-based OPC
KW  - Reduced scale
KW  - Seismic Performance
KW  - Shake-table tests
KW  - System models
KW  - Three dimensional finite element model
KW  - Transformer bushings
KW  - Transformer-bushing system
KW  - computer simulation
KW  - finite element method
KW  - numerical model
KW  - seismic response
KW  - shaking table test
KW  - Power transformers
PB  - SAGE Publications Inc.
SN  - 87552930 (ISSN)
LA  - English
J2  - Earthquake Spectra
M3  - Article
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 0; Correspondence Address: J. He; Department of Civil Engineering, School of Naval Architecture, Ocean & Civil Engineering, Shanghai Jiao Tong University, Shanghai, China; email: junhe@sjtu.edu.cn; CODEN: EASPE
ER  -

TY  - JOUR
AU  - Samaan, J.S.
AU  - Yeo, Y.H.
AU  - Rajeev, N.
AU  - Hawley, L.
AU  - Abel, S.
AU  - Ng, W.H.
AU  - Srinivasan, N.
AU  - Park, J.
AU  - Burch, M.
AU  - Watson, R.
AU  - Liran, O.
AU  - Samakar, K.
TI  - Assessing the Accuracy of Responses by the Language Model ChatGPT to Questions Regarding Bariatric Surgery
PY  - 2023
T2  - Obesity Surgery
VL  - 33
IS  - 6
SP  - 1790
EP  - 1796
DO  - 10.1007/s11695-023-06603-5
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85153707773&doi=10.1007%2fs11695-023-06603-5&partnerID=40&md5=265b056423b4a8a08430b71b8ad38236
AD  - Karsh Division of Gastroenterology and Hepatology, Cedars-Sinai Medical Center, 8700 Beverly Blvd, Los Angeles, 90048, CA, United States
AD  - Division of Upper GI and General Surgery, Department of Surgery, Health Care Consultation Center, Keck School of Medicine of USC, 1510 San Pablo St. #514, Los Angeles, 90033, CA, United States
AD  - Bristol Medical School, University of Bristol, 5 Tyndall Ave, Bristol, BS8 1UD, United Kingdom
AD  - Department of Surgery, Cedars-Sinai Medical Center, 8700 Beverly Blvd, Los Angeles, 90048, CA, United States
AD  - Department of Psychiatry and Behavioral Sciences, Cedars-Sinai Medical Center, 8700 Beverly Blvd, Los Angeles, 90048, CA, United States
AD  - Division of Health Services Research, Department of Medicine, Cedars-Sinai Medical Center, 8700 Beverly Blvd, Los Angeles, 90048, CA, United States
AB  - Purpose: ChatGPT is a large language model trained on a large dataset covering a broad range of topics, including the medical literature. We aim to examine its accuracy and reproducibility in answering patient questions regarding bariatric surgery. Materials and methods: Questions were gathered from nationally regarded professional societies and health institutions as well as Facebook support groups. Board-certified bariatric surgeons graded the accuracy and reproducibility of responses. The grading scale included the following: (1) comprehensive, (2) correct but inadequate, (3) some correct and some incorrect, and (4) completely incorrect. Reproducibility was determined by asking the model each question twice and examining difference in grading category between the two responses. Results: In total, 151 questions related to bariatric surgery were included. The model provided “comprehensive” responses to 131/151 (86.8%) of questions. When examined by category, the model provided “comprehensive” responses to 93.8% of questions related to “efficacy, eligibility and procedure options”; 93.3% related to “preoperative preparation”; 85.3% related to “recovery, risks, and complications”; 88.2% related to “lifestyle changes”; and 66.7% related to “other”. The model provided reproducible answers to 137 (90.7%) of questions. Conclusion: The large language model ChatGPT often provided accurate and reproducible responses to common questions related to bariatric surgery. ChatGPT may serve as a helpful adjunct information resource for patients regarding bariatric surgery in addition to standard of care provided by licensed healthcare professionals. We encourage future studies to examine how to leverage this disruptive technology to improve patient outcomes and quality of life. Graphical Abstract: [Figure not available: see fulltext.] © 2023, The Author(s).
KW  - Artificial intelligence
KW  - Bariatric surgery
KW  - ChatGPT
KW  - Health literacy
KW  - Language learning models
KW  - Weight loss
KW  - Bariatric Surgery
KW  - Humans
KW  - Language
KW  - Obesity, Morbid
KW  - Quality of Life
KW  - Reproducibility of Results
KW  - Article
KW  - artificial intelligence
KW  - bariatric surgery
KW  - clinical assessment
KW  - clinical effectiveness
KW  - clinical examination
KW  - comprehension
KW  - convalescence
KW  - data accuracy
KW  - eligibility criteria
KW  - human
KW  - language processing
KW  - lifestyle modification
KW  - medical society
KW  - nonhuman
KW  - online support group
KW  - postoperative complication
KW  - preoperative care
KW  - reproducibility
KW  - social media
KW  - surgical risk
KW  - language
KW  - morbid obesity
KW  - quality of life
PB  - Springer
SN  - 09608923 (ISSN)
C2  - 37106269
LA  - English
J2  - Obes. Surg.
M3  - Article
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 37; Correspondence Address: J.S. Samaan; Karsh Division of Gastroenterology and Hepatology, Cedars-Sinai Medical Center, Los Angeles, 8700 Beverly Blvd, 90048, United States; email: jamil.samaan@gmail.com; CODEN: OBSUE
ER  -

TY  - JOUR
AU  - Lam Hoai, X.-L.
AU  - Simonart, T.
TI  - Comparing Meta-Analyses with ChatGPT in the Evaluation of the Effectiveness and Tolerance of Systemic Therapies in Moderate-to-Severe Plaque Psoriasis
PY  - 2023
T2  - Journal of Clinical Medicine
VL  - 12
IS  - 16
C7  - 5410
DO  - 10.3390/jcm12165410
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85169088997&doi=10.3390%2fjcm12165410&partnerID=40&md5=62018c11fbc488c48dd6690250dde2ba
AD  - Department of Dermatology, St Pierre—Brugmann—HUDERF University Hospitals, Université Libre de Bruxelles, Brussels, 1050, Belgium
AD  - Department of Dermatology, Delta Hospital, CHIREC, Université Libre de Bruxelles, Brussels, 1050, Belgium
AB  - Background: Meta-analyses (MAs) and network meta-analyses (NMAs) are high-quality studies for assessing drug efficacy, but they are time-consuming and may be affected by biases. The capacity of artificial intelligence to aggregate huge amounts of information is emerging as particularly interesting for processing the volume of information needed to generate MAs. In this study, we analyzed whether the chatbot ChatGPT is able to summarize information in a useful fashion for providers and patients in a way that matches up with the results of MAs/NMAs. Methods: We included 16 studies (13 NMAs and 3 MAs) that evaluate biologics (n = 6) and both biologic and systemic treatment (n = 10) for moderate-to-severe psoriasis, published between January 2021 and May 2023. Results: The conclusions of the MAs/NMAs were compared to ChatGPT’s answers to queries about the molecules evaluated in the selected MAs/NMAs. The reproducibility between the results of ChatGPT and the MAs/NMAs was random regarding drug safety. Regarding efficacy, ChatGPT reached the same conclusion as 5 out of the 16 studies (four out of four studies when three molecules were compared), gave acceptable answers in 7 out of 16 studies, and was inconclusive in 4 out of 16 studies. Conclusions: ChatGPT can generate conclusions that are similar to MAs when the efficacy of fewer drugs is compared but is still unable to summarize information in a way that matches up to the results of MAs/NMAs when more than three molecules are compared. © 2023 by the authors.
KW  - artificial intelligence
KW  - meta-analysis
KW  - psoriasis
KW  - acitretin
KW  - adalimumab
KW  - alefacept
KW  - antipsoriasis agent
KW  - apremilast
KW  - baricitinib
KW  - bimekizumab
KW  - briakinumab
KW  - brodalumab
KW  - certolizumab pegol
KW  - cyclosporine
KW  - dimethyl fumarate
KW  - etanercept
KW  - guselkumab
KW  - infliximab
KW  - ixekizumab
KW  - methotrexate
KW  - placebo
KW  - risankizumab
KW  - secukinumab
KW  - tildrakizumab
KW  - tofacitinib
KW  - ustekinumab
KW  - adult
KW  - Article
KW  - ChatGPT
KW  - comparative effectiveness
KW  - controlled study
KW  - disease severity
KW  - drug efficacy
KW  - drug safety
KW  - drug withdrawal
KW  - human
KW  - immunotherapy
KW  - meta analysis
KW  - network meta-analysis
KW  - Psoriasis Area and Severity Index
KW  - psoriasis vulgaris
KW  - reproducibility
KW  - systematic review
KW  - systemic therapy
KW  - unspecified side effect
PB  - Multidisciplinary Digital Publishing Institute (MDPI)
SN  - 20770383 (ISSN)
LA  - English
J2  - J. Clin. Med.
M3  - Article
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 1; Correspondence Address: T. Simonart; Department of Dermatology, Delta Hospital, CHIREC, Université Libre de Bruxelles, Brussels, 1050, Belgium; email: tsimonar@outlook.com
ER  -

TY  - JOUR
AU  - Li, D.
AU  - Gupta, K.
AU  - Chong, J.
TI  - Evaluating Diagnostic Performance of ChatGPT in Radiology: Delving into Methods
PY  - 2023
T2  - Radiology
VL  - 308
IS  - 3
SP  - e232082
DO  - 10.1148/radiol.232082
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85171900895&doi=10.1148%2fradiol.232082&partnerID=40&md5=86061e754a311a52bfbd4a0d7ee198db
AD  - Department of Medical Imaging, London Health Sciences Centre, 800 Commissioners Rd E, London, N6A 5W9, ON, Canada
AD  - Department of Medical Imaging, Schulich School of Medicine and Dentistry, Western University, London, ON, Canada
KW  - Humans
KW  - Radiography
KW  - Radiology
KW  - human
KW  - radiography
KW  - radiology
PB  - NLM (Medline)
SN  - 15271315 (ISSN)
C2  - 37724974
LA  - English
J2  - Radiology
M3  - Letter
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 0
ER  -

TY  - JOUR
AU  - Islam, N.
AU  - Khan, R.
AU  - Das, S.K.
AU  - Sarker, S.K.
AU  - Islam, M.M.
AU  - Akter, M.
AU  - Muyeen, S.M.
TI  - Power transformer health condition evaluation: A deep generative model aided intelligent framework
PY  - 2023
T2  - Electric Power Systems Research
VL  - 218
C7  - 109201
DO  - 10.1016/j.epsr.2023.109201
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85147730303&doi=10.1016%2fj.epsr.2023.109201&partnerID=40&md5=03598f403f15a5a63417ad026f363314
AD  - Department of Mechatronics Engineering, Rajshahi University of Engineering & Technology, Rajshahi, Bangladesh
AD  - Department of Electrical & Electronic Engineering, Dhaka University of Engineering & Technology, Gazipur, Bangladesh
AD  - Department of Electrical Engineering, Qatar University, Doha, Qatar
AB  - This paper presents a deep generative model-aided intelligent framework for effective health condition evaluation of power grid transformers. The health assessment of a power transformer is required to guarantee the stable and sustainable operation of the grid and to precisely convert the electrical energy. A power transformer must undergo a series of tests to determine its state of health and identify its health index. In this paper, we develop a novel approach to identify and classify the health condition of power transformers using a machine learning approach. The proposed framework is structured by using a multi-layer perception generative model with a logistic regression classifier. The developed model uses the twelve input layers which enables the model to effectively compressed the dataset and eight categories in the output classification layers. The effectiveness of the proposed model is examined on the real-world testing data set of 31 categories of six hundred and eight transformers. The obtained performance using the proposed framework confirms its efficacy in precisely evaluating the transformer's health condition. The obtained results have also been compared with the existing machine-learning models. The comparisons show that the proposed model outperforms the state-of-the-art models by achieving 99% of accuracy. © 2023 Elsevier B.V.
KW  - Experts comments
KW  - Health index
KW  - Machine learning
KW  - Multilayer perceptron generative model
KW  - Power transformer
KW  - Subsystems
KW  - Classification (of information)
KW  - Electric transformer testing
KW  - Logistic regression
KW  - Machine learning
KW  - Statistical tests
KW  - Condition evaluation
KW  - Expert comment
KW  - Generative model
KW  - Health condition
KW  - Health indices
KW  - Machine-learning
KW  - Multilayer perceptron generative model
KW  - Multilayers perceptrons
KW  - Power grids
KW  - Subsystem
KW  - Power transformers
PB  - Elsevier Ltd
SN  - 03787796 (ISSN)
LA  - English
J2  - Electr Power Syst Res
M3  - Article
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 4; Correspondence Address: S.K. Sarker; Department of Mechatronics Engineering, Rajshahi University of Engineering & Technology, Rajshahi, Bangladesh; email: subrata@mte.ruet.ac.bd; CODEN: EPSRD
ER  -

TY  - CONF
AU  - Mirowski, P.
AU  - Mathewson, K.W.
AU  - Pittman, J.
AU  - Evans, R.
TI  - Co-Writing Screenplays and Theatre Scripts with Language Models: Evaluation by Industry Professionals
PY  - 2023
T2  - Conference on Human Factors in Computing Systems - Proceedings
C7  - 355
DO  - 10.1145/3544548.3581225
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85160002408&doi=10.1145%2f3544548.3581225&partnerID=40&md5=5ec981fec19d1d0b5bcb0eb194d11c05
AD  - DeepMind, London, United Kingdom
AD  - Stanford University, Stanford, United States
AB  - Language models are increasingly attracting interest from writers. However, such models lack long-range semantic coherence, limiting their usefulness for longform creative writing. We address this limitation by applying language models hierarchically, in a system we call Dramatron. By building structural context via prompt chaining, Dramatron can generate coherent scripts and screenplays complete with title, characters, story beats, location descriptions, and dialogue. We illustrate Dramatron's usefulness as an interactive co-creative system with a user study of 15 theatre and film industry professionals. Participants co-wrote theatre scripts and screenplays with Dramatron and engaged in open-ended interviews. We report reflections both from our interviewees and from independent reviewers who critiqued performances of several of the scripts to illustrate how both Dramatron and hierarchical text generation could be useful for human-machine co-creativity. Finally, we discuss the suitability of Dramatron for co-creativity, ethical considerations - including plagiarism and bias - and participatory models for the design and deployment of such tools. © 2023 Owner/Author.
KW  - co-creativity
KW  - computational creativity
KW  - human-computer interaction
KW  - improvisation
KW  - natural language evaluation
KW  - natural language generation
KW  - theatre
KW  - Artificial intelligence
KW  - Computational linguistics
KW  - Natural language processing systems
KW  - Semantics
KW  - Theaters
KW  - Co-creativity
KW  - Computational creativities
KW  - Improvization
KW  - Industry professionals
KW  - Language evaluations
KW  - Language model
KW  - Model evaluation
KW  - Natural language evaluation
KW  - Natural language generation
KW  - Natural languages
KW  - Human computer interaction
PB  - Association for Computing Machinery
SN  - 978-145039421-5 (ISBN)
LA  - English
J2  - Conf Hum Fact Comput Syst Proc
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 13; Conference name: 2023 CHI Conference on Human Factors in Computing Systems, CHI 2023; Conference date: 23 April 2023 through 28 April 2023; Conference code: 188036
ER  -

TY  - JOUR
AU  - Naidu, K.
AU  - Sevnarayan, K.
TI  - ChatGPT: An ever-increasing encroachment of artificial intelligence in online assessment in distance education
PY  - 2023
T2  - Online Journal of Communication and Media Technologies
VL  - 13
IS  - 3
C7  - e202336
DO  - 10.30935/ojcmt/13291
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85161997409&doi=10.30935%2fojcmt%2f13291&partnerID=40&md5=e142e098124e6ae79dfce6267bd42910
AD  - Department of Curriculum and Instructional Studies, University of South Africa, Pretoria, South Africa
AD  - Department of English Studies, University of South Africa, Pretoria, South Africa
AB  - The use of artificial intelligence (AI) in education is becoming increasingly prevalent, and its encroachment and impact on online education and assessment is a topic of interest to researchers and lecturers. ChatGPT is one such AI model that has been trained on a large corpus of text data to generate human-like responses to questions and prompts. Using the theory of disruptive innovation as a foundation for our argument, this conceptual article explores the potential and possible disruption of ChatGPT in online assessment. This article also considers the ethical and pedagogical implications of using ChatGPT, particularly in relation to online assessment in distance education. While the use of AI in online assessment presents a myriad of limitations and possibilities, it is crucial to approach its use with caution and consider the ethical implications of academic integrity for online assessment. This article aims to contribute to the ongoing discussion and debate around the use of AI in online higher education and assessment, highlighting the need for continued research and critical evaluation of its impact. © 2023 by authors.
KW  - artificial intelligence
KW  - ChatGPT
KW  - higher education institutions
KW  - online assessment
KW  - open distance and e-learning
PB  - Bastas
SN  - 19863497 (ISSN)
LA  - English
J2  - Online J. Commun. Media Technol.
M3  - Article
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 4; Correspondence Address: K. Naidu; Department of Curriculum and Instructional Studies, University of South Africa, Pretoria, South Africa; email: naiduk1@unisa.ac.za
ER  -

TY  - JOUR
AU  - Frank, M.C.
TI  - Baby steps in evaluating the capacities of large language models
PY  - 2023
T2  - Nature Reviews Psychology
VL  - 2
IS  - 8
SP  - 451
EP  - 452
DO  - 10.1038/s44159-023-00211-x
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85162995737&doi=10.1038%2fs44159-023-00211-x&partnerID=40&md5=633a3dfe502e09c5355795cf0d36e739
AD  - Department of Psychology, Stanford University, Stanford, CA, United States
PB  - Nature Publishing Group
SN  - 27310574 (ISSN)
LA  - English
J2  - Nat. Rev. Psychol.
M3  - Note
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 5; Correspondence Address: M.C. Frank; Department of Psychology, Stanford University, Stanford, United States; email: mcfrank@stanford.edu
ER  -

TY  - JOUR
AU  - Dubin, J.A.
AU  - Bains, S.S.
AU  - Hameed, D.
AU  - Chen, Z.
AU  - Nace, J.
AU  - Mont, M.A.
AU  - Delanois, R.E.
TI  - Letter to the Editor “Assessing ChatGPT's Potential: A Critical Analysis and Future Directions in Total Joint Arthroplasty”
PY  - 2023
T2  - Journal of Arthroplasty
VL  - 38
IS  - 9
SP  - e21
DO  - 10.1016/j.arth.2023.05.059
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85167395078&doi=10.1016%2fj.arth.2023.05.059&partnerID=40&md5=495f750cf172c6f02ecff9d6e947843f
AD  - LifeBridge Health, Sinai Hospital of Baltimore, Rubin Institute for Advanced Orthopedics, Baltimore, MD, United States
KW  - Arthroplasty
KW  - Artificial Intelligence
KW  - Humans
KW  - ChatGPT
KW  - data quality
KW  - gold standard
KW  - human
KW  - information seeking
KW  - information source
KW  - Internet
KW  - Letter
KW  - medical information
KW  - orthopedics
KW  - rehabilitation care
KW  - search engine
KW  - symptom
KW  - total arthroplasty
KW  - United States
KW  - arthroplasty
KW  - artificial intelligence
PB  - Elsevier B.V.
SN  - 08835403 (ISSN)
C2  - 37573084
LA  - English
J2  - J. Arthroplasty
M3  - Letter
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 0; CODEN: JOARE
ER  -

TY  - JOUR
AU  - Ray, P.P.
AU  - Majumder, P.
TI  - Assessing the Accuracy of Responses by the Language Model ChatGPT to Questions Regarding Bariatric Surgery: a Critical Appraisal
PY  - 2023
T2  - Obesity Surgery
VL  - 33
IS  - 8
SP  - 2588
EP  - 2589
DO  - 10.1007/s11695-023-06664-6
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85161615833&doi=10.1007%2fs11695-023-06664-6&partnerID=40&md5=b80eac9075480d8147cbf75d7d8a5af1
AD  - Sikkim University, Gangtok, India
AD  - Maulana Abul Kalam Azad University of Technology, Kolkata, India
KW  - Bariatric Surgery
KW  - Humans
KW  - Obesity, Morbid
KW  - bariatric surgery
KW  - disruptive technology
KW  - health care
KW  - health care personnel
KW  - health care system
KW  - human
KW  - language
KW  - Letter
KW  - patient coding
KW  - patient safety
KW  - quality of life
KW  - reproducibility
KW  - support group
KW  - treatment outcome
KW  - morbid obesity
PB  - Springer
SN  - 09608923 (ISSN)
C2  - 37301782
LA  - English
J2  - Obes. Surg.
M3  - Letter
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 2; Correspondence Address: P.P. Ray; Sikkim University, Gangtok, India; email: ppray@cus.ac.in; CODEN: OBSUE
ER  -

TY  - JOUR
AU  - Kao, H.-J.
AU  - Chien, T.-W.
AU  - Wang, W.-C.
AU  - Chou, W.
AU  - Chow, J.C.
TI  - Assessing ChatGPT's capacity for clinical decision support in pediatrics: A comparative study with pediatricians using KIDMAP of Rasch analysis
PY  - 2023
T2  - Medicine (United States)
VL  - 102
IS  - 25
SP  - E34068
DO  - 10.1097/MD.0000000000034068
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85162801732&doi=10.1097%2fMD.0000000000034068&partnerID=40&md5=08ad9198c9a85c2e6757550f94fbd661
AD  - Department of Internal Medicine, Chi Mei Medical Center, Chiali, Taiwan
AD  - Department of Medical Research, Chi-Mei Medical Center, Tainan, Taiwan
AD  - The Education University of Hong Kong, Hong Kong, Hong Kong
AD  - Department of Physical Medicine and Rehabilitation, Chi Mei Medical Center, Tainan, Taiwan
AD  - Department of Physical Medicine and Rehabilitation, Chung San Medical University Hospital, Taichung, Taiwan
AD  - Department of Pediatrics, Chi Mei Medical Center, Tainan, Taiwan
AD  - Department of Pediatrics, School of Medicine, College of Medicine, Taipei Medical University, Taipei, Taiwan
AB  - Background: The application of large language models in clinical decision support (CDS) is an area that warrants further investigation. ChatGPT, a prominent large language models developed by OpenAI, has shown promising performance across various domains. However, there is limited research evaluating its use specifically in pediatric clinical decision-making. This study aimed to assess ChatGPT's potential as a CDS tool in pediatrics by evCDSaluating its performance on 8 common clinical symptom prompts. Study objectives were to answer the 2 research questions: the ChatGPT's overall grade in a range from A (high) to E (low) compared to a normal sample and the difference in assessment of ChatGPT between 2 pediatricians. Methods: We compared ChatGPT's responses to 8 items related to clinical symptoms commonly encountered by pediatricians. Two pediatricians independently assessed the answers provided by ChatGPT in an open-ended format. The scoring system ranged from 0 to 100, which was then transformed into 5 ordinal categories. We simulated 300 virtual students with a normal distribution to provide scores on items based on Rasch rating scale model and their difficulties in a range between -2 to 2.5 logits. Two visual presentations (Wright map and KIDMAP) were generated to answer the 2 research questions outlined in the objectives of the study. Results: The 2 pediatricians' assessments indicated that ChatGPT's overall performance corresponded to a grade of C in a range from A to E, with average scores of -0.89 logits and 0.90 logits (=log odds), respectively. The assessments revealed a significant difference in performance between the 2 pediatricians (P <.05), with scores of -0.89 (SE = 0.37) and 0.90 (SE = 0.41) in log odds units (logits in Rasch analysis). Conclusion: This study demonstrates the feasibility of utilizing ChatGPT as a CDS tool for patients presenting with common pediatric symptoms. The findings suggest that ChatGPT has the potential to enhance clinical workflow and aid in responsible clinical decision-making. Further exploration and refinement of ChatGPT's capabilities in pediatric care can potentially contribute to improved healthcare outcomes and patient management.  © 2023 Wolters Kluwer Health, Inc. All rights reserved.
KW  - artificial intelligence
KW  - ChatGPT
KW  - KIDMAP
KW  - logit
KW  - pediatrics
KW  - Rasch analysis
KW  - Wright Map
KW  - Child
KW  - Decision Support Systems, Clinical
KW  - Delivery of Health Care
KW  - Humans
KW  - Pediatricians
KW  - Pediatrics
KW  - Software
KW  - artificial intelligence
KW  - child
KW  - clinical decision making
KW  - comparative study
KW  - controlled study
KW  - decision support system
KW  - feasibility study
KW  - female
KW  - human
KW  - major clinical study
KW  - male
KW  - normal distribution
KW  - outcome assessment
KW  - patient care
KW  - pediatrician
KW  - pediatrics
KW  - Rasch analysis
KW  - review
KW  - scoring system
KW  - simulation
KW  - workflow
KW  - clinical decision support system
KW  - health care delivery
KW  - pediatrician
KW  - software
PB  - Lippincott Williams and Wilkins
SN  - 00257974 (ISSN)
C2  - 37352054
LA  - English
J2  - Medicine
M3  - Review
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 3; Correspondence Address: J.C. Chow; Chi-Mei Medical Center, Tainan, 901 Chung Hwa Road, Yung Kung Dist., 710, Taiwan; email: jcchow2@yahoo.com.tw; CODEN: MEDIA
ER  -

TY  - JOUR
AU  - Hofert, M.
TI  - Assessing ChatGPT’s Proficiency in Quantitative Risk Management
PY  - 2023
T2  - Risks
VL  - 11
IS  - 9
C7  - 166
DO  - 10.3390/risks11090166
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85172263185&doi=10.3390%2frisks11090166&partnerID=40&md5=91ca3729c3126f079bfe6ceee3e834ca
AD  - Department of Statistics and Actuarial Science, The University of Hong Kong, Hong Kong
AB  - The purpose and novelty of this article is to investigate the extent to which artificial intelligence chatbot ChatGPT can grasp concepts from quantitative risk management. To this end, we enter a scholarly discussion with ChatGPT in the form of questions and answers, and analyze the responses. The questions are classics from undergraduate and graduate courses on quantitative risk management, and address risk in general, risk measures, time series, extremes and dependence. As a result, the non-technical aspects of risk (such as explanations of various types of financial risk, the driving factors underlying the financial crisis of 2007 to 2009, or a basic introduction to the Basel Framework) are well understood by ChatGPT. More technical aspects (such as mathematical facts), however, are often inaccurate or wrong, partly in rather subtle ways not obvious without expert knowledge, which we point out. The article concludes by providing guidance on the types of applications for which consulting ChatGPT can be useful in order to enhance one’s own knowledge of quantitative risk management (e.g., using ChatGPT as an educational tool to test one’s own understanding of an already grasped concept, or using ChatGPT as a practical tool for identifying risks just not on one’s own radar), and points out those applications for which the current version of ChatGPT should not be invoked (e.g., for learning mathematical concepts, or for learning entirely new concepts for which one has no basis of comparison to assess ChatGPT’s capabilities). © 2023 by the author.
KW  - ChatGPT
KW  - dependence
KW  - extremes
KW  - quantitative risk management
KW  - risk
KW  - risk measures
KW  - time series
PB  - Multidisciplinary Digital Publishing Institute (MDPI)
SN  - 22279091 (ISSN)
LA  - English
J2  - Risks
M3  - Article
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 0; Correspondence Address: M. Hofert; Department of Statistics and Actuarial Science, The University of Hong Kong, Hong Kong; email: mhofert@hku.hk
ER  -

TY  - JOUR
AU  - Deebel, N.A.
AU  - Terlecki, R.
TI  - ChatGPT Performance on the American Urological Association Self-assessment Study Program and the Potential Influence of Artificial Intelligence in Urologic Training
PY  - 2023
T2  - Urology
VL  - 177
SP  - 29
EP  - 33
DO  - 10.1016/j.urology.2023.05.010
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85162267516&doi=10.1016%2fj.urology.2023.05.010&partnerID=40&md5=8bf2ccadde5563ce5956868f2ac88a63
AD  - Department of Urology, Wake Forest University School of Medicine, Winston-Salem, NC, United States
AB  - Objective: To assess chat generative pre-trained transformer's (ChatGPT) performance on the American Urological Association Self-Assessment Study Program (AUA SASP) and stratify performance by question stem complexity. Methods: Questions from the 2021-2022 AUA SASP program were administered to ChatGPT version 3 (ChatGPT-3). Questions were administered to the model utilizing a standardized prompt. The answer choice selected by ChatGPT was then used to answer the question stem in the AUA SASP program. ChatGPT was then prompted to assign a question stem order (first, second, third) to each question. The percentage of correctly answered questions was determined for each order level. All responses provided by ChatGPT were qualitatively assessed for appropriate rationale. Results: A total of 268 questions were administered to ChatGPT. ChatGPT performed better on 2021 compared to the 2022 AUA SASP question set, answering 42.3% versus 30.0% of questions correctly (P <.05). Hundred percent of answer explanations provided appropriate, relevant rationale regardless of whether the answer was correct. Further stratification included assessment by question order level. ChatGPT performed progressively better on the 2021 question set with decreasing order levels, with first-order questions reaching 53.8% (n = 14). However, differences in proportions did not reach statistical significance (P >.05). Conclusion: ChatGPT answered many high-level questions correctly and provided a reasonable rationale for each answer choice. While ChatGPT was unable to answer numerous first-order questions, future language processing model learning may lead to the optimization of its fund of knowledge. This may lead to the utilization of artificial intelligence like ChatGPT as an educational tool for urology trainees and professors. © 2023 Elsevier Inc.
KW  - Artificial Intelligence
KW  - Educational Status
KW  - Humans
KW  - Self-Assessment
KW  - Urologic Diseases
KW  - Urology
KW  - article
KW  - artificial intelligence
KW  - clinical article
KW  - controlled study
KW  - human
KW  - language processing
KW  - learning
KW  - self evaluation
KW  - statistical significance
KW  - urology
KW  - artificial intelligence
KW  - educational status
KW  - self evaluation
KW  - urinary tract disease
KW  - urology
PB  - Elsevier Inc.
SN  - 00904295 (ISSN)
C2  - 37209880
LA  - English
J2  - Urology
M3  - Article
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 9; Correspondence Address: N.A. Deebel; Department of Urology, Wake Forest University School of Medicine, Winston-Salem, 1 Medical Center Blvd, 27157, United States; email: ndeebel@wakehealth.edu; CODEN: URGYA
ER  -

TY  - JOUR
AU  - Sun, Z.
AU  - Ong, H.
AU  - Kennedy, P.
AU  - Tang, L.
AU  - Chen, S.
AU  - Elias, J.
AU  - Lucas, E.
AU  - Shih, G.
AU  - Peng, Y.
TI  - Evaluating GPT-4 on Impressions Generation in Radiology Reports
PY  - 2023
T2  - Radiology
VL  - 307
IS  - 5
C7  - e231259
DO  - 10.1148/radiol.231259
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85164211574&doi=10.1148%2fradiol.231259&partnerID=40&md5=468557f98c345283877ecee0796897c8
AD  - The Departments of Population Health Sciences, Weill Cornell Medicine, 425 E 61st St, Suite 301, New York, 10065, NY, United States
AD  - Radiology, Weill Cornell Medicine, 425 E 61st St, Suite 301, New York, 10065, NY, United States
AD  - Primary Care, Weill Cornell Medicine, 425 E 61st St, Suite 301, New York, 10065, NY, United States
AD  - School of Information, The University of Texas at Austin, Austin, TX, United States
AD  - Comprehensive Weight Control Center, New York–Presbyterian/ Weill Cornell Medical Center, New York, NY, United States
KW  - Humans
KW  - Radiology
KW  - Article
KW  - evidence based practice
KW  - human
KW  - information processing
KW  - Likert scale
KW  - radiology
KW  - training
PB  - Radiological Society of North America Inc.
SN  - 00338419 (ISSN)
C2  - 37367439
LA  - English
J2  - Radiology
M3  - Article
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 11; Correspondence Address: Y. Peng; The Departments of Population Health Sciences, Weill Cornell Medicine, New York, 425 E 61st St, Suite 301, 10065, United States; email: yip4002@med.cornell.edu; CODEN: RADLA
ER  -

TY  - JOUR
AU  - Dubin, J.A.
AU  - Bains, S.S.
AU  - Chen, Z.
AU  - Hameed, D.
AU  - Nace, J.
AU  - Mont, M.A.
AU  - Delanois, R.E.
TI  - Using a Google Web Search Analysis to Assess the Utility of ChatGPT in Total Joint Arthroplasty
PY  - 2023
T2  - Journal of Arthroplasty
VL  - 38
IS  - 7
SP  - 1195
EP  - 1202
DO  - 10.1016/j.arth.2023.04.007
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85153406853&doi=10.1016%2fj.arth.2023.04.007&partnerID=40&md5=06545a90b964f9dbbf4a5605c00f7378
AD  - LifeBridge Health, Sinai Hospital of Baltimore, Rubin Institute for Advanced Orthopedics, Baltimore, Maryland, United States
AB  - Background: Rapid technological advancements have laid the foundations for the use of artificial intelligence in medicine. The promise of machine learning (ML) lies in its potential ability to improve treatment decision making, predict adverse outcomes, and streamline the management of perioperative healthcare. In an increasing consumer-focused health care model, unprecedented access to information may extend to patients using ChatGPT to gain insight into medical questions. The main objective of our study was to replicate a patient's internet search in order to assess the appropriateness of ChatGPT, a novel machine learning tool released in 2022 that provides dialogue responses to queries, in comparison to Google Web Search, the most widely used search engine in the United States today, as a resource for patients for online health information. For the 2 different search engines, we compared i) the most frequently asked questions (FAQs) associated with total knee arthroplasty (TKA) and total hip arthroplasty (THA) by question type and topic; ii) the answers to the most frequently asked questions; as well as iii) the FAQs yielding a numerical response. Methods: A Google web search was performed with the following search terms: “total knee replacement” and “total hip replacement.” These terms were individually entered and the first 10 FAQs were extracted along with the source of the associated website for each question. The following statements were inputted into ChatGPT: 1) “Perform a google search with the search term ‘total knee replacement’ and record the 10 most FAQs related to the search term” as well as 2) “Perform a google search with the search term ‘total hip replacement’ and record the 10 most FAQs related to the search term.” A Google web search was repeated with the same search terms to identify the first 10 FAQs that included a numerical response for both “total knee replacement” and “total hip replacement.” These questions were then inputted into ChatGPT and the questions and answers were recorded. Results: There were 5 of 20 (25%) questions that were similar when performing a Google web search and a search of ChatGPT for all search terms. Of the 20 questions asked for the Google Web Search, 13 of 20 were provided by commercial websites. For ChatGPT, 15 of 20 (75%) questions were answered by government websites, with the most frequent one being PubMed. In terms of numerical questions, 11 of 20 (55%) of the most FAQs provided different responses between a Google web search and ChatGPT. Conclusion: A comparison of the FAQs by a Google web search with attempted replication by ChatGPT revealed heterogenous questions and responses for open and discrete questions. ChatGPT should remain a trending use as a potential resource to patients that needs further corroboration until its ability to provide credible information is verified and concordant with the goals of the physician and the patient alike. © 2023
KW  - ChatGPT
KW  - google
KW  - total joint arthroplasty
KW  - utility
KW  - web search
KW  - Arthroplasty, Replacement, Hip
KW  - Arthroplasty, Replacement, Knee
KW  - Artificial Intelligence
KW  - Humans
KW  - Search Engine
KW  - adult
KW  - article
KW  - controlled study
KW  - government
KW  - human
KW  - Internet
KW  - machine learning
KW  - medical information
KW  - Medline
KW  - physician
KW  - search engine
KW  - total hip replacement
KW  - total knee arthroplasty
KW  - United States
KW  - artificial intelligence
KW  - hip replacement
KW  - knee replacement
PB  - Elsevier B.V.
SN  - 08835403 (ISSN)
C2  - 37040823
LA  - English
J2  - J. Arthroplasty
M3  - Article
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 17; CODEN: JOARE
ER  -

TY  - CONF
AU  - Ouh, E.L.
AU  - Gan, B.K.S.
AU  - Jin Shim, K.
AU  - Wlodkowski, S.
TI  - ChatGPT, Can You Generate Solutions for my Coding Exercises? An Evaluation on its Effectiveness in an undergraduate Java Programming Course.
PY  - 2023
T2  - Annual Conference on Innovation and Technology in Computer Science Education, ITiCSE
VL  - 1
SP  - 54
EP  - 60
DO  - 10.1145/3587102.3588794
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85166250328&doi=10.1145%2f3587102.3588794&partnerID=40&md5=e0007cc8e0e1dcabf9aae9f7a138e634
AD  - Singapore Management University, Singapore, Singapore
AB  - In this study, we assess the efficacy of employing the ChatGPT language model to generate solutions for coding exercises within an undergraduate Java programming course. ChatGPT, a large-scale, deep learning-driven natural language processing model, is capable of producing programming code based on textual input. Our evaluation involves analyzing ChatGPT-generated solutions for 80 diverse programming exercises and comparing them to the correct solutions. Our findings indicate that ChatGPT accurately generates Java programming solutions, which are characterized by high readability and well-structured organization. Additionally, the model can produce alternative, memory-efficient solutions. However, as a natural language processing model, ChatGPT struggles with coding exercises containing non-textual descriptions or class files, leading to invalid solutions. In conclusion, ChatGPT holds potential as a valuable tool for students seeking to overcome programming challenges and explore alternative approaches to solving coding problems. By understanding its limitations, educators can design coding exercises that minimize the potential for misuse as a cheating aid while maintaining their validity as assessment tools.  © 2023 ACM.
KW  - computer science education
KW  - Java
KW  - object-oriented
KW  - programming
KW  - Codes (symbols)
KW  - Deep learning
KW  - Education computing
KW  - Engineering education
KW  - Natural language processing systems
KW  - Object oriented programming
KW  - Students
KW  - Computer Science Education
KW  - Java
KW  - Java programming
KW  - Language model
KW  - Language processing
KW  - Natural languages
KW  - Object oriented
KW  - Processing model
KW  - Programming
KW  - Programming course
KW  - Java programming language
PB  - Association for Computing Machinery
SN  - 1942647X (ISSN); 979-840070138-2 (ISBN)
LA  - English
J2  - Annu. Conf. Innov. Technol. Comput. Sci. Educ. ITiCSE
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 3; Conference name: 28th Annual Conference on Innovation and Technology in Computer Science Education, ITiCSE 2023; Conference date: 8 July 2023 through 12 July 2023; Conference code: 190016
ER  -

TY  - JOUR
AU  - Krittanawong, C.
AU  - Virk, H.U.H.
AU  - Kaplin, S.L.
AU  - Wang, Z.
AU  - Sharma, S.
AU  - Jneid, H.
TI  - Assessing the Potential of ChatGPT for Patient Education in Cardiac Catheterization Care
PY  - 2023
T2  - JACC: Cardiovascular Interventions
VL  - 16
IS  - 12
SP  - 1551
EP  - 1552
DO  - 10.1016/j.jcin.2023.04.042
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85162136669&doi=10.1016%2fj.jcin.2023.04.042&partnerID=40&md5=71dd38507ec22ff07468d7fc804e0312
KW  - Cardiac Catheterization
KW  - Humans
KW  - Patient Education as Topic
KW  - Treatment Outcome
KW  - artificial intelligence
KW  - cardiac patient
KW  - heart catheterization
KW  - human
KW  - Letter
KW  - patient care
KW  - patient education
KW  - percutaneous transluminal angioplasty
KW  - treatment outcome
PB  - Elsevier Inc.
SN  - 19368798 (ISSN)
C2  - 37380244
LA  - English
J2  - JACC Cardiovasc. Interventions
M3  - Letter
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 0; Correspondence Address: C. Krittanawong; NYU School of Medicine, Cardiology Division, Section of Cardiology, New York, 550 First Avenue, 10016, United States; email: chayakrit.krittanawong@nyulangone.org
ER  -

TY  - JOUR
AU  - You, Y.
AU  - Shao, K.
AU  - Yi, Z.
TI  - Dynamic Heat Dissipation Model of Distributed Parameters for Oil-Directed and Air-Forced Traction Transformers and Its Experimental Validation
PY  - 2023
T2  - Entropy
VL  - 25
IS  - 3
C7  - 457
DO  - 10.3390/e25030457
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85151661742&doi=10.3390%2fe25030457&partnerID=40&md5=b40991808f0ec9daf37bc5c3ffbd8bfe
AD  - State Key Lab. of Refractories and Metallurgy, Wuhan University of Science and Technology, Wuhan, 430081, China
AD  - International Research Institute for Steel Technology, Wuhan University of Science and Technology, Wuhan, 430081, China
AB  - A traction transformer with narrow oil channels is usually cooled with the ODAF or “Oil Directed Air Forced” method, where its temperature greatly depends on the Joule heat of windings, the conjugate heat transfer in the transformer, and the secondary heat release via oil cooler, together with the oil flowrate generated by oil pump. Neither the thermal–electric analogy nor the CFD simulation approach is qualified to predict the temporal and spatial temperature variations in this type of transformer. In the current work, the distributed parameter models are built for traction transformers and oil coolers with the assumption of a one-dimensional temperature field in the oil flow direction, respectively. Then, the two models are combined with the lumped parameter ones of oil pumps and pipes via the flow rate, temperature and pressure continuities at their interfaces, resulting in the derivation of the dynamic heat dissipation model of oil-directed and air-forced traction transformers. Additionally, an efficient algorithm is proposed for its numerical solution, and the temperature rise experiment is performed for model validation. Finally, the fundamental of dynamic heat dissipation in traction transformers is investigated with the current numerical model and the effects of ambient temperature are studied. © 2023 by the authors.
KW  - dynamic heat dissipation
KW  - modeling
KW  - temperature rise experiment
KW  - traction transformer
PB  - MDPI
SN  - 10994300 (ISSN)
LA  - English
J2  - Entropy
M3  - Article
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 1; Correspondence Address: Y. You; State Key Lab. of Refractories and Metallurgy, Wuhan University of Science and Technology, Wuhan, 430081, China; email: youyonghua@wust.edu.cn
ER  -

TY  - CONF
AU  - Savelka, J.
AU  - Agarwal, A.
AU  - Bogart, C.
AU  - Song, Y.
AU  - Sakr, M.
TI  - Can Generative Pre-trained Transformers (GPT) Pass Assessments in Higher Education Programming Courses?
PY  - 2023
T2  - Annual Conference on Innovation and Technology in Computer Science Education, ITiCSE
VL  - 1
SP  - 117
EP  - 123
DO  - 10.1145/3587102.3588792
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85150820114&doi=10.1145%2f3587102.3588792&partnerID=40&md5=6b69f9bf2fc63c387a45ba81e7612f8e
AD  - Carnegie Mellon University, Pittsburgh, PA, United States
AB  - We evaluated the capability of generative pre-trained transformers (GPT), to pass assessments in introductory and intermediate Python programming courses at the postsecondary level. Discussions of potential uses (e.g., exercise generation, code explanation) and misuses (e.g., cheating) of this emerging technology in programming education have intensified, but to date there has not been a rigorous analysis of the models' capabilities in the realistic context of a full-fledged programming course with diverse set of assessment instruments. We evaluated GPT on three Python courses that employ assessments ranging from simple multiple-choice questions (no code involved) to complex programming projects with code bases distributed into multiple files (599 exercises overall). Further, we studied if and how successfully GPT models leverage feedback provided by an auto-grader. We found that the current models are not capable of passing the full spectrum of assessments typically involved in a Python programming course (<70% on even entry-level modules). Yet, it is clear that a straightforward application of these easily accessible models could enable a learner to obtain a non-trivial portion of the overall available score (>55%) in introductory and intermediate courses alike. While the models exhibit remarkable capabilities, including correcting solutions based on auto-grader's feedback, some limitations exist (e.g., poor handling of exercises requiring complex chains of reasoning steps). These findings can be leveraged by instructors wishing to adapt their assessments so that GPT becomes a valuable assistant for a learner as opposed to an end-to-end solution.  © 2023 Owner/Author.
KW  - AI code generation
KW  - alphacode
KW  - codex
KW  - generative pre-trained transformers
KW  - GitHub copilot
KW  - GPT
KW  - introductory and intermediate programming
KW  - programming knowledge assessment
KW  - python course
KW  - Education computing
KW  - Engineering education
KW  - High level languages
KW  - AI code generation
KW  - Alphacode
KW  - Codegeneration
KW  - Codex
KW  - Generative pre-trained transformer
KW  - Github copilot
KW  - Introductory and intermediate programming
KW  - Knowledge assessment
KW  - Programming knowledge
KW  - Programming knowledge assessment
KW  - Python course
KW  - Python
PB  - Association for Computing Machinery
SN  - 1942647X (ISSN); 979-840070138-2 (ISBN)
LA  - English
J2  - Annu. Conf. Innov. Technol. Comput. Sci. Educ. ITiCSE
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 6; Conference name: 28th Annual Conference on Innovation and Technology in Computer Science Education, ITiCSE 2023; Conference date: 8 July 2023 through 12 July 2023; Conference code: 190016
ER  -

TY  - JOUR
AU  - Haver, H.L.
AU  - Lin, C.T.
AU  - Sirajuddin, A.
AU  - Yi, P.H.
AU  - Jeudy, J.
TI  - Evaluating ChatGPT’s Accuracy in Lung Cancer Prevention and Screening Recommendations
PY  - 2023
T2  - Radiology: Cardiothoracic Imaging
VL  - 5
IS  - 4
DO  - 10.1148/ryct.230115
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85169325840&doi=10.1148%2fryct.230115&partnerID=40&md5=1c577cf1426ce592bbb806108094083c
AD  - University of Maryland Medical Intelligent Imaging (UM2ii) Center, Department of Diagnostic Radiology and Nuclear Medicine, University of Maryland School of Medicine, 22 S Greene St, Baltimore, 21201, MD, United States
AD  - The Russell H. Morgan Department of Radiology and Radiological Science, Johns Hopkins University School of Medicine, Baltimore, MD, United States
AD  - Radiology and Imaging Sciences Clinical Center, National Institutes of Health (NIH), Bethesda, MD, United States
AD  - Malone Center for Engineering in Healthcare, Whiting School of Engineering, Johns Hopkins University, Baltimore, MD, United States
AD  - Fischell Department of Bioengineering, A. James Clark School of Engineering, University of Maryland, College Park, College Park, MD, United States
KW  - accuracy
KW  - artificial intelligence
KW  - breast cancer
KW  - cancer prevention
KW  - cancer screening
KW  - cardiovascular disease
KW  - ChatGPT
KW  - clinical evaluation
KW  - consensus
KW  - human
KW  - large language model
KW  - Letter
KW  - lung cancer
KW  - lung imaging reporting and data system
KW  - medical information
KW  - misinformation
KW  - practice guideline
KW  - questionnaire
KW  - statistics
KW  - United States
PB  - Radiological Society of North America Inc.
SN  - 26386135 (ISSN)
LA  - English
J2  - Radiol. Cardiothorac. Imaging.
M3  - Letter
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 2; Correspondence Address: J. Jeudy; University of Maryland Medical Intelligent Imaging (UM2ii) Center, Department of Diagnostic Radiology and Nuclear Medicine, University of Maryland School of Medicine, Baltimore, 22 S Greene St, 21201, United States; email: jjeudy@som.umaryland.edu
ER  -

TY  - JOUR
AU  - Li, L.
AU  - Zhang, H.
AU  - Li, C.
AU  - You, H.
AU  - Cui, W.
TI  - Evaluation on ChatGPT for Chinese Language Understanding
PY  - 2023
T2  - Data Intelligence
VL  - 5
IS  - 4
SP  - 885
EP  - 903
DO  - 10.1162/dint_a_00232
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85179658086&doi=10.1162%2fdint_a_00232&partnerID=40&md5=20ac9dcd7e723bb50e9899eb8b92083e
AD  - School of Computer Science, Beijing Institute of Technology, Beijing, China
AB  - ChatGPT has attracted extension attention of academia and industry. This paper aims to evaluate ChatGPT in Chinese language understanding capability on 6 tasks using 11 datasets. Experiments indicate that ChatGPT achieved competitive results in sentiment analysis, summary, and reading comprehension in Chinese, while it is prone to factual errors in closed-book QA. Further, on two more difficult Chinese understanding tasks, that is, idiom fill-in-the-blank and cants understanding, we found that a simple chain-of-thought prompt can improve the accuracy of ChatGPT in complex reasoning. This paper further analyses the possible risks of using ChatGPT based on the results. Finally, we briefly describe the research and development progress of our ChatBIT. © 2023 MIT Press Journals. All rights reserved.
KW  - Artificial intelligence
KW  - ChatBIT
KW  - ChatGPT
KW  - Chinese Language Understanding
KW  - Language Model
KW  - Artificial intelligence
KW  - ChatBIT
KW  - ChatGPT
KW  - Chinese language
KW  - Chinese language understanding
KW  - Language model
KW  - Language understanding
KW  - Reading comprehension
KW  - Research and development
KW  - Sentiment analysis
KW  - Simple++
KW  - Sentiment analysis
PB  - MIT Press Journals
SN  - 20967004 (ISSN)
LA  - English
J2  - Data. Intell.
M3  - Article
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 1; Correspondence Address: H. Zhang; School of Computer Science, Beijing Institute of Technology, Beijing, China; email: kevinzhang@bit.edu.cn
ER  -

TY  - JOUR
AU  - Wei, X.
AU  - Wang, G.
AU  - Schmalz, B.
AU  - Hagan, D.F.T.
AU  - Duan, Z.
TI  - Evaluate Transformer model and Self-Attention mechanism in the Yangtze River basin runoff prediction
PY  - 2023
T2  - Journal of Hydrology: Regional Studies
VL  - 47
C7  - 101438
DO  - 10.1016/j.ejrh.2023.101438
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85163278876&doi=10.1016%2fj.ejrh.2023.101438&partnerID=40&md5=b31fa12937dac46d89e792d8f9a9eba6
AD  - Collaborative Innovation Center on Forecast and Evaluation of Meteorological Disasters, Nanjing University of Information Science and Technology (NUIST), Nanjing, 210044, China
AD  - Engineering Hydrology and Water Management, Technical University of Darmstadt, Darmstadt, 64287, Germany
AD  - Department of Physical Geography and Ecosystem Science, Lund University, Sölvegatan 12, Lund, 223 62, Sweden
AB  - Study region: In the Yangtze River basin of China. Study focus: We applied a recently popular deep learning (DL) algorithm, Transformer (TSF), and two commonly used DL methods, Long-Short-Term Memory (LSTM) and Gated Recurrent Unit (GRU), to evaluate the performance of TSF in predicting runoff in the Yangtze River basin. We also add the main structure of TSF, Self-Attention (SA), to the LSTM and GRU models, namely LSTM-SA and GRU-SA, to investigate whether the inclusion of the SA mechanism can improve the prediction capability. Seven climatic observations (mean temperature, maximum temperature, precipitation, etc.) are the input data in our study. The whole dataset was divided into training, validation and test datasets. In addition, we investigated the relationship between model performance and input time steps. New hydrological insights for the region: Our experimental results show that the GRU has the best performance with the fewest parameters while the TSF has the worst performance due to the lack of sufficient data. GRU and the LSTM models are better than TSF for runoff prediction when the training samples are limited (such as the model parameters being ten times larger than the samples). Furthermore, the SA mechanism improves the prediction accuracy when added to the LSTM and the GRU structures. Different input time steps (5 d, 10 d, 15 d, 20 d, 25 d and 30 d) are used to train the DL models with different prediction lengths to understand their relationship with model performance, showing that an appropriate input time step can significantly improve the model performance. © 2023 The Authors
KW  - GRU
KW  - LSTM
KW  - Runoff prediction
KW  - Self-Attention
KW  - Transformer
PB  - Elsevier B.V.
SN  - 22145818 (ISSN)
LA  - English
J2  - J. Hydrol. Reg. Stud.
M3  - Article
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 0; Correspondence Address: G. Wang; Collaborative Innovation Center on Forecast and Evaluation of Meteorological Disasters, Nanjing University of Information Science and Technology (NUIST), Nanjing, 210044, China; email: gwang@nuist.edu.cn
ER  -

TY  - JOUR
AU  - Jiang, S.-T.
AU  - Xu, Y.-Y.
AU  - Lu, X.
TI  - ChatGPT in Radiology: Evaluating Proficiencies, Addressing Shortcomings, and Proposing Integrative Approaches for the Future
PY  - 2023
T2  - Radiology
VL  - 308
IS  - 1
DO  - 10.1148/RADIOL.231335
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85164276307&doi=10.1148%2fRADIOL.231335&partnerID=40&md5=cc0c4d3f0458bd86608ab0f8f96bce55
AD  - Department of Liver Surgery, Peking Union Medical College Hospital, Chinese Academy of Medical Sciences, Peking Union Medical College, No. 1 Shuaifuyuan Wangfujing, Dongcheng District, Beijing, 100730, China
KW  - Humans
KW  - Radiography
KW  - Radiology
KW  - artificial intelligence
KW  - ChatGPT
KW  - cognition
KW  - data privacy
KW  - human
KW  - image analysis
KW  - Letter
KW  - medical ethics
KW  - radiologist
KW  - radiology
KW  - reasoning
KW  - training
KW  - radiography
PB  - Radiological Society of North America Inc.
SN  - 00338419 (ISSN)
C2  - 37432082
LA  - English
J2  - Radiology
M3  - Letter
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 3; Correspondence Address: X. Lu; Department of Liver Surgery, Peking Union Medical College Hospital, Chinese Academy of Medical Sciences, Peking Union Medical College, Beijing, No. 1 Shuaifuyuan Wangfujing, Dongcheng District, 100730, China; email: luxin@pumch.cn; CODEN: RADLA
ER  -

TY  - CONF
AU  - Morris, W.
AU  - Crossley, S.
AU  - Holmes, L.
AU  - Trumbore, A.
TI  - Using Transformer Language Models to Validate Peer-Assigned Essay Scores in Massive Open Online Courses (MOOCs)
PY  - 2023
T2  - ACM International Conference Proceeding Series
SP  - 315
EP  - 323
DO  - 10.1145/3576050.3576098
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85149334252&doi=10.1145%2f3576050.3576098&partnerID=40&md5=81e1c5214a0188ceae6d686480042c8f
AD  - Vanderbilt University, Nashville, TN, United States
AD  - University of Virginia, United States
AB  - Massive Open Online Courses (MOOCs) such as those offered by Coursera are popular ways for adults to gain important skills, advance their careers, and pursue their interests. Within these courses, students are often required to compose, submit, and peer review written essays, providing a valuable pedagogical experience for the student and a wealth of natural language data for the educational researcher. However, the scores provided by peers do not always reflect the actual quality of the text, generating questions about the reliability and validity of the scores. This study evaluates methods to increase the reliability of MOOC peer-review ratings through a series of validation tests on peer-reviewed essays. Reliability of reviewers was based on correlations between text length and essay quality. Raters were pruned based on score variance and the lexical diversity observed in their comments to create sub-sets of raters. Each subset was then used as training data to finetune distilBERT large language models to automatically score essay quality as a measure of validation. The accuracy of each language model for each subset was evaluated. We find that training language models on data subsets produced by more reliable raters based on a combination of score variance and lexical diversity produce more accurate essay scoring models. The approach developed in this study should allow for enhanced reliability of peer-reviewed scoring in MOOCS affording greater credibility within the systems.  © 2023 ACM.
KW  - moocs
KW  - natural language processing
KW  - rater reliability
KW  - transformers
KW  - Computational linguistics
KW  - E-learning
KW  - Natural language processing systems
KW  - Quality control
KW  - Students
KW  - Language model
KW  - Language processing
KW  - Massive open online course
KW  - Moocs
KW  - Natural language processing
KW  - Natural languages
KW  - Peer review
KW  - Rater reliability
KW  - Reliability and validity
KW  - Transformer
KW  - Reliability
PB  - Association for Computing Machinery
SN  - 978-145039865-7 (ISBN)
LA  - English
J2  - ACM Int. Conf. Proc. Ser.
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 0; Conference name: 13th International Conference on Learning Analytics and Knowledge: Towards Trustworthy Learning Analytics, LAK 2023; Conference date: 13 March 2023 through 17 March 2023; Conference code: 186834
ER  -

TY  - JOUR
AU  - Klang, E.
AU  - Levy-Mendelovich, S.
TI  - Evaluation of OpenAI's large language model as a new tool for writing papers in the field of thrombosis and hemostasis
PY  - 2023
T2  - Journal of Thrombosis and Haemostasis
VL  - 21
IS  - 4
SP  - 1055
EP  - 1058
DO  - 10.1016/j.jtha.2023.01.011
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85150754580&doi=10.1016%2fj.jtha.2023.01.011&partnerID=40&md5=e2bd33f334b88fb1cc4f42b85b765018
AD  - Sami Sagol AI Hub, ARC, Sheba Medical Center, Ramat Gan, Israel
AD  - Sackler School of Medicine, Tel Aviv University, Tel Aviv, Israel
AD  - The Sheba Talpiot Medical Leadership Program, Sheba Medical Center, Ramat Gan, Israel
AD  - National Hemophilia Center, Sheba Medical Center, Ramat Gan, Israel
AD  - Amalia Biron Research Institute of Thrombosis and Hemostasis, Sheba Medical Center, Ramat Gan, Israel
KW  - Hemostasis
KW  - Humans
KW  - Language
KW  - Thrombosis
KW  - Writing
KW  - adeno associated virus vector
KW  - anticoagulant agent
KW  - nanoparticle
KW  - accuracy
KW  - artificial intelligence
KW  - gene therapy
KW  - hematology
KW  - hemostasis
KW  - human
KW  - knowledge
KW  - Letter
KW  - medical literature
KW  - task performance
KW  - thrombosis
KW  - language
KW  - thrombosis
KW  - writing
PB  - Elsevier B.V.
SN  - 15387933 (ISSN)
C2  - 36775769
LA  - English
J2  - J. Thromb. Haemost.
M3  - Letter
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 5; Correspondence Address: S. Levy-Mendelovich; National Hemophilia Center, Coagulation Unit, and Amalia Biron Research Institute of Thrombosis and Hemostasis, Sheba Medical Center, 2 Derech Sheba, Tel Hashomer, Ramat Gan, 52621, Israel; email: Sarina.Levy@sheba.health.gov.il; CODEN: JTHOA
ER  -

TY  - JOUR
AU  - Samaan, J.S.
AU  - Yeo, Y.H.
AU  - Rajeev, N.
AU  - Ng, W.H.
AU  - Srinivasan, N.
AU  - Samakar, K.
TI  - Reply to “Assessing the Accuracy of Responses by the Language Model ChatGPT to Questions Regarding Bariatric Surgery: a Critical Appraisal”
PY  - 2023
T2  - Obesity Surgery
VL  - 33
IS  - 8
SP  - 2590
EP  - 2591
DO  - 10.1007/s11695-023-06666-4
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85163067569&doi=10.1007%2fs11695-023-06666-4&partnerID=40&md5=b050a3fb0166c87e673c9187b7783dfd
AD  - Karsh Division of Gastroenterology and Hepatology, Cedars-Sinai Medical Center, 8700 Beverly Blvd., Los Angeles, 90048, CA, United States
AD  - Division of Upper GI and General Surgery, Department of Surgery, Keck School of Medicine of USC, Health Care Consultation Center, 1510 San Pablo St #514, Los Angeles, 90033, CA, United States
AD  - Bristol Medical School, University of Bristol, 5 Tyndall Ave, Bristol, BS8 1UD, United Kingdom
KW  - Bariatric Surgery
KW  - Humans
KW  - Obesity, Morbid
KW  - artificial intelligence
KW  - attitude to health
KW  - bariatric surgery
KW  - chatgpt
KW  - clinical assessment
KW  - clinical evaluation
KW  - clinical practice
KW  - electronic health record
KW  - health care
KW  - health care personnel
KW  - health care system
KW  - health literacy
KW  - human
KW  - information dissemination
KW  - Internet
KW  - language
KW  - Letter
KW  - medical ethics
KW  - medical expert
KW  - medical information
KW  - multidisciplinary team
KW  - outcome assessment
KW  - patient counseling
KW  - practice guideline
KW  - selection bias
KW  - social media
KW  - software
KW  - standardization
KW  - stratified sample
KW  - support group
KW  - morbid obesity
PB  - Springer
SN  - 09608923 (ISSN)
C2  - 37312008
LA  - English
J2  - Obes. Surg.
M3  - Letter
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 0; Correspondence Address: J.S. Samaan; Karsh Division of Gastroenterology and Hepatology, Cedars-Sinai Medical Center, Los Angeles, 8700 Beverly Blvd., 90048, United States; email: jamil.samaan@gmail.com; CODEN: OBSUE
ER  -

TY  - JOUR
AU  - Yeo, Y.H.
AU  - Samaan, J.S.
AU  - Ng, W.H.
TI  - Correspondence on Letter 1 regarding “Assessing the performance of ChatGPT in answering ques- tions regarding cirrhosis and hepatocellular carci- noma”
PY  - 2023
T2  - Clinical and Molecular Hepatology
VL  - 29
IS  - 3
SP  - 821
EP  - 822
DO  - 10.3350/cmh.2023.0183
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85167848792&doi=10.3350%2fcmh.2023.0183&partnerID=40&md5=093453a904cd4ae622444ef31bf488f0
AD  - Karsh Division of Gastroenterology and Hepatology, Department of Medicine, Cedars-Sinai Medical Center, Los Angeles, 90048, CA, United States
AD  - Bristol Medical School, University of Bristol, Bristol, United Kingdom
KW  - Artificial intelligence
KW  - Cancer
KW  - Health equity
KW  - Health literacy
KW  - Liver cirrhosis
KW  - artificial intelligence
KW  - ChatGPT
KW  - health literacy
KW  - Letter
KW  - lifestyle modification
KW  - liver cell carcinoma
KW  - liver cirrhosis
PB  - Korean Association for the Study of the Liver
SN  - 22872728 (ISSN)
C2  - 37254486
LA  - English
J2  - Clin. Mol. Hepatol.
M3  - Letter
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 0; Correspondence Address: Y.H. Yeo; Karsh Division of Gastroenterology and Hepatology, Department of Medicine, Cedars-Sinai Medical Center, Los Angeles, 90048, United States; email: Yeehui.yeo@cshs.org
ER  -

TY  - JOUR
AU  - Haruna-Cooper, L.
AU  - Rashid, M.A.
TI  - GPT-4: the future of artificial intelligence in medical school assessments
PY  - 2023
T2  - Journal of the Royal Society of Medicine
VL  - 116
IS  - 6
SP  - 218
EP  - 219
DO  - 10.1177/01410768231181251
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85164252454&doi=10.1177%2f01410768231181251&partnerID=40&md5=2819a7cfeb4a1e143a2ebaeb3f54a242
AD  - UCL Medical School, Faculty of Medical Sciences, University College London, London, WC1E 6BT, United Kingdom
KW  - Artificial Intelligence
KW  - Forecasting
KW  - Humans
KW  - Schools, Medical
KW  - artificial intelligence
KW  - medical education
KW  - medical school
KW  - Note
KW  - software
KW  - forecasting
KW  - human
PB  - SAGE Publications Ltd
SN  - 01410768 (ISSN)
C2  - 37318843
LA  - English
J2  - J. R. Soc. Med.
M3  - Note
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 2; Correspondence Address: L. Haruna-Cooper; UCL Medical School, Faculty of Medical Sciences, University College London, London, WC1E 6BT, United Kingdom; email: l.haruna@ucl.ac.uk; CODEN: JRSMD
ER  -

TY  - JOUR
AU  - Giannos, P.
TI  - Evaluating the limits of AI in medical specialisation: ChatGPT's performance on the UK Neurology Specialty Certificate Examination
PY  - 2023
T2  - BMJ Neurology Open
VL  - 5
IS  - 1
C7  - e000451
DO  - 10.1136/bmjno-2023-000451
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85164536952&doi=10.1136%2fbmjno-2023-000451&partnerID=40&md5=135b87823f784a54dd46bda512323a17
AD  - Department of Life Sciences, Imperial College London, London, United Kingdom
AD  - Society of Meta-Research and Biomedical Innovation, London, United Kingdom
AD  - Promotion of Emerging and Evaluative Research Society, London, United Kingdom
AB  - Background Large language models such as ChatGPT have demonstrated potential as innovative tools for medical education and practice, with studies showing their ability to perform at or near the passing threshold in general medical examinations and standardised admission tests. However, no studies have assessed their performance in the UK medical education context, particularly at a specialty level, and specifically in the field of neurology and neuroscience. Methods We evaluated the performance of ChatGPT in higher specialty training for neurology and neuroscience using 69 questions from the Pool - Specialty Certificate Examination (SCE) Neurology Web Questions bank. The dataset primarily focused on neurology (80%). The questions spanned subtopics such as symptoms and signs, diagnosis, interpretation and management with some questions addressing specific patient populations. The performance of ChatGPT 3.5 Legacy, ChatGPT 3.5 Default and ChatGPT-4 models was evaluated and compared. Results ChatGPT 3.5 Legacy and ChatGPT 3.5 Default displayed overall accuracies of 42% and 57%, respectively, falling short of the passing threshold of 58% for the 2022 SCE neurology examination. ChatGPT-4, on the other hand, achieved the highest accuracy of 64%, surpassing the passing threshold and outperforming its predecessors across disciplines and subtopics. Conclusions The advancements in ChatGPT-4's performance compared with its predecessors demonstrate the potential for artificial intelligence (AI) models in specialised medical education and practice. However, our findings also highlight the need for ongoing development and collaboration between AI developers and medical experts to ensure the models' relevance and reliability in the rapidly evolving field of medicine.  © Author(s) (or their employer(s)) 2023. Re-use permitted under CC BY-NC. No commercial re-use. See rights and permissions. Published by BMJ.
KW  - clinical neurology
KW  - health policy & practice
KW  - medicine
KW  - adult
KW  - article
KW  - artificial intelligence
KW  - health care policy
KW  - human
KW  - medical education
KW  - medical expert
KW  - neurology
KW  - neuroscience
KW  - reliability
KW  - specialization
PB  - BMJ Publishing Group
SN  - 26326140 (ISSN)
LA  - English
J2  - BMJ Neurol. Open
M3  - Article
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 8; Correspondence Address: P. Giannos; Department of Life Sciences, Imperial College London, London, United Kingdom; email: panagiotis.giannos19@imperial.ac.uk
ER  -

TY  - JOUR
AU  - Li, Z.
AU  - Liu, K.
AU  - Lin, M.
AU  - Xin, D.
AU  - Tang, H.
AU  - Wu, G.
TI  - A zero-sample state evaluation model for valve-side bushing of UHV converter transformer oriented to digital twin under attribute analysis
PY  - 2023
T2  - IET Generation, Transmission and Distribution
VL  - 17
IS  - 5
SP  - 1123
EP  - 1134
DO  - 10.1049/gtd2.12721
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85145371518&doi=10.1049%2fgtd2.12721&partnerID=40&md5=8f13f17102c02be684e7e78853a07696
AD  - School of Electrical Engineering, Southwest Jiaotong University, Chengdu, China
AD  - China Electric Power Research Institute, Beijing, China
AB  - The valve-side bushing of the UHV converter transformer is the key equipment in the DC transmission project, and its running state directly affects the security and stability of the power system. This paper analyses the attributes of the physical entities, uses the digital twins to establish the state feature set and proposes a zero-sample state evaluation algorithm for the valve-side bushing. First, the geometric, materials and electrical characteristics are analyzed, and the detailed components of carrier current are obtained by empirical mode decomposition. Then, COMSOL is used to establish digital twins, verify the validity of twins with axial heat distribution of bushing, and establish a state feature set with the extreme temperature inside and outside bushing. Finally, the fuzzy clustering algorithm is used to classify the state feature set, and the similarity is used as the index to realize the zero-sample state evaluation of the valve-side bushing. Through the demonstration and analysis of examples, the evaluation model solves the problems of difficulty in extracting the internal features, fewer fault samples, and training difficulty, which is conducive to improving the operation and maintenance management level of power transmission equipment. © 2022 The Authors. IET Generation, Transmission & Distribution published by John Wiley & Sons Ltd on behalf of The Institution of Engineering and Technology.
KW  - contact resistance
KW  - finite element analysis
KW  - HVDC power transmission
KW  - polymer insulators
KW  - SF6 insulation
KW  - state estimation
KW  - Bushings
KW  - Clustering algorithms
KW  - DC transformers
KW  - Electric power distribution
KW  - Fuzzy clustering
KW  - HVDC power transmission
KW  - Power transmission
KW  - SF6 insulation
KW  - Sulfur hexafluoride
KW  - UHV power transmission
KW  - Attribute analysis
KW  - Converter transformers
KW  - Evaluation models
KW  - Features sets
KW  - Finite element analyse
KW  - Key equipment
KW  - Polymer insulator
KW  - State evaluation
KW  - State feature
KW  - Transmission projects
KW  - Finite element method
PB  - John Wiley and Sons Inc
SN  - 17518687 (ISSN)
LA  - English
J2  - IET Gener. Transm. Distrib.
M3  - Article
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 2; Correspondence Address: K. Liu; School of Electrical Engineering, Southwest Jiaotong University, Chengdu, China; email: liukai@swjtu.edu.cn
ER  -

TY  - JOUR
AU  - Kung, J.E.
AU  - Marshall, C.
AU  - Gauthier, C.
AU  - Gonzalez, T.A.
AU  - Jackson, J.B.
TI  - Evaluating ChatGPT Performance on the Orthopaedic In-Training Examination
PY  - 2023
T2  - JBJS Open Access
VL  - 8
IS  - 3
C7  - e23.00056
DO  - 10.2106/JBJS.OA.23.00056
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85172701683&doi=10.2106%2fJBJS.OA.23.00056&partnerID=40&md5=6ad74fa7a07b5a7d84f5391af0768486
AD  - Department of Orthopedic Surgery, Prisma Health-Midlands University of South Carolina, Columbia, SC, United States
AD  - University of South Carolina, School of Medicine, Columbia, SC, United States
AB  - Background:Artificial intelligence (AI) holds potential in improving medical education and healthcare delivery. ChatGPT is a state-of-the-art natural language processing AI model which has shown impressive capabilities, scoring in the top percentiles on numerous standardized examinations, including the Uniform Bar Exam and Scholastic Aptitude Test. The goal of this study was to evaluate ChatGPT performance on the Orthopaedic In-Training Examination (OITE), an assessment of medical knowledge for orthopedic residents.Methods:OITE 2020, 2021, and 2022 questions without images were inputted into ChatGPT version 3.5 and version 4 (GPT-4) with zero prompting. The performance of ChatGPT was evaluated as a percentage of correct responses and compared with the national average of orthopedic surgery residents at each postgraduate year (PGY) level. ChatGPT was asked to provide a source for its answer, which was categorized as being a journal article, book, or website, and if the source could be verified. Impact factor for the journal cited was also recorded.Results:ChatGPT answered 196 of 360 answers correctly (54.3%), corresponding to a PGY-1 level. ChatGPT cited a verifiable source in 47.2% of questions, with an average median journal impact factor of 5.4. GPT-4 answered 265 of 360 questions correctly (73.6%), corresponding to the average performance of a PGY-5 and exceeding the corresponding passing score for the American Board of Orthopaedic Surgery Part I Examination of 67%. GPT-4 cited a verifiable source in 87.9% of questions, with an average median journal impact factor of 5.2.Conclusions:ChatGPT performed above the average PGY-1 level and GPT-4 performed better than the average PGY-5 level, showing major improvement. Further investigation is needed to determine how successive versions of ChatGPT would perform and how to optimize this technology to improve medical education.Clinical Relevance:AI has the potential to aid in medical education and healthcare delivery. © Lippincott Williams & Wilkins.
KW  - adult
KW  - artificial intelligence
KW  - ChatGPT
KW  - clinical significance
KW  - controlled study
KW  - female
KW  - health care delivery
KW  - human
KW  - human experiment
KW  - journal impact factor
KW  - male
KW  - medical education
KW  - orthopedic surgery
KW  - postgraduate student
KW  - resident
KW  - review
PB  - Lippincott Williams and Wilkins
SN  - 24727245 (ISSN)
LA  - English
J2  - JBJS Open Access
M3  - Review
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 2; Correspondence Address: J.E. Kung; Department of Orthopedic Surgery, Prisma Health-Midlands University of South Carolina, Columbia, United States; email: Justin.Kung@prismahealth.org
ER  -

TY  - JOUR
AU  - Shi, Y.
AU  - Wang, J.
AU  - Ren, P.
AU  - ValizadehAslani, T.
AU  - Zhang, Y.
AU  - Hu, M.
AU  - Liang, H.
TI  - Fine-tuning BERT for automatic ADME semantic labeling in FDA drug labeling to enhance product-specific guidance assessment
PY  - 2023
T2  - Journal of Biomedical Informatics
VL  - 138
C7  - 104285
DO  - 10.1016/j.jbi.2023.104285
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85147191657&doi=10.1016%2fj.jbi.2023.104285&partnerID=40&md5=80f103e02ad1bbadb88abe29a32735f9
AD  - College of Computing and Informatics, Drexel University, Philadelphia, PA, United States
AD  - Office of Research and Standards, Office of Generic Drugs, Center for Drug Evaluation and Research, Food and Drug Administration, Silver Spring, MD, United States
AD  - Department of Electrical and Computer Engineering, College of Engineering, Drexel University, Philadelphia, PA, United States
AD  - School of Biomedical Engineering, Science and Health Systems, Drexel University, Philadelphia, PA, United States
AB  - Product-specific guidances (PSGs) recommended by the United States Food and Drug Administration (FDA) are instrumental to promote and guide generic drug product development. To assess a PSG, the FDA assessor needs to take extensive time and effort to manually retrieve supportive drug information of absorption, distribution, metabolism, and excretion (ADME) from the reference listed drug labeling. In this work, we leveraged the state-of-the-art pre-trained language models to automatically label the ADME paragraphs in the pharmacokinetics section from the FDA-approved drug labeling to facilitate PSG assessment. We applied a transfer learning approach by fine-tuning the pre-trained Bidirectional Encoder Representations from Transformers (BERT) model to develop a novel application of ADME semantic labeling, which can automatically retrieve ADME paragraphs from drug labeling instead of manual work. We demonstrate that fine-tuning the pre-trained BERT model can outperform conventional machine learning techniques, achieving up to 12.5% absolute F1 improvement. To our knowledge, we were the first to successfully apply BERT to solve the ADME semantic labeling task. We further assessed the relative contribution of pre-training and fine-tuning to the overall performance of the BERT model in the ADME semantic labeling task using a series of analysis methods, such as attention similarity and layer-based ablations. Our analysis revealed that the information learned via fine-tuning is focused on task-specific knowledge in the top layers of the BERT, whereas the benefit from the pre-trained BERT model is from the bottom layers. © 2023 Elsevier Inc.
KW  - ADME
KW  - BERT
KW  - Drug Labeling
KW  - Natural Language Processing
KW  - Semantic Labeling
KW  - Transfer Learning
KW  - Drug Labeling
KW  - Knowledge
KW  - Language
KW  - Natural Language Processing
KW  - Semantics
KW  - United States
KW  - United States Food and Drug Administration
KW  - Learning algorithms
KW  - Learning systems
KW  - Natural language processing systems
KW  - Transfer learning
KW  - Absorption distribution metabolism and excretions
KW  - Bidirectional encoder representation from transformer
KW  - Drug labeling
KW  - Fine tuning
KW  - Language processing
KW  - Natural language processing
KW  - Natural languages
KW  - Semantic labeling
KW  - Transfer learning
KW  - Transformer modeling
KW  - Article
KW  - automation
KW  - Bidirectional Encoder Representations from Transformers
KW  - controlled study
KW  - drug absorption
KW  - drug distribution
KW  - drug excretion
KW  - drug information
KW  - drug labeling
KW  - drug metabolism
KW  - Food and Drug Administration
KW  - machine learning
KW  - model
KW  - natural language processing
KW  - pharmacokinetics
KW  - product development
KW  - semantics
KW  - transfer of learning
KW  - Food and Drug Administration
KW  - knowledge
KW  - language
KW  - semantics
KW  - United States
KW  - Semantics
PB  - Academic Press Inc.
SN  - 15320464 (ISSN)
C2  - 36632860
LA  - English
J2  - J. Biomed. Informatics
M3  - Article
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 6; Correspondence Address: H. Liang; School of Biomedical Engineering, Science and Health Systems, Drexel University, Philadelphia, United States; email: hualou.liang@drexel.edu; CODEN: JBIOB
ER  -

TY  - JOUR
AU  - Pan, R.
AU  - García-Díaz, J.A.
AU  - Vivancos-Vicente, P.J.
AU  - Valencia-García, R.
TI  - Evaluation of transformer-based models for punctuation and capitalization restoration in Catalan and Galician
ST  - Evaluación de modelos basados en Transformers para el sistema de recuperación de puntuación y mayúsculas en Catalán y Gallego
PY  - 2023
T2  - Procesamiento del Lenguaje Natural
IS  - 70
SP  - 27
EP  - 38
DO  - 10.26342/2023-70-2
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85153055338&doi=10.26342%2f2023-70-2&partnerID=40&md5=bacfe194c069a9fe0678893708ef25b1
AD  - Facultad de Informática, Universidad de Murcia, Campus de Espinardo, Murcia, 30100, Spain
AD  - VÓCALI Sistemas Inteligentes S.L., Parque Científico de Murcia, Carretera de Madrid km 388. Complejo de Espinardo, Murcia, 30100, Spain
AB  - In recent years, the performance of Automatic Speech Recognition systems (ASR) has increased considerably due to new deep learning methods. However, the raw output of an ASR system consists of a sequence of words without capital letters and punctuation marks. Therefore, a capitalization and punctuation restoration system are one of the most important post-processes of ASR to improve readability and to enable the subsequent use of these results in other NLP models. Most models focus solely on English punctuation resolution, and recently new models of Spanish punctuation restoration have emerged. However, none focus on capitalization and punctuation restoration in Galician and Catalan. In this sense, we propose a system for capitalization and punctuation restoration based on Transformers models for Catalan and Galician. Both models perform very well, with an overall performance of 90.2% for Galician and 90.86% for Catalan, and have the ability to identify proper names, country names, and organizations for uppercase restoration. ©2023 Sociedad Española para el Procesamiento del Lenguaje Natural.
KW  - Automatic Speech Recognition
KW  - Capitalization Restoration
KW  - Catalan
KW  - Galician
KW  - Punctuation Restoration
KW  - Transformers
PB  - Sociedad Espanola para el Procesamiento del Lenguaje Natural
SN  - 11355948 (ISSN)
LA  - English
J2  - Proces. Lenguaje Nat.
M3  - Article
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 2
ER  -

TY  - JOUR
AU  - Huynh, L.M.
AU  - Bonebrake, B.T.
AU  - Schultis, K.
AU  - Quach, A.
AU  - Deibert, C.M.
TI  - New Artificial Intelligence ChatGPT Performs Poorly on the 2022 Self-assessment Study Program for Urology
PY  - 2023
T2  - Urology Practice
VL  - 10
IS  - 4
SP  - 409
EP  - 415
DO  - 10.1097/UPJ.0000000000000406
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85164910477&doi=10.1097%2fUPJ.0000000000000406&partnerID=40&md5=f3d885c6c1437ef59c2853948a74d95a
AD  - University of Nebraska Medical Center, Omaha, NE, United States
AD  - College of Medicine, University of Nebraska Medical Center, Omaha, NE, United States
AD  - Division of Urology, University of Nebraska Medical Center, Omaha, NE, United States
AB  - Introduction:Large language models have demonstrated impressive capabilities, but application to medicine remains unclear. We seek to evaluate the use of ChatGPT on the American Urological Association Self-assessment Study Program as an educational adjunct for urology trainees and practicing physicians.Methods:One hundred fifty questions from the 2022 Self-assessment Study Program exam were screened, and those containing visual assets (n=15) were removed. The remaining items were encoded as open ended or multiple choice. ChatGPT's output was coded as correct, incorrect, or indeterminate; if indeterminate, responses were regenerated up to 2 times. Concordance, quality, and accuracy were ascertained by 3 independent researchers and reviewed by 2 physician adjudicators. A new session was started for each entry to avoid crossover learning.Results:ChatGPT was correct on 36/135 (26.7%) open-ended and 38/135 (28.2%) multiple-choice questions. Indeterminate responses were generated in 40 (29.6%) and 4 (3.0%), respectively. Of the correct responses, 24/36 (66.7%) and 36/38 (94.7%) were on initial output, 8 (22.2%) and 1 (2.6%) on second output, and 4 (11.1%) and 1 (2.6%) on final output, respectively. Although regeneration decreased indeterminate responses, proportion of correct responses did not increase. For open-ended and multiple-choice questions, ChatGPT provided consistent justifications for incorrect answers and remained concordant between correct and incorrect answers.Conclusions:ChatGPT previously demonstrated promise on medical licensing exams; however, application to the 2022 Self-assessment Study Program was not demonstrated. Performance improved with multiple-choice over open-ended questions. More importantly were the persistent justifications for incorrect responses - left unchecked, utilization of ChatGPT in medicine may facilitate medical misinformation. © 2023 Lippincott Williams and Wilkins. All rights reserved.
KW  - artificial intelligence
KW  - medical informatics applications
KW  - urology
KW  - article
KW  - artificial intelligence
KW  - clinical article
KW  - human
KW  - human experiment
KW  - learning
KW  - licensing
KW  - medical informatics
KW  - misinformation
KW  - multiple choice test
KW  - physician
KW  - regeneration
KW  - self evaluation
KW  - urology
PB  - Lippincott Williams and Wilkins
SN  - 23520779 (ISSN)
LA  - English
J2  - Urol. Pract.
M3  - Article
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 13; Correspondence Address: C.M. Deibert; Department of Surgery, Division of Urology, University of Nebraska Medical Center, Omaha, 987521 Nebraska Medical Center, 68198-7521, United States; email: christopher.deibert@unmc.edu
ER  -

TY  - JOUR
AU  - Lim, Z.W.
AU  - Pushpanathan, K.
AU  - Yew, S.M.E.
AU  - Lai, Y.
AU  - Sun, C.-H.
AU  - Lam, J.S.H.
AU  - Chen, D.Z.
AU  - Goh, J.H.L.
AU  - Tan, M.C.J.
AU  - Sheng, B.
AU  - Cheng, C.-Y.
AU  - Koh, V.T.C.
AU  - Tham, Y.-C.
TI  - Benchmarking large language models’ performances for myopia care: a comparative analysis of ChatGPT-3.5, ChatGPT-4.0, and Google Bard
PY  - 2023
T2  - eBioMedicine
VL  - 95
C7  - 104770
DO  - 10.1016/j.ebiom.2023.104770
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85168786502&doi=10.1016%2fj.ebiom.2023.104770&partnerID=40&md5=9a7eced9880d0245078d267687ee6c8d
AD  - Yong Loo Lin School of Medicine, National University of Singapore, Singapore
AD  - Centre of Innovation and Precision Eye Health, Department of Ophthalmology, Yong Loo Lin School of Medicine, National University of Singapore and National University Health System, Singapore
AD  - Department of Ophthalmology, National University Hospital, Singapore
AD  - Singapore Eye Research Institute, Singapore National Eye Centre, Singapore
AD  - Department of Computer Science and Engineering, Shanghai Jiao Tong University, Shanghai, China
AD  - Department of Endocrinology and Metabolism, Shanghai Jiao Tong University Affiliated Sixth People's Hospital, Shanghai Diabetes Institute, Shanghai Clinical Center for Diabetes, Shanghai, China
AD  - MoE Key Lab of Artificial Intelligence, Artificial Intelligence Institute, Shanghai Jiao Tong University, Shanghai, China
AD  - Eye Academic Clinical Program (Eye ACP), Duke NUS Medical School, Singapore
AB  - Background: Large language models (LLMs) are garnering wide interest due to their human-like and contextually relevant responses. However, LLMs’ accuracy across specific medical domains has yet been thoroughly evaluated. Myopia is a frequent topic which patients and parents commonly seek information online. Our study evaluated the performance of three LLMs namely ChatGPT-3.5, ChatGPT-4.0, and Google Bard, in delivering accurate responses to common myopia-related queries. Methods: We curated thirty-one commonly asked myopia care-related questions, which were categorised into six domains—pathogenesis, risk factors, clinical presentation, diagnosis, treatment and prevention, and prognosis. Each question was posed to the LLMs, and their responses were independently graded by three consultant-level paediatric ophthalmologists on a three-point accuracy scale (poor, borderline, good). A majority consensus approach was used to determine the final rating for each response. ‘Good’ rated responses were further evaluated for comprehensiveness on a five-point scale. Conversely, ‘poor’ rated responses were further prompted for self-correction and then re-evaluated for accuracy. Findings: ChatGPT-4.0 demonstrated superior accuracy, with 80.6% of responses rated as ‘good’, compared to 61.3% in ChatGPT-3.5 and 54.8% in Google Bard (Pearson's chi-squared test, all p ≤ 0.009). All three LLM-Chatbots showed high mean comprehensiveness scores (Google Bard: 4.35; ChatGPT-4.0: 4.23; ChatGPT-3.5: 4.11, out of a maximum score of 5). All LLM-Chatbots also demonstrated substantial self-correction capabilities: 66.7% (2 in 3) of ChatGPT-4.0's, 40% (2 in 5) of ChatGPT-3.5's, and 60% (3 in 5) of Google Bard's responses improved after self-correction. The LLM-Chatbots performed consistently across domains, except for ‘treatment and prevention’. However, ChatGPT-4.0 still performed superiorly in this domain, receiving 70% ‘good’ ratings, compared to 40% in ChatGPT-3.5 and 45% in Google Bard (Pearson's chi-squared test, all p ≤ 0.001). Interpretation: Our findings underscore the potential of LLMs, particularly ChatGPT-4.0, for delivering accurate and comprehensive responses to myopia-related queries. Continuous strategies and evaluations to improve LLMs’ accuracy remain crucial. Funding: Dr Yih-Chung Tham was supported by the National Medical Research Council of Singapore (NMRC/MOH/HCSAINV21nov-0001). © 2023 The Author(s)
KW  - Chatbot
KW  - ChatGPT-3.5
KW  - ChatGPT-4.0
KW  - Google Bard
KW  - Large language models
KW  - Myopia
KW  - Benchmarking
KW  - Child
KW  - Consensus
KW  - Humans
KW  - Language
KW  - Myopia
KW  - Search Engine
KW  - accuracy
KW  - Article
KW  - benchmarking
KW  - burnout
KW  - child growth
KW  - consensus
KW  - health care
KW  - human
KW  - information dissemination
KW  - language
KW  - medical research
KW  - memory consolidation
KW  - myopia
KW  - natural language processing
KW  - ophthalmologist
KW  - qualitative analysis
KW  - refraction error
KW  - reliability
KW  - risk factor
KW  - scientific literature
KW  - child
KW  - myopia
KW  - search engine
PB  - Elsevier B.V.
SN  - 23523964 (ISSN)
C2  - 37625267
LA  - English
J2  - eBioMedicine
M3  - Article
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 10; Correspondence Address: Y.-C. Tham; Yong Loo Lin School of Medicine, National University of Singapore, MD1 Tahir Foundation Building, Level 13, 12 Science Drive 2, 117549, Singapore; email: thamyc@nus.edu.sg
ER  -

TY  - JOUR
AU  - Head, C.B.
AU  - Jasper, P.
AU  - McConnachie, M.
AU  - Raftree, L.
AU  - Higdon, G.
TI  - Large language model applications for evaluation: Opportunities and ethical implications
PY  - 2023
T2  - New Directions for Evaluation
VL  - 2023
IS  - 178-179
SP  - 33
EP  - 46
DO  - 10.1002/ev.20556
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85176012322&doi=10.1002%2fev.20556&partnerID=40&md5=2bfb8038a61363842eb8fb036b15fa63
AD  - Department of Sociology, University of Florida, Gainesville, United States
AD  - Principal Consultant, Data Innovation, Oxford Policy Management, Oxford, United Kingdom
AD  - Principal Consultant, NIRAS, Edinburgh, United Kingdom
AD  - Natural Language Processing Community of Practice, MERL Tech, Brooklyn, United States
AD  - Data Strategy and Policy, Development Gateway, Washington, DC, United States
AB  - Large language models (LLMs) are a type of generative artificial intelligence (AI) designed to produce text-based content. LLMs use deep learning techniques and massively large data sets to understand, summarize, generate, and predict new text. LLMs caught the public eye in early 2023 when ChatGPT (the first consumer facing LLM) was released. LLM technologies are driven by recent advances in deep-learning AI techniques, where language models are trained on extremely large text data from the internet and then re-used for downstream tasks with limited fine-tuning required. They offer exciting opportunities for evaluators to automate and accelerate time-consuming tasks involving text analytics and text generation. We estimate that over two-thirds of evaluation tasks will be affected by LLMs in the next 5 years. Use-case examples include summarizing text data, extracting key information from text, analyzing and classifying text content, writing text, and translation. Despite the advances, the technologies pose significant challenges and risks. Because LLM technologies are generally trained on text from the internet, they tend to perpetuate biases (racism, sexism, ethnocentrism, and more) and exclusion of non-majority languages. Current tools like ChatGPT have not been specifically developed for monitoring, evaluation, research, and learning (MERL) purposes, possibly limiting their accuracy and usefulness for evaluation. In addition, technical limitations and challenges with bias can lead to real world harm. To overcome these technical challenges and ethical risks, the evaluation community will need to work collaboratively with the data science community to co-develop tools and processes and to ensure the application of quality and ethical standards. © 2023 American Evaluation Association and Wiley Periodicals LLC.
PB  - John Wiley and Sons Inc
SN  - 10976736 (ISSN)
LA  - English
J2  - New Dir. Eval.
M3  - Article
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 5; Correspondence Address: L. Raftree; MERL Tech, Brooklyn, United States; email: linda@merltech.org
ER  -

TY  - JOUR
AU  - Zapata, S.
AU  - Gallardo, F.
AU  - Sevilla, G.
AU  - Torres, E.
AU  - Forradellas, R.
TI  - Trust evaluation in virtual software development teams using BERT-based language models
ST  - Evaluación de confianza en equipos virtuales de desarrollo de software usando modelos de lenguajes basados en BERT
PY  - 2023
T2  - Journal of Computer Science and Technology(Argentina)
VL  - 23
IS  - 1
SP  - 45
EP  - 54
DO  - 10.24215/16666038.23.e04
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85153601092&doi=10.24215%2f16666038.23.e04&partnerID=40&md5=a242818485d7410f4f22bb2af9964f05
AD  - Informatic Institute, Universidad Nacional de San Juan, Argentina
AD  - Informatic Departament, Universidad Nacional de San Juan, Argentina
AD  - Intelligent Systems Laboratory, Universidad Nacional de Cuyo, Argentina
AB  - Nowadays, people from different geographical areas can be closely related thanks to advances in information and communication technologies. This has a greater impact in software development organizations where their members form virtual work teams. In these new co-located work scenarios, the construction of interpersonal trust is more complex and its impact is very relevant in the performance of software development teams. This paper presents the results of the performance evaluation of four pre-trained language models based on BERT applied to trust analysis tasks. For this work, a small dataset of 1453 comments obtained from software projects stored on Github was created. The evaluated language models achieved moderately good values, in the order of 0.84 for the F1-score metric, which augurs that with further research they could be significantly improved. © 2023, Facultad de Informatica, Universidad Nacional de La Plata. All rights reserved.
KW  - BERT-based language model
KW  - Social software engineering
KW  - Trust analysis
PB  - Facultad de Informatica, Universidad Nacional de La Plata
SN  - 16666046 (ISSN)
LA  - English
J2  - J. Comput. Sci. Technol.
M3  - Article
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 0
ER  -

TY  - JOUR
AU  - Deiana, G.
AU  - Dettori, M.
AU  - Arghittu, A.
AU  - Azara, A.
AU  - Gabutti, G.
AU  - Castiglia, P.
TI  - Artificial Intelligence and Public Health: Evaluating ChatGPT Responses to Vaccination Myths and Misconceptions
PY  - 2023
T2  - Vaccines
VL  - 11
IS  - 7
C7  - 1217
DO  - 10.3390/vaccines11071217
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85166429128&doi=10.3390%2fvaccines11071217&partnerID=40&md5=f5ccb83f7a22b9c4ec81e6cf84bf61ba
AD  - Department of Biomedical Sciences, University of Sassari, Sassari, 07100, Italy
AD  - Department of Medical, Surgical and Experimental Sciences, University Hospital of Sassari, Sassari, 07100, Italy
AD  - Department of Medicine, Surgery and Pharmacy, University of Sassari, Sassari, 07100, Italy
AD  - Department of Restorative, Pediatric and Preventive Dentistry, University of Bern, Bern, 3012, Switzerland
AD  - Working Group “Vaccines and Immunization Policies”, Italian Society of Hygiene, Preventive Medicine and Public Health, Cogorno, 16030, Italy
AB  - Artificial intelligence (AI) tools, such as ChatGPT, are the subject of intense debate regarding their possible applications in contexts such as health care. This study evaluates the Correctness, Clarity, and Exhaustiveness of the answers provided by ChatGPT on the topic of vaccination. The World Health Organization’s 11 “myths and misconceptions” about vaccinations were administered to both the free (GPT-3.5) and paid version (GPT-4.0) of ChatGPT. The AI tool’s responses were evaluated qualitatively and quantitatively, in reference to those myth and misconceptions provided by WHO, independently by two expert Raters. The agreement between the Raters was significant for both versions (p of K < 0.05). Overall, ChatGPT responses were easy to understand and 85.4% accurate although one of the questions was misinterpreted. Qualitatively, the GPT-4.0 responses were superior to the GPT-3.5 responses in terms of Correctness, Clarity, and Exhaustiveness (Δ = 5.6%, 17.9%, 9.3%, respectively). The study shows that, if appropriately questioned, AI tools can represent a useful aid in the health care field. However, when consulted by non-expert users, without the support of expert medical advice, these tools are not free from the risk of eliciting misleading responses. Moreover, given the existing social divide in information access, the improved accuracy of answers from the paid version raises further ethical issues. © 2023 by the authors.
KW  - artificial intelligence
KW  - ChatGPT
KW  - immunization
KW  - myths and misconceptions
KW  - public health
KW  - vaccines
KW  - vaccine
KW  - Article
KW  - artificial intelligence
KW  - ChatGPT
KW  - health care
KW  - health practitioner
KW  - human
KW  - immunization
KW  - Likert scale
KW  - public health
KW  - qualitative analysis
KW  - quantitative analysis
KW  - vaccination
KW  - World Health Organization
PB  - Multidisciplinary Digital Publishing Institute (MDPI)
SN  - 2076393X (ISSN)
LA  - English
J2  - Vaccines
M3  - Article
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 13; Correspondence Address: M. Dettori; Department of Medical, Surgical and Experimental Sciences, University Hospital of Sassari, Sassari, 07100, Italy; email: madettori@uniss.it
ER  -

TY  - CONF
AU  - Wu, Z.
AU  - Larson, E.
AU  - Sano, M.
AU  - Baker, D.
AU  - Gage, N.
AU  - Kamata, A.
TI  - Towards Scalable Vocabulary Acquisition Assessment with BERT
PY  - 2023
T2  - L@S 2023 - Proceedings of the 10th ACM Conference on Learning @ Scale
SP  - 272
EP  - 276
DO  - 10.1145/3573051.3596170
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85167869812&doi=10.1145%2f3573051.3596170&partnerID=40&md5=b22930db6042f074b9b2a6e0c67d5df1
AD  - Southern Methodist University, Dallas, TX, United States
AD  - Mack-the-Psych.com, Tokyo, Setagaya, Japan
AD  - University of Texas at Austin, Austin, TX, United States
AB  - In this investigation we propose new machine learning methods for automated scoring models that predict the vocabulary acquisition in science and social studies of second grade English language learners, based upon free-form spoken responses. We evaluate performance on an existing dataset and use transfer learning from a large pre-trained language model, reporting the influence of various objective function designs and the input-convex network design. In particular, we find that combining objective functions with varying properties, such as distance among scores, greatly improves the model reliability compared to human raters. Our models extend the current state of the art performance for assessing word definition tasks and sentence usage tasks in science and social studies, achieving excellent quadratic weighted kappa scores compared with human raters. However, human-human agreement still surpasses model-human agreement, leaving room for future improvement. Even so, our work highlights the scalability of automated vocabulary assessment of free-form spoken language tasks in early grades. © 2023 Owner/Author.
KW  - automated scoring
KW  - deep neural networks
KW  - human-machine reliability
KW  - natural language processing
KW  - transfer learning
KW  - Automation
KW  - Large dataset
KW  - Learning algorithms
KW  - Learning systems
KW  - Natural language processing systems
KW  - Transfer learning
KW  - Automated scoring
KW  - Human-machine
KW  - Human-machine reliability
KW  - Language processing
KW  - Machine reliability
KW  - Natural language processing
KW  - Natural languages
KW  - Science studies
KW  - Transfer learning
KW  - Vocabulary acquisition
KW  - Deep neural networks
PB  - Association for Computing Machinery, Inc
SN  - 979-840070025-5 (ISBN)
LA  - English
J2  - L@S - Proc. ACM Conf. Learn. @ Scale
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 0; Conference name: 10th ACM Conference on Learning @ Scale, L@S 2023; Conference date: 20 July 2023 through 22 July 2023; Conference code: 190884
ER  -

TY  - CONF
AU  - Omrani Sabbaghi, S.
AU  - Wolfe, R.
AU  - Caliskan, A.
TI  - Evaluating Biased Attitude Associations of Language Models in an Intersectional Context
PY  - 2023
T2  - AIES 2023 - Proceedings of the 2023 AAAI/ACM Conference on AI, Ethics, and Society
SP  - 542
EP  - 553
DO  - 10.1145/3600211.3604666
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85170383303&doi=10.1145%2f3600211.3604666&partnerID=40&md5=d6763bc0345acb9c36ac4b8898ab81aa
AD  - George Washington University, Washington, DC, United States
AD  - University of Washington, Seattle, WA, United States
AB  - Language models are trained on large-scale corpora that embed implicit biases documented in psychology. Valence associations (pleasantness/unpleasantness) of social groups determine the biased attitudes towards groups and concepts in social cognition. Building on this established literature, we quantify how social groups are valenced in English language models using a sentence template that provides an intersectional context. We study biases related to age, education, gender, height, intelligence, literacy, race, religion, sex, sexual orientation, social class, and weight. We present a concept projection approach to capture the valence subspace through contextualized word embeddings of language models. Adapting the projection-based approach to embedding association tests that quantify bias, we find that language models exhibit the most biased attitudes against gender identity, social class, and sexual orientation signals in language. We find that the largest and better-performing model that we study is also more biased as it effectively captures bias embedded in sociocultural data. We validate the bias evaluation method by overperforming on an intrinsic valence evaluation task. The approach enables us to measure complex intersectional biases as they are known to manifest in the outputs and applications of language models that perpetuate historical biases. Moreover, our approach contributes to design justice as it studies the associations of groups underrepresented in language such as transgender and homosexual individuals.  © 2023 Owner/Author.
KW  - AI bias
KW  - contextualized word embeddings
KW  - intersectional bias
KW  - language models
KW  - psycholinguistics
KW  - Artificial intelligence
KW  - Computational linguistics
KW  - AI bias
KW  - Contextualized word embedding
KW  - Embeddings
KW  - Intersectional bias
KW  - Language model
KW  - Large-scales
KW  - Psycholinguistic
KW  - Sexual orientations
KW  - Social cognition
KW  - Social groups
KW  - Embeddings
PB  - Association for Computing Machinery, Inc
SN  - 979-840070231-0 (ISBN)
LA  - English
J2  - AIES - Proc. AAAI/ACM Conf. AI, Ethics, Soc.
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 2; Conference name: 2023 AAAI / ACM Conference on Artificial Intelligence, Ethics, and Society, AIES 2023; Conference date: 8 August 2023 through 10 August 2023; Conference code: 192626
ER  -

TY  - JOUR
AU  - Khanna, R.K.
AU  - Ducloyer, J.-B.
AU  - Hage, A.
AU  - Rezkallah, A.
AU  - Durbant, E.
AU  - Bigoteau, M.
AU  - Mouchel, R.
AU  - Guillon-Rolf, R.
AU  - Le, L.
AU  - Tahiri, R.
AU  - Chammas, J.
AU  - Baudouin, C.
TI  - Evaluating the potential of ChatGPT-4 in ophthalmology: The good, the bad and the ugly
ST  - Révolutionner la pratique de l'ophtalmologie avec les chatbots: perspectives, limitations et risques de ChatGPT-4
PY  - 2023
T2  - Journal Francais d'Ophtalmologie
VL  - 46
IS  - 7
SP  - 697
EP  - 705
DO  - 10.1016/j.jfo.2023.07.001
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85167981784&doi=10.1016%2fj.jfo.2023.07.001&partnerID=40&md5=01a90013a3efb48f002346ee784994eb
AD  - Service d'ophtalmologie, hôpital universitaire Bretonneau, Inserm 1253 iBrain, Tours, France
AD  - Service d'ophtalmologie, Nantes université, CHU de Nantes, Nantes, 44000, France
AD  - Service d'ophtalmologie, CHNO 15-20, Paris, France
AD  - Service d'ophtalmologie, hôpital de la Croix Rousse, Lyon, France
AD  - Cabinet d'ophtalmologie, Paris, France
AD  - Service d'ophtalmologie, hôpital Jacques-Cœur, Bourges, France
AD  - Centre ophtalmologique Kléber, Clinique du parc, Lyon, France
AD  - Service d'ophtalmologie, Fondation Adolphe-de-Rothschild, Paris, France
AD  - Cabinet d'ophtalmologie, Chartres, France
AD  - Service de chirurgie ambulatoire, centre hospitalier d'Avranches-Granville, 849, rue des Menneries, Granville, 50400, France
AD  - Service d'ophtalmologie, CHU Robert-Debré, Reims, France
AD  - Service d'ophtalmologie, CHNO 15-20, Sorbonne Université, Inserm, CNRS, Institut de la Vision, IHU FOReSIGHT, Paris, France
AD  - Centre ophtalmologique du Grand Lac, Aix-les-Bains, France
AD  - Centre ophtalmologique du Rhin, Strasbourg, France
AB  - There is growing interest nowadays for artificial intelligence (AI) in all medical fields. Beyond the direct medical application of AI to medical data, generative AI such as “pre-trained transformer” (GPT) could significantly change the ophthalmology landscape, opening up new avenues for enhancing precision, productivity, and patient outcomes. At present, ChatGPT-4 has been investigated in various ways in ophthalmology for research, medical education, and support for clinical decisions purposes. This article intends to demonstrate the application of ChatGPT-4 within the field of ophthalmology by employing a ‘mise en abime’ approach. While we explore its potential to enhance the future of ophthalmology care, we will also carefully outline its current limitations and potential risks. © 2023 Elsevier Masson SAS
KW  - Artificial Intelligence
KW  - Chatbot
KW  - ChatGPT-4
KW  - Ophthalmology
KW  - Artificial Intelligence
KW  - Humans
KW  - Ophthalmology
KW  - artificial intelligence
KW  - human
KW  - ophthalmology
PB  - Elsevier Masson s.r.l.
SN  - 01815512 (ISSN)
C2  - 37573231
LA  - English
J2  - J. Fr. Ophtalmol.
M3  - Article
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 2; Correspondence Address: R.K. Khanna; Ophtalmologie, Bretonneau Hospital, Tours, 2, boulevard Tonnellé, 37000, France; email: raoul.khanna@univ-tours.fr; CODEN: JFOPD
ER  -

TY  - JOUR
AU  - Patel, N.
AU  - Nagpal, P.
AU  - Shah, T.
AU  - Sharma, A.
AU  - Malvi, S.
AU  - Lomas, D.
TI  - Improving mathematics assessment readability: Do large language models help?
PY  - 2023
T2  - Journal of Computer Assisted Learning
VL  - 39
IS  - 3
SP  - 804
EP  - 822
DO  - 10.1111/jcal.12776
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85146646547&doi=10.1111%2fjcal.12776&partnerID=40&md5=4ebf6ae3a039f5767c90849d0ffeaabb
AD  - Playpower Labs, Gujarat, India
AD  - Central Square Foundation, Delhi, India
AD  - Industrial Design Engineering, Delft University of Technology, Delft, Netherlands
AB  - Background: Readability metrics provide us with an objective and efficient way to assess the quality of educational texts. We can use the readability measures for finding assessment items that are difficult to read for a given grade level. Hard-to-read math word problems can put some students at a disadvantage if they are behind in their literacy learning. Despite their math abilities, these students can perform poorly on difficult-to-read word problems because of their poor reading skills. Less readable math tests can create equity issues for students who are relatively new to the language of assessment. Less readable test items can also affect the assessment's construct validity by partially measuring reading comprehension. Objectives: This study shows how large language models help us improve the readability of math assessment items. Methods: We analysed 250 test items from grades 3 to 5 of EngageNY, an open-source curriculum. We used the GPT-3 AI system to simplify the text of these math word problems. We used text prompts and the few-shot learning method for the simplification task. Results and Conclusions: On average, GPT-3 AI produced output passages that showed improvements in readability metrics, but the outputs had a large amount of noise and were often unrelated to the input. We used thresholds over text similarity metrics and changes in readability measures to filter out the noise. We found meaningful simplifications that can be given to item authors as suggestions for improvement. Takeaways: GPT-3 AI is capable of simplifying hard-to-read math word problems. The model generates noisy simplifications using text prompts or few-shot learning methods. The noise can be filtered using text similarity and readability measures. The meaningful simplifications AI produces are sound but not ready to be used as a direct replacement for the original items. To improve test quality, simplifications can be suggested to item authors at the time of digital question authoring. © 2023 John Wiley & Sons Ltd.
KW  - GPT-3
KW  - mathematics assessment
KW  - readability
KW  - text simplification
PB  - John Wiley and Sons Inc
SN  - 02664909 (ISSN)
LA  - English
J2  - J. Comput. Assisted Learn.
M3  - Article
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 1; Correspondence Address: N. Patel; Playpower Labs, Gujarat, India; email: nirmal@playpowerlabs.com
ER  -

TY  - JOUR
AU  - Meo, S.A.
AU  - Al-Masri, A.A.
AU  - Alotaibi, M.
AU  - Meo, M.Z.S.
AU  - Meo, M.O.S.
TI  - ChatGPT Knowledge Evaluation in Basic and Clinical Medical Sciences: Multiple Choice Question Examination-Based Performance
PY  - 2023
T2  - Healthcare (Switzerland)
VL  - 11
IS  - 14
C7  - 2046
DO  - 10.3390/healthcare11142046
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85166553214&doi=10.3390%2fhealthcare11142046&partnerID=40&md5=d2b76e867730f8737a5d05abdf5e61fa
AD  - Department of Physiology, College of Medicine, King Saud University, Riyadh, 11461, Saudi Arabia
AD  - University Diabetes Unit, Department of Medicine, College of Medicine, King Saud University, Riyadh, 11461, Saudi Arabia
AD  - College of Medicine, Alfaisal University, Riyadh, 11533, Saudi Arabia
AB  - The Chatbot Generative Pre-Trained Transformer (ChatGPT) has garnered great attention from the public, academicians and science communities. It responds with appropriate and articulate answers and explanations across various disciplines. For the use of ChatGPT in education, research and healthcare, different perspectives exist with some level of ambiguity around its acceptability and ideal uses. However, the literature is acutely lacking in establishing a link to assess the intellectual levels of ChatGPT in the medical sciences. Therefore, the present study aimed to investigate the knowledge level of ChatGPT in medical education both in basic and clinical medical sciences, multiple-choice question (MCQs) examination-based performance and its impact on the medical examination system. In this study, initially, a subject-wise question bank was established with a pool of multiple-choice questions (MCQs) from various medical textbooks and university examination pools. The research team members carefully reviewed the MCQ contents and ensured that the MCQs were relevant to the subject’s contents. Each question was scenario-based with four sub-stems and had a single correct answer. In this study, 100 MCQs in various disciplines, including basic medical sciences (50 MCQs) and clinical medical sciences (50 MCQs), were randomly selected from the MCQ bank. The MCQs were manually entered one by one, and a fresh ChatGPT session was started for each entry to avoid memory retention bias. The task was given to ChatGPT to assess the response and knowledge level of ChatGPT. The first response obtained was taken as the final response. Based on a pre-determined answer key, scoring was made on a scale of 0 to 1, with zero representing incorrect and one representing the correct answer. The results revealed that out of 100 MCQs in various disciplines of basic and clinical medical sciences, ChatGPT attempted all the MCQs and obtained 37/50 (74%) marks in basic medical sciences and 35/50 (70%) marks in clinical medical sciences, with an overall score of 72/100 (72%) in both basic and clinical medical sciences. It is concluded that ChatGPT obtained a satisfactory score in both basic and clinical medical sciences subjects and demonstrated a degree of understanding and explanation. This study’s findings suggest that ChatGPT may be able to assist medical students and faculty in medical education settings since it has potential as an innovation in the framework of medical sciences and education. © 2023 by the authors.
KW  - ChatGPT
KW  - intellect level
KW  - knowledge
KW  - medical education
PB  - Multidisciplinary Digital Publishing Institute (MDPI)
SN  - 22279032 (ISSN)
LA  - English
J2  - Healthcare (Basel)
M3  - Article
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 9; Correspondence Address: S.A. Meo; Department of Physiology, College of Medicine, King Saud University, Riyadh, 11461, Saudi Arabia; email: smeo@ksu.edu.sa
ER  -

TY  - JOUR
AU  - Badini, S.
AU  - Regondi, S.
AU  - Frontoni, E.
AU  - Pugliese, R.
TI  - Assessing the capabilities of ChatGPT to improve additive manufacturing troubleshooting
PY  - 2023
T2  - Advanced Industrial and Engineering Polymer Research
VL  - 6
IS  - 3
SP  - 278
EP  - 287
DO  - 10.1016/j.aiepr.2023.03.003
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85151402811&doi=10.1016%2fj.aiepr.2023.03.003&partnerID=40&md5=1c82112e13c9fdf41f6b4435bcd10c72
AD  - NeMO Lab, ASST GOM Niguarda Cà Granda Hospital, Milan, Italy
AD  - VRAI Lab, SPOCRI Department, University of Macerata, Macerata, Italy
AB  - This paper explores the potential of using Chat Generative Pre-trained Transformer (ChatGPT), a Large Language Model (LLM) developed by OpenAI, to address the main challenges and improve the efficiency of the Gcode generation process in Additive Manufacturing (AM), also known as 3D printing. The Gcode generation process, which controls the movements of the printer's extruder and the layer-by-layer build process, is a crucial step in the AM process and optimizing the Gcode is essential for ensuring the quality of the final product and reducing print time and waste. ChatGPT can be trained on existing Gcode data to generate optimized Gcode for specific polymeric materials, printers, and objects, as well as analyze and optimize the Gcode based on various printing parameters such as printing temperature, printing speed, bed temperature, fan speed, wipe distance, extrusion multiplier, layer thickness, and material flow. Here the capability of ChatGPT in performing complex tasks related to AM process optimization was demonstrated. In particular performance tests were conducted to evaluate ChatGPT's expertise in technical matters, focusing on the evaluation of printing parameters and bed detachment, warping, and stringing issues for Fused Filament Fabrication (FFF) methods using thermoplastic polyurethane polymer as feedstock material. This work provides effective feedback on the performance of ChatGPT and assesses its potential for use in the AM field. The use of ChatGPT for AM process optimization has the potential to revolutionize the industry by offering a user-friendly interface and utilizing machine learning algorithms to improve the efficiency and accuracy of the Gcode generation process and optimal printing parameters. Furthermore, the real-time optimization capabilities of ChatGPT can lead to significant time and material savings, making AM a more accessible and cost-effective solution for manufacturers and industry. © 2023 Kingfa Scientific and Technological Co. Ltd.
KW  - 3D printing
KW  - Accuracy
KW  - Additive manufacturing
KW  - ChatGPT
KW  - Efficiency
KW  - Gcode
KW  - Machine learning
KW  - Material savings
KW  - Optimization
KW  - Process control
KW  - Time savings
KW  - 3D printing
KW  - Additives
KW  - Cost effectiveness
KW  - Learning algorithms
KW  - Machine learning
KW  - Optimization
KW  - Parameter estimation
KW  - Printing presses
KW  - Process control
KW  - 3-D printing
KW  - 3D-printing
KW  - Accuracy
KW  - Chat generative pre-trained transformer
KW  - Gcode
KW  - Generation process
KW  - Machine-learning
KW  - Materials - savings
KW  - Optimisations
KW  - Time saving
KW  - Efficiency
PB  - KeAi Communications Co.
SN  - 25425048 (ISSN)
LA  - English
J2  - Adv. Ind. Eng. Polym. Res.
M3  - Article
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 15; Correspondence Address: R. Pugliese; NeMO Lab, ASST GOM Niguarda Cà Granda Hospital, Milan, Italy; email: raffaele.pugliese@nemolab.it
ER  -

TY  - JOUR
AU  - Liu, J.
AU  - Wang, S.
AU  - Zhu, Q.
AU  - Zhao, C.
AU  - Zhang, G.
AU  - Zhao, Z.
AU  - Lu, X.
TI  - Overhead transmission line condition assessment based on intention classification and slot filling using optimized BERT model
PY  - 2023
T2  - Energy Reports
VL  - 9
SP  - 838
EP  - 846
DO  - 10.1016/j.egyr.2023.04.357
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85158000653&doi=10.1016%2fj.egyr.2023.04.357&partnerID=40&md5=7be943ff07c6c15307debbc296eb23d1
AD  - State Grid Liaoning Electric Power Company Limited Electric Power Research Institute, Shenyang, 110006, China
AD  - State Key Laboratory of Electrical Insulation and Power Equipment, Xi'an Jiaotong University, Xi'an, 710049, China
AB  - As the key equipment in power system, the running state of overhead transmission lines is affected by various complex and random factors, and the maintenance workload of the line is too heavy to overhaul regularly. Therefore, it is very necessary to build a refined condition assessment system to improve the diagnosis accuracy and maintenance efficiency of overhead transmission lines. Recent years, State Grid Corporation of China (SGCC) has recorded mass of monitoring reports of transmission lines. The natural language processing (NLP) with deep learning model provides an effective way to extract the key defect information from the monitoring reports. In this paper, the joint model of intention classification and slot filling (ICSF) based on bidirectional encoder representation from transformers (BERT) is introduced. To improve the precision of defect information extraction, two optimization models of BERT are presented. The results show that Robustly Optimized BERT Pre-Training Approach (RoBERTa) has achieved better effects on ICSF with the extraction accuracy of 92.22%. Then, the hierarchical weighted scoring method is introduced to score the status of overhead transmission line based on the results of ICSF-RoBERTa. And the assessment results of the overhead transmission line state and the corresponding maintenance strategies are provided according to the scores. Finally, the feasibility of the proposed method is validated by practical cases of line inspection reports. © 2023 The Author(s)
KW  - BERT
KW  - Condition assessment
KW  - Hierarchical weighted scoring method
KW  - Intention classification
KW  - Overhead transmission line
KW  - Slot filling
KW  - Condition based maintenance
KW  - Deep learning
KW  - Defects
KW  - Electric power transmission
KW  - Natural language processing systems
KW  - Overhead lines
KW  - Bidirectional encoder representation from transformer
KW  - Condition assessments
KW  - Hierarchical weighted scoring method
KW  - Intention classification
KW  - Key equipment
KW  - Overhead transmission lines
KW  - Pre-training
KW  - Scoring methods
KW  - Slot filling
KW  - Transformer modeling
KW  - Filling
PB  - Elsevier Ltd
SN  - 23524847 (ISSN)
LA  - English
J2  - Energy Rep.
M3  - Article
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 1; Correspondence Address: G. Zhang; State Key Laboratory of Electrical Insulation and Power Equipment, Xi'an Jiaotong University, Xi'an, 710049, China; email: ggzhang@mail.xjtu.edu.cn
ER  -

TY  - JOUR
AU  - Springenberg, M.
AU  - Frommholz, A.
AU  - Wenzel, M.
AU  - Weicken, E.
AU  - Ma, J.
AU  - Strodthoff, N.
TI  - From modern CNNs to vision transformers: Assessing the performance, robustness, and classification strategies of deep learning models in histopathology
PY  - 2023
T2  - Medical Image Analysis
VL  - 87
C7  - 102809
DO  - 10.1016/j.media.2023.102809
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85159191387&doi=10.1016%2fj.media.2023.102809&partnerID=40&md5=4ca59782b8a6b37b87970b85ff210f6a
AD  - Fraunhofer Heinrich Hertz Institute, Einsteinufer 37, Berlin, 10587, Germany
AD  - University of Oldenburg, Ammerländer Heerstr. 114-118, Oldenburg, 26129, Germany
AB  - While machine learning is currently transforming the field of histopathology, the domain lacks a comprehensive evaluation of state-of-the-art models based on essential but complementary quality requirements beyond a mere classification accuracy. In order to fill this gap, we developed a new methodology to extensively evaluate a wide range of classification models, including recent vision transformers, and convolutional neural networks such as: ConvNeXt, ResNet (BiT), Inception, ViT and Swin transformer, with and without supervised or self-supervised pretraining. We thoroughly tested the models on five widely used histopathology datasets containing whole slide images of breast, gastric, and colorectal cancer and developed a novel approach using an image-to-image translation model to assess the robustness of a cancer classification model against stain variations. Further, we extended existing interpretability methods to previously unstudied models and systematically reveal insights of the models’ classification strategies that allow for plausibility checks and systematic comparisons. The study resulted in specific model recommendations for practitioners as well as putting forward a general methodology to quantify a model's quality according to complementary requirements that can be transferred to future model architectures. © 2023 Elsevier B.V.
KW  - Histopathology
KW  - Interpretability
KW  - Machine learning
KW  - Robustness
KW  - Breast
KW  - Deep Learning
KW  - Humans
KW  - Machine Learning
KW  - Neural Networks, Computer
KW  - Classification (of information)
KW  - Deep learning
KW  - Diseases
KW  - Learning systems
KW  - Medical imaging
KW  - Quality control
KW  - ART model
KW  - Classification models
KW  - Comprehensive evaluation
KW  - Histopathology
KW  - Interpretability
KW  - Learning models
KW  - Machine-learning
KW  - Performance robustness
KW  - Robustness
KW  - State of the art
KW  - area under the curve
KW  - Article
KW  - breast cancer
KW  - cancer classification
KW  - carcinogenesis
KW  - classification algorithm
KW  - colorectal cancer
KW  - convnext network
KW  - convnext t netwotk
KW  - convolutional neural network
KW  - deep learning
KW  - diagnostic accuracy
KW  - feature extraction
KW  - histopathology
KW  - human
KW  - image segmentation
KW  - inception network
KW  - inception v3 network
KW  - model
KW  - physician
KW  - quantitative analysis
KW  - residual neural network
KW  - resnet 50x1 model
KW  - stomach cancer
KW  - swin transformer
KW  - vit network
KW  - artificial neural network
KW  - breast
KW  - machine learning
KW  - Convolutional neural networks
PB  - Elsevier B.V.
SN  - 13618415 (ISSN)
C2  - 37201221
LA  - English
J2  - Med. Image Anal.
M3  - Article
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 6; Correspondence Address: M. Springenberg; Fraunhofer Heinrich Hertz Institute, Berlin, Einsteinufer 37, 10587, Germany; email: maximilian.springenberg@hhi.fraunhofer.de; CODEN: MIAEC
ER  -

TY  - JOUR
AU  - Madden, M.G.
AU  - McNicholas, B.A.
AU  - Laffey, J.G.
TI  - Assessing the usefulness of a large language model to query and summarize unstructured medical notes in intensive care
PY  - 2023
T2  - Intensive Care Medicine
VL  - 49
IS  - 8
SP  - 1018
EP  - 1020
DO  - 10.1007/s00134-023-07128-2
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85162247588&doi=10.1007%2fs00134-023-07128-2&partnerID=40&md5=e1027aae085f49c051b48156dd00c64a
AD  - School Computer Science, University of Galway, Galway, Ireland
AD  - Anaesthesia and Intensive Care Medicine, School of Medicine, University of Galway, Galway, Ireland
AD  - Department of Anaesthesia and Intensive Care Medicine, Galway University Hospitals, SAOLTA University Health Care Group, Galway, Ireland
KW  - Critical Care
KW  - Electronic Health Records
KW  - Humans
KW  - human
KW  - intensive care
KW  - Letter
KW  - medical documentation
KW  - medical information
KW  - electronic health record
PB  - Springer Science and Business Media Deutschland GmbH
SN  - 03424642 (ISSN)
C2  - 37338549
LA  - English
J2  - Intensive Care Med.
M3  - Letter
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 0; Correspondence Address: J.G. Laffey; Anaesthesia and Intensive Care Medicine, School of Medicine, University of Galway, Galway, Ireland; email: john.laffey@universityofgalway.ie; CODEN: ICMED
ER  -

TY  - JOUR
AU  - Chen, Q.
AU  - Sun, H.
AU  - Liu, H.
AU  - Jiang, Y.
AU  - Ran, T.
AU  - Jin, X.
AU  - Xiao, X.
AU  - Lin, Z.
AU  - Chen, H.
AU  - Niu, Z.
TI  - An extensive benchmark study on biomedical text generation and mining with ChatGPT
PY  - 2023
T2  - Bioinformatics
VL  - 39
IS  - 9
C7  - btad557
DO  - 10.1093/bioinformatics/btad557
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85175201973&doi=10.1093%2fbioinformatics%2fbtad557&partnerID=40&md5=d265514207f7bf976ae48fbfe4051859
AD  - College of Life Sciences, Nankai University, Tianjin, 300071, China
AD  - AIDD, Mindrank AI Ltd, Zhejiang, 310000, China
AD  - Guangzhou Laboratory, GuangDong, 510005, China
AD  - National Heart and Lung Institute, Imperial College London, London, United Kingdom
AB  - Motivation: In recent years, the development of natural language process (NLP) technologies and deep learning hardware has led to significant improvement in large language models (LLMs). The ChatGPT, the state-of-the-art LLM built on GPT-3.5 and GPT-4, shows excellent capabilities in general language understanding and reasoning. Researchers also tested the GPTs on a variety of NLP-related tasks and benchmarks and got excellent results. With exciting performance on daily chat, researchers began to explore the capacity of ChatGPT on expertise that requires professional education for human and we are interested in the biomedical domain. Results: To evaluate the performance of ChatGPT on biomedical-related tasks, this article presents a comprehensive benchmark study on the use of ChatGPT for biomedical corpus, including article abstracts, clinical trials description, biomedical questions, and so on. Typical NLP tasks like named entity recognization, relation extraction, sentence similarity, question and answering, and document classification are included. Overall, ChatGPT got a BLURB score of 58.50 while the state-of-the-art model had a score of 84.30. Through a series of experiments, we demonstrated the effectiveness and versatility of ChatGPT in biomedical text understanding, reasoning and generation, and the limitation of ChatGPT build on GPT-3.5. © The Author(s) 2023. Published by Oxford University Press.
KW  - article
KW  - ChatGPT
KW  - human
KW  - human experiment
KW  - language
KW  - mining
KW  - reasoning
KW  - vocational education
PB  - Oxford University Press
SN  - 13674803 (ISSN)
LA  - English
J2  - Bioinformatics
M3  - Article
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 2; Correspondence Address: H. Chen; Guangzhou Laboratory, GuangDong, 510005, China; email: chen_homgming@gzlab.ac.cn; Z. Niu; AIDD, Mindrank AI Ltd, Zhejiang, 310000, China; email: zhangming@mindrank.ai; CODEN: BOINF
ER  -

TY  - CONF
AU  - Dantas, C.E.C.
AU  - Rocha, A.M.
AU  - Maia, M.A.
TI  - Assessing the Readability of ChatGPT Code Snippet Recommendations: A Comparative Study
PY  - 2023
T2  - ACM International Conference Proceeding Series
SP  - 283
EP  - 292
DO  - 10.1145/3613372.3613413
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85174497362&doi=10.1145%2f3613372.3613413&partnerID=40&md5=d5c6dbbc24b5158d1b632ed9f329f4dc
AD  - Federal University of Uberlândia, Brazil
AB  - Developers often rely on code search engines to find high-quality and reusable code snippets online, such as those available on Stack Overflow. Recently, ChatGPT, a language model trained for dialog tasks, has been gaining attention as a promising approach for code snippet generation. However, there is still a need for in-depth analysis of the quality of its recommendations. In this work, we propose the evaluation of the readability of code snippets generated by ChatGPT, comparing them with those recommended by CROKAGE, a state-of-the-art code search engine for Stack Overflow. We compare the recommended snippets of both approaches using readability issues raised by the automated static analysis tool (ASAT) SonarQube. Our results show that ChatGPT can generate cleaner code snippets and more consistent naming and code conventions than those written by humans and recommended by CROKAGE. However, in some cases, ChatGPT generates code that lacks recent features from Java API such as try-with-resources, lambdas, and others. Overall, our findings suggest that ChatGPT can provide valuable assistance to developers searching for didactic and high-quality code snippets online. However, it is still important for developers to review the generated code, either manually or assisted by an ASAT, to prevent potential readability issues, as the correctness of the generated code snippets.  © 2023 ACM.
KW  - ChatGPT
KW  - code snippets
KW  - readability
KW  - SonarQube
KW  - Stack Overflow
KW  - Codes (symbols)
KW  - Quality control
KW  - Search engines
KW  - Analysis tools
KW  - ChatGPT
KW  - Code search engine
KW  - Code snippet
KW  - Comparatives studies
KW  - High quality
KW  - Quality codes
KW  - Readability
KW  - Sonarqube
KW  - Stack overflow
KW  - Static analysis
PB  - Association for Computing Machinery
SN  - 979-840070787-2 (ISBN)
LA  - English
J2  - ACM Int. Conf. Proc. Ser.
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 0; Conference name: 37th Brazilian Symposium on Software Engineering, SBES 2023, held in conjunction with the Brazilian Conference on Software: Theory and Practice, CBSoft 2023; Conference date: 25 September 2023 through 29 September 2023; Conference code: 193067
ER  -

TY  - JOUR
AU  - Gamage, K.A.A.
AU  - Dehideniya, S.C.P.
AU  - Xu, Z.
AU  - Tang, X.
TI  - ChatGPT and higher education assessments: More opportunities than concerns?
PY  - 2023
T2  - Journal of Applied Learning and Teaching
VL  - 6
IS  - 2
SP  - 358
EP  - 369
DO  - 10.37074/jalt.2023.6.2.32
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85178965802&doi=10.37074%2fjalt.2023.6.2.32&partnerID=40&md5=52f83e90aa7bb3c4b7a5ebc13ccbc02f
AD  - Centre for Educational Development and Innovation, James Watt School of Engineering, University of Glasgow, United Kingdom
AD  - Department of Education, University of Peradeniya, Sri Lanka
AD  - Department of Nuclear Science and Technology, Nanjing University of Aeronautics and Astronautics, China
AD  - Key Laboratory of Nuclear Technology Application and Radiation Protection in Astronautics, Ministry of Industry and Information Technology, Nanjing, China
AB  - In recent times, higher education has seen a growing concern regarding the utilisation of artificial intelligence, especially with the emergence of ChatGPT. This technology can generate written content and respond to queries at a level that is nearly indistinguishable from a human writer. This feature has drawn substantial interest from students in higher education and has led to concern that students will use ChatGPT’s capabilities to cheat on written formative and summative assessments. In this paper, we will review the usage of ChatGPT in higher education assessments and investigate why students want to cheat using artificial intelligence capabilities. It also offers a critical perspective on the challenges associated with detecting ChatGPT-generated content and its impact on academic integrity. We also consider whether artificial intelligence provides more opportunities for academics to focus on assessing higher-order thinking and strategies. © 2023. Kelum A.A. Gamage, Shyama C. P. Dehideniya, Zhiheng Xu, and Xiaobin Tang.
KW  - Academic integrity
KW  - artificial intelligence
KW  - assessments
KW  - ChatGPT
KW  - higher education
KW  - learning and teaching
KW  - quality assurance
PB  - Kaplan Singapore
SN  - 2591801X (ISSN)
LA  - English
J2  - J. Appl. Learn. Teach.
M3  - Article
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 2
ER  -

TY  - JOUR
AU  - Bommasani, R.
AU  - Liang, P.
AU  - Lee, T.
TI  - Holistic Evaluation of Language Models
PY  - 2023
T2  - Annals of the New York Academy of Sciences
VL  - 1525
IS  - 1
SP  - 140
EP  - 146
DO  - 10.1111/nyas.15007
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85165546271&doi=10.1111%2fnyas.15007&partnerID=40&md5=137c8c274219d1295927de6bceba27cc
AD  - Center for Research on Foundation Models, Stanford University, Stanford, CA, United States
AB  - Language models (LMs) like GPT-3, PaLM, and ChatGPT are the foundation for almost all major language technologies, but their capabilities, limitations, and risks are not well understood. We present Holistic Evaluation of Language Models (HELM) to improve the transparency of LMs. LMs can serve many purposes and their behavior should satisfy many desiderata. To navigate the vast space of potential scenarios and metrics, we taxonomize the space and select representative subsets. We evaluate models on 16 core scenarios and 7 metrics, exposing important trade-offs. We supplement our core evaluation with seven targeted evaluations to deeply analyze specific aspects (including world knowledge, reasoning, regurgitation of copyrighted content, and generation of disinformation). We benchmark 30 LMs, from OpenAI, Microsoft, Google, Meta, Cohere, AI21 Labs, and others. Prior to HELM, models were evaluated on just 17.9% of the core HELM scenarios, with some prominent models not sharing a single scenario in common. We improve this to 96.0%: all 30 models are now benchmarked under the same standardized conditions. Our evaluation surfaces 25 top-level findings. For full transparency, we release all raw model prompts and completions publicly. HELM is a living benchmark for the community, continuously updated with new scenarios, metrics, and models https://crfm.stanford.edu/helm/latest/. © 2023 New York Academy of Sciences.
KW  - artificial intelligence
KW  - evaluation
KW  - foundation models
KW  - language models
KW  - natural language processing
KW  - transparency
KW  - Dietary Supplements
KW  - Humans
KW  - Knowledge
KW  - Language
KW  - Problem Solving
KW  - Technology
KW  - dietary supplement
KW  - human
KW  - knowledge
KW  - language
KW  - problem solving
KW  - technology
PB  - NLM (Medline)
SN  - 17496632 (ISSN)
C2  - 37230490
LA  - English
J2  - Ann N Y Acad Sci
M3  - Article
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 4
ER  -

TY  - JOUR
AU  - Yeo, Y.H.
AU  - Samaan, J.S.
AU  - Ng, W.H.
AU  - Ting, P.-S.
AU  - Trivedi, H.
AU  - Vipani, A.
AU  - Ayoub, W.
AU  - Yang, J.D.
AU  - Liran, O.
AU  - Spiegel, B.
AU  - Kuo, A.
TI  - Assessing the performance of ChatGPT in answer- ing questions regarding cirrhosis and hepatocellu- lar carcinoma
PY  - 2023
T2  - Clinical and Molecular Hepatology
VL  - 29
IS  - 3
SP  - 721
EP  - 732
DO  - 10.3350/cmh.2023.0089
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85160715682&doi=10.3350%2fcmh.2023.0089&partnerID=40&md5=d41b1662bd73a2df1b66653b329f7a39
AD  - Karsh Division of Gastroenterology and Hepatology, Department of Medicine, Cedars-Sinai Medical Center, 8700 Beverly Blvd, Los Angeles, CA, United States
AD  - Bristol Medical School, University of Bristol, Bristol, United Kingdom
AD  - School of Medicine, Tulane University, New Orleans, LA, United States
AD  - Comprehensive Transplant Center, Cedars-Sinai Medical Center, United States
AD  - Samuel Oschin Comprehensive Cancer Institute, Cedars Sinai Medical Center, United States
AD  - Department of Psychiatry and Behavioral Sciences, Cedars-Sinai, United States
AD  - Division of Health Services Research, Department of Medicine, Cedars-Sinai, Los Angeles, CA, United States
AB  - Background/Aims: Patients with cirrhosis and hepatocellular carcinoma (HCC) require extensive and personalized care to improve outcomes. ChatGPT (Generative Pre-trained Transformer), a large language model, holds the potential to provide professional yet patient-friendly support. We aimed to examine the accuracy and reproducibility of ChatGPT in answering questionsregarding knowledge, management, and emotionalsupport for cirrhosis and HCC. Methods: ChatGPT’s responses to 164 questions were independently graded by two transplant hepatologists and resolved by a third reviewer. The performance of ChatGPT was also assessed using two published questionnaires and 26 questions formulated from the quality measures of cirrhosis management. Finally, its emotional support capacity was tested. Results: We showed that ChatGPT regurgitated extensive knowledge of cirrhosis (79.1% correct) and HCC (74.0% correct), but only small proportions (47.3% in cirrhosis, 41.1% in HCC) were labeled as comprehensive. The performance was better in basic knowledge, lifestyle, and treatment than in the domains of diagnosis and preventive medicine. For the quality measures, the model answered 76.9% of questions correctly but failed to specify decision-making cut-offs and treatment durations. ChatGPT lacked knowledge of regional guidelines variations, such as HCC screening criteria. However, it provided practical and multifaceted advice to patients and caregivers regarding the next steps and adjusting to a new diagnosis. Conclusions: We analyzed the areas of robustness and limitations of ChatGPT’s responses on the management of cirrhosis and HCC and relevant emotional support. ChatGPT may have a role as an adjunct informational tool for patients and physiciansto improve outcomes. (Clin Mol Hepatol 2023;29:721-732) © 2023 by Korean Association for the Study of the Liver.
KW  - Artificial intelligence
KW  - Chronic disease management
KW  - Health communication
KW  - Patient education as topic
KW  - Telemedicine
KW  - Article
KW  - artificial intelligence
KW  - cancer epidemiology
KW  - cancer staging
KW  - chat generative pre-trained transformer
KW  - decision making
KW  - emotional support
KW  - hepatologist
KW  - human
KW  - knowledge
KW  - lifestyle
KW  - liver cell carcinoma
KW  - liver cirrhosis
KW  - performance
KW  - preventive medicine
KW  - questionnaire
KW  - reinforcement learning (machine learning)
KW  - reproducibility
KW  - treatment duration
PB  - Korean Association for the Study of the Liver
SN  - 22872728 (ISSN)
C2  - 36946005
LA  - English
J2  - Clin. Mol. Hepatol.
M3  - Article
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 70; Correspondence Address: Y.H. Yeo; Karsh Division of Gastroenterology and Hepatology, Department of Medicine, Cedars-Sinai Medical Center, Los Angeles, 8700 Beverly Blvd, United States; email: Brennan.Spiegel@cshs.org
ER  -

TY  - JOUR
AU  - Panthier, C.
AU  - Gatinel, D.
TI  - Success of ChatGPT, an AI language model, in taking the French language version of the European Board of Ophthalmology examination: A novel approach to medical knowledge assessment
ST  - Succès de ChatGPT, intelligence artificielle conversationnelle, aux annales en français de l'European Board of Ophthalmology: une nouvelle approche dans l’évaluation de l'apprentissage médical
PY  - 2023
T2  - Journal Francais d'Ophtalmologie
VL  - 46
IS  - 7
SP  - 706
EP  - 711
DO  - 10.1016/j.jfo.2023.05.006
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85167989299&doi=10.1016%2fj.jfo.2023.05.006&partnerID=40&md5=55c3e188a27eaada3cb3c12ef28b7e89
AD  - Department of Ophthalmology, Rothschild Foundation Hospital, 25, rue Manin, Paris, 75019, France
AD  - Center of Expertise and Research in Optics for Vision (CEROV), Paris, France
AB  - Purpose: The purpose of this study was to evaluate the performance of ChatGPT, a cutting-edge artificial intelligence (AI) language model developed by OpenAI, in successfully completing the French language version of the European Board of Ophthalmology (EBO) examination and to assess its potential role in medical education and knowledge assessment. Methods: ChatGPT, based on the GPT-4 architecture, was exposed to a series of EBO examination questions in French, covering various aspects of ophthalmology. The AI's performance was evaluated by comparing its responses with the correct answers provided by ophthalmology experts. Additionally, the study assessed the time taken by ChatGPT to answer each question as a measure of efficiency. Results: ChatGPT achieved a 91% success rate on the EBO examination, demonstrating a high level of competency in ophthalmology knowledge and application. The AI provided correct answers across all question categories, indicating a strong understanding of basic sciences, clinical knowledge, and clinical management. The AI model also answered the questions rapidly, taking only a fraction of the time needed by human test-takers. Conclusion: ChatGPT's performance on the French language version of the EBO examination demonstrates its potential to be a valuable tool in medical education and knowledge assessment. Further research is needed to explore optimal ways to implement AI language models in medical education and to address the associated ethical and practical concerns. © 2023 The Author(s)
KW  - AI applications
KW  - Artificial intelligence
KW  - ChatGPT
KW  - Deep learning
KW  - Ethics in AI
KW  - European Board of Ophthalmology
KW  - Generative AI
KW  - Human-like interaction
KW  - Language model
KW  - Machine learning
KW  - Medical examination
KW  - Natural language processing
KW  - OpenAI
KW  - Ophthalmology
KW  - Text generation
KW  - Training dataset
KW  - Transformer architecture
KW  - Artificial Intelligence
KW  - Humans
KW  - Language
KW  - Ophthalmology
KW  - artificial intelligence
KW  - human
KW  - language
KW  - ophthalmology
PB  - Elsevier Masson s.r.l.
SN  - 01815512 (ISSN)
C2  - 37537126
LA  - English
J2  - J. Fr. Ophtalmol.
M3  - Article
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 6; Correspondence Address: D. Gatinel; Department of Ophthalmology, Rothschild Foundation, Paris, 25, rue Manin, 75019, France; email: gatinel@gmail.com; CODEN: JFOPD
ER  -

TY  - JOUR
AU  - Khademi, A.
TI  - Can ChatGPT and Bard generate aligned assessment items? A reliability analysis against human performance
PY  - 2023
T2  - Journal of Applied Learning and Teaching
VL  - 6
IS  - 1
SP  - 75
EP  - 80
DO  - 10.37074/jalt.2023.6.1.28
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85163025507&doi=10.37074%2fjalt.2023.6.1.28&partnerID=40&md5=890d511098a835341e8285c864019c0e
AD  - Postdoctoral Fellow, University of Maryland, Baltimore, United States
AB  - ChatGPT and Bard are AI chatbots based on Large Language Models (LLM) that are slated to promise different applications in diverse areas. In education, these AI technologies have been tested for applications in assessment and teaching. In assessment, AI has long been used in automated essay scoring and automated item generation. One psychometric property that these tools must have to assist or replace humans in assessment is high reliability in terms of agreement between AI scores and human raters. In this paper, the reliability of OpenAI’s ChatGPT and Google’s Bard LLMs tools against experienced and trained humans in perceiving and rating the complexity of writing prompts is measured. Intraclass correlation (ICC) as a performance metric showed that the reliability of both ChatGPT and Bard was low against the gold standard of human ratings. © 2023, Kaplan Singapore. All rights reserved.
KW  - Artificial intelligence
KW  - automated item generation
KW  - ChatGPT
KW  - educational technology
KW  - Google Bard
KW  - Large Language Models (LLMs)
KW  - natural language processing (NLP)
PB  - Kaplan Singapore
SN  - 2591801X (ISSN)
LA  - English
J2  - J. Appl. Learn. Teach.
M3  - Article
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 5; Correspondence Address: A. Khademi; Postdoctoral Fellow, University of Maryland, Baltimore, United States; email: vahab.khademi@gmail.com
ER  -

TY  - CONF
AU  - Hämäläinen, P.
AU  - Tavast, M.
AU  - Kunnari, A.
TI  - Evaluating Large Language Models in Generating Synthetic HCI Research Data: a Case Study
PY  - 2023
T2  - Conference on Human Factors in Computing Systems - Proceedings
C7  - 433
DO  - 10.1145/3544548.3580688
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85153854298&doi=10.1145%2f3544548.3580688&partnerID=40&md5=ed0bd914ab4f4d1901bcb48948fe33b3
AD  - Aalto University, Espoo, Finland
AD  - University of Helsinki, Helsinki, Finland
AB  - Collecting data is one of the bottlenecks of Human-Computer Interaction (HCI) research. Motivated by this, we explore the potential of large language models (LLMs) in generating synthetic user research data. We use OpenAI's GPT-3 model to generate open-ended questionnaire responses about experiencing video games as art, a topic not tractable with traditional computational user models. We test whether synthetic responses can be distinguished from real responses, analyze errors of synthetic data, and investigate content similarities between synthetic and real data. We conclude that GPT-3 can, in this context, yield believable accounts of HCI experiences. Given the low cost and high speed of LLM data generation, synthetic data should be useful in ideating and piloting new experiments, although any findings must obviously always be validated with real data. The results also raise concerns: if employed by malicious users of crowdsourcing services, LLMs may make crowdsourcing of self-report data fundamentally unreliable. © 2023 Owner/Author.
KW  - GPT-3
KW  - Language models
KW  - User experience
KW  - User models
KW  - Computational linguistics
KW  - Human computer interaction
KW  - User interfaces
KW  - Case-studies
KW  - GPT-3
KW  - Human-computer interaction researches
KW  - Language model
KW  - Open-ended questionnaire
KW  - Research data
KW  - Synthetic data
KW  - User Modelling
KW  - User research
KW  - Users' experiences
KW  - Crowdsourcing
PB  - Association for Computing Machinery
SN  - 978-145039421-5 (ISBN)
LA  - English
J2  - Conf Hum Fact Comput Syst Proc
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 9; Conference name: 2023 CHI Conference on Human Factors in Computing Systems, CHI 2023; Conference date: 23 April 2023 through 28 April 2023; Conference code: 188036
ER  -

TY  - JOUR
AU  - Ray, P.P.
AU  - Majumder, P.
TI  - Assessing ChatGPT's Potential: A Critical Analysis and Future Directions in Total Joint Arthroplasty
PY  - 2023
T2  - Journal of Arthroplasty
VL  - 38
IS  - 9
SP  - e19
EP  - e20
DO  - 10.1016/j.arth.2023.05.057
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85167770000&doi=10.1016%2fj.arth.2023.05.057&partnerID=40&md5=8cb729d50cec841144edc19dad102a60
AD  - Sikkim University, Sikkim, Gangtok, India
AD  - Maulana Abul Kalam Azad University of Technology, West Bengal, Kolkata, India
KW  - Arthroplasty, Replacement, Knee
KW  - Forecasting
KW  - Humans
KW  - data quality
KW  - decision support system
KW  - human
KW  - Internet
KW  - Letter
KW  - medical education
KW  - medical informatics
KW  - medical information
KW  - medical research
KW  - Medline
KW  - patient education
KW  - patient engagement
KW  - rehabilitation
KW  - search engine
KW  - total arthroplasty
KW  - total hip replacement
KW  - total knee arthroplasty
KW  - forecasting
KW  - knee replacement
PB  - Elsevier B.V.
SN  - 08835403 (ISSN)
C2  - 37573083
LA  - English
J2  - J. Arthroplasty
M3  - Letter
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 0; CODEN: JOARE
ER  -

TY  - CONF
AU  - Déjean, H.
AU  - Clinchant, S.
AU  - Lassance, C.
AU  - Lupart, S.
AU  - Formal, T.
TI  - Benchmarking Middle-Trained Language Models for Neural Search
PY  - 2023
T2  - SIGIR 2023 - Proceedings of the 46th International ACM SIGIR Conference on Research and Development in Information Retrieval
SP  - 1848
EP  - 1852
DO  - 10.1145/3539618.3591956
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85168677462&doi=10.1145%2f3539618.3591956&partnerID=40&md5=374fd605745a4309cf8e7c7833608056
AD  - Naver Labs Europe, Meylan, France
AB  - Middle training methods aim to bridge the gap between the Masked Language Model (MLM) pre-training and the final finetuning for retrieval. Recent models such as CoCondenser, RetroMAE, and LexMAE argue that the MLM task is not sufficient enough to pretrain a transformer network for retrieval and hence propose various tasks to do so. Intrigued by those novel methods, we noticed that all these models used different finetuning protocols, making it hard to assess the benefits of middle training. We propose in this paper a benchmark of CoCondenser, RetroMAE, and LexMAE, under the same finetuning conditions. We compare both dense and sparse approaches under various finetuning protocols and middle training on different collections (MS MARCO, Wikipedia). We use additional middle training baselines, such as a standard MLM finetuning on the retrieval collection, optionally augmented by a CLS predicting the passage term frequency. For the sparse approach, our study reveals that there is almost no statistical difference between those methods: the more effective the finetuning procedure is, the less difference there is between those models. For the dense approach, RetroMAE using MS MARCO as middle-training collection shows excellent results in almost all the settings. Finally, we show that middle training on the retrieval collection, thus adapting the language model to it, is a critical factor. Overall, a better experimental setup should be adopted to evaluate middle training methods. © 2023 Copyright held by the owner/author(s). Publication rights licensed to ACM.
KW  - benchmarking
KW  - information retrieval
KW  - middle training
KW  - neural search
KW  - Computational linguistics
KW  - Information retrieval
KW  - Condition
KW  - Language model
KW  - Middle training
KW  - Modeling task
KW  - Neural search
KW  - Novel methods
KW  - Pre-training
KW  - Term Frequency
KW  - Training methods
KW  - Wikipedia
KW  - Benchmarking
PB  - Association for Computing Machinery, Inc
SN  - 978-145039408-6 (ISBN)
LA  - English
J2  - SIGIR - Proc. Int. ACM SIGIR Conf. Res. Dev. Inf. Retr.
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 0; Conference name: 46th International ACM SIGIR Conference on Research and Development in Information Retrieval, SIGIR 2023; Conference date: 23 July 2023 through 27 July 2023; Conference code: 190882
ER  -

TY  - JOUR
AU  - Chernyshev, D.I.
AU  - Dobrov, B.V.
TI  - Evaluating the Summarization Comprehension of Pre-Trained Language Models
PY  - 2023
T2  - Lobachevskii Journal of Mathematics
VL  - 44
IS  - 8
SP  - 3028
EP  - 3039
DO  - 10.1134/S1995080223080115
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85178197274&doi=10.1134%2fS1995080223080115&partnerID=40&md5=d2eaaf82477e3227eee0559771c0b6b4
AD  - Research Computing Center, Moscow State University, Moscow, 119991, Russian Federation
AB  - Abstract: Recent advances in abstractive summarization demonstrate the importance of pre-training tasks, however, general purpose language models manage to outperform summarization-specialized pre-training approaches. While several works addressed the question of pseudo-summarization pre-training efficiency in abstractive summarization fine-tuning, none has explored the properties of pre-trained models in a low-resource setting. This work attempts to fill this gap. We benchmark 5 state-of-the-art pre-trained language models on 5 single-document abstractive summarization datasets of different domains. To probe the models, we propose 4 novel task comprehension tests that evaluate the main components of summarization models. Our experiments reveal that pseudo-summarization pre-training biases the models towards more extractive behavior and inhibits their ability to properly filter the salient content, leading to worse generalization. © 2023, Pleiades Publishing, Ltd.
KW  - abstractive summarization
KW  - machine learning
KW  - neural networks
PB  - Pleiades Publishing
SN  - 19950802 (ISSN)
LA  - English
J2  - Lobachevskii J. Math.
M3  - Article
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 0; Correspondence Address: D.I. Chernyshev; Research Computing Center, Moscow State University, Moscow, 119991, Russian Federation; email: chdanorbis@yandex.ru; B.V. Dobrov; Research Computing Center, Moscow State University, Moscow, 119991, Russian Federation; email: dobrov_bv@mail.ru
ER  -

TY  - JOUR
AU  - Cámara, J.
AU  - Troya, J.
AU  - Burgueño, L.
AU  - Vallecillo, A.
TI  - On the assessment of generative AI in modeling tasks: an experience report with ChatGPT and UML
PY  - 2023
T2  - Software and Systems Modeling
VL  - 22
IS  - 3
SP  - 781
EP  - 793
DO  - 10.1007/s10270-023-01105-5
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85160072219&doi=10.1007%2fs10270-023-01105-5&partnerID=40&md5=d8583d705f4bf2c7e97fe11bfb1b00c8
AD  - ITIS Software, Universidad de Málaga, ETSI Informática, Campus de Teatinos. Bulevar Louis Pasteur, Málaga, 35. 29071, Spain
AB  - Most experts agree that large language models (LLMs), such as those used by Copilot and ChatGPT, are expected to revolutionize the way in which software is developed. Many papers are currently devoted to analyzing the potential advantages and limitations of these generative AI models for writing code. However, the analysis of the current state of LLMs with respect to software modeling has received little attention. In this paper, we investigate the current capabilities of ChatGPT to perform modeling tasks and to assist modelers, while also trying to identify its main shortcomings. Our findings show that, in contrast to code generation, the performance of the current version of ChatGPT for software modeling is limited, with various syntactic and semantic deficiencies, lack of consistency in responses and scalability issues. We also outline our views on how we perceive the role that LLMs can play in the software modeling discipline in the short term, and how the modeling community can help to improve the current capabilities of ChatGPT and the coming LLMs for software modeling. © 2023, The Author(s).
KW  - ChatGPT
KW  - Large language models
KW  - Modeling languages
KW  - Software models
KW  - UML
KW  - Computational linguistics
KW  - Semantics
KW  - 'current
KW  - ChatGPT
KW  - Current capability
KW  - Experience report
KW  - Language model
KW  - Large language model
KW  - Modeling task
KW  - Software modeling
KW  - UML
KW  - Writing codes
KW  - Modeling languages
PB  - Springer Science and Business Media Deutschland GmbH
SN  - 16191366 (ISSN)
LA  - English
J2  - Softw. Syst. Model.
M3  - Article
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 14; Correspondence Address: J. Cámara; ITIS Software, Universidad de Málaga, Málaga, ETSI Informática, Campus de Teatinos. Bulevar Louis Pasteur, 35. 29071, Spain; email: jcamara@uma.es
ER  -

TY  - JOUR
AU  - DeLong, K.A.
AU  - Trott, S.
AU  - Kutas, M.
TI  - Offline dominance and zeugmatic similarity normings of variably ambiguous words assessed against a neural language model (BERT)
PY  - 2023
T2  - Behavior Research Methods
VL  - 55
IS  - 4
SP  - 1537
EP  - 1557
DO  - 10.3758/s13428-022-01869-6
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85133243256&doi=10.3758%2fs13428-022-01869-6&partnerID=40&md5=c2c25dc6b1358576b6724491ca1b2f2b
AD  - Department of Cognitive Science, University of California, San Diego (UCSD), 9500 Gilman Drive, La Jolla, 92093-0515, CA, United States
AD  - UCSD Center for Research in Language, La Jolla, CA, United States
AD  - UCSD Department of Neurosciences, La Jolla, CA, United States
AD  - UCSD Kavli Institute for Brain and Mind, La Jolla, CA, United States
AB  - For any research program examining how ambiguous words are processed in broader linguistic contexts, a first step is to establish factors relating to the frequency balance or dominance of those words’ multiple meanings, as well as the similarity of those meanings to one other. Homonyms—words with divergent meanings—are one ambiguous word type commonly utilized in psycholinguistic research. In contrast, although polysemes—words with multiple related senses—are far more common in English, they have been less frequently used as tools for understanding one-to-many word-to-meaning mappings. The current paper details two norming studies of a relatively large number of ambiguous English words. In the first, offline dominance norming is detailed for 547 homonyms and polysemes via a free association task suitable for words across the ambiguity continuum, with a goal of identifying words with more equibiased meanings. The second norming assesses offline meaning similarity for a partial subset of 318 ambiguous words (including homonyms, unambiguous words, and polysemes divided into regular and irregular types) using a novel, continuous rating method reliant on the linguistic phenomenon of zeugma. In addition, we conduct computational analyses on the human similarity norming data using the BERT pretrained neural language model (Devlin et al., 2018, BERT: Pre-training of deep bidirectional transformers for language understanding. ArXiv Preprint. arXiv:1810.04805) to evaluate factors that may explain variance beyond that accounted for by dictionary-criteria ambiguity categories. Finally, we make available the summarized item dominance values and similarity ratings in resultant appendices (see supplementary material), as well as individual item and participant norming data, which can be accessed online (https://osf.io/g7fmv/). © 2022, The Author(s).
KW  - Dominance norming
KW  - Homonyms
KW  - Polysemes
KW  - Semantic ambiguity
KW  - Similarity rating
KW  - Zeugma
KW  - Free Association
KW  - Humans
KW  - Language
KW  - Linguistics
KW  - Psycholinguistics
KW  - Semantics
KW  - adult
KW  - article
KW  - female
KW  - human
KW  - human experiment
KW  - language
KW  - male
KW  - psychoanalysis
KW  - linguistics
KW  - psycholinguistics
KW  - semantics
PB  - Springer
SN  - 1554351X (ISSN)
C2  - 35689168
LA  - English
J2  - Behav. Res. Methods
M3  - Article
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 2; Correspondence Address: K.A. DeLong; Department of Cognitive Science, University of California, San Diego (UCSD), 9500 Gilman Drive, La Jolla, 92093-0515, United States; email: kadelong@ucsd.edu
ER  -

TY  - JOUR
AU  - Cadamuro, J.
AU  - Cabitza, F.
AU  - Debeljak, Z.
AU  - De Bruyne, S.
AU  - Frans, G.
AU  - Perez, S.M.
AU  - Ozdemir, H.
AU  - Tolios, A.
AU  - Carobene, A.
AU  - Padoan, A.
TI  - Potentials and pitfalls of ChatGPT and natural-language artificial intelligence models for the understanding of laboratory medicine test results. An assessment by the European Federation of Clinical Chemistry and Laboratory Medicine (EFLM) Working Group on Artificial Intelligence (WG-AI)
PY  - 2023
T2  - Clinical Chemistry and Laboratory Medicine
VL  - 61
IS  - 7
SP  - 1158
EP  - 1166
DO  - 10.1515/cclm-2023-0355
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85156160041&doi=10.1515%2fcclm-2023-0355&partnerID=40&md5=b00ca4bd799c9bf5fe8fa61eeb1801da
AD  - Department of Laboratory Medicine, Paracelsus Medical University Salzburg, Salzburg, Austria
AD  - DISCo, Università Degli Studi di Milano-Bicocca, Milano, Italy
AD  - IRCCS Istituto Ortopedico Galeazzi, Milan, Italy
AD  - Faculty of Medicine, Josip Juraj Strossmayer University of Osijek, Osijek, Croatia
AD  - Clinical Institute of Laboratory Diagnostics, University Hospital Center Osijek, Osijek, Croatia
AD  - Department of Laboratory Medicine, Ghent University Hospital, Ghent, Belgium
AD  - Department of Laboratory Medicine, University Hospitals Leuven, KU Leuven, Leuven, Belgium
AD  - Unidad de Bioquímica Clínica, Hospital Universitario Virgen Macarena, Sevilla, Spain
AD  - Department of Medical Biochemistry, Faculty of Medicine, Manisa Celal Bayar University, Manisa, Turkey
AD  - Department of Transfusion Medicine and Cell Therapy, Medical University of Vienna, Vienna, Austria
AD  - IRCCS San Raffaele Scientific Institute, Milan, Italy
AD  - Department of Medicine (DIMED), University of Padova, Padova, Italy
AB  - Objectives: ChatGPT, a tool based on natural language processing (NLP), is on everyone's mind, and several potential applications in healthcare have been already proposed. However, since the ability of this tool to interpret laboratory test results has not yet been tested, the EFLM Working group on Artificial Intelligence (WG-AI) has set itself the task of closing this gap with a systematic approach. Methods: WG-AI members generated 10 simulated laboratory reports of common parameters, which were then passed to ChatGPT for interpretation, according to reference intervals (RI) and units, using an optimized prompt. The results were subsequently evaluated independently by all WG-AI members with respect to relevance, correctness, helpfulness and safety. Results: ChatGPT recognized all laboratory tests, it could detect if they deviated from the RI and gave a test-by-test as well as an overall interpretation. The interpretations were rather superficial, not always correct, and, only in some cases, judged coherently. The magnitude of the deviation from the RI seldom plays a role in the interpretation of laboratory tests, and artificial intelligence (AI) did not make any meaningful suggestion regarding follow-up diagnostics or further procedures in general. Conclusions: ChatGPT in its current form, being not specifically trained on medical data or laboratory data in particular, may only be considered a tool capable of interpreting a laboratory report on a test-by-test basis at best, but not on the interpretation of an overall diagnostic picture. Future generations of similar AIs with medical ground truth training data might surely revolutionize current processes in healthcare, despite this implementation is not ready yet.  © 2023 Walter de Gruyter GmbH, Berlin/Boston.
KW  - artificial intelligence
KW  - chatbot
KW  - ChatGPT
KW  - laboratory tests
KW  - natural language processing
KW  - Artificial Intelligence
KW  - Chemistry, Clinical
KW  - Humans
KW  - Laboratories
KW  - alanine aminotransferase
KW  - alkaline phosphatase
KW  - aspartate aminotransferase
KW  - bilirubin
KW  - creatinine
KW  - ferritin
KW  - gamma glutamyltransferase
KW  - glucose
KW  - hemoglobin A1c
KW  - high density lipoprotein cholesterol
KW  - low density lipoprotein cholesterol
KW  - prostate specific antigen
KW  - thyrotropin
KW  - activated partial thromboplastin time
KW  - Article
KW  - artificial intelligence
KW  - blood cell count
KW  - controlled study
KW  - data interpretation
KW  - follow up
KW  - free thyroxine index
KW  - human
KW  - laboratory test
KW  - prothrombin time
KW  - reference value
KW  - clinical chemistry
KW  - laboratory
PB  - De Gruyter Open Ltd
SN  - 14346621 (ISSN)
C2  - 37083166
LA  - English
J2  - Clin. Chem. Lab. Med.
M3  - Article
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 25; Correspondence Address: A. Padoan; Department of Medicine (DIMED), University of Padova, Padova, Italy; email: andrea.padoan@unipd.it; CODEN: CCLMF
ER  -

TY  - JOUR
AU  - Callan, D.
AU  - Foster, J.
TI  - How interesting and coherent are the stories generated by a large-scale neural language model? Comparing human and automatic evaluations of machine-generated text
PY  - 2023
T2  - Expert Systems
VL  - 40
IS  - 6
C7  - e13292
DO  - 10.1111/exsy.13292
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85151401826&doi=10.1111%2fexsy.13292&partnerID=40&md5=0c7753547d67fd071b5b1cf785fc1e1b
AD  - School of Computing, Dublin City University, Dublin, Ireland
AB  - Evaluation of the narrative text generated by machines has traditionally been a challenge, particularly when attempting to evaluate subjective elements such as interest or believability. Recent improvements in narrative machine text generation have been largely driven by the emergence of transformer-based language models, trained on massive quantities of data, resulting in higher quality text generation. In this study, a corpus of stories is generated using the pre-trained GPT-Neo transformer model, with human-written prompts as inputs upon which to base the narrative text. The stories generated through this process are subsequently evaluated through both human evaluation and two automated metrics: BERTScore and BERT Next Sentence Prediction, with the aim of determining whether there is a correlation between the automatic scores and the human judgements. The results show variation in human evaluation results in comparison to modern automated metrics, suggesting further work is required to train automated metrics to identify text that is defined as interesting by humans. © 2023 The Authors. Expert Systems published by John Wiley & Sons Ltd.
KW  - evaluation
KW  - machine-generated text
KW  - natural language generation
KW  - transformers
KW  - Automation
KW  - Computational linguistics
KW  - Natural language processing systems
KW  - Automated metric
KW  - Automatic evaluation
KW  - Evaluation
KW  - Human evaluation
KW  - Language model
KW  - Large-scales
KW  - Machine-generated texts
KW  - Natural language generation
KW  - Text generations
KW  - Transformer
KW  - Expert systems
PB  - John Wiley and Sons Inc
SN  - 02664720 (ISSN)
LA  - English
J2  - Expert Syst
M3  - Article
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 0; Correspondence Address: D. Callan; School of Computing, Dublin City University, Dublin, Ireland; email: dominic.callan24@mail.dcu.ie; J. Foster; School of Computing, Dublin City University, Dublin, Ireland; email: jennifer.foster@dcu.ie; CODEN: EXSYE
ER  -

TY  - JOUR
AU  - Piccolo, S.R.
AU  - Denny, P.
AU  - Luxton-Reilly, A.
AU  - Payne, S.H.
AU  - Ridge, P.G.
TI  - Evaluating a large language model’s ability to solve programming exercises from an introductory bioinformatics course
PY  - 2023
T2  - PLoS Computational Biology
VL  - 19
IS  - 9
C7  - e1011511
DO  - 10.1371/journal.pcbi.1011511
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85173538194&doi=10.1371%2fjournal.pcbi.1011511&partnerID=40&md5=ebd5def92b1d9c25832cb5a27d2af3af
AD  - Department of Biology, Brigham Young University, Provo, UT, United States
AD  - School of Computer Science, The University of Auckland, Auckland, New Zealand
AB  - Computer programming is a fundamental tool for life scientists, allowing them to carry out essential research tasks. However, despite various educational efforts, learning to write code can be a challenging endeavor for students and researchers in life-sciences disciplines. Recent advances in artificial intelligence have made it possible to translate human-language prompts to functional code, raising questions about whether these technologies can aid (or replace) life scientists’ efforts to write code. Using 184 programming exercises from an introductory-bioinformatics course, we evaluated the extent to which one such tool —OpenAI’s ChatGPT—could successfully complete programming tasks. ChatGPT solved 139 (75.5%) of the exercises on its first attempt. For the remaining exercises, we provided natural-language feedback to the model, prompting it to try different approaches. Within 7 or fewer attempts, ChatGPT solved 179 (97.3%) of the exercises. These findings have implications for life-sciences education and research. Instructors may need to adapt their pedagogical approaches and assessment techniques to account for these new capabilities that are available to the general public. For some programming tasks, researchers may be able to work in collaboration with machine-learning models to produce functional code. Copyright: © 2023 Piccolo et al.
KW  - Artificial intelligence
KW  - Education computing
KW  - Functional programming
KW  - Functional codes
KW  - Fundamental tools
KW  - Human language
KW  - Language model
KW  - Life scientists
KW  - Life-sciences
KW  - Natural languages
KW  - Programming exercise
KW  - Programming tasks
KW  - Science disciplines
KW  - article
KW  - bioinformatics
KW  - biomedicine
KW  - ChatGPT
KW  - education
KW  - exercise
KW  - human
KW  - human experiment
KW  - large language model
KW  - machine learning
KW  - Bioinformatics
PB  - Public Library of Science
SN  - 1553734X (ISSN)
C2  - 37769024
LA  - English
J2  - PLoS Comput. Biol.
M3  - Article
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 0; Correspondence Address: S.R. Piccolo; Department of Biology, Brigham Young University, Provo, United States; email: stephen_piccolo@byu.edu
ER  -

TY  - CONF
AU  - Akbari, R.
TI  - Evaluating TF-IDF and Transformers-based Models for Detecting COVID-19 related Conspiracies
PY  - 2023
T2  - CEUR Workshop Proceedings
VL  - 3583
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85180157859&partnerID=40&md5=afa439affa5648671ba6a898bf8c624b
AD  - Simula Research Laboratory, Norway
AB  - The proliferation of misinformation and conspiracy theories on online social media platforms has become a significant concern for public health and safety. To effectively combat this issue, a new generation of data mining and analysis algorithms is essential for early detection and tracking of these information cascades. In this paper, we employed a multifaceted approach for detecting and identifying conspiracy theories and misinformation spreaders related to the Coronavirus pandemic. Specifically, we utilized Text-Based Detection (Task 1) through a combination of TF-IDF-based and Transformers-based methods, Graph-Based Detection (Task 2) through a graph convolutional network, and alternative Transformers-based methods to improve the results of Task 1. Our efforts have yielded promising results, with our best models achieving an impressive MCC score of 0.705 for Task 1, 0.041 for Task 2, and 0.698 for Task 3. © 2022 Copyright for this paper by its authors. Use permitted under Creative Commons License Attribution 4.0 International (CC BY 4.0).
KW  - Coronavirus
KW  - Data mining
KW  - Social networking (online)
KW  - Coronaviruses
KW  - Data analysis algorithms
KW  - Data mining algorithm
KW  - Detection and tracking
KW  - Detection tasks
KW  - Health and safety
KW  - Information cascades
KW  - Multi-faceted approach
KW  - Online social medias
KW  - Social media platforms
KW  - Graphic methods
A2  - Hicks S.
A2  - De Herrera A.G.S.
A2  - Langguth J.
A2  - Langguth J.
A2  - Lommatzsch A.
A2  - Andreadis S.
A2  - Dao M.-S.
A2  - Martin P.-E.
A2  - Hurriyetoglu A.
A2  - Thambawita V.
A2  - Nordmo T.-A.
A2  - Vuillemot R.
A2  - Larson M.
PB  - CEUR-WS
SN  - 16130073 (ISSN)
LA  - English
J2  - CEUR Workshop Proc.
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 0; Correspondence Address: R. Akbari; Simula Research Laboratory, Norway; email: rohullaa@uio.no; Conference name: 2022 MediaEval Workshop, MediaEval 2022; Conference date: 12 January 2023 through 13 January 2023; Conference code: 195253
ER  -

TY  - JOUR
AU  - Ma, H.
AU  - Ma, X.
AU  - Yang, C.
AU  - Niu, Q.
AU  - Gao, T.
AU  - Liu, C.
AU  - Chen, Y.
TI  - Development and evaluation of a program based on a generative pre-trained transformer model from a public natural language processing platform for efficiency enhancement in post-procedural quality control of esophageal endoscopic submucosal dissection
PY  - 2023
T2  - Surgical Endoscopy
DO  - 10.1007/s00464-023-10620-x
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85179737751&doi=10.1007%2fs00464-023-10620-x&partnerID=40&md5=3076de6f3dbed97e1f2c4bd364aad5c6
AD  - Department of Gastroenterology and Hepatology, Binzhou Medical University Hospital, Shandong, Binzhou, 256603, China
AD  - Digestive Disease Research Institute of Binzhou Medical University Hospital, Shandong, Binzhou, China
AD  - Endoscopy Center of Binzhou Medical University Hospital, Shandong, Binzhou, China
AB  - Background: Post-procedural quality control of endoscopic submucosal dissection (ESD) is emphasized in guidelines. However, this process can be tedious and time-consuming. Recently, a pre-training model called generative pre-trained transformer (GPT) on a public natural language processing platform has emerged and garnered significant attention, whose capabilities align well with the post-procedural quality control process and have the potential to streamline it. Therefore, we developed a simple program utilizing this platform and evaluated its performance. Methods: Esophageal ESDs were retrospectively included. The manual quality control process was performed and act as reference standard. GPT’s prompt was optimized through multiple iterations. A Python program was developed to automatically submit prompt with pathological report of each ESD procedure and collect quality control information provided by GPT. Its performance on quality control was evaluated with accuracy, precision, recall, and F-1 score. Results: 165 cases were involved into the dataset, of which 5 were utilized as the prompt optimization dataset and 160 as the validation dataset. Definitive prompt was achieved through seven iterations. Time spent on the validation dataset by GPT was 13.47 ± 2.43 min. Accuracies of pathological diagnosis, invasion depth, horizontal margin, vertical margin, vascular invasion, and lymphatic invasion of the quality control program were (0.940, 0.952) (95% CI), (0.925, 0.945) (95% CI), 0.931, 1.0, and 1.0, respectively. Precisions were (0.965, 0.969) (95% CI), (0.934, 0.954) (95% CI), and 0.957 for pathological diagnosis, invasion depth, and horizontal margin, respectively. Recalls were (0.940, 0.952) (95% CI), (0.925, 0.945) (95% CI), and 0.931 for factors as mentioned, respectively. F1-score were (0.945, 0.957) (95% CI), (0.928, 0.948) (95% CI), and 0.941 for factors as mentioned, respectively. Conclusions: This quality control program was qualified of post-procedural quality control of esophageal ESDs. GPT can be easily applied to this quality control process and reduce workload of the endoscopists. © 2023, The Author(s), under exclusive licence to Springer Science+Business Media, LLC, part of Springer Nature.
KW  - Artificial Intelligence
KW  - Endoscopic submucosal dissection
KW  - Esophagus
KW  - Natural language processing
KW  - Quality control
PB  - Springer
SN  - 09302794 (ISSN)
LA  - English
J2  - Surg. Endosc.
M3  - Article
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 0; Correspondence Address: C. Liu; Department of Gastroenterology and Hepatology, Binzhou Medical University Hospital, Binzhou, Shandong, 256603, China; email: phdlcx@163.com; Y. Chen; Department of Gastroenterology and Hepatology, Binzhou Medical University Hospital, Binzhou, Shandong, 256603, China; email: chenyanfeihong0906@163.com
ER  -

TY  - CONF
AU  - Uymaz, H.A.
AU  - Metin, S.K.
TI  - Collaborative Emotion Annotation: Assessing the Intersection of Human and AI Performance with GPT Models
PY  - 2023
T2  - International Joint Conference on Knowledge Discovery, Knowledge Engineering and Knowledge Management, IC3K - Proceedings
VL  - 1
SP  - 298
EP  - 305
DO  - 10.5220/0012183200003598
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85179758970&doi=10.5220%2f0012183200003598&partnerID=40&md5=e21c12d318a4fc2386f0e6e6d7066e54
AD  - İzmir University of Economics, Department of Software Engineering, İzmir, Turkey
AB  - In this study, we explore emotion detection in text, a complex yet vital aspect of human communication. Our focus is on the formation of an annotated dataset, a task that often presents difficulties due to factors such as reliability, time, and consistency. We propose an alternative approach by employing artificial intelligence (AI) models as potential annotators, or as augmentations to human annotators. Specifically, we utilize ChatGPT, an AI language model developed by OpenAI. We use its latest versions, GPT3.5 and GPT4, to label a Turkish dataset having 8290 terms according to Plutchik's emotion categories, alongside three human annotators. We conduct experiments to assess the AI's annotation capabilities both independently and in conjunction with human annotators. We measure inter-rater agreement using Cohen's Kappa, Fleiss Kappa, and percent agreement metrics across varying emotion categorizations- eight, four, and binary. Particularly, when we filtered out the terms where the AI models were indecisive, it was found that including AI models in the annotation process was successful in increasing inter-annotator agreement. Our findings suggest that, the integration of AI models in the emotion annotation process holds the potential to enhance efficiency, reduce the time of lexicon development and thereby advance the field of emotion/sentiment analysis. Copyright © 2023 by SCITEPRESS - Science and Technology Publications, Lda. Under CC license (CC BY-NC-ND 4.0)
KW  - Annotation
KW  - Cohen's Kappa
KW  - Emotion
KW  - Fleiss Kappa
KW  - Lexicon
KW  - Sentiment
KW  - Annotation
KW  - Cohen's kappas
KW  - Emotion
KW  - Emotion detection
KW  - Fleiss' kappas
KW  - Human communications
KW  - Intelligence models
KW  - Lexicon
KW  - Performance
KW  - Sentiment
A2  - Fred A.
A2  - Coenen F.
A2  - Bernardino J.
PB  - Science and Technology Publications, Lda
SN  - 21843228 (ISSN); 978-989758671-2 (ISBN)
LA  - English
J2  - International Joint Conference on Knowledge Discovery, Knowledge Engineering and Knowledge Management, IC3K - Proceedings
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 0; Conference name: 15th International Conference on Knowledge Discovery and Information Retrieval, KDIR 2023 as part of the 15th International Joint Conference on Knowledge Discovery, Knowledge Engineering and Knowledge Management, IC3K 2023; Conference date: 13 November 2023 through 15 November 2023; Conference code: 194821
ER  -

TY  - CONF
AU  - Ferron, A.
AU  - Shore, A.
AU  - Mitra, E.
AU  - Agrawal, A.
TI  - MEEP: Is this Engaging? Prompting Large Language Models for Dialogue Evaluation in Multilingual Settings
PY  - 2023
T2  - Findings of the Association for Computational Linguistics: EMNLP 2023
SP  - 2078
EP  - 2100
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85183309428&partnerID=40&md5=897abc2d88f15962b99352fbcef19298
AD  - Department of Computer Science, Portland State University, United States
AB  - As dialogue systems become more popular, evaluation of their response quality gains importance. Engagingness highly correlates with overall quality and creates a sense of connection that gives human participants a more fulfilling experience. Although qualities like coherence and fluency are readily measured with well-worn automatic metrics, evaluating engagingness often relies on human assessment, which is a costly and time-consuming process. Existing automatic engagingness metrics evaluate the response without the conversation history, are designed for one dataset, or have limited correlation with human annotations. Furthermore, they have been tested exclusively on English conversations. Given that dialogue systems are increasingly available in languages beyond English, multilingual evaluation capabilities are essential. We propose that large language models (LLMs) may be used for evaluation of engagingness in dialogue through prompting, and ask how prompt constructs and translated prompts compare in a multilingual setting. We provide a prompt-design taxonomy for engagingness and find that using selected prompt elements with LLMs, including our comprehensive definition of engagingness, outperforms state-of-the-art methods on evaluation of engagingness in dialogue across multiple languages. © 2023 Association for Computational Linguistics.
KW  - Computational linguistics
KW  - Speech processing
KW  - Automatic metrics
KW  - Design taxonomy
KW  - Dialogue evaluation
KW  - Dialogue systems
KW  - Human annotations
KW  - Human assessment
KW  - Language model
KW  - Multiple languages
KW  - Overall quality
KW  - State-of-the-art methods
KW  - Quality control
PB  - Association for Computational Linguistics (ACL)
SN  - 979-889176061-5 (ISBN)
LA  - English
J2  - Find. Assoc. Comput. Linguist.: EMNLP
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 0; Conference name: 2023 Findings of the Association for Computational Linguistics: EMNLP 2023; Conference date: 6 December 2023 through 10 December 2023; Conference code: 196127
ER  -

TY  - CONF
AU  - Guo, Y.
AU  - Xu, Z.
AU  - Yang, Y.
TI  - Is ChatGPT a Financial Expert? Evaluating Language Models on Financial Natural Language Processing
PY  - 2023
T2  - Findings of the Association for Computational Linguistics: EMNLP 2023
SP  - 815
EP  - 821
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85183296785&partnerID=40&md5=b69e8abcd32d94745940e669e0199909
AD  - The Hong Kong University of Science and Technology, Hong Kong
AB  - The emergence of Large Language Models (LLMs), such as ChatGPT, has revolutionized general natural language preprocessing (NLP) tasks. However, their expertise in the financial domain lacks a comprehensive evaluation. To assess the ability of LLMs to solve financial NLP tasks, we present FinLMEval, a framework for Financial Language Model Evaluation, comprising nine datasets designed to evaluate the performance of language models. This study compares the performance of encoder-only language models and the decoder-only language models. Our findings reveal that while some decoder-only LLMs demonstrate notable performance across most financial tasks via zero-shot prompting, they generally lag behind the fine-tuned expert models, especially when dealing with proprietary datasets. We hope this study provides foundation evaluations for continuing efforts to build more advanced LLMs in the financial domain. © 2023 Association for Computational Linguistics.
KW  - Computational linguistics
KW  - Decoding
KW  - Natural language processing systems
KW  - Zero-shot learning
KW  - Comprehensive evaluation
KW  - Expert modeling
KW  - Financial domains
KW  - Financial experts
KW  - Language model
KW  - Language processing
KW  - Model evaluation
KW  - Natural languages
KW  - Performance
KW  - Finance
PB  - Association for Computational Linguistics (ACL)
SN  - 979-889176061-5 (ISBN)
LA  - English
J2  - Find. Assoc. Comput. Linguist.: EMNLP
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 0; Conference name: 2023 Findings of the Association for Computational Linguistics: EMNLP 2023; Conference date: 6 December 2023 through 10 December 2023; Conference code: 196127
ER  -

TY  - CONF
AU  - Gao, J.
AU  - Ding, X.
AU  - Qin, B.
AU  - Liu, T.
TI  - Is ChatGPT a Good Causal Reasoner? A Comprehensive Evaluation
PY  - 2023
T2  - Findings of the Association for Computational Linguistics: EMNLP 2023
SP  - 11111
EP  - 11126
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85183310419&partnerID=40&md5=d342fb0b500fc21b9f3138520b818d80
AD  - Research Center for Social Computing and Information Retrieval, Harbin Institute of Technology, China
AB  - Causal reasoning ability is crucial for numerous NLP applications. Despite the impressive emerging ability of ChatGPT in various NLP tasks, it is unclear how well ChatGPT performs in causal reasoning. In this paper, we conduct the first comprehensive evaluation of the ChatGPT's causal reasoning capabilities. Experiments show that ChatGPT is not a good causal reasoner, but a good causal explainer. Besides, ChatGPT has a serious hallucination on causal reasoning, possibly due to the reporting biases between causal and non-causal relationships in natural language, as well as ChatGPT's upgrading processes, such as RLHF. The In-Context Learning (ICL) and Chain-of-Thought (CoT) techniques can further exacerbate such causal hallucination. Additionally, the causal reasoning ability of ChatGPT is sensitive to the words used to express the causal concept in prompts, and close-ended prompts perform better than open-ended prompts. For events in sentences, ChatGPT excels at capturing explicit causality rather than implicit causality, and performs better in sentences with lower event density and smaller lexical distance between events. The code is available on https://github.com/ArrogantL/ChatGPT4CausalReasoning. © 2023 Association for Computational Linguistics.
KW  - Computational linguistics
KW  - Causal reasoning
KW  - Causal relationships
KW  - Comprehensive evaluation
KW  - Context learning
KW  - In contexts
KW  - Natural languages
KW  - Reasoners
KW  - Reasoning ability
KW  - Reasoning capabilities
KW  - Reporting bias
KW  - Natural language processing systems
PB  - Association for Computational Linguistics (ACL)
SN  - 979-889176061-5 (ISBN)
LA  - English
J2  - Find. Assoc. Comput. Linguist.: EMNLP
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 1; Correspondence Address: X. Ding; Research Center for Social Computing and Information Retrieval, Harbin Institute of Technology, China; email: xding@ir.hit.edu.cn; Conference name: 2023 Findings of the Association for Computational Linguistics: EMNLP 2023; Conference date: 6 December 2023 through 10 December 2023; Conference code: 196127
ER  -

TY  - JOUR
AU  - Ye, C.
AU  - Zweck, E.
AU  - Ma, Z.
AU  - Smith, J.
AU  - Katz, S.
TI  - Doctor Versus Artificial Intelligence: Patient and Physician Evaluation of Large Language Model Responses to Rheumatology Patient Questions in a Cross-Sectional Study
PY  - 2023
T2  - Arthritis and Rheumatology
DO  - 10.1002/art.42737
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85181249810&doi=10.1002%2fart.42737&partnerID=40&md5=e5397cb48b88dac025ef924c82ca67a7
AD  - University of Alberta, Edmonton, AB, Canada
AD  - University Hospital Düsseldorf, Düsseldorf, Germany
AB  - Objective: The objective of the current study was to assess the quality of large language model (LLM) chatbot versus physician-generated responses to patient-generated rheumatology questions. Methods: We conducted a single-center cross-sectional survey of rheumatology patients (n = 17) in Edmonton, Alberta, Canada. Patients evaluated LLM chatbot versus physician-generated responses for comprehensiveness and readability, with four rheumatologists also evaluating accuracy by using a Likert scale from 1 to 10 (1 being poor, 10 being excellent). Results: Patients rated no significant difference between artificial intelligence (AI) and physician-generated responses in comprehensiveness (mean 7.12 ± SD 0.99 vs 7.52 ± 1.16; P = 0.1962) or readability (7.90 ± 0.90 vs 7.80 ± 0.75; P = 0.5905). Rheumatologists rated AI responses significantly poorer than physician responses on comprehensiveness (AI 5.52 ± 2.13 vs physician 8.76 ± 1.07; P < 0.0001), readability (AI 7.85 ± 0.92 vs physician 8.75 ± 0.57; P = 0.0003), and accuracy (AI 6.48 ± 2.07 vs physician 9.08 ± 0.64; P < 0.0001). The proportion of preference to AI- versus physician-generated responses by patients and physicians was 0.45 ± 0.18 and 0.15 ± 0.08, respectively (P = 0.0106). After learning that one answer for each question was AI generated, patients were able to correctly identify AI-generated answers at a lower proportion compared to physicians (0.49 ± 0.26 vs 0.97 ± 0.04; P = 0.0183). The average word count of AI answers was 69.10 ± 25.35 words, as compared to 98.83 ± 34.58 words for physician-generated responses (P = 0.0008). Conclusion: Rheumatology patients rated AI-generated responses to patient questions similarly to physician-generated responses in terms of comprehensiveness, readability, and overall preference. However, rheumatologists rated AI responses significantly poorer than physician-generated responses, suggesting that LLM chatbot responses are inferior to physician responses, a difference that patients may not be aware of. (Figure presented.). © 2023 The Authors. Arthritis & Rheumatology published by Wiley Periodicals LLC on behalf of American College of Rheumatology.
PB  - John Wiley and Sons Inc
SN  - 23265191 (ISSN)
C2  - 37902018
LA  - English
J2  - Arthritis Rheum.
M3  - Article
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 4; Correspondence Address: C. Ye; University of Alberta, Edmonton, Canada; email: cye@ualberta.ca
ER  -

TY  - CONF
AU  - Ishchenko, A.
AU  - Nibhanupudi, S.S.
AU  - Willemsen, C.
TI  - VALIDATION OF GAUSSIAN MIXTURE LV LOAD MODELS BASED ON MV/LV TRANSFORMER STATIONS MEASUREMENTS
PY  - 2023
T2  - IET Conference Proceedings
VL  - 2023
IS  - 6
SP  - 1948
EP  - 1952
DO  - 10.1049/icp.2023.1084
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85181542244&doi=10.1049%2ficp.2023.1084&partnerID=40&md5=c925da90d7691433d8715690b2c73758
AD  - Phase to Phase B.V., Netherlands
AB  - In today's world, with rapid advancement of technology and the need for a shift towards green energy, it is seen that the power grid especially on the low voltage (LV) side is becoming more complex than ever. Introduction of different appliances has made it harder to comprehend the grid accurately. For this very reason, Gaussian mixture modelling is turned to for modelling of LV load models which is described in this paper. The advantages of this method along with validation for a set of LV networks against the secondary substation measurements is done. Further steps to be taken in order to improve upon this load model are explained in conclusions. © The Institution of Engineering and Technology 2023.
KW  - Gaussian Mixture Model
KW  - Gaussian-mixtures
KW  - Green energy
KW  - Load modeling
KW  - Low voltages
KW  - Low-voltage networks
KW  - Model-based OPC
KW  - Power grids
KW  - Transformer stations
KW  - Voltage transformer
KW  - Electric substations
PB  - Institution of Engineering and Technology
SN  - 27324494 (ISSN)
LA  - English
J2  - IET. Conf. Proc.
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 0; Conference name: 27th International Conference on Electricity Distribution, CIRED 2023; Conference date: 12 June 2023 through 15 June 2023; Conference code: 195672
ER  -

TY  - CONF
AU  - Susanto, A.D.
AU  - Andrian Pradita, S.
AU  - Stryadhi, C.
AU  - Setiawan, K.E.
AU  - Fikri Hasani, M.
TI  - Text Vectorization Techniques for Trending Topic Clustering on Twitter: A Comparative Evaluation of TF-IDF, Doc2Vec, and Sentence-BERT
PY  - 2023
T2  - 2023 5th International Conference on Cybernetics and Intelligent Systems, ICORIS 2023
DO  - 10.1109/ICORIS60118.2023.10352228
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85182392656&doi=10.1109%2fICORIS60118.2023.10352228&partnerID=40&md5=b267d9ac5d2ec3e77e5ec906ea1ba7ee
AD  - School of Computer Science Bina Nusantara University, Computer Science Department, Tangerang, Indonesia
AD  - School of Computer Science Bina Nusantara University, Computer Science Department, Jakarta, Indonesia
AB  - In this digital era, where technology is rapidly advancing, social media has become a primary platform for obtaining and disseminating information. Knowing what is being widely discussed and trending on social media is crucial for important aspects such as politics, economic, social and cultural issues. The objective of this research is to perform clustering on texts or sentences, and within each cluster, identify the most influential keywords that can serve as parameters to determine the topics being discussed in each cluster. Twitter was chosen as the social media platform to be analyzed in this research due to its text-based nature. The clustering method used is DBSCAN, considering that the number of clusters is unknown, and three text embedding techniques to be compared, namely TF-IDF, Doc2Vec, and Sentence-BERT. The performance of clustering with different text embedding techniques were evaluated using the silhouette coefficient. Hyperparameter tuning has been done to find the best-performing hyperparameters. From the best-performing technique, topic finding within the resulting clusters was conducted using Latent Dirichlet allocation (LDA). The results of this research indicated that clustering with DBSCAN and TF-IDF, with the highest silhouette coefficient, namely -0.00001, produced one cluster and 3342 outliers. DBSCAN and Doc2Vec, with the highest silhouette coefficient, namely 0.71590, produced one cluster and one outlier. DBSCAN and Sentence-BERT, with the highest silhouette coefficient, namely -0.02425, produced two clusters and two outliers. Based on the research findings, smaller silhouette scores tend to have a more varied number of clusters. DBSCAN with each tested text embeddings showed that the topic for every cluster, except for the first cluster of DBSCAN that use Sentence-BERT, were COVID-19 related topic. The DBSCAN and Sentence-BERT model, despite having a lower silhouette score, successfully identifies two separate clusters with distinct topics, whereas the other models only identify a single cluster.  © 2023 IEEE.
KW  - clustering
KW  - Sentence-BERT
KW  - TF-IDF
KW  - vectorization
KW  - Word2Vec
KW  - COVID-19
KW  - Information dissemination
KW  - Social networking (online)
KW  - Statistics
KW  - Clusterings
KW  - Embedding technique
KW  - Hyper-parameter
KW  - Number of clusters
KW  - Sentence-BERT
KW  - Social media
KW  - TF-IDF
KW  - Vectorization
KW  - Vectorization techniques
KW  - Word2vec
KW  - Embeddings
PB  - Institute of Electrical and Electronics Engineers Inc.
SN  - 979-835036948-9 (ISBN)
LA  - English
J2  - Int. Conf. Cybern. Intell. Syst., ICORIS
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 0; Correspondence Address: A.D. Susanto; School of Computer Science Bina Nusantara University, Computer Science Department, Tangerang, Indonesia; email: alvian.susanto@binus.ac.id; Conference name: 5th International Conference on Cybernetics and Intelligent Systems, ICORIS 2023; Conference date: 6 October 2023 through 7 October 2023; Conference code: 195656
ER  -

TY  - JOUR
AU  - Cevik, J.
AU  - Lim, B.
AU  - Seth, I.
AU  - Sofiadellis, F.
AU  - Ross, R.J.
AU  - Cuomo, R.
AU  - Rozen, W.M.
TI  - Assessment of the bias of artificial intelligence generated images and large language models on their depiction of a surgeon
PY  - 2023
T2  - ANZ Journal of Surgery
DO  - 10.1111/ans.18792
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85179326269&doi=10.1111%2fans.18792&partnerID=40&md5=0da9f7ed185260b64e60530fb699317b
AD  - Department of Plastic Surgery, Peninsula Health, Melbourne, 3199, VIC, Australia
AD  - The Alfred Centre, Central Clinical School at Monash University, 99 Commercial Rd, Melbourne, 3004, VIC, Australia
AD  - Plastic Surgery Unit, Department of Medicine, Surgery and Neuroscience, University of Siena, Siena, 53100, Italy
PB  - John Wiley and Sons Inc
SN  - 14451433 (ISSN)
LA  - English
J2  - ANZ J. Surg.
M3  - Article
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 0; CODEN: AJSNB
ER  -

TY  - CONF
AU  - Li, Z.
AU  - Arous, I.
AU  - Reddy, S.
AU  - Cheung, J.C.K.
TI  - Evaluating Dependencies in Fact Editing for Language Models: Specificity and Implication Awareness
PY  - 2023
T2  - Findings of the Association for Computational Linguistics: EMNLP 2023
SP  - 7623
EP  - 7626
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85182834576&partnerID=40&md5=bd573744a7fd512233a025afe734c109
AD  - Mila, McGill University, Canada
AB  - The potential of using a large language model (LLM) as a knowledge base (KB) has sparked significant interest. To manage the knowledge acquired by LLMs, we need to ensure that the editing of learned facts respects internal logical constraints, which are known as dependency of knowledge. Existing work on editing LLMs has partially addressed the issue of dependency, when the editing of a fact should apply to its lexical variations without disrupting irrelevant ones. However, they neglect the dependency between a fact and its logical implications. We propose an evaluation protocol with an accompanying question-answering dataset, DepEdit, that provides a comprehensive assessment of the editing process considering the above notions of dependency. Our protocol involves setting up a controlled environment in which we edit facts and monitor their impact on LLMs, along with their implications based on If-Then rules. Extensive experiments on DepEdit show that existing knowledge editing methods are sensitive to the surface form of knowledge, and that they have limited performance in inferring the implications of edited facts. © 2023 Association for Computational Linguistics.
KW  - Computational linguistics
KW  - Natural language processing systems
KW  - Comprehensive assessment
KW  - Controlled environment
KW  - Evaluation protocol
KW  - If-then rules
KW  - Language model
KW  - Logical constraints
KW  - Logical implications
KW  - Performance
KW  - Question Answering
KW  - Surface forms
KW  - Knowledge based systems
PB  - Association for Computational Linguistics (ACL)
SN  - 979-889176061-5 (ISBN)
LA  - English
J2  - Find. Assoc. Comput. Linguist.: EMNLP
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 0; Conference name: 2023 Findings of the Association for Computational Linguistics: EMNLP 2023; Conference date: 6 December 2023 through 10 December 2023; Conference code: 196127
ER  -

TY  - CONF
AU  - Marivate, V.
AU  - Mots’Oehli, M.
AU  - Wagnerinst, V.
AU  - Lastrucci, R.
AU  - Dzingirai, I.
TI  - PuoBERTa: Training and Evaluation of a Curated Language Model for Setswana
PY  - 2023
T2  - Communications in Computer and Information Science
VL  - 1976 CCIS
SP  - 253
EP  - 266
DO  - 10.1007/978-3-031-49002-6_17
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85180532694&doi=10.1007%2f978-3-031-49002-6_17&partnerID=40&md5=908bba47afb697d88fac3136b73e97a8
AD  - Department of Computer Science, University of Pretoria, Hatfield, South Africa
AD  - Lelapa AI, Johannesburg, South Africa
AD  - University of Hawaii at Manoa, Honolulu, United States
AD  - Sol Plaatje University, Kimberley, South Africa
AB  - Natural language processing (NLP) has made significant progress for well-resourced languages such as English but lagged behind for low-resource languages like Setswana. This paper addresses this gap by presenting PuoBERTa, a customised masked language model trained specifically for Setswana. We cover how we collected, curated, and prepared diverse monolingual texts to generate a high-quality corpus for PuoBERTa’s training. Building upon previous efforts in creating monolingual resources for Setswana, we evaluated PuoBERTa across several NLP tasks, including part-of-speech (POS) tagging, named entity recognition (NER), and news categorisation. Additionally, we introduced a new Setswana news categorisation dataset and provided the initial benchmarks using PuoBERTa. Our work demonstrates the efficacy of PuoBERTa in fostering NLP capabilities for understudied languages like Setswana and paves the way for future research directions. © 2023, The Author(s), under exclusive license to Springer Nature Switzerland AG.
KW  - Language Models
KW  - Natural Language Processing
KW  - Setswana
KW  - Natural language processing systems
KW  - Speech recognition
KW  - High quality
KW  - Language model
KW  - Language processing
KW  - Low resource languages
KW  - Monolingual texts
KW  - Natural language processing
KW  - Natural languages
KW  - Part of speech tagging
KW  - Parts-of-speech tagging
KW  - Setswanum
KW  - Computational linguistics
A2  - Pillay A.
A2  - Jembere E.
A2  - J. Gerber A.
PB  - Springer Science and Business Media Deutschland GmbH
SN  - 18650929 (ISSN); 978-303149001-9 (ISBN)
LA  - English
J2  - Commun. Comput. Info. Sci.
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 0; Correspondence Address: V. Marivate; Department of Computer Science, University of Pretoria, Hatfield, South Africa; email: vukosi.marivate@cs.up.ac.za; Conference name: 4th Southern African Conference for Artificial Intelligence Research, SACAIR 2023; Conference date: 4 December 2023 through 8 December 2023; Conference code: 305769
ER  -

TY  - JOUR
AU  - Alabidi, S.
AU  - Alarabi, K.
AU  - Alsalhi, N.R.
AU  - Mansoori, M.A.
TI  - The Dawn of ChatGPT: Transformation in Science Assessment
PY  - 2023
T2  - Eurasian Journal of Educational Research
VL  - 2023
IS  - 106
SP  - 321
EP  - 337
DO  - 10.14689/ejer.2023.106.019
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85183202337&doi=10.14689%2fejer.2023.106.019&partnerID=40&md5=51a17f964cc6cb305d676ab4199fb2ff
AD  - College of Education, Humanities and Social Sciences, Al Ain University, United Arab Emirates
AD  - College of Arts, Humanities, and Social Sciences, University of Sharjah, Sharjah, United Arab Emirates
AB  - The integration of Artificial Intelligence (AI) and ChatGPT in assessment has brought about a notable transformation in science education. The present study has undertaken an analysis of the limitations inherent in conventional assessments rooted in behaviourism while emphasising the significance of authentic assessments grounded in cognitivist principles. Furthermore, the utilisation of ChatGPT has demonstrated its capacity as a valuable instrument for the creation of interactive, customised, and captivating evaluation opportunities within the realm of science education. Educators have the potential to adopt AI technology in order to facilitate a transformative departure from passive recall-based assessments towards interactive and immersive learning experiences. The utilisation of ChatGPT's simulated interactions, individualised feedback, and adaptive assessment facilitates students' ability to actively participate in authentic scientific inquiry, employ critical thinking skills, and engage in problem-solving activities. In light of the evolving educational landscape, it is imperative to undertake a thorough examination and exploration of the potential impact of artificial intelligence (AI) on the future of science assessment. © 2023 Ani Publishing Ltd. All rights reserved.
KW  - Authentic Assessment
KW  - ChatGPT
KW  - Science Assessment
KW  - Traditional Assessment
PB  - Ani Publishing
SN  - 1302597X (ISSN)
LA  - English
J2  - Eurasian J. Educ. Res.
M3  - Article
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 0; Correspondence Address: N.R. Alsalhi; College of Arts, Humanities, and Social Sciences, University of Sharjah, Sharjah, United Arab Emirates; email: nalsalhi@sharjah.ac.ae
ER  -

TY  - CONF
AU  - Chen, Z.
AU  - Zhang, C.
AU  - Wang, Q.
AU  - Troidl, J.
AU  - Warchol, S.
AU  - Beyer, J.
AU  - Gehlenborg, N.
AU  - Pfister, H.
TI  - Beyond Generating Code: Evaluating GPT on a Data Visualization Course
PY  - 2023
T2  - Proceedings - 2023 IEEE VIS Workshop on Visualization Education, Literacy, and Activities, EduVis 2023
SP  - 16
EP  - 21
DO  - 10.1109/EduVis60792.2023.00009
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85182311001&doi=10.1109%2fEduVis60792.2023.00009&partnerID=40&md5=d70fbd6eb55a0b3578aa4f10899a7e21
AD  - Harvard University, John A. Paulson School of Engineering and Applied Sciences, United States
AD  - Research Intern in Harvard, United States
AD  - Harvard Medical School, Biomedical Informatics, United States
AB  - This paper presents an empirical evaluation of the performance of the Generative Pre-trained Transformer (GPT) model in Harvard's CS171 data visualization course. While previous studies have focused on GPT's ability to generate code for visualizations, this study goes beyond code generation to evaluate GPT's abilities in various visualization tasks, such as data interpretation, visualization design, visual data exploration, and insight communication. The evaluation utilized GPT-3.5 and GPT-4 through the APIs of OpenAI to complete assignments of CS171, and included a quantitative assessment based on the established course rubrics, a qualitative analysis informed by the feedback of three experienced graders, and an exploratory study of GPT's capabilities in completing border visualization tasks. Findings show that GPT-4 scored 80% on quizzes and homework, and Teaching Fellows could distinguish between GPT-and human-generated homework with 70% accuracy. The study also demonstrates GPT's potential in completing various visualization tasks, such as data cleanup, interaction with visualizations, and insight communication. The paper concludes by discussing the strengths and limitations of GPT in data visualization, potential avenues for incorporating GPT in broader visualization tasks, and the need to redesign visualization education.  © 2023 IEEE.
KW  - Codes (symbols)
KW  - Data visualization
KW  - Codegeneration
KW  - Data interpretation
KW  - Empirical evaluations
KW  - Harvard
KW  - Performance
KW  - Qualitative analysis
KW  - Quantitative assessments
KW  - Transformer modeling
KW  - Visual data exploration
KW  - Visualization designs
KW  - Visualization
PB  - Institute of Electrical and Electronics Engineers Inc.
SN  - 979-835033030-4 (ISBN)
LA  - English
J2  - Proc. - IEEE VIS Workshop Vis. Educ., Lit., Act., EduVis
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 0; Correspondence Address: H. Pfister; Harvard University, John A. Paulson School of Engineering and Applied Sciences, United States; email: pfister@seas.harvard.edu; J. Troidl; Harvard University, John A. Paulson School of Engineering and Applied Sciences, United States; email: jtroidl@seas.harvard.edu; S. Warchol; Harvard University, John A. Paulson School of Engineering and Applied Sciences, United States; email: simonwarchol@seas.harvard.edu; J. Beyer; Harvard University, John A. Paulson School of Engineering and Applied Sciences, United States; email: jbeyer@seas.harvard.edu; Z. Chen; Harvard University, John A. Paulson School of Engineering and Applied Sciences, United States; email: ztchen@seas.harvard.edu; Conference name: 1st IEEE VIS Workshop on Visualization Education, Literacy, and Activities, EduVis 2023; Conference date: 22 October 2023 through 23 October 2023; Conference code: 195413
ER  -

TY  - CONF
AU  - Mei, A.
AU  - Levy, S.
AU  - Wang, W.Y.
TI  - ASSERT: Automated Safety Scenario Red Teaming for Evaluating the Robustness of Large Language Models
PY  - 2023
T2  - Findings of the Association for Computational Linguistics: EMNLP 2023
SP  - 5841
EP  - 5847
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85183299887&partnerID=40&md5=fc6d5f86c7c0010de286008b12b00c27
AD  - University of California, Santa Barbara, Santa Barbara, CA, United States
AB  - As large language models are integrated into society, robustness toward a suite of prompts is increasingly important to maintain reliability in a high-variance environment. Robustness evaluations must comprehensively encapsulate the various settings in which a user may invoke an intelligent system. This paper proposes ASSERT, Automated Safety ScEnario Red Teaming, consisting of three methods - semantically aligned augmentation, target bootstrapping, and adversarial knowledge injection. For robust safety evaluation, we apply these methods in the critical domain of AI safety to algorithmically generate a test suite of prompts covering diverse robustness settings - semantic equivalence, related scenarios, and adversarial. We partition our prompts into four safety domains for a fine-grained analysis of how the domain affects model performance. Despite dedicated safeguards in existing state-of-the-art models, we find statistically significant performance differences of up to 11% in absolute classification accuracy among semantically related scenarios and error rates of up to 19% absolute error in zero-shot adversarial settings, raising concerns for users' physical safety. © 2023 Association for Computational Linguistics.
KW  - Classification (of information)
KW  - Computational linguistics
KW  - Intelligent systems
KW  - Zero-shot learning
KW  - Affect modeling
KW  - Critical domain
KW  - Fine-grained analysis
KW  - Language model
KW  - Modeling performance
KW  - Red teaming
KW  - Robustness evaluation
KW  - Safety evaluations
KW  - Semantic equivalences
KW  - State of the art
KW  - Semantics
PB  - Association for Computational Linguistics (ACL)
SN  - 979-889176061-5 (ISBN)
LA  - English
J2  - Find. Assoc. Comput. Linguist.: EMNLP
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 0; Conference name: 2023 Findings of the Association for Computational Linguistics: EMNLP 2023; Conference date: 6 December 2023 through 10 December 2023; Conference code: 196127
ER  -

TY  - CONF
AU  - Zhan, H.
AU  - Ong, D.C.
AU  - Li, J.J.
TI  - Evaluating Subjective Cognitive Appraisals of Emotions from Large Language Models
PY  - 2023
T2  - Findings of the Association for Computational Linguistics: EMNLP 2023
SP  - 14418
EP  - 14446
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85183290677&partnerID=40&md5=88bfe73cffe8c6d06e337e5c4a0fa3d5
AD  - Department of Linguistics, The University of Texas, Austin, United States
AD  - Department of Psychology, The University of Texas, Austin, United States
AB  - The emotions we experience involve complex processes; besides physiological aspects, research in psychology has studied cognitive appraisals where people assess their situations subjectively, according to their own values (Scherer, 2005). Thus, the same situation can often result in different emotional experiences. While the detection of emotion is a well-established task, there is very limited work so far on the automatic prediction of cognitive appraisals. This work fills the gap by presenting COVIDET-APPRAISALS, the most comprehensive dataset to-date that assesses 24 appraisal dimensions, each with a natural language rationale, across 241 Reddit posts. COVIDET-APPRAISALS presents an ideal testbed to evaluate the ability of large language models - excelling at a wide range of NLP tasks - to automatically assess and explain cognitive appraisals. We found that while the best models are performant, open-sourced LLMs fall short at this task, presenting a new challenge in the future development of emotionally intelligent models. We release our dataset at https://github.com/honglizhan/CovidET-Appraisals-Public. © 2023 Association for Computational Linguistics.
KW  - Computational linguistics
KW  - Physiological models
KW  - Psychophysiology
KW  - Automatic prediction
KW  - Best model
KW  - Cognitive appraisal
KW  - Complex Processes
KW  - Emotional experiences
KW  - Intelligent models
KW  - Language model
KW  - Natural languages
KW  - Natural language processing systems
PB  - Association for Computational Linguistics (ACL)
SN  - 979-889176061-5 (ISBN)
LA  - English
J2  - Find. Assoc. Comput. Linguist.: EMNLP
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 0; Conference name: 2023 Findings of the Association for Computational Linguistics: EMNLP 2023; Conference date: 6 December 2023 through 10 December 2023; Conference code: 196127
ER  -

TY  - CONF
AU  - Jui, J.H.
AU  - Hauskrecht, M.
TI  - Uncovering the Effects of Genes, Proteins, and Medications on Functions of Wound Healing: A Dependency Rule-Based Text Mining Approach Leveraging GPT-4 based Evaluation
PY  - 2023
T2  - BHI 2023 - IEEE-EMBS International Conference on Biomedical and Health Informatics, Proceedings
DO  - 10.1109/BHI58575.2023.10313354
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85179523725&doi=10.1109%2fBHI58575.2023.10313354&partnerID=40&md5=b0dc96d387d6dd42c064b37636800e2f
AD  - University of Pittsburgh, Department of Computer Science, Pittsburgh, 15260, PA, United States
AB  - Wound healing is a complex biological process characterized by intricate cellular and molecular interactions. Understanding the underlying mechanisms and the effects of different biological entities, such as genes, proteins, and medications, on the cellular and biological functions of wound healing is of paramount importance for the development of effective therapeutic interventions. In this paper, we present a text-mining approach aimed to explore and unravel the complex regulatory relationships of genes, proteins, and medications with the biological mechanisms of wound healing. Our approach relies on a set of predefined dependency rules to capture the relationships between biological entities and their target functions from text. By leveraging advanced AI technology like Generative Pre-trained Transformer 4 (GPT-4), also known as ChatGPT, we evaluate the accuracy and quality of the extracted relations. We present a detailed discussion of the encouraging preliminary results that validate the efficacy of our model in identifying potential therapeutic targets in the complex biological system. © 2023 IEEE.
KW  - Biological Function
KW  - GPT-4
KW  - Medline
KW  - Relation Extraction
KW  - Wound Healing
KW  - Bioinformatics
KW  - Biological systems
KW  - Data mining
KW  - Function evaluation
KW  - Proteins
KW  - Quality control
KW  - Biological entities
KW  - Biological functions
KW  - Biological process
KW  - Dependency rules
KW  - Generative pre-trained transformer 4
KW  - Medline
KW  - Relation extraction
KW  - Rule based
KW  - Text-mining
KW  - Wound healing
KW  - Genes
PB  - Institute of Electrical and Electronics Engineers Inc.
SN  - 979-835031050-4 (ISBN)
LA  - English
J2  - BHI - IEEE-EMBS Int. Conf. Biomed. Health Informatics, Proc.
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 0; Correspondence Address: J.H. Jui; University of Pittsburgh, Department of Computer Science, Pittsburgh, 15260, United States; email: jaj146@pitt.edu; Conference name: 2023 IEEE-EMBS International Conference on Biomedical and Health Informatics, BHI 2023; Conference date: 15 October 2023 through 18 October 2023; Conference code: 194485
ER  -

TY  - JOUR
AU  - Fatemi, B.
AU  - Rabbi, F.
AU  - Opdahl, A.L.
TI  - Evaluating the Effectiveness of GPT Large Language Model for News Classification in the IPTC News Ontology
PY  - 2023
T2  - IEEE Access
VL  - 11
SP  - 145386
EP  - 145394
DO  - 10.1109/ACCESS.2023.3345414
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85181543202&doi=10.1109%2fACCESS.2023.3345414&partnerID=40&md5=736a0a3be5737ac23440240ea35496f1
AD  - University of Bergen, Department of Information Science and Media Studies, Bergen, 5007, Norway
AB  - News classification plays a vital role in newsrooms, as it involves the time-consuming task of categorizing news articles and requires domain knowledge. Effective news classification is essential for categorizing and organizing a constant flow of information, serving as the foundation for subsequent tasks, such as news aggregation, monitoring, filtering, and organization. The automation of this process can significantly benefit newsrooms by saving time and resources. In this study, we explore the potential of the GPT large language model in a zero-shot setting for multi-class classification of news articles within the widely accepted International Press Telecommunications Council (IPTC) news ontology. The IPTC news ontology provides a structured framework for categorizing news, facilitating the efficient organization and retrieval of news content. By investigating the effectiveness of the GPT language model in this classification task, we aimed to understand its capabilities and potential applications in the news domain. This study was conducted as part of our ongoing research in the field of automated journalism. © 2013 IEEE.
KW  - IPTC media topics
KW  - journalism
KW  - large language models
KW  - news classification
KW  - Classification (of information)
KW  - Computational linguistics
KW  - Information filtering
KW  - Job analysis
KW  - Zero-shot learning
KW  - Adaptation models
KW  - Annotation
KW  - International press telecommunication council medium topic
KW  - International press telecommunications councils
KW  - Journalism
KW  - Language model
KW  - Large language model
KW  - News classification
KW  - Ontology's
KW  - Support vectors machine
KW  - Tag clouds
KW  - Task analysis
KW  - Ontology
PB  - Institute of Electrical and Electronics Engineers Inc.
SN  - 21693536 (ISSN)
LA  - English
J2  - IEEE Access
M3  - Article
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 0; Correspondence Address: B. Fatemi; University of Bergen, Department of Information Science and Media Studies, Bergen, 5007, Norway; email: Bahareh.Fatemi@uib.no; F. Rabbi; University of Bergen, Department of Information Science and Media Studies, Bergen, 5007, Norway; email: Fazle.Rabbi@uib.no
ER  -

TY  - JOUR
AU  - Hwang, Y.-S.
AU  - Um, J.-S.
AU  - Pradhan, B.
AU  - Choudhury, T.
AU  - Schlueter, S.
TI  - How does ChatGPT evaluate the value of spatial information in the 4th industrial revolution?
PY  - 2023
T2  - Spatial Information Research
DO  - 10.1007/s41324-023-00567-5
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85179357690&doi=10.1007%2fs41324-023-00567-5&partnerID=40&md5=d6d3d57cc0363b3c416c019d92afca92
AD  - Department of Spatial Information Science, Kyungpook National University, Daegu, 41566, South Korea
AD  - Department of Geography, Kyungpook National University, Daegu, 41566, South Korea
AD  - Centre for Advanced Modelling and Geospatial Information Systems (CAMGIS), School of Civil and Environmental Engineering, University of Technology Sydney, Sydney, 2007, NSW, Australia
AD  - Earth Observation Centre, Institute of Climate Change, Universiti Kebangsaan Malaysia, Selangor, Bangi, 43600 UKM, Malaysia
AD  - CSE Dept, Symbiosis Institute of Technology, Symbiosis International (Deemed University), Maharashtra, Pune, 412115, India
AD  - Department of Mathematics, Natural and Economic Sciences, Ulm University of Applied Sciences, Ulm, 89075, Germany
AB  - Chat Generative Pre-trained Transformer (ChatGPT), developed by OpenAI, is a prominent AI model capable of understanding and generating human-like text based on input. Since terms and concepts of spatial information are contextual, the applications of ChatGPT on spatial information disciplines can be biased by the perceptions and perspectives of ChatGPT towards spatial information. Therefore, a thorough understanding of the real magnitude and level of comprehension of spatial information by ChatGPT is essential before exploring its potential applications in spatial information disciplines. This article aims to investigate how ChatGPT evaluates spatial information and its potential contributions to 4th Industrial Revolution (Industry 4.0). ChatGPT has summarized a notable perspective on evaluating and utilizing spatial information in the context of the Industry 4.0. The result of this study shows that ChatGPT has a good understanding on contextual concepts related to spatial information. However, it exhibits potential biases and challenges, as its responses lean towards the technological and analytical aspects. The results provide a crucial understanding on how to leverage ChatGPT’s benefits to the fullest while recognizing its constraints, with the aim to enhance the efficacy from the perspective of applications linked to spatial information. © 2023, The Author(s).
KW  - 4th Industrial Revolution
KW  - ChatGPT
KW  - Perception
KW  - Spatial information
PB  - Springer Science and Business Media B.V.
SN  - 23663294 (ISSN)
LA  - English
J2  - Spat. Inf. Res.
M3  - Review
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 0; Correspondence Address: S. Schlueter; Department of Mathematics, Natural and Economic Sciences, Ulm University of Applied Sciences, Ulm, 89075, Germany; email: Stephan.Schlueter@thu.de
ER  -

TY  - CONF
AU  - Murty, S.
AU  - Paradise, O.
AU  - Sharma, P.
TI  - Pseudointelligence: A Unifying Framework for Language Model Evaluation
PY  - 2023
T2  - Findings of the Association for Computational Linguistics: EMNLP 2023
SP  - 7284
EP  - 7290
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85183306715&partnerID=40&md5=d99836b92d5aa18c4079538e3d761dec
AD  - Stanford University, United States
AD  - UC Berkeley, United States
AD  - MIT, United States
AB  - With large language models surpassing human performance on an increasing number of benchmarks, we must take a principled approach for targeted evaluation of model capabilities. Inspired by pseudorandomness, we propose pseudointelligence, which captures the maxim that “(perceived) intelligence lies in the eye of the beholder.” That is, that claims of intelligence are meaningful only when their evaluator is taken into account. Concretely, we propose a complexity-theoretic framework of model evaluation cast as a dynamic interaction between a model and a learned evaluator. We demonstrate that this framework can be used to reason about two case studies in language model evaluation, as well as analyze existing evaluation methods. © 2023 Association for Computational Linguistics.
KW  - Computational linguistics
KW  - Petroleum reservoir evaluation
KW  - Case-studies
KW  - Dynamic interaction
KW  - Evaluation methods
KW  - Human performance
KW  - Language model
KW  - Model evaluation
KW  - Modeling analyzes
KW  - Pseudorandomness
KW  - Benchmarking
PB  - Association for Computational Linguistics (ACL)
SN  - 979-889176061-5 (ISBN)
LA  - English
J2  - Find. Assoc. Comput. Linguist.: EMNLP
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 0; Conference name: 2023 Findings of the Association for Computational Linguistics: EMNLP 2023; Conference date: 6 December 2023 through 10 December 2023; Conference code: 196127
ER  -

TY  - CONF
AU  - Klamra, C.
AU  - Kryńska, K.
AU  - Ogrodniczuk, M.
TI  - Evaluating the Use of Generative LLMs for Intralingual Diachronic Translation of Middle-Polish Texts into Contemporary Polish
PY  - 2023
T2  - Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)
VL  - 14457 LNCS
SP  - 18
EP  - 27
DO  - 10.1007/978-981-99-8085-7_2
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85180151374&doi=10.1007%2f978-981-99-8085-7_2&partnerID=40&md5=2e9a5b03e921da348e70544edf5f9ed7
AD  - Institute of Computer Science, Polish Academy of Sciences, Jana Kazimierza 5, Warszawa, 01-248, Poland
AD  - Institute of Polish Language, Polish Academy of Sciences, al. Mickiewicza 31, Kraków, 31-120, Poland
AB  - This paper presents efforts towards creating a tool for translating texts from Middle Polish into modern Polish. Archaic texts sourced from the CBDU digital library were translated into modern language using ChatGPT and the resulting parallel corpus was used to train a neural text-to-text model. We assessed the results using automatic metrics and performed human evaluation of translations of the best-performing model and ChatGPT. Even though the performance of the trained models was far from perfect, the quality of translations produced with ChatGPT was good in most cases. Although caution should be exercised, we believe that LLMs have a high potential for text-to-text annotation applications. © 2023, The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd.
KW  - Automatic annotation
KW  - Intralingual diachronic translation
KW  - Large Language Models
KW  - Translation (languages)
KW  - Automatic annotation
KW  - Automatic metrics
KW  - Human evaluation
KW  - Intralingual diachronic translation
KW  - Language model
KW  - Large language model
KW  - Modern languages
KW  - Parallel corpora
KW  - Performance
KW  - Text modeling
KW  - Digital libraries
A2  - Goh D.H.
A2  - Chen S.-J.
A2  - Tuarob S.
PB  - Springer Science and Business Media Deutschland GmbH
SN  - 03029743 (ISSN); 978-981998084-0 (ISBN)
LA  - English
J2  - Lect. Notes Comput. Sci.
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 0; Correspondence Address: M. Ogrodniczuk; Institute of Computer Science, Polish Academy of Sciences, Warszawa, Jana Kazimierza 5, 01-248, Poland; email: maciej.ogrodniczuk@ipipan.waw.pl; Conference name: 25th International Conference on Asia-Pacific Digital Libraries, ICADL 2023; Conference date: 4 December 2023 through 7 December 2023; Conference code: 305139
ER  -

TY  - JOUR
AU  - Nguyen, D.
AU  - Swanson, D.
AU  - Newbury, A.
AU  - Kim, Y.H.
TI  - Evaluation of ChatGPT and Google Bard Using Prompt Engineering in Cancer Screening Algorithms
PY  - 2023
T2  - Academic Radiology
DO  - 10.1016/j.acra.2023.11.002
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85180340892&doi=10.1016%2fj.acra.2023.11.002&partnerID=40&md5=83720d73618ef8522591f9e9e28e7d1b
AD  - University of Massachusetts Chan Medical School, Worcester, Massachusetts, United States
AD  - Department of Radiology, University of Massachusetts Chan Medical School, Worcester, Massachusetts, United States
AB  - Large language models (LLMs) such as ChatGPT and Bard have emerged as powerful tools in medicine, showcasing strong results in tasks such as radiology report translations and research paper drafting. While their implementation in clinical practice holds promise, their response accuracy remains variable. This study aimed to evaluate the accuracy of ChatGPT and Bard in clinical decision-making based on the American College of Radiology Appropriateness Criteria for various cancers. Both LLMs were evaluated in terms of their responses to open-ended (OE) and select-all-that-apply (SATA) prompts. Furthermore, the study incorporated prompt engineering (PE) techniques to enhance the accuracy of LLM outputs. The results revealed similar performances between ChatGPT and Bard on OE prompts, with ChatGPT exhibiting marginally higher accuracy in SATA scenarios. The introduction of PE also marginally improved LLM outputs in OE prompts but did not enhance SATA responses. The results highlight the potential of LLMs in aiding clinical decision-making processes, especially when guided by optimally engineered prompts. Future studies in diverse clinical situations are imperative to better understand the impact of LLMs in radiology. © 2023 The Association of University Radiologists
PB  - Elsevier Inc.
SN  - 10766332 (ISSN)
C2  - 38103973
LA  - English
J2  - Acad. Radiol.
M3  - Article
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 0; Correspondence Address: D. Nguyen; University of Massachusetts Chan Medical School, Worcester, United States; email: dan.nguyen@umassmed.edu; CODEN: ARADF
ER  -

TY  - CONF
AU  - Karmaker, S.K.
AU  - Feng, D.
TI  - TELeR: A General Taxonomy of LLM Prompts for Benchmarking Complex Tasks
PY  - 2023
T2  - Findings of the Association for Computational Linguistics: EMNLP 2023
SP  - 14197
EP  - 14203
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85182847863&partnerID=40&md5=df1fa11f9ba781bb319ce2539775c580
AD  - Big Data Intelligence (BDI) Lab, Department of Computer Science & Software Engineering, Auburn University, AL, United States
AB  - While LLMs have shown great success in understanding and generating text in traditional conversational settings, their potential for performing ill-defined complex tasks is largely under-studied and yet to be benchmarked. However, conducting such benchmarking studies is challenging because of the large variations in LLMs' performance when different prompt types/styles are used and different degrees of detail are provided in the prompts. To address this issue, this paper proposes a general taxonomy that can be used to design prompts with specific properties in order to perform a wide range of complex tasks. This taxonomy will allow future benchmarking studies to report the specific categories of prompts used as part of the study, enabling meaningful comparisons across different studies. Also, by establishing a common standard through this taxonomy, researchers will be able to draw more accurate conclusions about LLMs' performance on a specific complex task. © 2023 Association for Computational Linguistics.
KW  - Benchmarking
KW  - Computational linguistics
KW  - Common standards
KW  - Complex task
KW  - Performance
KW  - Specific properties
KW  - Taxonomies
PB  - Association for Computational Linguistics (ACL)
SN  - 979-889176061-5 (ISBN)
LA  - English
J2  - Find. Assoc. Comput. Linguist.: EMNLP
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 0; Conference name: 2023 Findings of the Association for Computational Linguistics: EMNLP 2023; Conference date: 6 December 2023 through 10 December 2023; Conference code: 196127
ER  -

TY  - CONF
AU  - Gómez-Rodríguez, C.
AU  - Williams, P.
TI  - A Confederacy of Models: a Comprehensive Evaluation of LLMs on Creative Writing
PY  - 2023
T2  - Findings of the Association for Computational Linguistics: EMNLP 2023
SP  - 14504
EP  - 14528
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85183293377&partnerID=40&md5=33539624769389cf012ae9fdfa861d09
AD  - Universidade da Coruña, CITIC Department of CS and IT, A Coruña, 15071, Spain
AD  - School of Business & Creative Industries, University of the Sunshine Coast, Sunshine Coast, Australia
AB  - We evaluate a range of recent LLMs on English creative writing, a challenging and complex task that requires imagination, coherence, and style. We use a difficult, open-ended scenario chosen to avoid training data reuse: an epic narration of a single combat between Ignatius J. Reilly, the protagonist of the Pulitzer Prize-winning novel A Confederacy of Dunces (1980), and a pterodactyl, a prehistoric flying reptile. We ask several LLMs and humans to write such a story and conduct a human evalution involving various criteria such as fluency, coherence, originality, humor, and style. Our results show that some state-of-the-art commercial LLMs match or slightly outperform our writers in most dimensions; whereas opensource LLMs lag behind. Humans retain an edge in creativity, while humor shows a binary divide between LLMs that can handle it comparably to humans and those that fail at it. We discuss the implications and limitations of our study and suggest directions for future research. © 2023 Association for Computational Linguistics.
KW  - Complex task
KW  - Comprehensive evaluation
KW  - Creative writings
KW  - Data reuse
KW  - Open-source
KW  - Pulitzer prize
KW  - State of the art
KW  - Training data
PB  - Association for Computational Linguistics (ACL)
SN  - 979-889176061-5 (ISBN)
LA  - English
J2  - Find. Assoc. Comput. Linguist.: EMNLP
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 0; Conference name: 2023 Findings of the Association for Computational Linguistics: EMNLP 2023; Conference date: 6 December 2023 through 10 December 2023; Conference code: 196127
ER  -

TY  - JOUR
AU  - Peng, Z.
AU  - Ma, R.
AU  - Zhang, Y.
AU  - Yan, M.
AU  - Lu, J.
AU  - Cheng, Q.
AU  - Liao, J.
AU  - Zhang, Y.
AU  - Wang, J.
AU  - Zhao, Y.
AU  - Zhu, J.
AU  - Qin, B.
AU  - Jiang, Q.
AU  - Shi, F.
AU  - Qian, J.
AU  - Chen, X.
AU  - Zhao, C.
TI  - Development and evaluation of multimodal AI for diagnosis and triage of ophthalmic diseases using ChatGPT and anterior segment images: protocol for a two-stage cross-sectional study
PY  - 2023
T2  - Frontiers in Artificial Intelligence
VL  - 6
C7  - 1323924
DO  - 10.3389/frai.2023.1323924
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85180423768&doi=10.3389%2ffrai.2023.1323924&partnerID=40&md5=7b68fede0b741577331ac0733124150d
AD  - Department of Ophthalmology, Fudan Eye & ENT Hospital, Shanghai, China
AD  - Department of Ophthalmology, The First Affiliated Hospital, Zhejiang University School of Medicine, Zhejiang, Hangzhou, China
AD  - Laboratory of Myopia, Chinese Academy of Medical Sciences, Shanghai, China
AD  - NHC Key Laboratory of Myopia, Fudan University, Shanghai, China
AD  - School of Basic Medical Sciences, Fudan University, Shanghai, China
AD  - School of Public Health, Fudan University, Shanghai, China
AD  - Medical Image Processing, Analysis, and Visualization (MIVAP) Lab, School of Electronics and Information Engineering, Soochow University, Suzhou, China
AD  - The Affiliated Eye Hospital, Nanjing Medical University, Nanjing, China
AD  - Department of Ophthalmology, Suqian First Hospital, Suqian, China
AD  - The Fourth School of Clinical Medicine, Nanjing Medical University, Nanjing, China
AD  - State Key Laboratory of Radiation Medicine and Protection, Soochow University, Suzhou, China
AB  - Introduction: Artificial intelligence (AI) technology has made rapid progress for disease diagnosis and triage. In the field of ophthalmic diseases, image-based diagnosis has achieved high accuracy but still encounters limitations due to the lack of medical history. The emergence of ChatGPT enables human-computer interaction, allowing for the development of a multimodal AI system that integrates interactive text and image information. Objective: To develop a multimodal AI system using ChatGPT and anterior segment images for diagnosing and triaging ophthalmic diseases. To assess the AI system's performance through a two-stage cross-sectional study, starting with silent evaluation and followed by early clinical evaluation in outpatient clinics. Methods and analysis: Our study will be conducted across three distinct centers in Shanghai, Nanjing, and Suqian. The development of the smartphone-based multimodal AI system will take place in Shanghai with the goal of achieving ≥90% sensitivity and ≥95% specificity for diagnosing and triaging ophthalmic diseases. The first stage of the cross-sectional study will explore the system's performance in Shanghai's outpatient clinics. Medical histories will be collected without patient interaction, and anterior segment images will be captured using slit lamp equipment. This stage aims for ≥85% sensitivity and ≥95% specificity with a sample size of 100 patients. The second stage will take place at three locations, with Shanghai serving as the internal validation dataset, and Nanjing and Suqian as the external validation dataset. Medical history will be collected through patient interviews, and anterior segment images will be captured via smartphone devices. An expert panel will establish reference standards and assess AI accuracy for diagnosis and triage throughout all stages. A one-vs.-rest strategy will be used for data analysis, and a post-hoc power calculation will be performed to evaluate the impact of disease types on AI performance. Discussion: Our study may provide a user-friendly smartphone-based multimodal AI system for diagnosis and triage of ophthalmic diseases. This innovative system may support early detection of ocular abnormalities, facilitate establishment of a tiered healthcare system, and reduce the burdens on tertiary facilities. Trial registration: The study was registered in ClinicalTrials.gov on June 25th, 2023 (NCT 05930444). Copyright © 2023 Peng, Ma, Zhang, Yan, Lu, Cheng, Liao, Zhang, Wang, Zhao, Zhu, Qin, Jiang, Shi, Qian, Chen and Zhao.
KW  - anterior segment images
KW  - ChatGPT
KW  - cross-sectional study
KW  - multimodal AI
KW  - ophthalmic diseases
KW  - prompt engineering
KW  - protocol
PB  - Frontiers Media SA
SN  - 26248212 (ISSN)
LA  - English
J2  - Frontier. Artif. Intell.
M3  - Article
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 0; Correspondence Address: J. Qian; Department of Ophthalmology, Shanghai, China; email: qianjiang@fudan.edu.cn; C. Zhao; Department of Ophthalmology, Fudan Eye & ENT Hospital, Shanghai, China; email: dr_zhaochen@fudan.edu.cn; F. Shi; Medical Image Processing, Analysis, and Visualization, School of Electronics and Information Engineering, Soochow University, Suzhou, China; email: shifei@suda.edu.cn; X. Chen; Medical Image Processing, Analysis, and Visualization (MIVAP) Lab, School of Electronics and Information Engineering, Soochow University, Suzhou, China; email: dr_zhaochen@fudan.edu.cn
ER  -

TY  - CONF
AU  - Alam, A.I.
AU  - Roy, P.R.
AU  - Al-Omari, F.
AU  - Roy, C.K.
AU  - Roy, B.
AU  - Schneider, K.A.
TI  - GPTCloneBench: A comprehensive benchmark of semantic clones and cross-language clones using GPT-3 model and SemanticCloneBench
PY  - 2023
T2  - Proceedings - 2023 IEEE International Conference on Software Maintenance and Evolution, ICSME 2023
SP  - 1
EP  - 13
DO  - 10.1109/ICSME58846.2023.00013
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85181540317&doi=10.1109%2fICSME58846.2023.00013&partnerID=40&md5=24685f11082166e3f00c826c911f3bb8
AD  - University of Saskatchewan, Department of Computer Science, Saskatoon, Canada
AB  - With the emergence of Machine Learning, there has been a surge in leveraging its capabilities for problem-solving across various domains. In the code clone realm, the identification of type-4 or semantic clones has emerged as a crucial yet challenging task. Researchers aim to utilize Machine Learning to tackle this challenge, often relying on the Big-CloneBench dataset. However, it's worth noting that BigCloneBench, originally not designed for semantic clone detection, presents several limitations that hinder its suitability as a comprehensive training dataset for this specific purpose. Furthermore, CLCDSA dataset suffers from a lack of reusable examples aligning with real-world software systems, rendering it inadequate for cross-language clone detection approaches. In this work, we present a comprehensive semantic clone and cross-language clone benchmark, GPTCloneBench 1 by exploiting SemanticCloneBench and OpenAI's GPT-3 model. In particular, using code fragments from SemanticCloneBench as sample inputs along with appropriate prompt engineering for GPT-3 model, we generate semantic and cross-language clones for these specific fragments and then conduct a combination of extensive manual analysis, tool-assisted filtering, functionality testing and automated validation in building the benchmark. From 79,928 clone pairs of GPT-3 output, we created a benchmark with 37,149 true semantic clone pairs, 19,288 false semantic pairs(Type-1/Type-2), and 20,770 cross-language clones across four languages (Java, C, C#, and Python). Our benchmark is 15-fold larger than SemanticCloneBench, has more functional code examples for software systems and programming language support than CLCDSA, and overcomes BigCloneBench's qualities, quantification, and language variety limitations. GPTCloneBench can be found here1. © 2023 IEEE.
KW  - BigCloneBench
KW  - Cross Language Clone
KW  - GPT-3
KW  - Language Model
KW  - Machine Learning
KW  - Semantic Clone
KW  - SemanticCloneBench
KW  - Software Clone
KW  - Benchmarking
KW  - Cloning
KW  - Computer software reusability
KW  - Functional programming
KW  - Machine learning
KW  - Bigclonebench
KW  - Clone detection
KW  - Cross language clone
KW  - Cross languages
KW  - GPT-3
KW  - Language model
KW  - Machine-learning
KW  - Semantic clone
KW  - Semanticclonebench
KW  - Software clones
KW  - Semantics
PB  - Institute of Electrical and Electronics Engineers Inc.
SN  - 979-835032783-0 (ISBN)
LA  - English
J2  - Proc. - IEEE Int. Conf. Softw. Maint. Evolut., ICSME
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 0; Correspondence Address: A.I. Alam; University of Saskatchewan, Department of Computer Science, Saskatoon, Canada; email: ajmain.alam@usask.ca; Conference name: 39th IEEE International Conference on Software Maintenance and Evolution, ICSME 2023; Conference date: 1 October 2023 through 6 October 2023; Conference code: 195314
ER  -

TY  - JOUR
AU  - Sarangi, P.K.
AU  - Narayan, R.K.
AU  - Mohakud, S.
AU  - Vats, A.
AU  - Sahani, D.
AU  - Mondal, H.
TI  - Assessing the Capability of ChatGPT, Google Bard, and Microsoft Bing in Solving Radiology Case Vignettes
PY  - 2023
T2  - Indian Journal of Radiology and Imaging
DO  - 10.1055/s-0043-1777746
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85182371582&doi=10.1055%2fs-0043-1777746&partnerID=40&md5=386d4a1229334645b9fa5698d436ff82
AD  - Department of Radiodiagnosis, All India Institute of Medical Sciences, Jharkhand, Deoghar, India
AD  - Department of Anatomy, ESIC Medical College & Hospital, Bihta Bihar, Patna, India
AD  - Department of Radiodiagnosis, All India Institute of Medical Sciences, Odisha, Bhubaneswar, India
AD  - Department of Physiology, All India Institute of Medical Sciences, Jharkhand, Deoghar, 814152, India
AB  - Background The field of radiology relies on accurate interpretation of medical images for effective diagnosis and patient care. Recent advancements in artificial intelligence (AI) and natural language processing have sparked interest in exploring the potential of AI models in assisting radiologists. However, limited research has been conducted to assess the performance of AI models in radiology case interpretation, particularly in comparison to human experts. Objective This study aimed to evaluate the performance of ChatGPT, Google Bard, and Bing in solving radiology case vignettes (Fellowship of the Royal College of Radiologists 2A [FRCR2A] examination style questions) by comparing their responses to those provided by two radiology residents. Methods A total of 120 multiple-choice questions based on radiology case vignettes were formulated according to the pattern of FRCR2A examination. The questions were presented to ChatGPT, Google Bard, and Bing. Two residents wrote the examination with the same questions in 3 hours. The responses generated by the AI models were collected and compared to the answer keys and explanation of the answers was rated by the two radiologists. A cutoff of 60% was set as the passing score. Results The two residents (63.33 and 57.5%) outperformed the three AI models: Bard (44.17%), Bing (53.33%), and ChatGPT (45%), but only one resident passed the examination. The response patterns among the five respondents were significantly different (p = 0.0117). In addition, the agreement among the generative AI models was significant (intraclass correlation coefficient [ICC] = 0.628), but there was no agreement between the residents (Kappa = -0.376). The explanation of generative AI models in support of answer was 44.72% accurate. Conclusion Humans exhibited superior accuracy compared to the AI models, showcasing a stronger comprehension of the subject matter. All three AI models included in the study could not achieve the minimum percentage needed to pass an FRCR2A examination. However, generative AI models showed significant agreement in their answers where the residents exhibited low agreement, highlighting a lack of consistency in their responses. © 2023 Wolters Kluwer Medknow Publications. All rights reserved.
KW  - artificial intelligence
KW  - Bard
KW  - Bing
KW  - ChatGPT
KW  - fellowship
KW  - FRCR2A
KW  - natural language processing
KW  - radiology
PB  - Thieme Medical Publishers, Inc.
SN  - 09713026 (ISSN)
LA  - English
J2  - Indian J. Radiol. Imaging
M3  - Article
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 0; Correspondence Address: H. Mondal; Department of Physiology, All India Institute of Medical Sciences, Deoghar, Jharkhand, 814152, India; email: himelmkcg@gmail.com; CODEN: IJRIE
ER  -

TY  - CONF
AU  - Veseli, B.
AU  - Razniewski, S.
AU  - Kalo, J.-C.
AU  - Weikum, G.
TI  - Evaluating the Knowledge Base Completion Potential of GPT
PY  - 2023
T2  - Findings of the Association for Computational Linguistics: EMNLP 2023
SP  - 6432
EP  - 6443
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85179550011&partnerID=40&md5=d682d50742e1685be976bd78c68c93ad
AD  - Max Planck Institute for Informatics, Germany
AD  - Bosch Center for AI
AD  - University of Amsterdam, Netherlands
AB  - Structured knowledge bases (KBs) are an asset for search engines and other applications, but are inevitably incomplete. Language models (LMs) have been proposed for unsupervised knowledge base completion (KBC), yet, their ability to do this at scale and with high accuracy remains an open question. Prior experimental studies mostly fall short because they only evaluate on popular subjects, or sample already existing facts from KBs. In this work, we perform a careful evaluation of GPT's potential to complete the largest public KB: Wikidata. We find that, despite their size and capabilities, models like GPT-3, ChatGPT and GPT-4 do not achieve fully convincing results on this task. Nonetheless, they provide solid improvements over earlier approaches with smaller LMs. In particular, we show that, with proper thresholding, GPT-3 enables to extend Wikidata by 27M facts at 90% precision. © 2023 Association for Computational Linguistics.
KW  - Computational linguistics
KW  - Knowledge based systems
KW  - Capability model
KW  - High-accuracy
KW  - Language model
KW  - Public knowledge
KW  - Size models
KW  - Structured knowledge
KW  - Thresholding
KW  - Search engines
PB  - Association for Computational Linguistics (ACL)
SN  - 979-889176061-5 (ISBN)
LA  - English
J2  - Find. Assoc. Comput. Linguist.: EMNLP
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 1; Conference name: 2023 Findings of the Association for Computational Linguistics: EMNLP 2023; Conference date: 6 December 2023 through 10 December 2023; Conference code: 196127
ER  -

TY  - CONF
AU  - Samsi, S.
AU  - Zhao, D.
AU  - McDonald, J.
AU  - Li, B.
AU  - Michaleas, A.
AU  - Jones, M.
AU  - Bergeron, W.
AU  - Kepner, J.
AU  - Tiwari, D.
AU  - Gadepally, V.
TI  - From Words to Watts: Benchmarking the Energy Costs of Large Language Model Inference
PY  - 2023
T2  - 2023 IEEE High Performance Extreme Computing Conference, HPEC 2023
DO  - 10.1109/HPEC58863.2023.10363447
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85182600249&doi=10.1109%2fHPEC58863.2023.10363447&partnerID=40&md5=96d913d3010c8e09071475b81f9c11b0
AD  - Mit, United States
AD  - Northeastern University, United States
AD  - Nyu, United States
AB  - Large language models (LLMs) have exploded in popularity due to their new generative capabilities that go far beyond prior state-of-the-art. These technologies are increasingly being leveraged in various domains such as law, finance, and medicine. However, these models carry significant computational challenges, especially the compute and energy costs required for inference. Inference energy costs already receive less attention than the energy costs of training LLMs-despite how often these large models are called on to conduct inference in reality (e.g., ChatGPT). As these state-of-the-art LLMs see increasing usage and deployment in various domains, a better understanding of their resource utilization is crucial for cost-savings, scaling performance, efficient hardware usage, and optimal inference strategies. In this paper, we describe experiments conducted to study the computational and energy utilization of inference with LLMs. We benchmark and conduct a preliminary analysis of the inference performance and inference energy costs of different sizes of LLaMA-a recent state-of-the-art LLM-developed by Meta AI on two generations of popular GPUs (NVIDIA V100 & A100) and two datasets (Alpaca and GSM8K) to reflect the diverse set of tasks/benchmarks for LLMs in research and practice. We present the results of multi-node, multi-GPU inference using model sharding across up to 32 GPUs. To our knowledge, our work is the one of the first to study LLM inference performance from the perspective of computational and energy resources at this scale.  © 2023 IEEE.
KW  - Deep Learning
KW  - Distributed Computing
KW  - Energy
KW  - Green AI
KW  - Inference
KW  - Large Language Models
KW  - LLM
KW  - Natural Language Processing
KW  - NLP
KW  - Sustainability
KW  - Benchmarking
KW  - Computational linguistics
KW  - Computing power
KW  - Cost benefit analysis
KW  - Deep learning
KW  - Energy resources
KW  - Energy utilization
KW  - Green computing
KW  - Learning algorithms
KW  - Natural language processing systems
KW  - Program processors
KW  - Deep learning
KW  - Energy
KW  - Green AI
KW  - Inference
KW  - Language model
KW  - Language processing
KW  - Large language model
KW  - Natural language processing
KW  - Natural languages
KW  - Graphics processing unit
PB  - Institute of Electrical and Electronics Engineers Inc.
SN  - 979-835030860-0 (ISBN)
LA  - English
J2  - IEEE High Perform. Extrem. Comput. Conf., HPEC
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 0; Conference name: 2023 IEEE High Performance Extreme Computing Conference, HPEC 2023; Conference date: 25 September 2023 through 29 September 2023; Conference code: 195846
ER  -

TY  - JOUR
AU  - Phillips, G.
TI  - Evaluating the carousel format of Sunderland Online’s LLM programme
PY  - 2023
T2  - Law Teacher
VL  - 57
IS  - 4
SP  - 560
EP  - 564
DO  - 10.1080/03069400.2023.2279445
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85180192316&doi=10.1080%2f03069400.2023.2279445&partnerID=40&md5=0f599edbf296ae74b58746bfd131e1d2
AD  - Faculty of Business, Law and Tourism, University of Sunderland, Sunderland, United Kingdom
KW  - distance learning
KW  - masters
KW  - Online learning
PB  - Routledge
SN  - 03069400 (ISSN)
LA  - English
J2  - Law Teach.
M3  - Review
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 0; Correspondence Address: G. Phillips; Faculty of Business, Law and Tourism, University of Sunderland, Sunderland, United Kingdom; email: Gemma.Phillips@sunderland.ac.uk
ER  -

TY  - CONF
AU  - Liu, M.
AU  - Pinckney, N.
AU  - Khailany, B.
AU  - Ren, H.
TI  - Invited Paper: VerilogEval: Evaluating Large Language Models for Verilog Code Generation
PY  - 2023
T2  - IEEE/ACM International Conference on Computer-Aided Design, Digest of Technical Papers, ICCAD
DO  - 10.1109/ICCAD57390.2023.10323812
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85181402881&doi=10.1109%2fICCAD57390.2023.10323812&partnerID=40&md5=2992f3a76c64360b5a6c38d187b647be
AD  - Nvidia Corporation, United States
AB  - The increasing popularity of large language models (LLMs) has paved the way for their application in diverse domains. This paper proposes a benchmarking framework tailored specifically for evaluating LLM performance in the context of Verilog code generation for hardware design and verification. We present a comprehensive evaluation dataset consisting of 156 problems from the Verilog instructional website HDLBits. The evaluation set consists of a diverse set of Verilog code generation tasks, ranging from simple combinational circuits to complex finite state machines. The Verilog code completions can be automatically tested for functional correctness by comparing the transient simulation outputs of the generated design with a golden solution. We also demonstrate that the Verilog code generation capability of pretrained language models could be improved with supervised fine-tuning by bootstrapping with LLM generated synthetic problem-code pairs.  © 2023 IEEE.
KW  - Benchmarking
KW  - Computational linguistics
KW  - Code completions
KW  - Codegeneration
KW  - Comprehensive evaluation
KW  - Diverse domains
KW  - Finite states machine
KW  - Hardware design and verification
KW  - Language model
KW  - Modeling performance
KW  - Simple++
KW  - Verilog code
KW  - Computer hardware description languages
PB  - Institute of Electrical and Electronics Engineers Inc.
SN  - 10923152 (ISSN); 979-835031559-2 (ISBN)
LA  - English
J2  - IEEE ACM Int. Conf. Comput. Des. Dig. Tech. Pap. ICCAD
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 0; Conference name: 42nd IEEE/ACM International Conference on Computer-Aided Design, ICCAD 2023; Conference date: 28 October 2023 through 2 November 2023; Conference code: 195041; CODEN: DICDF
ER  -

TY  - CONF
AU  - Murthy, S.K.
AU  - Parece, K.
AU  - Bridgers, S.
AU  - Qian, P.
AU  - Ullman, T.
TI  - Comparing the Evaluation and Production of Loophole Behavior in Humans and Large Language Models
PY  - 2023
T2  - Findings of the Association for Computational Linguistics: EMNLP 2023
SP  - 4010
EP  - 4025
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85183296253&partnerID=40&md5=df324eddb85b5aae9378369817b61b78
AD  - School of Engineering and Applied Sciences, Harvard University, United States
AD  - Department of Psychology, Harvard University, United States
AD  - Department of Brain and Cognitive Sciences, Massachusetts Institute of Technology, United States
AB  - In law, lore, and everyday life, loopholes are commonplace. When people exploit a loophole, they understand the intended meaning or goal of another person, but choose to go with a different interpretation. Past and current AI research has shown that artificial intelligence engages in what seems superficially like the exploitation of loopholes, but this is likely an-thropomorphization. It remains unclear to what extent current models, especially Large Language Models (LLMs), capture the pragmatic understanding required for engaging in loopholes. We examined the performance of LLMs on two metrics developed for studying loophole behavior in humans: evaluation (ratings of trouble, upset, and humor), and generation (coming up with new loopholes in a given context). We conducted a fine-grained comparison of state-of-the-art LLMs to humans, and find that while many of the models rate loophole behaviors as resulting in less trouble and upset than outright non-compliance (in line with humans), they struggle to recognize the humor in the creative exploitation of loopholes in the way that humans do. Furthermore, only two of the models, GPT-3.5 and 3, are capable of reliably generating loopholes of their own, with GPT-3.5 performing closest to the human baseline. © 2023 Association for Computational Linguistics.
KW  - 'current
KW  - Creatives
KW  - Current modeling
KW  - Evaluation rating
KW  - Fine grained
KW  - Human evaluation
KW  - Language model
KW  - Non-compliance
KW  - Performance
KW  - State of the art
KW  - Computational linguistics
PB  - Association for Computational Linguistics (ACL)
SN  - 979-889176061-5 (ISBN)
LA  - English
J2  - Find. Assoc. Comput. Linguist.: EMNLP
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 0; Conference name: 2023 Findings of the Association for Computational Linguistics: EMNLP 2023; Conference date: 6 December 2023 through 10 December 2023; Conference code: 196127
ER  -

TY  - CONF
AU  - Morbidoni, C.
AU  - Sarra, A.
TI  - Can LLMs assist humans in assessing online misogyny? Experiments with GPT-3.5
PY  - 2023
T2  - CEUR Workshop Proceedings
VL  - 3571
SP  - 31
EP  - 43
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85180126587&partnerID=40&md5=fba7b0cfd77efa95ce81e27d6c5066da
AD  - Università degli Studi G. d'Annunzio, Pescara, Italy
AB  - Today's social media landscape is flooded with unfiltered content, which can range from hate speech to cyberbullying and cyberstalking. As a result, locating and eliminating such toxic language presents a significant challenge and is an active current research area. In this paper we focus on detecting hate speech against women, i.e. misogyny, exploiting a “prompt-based learning” paradigm with the aim of providing a first assessment of recent developed LLM (OpenAI's GPT-3.5-turbo). We experiment with a benchmark dataset of Reddit posts and evaluate different prompts types w.r.t. response stability, classification accuracy and inter-annotator agreement. Our experiments show that zero-shot detection GPT capabilities - against human annotations - outperform supervised baselines on our evaluation dataset and that ensembling different prompts possibly further improve the accuracy up to 91%. We also found that responses to specific prompts is quite stable, while slightly more variation and less agreement is observed when asking the questions in different ways. © 2022 Copyright for this paper by its authors. Use permitted under Creative Commons License Attribution 4.0 International (CC BY 4.0).
KW  - GPT
KW  - online misogyny detection
KW  - pre-trained language model
KW  - prompt-based learning
KW  - text classification
KW  - E-learning
KW  - Text processing
KW  - Zero-shot learning
KW  - Active current
KW  - Cyber bullying
KW  - Cyberstalking
KW  - GPT
KW  - Language model
KW  - Online misogyny detection
KW  - Pre-trained language model
KW  - Prompt-based learning
KW  - Social media
KW  - Text classification
KW  - Classification (of information)
A2  - Torrielli F.
A2  - University of Torino, Department of Computer Science, Corso Svizzera 185, Torino
A2  - Di Caro L.
A2  - University of Torino, Department of Computer Science, Corso Svizzera 185, Torino
A2  - Rapp A.
A2  - University of Torino, Department of Computer Science, Corso Svizzera 185, Torino
PB  - CEUR-WS
SN  - 16130073 (ISSN)
LA  - English
J2  - CEUR Workshop Proc.
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 0; Correspondence Address: C. Morbidoni; Università degli Studi G. d'Annunzio, Pescara, Italy; email: christian.morbidoni@unich.it; Conference name: 2023 Workshop on GENerative, Explainable and Reasonable Artificial Learning, GENERAL 2023; Conference date: 20 September 2023 through 22 September 2023; Conference code: 194815
ER  -

TY  - CONF
AU  - Sujatha, R.
AU  - Nimala, K.
TI  - Enhancing Idiom Classification on Text-based Conversational Data: Evaluating Transformer Model Performance through k-fold Cross-Validation
PY  - 2023
T2  - 2023 1st International Conference on Advances in Electrical, Electronics and Computational Intelligence, ICAEECI 2023
DO  - 10.1109/ICAEECI58247.2023.10370954
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85183547327&doi=10.1109%2fICAEECI58247.2023.10370954&partnerID=40&md5=2acb2b32a61c7857160fe12a20034543
AD  - SRM Institute of Science and Technology, Department of Networking and Communications, Chengalpattu, Tamil Nadu, Kattankulathur, India
AB  - This study focuses on enhancing the classification of idioms within conversational data by leveraging transformer models. Idioms pose a challenges in natural language understanding due to their figurative nature and context-dependent meaning. Transformer models, such as BERT and T5, which are well-known for their ability to capture complex linguistic patterns and have been extensively explored for this task. The study incorporates embedding methods with these models and observes the results: a rigorous evaluation methodology, k-fold cross-validation, assesses of their performance. The dataset is divided into multiple folds, allowing for comprehensive training and evaluation of the models. This evaluation approach provides reliable and robust measures of the transformer models' effectiveness in accurately classifying idioms in conversational contexts. The findings from this study contribute to advancing the understanding of idiomatic expressions and demonstrate the potential of transformer models for improving idiom classification in conversational data. The transformer model BERT with ELMo embedding and the T5 model achieved better performance than the BERT base model. © 2023 IEEE.
KW  - Conversational Systems
KW  - Idioms classification
KW  - k-fold cross-validation
KW  - text-based conversation
KW  - transformer model
PB  - Institute of Electrical and Electronics Engineers Inc.
SN  - 979-835034279-6 (ISBN)
LA  - English
J2  - Int. Conf. Adv. Electr., Electron. Comput. Intell., ICAEECI
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 0; Correspondence Address: K. Nimala; SRM Institute of Science and Technology, Department of Networking and Communications, Kattankulathur, Chengalpattu, Tamil Nadu, India; email: nimalak@srmist.edu.in; Conference name: 1st International Conference on Advances in Electrical, Electronics and Computational Intelligence, ICAEECI 2023; Conference date: 19 October 2023 through 20 October 2023; Conference code: 196103
ER  -

TY  - CONF
AU  - Su, H.
AU  - Ai, J.
AU  - Yu, D.
AU  - Zhang, H.
TI  - An Evaluation Method for Large Language Models' Code Generation Capability
PY  - 2023
T2  - Proceedings - 2023 10th International Conference on Dependable Systems and Their Applications, DSA 2023
SP  - 831
EP  - 838
DO  - 10.1109/DSA59317.2023.00118
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85179502301&doi=10.1109%2fDSA59317.2023.00118&partnerID=40&md5=1ceaed74d62d9b6624a47ca30d838f59
AD  - Beihang University, Beijing, China
AB  - Large language models are becoming increasingly popular in various professional fields. One of their applications is providing code suggestions. However, the differences in code generation capabilities of different large language models and the problems they may make in giving code suggestions have not been well studied. This paper proposes a method for evaluating the code generation capabilities of large language models and applies it to several commonly used models, including ChatGPT, Claude, Spark, and Bing AI. Through experimental evaluation and data analysis, we find that search-based large language models, such as Bing AI, exhibit stronger code generation capabilities than pre-trained models, such as ChatGPT, Claude, and Spark. We also find that the current large language models possess strong natural language understanding abilities, and errors in code suggestions are more likely to be due to code problems rather than understanding problems.  © 2023 IEEE.
KW  - Code Generation
KW  - Evaluation Method
KW  - Large Language Model
KW  - 'current
KW  - Codegeneration
KW  - Evaluation methods
KW  - Experimental evaluation
KW  - Language model
KW  - Large language model
KW  - Natural language understanding
KW  - Professional fields
KW  - Search-based
KW  - Computational linguistics
PB  - Institute of Electrical and Electronics Engineers Inc.
SN  - 979-835030477-0 (ISBN)
LA  - English
J2  - Proc. - Int. Conf. Dependable Syst. Their Appl., DSA
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 0; Correspondence Address: H. Zhang; Beihang University, Beijing, China; email: zh@buaa.edu.cn; Conference name: 10th International Conference on Dependable Systems and Their Applications, DSA 2023; Conference date: 10 August 2023 through 11 August 2023; Conference code: 194487
ER  -

TY  - CONF
AU  - Rao, H.
AU  - Leung, C.
AU  - Miao, C.
TI  - Can ChatGPT Assess Human Personalities? A General Evaluation Framework
PY  - 2023
T2  - Findings of the Association for Computational Linguistics: EMNLP 2023
SP  - 1184
EP  - 1194
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85182843373&partnerID=40&md5=793cd3f7632cdf9f928db41b17feeb65
AD  - School of Computer Science and Engineering, Nanyang Technological University, Singapore
AD  - LILY Research Centre, Nanyang Technological University, Singapore
AD  - Department of Electrical and Computer Engineering, The University of British Columbia, Canada
AB  - Large Language Models (LLMs) especially ChatGPT have produced impressive results in various areas, but their potential human-like psychology is still largely unexplored. Existing works study the virtual personalities of LLMs but rarely explore the possibility of analyzing human personalities via LLMs. This paper presents a generic evaluation framework for LLMs to assess human personalities based on Myers-Briggs Type Indicator (MBTI) tests. Specifically, we first devise unbiased prompts by randomly permuting options in MBTI questions and adopt the average testing result to encourage more impartial answer generation. Then, we propose to replace the subject in question statements to enable flexible queries and assessments on different subjects from LLMs. Finally, we re-formulate the question instructions in a manner of correctness evaluation to facilitate LLMs to generate clearer responses. The proposed framework enables LLMs to flexibly assess personalities of different groups of people. We further propose three evaluation metrics to measure the consistency, robustness, and fairness of assessment results from state-of-the-art LLMs including ChatGPT and GPT-4. Our experiments reveal ChatGPT's ability to assess human personalities, and the average results demonstrate that it can achieve more consistent and fairer assessments in spite of lower robustness against prompt biases compared with InstructGPT. © 2023 Association for Computational Linguistics.
KW  - Virtual reality
KW  - Evaluation framework
KW  - Evaluation metrics
KW  - Flexible assessments
KW  - Flexible queries
KW  - Generic evaluation
KW  - Human like
KW  - Language model
KW  - Myers-Briggs Type Indicators
KW  - State of the art
KW  - Work study
KW  - Computational linguistics
PB  - Association for Computational Linguistics (ACL)
SN  - 979-889176061-5 (ISBN)
LA  - English
J2  - Find. Assoc. Comput. Linguist.: EMNLP
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 0; Correspondence Address: C. Miao; School of Computer Science and Engineering, Nanyang Technological University, Singapore; email: ascymiao@ntu.edu.sg; Conference name: 2023 Findings of the Association for Computational Linguistics: EMNLP 2023; Conference date: 6 December 2023 through 10 December 2023; Conference code: 196127
ER  -

TY  - CONF
AU  - Nehar, A.
AU  - Bellaouar, S.
AU  - Souffi, S.
AU  - Bouameur, M.
TI  - Dhati: A Fine-Tuned Large Language Model for evaluating Subjectivity in Arabic Textual Data
PY  - 2023
T2  - 2023 5th International Conference on Pattern Analysis and Intelligent Systems, PAIS 2023
DO  - 10.1109/PAIS60821.2023.10322022
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85179887253&doi=10.1109%2fPAIS60821.2023.10322022&partnerID=40&md5=bf9bdea0bacd26c82d85da0c479b3643
AD  - Ziane Achour University, Djelfa, Algeria
AD  - Universite A. Telidji, Lab. d'Informatique et Mathematiques (LIM), Laghouat, Algeria
AD  - Universite de Ghardaia, Lab. des Mathematiques et Sciences Appliquees (LMSA), Dept. of Mathematics and CS, Algeria
AD  - Universite de Ghardaia Lab. des Mathematiques et Sciences Appliquees Universite de Ghardaia, Dept. of Mathematics and CS, Algeria
AB  - Despite being a linguistically rich and morphologically complex language, Arabic remains an under-resourced language. The scarcity of large annotated datasets creates a challenge to providing accurate tools for many natural language processing (NLP) tasks such as subjectivity and sentiment analysis. The efficacy of text classification has been significantly enhanced for various languages, including English and French, due to the notable progress made in deep learning (DL) and Transformers, leading to the development of large language models. The aforementioned models have undergone pre-Training using extensive datasets, followed by a process of fine-Tuning for targeted downstream tasks. In this paper, we provide a tool, which we call "Dhati", for the evaluation of subjectivity in Arabic textual data by fine-Tuning a large language model (XLM-RoBERTa) on the Arabic Sentiment Tweets Dataset (ASTD). Then, for comparison purposes, we provide a parallel approach, where we translate the Arabic text into English and use two existing fine-Tuned models. The findings indicate that the Dhati model has superior performance compared to the parallel approach, as it achieves an accuracy rate of 82% in the Arabic subjectivity classification task using the ASTD benchmark.  © 2023 IEEE.
KW  - Arabic Sentiment Classification
KW  - Large Language Models
KW  - Subjectivity
KW  - Transformers
KW  - XLM-RoBERTa
KW  - Benchmarking
KW  - Classification (of information)
KW  - Computational linguistics
KW  - Deep learning
KW  - Large dataset
KW  - Arabic sentiment classification
KW  - Fine tuning
KW  - Language model
KW  - Large language model
KW  - Sentiment classification
KW  - Subjectivity
KW  - Textual data
KW  - Transformer
KW  - Under-resourced languages
KW  - XLM-RoBERTa
KW  - Sentiment analysis
PB  - Institute of Electrical and Electronics Engineers Inc.
SN  - 979-835038145-0 (ISBN)
LA  - English
J2  - Int. Conf. Pattern Anal. Intell. Syst., PAIS
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 0; Correspondence Address: A. Nehar; Ziane Achour University, Djelfa, Algeria; email: neharattia@univ-djelfa.dz; Conference name: 5th International Conference on Pattern Analysis and Intelligent Systems, PAIS 2023; Conference date: 25 October 2023 through 26 October 2023; Conference code: 194640
ER  -

TY  - CONF
AU  - Cassese, M.
AU  - Bondielli, A.
AU  - Lenci, A.
TI  - Assessing Language and Vision-Language Models on Event Plausibility
PY  - 2023
T2  - CEUR Workshop Proceedings
VL  - 3596
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85181174037&partnerID=40&md5=806b5532d80328b304783307dafbadf8
AD  - CoLing Lab, Department of Philology, Literature, and Linguistics, University of Pisa, 36 S. Maria St, Pisa, I-56126, Italy
AD  - Department of Computer Science, University of Pisa, 3 Largo Bruno Pontecorvo, Pisa, 56127, Italy
AB  - ITransformer-based Language Models (LMs) excel in many tasks, but they appear to lack robustness in capturing crucial aspects of event knowledge due to their reliance on surface-level linguistic features and the mismatch between language descriptions and real-world occurrences. In this paper, we investigate the potential of Transformer-based Vision-Language Models (VLMs) in comprehending Generalized Event Knowledge (GEK), aiming to determine whether the inclusion of a visual component affects the mastery of GEK. To do so, we compare multimodal Transformer models with unimodal ones on a task evaluating the plausibility of curated minimal sentence pairs. We show that current VLMs generally perform worse than their unimodal counterparts, suggesting that VL pre-training strategies are not yet as effective to model semantic understanding and resulting models are more akin to bag-of-words in this context. © 2023 CEUR-WS. All rights reserved.
KW  - Computational linguistics
KW  - Visual languages
KW  - 'current
KW  - Excel
KW  - Language description
KW  - Language model
KW  - Linguistic features
KW  - Multi-modal
KW  - Real-world
KW  - Transformer modeling
KW  - Unimodal
KW  - Visual components
KW  - Semantics
A2  - Boschetti F.
A2  - Boschetti F.
A2  - Lebani G.E.
A2  - Magnini B.
A2  - Novielli N.
PB  - CEUR-WS
SN  - 16130073 (ISSN)
LA  - English
J2  - CEUR Workshop Proc.
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 0; Correspondence Address: M. Cassese; CoLing Lab, Department of Philology, Literature, and Linguistics, University of Pisa, Pisa, 36 S. Maria St, I-56126, Italy; email: m.cassese4@studenti.unipi.it; Conference name: 9th Italian Conference on Computational Linguistics, CLiC-it 2023; Conference date: 30 November 2023 through 2 December 2023; Conference code: 195716
ER  -

TY  - CONF
AU  - Hsu, T.-Y.
AU  - Huang, C.-Y.
AU  - Rossi, R.
AU  - Kim, S.
AU  - Giles, C.L.
AU  - Huang, T.-H.K.
TI  - GPT-4 as an Effective Zero-Shot Evaluator for Scientific Figure Captions
PY  - 2023
T2  - Findings of the Association for Computational Linguistics: EMNLP 2023
SP  - 5464
EP  - 5474
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85183289166&partnerID=40&md5=be81ce2531a43378f07ed3840ce0f40e
AD  - Pennsylvania State University, University Park, PA, United States
AD  - Adobe Research, San Francisco, CA, United States
AB  - There is growing interest in systems that generate captions for scientific figures. However, assessing these systems' output poses a significant challenge. Human evaluation requires academic expertise and is costly, while automatic evaluation depends on often low-quality author-written captions. This paper investigates using large language models (LLMs) as a cost-effective, reference-free method for evaluating figure captions. We first constructed SCICAP-EVAL, a human evaluation dataset that contains human judgments for 3,600 scientific figure captions, both original and machine-made, for 600 arXiv figures. We then prompted LLMs like GPT-4 and GPT-3 to score (1-6) each caption based on its potential to aid reader understanding, given relevant context such as figure-mentioning paragraphs. Results show that GPT-4, used as a zero-shot evaluator, outperformed all other models and even surpassed assessments made by Computer Science and Informatics undergraduates, achieving a Kendall correlation score of 0.401 with Ph.D. students' rankings. © 2023 Association for Computational Linguistics.
KW  - Computational linguistics
KW  - Quality control
KW  - Zero-shot learning
KW  - Automatic evaluation
KW  - Cost effective
KW  - Human evaluation
KW  - Human judgments
KW  - Informatics
KW  - Kendall correlations
KW  - Language model
KW  - Low qualities
KW  - Reference-free
KW  - System output
KW  - Cost effectiveness
PB  - Association for Computational Linguistics (ACL)
SN  - 979-889176061-5 (ISBN)
LA  - English
J2  - Find. Assoc. Comput. Linguist.: EMNLP
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 0; Conference name: 2023 Findings of the Association for Computational Linguistics: EMNLP 2023; Conference date: 6 December 2023 through 10 December 2023; Conference code: 196127
ER  -

TY  - CONF
AU  - Yu, D.
AU  - Ai, J.
AU  - Su, H.
AU  - Zhang, H.
TI  - Assessing ChatGPT's Comprehension of Perturbed Text through Text Linguistic Features
PY  - 2023
T2  - Proceedings - 2023 10th International Conference on Dependable Systems and Their Applications, DSA 2023
SP  - 839
EP  - 850
DO  - 10.1109/DSA59317.2023.00119
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85179519301&doi=10.1109%2fDSA59317.2023.00119&partnerID=40&md5=11da40eee289409e93f2c96341d6abb0
AD  - Beihang University, Beijing, China
AB  - This paper presents an evaluation method for assessing ChatGPT's ability to understand perturbed text, offering a novel approach to evaluating the robustness of large language models from a text understanding perspective. The proposed method analyzes ChatGPT's comprehension of perturbed text across three dimensions: static sensitivity, dynamic sensitivity, and comprehensive ability. This is achieved through the utilization of traditional metrics and a difference norm based on textual linguistic features. The integration of linguistic features into the assessment of text perturbation degree provides a fast, efficient, and accurate evaluation method that can be easily applied to other large language models. Analysing of results identifies perturbations with high static and dynamic sensitivity for ChatGPT, and assesses its comprehensive comprehension both qualitatively and quantitatively.  © 2023 IEEE.
KW  - ChatGPT
KW  - Large Language Model
KW  - Linguistic feature
KW  - Perturbation
KW  - Robustness
KW  - ChatGPT
KW  - Dynamic sensitivity
KW  - Evaluation methods
KW  - Language model
KW  - Large language model
KW  - Linguistic features
KW  - Method analysis
KW  - Perturbation
KW  - Robustness
KW  - Three dimensions
KW  - Computational linguistics
PB  - Institute of Electrical and Electronics Engineers Inc.
SN  - 979-835030477-0 (ISBN)
LA  - English
J2  - Proc. - Int. Conf. Dependable Syst. Their Appl., DSA
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 0; Correspondence Address: H. Zhang; Beihang University, Beijing, China; email: zh@buaa.edu.cn; Conference name: 10th International Conference on Dependable Systems and Their Applications, DSA 2023; Conference date: 10 August 2023 through 11 August 2023; Conference code: 194487
ER  -

TY  - CONF
AU  - Tang, R.
AU  - Lueck, G.
AU  - Quispe, R.
AU  - Inan, H.A.
AU  - Kulkarni, J.
AU  - Hu, X.
TI  - Assessing Privacy Risks in Language Models: A Case Study on Summarization Tasks
PY  - 2023
T2  - Findings of the Association for Computational Linguistics: EMNLP 2023
SP  - 15406
EP  - 15418
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85183292318&partnerID=40&md5=a02f37247adf6a26a6dca469e348e3fe
AD  - Department of Computer Science, Rice University, TX, United States
AD  - Microsoft, Redmond, WA, United States
AD  - Microsoft Research, Redmond, WA, United States
AB  - Large language models have revolutionized the field of NLP by achieving state-of-the-art performance on various tasks. However, there is a concern that these models may disclose information in the training data. In this study, we focus on the summarization task and investigate the membership inference (MI) attack: given a sample and black-box access to a model's API, it is possible to determine if the sample was part of the training data. We exploit text similarity and the model's resistance to document modifications as potential MI signals and evaluate their effectiveness on widely used datasets. Our results demonstrate that summarization models are at risk of exposing data membership, even in cases where the reference summary is not available. Furthermore, we discuss several safeguards for training summarization models to protect against MI attacks and discuss the inherent trade-off between privacy and utility. © 2023 Association for Computational Linguistics.
KW  - Computational linguistics
KW  - Natural language processing systems
KW  - Risk assessment
KW  - Black boxes
KW  - Case-studies
KW  - Inference attacks
KW  - Language model
KW  - Privacy risks
KW  - Sample box
KW  - State-of-the-art performance
KW  - Summarization models
KW  - Text similarity
KW  - Training data
KW  - Economic and social effects
PB  - Association for Computational Linguistics (ACL)
SN  - 979-889176061-5 (ISBN)
LA  - English
J2  - Find. Assoc. Comput. Linguist.: EMNLP
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 0; Conference name: 2023 Findings of the Association for Computational Linguistics: EMNLP 2023; Conference date: 6 December 2023 through 10 December 2023; Conference code: 196127
ER  -

TY  - JOUR
AU  - Krzyewska, A.
TI  - Climate change in Poland - The assessment of the conversation with ChatGPT
PY  - 2023
T2  - Miscellanea Geographica
DO  - 10.2478/mgrsd-2023-0017
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85180070554&doi=10.2478%2fmgrsd-2023-0017&partnerID=40&md5=9675066d41854f56c83dd9c15a70b92c
AD  - Departament of Hydrology and Climatology, Institute of Earth and Environmental Sciences, University of Maria Curie Skłodowska in Lublin, Lublin, Poland
AB  - ChatGPT, along with its applications, possibilities, limitations and future development, is currently one of the most often discussed topics worldwide. One of the issues raised in those discussions is its ethically questionable role in science and education. The goal of this paper is to assess the accuracy and correctness of the responses given by ChatGPT, using climate change in Poland as an example. Eight questions related to this topic were posed to ChatGPT, and each answer was subsequently verified and assigned a grade on a scale of 0-10. The overall grade obtained was 3.8, indicating that only 30-40% of the information provided by ChatGPT was accurate. This poor result can be attributed to fake references, inaccurate data, overgeneralizations and simplification. Nevertheless, with proper training and development, ChatGPT has tremendous potential to serve as a valuable tool for ethically sound applications in the field of science. © 2023 Agnieszka Krzyewska, published by Sciendo 2023.
KW  - ChatGPT
KW  - ChatGPT applications
KW  - ChatGPT assessment
KW  - climate change in Poland
PB  - Sciendo
SN  - 08676046 (ISSN)
LA  - English
J2  - Misc. Geogr.
M3  - Article
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 0; Correspondence Address: A. Krzyewska; Departament of Hydrology and Climatology, Institute of Earth and Environmental Sciences, University of Maria Curie Skłodowska in Lublin, Lublin, Poland; email: agnieszka.krzyzewska@umcs.pl
ER  -

TY  - JOUR
AU  - Savage, T.
AU  - Wang, J.
AU  - Shieh, L.
TI  - A Large Language Model Screening Tool to Target Patients for Best Practice Alerts: Development and Validation
PY  - 2023
T2  - JMIR Medical Informatics
VL  - 11
IS  - 1
C7  - e49886
DO  - 10.2196/49886
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85180079533&doi=10.2196%2f49886&partnerID=40&md5=987d1a6189aeb158ee224083582d56a6
AD  - Division of Hospital Medicine, Department of Medicine, Stanford University, Palo Alto, CA, United States
AD  - Divison of Gastroenterology and Hepatology, Department of Medicine, Stanford University, Palo Alto, CA, United States
AB  - Background: Best Practice Alerts (BPAs) are alert messages to physicians in the electronic health record that are used to encourage appropriate use of health care resources. While these alerts are helpful in both improving care and reducing costs, BPAs are often broadly applied nonselectively across entire patient populations. The development of large language models (LLMs) provides an opportunity to selectively identify patients for BPAs. Objective: In this paper, we present an example case where an LLM screening tool is used to select patients appropriate for a BPA encouraging the prescription of deep vein thrombosis (DVT) anticoagulation prophylaxis. The artificial intelligence (AI) screening tool was developed to identify patients experiencing acute bleeding and exclude them from receiving a DVT prophylaxis BPA. Methods: Our AI screening tool used a BioMed-RoBERTa (Robustly Optimized Bidirectional Encoder Representations from Transformers Pretraining Approach; AllenAI) model to perform classification of physician notes, identifying patients without active bleeding and thus appropriate for a thromboembolism prophylaxis BPA. The BioMed-RoBERTa model was fine-tuned using 500 history and physical notes of patients from the MIMIC-III (Medical Information Mart for Intensive Care) database who were not prescribed anticoagulation. A development set of 300 MIMIC patient notes was used to determine the model’s hyperparameters, and a separate test set of 300 patient notes was used to evaluate the screening tool. Results: Our MIMIC-III test set population of 300 patients included 72 patients with bleeding (ie, were not appropriate for a DVT prophylaxis BPA) and 228 without bleeding who were appropriate for a DVT prophylaxis BPA. The AI screening tool achieved impressive accuracy with a precision-recall area under the curve of 0.82 (95% CI 0.75-0.89) and a receiver operator curve area under the curve of 0.89 (95% CI 0.84-0.94). The screening tool reduced the number of patients who would trigger an alert by 20% (240 instead of 300 alerts) and increased alert applicability by 14.8% (218 [90.8%] positive alerts from 240 total alerts instead of 228 [76%] positive alerts from 300 total alerts), compared to nonselectively sending alerts for all patients. Conclusions: These results show a proof of concept on how language models can be used as a screening tool for BPAs. We provide an example AI screening tool that uses a HIPAA (Health Insurance Portability and Accountability Act)–compliant BioMed-RoBERTa model deployed with minimal computing power. Larger models (eg, Generative Pre-trained Transformers–3, Generative Pre-trained Transformers–4, and Pathways Language Model) will exhibit superior performance but require data use agreements to be HIPAA compliant. We anticipate LLMs to revolutionize quality improvement in hospital medicine. © 2023 JMIR Publications Inc. All rights reserved.
KW  - Artificial Intelligence
KW  - EHR
KW  - health record
KW  - health records
KW  - language model
KW  - language models
KW  - large language models
KW  - Natural Language Processing
KW  - quality improvement
PB  - JMIR Publications Inc.
SN  - 22919694 (ISSN)
LA  - English
J2  - JMIR Med. Inform.
M3  - Article
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 0; Correspondence Address: T. Savage; Division of Hospital Medicine Department of Medicine Stanford University, Palo Alto, 300 Pasteur Drive, 94304, United States; email: tsavage@stanford.edu
ER  -

TY  - JOUR
AU  - Klang, E.
AU  - Sourosh, A.
AU  - Nadkarni, G.N.
TI  - Evaluating the role of ChatGPT in gastroenterology: a comprehensive systematic review of applications, benefits, and limitations
PY  - 2023
T2  - Therapeutic Advances in Gastroenterology
VL  - 16
DO  - 10.1177/17562848231218618
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85181202989&doi=10.1177%2f17562848231218618&partnerID=40&md5=f140f221a1d2b9bf51cf5730139cb28c
AD  - Division of Data-Driven and Digital Medicine (D3M), Icahn School of Medicine at Mount Sinai, New York, NY, United States
AD  - The Charles Bronfman Institute of Personalized Medicine, Icahn School of Medicine at Mount Sinai, New York, NY, United States
AD  - ARC Innovation Center, Sheba Medical Center, Tel Hashomer Affiliated with Tel Aviv Medical School, Tel Aviv University, Tel Aviv, Israel
AB  - Background: The integration of artificial intelligence (AI) into healthcare has opened new avenues for enhancing patient care and clinical research. In gastroenterology, the potential of AI tools, specifically large language models like ChatGPT, is being explored to understand their utility and effectiveness. Objectives: The primary goal of this systematic review is to assess the various applications, ascertain the benefits, and identify the limitations of utilizing ChatGPT within the realm of gastroenterology. Design: Through a systematic approach, this review aggregates findings from multiple studies to evaluate the impact of ChatGPT on the field. Data sources and methods: The review was based on a detailed literature search of the PubMed database, targeting research that delves into the use of ChatGPT for gastroenterological purposes. It incorporated six selected studies, which were meticulously evaluated for quality using the Joanna Briggs Institute critical appraisal instruments. The data were then synthesized narratively to encapsulate the roles, advantages, and drawbacks of ChatGPT in gastroenterology. Results: The investigation unearthed various roles of ChatGPT, including its use in patient education, diagnostic self-assessment, disease management, and the formulation of research queries. Notable benefits were its capability to provide pertinent recommendations, enhance communication between patients and physicians, and prompt valuable research inquiries. Nonetheless, it encountered obstacles in decoding intricate medical questions, yielded inconsistent responses at times, and exhibited limitations in generating novel content. The review also considered ethical implications. Conclusion: ChatGPT has demonstrated significant potential in the field of gastroenterology, especially in facilitating patient–physician interactions and managing diseases. Despite these advancements, the review underscores the necessity for ongoing refinement, customization, and ethical regulation of AI tools. These findings serve to enrich the dialog concerning AI’s role in healthcare, with a specific focus on ChatGPT’s application in gastroenterology. © The Author(s), 2023.
KW  - artificial intelligence
KW  - ChatGPT
KW  - gastroenterology
KW  - large language models
KW  - review
KW  - proton pump inhibitor
KW  - artificial intelligence
KW  - ChatGPT
KW  - clinical research
KW  - colonoscopy
KW  - consultation
KW  - education
KW  - encapsulation
KW  - gastroenterology
KW  - gastroesophageal reflux
KW  - health care
KW  - human
KW  - integration
KW  - Joanna Briggs Institute critical appraisal checklist
KW  - large language model
KW  - medical education
KW  - Medline
KW  - patient care
KW  - patient education
KW  - physician
KW  - practice guideline
KW  - quality control
KW  - questionnaire
KW  - reproducibility
KW  - Review
KW  - search engine
KW  - self evaluation
KW  - systematic review
PB  - SAGE Publications Ltd
SN  - 1756283X (ISSN)
LA  - English
J2  - Ther. Adv. Gastroenterol.
M3  - Review
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 0; Correspondence Address: A. Lahat; email: zokadi@gmail.com
ER  -

TY  - CONF
AU  - Agostini, D.
AU  - Picasso, F.
TI  - Large Language Models for Sustainable Assessment and Feedback in Higher Education: Towards a Pedagogical and Technological Framework
PY  - 2023
T2  - CEUR Workshop Proceedings
VL  - 3605
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85183207058&partnerID=40&md5=980513e31ae1f48174bfa2bce2a65e80
AD  - University of Trento, Palazzo Fedrigotti, corso Bettini 31, Rovereto, 38068, Italy
AB  - Nowadays, there is growing attention on enhancing the quality of teaching, learning and assessment processes. As a recent EU Report underlines, the assessment and feedback area remains a problematic issue regarding educational professionals’ training and adopting new practices. In fact, traditional summative assessment practices are predominantly used in European countries, against the recommendations of the Bologna Process guidelines that promote the implementation of alternative assessment practices that seem crucial in order to engage and provide lifelong learning skills for students, also with the use of technology. Looking at the literature, a series of sustainability problems arise when these requests meet real-world teaching, particularly when academic instructors face the assessment of extensive classes. With the fast advancement in Large Language Models (LLMs) and their increasing availability, affordability and capability, part of the solution to these problems might be at hand. In fact, LLMs can process large amounts of text, summarise and give feedback about it following predetermined criteria. The insights of that analysis can be used both for giving feedback to the student and helping the instructor assess the text. With the proper pedagogical and technological framework, LLMs can disengage instructors from some of the time-related sustainability issues and so from the only choice of the multiple-choice test and similar. For this reason, as a first step, we are proposing a starting point for such a framework to a panel of experts following the Delphi methodology and reporting the results. © 2022 Copyright for this paper by its authors. Use permitted under Creative Commons License Attribution 4.0 International (CC BY 4.0).
KW  - Artificial Intelligence
KW  - Assessment
KW  - Educational Technology
KW  - Evaluation
KW  - Higher Education
KW  - Large Language Models
KW  - Technology-Enhanced Assessment
KW  - Computational linguistics
KW  - Education computing
KW  - Engineering education
KW  - Sustainable development
KW  - Assessment
KW  - Assessment practices
KW  - Evaluation
KW  - High educations
KW  - Language model
KW  - Large language model
KW  - Quality of teaching
KW  - Sustainable assessment
KW  - Technological framework
KW  - Technology-enhanced assessment
KW  - Students
A2  - Schicchi D.
A2  - National Research Council, Istitute for Education Technology, Via Ugo la Malfa 152, Palermo
A2  - Taibi D.
A2  - National Research Council, Istitute for Education Technology, Via Ugo la Malfa 152, Palermo
A2  - Temperini M.
A2  - Universita Roma Sapienza, Ingegneria Informatica, Automatica, e Gestionale "Antonio Ruberti", Via Ariosto, 25, Roma
PB  - CEUR-WS
SN  - 16130073 (ISSN)
LA  - English
J2  - CEUR Workshop Proc.
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 0; Correspondence Address: D. Agostini; University of Trento, Palazzo Fedrigotti, Rovereto, corso Bettini 31, 38068, Italy; email: daniele.agostini@unitn.it; Conference name: 1st International Workshop on High-Performance Artificial Intelligence Systems in Education, AIxEDU 2023; Conference code: 196077
ER  -

TY  - JOUR
AU  - Campbell, D.J.
AU  - Estephan, L.E.
AU  - Sina, E.M.
AU  - Mastrolonardo, E.V.
AU  - Alapati, R.
AU  - Amin, D.R.
AU  - Cottrill, E.E.
TI  - Evaluating ChatGPT Responses on Thyroid Nodules for Patient Education
PY  - 2023
T2  - Thyroid
DO  - 10.1089/thy.2023.0491
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85182229519&doi=10.1089%2fthy.2023.0491&partnerID=40&md5=801985f453f71d82c671ffed3bd9fa4c
AD  - Department of Otolaryngology—Head and Neck Surgery, Thomas Jefferson University Hospitals, Philadelphia, PA, United States
AB  - Background: ChatGPT, an artificial intelligence (AI) chatbot, is the fastest growing consumer application in history. Given recent trends identifying increasing patient use of Internet sources for self-education, we seek to evaluate the quality of ChatGPT-generated responses for patient education on thyroid nodules. Methods: ChatGPT was queried 4 times with 30 identical questions. Queries differed by initial chatbot prompting: no prompting, patient-friendly prompting, 8th-grade level prompting, and prompting for references. Answers were scored on a hierarchical score: incorrect, partially correct, correct, or correct with references. Proportions of responses at incremental score thresholds were compared by prompt type using chi-squared analysis. Flesch–Kincaid grade level was calculated for each answer. The relationship between prompt type and grade level was assessed using analysis of variance. References provided within ChatGPT answers were totaled and analyzed for veracity. Results: Across all prompts (n = 120 questions), 83 answers (69.2%) were at least correct. Proportions of responses that were at least partially correct (p = 0.795) and correct (p = 0.402) did not differ by prompt; responses that were correct with references did (p < 0.0001). Responses from 8th-grade level prompting were the lowest mean grade level (13.43 – 2.86) and were significantly lower than no prompting (14.97 – 2.01, p = 0.01) and prompting for references (16.43 – 2.05, p < 0.0001). Prompting for references generated 80/80 (100%) of referenced medical publications within answers. Seventy references (87.5%) were legitimate citations, and 58/80 (72.5%) provided accurately reported information from the referenced publication. Conclusion: ChatGPT overall provides appropriate answers to most questions on thyroid nodules regardless of prompting. Despite targeted prompting strategies, ChatGPT reliably generates responses corresponding to grade levels well-above accepted recommendations for presenting medical information to patients. Significant rates of AI hallucination may preclude clinicians from recommending the current version of ChatGPT as an educational tool for patients at this time. © Mary Ann Liebert, Inc.
KW  - artificial intelligence
KW  - ChatGPT
KW  - patient education
KW  - thyroid nodule
PB  - Mary Ann Liebert Inc.
SN  - 10507256 (ISSN)
C2  - 38010917
LA  - English
J2  - Thyroid
M3  - Article
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 1; Correspondence Address: D.J. Campbell; Department of Otolaryngology—Head and Neck Surgery, Thomas Jefferson University Hospitals, Philadelphia, 925 Chestnut Street, Floor 6, 19107, United States; email: djc024@jefferson.edu; CODEN: THYRE
ER  -

TY  - CONF
AU  - Sewunetie, W.T.
AU  - Kovács, L.
TI  - Efficiency Evaluation of ChatGPT for Adverb Type Categorization
PY  - 2023
T2  - DISA 2023 - World Symposium on Digital Intelligence for Systems and Machines, Proceedings
SP  - 199
EP  - 203
DO  - 10.1109/DISA59116.2023.10308928
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85179521050&doi=10.1109%2fDISA59116.2023.10308928&partnerID=40&md5=d1a0620523a06060d56f45c9a594d377
AD  - Institute of Informatics, University of Miskolc, Miskolc, Hungary
AB  - Recent generative pre-trained transformer models provide outstanding performance in many different natural language tasks. This paper presents an evaluation of the efficiency of the ChatGPT 3.5 language model, and Dictionary and MLbased methods, in the task of adverb type categorization within natural language processing. This evaluation provides insights into the strengths and weaknesses of ChatGPT 3.5 and its potential applications in English sentence parsing and language understanding tasks. In this evaluation scenario, the average test score for the ChatGPT-based method is found to be 3.5 out of 5, indicating the overall evaluation by the experts. Similarly, the Dictionary and ML-based method achieves an average test score of 3.6 out of 5, reflecting the collective assessment by the evaluators. These findings of our test results contribute to our understanding of the performance and effectiveness of both approaches in adverb-type categorization. © 2023 IEEE.
KW  - Adverb Type
KW  - ChatGPT
KW  - Dictionary-Based Method
KW  - Machine Learning-based method
KW  - Efficiency
KW  - Learning algorithms
KW  - Natural language processing systems
KW  - Syntactics
KW  - Adverb type
KW  - ChatGPT
KW  - Dictionary-based method
KW  - Efficiency evaluation
KW  - Learning-based methods
KW  - Machine learning-based method
KW  - Machine-learning
KW  - Natural languages
KW  - Performance
KW  - Transformer modeling
KW  - Machine learning
A2  - Sincak P.
A2  - Magyar J.
A2  - Szaboova M.
PB  - Institute of Electrical and Electronics Engineers Inc.
SN  - 979-835034353-3 (ISBN)
LA  - English
J2  - DISA - World Symp. Digit. Intell. Syst. Mach., Proc.
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 0; Correspondence Address: W.T. Sewunetie; Institute of Informatics, University of Miskolc, Miskolc, Hungary; email: waleligntewabe@gmail.com; Conference name: 2023 World Symposium on Digital Intelligence for Systems and Machines, DISA 2023; Conference date: 21 September 2023 through 22 September 2023; Conference code: 194437
ER  -

TY  - JOUR
AU  - Saad, E.
AU  - dos Santos, M.C.
TI  - Journalism, artificial intelligence and disinformation: preliminary assessment of the potential use of natural language generation tools, based on the GPT model, for the dissemination of false news
ST  - Periodismo, inteligencia artificial y desinformación: evaluación preliminar del uso potencial de herramientas de generación de lenguaje natural, basadas en el modelo GPT, para la difusión de notícias falsas
PY  - 2023
T2  - Estudios Sobre el Mensaje Periodistico
VL  - 29
IS  - 4
SP  - 783
EP  - 794
DO  - 10.5209/esmp.87965
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85179816063&doi=10.5209%2fesmp.87965&partnerID=40&md5=5e7e714f9bf6a0736252605e1684b3f4
AD  - Universidade de São Paulo, Brazil
AD  - Universidade Federal do Maranhão, Brazil
AB  - We propose an inconclusive reflection on the use of artificial intelligence systems in the field of Journalism, specifically, the use of generative systems based on GPT. We assume that such systems can support journalistic work by taking on repetitive tasks, but potentially are used as a tool for disseminating misinformation. The theoretical framework is supported by authors in the field, either for the understanding of disinformation, or for the different aspects of the use of generative systems in journalism. We chose to develop a multi-method approach to encompass a literature review and a digital-based experiment. The experiment consisted of a dialogue with the ChatGPT conversational bot on our topic, demonstrating vulnerabilities when confronted with aspects of quality, ethics, journalistic clarity in addition to the production of bias. As a result, the essential role of the human in journalistic processes was evidenced through active editorial and checking functions, guaranteeing the legitimacy of the field in society. © 2023 Universidad Complutense de Madrid. All rights reserved.
KW  - artificial intelligence
KW  - conversational robots
KW  - journalism
KW  - misinformation
PB  - Universidad Compultense Madrid
SN  - 11341629 (ISSN)
LA  - Portuguese
J2  - Estud. Sobre Mensaje Periodistico
M3  - Article
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 0
ER  -

TY  - CONF
AU  - Zhang, Z.
AU  - Yu, J.
AU  - Li, J.
AU  - Hou, L.
TI  - Exploring the Cognitive Knowledge Structure of Large Language Models: An Educational Diagnostic Assessment Approach
PY  - 2023
T2  - Findings of the Association for Computational Linguistics: EMNLP 2023
SP  - 1643
EP  - 1650
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85183294049&partnerID=40&md5=a5c986c114c78a3869ab79d71d2ea067
AD  - Department of Computer Science and Technology, Tsinghua University, Beijing, 100084, China
AB  - Large Language Models (LLMs) have not only exhibited exceptional performance across various tasks, but also demonstrated sparks of intelligence. Recent studies have focused on assessing their capabilities on human exams and revealed their impressive competence in different domains. However, cognitive research on the overall knowledge structure of LLMs is still lacking. In this paper, based on educational diagnostic assessment method, we conduct an evaluation using MoocRadar, a meticulously annotated human test dataset based on Bloom Taxonomy. We aim to reveal the knowledge structures of LLMs and gain insights of their cognitive capabilities. This research emphasizes the significance of investigating LLMs' knowledge and understanding the disparate cognitive patterns of LLMs. By shedding light on models' knowledge, researchers can advance development and utilization of LLMs in a more informed and effective manner. © 2023 Association for Computational Linguistics.
KW  - Computational linguistics
KW  - Assessment approaches
KW  - Bloom taxonomies
KW  - Cognitive capability
KW  - Different domains
KW  - Gain insight
KW  - Human tests
KW  - Knowledge structures
KW  - Language model
KW  - Model knowledge
KW  - Performance
KW  - Statistical tests
PB  - Association for Computational Linguistics (ACL)
SN  - 979-889176061-5 (ISBN)
LA  - English
J2  - Find. Assoc. Comput. Linguist.: EMNLP
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 0; Correspondence Address: J. Li; Department of Computer Science and Technology, Tsinghua University, Beijing, 100084, China; email: lijuanzi@tsinghua.edu.cn; Conference name: 2023 Findings of the Association for Computational Linguistics: EMNLP 2023; Conference date: 6 December 2023 through 10 December 2023; Conference code: 196127
ER  -

TY  - CONF
AU  - Lai, V.D.
AU  - Ngo, N.T.
AU  - Veyseh, A.P.B.
AU  - Man, H.
AU  - Dernoncourt, F.
AU  - Bui, T.
AU  - Nguyen, T.H.
TI  - ChatGPT Beyond English: Towards a Comprehensive Evaluation of Large Language Models in Multilingual Learning
PY  - 2023
T2  - Findings of the Association for Computational Linguistics: EMNLP 2023
SP  - 13171
EP  - 13189
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85183291334&partnerID=40&md5=750f615ac524c8261f4f9cd4bca3f281
AD  - Dept. of Computer Science, University of Oregon, OR, United States
AD  - Adobe Research, United States
AB  - Over the last few years, large language models (LLMs) have emerged as the most important breakthroughs in natural language processing (NLP) that fundamentally transform research and developments in the field. ChatGPT represents one of the most exciting LLM systems developed recently to showcase impressive skills for language generation and highly attract public attention. Among various exciting applications discovered for ChatGPT in English, the model can process and generate texts for multiple languages due to its multilingual training data. Given the broad adoption of ChatGPT for English in different problems and areas, a natural question is whether ChatGPT can also be applied effectively for other languages or it is necessary to develop more language-specific technologies. The answer to this question requires a thorough evaluation of ChatGPT over multiple tasks with diverse languages and large datasets (i.e., beyond reported anecdotes), which is still missing or limited in current research. Our work aims to fill this gap for the evaluation of ChatGPT and similar LLMs to provide more comprehensive information for multilingual NLP applications. In particular, we evaluate ChatGPT on 7 different tasks, covering 37 diverse languages with high, medium, low, and extremely low resources. Compared to the performance of previous models, our extensive experiments demonstrate the worse performance of ChatGPT for different NLP tasks and languages, calling for further research to develop better models and understanding for multilingual learning. © 2023 Association for Computational Linguistics.
KW  - Computational linguistics
KW  - Learning systems
KW  - Natural language processing systems
KW  - Comprehensive evaluation
KW  - Language generation
KW  - Language model
KW  - Language processing
KW  - Modelling systems
KW  - Multilingual learning
KW  - Multiple languages
KW  - Natural languages
KW  - Performance
KW  - Research and development
KW  - Large datasets
PB  - Association for Computational Linguistics (ACL)
SN  - 979-889176061-5 (ISBN)
LA  - English
J2  - Find. Assoc. Comput. Linguist.: EMNLP
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 1; Conference name: 2023 Findings of the Association for Computational Linguistics: EMNLP 2023; Conference date: 6 December 2023 through 10 December 2023; Conference code: 196127
ER  -

TY  - CONF
AU  - Rodriguez-Cardenas, D.
AU  - Palacio, D.N.
AU  - Khati, D.
AU  - Burke, H.
AU  - Poshyvanyk, D.
TI  - Benchmarking Causal Study to Interpret Large Language Models for Source Code
PY  - 2023
T2  - Proceedings - 2023 IEEE International Conference on Software Maintenance and Evolution, ICSME 2023
SP  - 329
EP  - 334
DO  - 10.1109/ICSME58846.2023.00040
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85181540936&doi=10.1109%2fICSME58846.2023.00040&partnerID=40&md5=3f30fddab450383f7c1fe92190286e8f
AD  - William and Mary, Department of Computer Science, Williamsburg, VA, United States
AB  - One of the most common solutions adopted by software researchers to address code generation is by training Large Language Models (LLMs) on massive amounts of source code. LLMs are rooted in the concept of emergent capabilities in which machines statistically learn complex patterns from code data. Although a number of studies have shown that LLMs have been effectively evaluated on popular accuracy metrics (e.g., BLEU, CodeBleu), previous research has largely overlooked the role of Causal Inference as a fundamental component of the interpretability of LLMs' performance. Existing benchmarks and datasets are meant to highlight the difference between the expected and the generated outcome, but do not take into account confounding variables (e.g., lines of code, number of tokens, prompt size) that equally influence the accuracy metrics. The fact remains that, when dealing with generative software tasks by LLMs, no benchmark is available to tell researchers how to quantify neither the causal effect of SE-based treatments nor the correlation of confounders to the model's performance. In an effort to bring statistical rigor to the evaluation of LLMs, this paper introduces a benchmarking strategy named Galeras comprised of curated testbeds for three SE tasks (i.e., code completion, code summarization, and commit generation) to help aid the interpretation of LLMs' performance.We illustrate the insights of our benchmarking strategy by conducting a case study on the performance of ChatGPT under distinct prompt engineering methods. The results of the case study demonstrate the positive causal influence of prompt semantics on ChatGPT's generative performance by an average treatment effect of ≈ 3%. Moreover, it was found that confounders such as prompt size are highly correlated with accuracy metrics (≈ 0.412). The end result of our case study is to showcase causal inference evaluations, in practice, to reduce confounding bias. By reducing the bias, we offer an interpretable solution for the accuracy metric under analysis. © 2023 IEEE.
KW  - dl4se
KW  - Interpretability
KW  - Large Language Models
KW  - Software Engineering
KW  - Testbeds
KW  - Codes (symbols)
KW  - Computational linguistics
KW  - Semantics
KW  - Testbeds
KW  - Case-studies
KW  - Causal inferences
KW  - Confounder
KW  - Dl4se
KW  - Interpretability
KW  - Language model
KW  - Large language model
KW  - Modeling performance
KW  - Performance
KW  - Source codes
KW  - Benchmarking
PB  - Institute of Electrical and Electronics Engineers Inc.
SN  - 979-835032783-0 (ISBN)
LA  - English
J2  - Proc. - IEEE Int. Conf. Softw. Maint. Evolut., ICSME
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 0; Correspondence Address: D. Rodriguez-Cardenas; William and Mary, Department of Computer Science, Williamsburg, United States; email: dhrodriguezcar@wm.edu; Conference name: 39th IEEE International Conference on Software Maintenance and Evolution, ICSME 2023; Conference date: 1 October 2023 through 6 October 2023; Conference code: 195314
ER  -

TY  - CONF
AU  - Rodríguez, R.A.N.
AU  - Contreras, J.P.
AU  - Unsihuay-Vila, C.
AU  - Ardila, O.P.
AU  - Kaiss, M.
TI  - Real-time validation of an equivalent model of Optimal Power Flow in Smart Transformer-based Meshed Hybrid Microgrids
PY  - 2023
T2  - 2023 IEEE Workshop on Power Electronics and Power Quality Applications, PEPQA 2023 - Proceedings
DO  - 10.1109/PEPQA59611.2023.10325800
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85179629081&doi=10.1109%2fPEPQA59611.2023.10325800&partnerID=40&md5=6dbcdb5c2f3567f80d80e3d66e939642
AD  - Facultad de Ingeniería - UNAB, Programa de Ingeniería Electrónica - UTS, Bucaramanga, Colombia
AD  - Universidad Autónoma de Occidente, Facultad de Ingeniería, Cali, Colombia
AD  - Universidade Federal do Paraná, Departamento de Engenharia Elétrica, Curitiba, Brazil
AD  - Universidad Pontificia Bolivariana, Facultad de Ingeniería Eléctrica y Electrónica, Bucaramanga, Colombia
AB  - Smart Transformer (ST)-based Meshed Hybrid Microgrids (MHM) present advantages concerning the performance of conventional AC-DC microgrids (MG). Integrating the ST in MHM and Optimal Power Flow (OPF) algorithms is a suitable alternative for managing microgrids with high penetration of distributed energy resources. Thus, equivalent models of converters associated with the MG and ST are required to facilitate the formulation and solution of the optimization problem. This paper proposes an equivalent power flow model in ST-based MHM to formulate an optimal power management algorithm for day-ahead operation. The management algorithm delivers the optimal operating points of each of the MG converters to allow power control on both the AC and DC sides. The feasible solution of the OPF is verified in a simulation model in Matlab® Simulink® and its implementation in Real-time on the OPAL-RT platform to compare the results and validate the accuracy of the static models of the OPF. According to the tests performed, the accuracy of the ST equivalent model for Optimal Power Flow for day-ahead operation problems of MHM was verified based on Software-In-the-Loop (SIL) approach.  © 2023 IEEE.
KW  - AC/DC microgrid
KW  - Distributed Generation
KW  - Meshed Hybrid Microgrids
KW  - Real-time Simulation
KW  - Smart Transformer
KW  - Acoustic generators
KW  - Electric load flow
KW  - Energy resources
KW  - MATLAB
KW  - Microgrids
KW  - Power control
KW  - Simulation platform
KW  - Software testing
KW  - AC/DC microgrid
KW  - Day-ahead
KW  - Equivalent modeling
KW  - Meshed hybrid microgrid
KW  - Microgrid
KW  - Optimal power flows
KW  - Real-time validation
KW  - Realtime simulation (RTS)
KW  - Smart transformer
KW  - Distributed power generation
PB  - Institute of Electrical and Electronics Engineers Inc.
SN  - 979-835038299-0 (ISBN)
LA  - English
J2  - IEEE Workshop Power Electron. Power Qual. Appl., PEPQA - Proc.
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 0; Conference name: 5th IEEE Workshop on Power Electronics and Power Quality Applications, PEPQA 2023; Conference date: 5 October 2023 through 6 October 2023; Conference code: 194792
ER  -

TY  - CONF
AU  - Wang, X.
AU  - Gupta, D.
AU  - Killian, M.
AU  - He, Z.
TI  - Benchmarking Transformer-Based Models for Identifying Social Determinants of Health in Clinical Notes
PY  - 2023
T2  - Proceedings - 2023 IEEE 11th International Conference on Healthcare Informatics, ICHI 2023
SP  - 570
EP  - 574
DO  - 10.1109/ICHI57859.2023.00102
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85181557095&doi=10.1109%2fICHI57859.2023.00102&partnerID=40&md5=8b3c29febe0f6bb9a636237422c836ab
AD  - Florida State University, Department of Statistics, Tallahassee, FL, United States
AD  - University of Florida, College of Medicine, Gainesville, FL, United States
AD  - Florida State University, College of Social Work, Tallahassee, FL, United States
AD  - Florida State University, School of Information, Tallahassee, FL, United States
AB  - Electronic health records (EHR) have been widely used in building machine learning models for health outcomes prediction. However, many EHR-based models are inherently biased due to lack of risk factors on social determinants of health (SDoH), which are responsible for up to 40% preventive deaths. As SDoH information is often captured in clinical notes, recent efforts have been made to extract such information from notes with natural language processing and append it to other structured data. In this work, we benchmark 7 pre-trained transformer-based models, including BERT, ALBERT, BioBERT, BioClinicalBERT, RoBERTa, ELECTRA, and RoBERTa-MIMIC-Trial, for recognizing SDoH terms using a previously annotated corpus of MIMIC-III clinical notes. Our study shows that BioClinicalBERT model performs best on F-1 scores (0.911, 0.923) under both strict and relaxed criteria. This work shows the promise of using transformer-based models for recognizing SDoH information from clinical notes. © 2023 IEEE.
KW  - Named entity recognition
KW  - Natural language processing
KW  - Social determinants of health
KW  - Economic and social effects
KW  - Learning algorithms
KW  - Medical informatics
KW  - Natural language processing systems
KW  - Clinical notes
KW  - Electronic health
KW  - Health informations
KW  - Health records
KW  - In-buildings
KW  - Language processing
KW  - Named entity recognition
KW  - Natural language processing
KW  - Natural languages
KW  - Social determinants of healths
KW  - Health risks
PB  - Institute of Electrical and Electronics Engineers Inc.
SN  - 979-835030263-9 (ISBN)
LA  - English
J2  - Proc. - IEEE Int. Conf. Healthc. Informatics, ICHI
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 0; Correspondence Address: X. Wang; Florida State University, Department of Statistics, Tallahassee, United States; email: xw22e@fsu.edu; Conference name: 11th IEEE International Conference on Healthcare Informatics, ICHI 2023; Conference date: 26 June 2023 through 29 June 2023; Conference code: 195320
ER  -

TY  - CONF
AU  - Li, J.
AU  - Gui, L.
AU  - Zhou, Y.
AU  - West, D.
AU  - Aloisi, C.
AU  - He, Y.
TI  - Distilling ChatGPT for Explainable Automated Student Answer Assessment
PY  - 2023
T2  - Findings of the Association for Computational Linguistics: EMNLP 2023
SP  - 6007
EP  - 6026
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85183290529&partnerID=40&md5=f547f2cf6ec9e739f3a3a51b6f11b121
AD  - Department of Informatics, King's College London, United Kingdom
AD  - AQA, United Kingdom
AD  - The Alan Turing Institute, United Kingdom
AB  - Providing explainable and faithful feedback is crucial for automated student answer assessment. In this paper, we introduce a novel framework that explores using ChatGPT, a cutting-edge large language model, for the concurrent tasks of student answer scoring and rationale generation. We identify the appropriate instructions by prompting ChatGPT with different templates to collect the rationales, where inconsistent rationales are refined to align with marking standards. The refined ChatGPT outputs enable us to fine-tune a smaller language model that simultaneously assesses student answers and provides rationales. Extensive experiments on the benchmark dataset show that the proposed method improves the overall QWK score by 11% compared to ChatGPT. Furthermore, our thorough analysis and human evaluation demonstrate that the rationales generated by our proposed method are comparable to those of ChatGPT. Our approach provides a viable solution to achieve explainable automated assessment in education. © 2023 Association for Computational Linguistics.
KW  - Automation
KW  - Computational linguistics
KW  - Analysis evaluation
KW  - Automated assessment
KW  - Benchmark datasets
KW  - Concurrent tasks
KW  - Cutting edges
KW  - Human evaluation
KW  - Language model
KW  - Viable solutions
KW  - Students
PB  - Association for Computational Linguistics (ACL)
SN  - 979-889176061-5 (ISBN)
LA  - English
J2  - Find. Assoc. Comput. Linguist.: EMNLP
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 0; Conference name: 2023 Findings of the Association for Computational Linguistics: EMNLP 2023; Conference date: 6 December 2023 through 10 December 2023; Conference code: 196127
ER  -

TY  - CONF
AU  - Shen, C.
AU  - Cheng, L.
AU  - Nguyen, X.-P.
AU  - You, Y.
AU  - Bing, L.
TI  - Large Language Models are Not Yet Human-Level Evaluators for Abstractive Summarization
PY  - 2023
T2  - Findings of the Association for Computational Linguistics: EMNLP 2023
SP  - 4215
EP  - 4233
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85183310221&partnerID=40&md5=98abae56cde5b7eb8e80630829cef9ac
AD  - DAMO Academy, Alibaba Group, Singapore
AD  - National University of Singapore, Singapore
AD  - Hupan Lab, Hangzhou, 310023, China
AB  - With the recent undeniable advancement in reasoning abilities in large language models (LLMs) like ChatGPT and GPT-4, there is a growing trend for using LLMs on various tasks. One area where LLMs can be employed is as an alternative evaluation metric for complex generative tasks, which generally demands expensive human judges to complement the traditional automatic metrics for various evaluation dimensions such as fluency and consistency. In this work, we conduct extensive analysis to investigate the stability and reliability of LLMs as automatic evaluators for abstractive summarization. We found that while ChatGPT and GPT-4 outperform the commonly used automatic metrics, they are not ready as human replacements due to significant limitations. That is, LLM evaluators rate each candidate system inconsistently and are dimension-dependent. They also struggle to compare candidates with close performance and become more unreliable with higher-quality summaries by obtaining a lower correlation with humans. In other words, with better abstractive summarization systems being introduced at a fast pace, LLMs may result in misleading and unreliable evaluations. © 2023 Association for Computational Linguistics.
KW  - Reliability analysis
KW  - Automatic metrics
KW  - Evaluation metrics
KW  - High quality
KW  - Human levels
KW  - Language model
KW  - Lower correlation
KW  - Performance
KW  - Reasoning ability
KW  - Stability and reliabilities
KW  - Summarization systems
KW  - Computational linguistics
PB  - Association for Computational Linguistics (ACL)
SN  - 979-889176061-5 (ISBN)
LA  - English
J2  - Find. Assoc. Comput. Linguist.: EMNLP
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 0; Correspondence Address: L. Bing; DAMO Academy, Alibaba Group, Singapore; email: l.bing@alibaba-inc.com; Conference name: 2023 Findings of the Association for Computational Linguistics: EMNLP 2023; Conference date: 6 December 2023 through 10 December 2023; Conference code: 196127
ER  -

TY  - CONF
AU  - Jumelet, J.
AU  - Zuidema, W.
TI  - Transparency at the Source: Evaluating and Interpreting Language Models With Access to the True Distribution
PY  - 2023
T2  - Findings of the Association for Computational Linguistics: EMNLP 2023
SP  - 4354
EP  - 4369
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85183310465&partnerID=40&md5=4ef1eabb8186ad1025d04ab009cfd27b
AD  - Institute for Logic, Language and Computation, University of Amsterdam, Netherlands
AB  - We present a setup for training, evaluating and interpreting neural language models, that uses artificial, language-like data. The data is generated using a massive probabilistic grammar (based on state-split PCFGs), that is itself derived from a large natural language corpus, but also provides us complete control over the generative process. We describe and release both grammar and corpus, and test for the naturalness of our generated data. This approach allows us to define closed-form expressions to efficiently compute exact lower bounds on obtainable perplexity using both causal and masked language modelling. Our results show striking differences between neural language modelling architectures and training objectives in how closely they allow approximating the lower bound on perplexity. Our approach also allows us to directly compare learned representations to symbolic rules in the underlying source. We experiment with various techniques for interpreting model behaviour and learning dynamics. With access to the underlying true source, our results show striking differences and outcomes in learning dynamics between different classes of words. © 2023 Association for Computational Linguistics.
KW  - Computational linguistics
KW  - Learning systems
KW  - Closed-form expression
KW  - Complete control
KW  - Generative process
KW  - Language model
KW  - Low bound
KW  - Model training
KW  - Modeling architecture
KW  - Natural languages
KW  - On state
KW  - Probabilistic grammars
KW  - Modeling languages
PB  - Association for Computational Linguistics (ACL)
SN  - 979-889176061-5 (ISBN)
LA  - English
J2  - Find. Assoc. Comput. Linguist.: EMNLP
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 0; Conference name: 2023 Findings of the Association for Computational Linguistics: EMNLP 2023; Conference date: 6 December 2023 through 10 December 2023; Conference code: 196127
ER  -

TY  - CONF
AU  - Shui, R.
AU  - Cao, Y.
AU  - Xiang, W.
AU  - Chua, T.-S.
TI  - A Comprehensive Evaluation of Large Language Models on Legal Judgment Prediction
PY  - 2023
T2  - Findings of the Association for Computational Linguistics: EMNLP 2023
SP  - 7337
EP  - 7348
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85183296473&partnerID=40&md5=2cb19582bc7c13ad6717ffa9f91024ab
AD  - National University of Singapore, Singapore
AD  - Singapore Management University, Singapore
AD  - University of Science and Technology, China
AB  - Large language models (LLMs) have demonstrated great potential for domain-specific applications, such as the law domain. However, recent disputes over GPT-4's law evaluation raise questions concerning their performance in real-world legal tasks. To systematically investigate their competency in the law, we design practical baseline solutions based on LLMs and test on the task of legal judgment prediction. In our solutions, LLMs can work alone to answer open questions or coordinate with an information retrieval (IR) system to learn from similar cases or solve simplified multi-choice questions. We show that similar cases and multi-choice options, namely label candidates, included in prompts can help LLMs recall domain knowledge that is critical for expertise legal reasoning. We additionally present an intriguing paradox wherein an IR system surpasses the performance of LLM+IR due to limited gains acquired by weaker LLMs from powerful IR systems. In such cases, the role of LLMs becomes redundant. Our evaluation pipeline can be easily extended into other tasks to facilitate evaluations in other domains. Code is available at https://github.com/srhthu/LM-CompEval-Legal. © 2023 Association for Computational Linguistics.
KW  - Computational linguistics
KW  - Domain Knowledge
KW  - Comprehensive evaluation
KW  - Domain-specific application
KW  - Information-retrieval systems
KW  - Language model
KW  - Law evaluation
KW  - Legal judgements
KW  - Multi choices
KW  - Performance
KW  - Real-world
KW  - Similar case
KW  - Search engines
PB  - Association for Computational Linguistics (ACL)
SN  - 979-889176061-5 (ISBN)
LA  - English
J2  - Find. Assoc. Comput. Linguist.: EMNLP
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 0; Conference name: 2023 Findings of the Association for Computational Linguistics: EMNLP 2023; Conference date: 6 December 2023 through 10 December 2023; Conference code: 196127
ER  -

TY  - JOUR
AU  - Dergaa, I.
AU  - Fekih-Romdhane, F.
AU  - Hallit, S.
AU  - Loch, A.A.
AU  - Glenn, J.M.
AU  - Fessi, M.S.
AU  - Ben Aissa, M.
AU  - Souissi, N.
AU  - Guelmami, N.
AU  - Swed, S.
AU  - El Omri, A.
AU  - Bragazzi, N.L.
AU  - Ben Saad, H.
TI  - ChatGPT is not ready yet for use in providing mental health assessment and interventions
PY  - 2023
T2  - Frontiers in Psychiatry
VL  - 14
C7  - 1277756
DO  - 10.3389/fpsyt.2023.1277756
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85182420102&doi=10.3389%2ffpsyt.2023.1277756&partnerID=40&md5=4828523bf4618e6759a6cf49209d8d0e
AD  - Primary Health Care Corporation (PHCC), Doha, Qatar
AD  - Research Unit Physical Activity, Sport, and Health, UR18JS01, National Observatory of Sport, Tunis, Tunisia
AD  - High Institute of Sport and Physical Education, University of Sfax, Sfax, Tunisia
AD  - The Tunisian Center of Early Intervention in Psychosis, Department of Psychiatry “Ibn Omrane”, Razi Hospital, Manouba, Tunisia
AD  - Faculty of Medicine of Tunis, Tunis El Manar University, Tunis, Tunisia
AD  - School of Medicine and Medical Sciences, Holy Spirit University of Kaslik, Jounieh, Lebanon
AD  - Psychology Department, College of Humanities, Effat University, Jeddah, Saudi Arabia
AD  - Applied Science Research Center, Applied Science Private University, Amman, Jordan
AD  - Laboratorio de Neurociencias (LIM 27), Hospital das Clínicas HCFMUSP, Faculdade de Medicina, Instituto de Psiquiatria, Universidade de Sao Paulo, São Paulo, Brazil
AD  - Instituto Nacional de Biomarcadores em Neuropsiquiatria (INBION), Conselho Nacional de Desenvolvimento Científico e Tecnológico, São Paulo, Brazil
AD  - Neurotrack Technologies, Redwood City, CA, United States
AD  - Department of Human and Social Sciences, Higher Institute of Sport and Physical Education of Kef, University of Jendouba, Jendouba, Tunisia
AD  - Department of Health Sciences (DISSAL), Postgraduate School of Public Health, University of Genoa, Genoa, Italy
AD  - Faculty of Medicine, Aleppo University, Aleppo, Syrian Arab Republic
AD  - Surgical Research Section, Department of Surgery, Hamad Medical Corporation, Doha, Qatar
AD  - Laboratory for Industrial and Applied Mathematics, Department of Mathematics and Statistics, York University, Toronto, ON, Canada
AD  - Service of Physiology and Functional Explorations, Farhat HACHED Hospital, University of Sousse, Sousse, Tunisia
AD  - Heart Failure (LR12SP09) Research Laboratory, Farhat HACHED Hospital, University of Sousse, Sousse, Tunisia
AB  - Background: Psychiatry is a specialized field of medicine that focuses on the diagnosis, treatment, and prevention of mental health disorders. With advancements in technology and the rise of artificial intelligence (AI), there has been a growing interest in exploring the potential of AI language models systems, such as Chat Generative Pre-training Transformer (ChatGPT), to assist in the field of psychiatry. Objective: Our study aimed to evaluates the effectiveness, reliability and safeness of ChatGPT in assisting patients with mental health problems, and to assess its potential as a collaborative tool for mental health professionals through a simulated interaction with three distinct imaginary patients. Methods: Three imaginary patient scenarios (cases A, B, and C) were created, representing different mental health problems. All three patients present with, and seek to eliminate, the same chief complaint (i.e., difficulty falling asleep and waking up frequently during the night in the last 2°weeks). ChatGPT was engaged as a virtual psychiatric assistant to provide responses and treatment recommendations. Results: In case A, the recommendations were relatively appropriate (albeit non-specific), and could potentially be beneficial for both users and clinicians. However, as complexity of clinical cases increased (cases B and C), the information and recommendations generated by ChatGPT became inappropriate, even dangerous; and the limitations of the program became more glaring. The main strengths of ChatGPT lie in its ability to provide quick responses to user queries and to simulate empathy. One notable limitation is ChatGPT inability to interact with users to collect further information relevant to the diagnosis and management of a patient’s clinical condition. Another serious limitation is ChatGPT inability to use critical thinking and clinical judgment to drive patient’s management. Conclusion: As for July 2023, ChatGPT failed to give the simple medical advice given certain clinical scenarios. This supports that the quality of ChatGPT-generated content is still far from being a guide for users and professionals to provide accurate mental health information. It remains, therefore, premature to conclude on the usefulness and safety of ChatGPT in mental health practice. Copyright © 2024 Dergaa, Fekih-Romdhane, Hallit, Loch, Glenn, Fessi, Ben Aissa, Souissi, Guelmami, Swed, El Omri, Bragazzi and Ben Saad.
KW  - anxiety
KW  - chatbots
KW  - depression
KW  - insomnia
KW  - language models
KW  - mental health
KW  - patient care
KW  - psychiatric disorders
KW  - adult
KW  - Article
KW  - breast feeding
KW  - case report
KW  - ChatGPT
KW  - clinical article
KW  - clinical judgment
KW  - cognition
KW  - cognitive behavioral therapy
KW  - critical thinking
KW  - depression
KW  - empathy
KW  - female
KW  - generative pretrained transformer
KW  - human
KW  - insomnia
KW  - intervention study
KW  - male
KW  - medical information
KW  - medical practice
KW  - mental disease
KW  - mental health
KW  - mental health care personnel
KW  - nutritional support
KW  - patient care
KW  - psychiatry
KW  - psychological care
KW  - psychosis
KW  - relaxation sensation
KW  - risk assessment
KW  - sleep environment
KW  - sleep hygiene
KW  - sleep quality
KW  - social support
KW  - stress management
KW  - systemic lupus erythematosus
KW  - young adult
PB  - Frontiers Media SA
SN  - 16640640 (ISSN)
LA  - English
J2  - Front. Psychiatry
M3  - Article
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 0; Correspondence Address: I. Dergaa; Primary Health Care Corporation (PHCC), Doha, Qatar; email: Phd.dergaa@gmail.com
ER  -

TY  - JOUR
AU  - Ziegelmayer, S.
AU  - Marka, A.W.
AU  - Lenhart, N.
AU  - Nehls, N.
AU  - Reischl, S.
AU  - Harder, F.
AU  - Sauter, A.
AU  - Makowski, M.
AU  - Graf, M.
AU  - Gawlitza, J.
TI  - Evaluation of GPT-4's Chest X-Ray Impression Generation: A Reader Study on Performance and Perception
PY  - 2023
T2  - Journal of Medical Internet Research
VL  - 25
IS  - 1
DO  - 10.2196/50865
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85181177483&doi=10.2196%2f50865&partnerID=40&md5=8d55dec6cef10f57857b5e16dac86498
AD  - Department of Diagnostic and Interventional Radiology, School of Medicine & Klinikum rechts der Isar, Technical University of Munich, Munich, Germany
AB  - Exploring the generative capabilities of the multimodal GPT-4, our study uncovered significant differences between radiological assessments and automatic evaluation metrics for chest x-ray impression generation and revealed radiological bias. © 2023 Journal of Medical Internet Research. All rights reserved.
KW  - AI
KW  - artificial intelligence
KW  - chest
KW  - diagnostic
KW  - generative
KW  - generative model
KW  - GPT
KW  - image
KW  - images
KW  - imaging
KW  - impression
KW  - impressions
KW  - medical imaging
KW  - multimodal
KW  - radiography
KW  - radiological
KW  - radiology
KW  - x-ray
KW  - x-rays
KW  - Benchmarking
KW  - Humans
KW  - Perception
KW  - Radiography
KW  - Radiology
KW  - X-Rays
KW  - Article
KW  - evaluation study
KW  - human
KW  - Likert scale
KW  - model
KW  - performance
KW  - radiologist
KW  - thorax radiography
KW  - benchmarking
KW  - perception
KW  - radiography
KW  - radiology
KW  - X ray
PB  - JMIR Publications Inc.
SN  - 14388871 (ISSN)
C2  - 38133918
LA  - English
J2  - J. Med. Internet Res.
M3  - Article
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 1; Correspondence Address: S. Ziegelmayer; Department of Diagnostic and Interventional Radiology, School of Medicine & Klinikum rechts der Isar, Technical University of Munich, Munich, Ismaninger Straße 22, 81675, Germany; email: ga89rog@mytum.de
ER  -

TY  - JOUR
AU  - Song, C.
AU  - Song, Y.
TI  - Enhancing academic writing skills and motivation: assessing the efficacy of ChatGPT in AI-assisted language learning for EFL students
PY  - 2023
T2  - Frontiers in Psychology
VL  - 14
C7  - 1260843
DO  - 10.3389/fpsyg.2023.1260843
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85180873281&doi=10.3389%2ffpsyg.2023.1260843&partnerID=40&md5=230a4973a69624d6c3d85cbde146d369
AD  - School of Foreign Studies, North Minzu University, Ningxia, Yinchuan, China
AD  - School of Public Administration, Central South University, Hunan, Changsha, China
AB  - Introduction: This mixed-methods study evaluates the impact of AI-assisted language learning on Chinese English as a Foreign Language (EFL) students’ writing skills and writing motivation. As artificial intelligence (AI) becomes more prevalent in educational settings, understanding its effects on language learning outcomes is crucial. Methods: The study employs a comprehensive approach, combining quantitative and qualitative methods. The quantitative phase utilizes a pre-test and post-test design to assess writing skills. Fifty EFL students, matched for proficiency, are randomly assigned to experimental (AI-assisted instruction via ChatGPT) or control (traditional instruction) groups. Writing samples are evaluated using established scoring rubrics. Concurrently, semi-structured interviews are conducted with a subset of participants to explore writing motivation and experiences with AI-assisted learning. Results: Quantitative analysis reveals significant improvements in both writing skills and motivation among students who received AI-assisted instruction compared to the control group. The experimental group demonstrates enhanced proficiency in various aspects of writing, including organization, coherence, grammar, and vocabulary. Qualitative findings showcase diverse perspectives, ranging from recognition of AI’s innovative instructional role and its positive influence on writing skills and motivation to concerns about contextual accuracy and over-reliance. Participants also reflect on the long-term impact and sustainability of AI-assisted instruction, emphasizing the need for ongoing development and adaptation of AI tools. Discussion: The nuanced findings offer a comprehensive understanding of AI’s transformative potential in education. These insights have practical implications for practitioners and researchers, emphasizing the benefits, challenges, and the evolving nature of AI’s role in language instruction. Copyright © 2023 Song and Song.
KW  - AI-assisted language learning
KW  - ChatGPT
KW  - EFL students
KW  - mixed methods study
KW  - writing motivation
KW  - writing skills
PB  - Frontiers Media SA
SN  - 16641078 (ISSN)
LA  - English
J2  - Front. Psychol.
M3  - Article
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 0; Correspondence Address: C. Song; School of Foreign Studies, North Minzu University, Yinchuan, Ningxia, China; email: songcp2023@163.com
ER  -

TY  - JOUR
AU  - Rojas-Carabali, W.
AU  - Cifuentes-González, C.
AU  - Wei, X.
AU  - Putera, I.
AU  - Sen, A.
AU  - Thng, Z.X.
AU  - Agrawal, R.
AU  - Elze, T.
AU  - Sobrin, L.
AU  - Kempen, J.H.
AU  - Lee, B.
AU  - Biswas, J.
AU  - Nguyen, Q.D.
AU  - Gupta, V.
AU  - de-la-Torre, A.
AU  - Agrawal, R.
TI  - Response to the Comment on “Evaluating the Diagnostic Accuracy and Management Recommendations of ChatGpt in Uveitis”
PY  - 2023
T2  - Ocular Immunology and Inflammation
DO  - 10.1080/09273948.2023.2293924
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85180725873&doi=10.1080%2f09273948.2023.2293924&partnerID=40&md5=1ba4760d2d00d7764a1adf17d8ec0ee8
AD  - National Healthcare Group Eye Institute, Tan Tock Seng Hospital, Singapore, Singapore
AD  - Department of Bioinformatics, Lee Kong Chiang School of Medicine, Nanyang Technological University, Singapore, Singapore
AD  - Neuroscience ResearchGroup (NEUROS), Neurovitae Center for Neuroscience, Institute of TranslationalMedicine (IMT), Escuela de Medicina y Ciencias de la Salud, Universidad del Rosario, Bogotá, Colombia
AD  - Department of Ophthalmology, Faculty of Medicine, Universitas Indonesia – CiptoMangunkusmoKirana Eye Hospital, Jakarta, Indonesia
AD  - Laboratory Medical Immunology, Department of Immunology, ErasmusMC, University Medical Centre, Rotterdam, Netherlands
AD  - department of Internal Medicine, Division of Clinical Immunology, Erasmus MC, University Medical Center, Rotterdam, Netherlands
AD  - Department of Ophthalmology, Erasmus MC, University Medical Center, Rotterdam, Netherlands
AD  - Department of Vitreoretinal and Uveitis, Sadguru Netra Chikatsalya, Chitrakoot, India
AD  - Department of Ophthalmology, Massachusetts Eye and Ear/Harvard Medical School, Schepens Eye Research Institute, Boston, MA, United States
AD  - Community Ophthalmology, Sight for Souls, Bellevue, WA, United States
AD  - Department of Ophthalmology, Myungsung Medical College, MCM Comprehensive Specialized Hospital, Addis Ababa, Ethiopia
AD  - Department of Ocular Pathology and Uveitis, Medical Research Foundation, Sankara Netralaya, Chennai, India
AD  - Byers Eye Institute, Stanford University, Palo Alto, CA, United States
AD  - Post Graduate Institute of Medical Education and Research (PGIMER), Advance Eye Centre, Chandigarh, India
AD  - Department of Ophthalmology and Visual Sciences, Academic Clinical Program, Duke-NUS Medical School, Singapore, Singapore
AD  - Moorfields Eye Hospital, NHS Foundation Trust, London, United Kingdom
AD  - Singapore Eye Research Institute, The Academia, Singapore, Singapore
PB  - Taylor and Francis Ltd.
SN  - 09273948 (ISSN)
LA  - English
J2  - Ocul. Immunol. Inflamm.
M3  - Letter
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 0; Correspondence Address: R. Agrawal; National Healthcare Group Eye Institute, Tan Tock Seng Hospital, Singapore, 308433, Singapore; email: rupeshttsh@gmail.com; CODEN: OIINE
ER  -

TY  - JOUR
AU  - Hackl, V.
AU  - Müller, A.E.
AU  - Granitzer, M.
AU  - Sailer, M.
TI  - Is GPT-4 a reliable rater? Evaluating consistency in GPT-4's text ratings
PY  - 2023
T2  - Frontiers in Education
VL  - 8
C7  - 1272229
DO  - 10.3389/feduc.2023.1272229
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85180183813&doi=10.3389%2ffeduc.2023.1272229&partnerID=40&md5=c2f86985e19ddef0a449cd3b1799e889
AD  - Faculty of Social and Educational Sciences, University of Passau, Passau, Germany
AD  - Faculty of Law, University of Passau, Passau, Germany
AD  - Faculty of Computer Science and Mathematics, University of Passau, Passau, Germany
AB  - This study reports the Intraclass Correlation Coefficients of feedback ratings produced by OpenAI's GPT-4, a large language model (LLM), across various iterations, time frames, and stylistic variations. The model was used to rate responses to tasks related to macroeconomics in higher education (HE), based on their content and style. Statistical analysis was performed to determine the absolute agreement and consistency of ratings in all iterations, and the correlation between the ratings in terms of content and style. The findings revealed high interrater reliability, with ICC scores ranging from 0.94 to 0.99 for different time periods, indicating that GPT-4 is capable of producing consistent ratings. The prompt used in this study is also presented and explained. Copyright © 2023 Hackl, Müller, Granitzer and Sailer.
KW  - artificial intelligence
KW  - feedback
KW  - GPT-4
KW  - higher education
KW  - large language model
KW  - prompt engineering
PB  - Frontiers Media SA
SN  - 2504284X (ISSN)
LA  - English
J2  - Front. Educ.
M3  - Article
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 0; Correspondence Address: V. Hackl; Faculty of Social and Educational Sciences, University of Passau, Passau, Germany; email: veronika.hackl@uni-passau.de
ER  -

TY  - JOUR
AU  - Perlis, R.H.
AU  - Fihn, S.D.
TI  - Evaluating the Application of Large Language Models in Clinical Research Contexts
PY  - 2023
T2  - JAMA Network Open
C7  - e2335924
DO  - 10.1001/jamanetworkopen.2023.35924
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85179678249&doi=10.1001%2fjamanetworkopen.2023.35924&partnerID=40&md5=d78b1feffcf93ac3db9bd5832aba9e46
AD  - Center for Quantitative Health, Massachusetts General Hospital, Boston, United States
AD  - Department of Psychiatry, Harvard Medical School, Boston, MA, United States
AD  - JAMA Network Open, Chicago, IL, United States
AD  - Division of General Internal Medicine, University of Washington, Seattle, United States
PB  - American Medical Association
SN  - 25743805 (ISSN)
LA  - English
J2  - JAMA Netw. Open
M3  - Editorial
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 1; Correspondence Address: R.H. Perlis; Department of Psychiatry, Harvard Medical School, Boston, Simches Research Building, 185 Cambridge St, 02114, United States; email: rperlis@mgh.harvard.edu
ER  -

TY  - CONF
AU  - Prentzas, J.
AU  - Sidiropoulou, M.
TI  - Assessing the Use of Open AI Chat-GPT in a University Department of Education
PY  - 2023
T2  - 14th International Conference on Information, Intelligence, Systems and Applications, IISA 2023
DO  - 10.1109/IISA59645.2023.10345910
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85182023490&doi=10.1109%2fIISA59645.2023.10345910&partnerID=40&md5=ec921258bb55368daddd815ddd8961a6
AD  - Democritus University of Thrace, Dept. of Education Sciences in Early Childhood, Alexandroupolis, Greece
AB  - ICT tools are often used in education in an effort to provide an added value to teaching, learning, productivity and handling of administrative issues. Artificial Intelligence methods may be integrated in the tools used to enhance their effectiveness. This trend is gaining importance due to the continuous advances in Artificial Intelligence. An Artificial Intelligence tool that has recently gained popularity concerns the OpenAI Chat-GPT. Chat-GPT is designed to generate human-like text responses according to the input it receives. This enables it to engage in conversational interactions with users and generate user-adapted text. This paper concerns work-in-progress about the impact of Chat-GPT usage in a University Department of Education. The research study will involve students enrolled in various courses and staff members. The paper first discusses indicative uses of Chat-GPT in a University Department. It then outlines the goals of the study and also presents preliminary assessment results obtained from senior pre-service teachers enrolled in the undergraduate course 'Creative Writing'. © 2023 IEEE.
KW  - AI in education
KW  - Large language models
KW  - Natural language processing
KW  - Teacher education
KW  - Web-based learning
KW  - Artificial intelligence
KW  - Computer aided instruction
KW  - Education computing
KW  - Natural language processing systems
KW  - Students
KW  - Teaching
KW  - AI in education
KW  - Department of Education
KW  - ICT-tools
KW  - Language model
KW  - Language processing
KW  - Large language model
KW  - Natural language processing
KW  - Natural languages
KW  - Teacher education
KW  - Web-based-learning
KW  - E-learning
PB  - Institute of Electrical and Electronics Engineers Inc.
SN  - 979-835031806-7 (ISBN)
LA  - English
J2  - Int. Conf. Inf., Intell., Syst. Appl., IISA
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 0; Correspondence Address: M. Sidiropoulou; Democritus University of Thrace, Dept. of Education Sciences in Early Childhood, Alexandroupolis, Greece; email: masidiro@psed.duth.gr; Conference name: 14th International Conference on Information, Intelligence, Systems and Applications, IISA 2023; Conference date: 10 July 2023 through 12 July 2023; Conference code: 195501
ER  -

TY  - CONF
AU  - Lupu, D.
AU  - Groza, A.
AU  - Pease, A.
TI  - Cross-validation of Answers with SUMO and GPT
PY  - 2023
T2  - CEUR Workshop Proceedings
VL  - 3577
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85179546948&partnerID=40&md5=19fa9a6d20f4be4ab6edf41544488940
AD  - Department of Computer Science, Technical University of Cluj-Napoca, Romania
AD  - Articulate Software, United States
AB  - We have developed a tool for fact-checking in automated question answering based on four technologies: (i) the Suggested Upper Merged Ontology (SUMO) for knowledge representation, (ii) the Vampire theorem prover [1] for fact verification, (iii) WordNet for lexical semantics and (iv) GPT (Generative Pretrained Transformer) for concept learning and alignment. SUMO provides a structured representation of knowledge in an expressive logic, facilitating semantic understanding and analysis. Vampire serves as an automated reasoning tool to check the validity of facts and claims. WordNet and GPT contribute to concept learning and alignment, enhancing the system’s ability to interpret natural language (NL) expressions and align them with the underlying ontological representations. By combining these components, the proposed framework offers a robust solution for fact-checking, combating misinformation, and promoting informed decision-making. © 2023 CEUR-WS. All rights reserved.
KW  - fake news
KW  - foundational language models
KW  - foundational ontologies
KW  - generative pre-trained transformers
KW  - Decision making
KW  - Knowledge representation
KW  - Semantics
KW  - Concept alignments
KW  - Concept learning
KW  - Cross validation
KW  - Fake news
KW  - Foundational language model
KW  - Foundational ontologies
KW  - Generative pre-trained transformer
KW  - Language model
KW  - Ontology's
KW  - Wordnet
KW  - Ontology
A2  - Razniewski S.
A2  - Kalo J.-C.
A2  - Singhania S.
A2  - Pan J.Z.
PB  - CEUR-WS
SN  - 16130073 (ISSN)
LA  - English
J2  - CEUR Workshop Proc.
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 0; Conference name: 1st Workshop on Knowledge Base Construction from Pre-Trained Language Models and the 2nd Challenge on Language Models for Knowledge Base Construction, KBC-LM + LM-KBC 2023; Conference code: 194944
ER  -

TY  - JOUR
AU  - Daungsupawong, H.
AU  - Wiwanitkit, V.
TI  - Physician and Patient Assessment of Extended Language Model Answers to Rheumatology Patient Inquiries: Doctor versus AI. Comment on the article by Ye et al
PY  - 2023
T2  - Arthritis and Rheumatology
DO  - 10.1002/art.42773
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85182717637&doi=10.1002%2fart.42773&partnerID=40&md5=6723bdadadcbd189f3719037f7c2664c
AD  - Private Academic Consultant, Phonhong, Laos
AD  - Chandigarh University, Mohali, India
PB  - John Wiley and Sons Inc
SN  - 23265191 (ISSN)
C2  - 38057132
LA  - English
J2  - Arthritis Rheum.
M3  - Letter
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 0; Correspondence Address: H. Daungsupawong; Private Academic Consultant, Phonhong, Laos; email: hinpetchdaung@gmail.com
ER  -

TY  - JOUR
AU  - Deb, J.
AU  - Saikia, L.
AU  - Dihingia, K.D.
AU  - Sastry, G.N.
TI  - ChatGPT in the Material Design: Selected Case Studies to Assess the Potential of ChatGPT
PY  - 2023
T2  - Journal of Chemical Information and Modeling
DO  - 10.1021/acs.jcim.3c01702
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85183492045&doi=10.1021%2facs.jcim.3c01702&partnerID=40&md5=0099f3c7c7d6364b5cb03f2ca1b335c3
AD  - Advanced Computation and Data Sciences Division, CSIR-North East Institute of Science and Technology, Assam, Jorhat, 785006, India
AD  - Advanced Materials Group, Materials Sciences & Technology Division, CSIR-North East Institute of Science and Technology, Assam, Jorhat, 785006, India
AD  - Academy of Scientific and Innovative Research (AcSIR), Uttar Pradesh, Ghaziabad, 201002, India
AB  - The pursuit of designing smart and functional materials is of paramount importance across various domains, such as material science, engineering, chemical technology, electronics, biomedicine, energy, and numerous others. Consequently, researchers are actively involved in the development of innovative models and strategies for material design. Recent advancements in analytical tools, experimentation, and computer technology additionally enhance the material design possibilities. Notably, data-driven techniques like artificial intelligence and machine learning have achieved substantial progress in exploring various applications within material science. One such approach, ChatGPT, a large language model, holds transformative potential for addressing complex queries. In this article, we explore ChatGPT’s understanding of material science by assigning some simple tasks across various subareas of computational material science. The findings indicate that while ChatGPT may make some minor errors in accomplishing general tasks, it demonstrates the capability to learn and adapt through human interactions. However, issues like output consistency, probable hidden errors, and ethical consequences should be addressed. © 2024 American Chemical Society.
KW  - Engineering education
KW  - Functional materials
KW  - Analytical tool
KW  - Case-studies
KW  - Chemical technologies
KW  - Computer technology
KW  - Energy
KW  - Innovative models
KW  - Innovative strategies
KW  - Material science
KW  - Materials design
KW  - Tool technology
KW  - Artificial intelligence
PB  - American Chemical Society
SN  - 15499596 (ISSN)
LA  - English
J2  - J. Chem. Inf. Model.
M3  - Article
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 0; Correspondence Address: J. Deb; Advanced Computation and Data Sciences Division, CSIR-North East Institute of Science and Technology, Jorhat, Assam, 785006, India; email: deb.jyotirmoy11@gmail.com; G.N. Sastry; Advanced Computation and Data Sciences Division, CSIR-North East Institute of Science and Technology, Jorhat, Assam, 785006, India; email: gnsastry@gmail.com; CODEN: JCISD
ER  -

TY  - JOUR
AU  - Pellert, M.
AU  - Lechner, C.M.
AU  - Wagner, C.
AU  - Rammstedt, B.
AU  - Strohmaier, M.
TI  - AI Psychometrics: Assessing the Psychological Profiles of Large Language Models Through Psychometric Inventories
PY  - 2023
T2  - Perspectives on Psychological Science
DO  - 10.1177/17456916231214460
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85181501686&doi=10.1177%2f17456916231214460&partnerID=40&md5=153138e35f0c5ed425f93ed9a226a582
AD  - Business School, University of Mannheim, Germany
AD  - GESIS–Leibniz Institute for the Social Sciences, Germany
AD  - Department of Society, Technology and Human Factors, RWTH Aachen University, Germany
AD  - Complexity Science Hub Vienna, Vienna, Austria
AB  - We illustrate how standard psychometric inventories originally designed for assessing noncognitive human traits can be repurposed as diagnostic tools to evaluate analogous traits in large language models (LLMs). We start from the assumption that LLMs, inadvertently yet inevitably, acquire psychological traits (metaphorically speaking) from the vast text corpora on which they are trained. Such corpora contain sediments of the personalities, values, beliefs, and biases of the countless human authors of these texts, which LLMs learn through a complex training process. The traits that LLMs acquire in such a way can potentially influence their behavior, that is, their outputs in downstream tasks and applications in which they are employed, which in turn may have real-world consequences for individuals and social groups. By eliciting LLMs’ responses to language-based psychometric inventories, we can bring their traits to light. Psychometric profiling enables researchers to study and compare LLMs in terms of noncognitive characteristics, thereby providing a window into the personalities, values, beliefs, and biases these models exhibit (or mimic). We discuss the history of similar ideas and outline possible psychometric approaches for LLMs. We demonstrate one promising approach, zero-shot classification, for several LLMs and psychometric inventories. We conclude by highlighting open challenges and future avenues of research for AI Psychometrics. © The Author(s) 2023.
KW  - artificial intelligence
KW  - gender/sex diversity beliefs
KW  - large language model
KW  - moral foundations
KW  - natural language inference
KW  - natural language processing
KW  - personality
KW  - psychometrics
KW  - values
KW  - article
KW  - artificial intelligence
KW  - gender and sex
KW  - human
KW  - large language model
KW  - morality
KW  - natural language processing
KW  - personality
KW  - psychometry
KW  - sediment
KW  - social group
KW  - speech
PB  - SAGE Publications Inc.
SN  - 17456916 (ISSN)
LA  - English
J2  - Perspect. Psychol. Sci.
M3  - Article
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 1; Correspondence Address: M. Pellert; Business School, University of Mannheim, Germany; email: max.pellert@uni-mannheim.de
ER  -

TY  - JOUR
AU  - Giannakopoulos, K.
AU  - Kavadella, A.
AU  - Salim, A.A.
AU  - Stamatopoulos, V.
AU  - Kaklamanos, E.G.
TI  - Evaluation of the Performance of Generative AI Large Language Models ChatGPT, Google Bard, and Microsoft Bing Chat in Supporting Evidence-Based Dentistry: Comparative Mixed Methods Study
PY  - 2023
T2  - Journal of Medical Internet Research
VL  - 25
IS  - 1
C7  - e51580
DO  - 10.2196/51580
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85181396069&doi=10.2196%2f51580&partnerID=40&md5=75055e76438ae649744ae2f15ccbf56c
AD  - School of Dentistry, European University Cyprus, Nicosia, Cyprus
AD  - Information Management Systems Institute, ATHENA Research and Innovation Center, Athens, Greece
AD  - School of Dentistry, Aristotle University of Thessaloniki, Thessaloniki, Greece
AD  - Mohammed Bin Rashid University of Medicine and Health Sciences, Dubai, United Arab Emirates
AB  - Background: The increasing application of generative artificial intelligence large language models (LLMs) in various fields, including dentistry, raises questions about their accuracy. Objective: This study aims to comparatively evaluate the answers provided by 4 LLMs, namely Bard (Google LLC), ChatGPT-3.5 and ChatGPT-4 (OpenAI), and Bing Chat (Microsoft Corp), to clinically relevant questions from the field of dentistry. Methods: The LLMs were queried with 20 open-type, clinical dentistry-related questions from different disciplines, developed by the respective faculty of the School of Dentistry, European University Cyprus. The LLMs' answers were graded 0 (minimum) to 10 (maximum) points against strong, traditionally collected scientific evidence, such as guidelines and consensus statements, using a rubric, as if they were examination questions posed to students, by 2 experienced faculty members. The scores were statistically compared to identify the best-performing model using the Friedman and Wilcoxon tests. Moreover, the evaluators were asked to provide a qualitative evaluation of the comprehensiveness, scientific accuracy, clarity, and relevance of the LLMs' answers. Results: Overall, no statistically significant difference was detected between the scores given by the 2 evaluators; therefore, an average score was computed for every LLM. Although ChatGPT-4 statistically outperformed ChatGPT-3.5 (P=.008), Bing Chat (P=.049), and Bard (P=.045), all models occasionally exhibited inaccuracies, generality, outdated content, and a lack of source references. The evaluators noted instances where the LLMs delivered irrelevant information, vague answers, or information that was not fully accurate. Conclusions: This study demonstrates that although LLMs hold promising potential as an aid in the implementation of evidence-based dentistry, their current limitations can lead to potentially harmful health care decisions if not used judiciously. Therefore, these tools should not replace the dentist's critical thinking and in-depth understanding of the subject matter. Further research, clinical validation, and model improvements are necessary for these tools to be fully integrated into dental practice. Dental practitioners must be aware of the limitations of LLMs, as their imprudent use could potentially impact patient care. Regulatory measures should be established to oversee the use of these evolving technologies. © 2023 Journal of Medical Internet Research. All rights reserved.
KW  - AI
KW  - artificial intelligence
KW  - ChatGPT
KW  - clinical decision-making
KW  - clinical practice
KW  - clinical practice guidelines
KW  - dental practice
KW  - dental professional
KW  - evidence-based dentistry
KW  - generative pretrained transformers
KW  - Google Bard
KW  - large language models
KW  - Microsoft Bing
KW  - Artificial Intelligence
KW  - Dentists
KW  - Evidence-Based Dentistry
KW  - Humans
KW  - Language
KW  - Professional Role
KW  - Search Engine
KW  - artificial intelligence
KW  - dentist
KW  - evidence based dentistry
KW  - human
KW  - language
KW  - professional standard
KW  - search engine
PB  - JMIR Publications Inc.
SN  - 14388871 (ISSN)
C2  - 38009003
LA  - English
J2  - J. Med. Internet Res.
M3  - Article
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 0; Correspondence Address: K. Giannakopoulos; School of Dentistry, European University Cyprus, Nicosia, 6 Diogenis St, Engomi, 2404, Cyprus; email: k.giannakopoulos@euc.ac.cy
ER  -

TY  - JOUR
AU  - Singer, M.B.
AU  - Fu, J.J.
AU  - Chow, J.
AU  - Teng, C.C.
TI  - Development and Evaluation of Aeyeconsult: A Novel Ophthalmology Chatbot Leveraging Verified Textbook Knowledge and GPT-4
PY  - 2023
T2  - Journal of Surgical Education
DO  - 10.1016/j.jsurg.2023.11.019
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85180609426&doi=10.1016%2fj.jsurg.2023.11.019&partnerID=40&md5=29f55af080729cac3415802aa7f6cd24
AD  - Department of Ophthalmology and Visual Science, Yale School of Medicine, New Haven, Connecticut, United States
AD  - Yale School of Medicine, New Haven, Connecticut, United States
AB  - Objective: There has been much excitement on the use of large language models (LLMs) such as ChatGPT in ophthalmology. However, LLMs are limited in that they are trained on unverified information and do not cite their sources. This paper highlights a new methodology to create a generative AI chatbot to answer eye care related questions which uses only verified ophthalmology textbooks as data and cites its sources. Setting: Yale School of Medicine Department of Ophthalmology and Visual Science. Design/Methods: Aeyeconsult, an ophthalmology chatbot, was developed using GPT-4 (the LLM used to power the publicly available chatbot ChatGPT-4), LangChain, and Pinecone. Ophthalmology textbooks were processed into embeddings and stored in Pinecone. User queries were similarly converted, compared to stored embeddings, and GPT-4 generated responses. The interface was adapted from public code. Both Aeyeconsult and ChatGPT-4 were tested on the same 260 questions from OphthoQuestions.com, with the first response from Aeyeconsult and ChatGPT-4 recorded as the answer. Results: Aeyeconsult outperformed ChatGPT-4 on the OKAP dataset, with 83.4% correct answers compared to 69.2% (p = 0.0118). Aeyeconsult also had fewer instances of no answer and multiple answers. Both systems performed best in General Medicine, with Aeyeconsult achieving 96.2% accuracy. Aeyeconsult's weakest performance was in Clinical Optics at 68.1%, but it still outperformed ChatGPT-4 in this category (45.5%). Conclusion: LLMs may be useful in answering ophthalmology questions but their trustworthiness and accuracy is limited due to training on unverified internet data and lack of source citation. We used a new methodology, using verified ophthalmology textbooks as source material and providing citations, to mitigate these issues, resulting in a chatbot more accurate than ChatGPT-4 in answering OKAPs style questions. © 2023 Association of Program Directors in Surgery
KW  - artificial intelligence
KW  - chatbot
KW  - ChatGPT
KW  - large language models
KW  - OKAPs
KW  - Systems-Based Practice
PB  - Elsevier Inc.
SN  - 19317204 (ISSN)
LA  - English
J2  - J. Surg. Educ.
M3  - Article
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 0; Correspondence Address: M.B. Singer; Department of Ophthalmology and Visual Science, Yale School of Medicine, New Haven, 40 Temple Street, 06510, United States; email: maxwell.singer@yale.edu
ER  -

TY  - CONF
AU  - Rocha, V.H.N.
AU  - Silveira, I.C.
AU  - Pirozelli, P.
AU  - Mauá, D.D.
AU  - Cozman, F.G.
TI  - Assessing Good, Bad and Ugly Arguments Generated by ChatGPT: a New Dataset, its Methodology and Associated Tasks
PY  - 2023
T2  - Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)
VL  - 14115 LNAI
SP  - 428
EP  - 440
DO  - 10.1007/978-3-031-49008-8_34
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85180623552&doi=10.1007%2f978-3-031-49008-8_34&partnerID=40&md5=878600ea11841070106be3a1864d44e0
AD  - Escola Politécnica, São Paulo, Brazil
AD  - Instituto de Matemática e Estatística, São Paulo, Brazil
AD  - Instituto de Estudos Avançados Universidade de São Paulo, C4AI (c4ai.inova.usp.br) Av. Prof. Lúcio Martins Rodrigues, 370, SP, São Paulo, 05508-020, Brazil
AB  - The recent success of Large Language Models (LLMs) has sparked concerns about their potential to spread misinformation. As a result, there is a pressing need for tools to identify “fake arguments” generated by such models. To create these tools, examples of texts generated by LLMs are needed. This paper introduces a methodology to obtain good, bad and ugly arguments from argumentative essays produced by ChatGPT, OpenAI’s LLM. We then describe a novel dataset containing a set of diverse arguments, ArGPT. We assess the effectiveness of our dataset and establish baselines for several argumentation-related tasks. Finally, we show that the artificially generated data relates well to human argumentation and thus is useful as a tool to train and test systems for the defined tasks. © 2023, The Author(s), under exclusive license to Springer Nature Switzerland AG.
KW  - Argument classification
KW  - Argument mining
KW  - Argumentation mining
KW  - Automatic essay scoring
KW  - ChatGPT
KW  - NLP
KW  - Natural language processing systems
KW  - Argument classification
KW  - Argument mining
KW  - Argumentation mining
KW  - Automatic essay scoring
KW  - ChatGPT
KW  - Language model
KW  - Pressung
KW  - Test systems
KW  - Train systems
KW  - Artificial intelligence
A2  - Moniz N.
A2  - Moniz N.
A2  - Vale Z.
A2  - Cascalho J.
A2  - Silva C.
A2  - Sebastião R.
PB  - Springer Science and Business Media Deutschland GmbH
SN  - 03029743 (ISSN); 978-303149007-1 (ISBN)
LA  - English
J2  - Lect. Notes Comput. Sci.
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 0; Correspondence Address: V.H.N. Rocha; Escola Politécnica, São Paulo, Brazil; email: victor.hugo.rocha@usp.br; Conference name: 22nd EPIA Conference on Artificial Intelligence, EPIA 2023; Conference date: 5 September 2023 through 8 September 2023; Conference code: 305499
ER  -

TY  - CONF
AU  - Saito, E.
AU  - Kameyama, W.
AU  - Sato, T.
AU  - Katsuyama, Y.
AU  - Sato, T.
TI  - Evaluation on a Method of Detecting Suspicious Objects with Transformer Model Using Passive and Active Imagers of W-band Radar
PY  - 2023
T2  - GCCE 2023 - 2023 IEEE 12th Global Conference on Consumer Electronics
SP  - 736
EP  - 737
DO  - 10.1109/GCCE59613.2023.10315333
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85179758755&doi=10.1109%2fGCCE59613.2023.10315333&partnerID=40&md5=a817f94f1bfc367f8e43d2e51a6ebd05
AD  - Waseda University, Graduate School of Fundamental Science and Engineering, Tokyo, Japan
AD  - Waseda University, Faculty of Science and Engineering, Tokyo, Japan
AD  - Waseda University, Waseda Research Institute for Science and Engineering, Tokyo, Japan
AB  - We are studying a method to improve the accuracy of detecting suspicious objects carried by walking persons using both passive and active imager images taken by the W-band radar system. In this paper, we propose a transformer model based on our previously proposed CNN-based model. According to the experiment, the proposed transformer model achieves better accuracy on suspicious object detection than our previously proposed CNN-based model.  © 2023 IEEE.
KW  - Active Imager
KW  - CNN
KW  - Passive Imager
KW  - Suspicious Object Detection
KW  - Transformer
KW  - W-band Radar
KW  - Image enhancement
KW  - Object recognition
KW  - Radar imaging
KW  - Active imager
KW  - Model-based OPC
KW  - Objects detection
KW  - Passive imagers
KW  - Suspicious object detection
KW  - Suspicious objects
KW  - Transformer
KW  - Transformer modeling
KW  - W-band Radar
KW  - Object detection
PB  - Institute of Electrical and Electronics Engineers Inc.
SN  - 979-835034018-1 (ISBN)
LA  - English
J2  - GCCE - IEEE Glob. Conf. Consum. Electron.
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 0; Correspondence Address: E. Saito; Waseda University, Graduate School of Fundamental Science and Engineering, Tokyo, Japan; email: phy24.erika@ruri.waseda.jp; Conference name: 12th IEEE Global Conference on Consumer Electronics, GCCE 2023; Conference date: 10 October 2023 through 13 October 2023; Conference code: 194542
ER  -

TY  - CONF
AU  - Ding, Z.
AU  - Smith-Renner, A.
AU  - Zhang, W.
AU  - Tetreault, J.R.
AU  - Jaimes, A.
TI  - Harnessing the Power of LLMs: Evaluating Human-AI Text Co-Creation through the Lens of News Headline Generation
PY  - 2023
T2  - Findings of the Association for Computational Linguistics: EMNLP 2023
SP  - 3321
EP  - 3339
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85183296567&partnerID=40&md5=97933ed5e8162d11beb499503be718d3
AD  - University of Maryland, College Park, United States
AD  - Dataminr Inc., United States
AB  - To explore how humans can best leverage LLMs for writing and how interacting with these models affects feelings of ownership and trust in the writing process, we compared common human-AI interaction types (e.g., guiding system, selecting from system outputs, post-editing outputs) in the context of LLM-assisted news headline generation. While LLMs alone can generate satisfactory news headlines, on average, human control is needed to fix undesirable model outputs. Of the interaction methods, guiding and selecting model output added the most benefit with the lowest cost (in time and effort). Further, AI assistance did not harm participants' perception of control compared to freeform editing. © 2023 Association for Computational Linguistics.
KW  - Co-creation
KW  - Guiding systems
KW  - Headline generation
KW  - Human control
KW  - Model outputs
KW  - Post-editing
KW  - Power
KW  - System output
KW  - Through the lens
KW  - Writing process
PB  - Association for Computational Linguistics (ACL)
SN  - 979-889176061-5 (ISBN)
LA  - English
J2  - Find. Assoc. Comput. Linguist.: EMNLP
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 0; Conference name: 2023 Findings of the Association for Computational Linguistics: EMNLP 2023; Conference date: 6 December 2023 through 10 December 2023; Conference code: 196127
ER  -

TY  - CONF
AU  - Fatima, R.
AU  - Birchfield, A.B.
TI  - Impact of Time-Dependent Transformer Thermal Model on Assessment of GICs in Large Power Systems
PY  - 2023
T2  - 2023 North American Power Symposium, NAPS 2023
DO  - 10.1109/NAPS58826.2023.10318789
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85179555749&doi=10.1109%2fNAPS58826.2023.10318789&partnerID=40&md5=660e31837087746a47354f4201f88964
AD  - Texas A&m University, Department of Electrical and Computer Engineering, College Station, TX, United States
AB  - Geomagnetically induced currents (GICs) in power systems are a potential source of introducing DC in transformers, resulting in undesirable occurrences of additional harmonics and higher temperatures. This paper reviews the methodology and results of case study that was performed on the transformer fleet of a 2000-bus synthetic grid on the geographic foot-print of Texas. The thermal assessment technique identifies the transformers with potential thermal impacts using a first-order hotspot calculation method for the structural parts of the power transformer. The analysis is undertaken by modeling severe GMD events-NERC benchmark event and its derivatives - to assess how the transient hotspot behavior of a power transformer is related to various environmental conditions, such as electric field magnitude and direction, transformer neutral current, and storm duration. © 2023 IEEE.
KW  - GIC
KW  - Power Transformers
KW  - thermal assessment
KW  - DC transformers
KW  - Electric fields
KW  - Case-studies
KW  - Geomagnetically induced currents
KW  - Highest temperature
KW  - Hotspots
KW  - Large power systems
KW  - Potential sources
KW  - Power
KW  - Thermal assessment
KW  - Time dependent
KW  - Transformer thermal models
KW  - Power transformers
PB  - Institute of Electrical and Electronics Engineers Inc.
SN  - 979-835031509-7 (ISBN)
LA  - English
J2  - North American Power Symp., NAPS
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 0; Conference name: 2023 North American Power Symposium, NAPS 2023; Conference date: 15 October 2023 through 17 October 2023; Conference code: 194607
ER  -

TY  - JOUR
AU  - Busch, F.
AU  - Adams, L.C.
AU  - Bressem, K.K.
TI  - Spotlight on the biomedical ethical integration of AI in medical education–Response to: ‘An explorative assessment of ChatGPT as an aid in medical education: Use it with caution’
PY  - 2023
T2  - Medical Teacher
DO  - 10.1080/0142159X.2023.2293655
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85179932736&doi=10.1080%2f0142159X.2023.2293655&partnerID=40&md5=aa5bd6a5084b826192cbfe8a83559770
AD  - Department of Radiology, Charité–Universitätsmedizin Berlin, Corporate Member of Freie Universität Berlin and Humboldt Universität zu Berlin, Berlin, Germany
AD  - Department of Radiology, Klinikum rechts der Isar, Technische Universität München (TUM), Munich, Germany
PB  - Taylor and Francis Ltd.
SN  - 0142159X (ISSN)
LA  - English
J2  - Med. Teach.
M3  - Letter
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 0; Correspondence Address: F. Busch; Department of Radiology, Charité–Universitätsmedizin Berlin, Corporate Member of Freie Universität Berlin and Humboldt Universität zu Berlin, Berlin, Germany; email: felix.busch@charite.de; CODEN: MEDTD
ER  -

TY  - CONF
AU  - He, J.
AU  - Lin, N.
AU  - Shen, M.
AU  - Zhou, D.
AU  - Yang, A.
TI  - Exploring Bias Evaluation Techniques for Quantifying Large Language Model Biases
PY  - 2023
T2  - Proceedings of 2023 International Conference on Asian Language Processing, IALP 2023
SP  - 265
EP  - 270
DO  - 10.1109/IALP61005.2023.10337300
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85181774905&doi=10.1109%2fIALP61005.2023.10337300&partnerID=40&md5=9d1c049549c43ba75167724cd793b2dd
AD  - Guangdong University of Technology, Guangzhou, China
AD  - Peking University, Beijing, China
AD  - Guangdong University of Foreign Studies, Guangzhou, China
AD  - Lingnan Normal University, Zhanjiang, China
AB  - In recent years, there has been a surge in the adoption of large language models (LLMs) such as "ChatG PT"trained by OpenAI. These models have gained popularity due to their impressive performance in various real-world applications. However, research has shown that small pre-trained language models (PLMs) such as BERT exhibit biases, particularly gender bias, that mirror societal stereotypes. Given the shared architecture between LLMs and small PLMs like Transformer, there is concern that these biases may also exist in LLMs. Although some studies suggest the presence of biases in LLMs, there is no consensus on how these biases should be measured. This paper employs three internal bias metrics, namely SEAT, StereoSet, and CrowS Pairs, to evaluate nine bias involving gender, age, race, occupation, nationality, religion, sexual orientation, physical appearance and disability in five open source LLMs (Llama, Llama2, Alpaca, Vicuna, and MPT), thereby determining their specific bias level. The experimental results demonstrate varying degrees of bias within these LLMs, with some models displaying high levels of bias that could potentially lead to harm in specific domains. Interestingly, we also discover that despite their larger architectures and greater number of parameters compared to small PLMs like BERT, these LLMs exhibit a lower level of bias. We posit that the inclusion of fairness considerations during the pre-training phase of these Language Model-based Learners (LLMs) is the primary contributing factor. This involves prioritizing the use of "fair"corpora while constructing the training data, and our experimental findings confirm the effectiveness of such an approach. Finally, by identifying the presence and measuring the specific level of bias, we contribute to the ongoing discourse on the mitigation of bias and the responsible usage of LLMs in various applications.  © 2023 IEEE.
KW  - bias
KW  - fairness metrics
KW  - Large language models
KW  - Bias
KW  - Fairness metric
KW  - Gender bias
KW  - Language model
KW  - Large language model
KW  - Model bias
KW  - Open-source
KW  - Performance
KW  - Real-world
KW  - Sexual orientations
KW  - Computational linguistics
A2  - Wang L.
A2  - Lu Y.
A2  - Dong M.
PB  - Institute of Electrical and Electronics Engineers Inc.
SN  - 979-835033078-6 (ISBN)
LA  - English
J2  - Proc. Int. Conf. Asian Lang. Process., IALP
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 0; Correspondence Address: D. Zhou; Guangdong University of Foreign Studies, Guangzhou, China; email: dongzhou@gdufs.edu.cn; A. Yang; Lingnan Normal University, Zhanjiang, China; email: amyang@gdut.edu.cn; Conference name: 27th International Conference on Asian Language Processing, IALP 2023; Conference date: 18 November 2023 through 20 November 2023; Conference code: 195317
ER  -

TY  - JOUR
AU  - Raghu, K.
AU  - Tamilselvi, S.
AU  - Devishamani, C.S.
AU  - Suchetha, M.
AU  - Rajalakshmi, R.
AU  - Raman, R.
TI  - The Utility of ChatGPT in Diabetic Retinopathy Risk Assessment: A Comparative Study with Clinical Diagnosis
PY  - 2023
T2  - Clinical Ophthalmology
VL  - 17
SP  - 4021
EP  - 4031
DO  - 10.2147/OPTH.S435052
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85181206869&doi=10.2147%2fOPTH.S435052&partnerID=40&md5=b367d36e00f2ea30a520002ffca4aca9
AD  - Shri Bhagwan Mahavir Vitreoretinal Services, Sankara Nethralaya, Tamil Nadu, Chennai, India
AD  - Centre for Health Care Advancement, Innovation, and Research Department, Vellore Institute of Technology, Tamil Nadu, Chennai, India
AD  - Department of Diabetology, Ophthalmology and Epidemiology, Madras Diabetes Research Foundation & Dr. Mohan’s Diabetes Specialities Centre, Tamil Nadu, Chennai, India
AB  - Purpose: To evaluate the ability of an artificial intelligence (AI) model, ChatGPT, in predicting the diabetic retinopathy (DR) risk. Methods: This retrospective observational study utilized an anonymized dataset of 111 patients with diabetes who underwent a comprehensive eye examination along with clinical and biochemical assessments. Clinical and biochemical data along with and without central subfield thickness (CST) values of the macula from OCT were uploaded to ChatGPT-4, and the response from the ChatGPT was compared to the clinical DR diagnosis made by an ophthalmologist. Results: The study assessed the consistency of responses provided by ChatGPT, yielding an Intraclass Correlation Coefficient (ICC) value of 0.936 (95% CI, 0.913–0.954, p < 0.001) (with CST) and 0.915 (95% CI, 0.706–0.846, p < 0.001) (without CST), both situations indicated excellent reliability. The sensitivity and specificity of ChatGPT in predicting the DR cases were evaluated. The results revealed a sensitivity of 67% with CST and 73% without CST. The specificity was 68% with CST and 54% without CST. However, Cohen’s kappa revealed only a fair agreement between ChatGPT predictions and clinical DR status in both situations, with CST (kappa = 0.263, p = 0.005) and without CST (kappa = 0.351, p < 0.001). Conclusion: This study suggests that ChatGPT has the potential of a preliminary DR screening tool with further optimization needed for clinical use. © 2023 Raghu et al.
KW  - artificial intelligence
KW  - ChatGPT
KW  - diabetes
KW  - diabetic retinopathy
KW  - hemoglobin A1c
KW  - high density lipoprotein cholesterol
KW  - low density lipoprotein cholesterol
KW  - triacylglycerol
KW  - adult
KW  - aged
KW  - Article
KW  - artificial intelligence
KW  - central subfield thickness
KW  - ChatGPT
KW  - comparative study
KW  - correlation coefficient
KW  - diabetes mellitus
KW  - diabetic retinopathy
KW  - diagnostic value
KW  - female
KW  - human
KW  - interrater reliability
KW  - male
KW  - medical education
KW  - microalbuminuria
KW  - observational study
KW  - optical coherence tomography
KW  - predictive value
KW  - retrospective study
KW  - risk assessment
KW  - sensitivity and specificity
KW  - validation study
KW  - visual acuity
PB  - Dove Medical Press Ltd
SN  - 11775467 (ISSN)
LA  - English
J2  - Clin. Ophthalmol.
M3  - Article
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 1; Correspondence Address: R. Raman; Shri Bhagwan Mahavir Vitreoretinal Services, Sankara Nethralaya, Chennai, Sankara Nethralaya (Main Campus), No. 41 (Old 18), College Road, Tamil Nadu, 600006, India; email: rajivpgraman@gmail.com
ER  -

TY  - CONF
AU  - Ramakrishna, A.
AU  - Gupta, R.
AU  - Lehmann, J.
AU  - Ziyadi, M.
TI  - INVITE: a Testbed of Automatically Generated Invalid Questions to Evaluate Large Language Models for Hallucinations
PY  - 2023
T2  - Findings of the Association for Computational Linguistics: EMNLP 2023
SP  - 5422
EP  - 5429
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85183290980&partnerID=40&md5=d8698ab1906608ee6a05696e66a6ca03
AD  - Amazon Alexa AI, United States
AB  - Recent advancements in Large language models (LLMs) have enabled them to hold free form conversations over multiple turns, but they exhibit a tendency to make unfounded and incorrect statements, commonly known as hallucinations. In particular, LLMs hallucinate frequently when given invalid questions, i.e. ones with incorrect assumptions. The most common approach to evaluate LLMs on hallucinations is to test them on Question Answering (QA) test sets such as TruthfulQA. However, LLMs are increasingly pretrained on massive text corpora scraped from the Internet, which may inevitably expose these test sets to the model during training, leading eventually to an overestimation of model performances on these test sets. In this work, we present an alternative framework to address this risk and to foster further research towards making LLMs robust against invalid questions. We name our framework INVITE: a testbed of automatically generated INValId questions to evaluaTE large language models for hallucinations. In each instantiation, our framework is set up to create a fresh batch of invalid questions by distorting valid facts in which subjects or objects are replaced by similar entities. We evaluate several state of the art LLMs against a testset generated by our framework and highlight its capacity to trigger hallucinations in these models. © 2023 Association for Computational Linguistics.
KW  - Computational linguistics
KW  - Natural language processing systems
KW  - Alternative framework
KW  - Automatically generated
KW  - Freeforms
KW  - Language model
KW  - Modeling performance
KW  - Question Answering
KW  - State of the art
KW  - Test sets
KW  - Text corpora
KW  - Testbeds
PB  - Association for Computational Linguistics (ACL)
SN  - 979-889176061-5 (ISBN)
LA  - English
J2  - Find. Assoc. Comput. Linguist.: EMNLP
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 0; Conference name: 2023 Findings of the Association for Computational Linguistics: EMNLP 2023; Conference date: 6 December 2023 through 10 December 2023; Conference code: 196127
ER  -

TY  - CONF
AU  - Katzy, J.
AU  - Izadi, M.
AU  - Deursen, A.V.
TI  - On the Impact of Language Selection for Training and Evaluating Programming Language Models
PY  - 2023
T2  - Proceedings - 2023 IEEE 23rd International Working Conference on Source Code Analysis and Manipulation, SCAM 2023
SP  - 271
EP  - 276
DO  - 10.1109/SCAM59687.2023.00038
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85182738345&doi=10.1109%2fSCAM59687.2023.00038&partnerID=40&md5=fafb783faeb02dbb30aec979f04bc208
AD  - Delft University of Technology, Delft, Netherlands
AB  - The recent advancements in Transformer-based Language Models have demonstrated significant potential in enhancing the multilingual capabilities of these models. The remarkable progress made in this domain not only applies to natural language tasks but also extends to the domain of programming languages. Despite the ability of these models to learn from multiple languages, evaluations typically focus on particular combinations of the same languages. In this study, we evaluate the similarity of programming languages by analyzing their representations using a CodeBERT-based model. Our experiments reveal that token representation in languages such as C++, Python, and Java exhibit proximity to one another, whereas the same tokens in languages such as Mathematica and R display significant dissimilarity. Our findings suggest that this phenomenon can potentially result in performance challenges when dealing with diverse languages. Thus, we recommend using our similarity measure to select a diverse set of programming languages when training and evaluating future models.  © 2023 IEEE.
KW  - code representation
KW  - language model
KW  - multilingual model
KW  - pretrained model
KW  - programming language
KW  - transfer learning
KW  - Transformer
KW  - Computational linguistics
KW  - Learning systems
KW  - Code representation
KW  - Language model
KW  - Learn+
KW  - Multilingual capability
KW  - Multilingual model
KW  - Natural languages
KW  - Pretrained model
KW  - Programming language models
KW  - Transfer learning
KW  - Transformer
KW  - C++ (programming language)
A2  - Moonen L.
A2  - Newman C.
A2  - Gorla A.
PB  - Institute of Electrical and Electronics Engineers Inc.
SN  - 979-835030506-7 (ISBN)
LA  - English
J2  - Proc. - IEEE Int. Working Conf. Source Code Anal. Manip., SCAM
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 0; Conference name: 23rd IEEE International Working Conference on Source Code Analysis and Manipulation, SCAM 2023; Conference date: 1 October 2023 through 2 October 2023; Conference code: 195700
ER  -

TY  - CONF
AU  - Sainz, O.
AU  - Campos, J.A.
AU  - García-Ferrero, I.
AU  - Etxaniz, J.
AU  - Lopez de Lacalle, O.
AU  - Agirre, E.
TI  - NLP Evaluation in trouble: On the Need to Measure LLM Data Contamination for each Benchmark
PY  - 2023
T2  - Findings of the Association for Computational Linguistics: EMNLP 2023
SP  - 10776
EP  - 10787
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85181695119&partnerID=40&md5=657f1e273ac849864fd600f9ff5f6b0d
AD  - HiTZ Center - Ixa, University of the Basque Country UPV/EHU, Spain
AD  - Cohere, University of the Basque Country UPV/EHU, Spain
AB  - In this position paper, we argue that the classical evaluation on Natural Language Processing (NLP) tasks using annotated benchmarks is in trouble. The worst kind of data contamination happens when a Large Language Model (LLM) is trained on the test split of a benchmark, and then evaluated in the same benchmark. The extent of the problem is unknown, as it is not straightforward to measure. Contamination causes an overestimation of the performance of a contaminated model in a target benchmark and associated task with respect to their non-contaminated counterparts. The consequences can be very harmful, with wrong scientific conclusions being published while other correct ones are discarded. This position paper defines different levels of data contamination and argues for a community effort, including the development of automatic and semi-automatic measures to detect when data from a benchmark was exposed to a model, and suggestions for flagging papers with conclusions that are compromised by data contamination. © 2023 Association for Computational Linguistics.
KW  - Benchmarking
KW  - Computational linguistics
KW  - Natural language processing systems
KW  - Exposed to
KW  - Language model
KW  - Language processing
KW  - Modeling data
KW  - Natural languages
KW  - Performance
KW  - Position papers
KW  - Semi-automatics
KW  - Contamination
PB  - Association for Computational Linguistics (ACL)
SN  - 979-889176061-5 (ISBN)
LA  - English
J2  - Find. Assoc. Comput. Linguist.: EMNLP
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 0; Conference name: 2023 Findings of the Association for Computational Linguistics: EMNLP 2023; Conference date: 6 December 2023 through 10 December 2023; Conference code: 196127
ER  -

TY  - CONF
AU  - Suzuki, K.
AU  - Cai, J.
AU  - Li, J.
AU  - Yamauchi, T.
AU  - Tei, K.
TI  - A Comparative Evaluation on Melody Generation of Large Language Models
PY  - 2023
T2  - 2023 IEEE International Conference on Consumer Electronics-Asia, ICCE-Asia 2023
DO  - 10.1109/ICCE-Asia59966.2023.10326362
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85179892512&doi=10.1109%2fICCE-Asia59966.2023.10326362&partnerID=40&md5=770630c489cd0c921d575c35b90dd51a
AD  - Waseda University, Tokyo, Japan
AD  - Tokyo Institute of Technology, Tokyo, Japan
AB  - Music has always been central to human culture. With the rise of digital tech and smart devices, its role in the Consumer Electronics (CE) sector has grown. Recently, large-scale language models (LLMs) like ChatGPT and Bard are promising to change the way we compose music. This paper explores the composing ability of Large Language Models (LLM) such as ChatGPT and Bard. Unlike older methods that required deep musical and statistical knowledge, LLM lets users simply describe what they want in music. We evaluated this LLM on how well it matches user input and the overall quality of its compositions, looking at factors like repetitiveness and scale diversity. This research aims to highlight the strengths, uses, and limits of LLM in music, setting the stage for its greater role in CE and the wider music world.Generated Melodies: https://github.com/545659928/LLMMelody  © 2023 IEEE.
KW  - Large Language Model
KW  - Melody Generation
KW  - Music Creation
KW  - Text to Music
KW  - Computational linguistics
KW  - Digital devices
KW  - Quality control
KW  - Comparative evaluations
KW  - Electronics sectors
KW  - Human cultures
KW  - Language model
KW  - Large language model
KW  - Large-scales
KW  - Melody generation
KW  - Music creation
KW  - Smart devices
KW  - Text to music
KW  - Music
PB  - Institute of Electrical and Electronics Engineers Inc.
SN  - 979-835034431-8 (ISBN)
LA  - English
J2  - IEEE Int. Conf. Consum. Electron.-Asia, ICCE-Asia
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 0; Correspondence Address: J. Li; Waseda University, Tokyo, Japan; email: lijialong@fuji.waseda.jp; Conference name: 2023 IEEE International Conference on Consumer Electronics-Asia, ICCE-Asia 2023; Conference date: 23 October 2023 through 25 October 2023; Conference code: 195006
ER  -

TY  - JOUR
AU  - Rudolph, J.
AU  - Tan, S.
AU  - Tan, S.
TI  - ChatGPT: Bullshit spewer or the end of traditional assessments in higher education?
PY  - 2023
T2  - Journal of Applied Learning and Teaching
VL  - 6
IS  - 1
SP  - 342
EP  - 363
DO  - 10.37074/jalt.2023.6.1.9
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85148608599&doi=10.37074%2fjalt.2023.6.1.9&partnerID=40&md5=5aed8395fdc3cde275b039226634df1f
AD  - Regional Strategy & Operations, Singapore
AB  - ChatGPT is the world’s most advanced chatbot thus far. Unlike other chatbots, it can create impressive prose within seconds, and it has created much hype and doomsday predictions when it comes to student assessment in higher education and a host of other matters. ChatGPT is a state-of-the-art language model (a variant of OpenAI’s Generative Pretrained Transformer (GPT) language model) designed to generate text that can be indistinguishable from text written by humans. It can engage in conversation with users in a seemingly natural and intuitive way. In this article, we briefly tell the story of OpenAI, the organisation behind ChatGPT. We highlight the fundamental change from a not-for-profit organisation to a commercial business model. In terms of our methods, we conducted an extensive literature review and experimented with this artificial intelligence (AI) software. Our literature review shows our review to be amongst the first peer-reviewed academic journal articles to explore ChatGPT and its relevance for higher education (especially assessment, learning and teaching). After a description of ChatGPT’s functionality and a summary of its strengths and limitations, we focus on the technology’s implications for higher education and discuss what is the future of learning, teaching and assessment in higher education in the context of AI chatbots such as ChatGPT. We position ChatGPT in the context of current Artificial Intelligence in Education (AIEd) research, discuss student-facing, teacher-facing and system-facing applications, and analyse opportunities and threats. We conclude the article with recommendations for students, teachers and higher education institutions. Many of them focus on assessment. © 2023. Jürgen Rudolph, Samson Tan and Shannon Tan.
KW  - Artificial Intelligence (AI)
KW  - Artificial Intelligence in Education (AIEd)
KW  - assessment
KW  - ChatGPT
KW  - Generative Pre-trained Transformer 3 (GPT-3)
KW  - higher education
KW  - learning & teaching
KW  - natural language processing (NLP)
PB  - Kaplan Singapore
SN  - 2591801X (ISSN)
LA  - English
J2  - J. Appl. Learn. Teach.
M3  - Article
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 199
ER  -

TY  - CONF
AU  - Tariq, R.
AU  - Malik, S.
AU  - Roy, M.
AU  - Islam, M.Z.
AU  - Rasheed, U.
AU  - Bian, J.
AU  - Zheng, K.
AU  - Zhang, R.
TI  - Assessing ChatGPT for Text Summarization, Simplification and Extraction Tasks
PY  - 2023
T2  - Proceedings - 2023 IEEE 11th International Conference on Healthcare Informatics, ICHI 2023
SP  - 746
EP  - 749
DO  - 10.1109/ICHI57859.2023.00136
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85181559132&doi=10.1109%2fICHI57859.2023.00136&partnerID=40&md5=e64adf1713f80abda9597bc5cabd4afa
AD  - Mayo Clinic, Department of Gastroenetrology and Hepatology, MN, United States
AD  - Rochester General Hospital, Department of Internal Medince, NewYork, United States
AD  - University of Minnesota, Division of Computational Health Sciences, MN, United States
AD  - Stanford University, Division of Social Work, CA, United States
AD  - Volkswagen Group of America, Department of Artifical Intelligence Engineering, Belmont, CA, United States
AD  - University of Florida, Department of Biomed Informatics, Gainsville, United States
AD  - University of California, Department of Informatics, Irvine, United States
AB  - In this study, we evaluated the performance of ChatGPT for various textual tasks regarding the information on dietary supplements. We found that ChatGPT performed reasonably well with text summarization, simplification and extracting relations. However, in about one third of sentences, human evaluators felts that some relevant information was lost among the output generated by ChatGPT. © 2023 IEEE.
KW  - ChatGPT
KW  - relation extraction
KW  - text simplification
KW  - text summarization
KW  - Dietary supplements
KW  - Extraction
KW  - ChatGPT
KW  - Performance
KW  - Relation extraction
KW  - Text extraction
KW  - Text simplification
KW  - Text Summarisation
KW  - Text processing
PB  - Institute of Electrical and Electronics Engineers Inc.
SN  - 979-835030263-9 (ISBN)
LA  - English
J2  - Proc. - IEEE Int. Conf. Healthc. Informatics, ICHI
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 0; Correspondence Address: R. Tariq; Mayo Clinic, Department of Gastroenetrology and Hepatology, United States; email: tariq.raseen@mayo.edu; Conference name: 11th IEEE International Conference on Healthcare Informatics, ICHI 2023; Conference date: 26 June 2023 through 29 June 2023; Conference code: 195320
ER  -

TY  - CONF
AU  - Wang, B.
AU  - Yue, X.
AU  - Sun, H.
TI  - Can ChatGPT Defend its Belief in Truth? Evaluating LLM Reasoning via Debate
PY  - 2023
T2  - Findings of the Association for Computational Linguistics: EMNLP 2023
SP  - 11865
EP  - 11881
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85180592028&partnerID=40&md5=007d7aab4bd76dfb0d5a06f8634ed6ad
AD  - The Ohio State University, Columbus, OH, United States
AB  - Large language models (LLMs) such as ChatGPT and GPT-4 have shown impressive performance in complex reasoning tasks. However, it is difficult to know whether the models are reasoning based on deep understandings of truth and logic, or leveraging their memorized patterns in a relatively superficial way. In this work, we explore testing LLMs' reasoning by engaging with them in a debate-like conversation, where given a question, the LLM and the user need to discuss to make the correct decision starting from opposing arguments. Upon mitigating the Clever Hans effect, our task requires the LLM to not only achieve the correct answer on its own, but also be able to hold and defend its belief instead of blindly believing or getting misled by the user's (invalid) arguments and critiques, thus testing in greater depth whether the LLM grasps the essence of the reasoning required to solve the problem. Across a range of complex reasoning benchmarks spanning math, commonsense, logic and BIG-Bench tasks, we find that despite their impressive performance as reported in existing work on generating correct step-by-step solutions in the beginning, LLMs like ChatGPT cannot maintain their beliefs in truth for a significant portion of examples when challenged by oftentimes absurdly invalid arguments. Our work points to danger zones of model alignment, and also suggests more careful treatments and interpretations of the recent findings that LLMs can improve their responses based on feedback. © 2023 Association for Computational Linguistics.
KW  - Computational linguistics
KW  - Computer circuits
KW  - Great depth
KW  - Language model
KW  - Model reasonings
KW  - Performance
KW  - Reasoning tasks
KW  - User need
KW  - Benchmarking
PB  - Association for Computational Linguistics (ACL)
SN  - 979-889176061-5 (ISBN)
LA  - English
J2  - Find. Assoc. Comput. Linguist.: EMNLP
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 0; Conference name: 2023 Findings of the Association for Computational Linguistics: EMNLP 2023; Conference date: 6 December 2023 through 10 December 2023; Conference code: 196127
ER  -

TY  - JOUR
AU  - Buhr, C.R.
AU  - Smith, H.
AU  - Huppertz, T.
AU  - Bahr-Hamm, K.
AU  - Matthias, C.
AU  - Blaikie, A.
AU  - Kelsey, T.
AU  - Kuhn, S.
AU  - Eckrich, J.
TI  - ChatGPT Versus Consultants: Blinded Evaluation on Answering Otorhinolaryngology Case–Based Questions
PY  - 2023
T2  - JMIR Medical Education
VL  - 9
IS  - 1
C7  - e49183
DO  - 10.2196/49183
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85180330765&doi=10.2196%2f49183&partnerID=40&md5=754df64b78416d66880c8e6179063f5a
AD  - Department of Otorhinolaryngology, University Medical Center of the Johannes Gutenberg-University Mainz, Mainz, Germany
AD  - School of Medicine, University of St Andrews, St Andrews, United Kingdom
AD  - School of Computer Science, University of St Andrews, St Andrews, United Kingdom
AD  - Institute of Digital Medicine, Philipps-University Marburg, University Hospital of Giessen and Marburg, Marburg, Germany
AB  - Background: Large language models (LLMs), such as ChatGPT (Open AI), are increasingly used in medicine and supplement standard search engines as information sources. This leads to more “consultations” of LLMs about personal medical symptoms. Objective: This study aims to evaluate ChatGPT’s performance in answering clinical case–based questions in otorhinolaryngology (ORL) in comparison to ORL consultants’ answers. Methods: We used 41 case-based questions from established ORL study books and past German state examinations for doctors. The questions were answered by both ORL consultants and ChatGPT 3. ORL consultants rated all responses, except their own, on medical adequacy, conciseness, coherence, and comprehensibility using a 6-point Likert scale. They also identified (in a blinded setting) if the answer was created by an ORL consultant or ChatGPT. Additionally, the character count was compared. Due to the rapidly evolving pace of technology, a comparison between responses generated by ChatGPT 3 and ChatGPT 4 was included to give an insight into the evolving potential of LLMs. Results: Ratings in all categories were significantly higher for ORL consultants (P<.001). Although inferior to the scores of the ORL consultants, ChatGPT’s scores were relatively higher in semantic categories (conciseness, coherence, and comprehensibility) compared to medical adequacy. ORL consultants identified ChatGPT as the source correctly in 98.4% (121/123) of cases. ChatGPT’s answers had a significantly higher character count compared to ORL consultants (P<.001). Comparison between responses generated by ChatGPT 3 and ChatGPT 4 showed a slight improvement in medical accuracy as well as a better coherence of the answers provided. Contrarily, neither the conciseness (P=.06) nor the comprehensibility (P=.08) improved significantly despite the significant increase in the mean amount of characters by 52.5% (n= (1470-964)/964; P<.001). Conclusions: While ChatGPT provided longer answers to medical problems, medical adequacy and conciseness were significantly lower compared to ORL consultants’ answers. LLMs have potential as augmentative tools for medical care, but their “consultation” for medical problems carries a high risk of misinformation as their high semantic quality may mask contextual deficits. © 2023 The Author(s).
KW  - AI
KW  - artificial intelligence
KW  - chatbot
KW  - chatbots
KW  - ChatGPT
KW  - digital health
KW  - global health
KW  - language model
KW  - large language models
KW  - LLM
KW  - LLMs
KW  - low- and middle-income countries
KW  - ORL
KW  - otorhinolaryngology
KW  - telehealth
KW  - telemedicine
PB  - JMIR Publications Inc.
SN  - 23693762 (ISSN)
LA  - English
J2  - JMIR Med. Educ.
M3  - Article
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 0; Correspondence Address: C.R. Buhr; Department of Otorhinolaryngology University Medical Center of the Johannes Gutenberg-University, Mainz, Mainz Langenbeckstraße 1, 55131, Germany; email: buhrchri@uni-mainz.de
ER  -

TY  - CONF
AU  - Chiusaroli, F.
AU  - Uricchio, T.
AU  - Monti, J.
AU  - Pierucci, M.L.
AU  - Sangati, F.
TI  - GPT-based Language Models meet Emojitaliano: A Preliminary Assessment Test between Automation and Creativity
PY  - 2023
T2  - CEUR Workshop Proceedings
VL  - 3596
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85181174902&partnerID=40&md5=ec88dd5d6b73cde0f94975e5ad0256ef
AD  - Università degli Studi di Macerata, Italy
AD  - Università di Napoli “L'Orientale”, Italy
AD  - OIST Graduate University, Japan
AB  - Starting from the crowdsourcing experience of Pinocchio in Emojitaliano [1], the present paper intends to test Chat-GPT's ability to take on the Emojitaliano grammar and dedicated glossary to verify and reapply the Emojitaliano rules in order to produce translations on its own. A test of re-translation of Pinocchio is presented here. Italiano. A partire dall'esperienza in crowdsourcing di Pinocchio in Emojitaliano [1], il presente contributo intende testare la capacità di Chat-GPT di assumere la relativa grammatica e il glossario dedicato per verificare e riapplicare le regole della emojilingua allo scopo di svolgere traduzioni in proprio. Si presenta qui un test di ritraduzione di Pinocchio. © 2023 Copyright for this paper by its authors. Use permitted under Creative Commons Licens Attribution 4.0 International (CC BY 4.0).
KW  - Assessment
KW  - Emojitaliano
KW  - Evaluation
KW  - LLM
KW  - Assessment
KW  - Emojitaliano
KW  - Evaluation
KW  - Language model
KW  - LLM
KW  - Preliminary assessment
KW  - Crowdsourcing
A2  - Boschetti F.
A2  - Boschetti F.
A2  - Lebani G.E.
A2  - Magnini B.
A2  - Novielli N.
PB  - CEUR-WS
SN  - 16130073 (ISSN)
LA  - English
J2  - CEUR Workshop Proc.
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 0; Correspondence Address: T. Uricchio; Università degli Studi di Macerata, Italy; email: tiberio.uricchio@unimc.it; Conference name: 9th Italian Conference on Computational Linguistics, CLiC-it 2023; Conference date: 30 November 2023 through 2 December 2023; Conference code: 195716
ER  -

TY  - CONF
AU  - Virvou, M.
AU  - Tsihrintzis, G.A.
TI  - Is ChatGPT Beneficial to Education? A Holistic Evaluation Framework Based on Intelligent Tutoring Systems
PY  - 2023
T2  - 14th International Conference on Information, Intelligence, Systems and Applications, IISA 2023
DO  - 10.1109/IISA59645.2023.10345949
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85182019187&doi=10.1109%2fIISA59645.2023.10345949&partnerID=40&md5=cadd7471a4188b4b35924184497087a5
AD  - University of Piraeus, Department of Informatics, Piraeus, Greece
AB  - The recent launch of ChatGPT by OpenAI has created a profound global impact, initiating deep questions among educators about how it might affect education, syllabi and teaching methods. Currently, the full scope of potential benefits and risks associated with ChatGPT in education remains unclear, given that its impact surpasses the level of preparation educators and institutions may have had for such a pre-trained generative AI tool. While Artificial Intelligence in Education has long been a subject of research, with a particular focus on developing Intelligent Tutoring Systems, the emergence of ChatGPT marks a distinctive advancement in this field. Unlike dedicated Intelligent Tutoring Systems, ChatGPT is readily available to a diverse spectrum of educational stakeholders, including teachers, students, schools, universities, and educational institutions. Scholars have initiated assessments of ChatGPT's effectiveness across various educational disciplines, even though ChatGPT was not explicitly designed for educational purposes. However, the widespread accessibility of ChatGPT, coupled with its extensive knowledge base, necessitates the development of comprehensive evaluation frameworks. In this paper, we introduce a holistic evaluation framework tailored for ChatGPT. This framework takes into account both soft and hard skills, and it is designed to seamlessly incorporate ChatGPT into Intelligent Tutoring Systems, making it suitable for a wide range of educational fields. By establishing a connection between ITS and ChatGPT, as they are both AI tools, we can benefit from the substantial background work achieved by previous research in ITSs to evaluate the educational influence of ChatGPT. © 2023 IEEE.
KW  - AI in Education
KW  - ChatGPT
KW  - e-learning
KW  - Educational Evaluation Frameworks
KW  - educational software
KW  - generative AI
KW  - Intelligent Tutoring Systems
KW  - large language models
KW  - Education computing
KW  - Intelligent vehicle highway systems
KW  - Knowledge based systems
KW  - Teaching
KW  - AI in education
KW  - ChatGPT
KW  - E - learning
KW  - Educational evaluation
KW  - Educational evaluation framework
KW  - Educational software
KW  - Evaluation framework
KW  - Generative AI
KW  - Intelligent tutoring
KW  - Intelligent tutoring system
KW  - Language model
KW  - Large language model
KW  - Tutoring system
KW  - Computer aided instruction
PB  - Institute of Electrical and Electronics Engineers Inc.
SN  - 979-835031806-7 (ISBN)
LA  - English
J2  - Int. Conf. Inf., Intell., Syst. Appl., IISA
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 0; Conference name: 14th International Conference on Information, Intelligence, Systems and Applications, IISA 2023; Conference date: 10 July 2023 through 12 July 2023; Conference code: 195501
ER  -

TY  - CONF
AU  - Kanaan, A.G.
AU  - Wahsheh, F.R.
AU  - El-Ebiary, Y.A.B.
AU  - Wan Hamzah, W.M.A.F.
AU  - Pandey, B.
AU  - Stenin, N.P.
TI  - An Evaluation and Annotation Methodology for Product Category Matching in E-Commerce Using GPT
PY  - 2023
T2  - 2023 International Conference on Computer Science and Emerging Technologies, CSET 2023
DO  - 10.1109/CSET58993.2023.10346684
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85182030928&doi=10.1109%2fCSET58993.2023.10346684&partnerID=40&md5=872f75a21c67b2f80c3242326335ff7e
AD  - Petra University, Faculty of Management and Financial Sciences, Business & E-commerce Department, Amman, Jordan
AD  - Faculty of Business, Ajloun National University, Department of Management Information Systems, Ajloun, Jordan
AD  - UniSZA, Faculty of Informatics and Computing, Malaysia
AD  - Eurasian National University, Kazakhstan
AD  - Jain Deemed to Be University, Bangalore, India
AB  - In the rapidly evolving landscape of e-commerce, accurately matching products to their relevant categories is crucial for improving search functionality, enhancing user experience, and driving sales. To address this challenge, this research paper proposes an innovative evaluation and annotation methodology that leverages the power of GPT (Generative Pre-trained Transformer) for product category matching. The primary goal of this study is to develop an efficient and reliable system that can automatically categorize products into appropriate groups based on their descriptions, titles, and other relevant attributes. To achieve this, we employ GPT, a state-of-the-art natural language processing model known for its proficiency in understanding and generating human-like text. The research methodology follows a multi-step approach. Firstly, a large dataset comprising product descriptions and corresponding categories is collected from diverse e-commerce platforms. Next, this dataset is carefully annotated by domain experts to establish ground truth category assignments. During the annotation process, specific challenges related to ambiguous product descriptions and overlapping categories are addressed to ensure high-quality annotations. Subsequently, the pre-trained GPT model is fine-tuned on the annotated dataset using transfer learning techniques. The fine-tuned model is then evaluated using various performance metrics, including precision, recall, F1-score, and accuracy, to quantify its effectiveness in categorizing products accurately. To validate the proposed methodology, extensive experiments are conducted on a representative set of e-commerce products. A comparative analysis is performed by benchmarking the GPT-based approach against traditional rule-based methods and other popular deep learning models in the field of text classification. The results demonstrate the superiority of the GPT-based model in product category matching, exhibiting significant improvements over existing methods. The research findings highlight the model's ability to capture complex semantic relationships between products and categories, leading to more accurate and context-aware categorization. This research paper contributes a robust evaluation and annotation methodology for product category matching in e-commerce using GPT. The study establishes the effectiveness of GPT in enhancing the performance of product categorization systems and showcases its potential in revolutionizing the e-commerce landscape. The proposed methodology holds promising implications for online retailers seeking to optimize product discovery, customer engagement, and overall user satisfaction. © 2023 IEEE.
KW  - Annotation
KW  - Artificial Intelligent
KW  - E-Commerce
KW  - GPT
KW  - NLP
KW  - Product Category
KW  - Classification (of information)
KW  - Customer satisfaction
KW  - Deep learning
KW  - Electronic commerce
KW  - Large dataset
KW  - Learning systems
KW  - Sales
KW  - Semantics
KW  - Text processing
KW  - Annotation
KW  - Artificial intelligent
KW  - E- commerces
KW  - Generative pre-trained transformer
KW  - Matchings
KW  - Product categories
KW  - Product descriptions
KW  - Research papers
KW  - Search functionality
KW  - Users' experiences
KW  - Natural language processing systems
PB  - Institute of Electrical and Electronics Engineers Inc.
SN  - 979-835034173-7 (ISBN)
LA  - English
J2  - Int. Conf. Comput. Sci. Emerg. Technol., CSET
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 0; Conference name: 1st International Conference on Computer Science and Emerging Technologies, CSET 2023; Conference date: 10 October 2023 through 12 October 2023; Conference code: 195632
ER  -

TY  - CONF
AU  - Luo, L.
AU  - Vu, T.-T.
AU  - Phung, D.
AU  - Haffari, G.
TI  - Systematic Assessment of Factual Knowledge in Large Language Models
PY  - 2023
T2  - Findings of the Association for Computational Linguistics: EMNLP 2023
SP  - 13272
EP  - 13286
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85183300786&partnerID=40&md5=16c4c33f7a0276a282d59858af569cde
AD  - Department of Data Science and AI, Faculty of Information Technology, Monash University, Australia
AB  - Previous studies have relied on existing question-answering benchmarks to evaluate the knowledge stored in large language models (LLMs). However, this approach has limitations regarding factual knowledge coverage, as it mostly focuses on generic domains which may overlap with the pretraining data. This paper proposes a framework to systematically assess the factual knowledge of LLMs by leveraging knowledge graphs (KGs). Our framework automatically generates a set of questions and expected answers from the facts stored in a given KG, and then evaluates the accuracy of LLMs in answering these questions. We systematically evaluate the state-of-the-art LLMs with KGs in generic and specific domains. The experiment shows that ChatGPT is consistently the top performer across all domains. We also find that LLMs performance depends on the instruction finetuning, domain and question complexity and is prone to adversarial context. © 2023 Association for Computational Linguistics.
KW  - Knowledge graph
KW  - Knowledge management
KW  - Factual knowledge
KW  - Knowledge graphs
KW  - Language model
KW  - Modeling performance
KW  - Pre-training
KW  - Question Answering
KW  - Set of questions
KW  - State of the art
KW  - Systematic assessment
KW  - Computational linguistics
PB  - Association for Computational Linguistics (ACL)
SN  - 979-889176061-5 (ISBN)
LA  - English
J2  - Find. Assoc. Comput. Linguist.: EMNLP
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 0; Conference name: 2023 Findings of the Association for Computational Linguistics: EMNLP 2023; Conference date: 6 December 2023 through 10 December 2023; Conference code: 196127
ER  -

TY  - CONF
AU  - Panagoulias, D.P.
AU  - Palamidas, F.A.
AU  - Virvou, M.
AU  - Tsihrintzis, G.A.
TI  - Evaluating the Potential of LLMs and ChatGPT on Medical Diagnosis and Treatment
PY  - 2023
T2  - 14th International Conference on Information, Intelligence, Systems and Applications, IISA 2023
DO  - 10.1109/IISA59645.2023.10345968
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85182024925&doi=10.1109%2fIISA59645.2023.10345968&partnerID=40&md5=67647116d692ddd0c19b2360b703a314
AD  - University of Piraeus, Department of Informatics, Piraeus, 185 34, Greece
AD  - Aristotle University of Thessaloniki, Department of Medicine, Thessaloniki, 541 24, Greece
AB  - We evaluate the validity, accuracy, and usefulness of ChatGPT-returned medical diagnosis of lung disease based on symptoms described by a human. Specifically, Tuberculosis and its symptoms are selected as the test case and our evaluation follows the directions of (i) medical validity and accuracy of the returned diagnosis in terms of both context and references, (ii) its usefulness to both doctors and patients and (iii) the economic value added to the healthcare system. It is shown that ChatGPT performs well in diagnosing Tuberculosis, but its performance improves when supervised by a human medical expert. In the interest of adding reproducibility and comparability, we propose a novel general evaluation procedure for the medical domain, to be followed when interacting with Large Language Models. This procedure integrates the various steps employed in our evaluation process and encompasses the review indices utilized for quantifying the outcome. © 2023 IEEE.
KW  - AI-empowered software engineering
KW  - ChatGPT
KW  - explainability
KW  - LLM
KW  - NLP
KW  - prompt-engineering
KW  - Software engineering
KW  - AI-empowered software engineering
KW  - ChatGPT
KW  - Economic value added
KW  - Explainability
KW  - Healthcare systems
KW  - LLM
KW  - Medical experts
KW  - Performance
KW  - Prompt-engineering
KW  - Test case
KW  - Diagnosis
PB  - Institute of Electrical and Electronics Engineers Inc.
SN  - 979-835031806-7 (ISBN)
LA  - English
J2  - Int. Conf. Inf., Intell., Syst. Appl., IISA
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 2; Conference name: 14th International Conference on Information, Intelligence, Systems and Applications, IISA 2023; Conference date: 10 July 2023 through 12 July 2023; Conference code: 195501
ER  -

TY  - CONF
AU  - Zhou, L.
AU  - Rao, G.
TI  - Chinese Stylistic Competence: Evaluation Method and Datasets of Large Language Model's Performance
PY  - 2023
T2  - Proceedings of 2023 International Conference on Asian Language Processing, IALP 2023
SP  - 271
EP  - 277
DO  - 10.1109/IALP61005.2023.10337306
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85181774590&doi=10.1109%2fIALP61005.2023.10337306&partnerID=40&md5=b61f95e23d9a2d50f0e8b679a7615b52
AD  - Beijing Language and Culture University, Beijing, China
AB  - Stylistic competence is an important pragmatic competence, and adequate stylistic competence is required for large language model (LLM) to land in language life. In this paper, stylistic competence is defined as the ability to use appropriate style for communication in a specific register, and based on this, three tasks of stylistic classification, stylistic generation, and stylistic transformation are designed to evaluate the Chinese stylistic competence of LLMs represented by ChatGPT. It is found that LLMs have their own advantages and limitations in different tasks and styles. GPT-4 demonstrates the most comprehensive and excellent Chinese stylistic competence, ChatGPT3.5 and ERNIE Bot have better performance, ChatGLM-6B and SparkDesk have unstable performance and notable shortcomings, with their overall abilities being somewhat lackluster. In addition, the degree of informality of the texts generated by each model is relatively limited, the literary grace is ordinary, and problems such as consistency errors, normative errors, factual errors, illogicality, insufficient sentence fluency, and obvious traces of machine translation still exist. For LLM, it should be viewed from an instrumental perspective, expanding its stylistic competence with rich and diversified stylistic data resources and technological advances, and at the same time reasonably utilizing and giving full play to its stylistic resources attribute, to make it better serve the language life.  © 2023 IEEE.
KW  - language resource
KW  - large language model
KW  - stylistic competence
KW  - Computational linguistics
KW  - Large dataset
KW  - Consistency error
KW  - Data resources
KW  - Evaluation methods
KW  - Language model
KW  - Language resources
KW  - Large language model
KW  - Machine translations
KW  - Modeling performance
KW  - Performance
KW  - Stylistic competence
KW  - Errors
A2  - Wang L.
A2  - Lu Y.
A2  - Dong M.
PB  - Institute of Electrical and Electronics Engineers Inc.
SN  - 979-835033078-6 (ISBN)
LA  - English
J2  - Proc. Int. Conf. Asian Lang. Process., IALP
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 0; Correspondence Address: G. Rao; Beijing Language and Culture University, Beijing, China; email: raogaoqi@blcu.edu.cn; Conference name: 27th International Conference on Asian Language Processing, IALP 2023; Conference date: 18 November 2023 through 20 November 2023; Conference code: 195317
ER  -

TY  - CONF
AU  - Mbula Mboma, J.G.
AU  - Tshipata, O.T.
AU  - Kambale, W.V.
AU  - Kyamakya, K.
TI  - Assessing How Large Language Models Can Be Integrated with or Used for Blockchain Technology: Overview and Illustrative Case Study
PY  - 2023
T2  - Proceedings - 27th International Conference on Circuits, Systems, Communications and Computers, CSCC 2023
SP  - 59
EP  - 70
DO  - 10.1109/CSCC58962.2023.00018
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85182742838&doi=10.1109%2fCSCC58962.2023.00018&partnerID=40&md5=2e8a39779476bb56a48a92be80a17e38
AD  - Génie Electrique et Informatique, Université de Kinshasa (UNIKIN), Kinshasa, Democratic Republic Congo
AD  - Institute for Smart Systems Technologies, Universitaet Klagenfurt, Klagenfurt, Austria
AD  - Universitaet Klagenfurt /Inst. F Smart Systems Technologies, Austria
AD  - Université de Kinshasa, Faculté Polytechnique, Democratic Republic Congo
AB  - While Large Language Models (LLMs) are turning the field of natural language processing on its head with their remarkable ability to understand context and generate creative content, blockchain is currently an excellent option for building decentralized systems that are both secure and transparent. While these two technologies are already powerful tools individually, combining them can only be promising. In this article, we will explore the opportunities offered by integrating LLMs with Blockchain. By reviewing existing work and research and discussing use cases, this article evaluates the benefits and analyzes the challenges of LLMs in Blockchain-based applications. We also propose two possible architectures and outline our approach for integrating LLMs into decentralized applications as a tool capable of understanding the sometimes imprecise and ambiguous intentions of decentralized application users and translating them into clear and executable instructions for optimal transactions. This approach aims to improve and optimize the interaction between users and the blockchain by better understanding their intentions, which could pave the way for massive use and adoption of decentralized systems. This work therefore contributes to Blockchain by proposing state-of-the-art LLM integration perspectives while presenting a precise approach to this integration.  © 2023 IEEE.
KW  - Blockchain
KW  - Large Language Models
KW  - Oracles
KW  - Smart contract
KW  - Blockchain
KW  - Computational linguistics
KW  - Decentralized systems
KW  - Natural language processing systems
KW  - Block-chain
KW  - Case-studies
KW  - Creatives
KW  - Decentralised
KW  - Decentralized system
KW  - Language model
KW  - Language processing
KW  - Large language model
KW  - Natural languages
KW  - Oracle
KW  - Smart contract
PB  - Institute of Electrical and Electronics Engineers Inc.
SN  - 979-835033759-4 (ISBN)
LA  - English
J2  - Proc. - Int. Conf. Circuits, Syst., Commun. Comput., CSCC
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 0; Conference name: 27th International Conference on Circuits, Systems, Communications and Computers, CSCC 2023; Conference date: 19 July 2023 through 22 July 2023; Conference code: 195844
ER  -

TY  - JOUR
AU  - Lockie, E.
AU  - Choi, J.
TI  - Evaluation of a chat GPT generated patient information leaflet about laparoscopic cholecystectomy
PY  - 2023
T2  - ANZ Journal of Surgery
DO  - 10.1111/ans.18834
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85180176682&doi=10.1111%2fans.18834&partnerID=40&md5=81b92be37c68493f42104c5adda5ce10
AD  - Department of General Surgery, Epworth Hospital Richmond, Melbourne, Australia
AD  - Department of General Surgery, Royal Melbourne Hospital, Melbourne, Australia
AD  - General and Hepato-pancreato-biliary surgery, Western Health, Melbourne, Australia
AB  - Background: Artificial intelligence is increasingly being used in all aspects of life in information compilation and writing, and this includes healthcare. This study aimed to evaluate a Chat GPT generated patient information leaflet (PIL) against a surgeon generated version, in order to explore a potential application of this artificial intelligence language processing model. Methods: Cross-sectional study, undertaken May to June 2023, asking two cohorts (patients and doctors) to complete a questionnaire evaluating a Chat GPT generated PIL and a surgeon generated PIL about laparoscopic cholecystectomy. The patients were having laparoscopic cholecystectomy at large private Hospital in Melbourne, Australia, and doctors were recruited from this hospital and a public quaternary hospital in Melbourne, Australia. The study included a convenience sample of 28 patients and 16 doctors. The main outcome measure was a questionnaire (maximum score out of 8) based on validated evaluation instrument for PILs. Results: The study recruited 28 patients and 15 doctors to complete the questionnaire. The Chat GPT and surgeon generated PILs were scored similarly by patients (median 8 for both PIL; mean 7.5 for Chat GPT PIL vs. 7.1 for surgeon PIL). Doctors also scored both versions similarly, with slightly higher scores for Chat GPT over surgeon version (median 7 vs. 6; mean 6.7 vs. 5.6, respectively). Conclusions: The Chat GPT generated PIL was assessed as being as good or slightly better than the surgeon generated version. This study shows that PIL are a feasible application of AI language processing models. © 2023 Royal Australasian College of Surgeons.
KW  - artificial intelligence
KW  - general surgery
KW  - patient information
KW  - surgical education
PB  - John Wiley and Sons Inc
SN  - 14451433 (ISSN)
LA  - English
J2  - ANZ J. Surg.
M3  - Article
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 0; Correspondence Address: E. Lockie; 36 Palmer Street, South Melbourne, 3205, Australia; email: elockie18@gmail.com; CODEN: AJSNB
ER  -

TY  - CONF
AU  - Singh, P.
AU  - Jain, B.
AU  - Sinha, K.
TI  - Evaluating Bert and GPT-2 Models for Personalised Linkedin Post Recommendation
PY  - 2023
T2  - 2023 14th International Conference on Computing Communication and Networking Technologies, ICCCNT 2023
DO  - 10.1109/ICCCNT56998.2023.10307957
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85179845557&doi=10.1109%2fICCCNT56998.2023.10307957&partnerID=40&md5=4ac0e2b82e3b83d3e06bab517cf962d7
AD  - Igdtuw, Department of Cse, New Delhi, India
AB  - Social networking platforms have become essential tools for individuals and organisations to connect, communicate, and collaborate in today's digital age. LinkedIn is a professional social networking platform facilitating career development and job searching. LinkedIn's traditional post recommendation system limits users to seeing only those posts that have been engaged upon by their following or first-degree connections, limiting the user's perspective. The proposed system leverages the content posted by the user to provide personalised content delivery on LinkedIn, potentially enhancing user engagement and satisfaction. This research study proposes and examines the performance of three content-based recommender models developed with Machine Learning (ML), Generative Pre-Trained Transformer (GPT-2), and Bidirectional Encoder Representations from Transformers (BERT). In terms of capturing the similarity between user-generated and recommended posts, BERT outperformed the other models, achieving the highest similarity score of 97.13%, compared to GPT-2 (96.27%) and basic ML (95.69%). © 2023 IEEE.
KW  - GPT-2
KW  - LinkedIn
KW  - Natural Language Processing
KW  - Recommender System
KW  - Transformers
KW  - Employment
KW  - Natural language processing systems
KW  - Social networking (online)
KW  - Career development
KW  - Digital age
KW  - GPT-2
KW  - Language processing
KW  - LinkedIn
KW  - Machine-learning
KW  - Natural language processing
KW  - Natural languages
KW  - Social-networking
KW  - Transformer
KW  - Recommender systems
PB  - Institute of Electrical and Electronics Engineers Inc.
SN  - 979-835033509-5 (ISBN)
LA  - English
J2  - Int. Conf. Comput. Commun. Netw. Technol., ICCCNT
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 0; Correspondence Address: P. Singh; Igdtuw, Department of Cse, New Delhi, India; email: prerna194btcse21@igdtuw.ac.in; Conference name: 14th International Conference on Computing Communication and Networking Technologies, ICCCNT 2023; Conference date: 6 July 2023 through 8 July 2023; Conference code: 194774
ER  -

TY  - CONF
AU  - Rahman Sifat, H.
AU  - Nuri Sabab, N.H.
AU  - Ahmed, T.
TI  - Evaluating the Effectiveness of Capsule Neural Network in Toxic Comment Classification Using Pre-Trained BERT Embeddings
PY  - 2023
T2  - IEEE Region 10 Annual International Conference, Proceedings/TENCON
SP  - 42
EP  - 46
DO  - 10.1109/TENCON58879.2023.10322429
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85179504921&doi=10.1109%2fTENCON58879.2023.10322429&partnerID=40&md5=7f9427f6e0349eefe06ba9abd855725b
AD  - The Hong Kong Polytechnic University Hung Hom, Department of Computing, Kowloon, Hong Kong
AD  - United International University, Department of Cse, Dhaka, Bangladesh
AD  - Ai Team, Smart Studios, Birkirkara, Malta
AB  - Large language models (LLMs) have attracted considerable interest in the fields of natural language understanding (NLU) and natural language generation (NLG) since their introduction. In contrast, the legacy of Capsule Neural Networks (CapsNet) appears to have been largely forgotten amidst all of this excitement. This project's objective is to reignite interest in CapsNet by reopening the previously closed studies and conducting a new research into CapsNet's potential. We present a study where CapsNet is used to classify toxic text by leveraging pre-trained BERT embed dings (bert-base-uncased) on a large multilingual dataset. In this experiment, CapsNet was tasked with categorizing toxic text. By comparing the performance of CapsNet to that of other architectures, such as DistilBERT, Vanilla Neural Networks (VNN), and Convolutional Neural Networks (CNN), we were able to achieve an accuracy of 90.44 %. This result highlights the benefits of CapsNet over text data and suggests new ways to enhance their performance so that it is comparable to DistilBERT and other reduced architectures.  © 2023 IEEE.
KW  - Classification (of information)
KW  - Computational linguistics
KW  - Convolutional neural networks
KW  - Large dataset
KW  - Network architecture
KW  - Convolutional neural network
KW  - Embeddings
KW  - Language model
KW  - Natural language generation
KW  - Natural language understanding
KW  - Neural-networks
KW  - Performance
KW  - Project objectives
KW  - Text data
KW  - Natural language processing systems
PB  - Institute of Electrical and Electronics Engineers Inc.
SN  - 21593442 (ISSN); 979-835030219-6 (ISBN)
LA  - English
J2  - IEEE Reg 10 Annu Int Conf Proc TENCON
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 0; Conference name: 38th IEEE Region 10 Conference, TENCON 2023; Conference date: 31 October 2023 through 3 November 2023; Conference code: 194660; CODEN: 85QXA
ER  -

TY  - CONF
AU  - Deng, Y.
AU  - Liao, L.
AU  - Chen, L.
AU  - Wang, H.
AU  - Lei, W.
AU  - Chua, T.-S.
TI  - Prompting and Evaluating Large Language Models for Proactive Dialogues: Clarification, Target-guided, and Non-collaboration
PY  - 2023
T2  - Findings of the Association for Computational Linguistics: EMNLP 2023
SP  - 10602
EP  - 10621
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85183301530&partnerID=40&md5=f701f9a0b3dc07bd8004b0a29b0b109f
AD  - National University of Singapore, Singapore
AD  - Singapore Management University, Singapore
AD  - The Chinese University of Hong Kong, Hong Kong
AD  - Sichuan University of Hong Kong, Hong Kong
AB  - Conversational systems based on Large Language Models (LLMs), such as ChatGPT, show exceptional proficiency in context understanding and response generation. However, they still possess limitations, such as failing to ask clarifying questions to ambiguous queries or refuse users' unreasonable requests, both of which are considered as key aspects of a conversational agent's proactivity. This raises the question of whether LLM-based conversational systems are equipped to handle proactive dialogue problems. In this work, we conduct a comprehensive analysis of LLM-based conversational systems, specifically focusing on three key aspects of proactive dialogues: clarification, target-guided, and non-collaborative dialogues. To trigger the proactivity of LLMs, we propose the Proactive Chain-of-Thought prompting scheme, which augments LLMs with the goal planning capability over descriptive reasoning chains. Empirical findings are discussed to promote future studies on LLM-based proactive dialogue systems. © 2023 Association for Computational Linguistics.
KW  - Computational linguistics
KW  - Speech processing
KW  - Comprehensive analysis
KW  - Conversational agents
KW  - Conversational systems
KW  - Empirical findings
KW  - In contexts
KW  - Language model
KW  - Model-based OPC
KW  - Planning capability
KW  - Proactivity
KW  - Response generation
KW  - Clarifiers
PB  - Association for Computational Linguistics (ACL)
SN  - 979-889176061-5 (ISBN)
LA  - English
J2  - Find. Assoc. Comput. Linguist.: EMNLP
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 0; Conference name: 2023 Findings of the Association for Computational Linguistics: EMNLP 2023; Conference date: 6 December 2023 through 10 December 2023; Conference code: 196127
ER  -

TY  - CONF
AU  - Zhou, K.
AU  - Lai, E.
AU  - Yeong, W.B.A.
AU  - Mouratidis, K.
AU  - Jiang, J.
TI  - ROME: Evaluating Pre-trained Vision-Language Models on Reasoning beyond Visual Common Sense
PY  - 2023
T2  - Findings of the Association for Computational Linguistics: EMNLP 2023
SP  - 10185
EP  - 10197
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85183295347&partnerID=40&md5=a146f2b243868661c65b26175f810e23
AD  - School of Computing and Information Systems, Singapore Management University, Singapore
AB  - Humans possess a strong capability for reasoning beyond common sense. For example, given an unconventional image of a goldfish laying on the table next to an empty fishbowl, a human would effortlessly determine that the fish is not inside the fishbowl. The case, however, may be different for a vision-language model, whose reasoning could gravitate towards the common scenario that the fish is inside the bowl, despite the visual input. In this paper, we introduce a novel probing dataset named ROME (reasoning beyond commonsense knowledge) to evaluate whether the state-of-the-art pretrained vision-language models have the reasoning capability to correctly interpret counter-intuitive content. ROME contains images that defy commonsense knowledge with regards to color, shape, material, size and positional relation. Experiments on the state-of-the-art pretrained vision-language models reveal that most of these models are still largely incapable of interpreting counter-intuitive scenarios. We hope that ROME will spur further investigations on reasoning beyond commonsense knowledge in vision-language research. © 2023 Association for Computational Linguistics.
KW  - Computational linguistics
KW  - Visual languages
KW  - Common sense
KW  - Commonsense knowledge
KW  - Goldfishes
KW  - Language model
KW  - Reasoning capabilities
KW  - State of the art
KW  - Fish
PB  - Association for Computational Linguistics (ACL)
SN  - 979-889176061-5 (ISBN)
LA  - English
J2  - Find. Assoc. Comput. Linguist.: EMNLP
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 0; Conference name: 2023 Findings of the Association for Computational Linguistics: EMNLP 2023; Conference date: 6 December 2023 through 10 December 2023; Conference code: 196127
ER  -

TY  - JOUR
AU  - Yang, T.
AU  - Zhang, Q.
AU  - Sun, Z.
AU  - Hou, Y.
TI  - Automatic assessment of divergent thinking in Chinese language with TransDis: A transformer-based language model approach
PY  - 2023
T2  - Behavior Research Methods
DO  - 10.3758/s13428-023-02313-z
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85180240235&doi=10.3758%2fs13428-023-02313-z&partnerID=40&md5=dce6f2294cc49627eed91058c046bf99
AD  - School of Psychological and Cognitive Sciences and Beijing Key Laboratory of Behavior and Mental Health, Peking University, Beijing, 100871, China
AD  - School of Engineering and Applied Science, George Washington University, Washington, 20052, DC, United States
AB  - Language models have been increasingly popular for automatic creativity assessment, generating semantic distances to objectively measure the quality of creative ideas. However, there is currently a lack of an automatic assessment system for evaluating creative ideas in the Chinese language. To address this gap, we developed TransDis, a scoring system using transformer-based language models, capable of providing valid originality (novelty) and flexibility (variety) scores for Alternative Uses Task (AUT) responses in Chinese. Study 1 demonstrated that the latent model-rated originality factor, comprised of three transformer-based models, strongly predicted human originality ratings, and the model-rated flexibility strongly correlated with human flexibility ratings as well. Criterion validity analyses indicated that model-rated originality and flexibility positively correlated to other creativity measures, demonstrating similar validity to human ratings. Study 2 and 3 showed that TransDis effectively distinguished participants instructed to provide creative vs. common uses (Study 2) and participants instructed to generate ideas in a flexible vs. persistent way (Study 3). Our findings suggest that TransDis can be a reliable and low-cost tool for measuring idea originality and flexibility in Chinese language, potentially paving the way for automatic creativity assessment in other languages. We offer an open platform to compute originality and flexibility for AUT responses in Chinese and over 50 other languages (https://osf.io/59jv2/). © 2023, The Psychonomic Society, Inc.
KW  - Assessment
KW  - Creativity
KW  - Divergent thinking
KW  - Flexibility
KW  - Natural language processing
KW  - Originality
KW  - Semantic distance
KW  - Transformer-based language model
KW  - adult
KW  - article
KW  - child
KW  - Chinese (language)
KW  - creativity
KW  - criterion related validity
KW  - female
KW  - human
KW  - language model
KW  - male
KW  - natural language processing
KW  - scoring system
KW  - thinking
KW  - validity
PB  - Springer
SN  - 1554351X (ISSN)
LA  - English
J2  - Behav. Res. Methods
M3  - Article
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 0; Correspondence Address: Y. Hou; School of Psychological and Cognitive Sciences and Beijing Key Laboratory of Behavior and Mental Health, Peking University, Beijing, 100871, China; email: houyubo@pku.edu.cn
ER  -

TY  - CONF
AU  - Chen, J.
AU  - Yoon, J.
AU  - Ebrahimi, S.
AU  - Arık, S.Ö.
AU  - Pfister, T.
AU  - Jha, S.
TI  - Adaptation with Self-Evaluation to Improve Selective Prediction in LLMs
PY  - 2023
T2  - Findings of the Association for Computational Linguistics: EMNLP 2023
SP  - 5190
EP  - 5213
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85183292516&partnerID=40&md5=5a3ccd8ab153451a10093744c537eb3c
AD  - University of Wisconsin-Madison, United States
AD  - Google LLC
AB  - Large language models (LLMs) have recently shown great advances in a variety of tasks, including natural language understanding and generation. However, their use in high-stakes decision-making scenarios is still limited due to the potential for errors. Selective prediction is a technique that can be used to improve the reliability of the LLMs by allowing them to abstain from making predictions when they are unsure of the answer. In this work, we propose a novel framework for adaptation with self-evaluation to improve the selective prediction performance of LLMs. Our framework is based on the idea of using parameter-efficient tuning to adapt the LLM to the specific task at hand while improving its ability to perform self-evaluation. We evaluate our method on a variety of question-answering (QA) datasets and show that it outperforms state-of-the-art selective prediction methods. For example, on the CoQA benchmark, our method improves the AUACC from 91.23% to 92.63% and improves the AUROC from 74.61% to 80.25%. © 2023 Association for Computational Linguistics.
KW  - Computational linguistics
KW  - Decision making
KW  - Natural language processing systems
KW  - Decisions makings
KW  - Language model
KW  - Natural language generation
KW  - Natural language understanding
KW  - Prediction methods
KW  - Prediction performance
KW  - Question Answering
KW  - Self evaluation
KW  - State of the art
KW  - Forecasting
PB  - Association for Computational Linguistics (ACL)
SN  - 979-889176061-5 (ISBN)
LA  - English
J2  - Find. Assoc. Comput. Linguist.: EMNLP
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 0; Conference name: 2023 Findings of the Association for Computational Linguistics: EMNLP 2023; Conference date: 6 December 2023 through 10 December 2023; Conference code: 196127
ER  -

TY  - JOUR
AU  - Surapaneni, K.M.
AU  - Rajajagadeesan, A.
AU  - Goudhaman, L.
AU  - Lakshmanan, S.
AU  - Sundaramoorthi, S.
AU  - Ravi, D.
AU  - Rajendiran, K.
AU  - Swaminathan, P.
TI  - Evaluating ChatGPT as a self-learning tool in medical biochemistry: A performance assessment in undergraduate medical university examination
PY  - 2023
T2  - Biochemistry and Molecular Biology Education
DO  - 10.1002/bmb.21808
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85180219788&doi=10.1002%2fbmb.21808&partnerID=40&md5=f56a25168928c59949eb6803f3ea5130
AD  - Department of Biochemistry, Panimalar Medical College Hospital & Research Institute, Chennai, India
AD  - Department of Medical Education, Panimalar Medical College Hospital & Research Institute, Chennai, India
AD  - Department of Clinical Skills & Simulation, Panimalar Medical College Hospital & Research Institute, Chennai, India
AD  - Department of Community Medicine, Panimalar Medical College Hospital & Research Institute, Chennai, India
AB  - The emergence of ChatGPT as one of the most advanced chatbots and its ability to generate diverse data has given room for numerous discussions worldwide regarding its utility, particularly in advancing medical education and research. This study seeks to assess the performance of ChatGPT in medical biochemistry to evaluate its potential as an effective self-learning tool for medical students. This evaluation was carried out using the university examination question papers of both parts 1 and 2 of medical biochemistry which comprised theory and multiple choice questions (MCQs) accounting for a total of 100 in each part. The questions were used to interact with ChatGPT, and three raters independently reviewed and scored the answers to prevent bias in scoring. We conducted the inter-item correlation matrix and the interclass correlation between raters 1, 2, and 3. For MCQs, symmetric measures in the form of kappa value (a measure of agreement) were performed between raters 1, 2, and 3. ChatGPT generated relevant and appropriate answers to all questions along with explanations for MCQs. ChatGPT has “passed” the medical biochemistry university examination with an average score of 117 out of 200 (58%) in both papers. In Paper 1, ChatGPT has secured 60 ± 2.29 and 57 ± 4.36 in Paper 2. The kappa value for all the cross-analysis of Rater 1, Rater 2, and Rater 3 scores in MCQ was 1.000. The evaluation of ChatGPT as a self-learning tool in medical biochemistry has yielded important insights. While it is encouraging that ChatGPT has demonstrated proficiency in this area, the overall score of 58% indicates that there is work to be done. To unlock its full potential as a self-learning tool, ChatGPT must focus on generating not only accurate but also comprehensive and contextually relevant content. © 2023 International Union of Biochemistry and Molecular Biology.
KW  - artificial intelligence
KW  - biochemistry
KW  - ChatGPT
KW  - medical education
PB  - John Wiley and Sons Inc
SN  - 14708175 (ISSN)
LA  - English
J2  - Biochem. Mol. Biol. Educ.
M3  - Article
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 0; Correspondence Address: K.M. Surapaneni; Departments of Biochemistry, Medical Education, Clinical Skills & Simulation, Panimalar Medical College Hospital & Research Institute, Poonamallee, Varadharajapuram, Tamil Nadu, Chennai, 600123, India; email: krishnamohan.surapaneni@gmail.com; CODEN: BMBEC
ER  -

TY  - CONF
AU  - Frey, J.
AU  - Meyer, L.-P.
AU  - Arndt, N.
AU  - Brei, F.
AU  - Bulert, K.
TI  - Benchmarking the Abilities of Large Language Models for RDF Knowledge Graph Creation and Comprehension: How Well Do LLMs Speak Turtle?
PY  - 2023
T2  - CEUR Workshop Proceedings
VL  - 3559
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85178596343&partnerID=40&md5=e04931624848f328aa2c4965169f67e2
AD  - Institute for Applied Informatics, Goerdelerring 9, Leipzig, 04109, Germany
AD  - Agile Knowledge Engineering and Semantic Web (AKSW), United States
AD  - Leipzig University, Institute for Informatics, Germany
AD  - eccenca GmbH, Leipzig, Germany
AB  - Large Language Models (LLMs) are advancing at a rapid pace, with significant improvements at natural language processing and coding tasks. Yet, their ability to work with formal languages representing data, specifically within the realm of knowledge graph engineering, remains under-investigated. To evaluate the proficiency of various LLMs, we created a set of five tasks that probe their ability to parse, understand, analyze, and create knowledge graphs serialized in Turtle syntax. These tasks, each embodying distinct degrees of complexity and being able to scale with the size of the problem, have been integrated into our automated evaluation system, the LLM-KG-Bench. The evaluation encompassed four commercially available LLMs - GPT-3.5, GPT-4, Claude 1.3, and Claude 2.0, as well as two freely accessible offline models, GPT4All Vicuna and GPT4All Falcon 13B. This analysis offers an in-depth understanding of the strengths and shortcomings of LLMs in relation to their application within RDF knowledge graph engineering workflows utilizing Turtle representation. While our findings show that the latest commercial models outperform their forerunners in terms of proficiency with the Turtle language, they also reveal an apparent weakness. These models fall short when it comes to adhering strictly to the output formatting constraints, a crucial requirement in this context. © 2023 Copyright for this paper by its authors.
KW  - Knowledge Graph Engineering
KW  - Large Language Model
KW  - Large Language Model Benchmark
KW  - Computational linguistics
KW  - Formal languages
KW  - Natural language processing systems
KW  - Petroleum reservoir evaluation
KW  - Resource Description Framework (RDF)
KW  - Automated evaluation systems
KW  - Degrees of complexity
KW  - Knowledge graph engineering
KW  - Knowledge graphs
KW  - Language model
KW  - Language processing
KW  - Large language model
KW  - Large language model benchmark
KW  - Natural languages
KW  - Knowledge graph
A2  - Alam M.
A2  - Buscaldi D.
A2  - Cochez M.
A2  - Osborne F.
A2  - Recupero D.R.
PB  - CEUR-WS
SN  - 16130073 (ISSN)
LA  - English
J2  - CEUR Workshop Proc.
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 0; Correspondence Address: J. Frey; Institute for Applied Informatics, Leipzig, Goerdelerring 9, 04109, Germany; email: frey@informatik.uni-leipzig.de; L.-P. Meyer; Institute for Applied Informatics, Leipzig, Goerdelerring 9, 04109, Germany; email: lpmeyer@infai.org; Conference name: 2023 Workshop on Deep Learning for Knowledge Graphs, DL4KG 2023; Conference date: 6 November 2023 through 10 November 2023; Conference code: 194582
ER  -

TY  - CONF
AU  - Sun, M.
AU  - Yang, Y.
AU  - Wang, Y.
AU  - Wen, M.
AU  - Jia, H.
AU  - Zhou, Y.
TI  - SMT Solver Validation Empowered by Large Pre-Trained Language Models
PY  - 2023
T2  - Proceedings - 2023 38th IEEE/ACM International Conference on Automated Software Engineering, ASE 2023
SP  - 1288
EP  - 1300
DO  - 10.1109/ASE56229.2023.00180
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85175596349&doi=10.1109%2fASE56229.2023.00180&partnerID=40&md5=212b4e6b0e87a619b2cd9b21ca97e624
AD  - Nanjing University, State Key Laboratory for Novel Software Technology, China
AD  - School of Cyber Science and Engineering, Huazhong University of Science and Technology, China
AB  - SMT solvers are utilized to check the satisfiability of logic formulas and have been applied in various crucial domains, including software verification, test case generation, and program synthesis. However, bugs hidden in SMT solvers can lead to severe consequences, causing erroneous results in these domains. Therefore, ensuring the reliability and robustness of SMT solvers is of critical importance. Despite several testing approaches proposed for SMT solvers, generating effective test formulas to comprehensively test SMT solvers remains a challenge. To address this challenge, in this study, we propose to port large language models (LLMs) to generate SMT formulas for fuzzing solvers. Specifically, the study presents a novel retrain-finetune pipeline to unleash the potential of language models to generate effective SMT formulas and improve their generation performance through data augmentation. We implemented our approach as a practical fuzzing tool, named LasT,and then extensively tested the state-of-the-art SMT solvers, namely Z3, cvc5, and Bitwuzla. To date, Last has successfully uncovered 65 genuine bugs for the solvers, of which 45 have been fixed by the developers.  © 2023 IEEE.
KW  - data augmentation
KW  - fuzzing
KW  - large language model
KW  - retrain-finetune
KW  - SMT solver
KW  - Computational linguistics
KW  - Verification
KW  - Data augmentation
KW  - Fuzzing
KW  - Language model
KW  - Large language model
KW  - Logic formulas
KW  - Retrain-finetune
KW  - Satisfiability
KW  - SMT solv
KW  - Software verification
KW  - Verification tests
KW  - Software testing
PB  - Institute of Electrical and Electronics Engineers Inc.
SN  - 979-835032996-4 (ISBN)
LA  - English
J2  - Proc. - IEEE/ACM Int. Conf. Autom. Softw. Eng., ASE
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 1; Correspondence Address: Y. Yang; Nanjing University, State Key Laboratory for Novel Software Technology, China; email: yangyibiao@nju.edu.cn; Y. Zhou; Nanjing University, State Key Laboratory for Novel Software Technology, China; email: zhouyuming@nju.edu.cn; Conference name: 38th IEEE/ACM International Conference on Automated Software Engineering, ASE 2023; Conference date: 11 September 2023 through 15 September 2023; Conference code: 194295
ER  -

TY  - CONF
AU  - Gundu, T.
TI  - ChatGPT-Proofing: Redesigning Assessment Practices for E-Learning
PY  - 2023
T2  - Proceedings of the European Conference on e-Learning, ECEL
VL  - 2023-October
SP  - 121
EP  - 130
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85179126498&partnerID=40&md5=1924434f4f14fb105df04fa5faf98a79
AD  - Nelson Mandela University, South Africa
AB  - The 21st century has ushered in a profound transformation in the realm of education, fueled by the widespread integration of e-learning, fueled by technological advancements and the pursuit of adaptable and accessible learning modalities. As the e-learning landscape continues to evolve, a pertinent question emerges: Do conventional assessment methods align effectively with the exigencies of the digital era and the competencies imperative for thriving in the knowledge economy? This systematic literature review undertakes a comprehensive exploration of this significant question. Through a meticulous synthesis and analysis of a diverse body of existing research, this review effectively brings to light compelling evidence that underscores the pressing need for the redesign of assessment practices within the context of e-learning. In probing this multifaceted subject, the review critically examines how traditional assessment approaches may fall short in capturing the intricacies of modern-day skillsets, critical thinking proficiencies, and adaptability demanded by the swiftly evolving digital landscape. In its conclusion, this study serves as a pivotal catalyst for change, illuminating the urgency and potential benefits of reimagining assessment practices for the dynamic realm of 21st-century e-learning. Based on the findings, it provides stakeholders with prudent and actionable recommendations, empowering them to embark on a purposeful journey of redesigning assessment strategies. By proactively embracing these recommendations, educators, policymakers, and institutions can engender a learner-centric ecosystem that optimally nurtures and empowers learners for a future defined by innovation and adaptability. © 2023 Academic Conferences Limited. All rights reserved.
KW  - Assessment Methods
KW  - ChatGPT
KW  - e-Learning
KW  - Generative AI
KW  - Higher Education
KW  - Assessment method
KW  - Assessment practices
KW  - ChatGPT
KW  - Digital era
KW  - E - learning
KW  - Generative AI
KW  - High educations
KW  - Knowledge economy
KW  - Learning modalities
KW  - Technological advancement
A2  - Johnston S.J.
A2  - Singh S.
PB  - Academic Conferences and Publishing International Limited
SN  - 20488637 (ISSN); 978-191458790-0 (ISBN)
LA  - English
J2  - Proc. Eur. Conf. e-Learn., ECEL
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 0; Correspondence Address: T. Gundu; Nelson Mandela University, South Africa; email: tapgun@gmail.com; Conference name: 22nd European Conference on e- Learning, ECEL 2023; Conference date: 26 October 2023 through 27 October 2023; Conference code: 194594
ER  -

TY  - JOUR
AU  - Ferreira, A.L.
AU  - Chu, B.
AU  - Grant-Kels, J.M.
AU  - Ogunleye, T.
AU  - Lipoff, J.B.
TI  - Evaluation of ChatGPT Dermatology Responses to Common Patient Queries
PY  - 2023
T2  - JMIR Dermatology
VL  - 6
IS  - 1
C7  - e49280
DO  - 10.2196/49280
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85179151211&doi=10.2196%2f49280&partnerID=40&md5=ec1979c8c911e66dcf2dcc6c6c550d3c
AD  - Department of Dermatology, Perelman School of Medicine, University of Pennsylvania, Philadelphia, PA, United States
AD  - Department of Dermatology, University of Connecticut Health Center, Farmington, CT, United States
AD  - Department of Dermatology, University of Florida, Gainesville, FL, United States
AD  - Department of Dermatology, Lewis Katz School of Medicine, Temple University, Philadelphia, PA, United States
AD  - Department of Dermatology, Lewis Katz School of Medicine, Temple University, 525 Jamestown Avenue, Suite #206, Philadelphia, 19128, PA, United States
KW  - AI
KW  - AI tool
KW  - artificial intelligence
KW  - ChatGPT
KW  - dermatologist
KW  - dermatology
KW  - GPT-4
KW  - information resource
KW  - medical advice
KW  - patient queries
KW  - response evaluation
KW  - skin
KW  - skin condition
KW  - tool
PB  - JMIR Publications Inc.
SN  - 25620959 (ISSN)
LA  - English
J2  - JMIR. Dermatol.
M3  - Article
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 1; Correspondence Address: J.B. Lipoff; Department of Dermatology, Lewis Katz School of Medicine, Temple University, Philadelphia, United States; email: jules.lipoff@temple.edu
ER  -

TY  - JOUR
AU  - Demirkol, M.
AU  - Malkoc, N.
TI  - Assessing the Intellectual Structure of the Evolving Knowledge Base on ChatGPT in the Field of Education and Health
PY  - 2023
T2  - Educational Process: International Journal
VL  - 12
IS  - 4
SP  - 36
EP  - 64
DO  - 10.22521/edupij.2023.124.3
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85178029940&doi=10.22521%2fedupij.2023.124.3&partnerID=40&md5=c827887c402d652ec0b494761c119b04
AD  - Vocational High School, Firat University, Turkey
AD  - Department of Exercise and Sport Sciences, University of Health Sciences, Istanbul, Turkey
AB  - Background/purpose –The unprecedented developments in AI-based technologies and large language models such as ChatGPT have exhibited a brand-new territory to be explored. Since its first release in November 2022, the potential utility of ChatGPT has garnered incremental attention in the scientific world, and has already accumulated a great number of studies from diverse fields. The current study was conducted with the purpose of exploring the scientific landscape of the evolving knowledge base related to the use of ChatGPT in the field of education and health through science mapping analysis of published research. Materials/methods – Data were retrieved from Web of Science and Scopus, and a comparative, period-based science mapping analysis was conducted using the SciMAT software. Results – The results showed that the studies published during the first period mostly focused on machine learning, reproductive medicine, education and first-year undergraduate themes. During the second period, though, the studies featured themes that are closely related to the design and performance of ChatGPT such as large language models (LLMs), natural language processing (NLP) and chatbot while abandoning a focus on artificial intelligence. These results imply that discussions and investigations over ChatGPT were being departed from those in the field of artificial intelligence, and the focus was becoming more central to the features of ChatGPT as a language model that can process huge amounts of information to generate human-like texts. Plagiarism and research ethics were also emerging themes during the last period. Conclusion – The results of the science mapping showed a growing interest into the opportunities and risks of ChatGPT, particularly for fields of education and medicine, and indicated that much research is warranted to discover the potential of GPT technology as an uncharted territory. Copyright © 2023 by the author(s).
KW  - artificial intelligence (AI); large language models (LLMs); natural language processing (NLP); chatbot; SciMAT
KW  - ChatGPT
KW  - education
PB  - Universitepark
SN  - 21470901 (ISSN)
LA  - English
J2  - Ed. Process. Int. J.
M3  - Article
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 0; Correspondence Address: M. Demirkol; Vocational High School, Firat University, Elazığ, 23119, Turkey; email: mdemirkol@firat.edu.tr
ER  -

TY  - CONF
AU  - Stefanska, A.
AU  - Stefański, T.P.
AU  - Czubenko, M.
TI  - Evaluation of ChatGPT Applicability to Learning Quantum Physics
PY  - 2023
T2  - 2023 16th International Conference on Signal Processing and Communication System, ICSPCS 2023 - Proceedings
DO  - 10.1109/ICSPCS58109.2023.10261132
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85174517706&doi=10.1109%2fICSPCS58109.2023.10261132&partnerID=40&md5=d62d00df1a0d97ad500272949d8c984f
AD  - Gdansk University of Technology, Faculty of Electronics, Telecommunications and Informatics, Gdansk, Poland
AB  - ChatGPT is an application that uses a large language model. Its purpose is to generate answers to various questions as well as provide information, help solve problems and participate in conversations on a wide range of topics. This application is also widely used by students for the purposes of learning or cheating (e.g., writing essays or programming codes). Therefore, in this contribution, we evaluate the ability of ChatGPT to answer questions in quantum physics. That is, we develop a benchmark consisting of ten questions, whose difficulty is measured on a ten-grade scale. Then ChatGPT answers are evaluated and discussed. In this way, we can measure how well quantum-physics information is processed by this application. Our results demonstrate that ChatGPT does not notice subtle differences between physical terms, and can provide wrong answers to quantum-physics-related questions. It can also provide false mathematical formulas, claim that they are correct and confirm its answers. Note that this AI application is not sure of its answers, and in seven cases it apologizes for the first answer when a user has negated it. To sum up, AI represented by ChatGPT is only able to support students in the process of learning quantum physics at the fundamental level. Moreover, during collective exams in the future, where cheating and the use of AI by students may occur, exam questions should not be descriptive, but should be focused on solving computational problems.  © 2023 IEEE.
KW  - data mining
KW  - large language models
KW  - natural language processing
KW  - quantum physics
KW  - Computational linguistics
KW  - Data mining
KW  - Learning systems
KW  - Natural language processing systems
KW  - AI applications
KW  - Language model
KW  - Language processing
KW  - Large language model
KW  - Mathematical formulas
KW  - Natural language processing
KW  - Natural languages
KW  - Programming codes
KW  - Quantum physics
KW  - Wrong answers
KW  - Students
A2  - Wysocki B.J.
A2  - Wysocki T.A.
PB  - Institute of Electrical and Electronics Engineers Inc.
SN  - 979-835033351-0 (ISBN)
LA  - English
J2  - Int. Conf. Signal Process. Commun. Syst., ICSPCS - Proc.
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 0; Conference name: 16th International Conference on Signal Processing and Communication System, ICSPCS 2023; Conference date: 6 September 2023 through 8 September 2023; Conference code: 193033
ER  -

TY  - CONF
AU  - Zhao, J.
AU  - Fang, M.
AU  - Shi, Z.
AU  - Li, Y.
AU  - Chen, L.
AU  - Pechenizkiy, M.
TI  - CHBias: Bias Evaluation and Mitigation of Chinese Conversational Language Models
PY  - 2023
T2  - Proceedings of the Annual Meeting of the Association for Computational Linguistics
VL  - 1
SP  - 13538
EP  - 13556
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85174392953&partnerID=40&md5=cfa005b5f5bf591346f006afae40a93f
AD  - Eindhoven University of Technology, Eindhoven, Netherlands
AD  - University of Liverpool, Liverpool, United Kingdom
AD  - AAII, University of Technology Sydney, NSW, Australia
AB  - Pretrained conversational agents have been exposed to safety issues, exhibiting a range of stereotypical human biases such as gender bias. However, there are still limited bias categories in current research, and most of them only focus on English. In this paper, we introduce a new Chinese dataset, CHBias, for bias evaluation and mitigation of Chinese conversational language models. Apart from those previous well-explored bias categories, CHBias includes under-explored bias categories, such as ageism and appearance biases, which received less attention. We evaluate two popular pretrained Chinese conversational models, CDial-GPT and EVA2.0, using CHBias. Furthermore, to mitigate different biases, we apply several debiasing methods to the Chinese pretrained models. Experimental results show that these Chinese pretrained models are potentially risky for generating texts that contain social biases, and debiasing methods using the proposed dataset can make response generation less biased while preserving the models' conversational capabilities. © 2023 Association for Computational Linguistics.
KW  - 'current
KW  - Conversational agents
KW  - Conversational model
KW  - De-biasing
KW  - Exposed to
KW  - Gender bias
KW  - Human bias
KW  - Language model
KW  - Response generation
KW  - Safety issues
KW  - Computational linguistics
PB  - Association for Computational Linguistics (ACL)
SN  - 0736587X (ISSN); 978-195942972-2 (ISBN)
LA  - English
J2  - Proc. Annu. Meet. Assoc. Comput Linguist.
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 1; Conference name: 61st Annual Meeting of the Association for Computational Linguistics, ACL 2023; Conference date: 9 July 2023 through 14 July 2023; Conference code: 192160
ER  -

TY  - JOUR
AU  - Fournier, A.
AU  - Fallet, C.
AU  - Sadeghipour, F.
AU  - Perrottet, N.
TI  - Assessing the applicability and appropriateness of ChatGPT in answering clinical pharmacy questions
ST  - Évaluation de l'applicabilité et de la pertinence de ChatGPT dans la réponse aux questions de pharmacie clinique
PY  - 2023
T2  - Annales Pharmaceutiques Francaises
DO  - 10.1016/j.pharma.2023.11.001
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85178579298&doi=10.1016%2fj.pharma.2023.11.001&partnerID=40&md5=5ed6429acb1097f26b2da8a7c71882ba
AD  - Service of Pharmacy, centre hospitalier universitaire Vaudois (CHUV), Lausanne, Switzerland
AD  - School of Pharmaceutical Sciences, University of Geneva, University of Lausanne, Geneva, Switzerland
AD  - Center for Research and Innovation in Clinical Pharmaceutical Sciences, Lausanne University Hospital and University of Lausanne, Lausanne, Switzerland
AB  - Objectives: Clinical pharmacists rely on different scientific references to ensure appropriate, safe, and cost-effective drug use. Tools based on artificial intelligence (AI) such as ChatGPT (Generative Pre-trained Transformer) could offer valuable support. The objective of this study was to assess ChatGPT's capacity to correctly respond to clinical pharmacy questions asked by healthcare professionals in our university hospital. Material and methods: ChatGPT's capacity to respond correctly to the last 100 consecutive questions recorded in our clinical pharmacy database was assessed. Questions were copied from our FileMaker Pro database and pasted into ChatGPT March 14 version online platform. The generated answers were then copied verbatim into an Excel file. Two blinded clinical pharmacists reviewed all the questions and the answers given by the software. In case of disagreements, a third blinded pharmacist intervened to decide. Results: Documentation-related issues (n = 36) and drug administration mode (n = 30) were preponderantly recorded. Among 69 applicable questions, the rate of correct answers varied from 30 to 57.1% depending on questions type with a global rate of 44.9%. Regarding inappropriate answers (n = 38), 20 were incorrect, 18 gave no answers and 8 were incomplete with 8 answers belonging to 2 different categories. No better answers than the pharmacists were observed. Conclusions: ChatGPT demonstrated a mitigated performance in answering clinical pharmacy questions. It should not replace human expertise as a high rate of inappropriate answers was highlighted. Future studies should focus on the optimization of ChatGPT for specific clinical pharmacy questions and explore the potential benefits and limitations of integrating this technology into clinical practice. © 2023 Académie Nationale de Pharmacie
KW  - Artificial intelligence
KW  - ChatGPT
KW  - Clinical pharmacy
KW  - Healthcare professionals’ issues
KW  - Large language models
PB  - Elsevier Masson s.r.l.
SN  - 00034509 (ISSN)
C2  - 37992892
LA  - English
J2  - Ann. Pharm. Fr.
M3  - Article
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 0; Correspondence Address: N. Perrottet; Service of Pharmacy, centre hospitalier universitaire Vaudois (CHUV), Lausanne, Switzerland; email: Nancy.Perrottet@chuv.ch; CODEN: APFRA
ER  -

TY  - JOUR
AU  - Ray, P.P.
TI  - Letter to the editor ‘Evaluating ChatGPT responses in the context of a 53-year-old male with a femoral neck fracture: a qualitative analysis’
PY  - 2023
T2  - European Journal of Orthopaedic Surgery and Traumatology
DO  - 10.1007/s00590-023-03766-w
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85174542901&doi=10.1007%2fs00590-023-03766-w&partnerID=40&md5=122b8376d124ac7eafdc5c0d59e3bd6b
AD  - Department of Computer Applications, Sikkim University, 6th Mile, PO-Tadong, Sikkim, Gangtok, 737102, India
PB  - Springer Nature
SN  - 16338065 (ISSN)
LA  - English
J2  - Eur. J. Orthop. Surg. Traumatol.
M3  - Letter
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 0; Correspondence Address: P.P. Ray; Department of Computer Applications, Sikkim University, Gangtok, 6th Mile, PO-Tadong, Sikkim, 737102, India; email: ppray@cus.ac.in; CODEN: EJOTF
ER  -

TY  - JOUR
AU  - Zhou, W.
AU  - Prater, L.C.
AU  - Goldstein, E.V.
AU  - Mooney, S.J.
TI  - Identifying Rare Circumstances Preceding Female Firearm Suicides: Validating A Large Language Model Approach
PY  - 2023
T2  - JMIR Mental Health
VL  - 10
IS  - 1
C7  - e49359
DO  - 10.2196/49359
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85175970894&doi=10.2196%2f49359&partnerID=40&md5=7130ba02c64521dadbb23065c28ccd6c
AD  - Department of Biomedical Informatics and Medical Education, School of Medicine, University of Washington, Seattle, WA, United States
AD  - Department of Psychiatry and Behavioral Health, University of Washington, Seattle, WA, United States
AD  - Harborview Medical Center, School of Medicine, University of Washington, Seattle, WA, United States
AD  - Department of Population Health Sciences, University of Utah, Salt Lake City, UT, United States
AD  - Department of Epidemiology, School of Public Health, University of Washington, Seattle, WA, United States
AB  - Background: Firearm suicide has been more prevalent among males, but age-adjusted female firearm suicide rates increased by 20% from 2010 to 2020, outpacing the rate increase among males by about 8 percentage points, and female firearm suicide may have different contributing circumstances. In the United States, the National Violent Death Reporting System (NVDRS) is a comprehensive source of data on violent deaths and includes unstructured incident narrative reports from coroners or medical examiners and law enforcement. Conventional natural language processing approaches have been used to identify common circumstances preceding female firearm suicide deaths but failed to identify rarer circumstances due to insufficient training data. Objective: This study aimed to leverage a large language model approach to identify infrequent circumstances preceding female firearm suicide in the unstructured coroners or medical examiners and law enforcement narrative reports available in the NVDRS. Methods: We used the narrative reports of 1462 female firearm suicide decedents in the NVDRS from 2014 to 2018. The reports were written in English. We coded 9 infrequent circumstances preceding female firearm suicides. We experimented with predicting those circumstances by leveraging a large language model approach in a yes/no question-answer format. We measured the prediction accuracy with F1-score (ranging from 0 to 1). F1-score is the harmonic mean of precision (positive predictive value) and recall (true positive rate or sensitivity). Results: Our large language model outperformed a conventional support vector machine–supervised machine learning approach by a wide margin. Compared to the support vector machine model, which had F1-scores less than 0.2 for most infrequent circumstances, our large language model approach achieved an F1-score of over 0.6 for 4 circumstances and 0.8 for 2 circumstances. Conclusions: The use of a large language model approach shows promise. Researchers interested in using natural language processing to identify infrequent circumstances in narrative report data may benefit from large language models. ©Weipeng Zhou, Laura C Prater, Evan V Goldstein, Stephen J Mooney. Originally published in JMIR Mental Health (https://mental.jmir.org), 17.10.2023. This is an open-access article distributed under the terms of the Creative Commons Attribution License (https://creativecommons.org/licenses/by/4.0/), which permits unrestricted use, distribution, and reproduction in any medium, provided the original work, first published in JMIR Mental Health, is properly cited. The complete bibliographic information, a link to the original publication on https://mental.jmir.org/, as well as this copyright and license information must be included.
KW  - depression
KW  - document classification
KW  - female
KW  - female firearm suicide
KW  - firearm suicide
KW  - language models
KW  - large language model
KW  - machine learning
KW  - mental health
KW  - mental health for women
KW  - suicidal
KW  - suicide
KW  - suicide prevention
KW  - violent death
KW  - women
KW  - accuracy
KW  - Article
KW  - coroner
KW  - female
KW  - firearm
KW  - human
KW  - intermethod comparison
KW  - large language model
KW  - law enforcement
KW  - major clinical study
KW  - open source technology
KW  - positivity rate
KW  - predictive value
KW  - suicide
KW  - supervised machine learning
KW  - support vector machine
PB  - JMIR Publications Inc.
SN  - 23687959 (ISSN)
LA  - English
J2  - JMIR Ment. Heal.
M3  - Article
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 0; Correspondence Address: S.J. Mooney; Department of Epidemiology, School of Public Health, University of Washington, Hans Rosling Center for Population Health, Seattle, 3980 15th Ave NE, 98195, United States; email: sjm2186@uw.edu
ER  -

TY  - CONF
AU  - Neves, M.
AU  - Yepes, A.J.
AU  - Névéol, A.
AU  - Bawden, R.
AU  - Di Nunzio, G.M.
AU  - Roller, R.
AU  - Thomas, P.
AU  - Vezzani, F.
AU  - Navarro, M.V.
AU  - Yeganova, L.
AU  - Wiemann, D.
AU  - Grozea, C.
TI  - Findings of the WMT 2023 Biomedical Translation Shared Task: Evaluation of ChatGPT 3.5 as a Comparison System
PY  - 2023
T2  - Conference on Machine Translation -  Proceedings
SP  - 43
EP  - 54
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85179139686&partnerID=40&md5=8eea6a4e56d000c2d3effa72d9737a2f
AD  - German Centre for the Protection of Laboratory Animals (Bf3R), German Federal Institute for Risk Assessment (BfR), Berlin, Germany
AD  - RMIT University, Australia
AD  - Université Paris-Saclay, CNRS, LISN, Orsay, France
AD  - Inria, Paris, France
AD  - Dept. of Linguistic and Literary Studies, University of Padua, Italy
AD  - German Research Center for Artificial Intelligence (DFKI), Berlin, Germany
AD  - Leica Biosystems, Australia
AD  - NCBI/NLM/NIH, Bethesda, United States
AD  - Novartis AG, Basel, Switzerland
AD  - Fraunhofer Institute FOKUS, Berlin, Germany
AD  - Dept. of Information Engineering, University of Padua, Italy
AB  - We present an overview of the Biomedical Translation Task that was part of the Eighth Conference on Machine Translation (WMT23). The aim of the task was the automatic translation of biomedical abstracts from the PubMed database. It included twelve language directions, namely, French, Spanish, Portuguese, Italian, German, and Russian, from and into English. We received submissions from 18 systems and for all the test sets that we released. Our comparison system was based on ChatGPT 3.5 and performed very well in comparison to many of the submissions. © 2023 Association for Computational Linguistics.
KW  - Machine translation
KW  - Automatic translation
KW  - Biomedical abstracts
KW  - Machine translations
KW  - On-machines
KW  - Test sets
KW  - Computational linguistics
PB  - Association for Computational Linguistics
SN  - 27680983 (ISSN); 979-889176041-7 (ISBN)
LA  - English
J2  - Conf. Mach. Transl. Proc.
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 1; Conference name: 8th Conference on Machine Translation, WMT 2023; Conference date: 6 December 2023 through 7 December 2023; Conference code: 194371
ER  -

TY  - JOUR
AU  - Lappin, S.
TI  - Assessing the Strengths and Weaknesses of Large Language Models
PY  - 2023
T2  - Journal of Logic, Language and Information
DO  - 10.1007/s10849-023-09409-x
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85176561685&doi=10.1007%2fs10849-023-09409-x&partnerID=40&md5=aead02a42a30b93b921314e15f6af8d1
AD  - School of Electronic Engineering and Compuer Science, Queen Mary University of London, London, United Kingdom
AD  - Centre for Linguistic Theory and Studies in Probability, University of Gothenburg, Gothenburg, Sweden
AD  - Department of Informatics, King’s College London, London, United Kingdom
AB  - The transformers that drive chatbots and other AI systems constitute large language models (LLMs). These are currently the focus of a lively discussion in both the scientific literature and the popular media. This discussion ranges from hyperbolic claims that attribute general intelligence and sentience to LLMs, to the skeptical view that these devices are no more than “stochastic parrots”. I present an overview of some of the weak arguments that have been presented against LLMs, and I consider several of the more compelling criticisms of these devices. The former significantly underestimate the capacity of transformers to achieve subtle inductive inferences required for high levels of performance on complex, cognitively significant tasks. In some instances, these arguments misconstrue the nature of deep learning. The latter criticisms identify significant limitations in the way in which transformers learn and represent patterns in data. They also point out important differences between the procedures through which deep neural networks and humans acquire knowledge of natural language. It is necessary to look carefully at both sets of arguments in order to achieve a balanced assessment of the potential and the limitations of LLMs. © 2023, The Author(s).
KW  - Artifical intelligence
KW  - Deep learning
KW  - Natural language processing
KW  - Transformers
PB  - Springer Science and Business Media B.V.
SN  - 09258531 (ISSN)
LA  - English
J2  - J. Logic Lang. Inf.
M3  - Article
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 0; Correspondence Address: S. Lappin; Department of Informatics, King’s College London, London, United Kingdom; email: s.lappin@qmul.ac.uk
ER  -

TY  - CONF
AU  - Bimagambetova, Z.
AU  - Rakhymzhanov, D.
AU  - Jaxylykova, A.
AU  - Pak, A.
TI  - Evaluating Large Language Models for Sentence Augmentation in Low-Resource Languages: A Case Study on Kazakh
PY  - 2023
T2  - Proceedings - 2023 19th International Asian School-Seminar on Optimization Problems of Complex Systems, OPCS 2023
SP  - 14
EP  - 18
DO  - 10.1109/OPCS59592.2023.10275753
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85175437915&doi=10.1109%2fOPCS59592.2023.10275753&partnerID=40&md5=6a1c2a1d32f087e7f698e72db9357418
AD  - Kbtu, Almaty, Kazakhstan
AD  - Iict, Almaty, Kazakhstan
AD  - Iict, Kbtu, Almaty, Kazakhstan
AB  - Large language models (LLMs) have revolutionized natural language processing (NLP) and demonstrated exceptional performance in various NLP tasks for widely spoken languages. However, their efficacy in handling low-resource languages remains an area of concern. This study investigates the performance of LLMs, particularly GPT-3, in sentence augmentation tasks for a low-resource language, Kazakh. We employ a blind peer review methodology, where five native Kazakh annotators assess the quality of LLM-generated augmentations. The results reveal that LLMs excel in popular languages like English, Chinese, and German, but face challenges with low-resource languages due to limited training data. This work sheds light on the importance of improving LLMs' adaptability and relevance to address the unique needs of low-resource languages. Further research could enhance the augmentation capabilities of LLMs in scenarios with limited data sources, ensuring their effectiveness in promoting linguistic diversity and inclusivity. Furthermore, this study underscores the significance of cross-language transfer learning and data collection efforts to empower LLMs in supporting linguistic diversity and fostering inclusivity across the global language landscape.  © 2023 IEEE.
KW  - Kazakh language
KW  - Large language models
KW  - low-resource languages
KW  - sentence augmentation
KW  - Computational linguistics
KW  - Case-studies
KW  - Kazakh language
KW  - Language model
KW  - Language processing
KW  - Large language model
KW  - Linguistic diversity
KW  - Low resource languages
KW  - Natural languages
KW  - Performance
KW  - Sentence augmentation
KW  - Natural language processing systems
PB  - Institute of Electrical and Electronics Engineers Inc.
SN  - 979-835033113-4 (ISBN)
LA  - English
J2  - Proc. - Int. Asian Sch.-Semin. Optim. Probl. Complex Syst., OPCS
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 0; Conference name: 19th International Asian School-Seminar on Optimization Problems of Complex Systems, OPCS 2023; Conference date: 14 August 2023 through 22 August 2023; Conference code: 193516
ER  -

TY  - CONF
AU  - Pan, R.
AU  - Alcaraz-Mármol, G.
AU  - García-Sánchez, F.
TI  - UMUTeam at HOPE2023@IberLEF: Evaluation of Transformer Model with Data Augmentation for Multilingual Hope Speech Detection
PY  - 2023
T2  - CEUR Workshop Proceedings
VL  - 3496
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85175296698&partnerID=40&md5=1c6bb666584d23abbe592f4b39841432
AD  - Facultad de Informática, Universidad de Murcia, Campus de Espinardo, 30100, Spain
AD  - Departamento de Filología Moderna, Universidad de Castilla, La Mancha, 45071, Spain
AB  - This paper describes the participation of the UMUTeam in the HOPE shared task organized at IberLEF 2023 within the SEPLN conference. We have addressed the two proposed subtasks. The objective of both subtasks is the detection of hopeful speech texts, but in the first subtask the texts are in Spanish and in the second one in English. The approach presented for both subtasks is based on fine-tuning different pre-trained Large Language Models (LLMs) based on Transformer with data augmentation for the sequence classification task, particularly for hope speech detection. In subtask 1, our team ranked in fifth position out of 11 participants, with a macro f1 score of 71.03, while in subtask 2 we were placed in seventh position out of 9 participants, with a macro f1 score of 48.22. © 2023 Copyright for this paper by its authors. Use permitted under Creative Commons License Attribution 4.0 International (CC BY 4.0).
KW  - Hope speech detection
KW  - Large Language Model
KW  - Natural Language Processing
KW  - Transformers
KW  - Classification (of information)
KW  - Computational linguistics
KW  - Natural language processing systems
KW  - Data augmentation
KW  - Hope speech detection
KW  - Language model
KW  - Language processing
KW  - Large language model
KW  - Natural language processing
KW  - Natural languages
KW  - Speech detection
KW  - Subtask
KW  - Transformer
KW  - Speech recognition
A2  - Montes-y-Gomez M.
A2  - Rangel F.
A2  - Jimenez-Zafra S.M.
A2  - Casavantes M.
A2  - Altuna B.
A2  - Alvarez-Carmona M.A.
A2  - Bel-Enguix G.
A2  - Chiruzzo L.
A2  - de la Iglesia I.
A2  - Escalante H.J.
A2  - Garcia-Cumbreras M.A.
A2  - Garcia-Diaz J.A.
A2  - Barba J.A.G.
A2  - Tamayo R.L.
A2  - Lima S.
A2  - Moral P.
A2  - del Arco F.M.P.
A2  - Valencia-Garcia R.
PB  - CEUR-WS
SN  - 16130073 (ISSN)
LA  - English
J2  - CEUR Workshop Proc.
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 0; Conference name: 2023 Iberian Languages Evaluation Forum, IberLEF 2023; Conference code: 193167
ER  -

TY  - CONF
AU  - Valiyev, G.
AU  - Eles, P.
AU  - Kok, A.
AU  - D'ercole, R.
TI  - Comparison of Transformer Models for Performance on Domain Specific Texts: A Systematic Evaluation of Intrinsic Model Performance
PY  - 2023
T2  - International Conference on Military Communications and Information Systems, ICMCIS 2023
DO  - 10.1109/ICMCIS59922.2023.10253491
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85174290522&doi=10.1109%2fICMCIS59922.2023.10253491&partnerID=40&md5=76cf5ab1454cd1c3e1fc8530cd93be65
AD  - Chief Technology Office
AD  - Operational Analysis Centre, NATO Communications and Information Agency, Den Haag, Netherlands
AB  - This paper presents a systematic evaluation of transformer models for Natural Language Processing (NLP) tasks on domain-specific text. The objective of the study is to understand if intrinsic performance statistics can help deter-mine how suitable a transformer model is for a given target corpus and NLP task, where directly measuring performance is not possible because of lacking labeled data. A number of pre-trained transformer models are considered, including BERT, BART, SciBERT, RoBERTa, and XLNET which are evaluated by measuring the intrinsic performance of such models, by examining the distribution of sentence embedding vectors in the sematic hyperspace, prior to applying any down-stream NLP task. We consider this intrinsic model performance for domain-specific texts (in our case on military do-main texts as well as texts on which the models were originally trained) in the case when that text deviates from the domain on which the model was originally trained. The results of the study provide insights into the characteristics and intrinsic performance of different transformer models on domain-specific text. Our results can be used to inform the selection of a model for downstream NLP tasks given an input dataset. Overall, the study contributes to the understanding of the trade-offs between different transformer models for NLP tasks on domain-specific texts, and how to make informed decisions about which model to use for a specific input dataset. This pa-per was originally presented at the NATO Science and Tech-nology Organization Symposium (ICMCIS) organized by the Information Systems Technology (IST) Panel, IST-200 RSY - the ICMCIS, held in Skopje, North Macedonia, 16-17 May 2023.  © 2023 IEEE.
KW  - BART
KW  - BERT
KW  - Deep Learning
KW  - Evaluation
KW  - NLP
KW  - RoBERTa
KW  - SciBERT
KW  - Transformers
KW  - XLNET
KW  - Deep learning
KW  - Learning algorithms
KW  - Natural language processing systems
KW  - BART
KW  - BERT
KW  - Deep learning
KW  - Evaluation
KW  - Language processing
KW  - Natural language processing
KW  - Natural languages
KW  - RoBERTa
KW  - SciBERT
KW  - Transformer
KW  - XLNET
KW  - Economic and social effects
PB  - Institute of Electrical and Electronics Engineers Inc.
SN  - 979-835034385-4 (ISBN)
LA  - English
J2  - Int. Conf. Mil. Commun. Inf. Syst., ICMCIS
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 0; Conference name: 2023 International Conference on Military Communications and Information Systems, ICMCIS 2023; Conference date: 16 May 2023 through 17 May 2023; Conference code: 192771
ER  -

TY  - CONF
AU  - Cam, N.B.
AU  - Ozgur, A.
TI  - Evaluation of ChatGPT and BERT-based Models for Turkish Hate Speech Detection
PY  - 2023
T2  - UBMK 2023 - Proceedings: 8th International Conference on Computer Science and Engineering
SP  - 229
EP  - 233
DO  - 10.1109/UBMK59864.2023.10286663
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85177606378&doi=10.1109%2fUBMK59864.2023.10286663&partnerID=40&md5=d1e52f8d5636f269585d0d6ce93c43d9
AD  - Bogazici University, Department of Computer Engineering, Istanbul, Turkey
AB  - The popularity of large language models (LLMs) is increasing day by day. ChatGPT is one of the most popular LLMs. It is known for its success in many areas of natural language processing (NLP). Most importantly, we have yet to find zero-shot performance on various NLP tasks for low-level languages such as Turkish. Detection of hate speech is among the most important problems in NLP. With the growing social media usage, the prevalence of hate speech has also increased. However, automatic detection of hate speech in Turkish is rare compared to studies conducted in English. In our work, we analyzed the performance of ChatGPT and various fine-tuned BERT-based transformer models in detecting hate speech in Turkish. We found that ChatGPT provides similar results to the BERT-based models in detecting Turkish hate speech; thus, it is promising. In this study, a dataset consisting of 1000 Turkish tweets labeled 'hate,' 'aggressor,' and 'none' was used. © 2023 IEEE.
KW  - BERT
KW  - ChatGPT
KW  - classification
KW  - hate speech
KW  - transformers
KW  - Turkish
KW  - Speech recognition
KW  - Zero-shot learning
KW  - BERT
KW  - ChatGPT
KW  - Hate speech
KW  - Language model
KW  - Language processing
KW  - Natural languages
KW  - Performance
KW  - Speech detection
KW  - Transformer
KW  - Turkishs
KW  - Natural language processing systems
PB  - Institute of Electrical and Electronics Engineers Inc.
SN  - 979-835034081-5 (ISBN)
LA  - English
J2  - UBMK - Proc.: Int. Conf. Comput. Sci. Eng.
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 0; Conference name: 8th International Conference on Computer Science and Engineering, UBMK 2023; Conference date: 13 September 2023 through 15 September 2023; Conference code: 193873
ER  -

TY  - JOUR
AU  - Wang, X.
AU  - Xu, X.
AU  - Liu, Z.
AU  - Tong, W.
TI  - Bidirectional Encoder Representations from Transformers-like large language models in patient safety and pharmacovigilance: A comprehensive assessment of causal inference implications
PY  - 2023
T2  - Experimental Biology and Medicine
DO  - 10.1177/15353702231215895
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85179325449&doi=10.1177%2f15353702231215895&partnerID=40&md5=5f834bbc477e6e87948ab2ccfa897178
AD  - Department of Information Science, University of Arkansas at Little Rock, Little Rock, 72204, AR, United States
AD  - FDA/National Center for Toxicological Research, Jefferson, 72079, AR, United States
AD  - Nonclinical Drug Safety, Boehringer Ingelheim Pharmaceuticals, Inc., Ridgefield, 06877, CT, United States
AB  - Causality assessment is vital in patient safety and pharmacovigilance (PSPV) for safety signal detection, adverse reaction management, and regulatory submission. Large language models (LLMs), especially those designed with transformer architecture, are revolutionizing various fields, including PSPV. While attempts to utilize Bidirectional Encoder Representations from Transformers (BERT)-like LLMs for causal inference in PSPV are underway, a detailed evaluation of “fit-for-purpose” BERT-like model selection to enhance causal inference performance within PSPV applications remains absent. This study conducts an in-depth exploration of BERT-like LLMs, including generic pre-trained BERT LLMs, domain-specific pre-trained LLMs, and domain-specific pre-trained LLMs with safety knowledge-specific fine-tuning, for causal inference in PSPV. Our investigation centers around (1) the influence of data complexity and model architecture, (2) the correlation between the BERT size and its impact, and (3) the role of domain-specific training and fine-tuning on three publicly accessible PSPV data sets. The findings suggest that (1) BERT-like LLMs deliver consistent predictive power across varied data complexity levels, (2) the predictive performance and causal inference results do not directly correspond to the BERT-like model size, and (3) domain-specific pre-trained LLMs, with or without safety knowledge-specific fine-tuning, surpass generic pre-trained BERT models in causal inference. The findings are valuable to guide the future application of LLMs in a broad range of application. © 2023 by the Society for Experimental Biology and Medicine.
KW  - BERT
KW  - large language models
KW  - patient safety
KW  - Pharmacovigilance
KW  - transformers
KW  - Humans
KW  - Language
KW  - Patient Safety
KW  - Pharmacovigilance
KW  - human
KW  - language
KW  - patient safety
KW  - pharmacovigilance
PB  - SAGE Publications Inc.
SN  - 15353702 (ISSN)
C2  - 38084745
LA  - English
J2  - Exp. Biol. Med.
M3  - Article
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 1; Correspondence Address: W. Tong; FDA/National Center for Toxicological Research, Jefferson, 72079, United States; email: weida.tong@fda.hhs.gov; CODEN: EBMMB
ER  -

TY  - JOUR
AU  - Knebel, D.
AU  - Priglinger, S.
AU  - Scherer, N.
AU  - Klaas, J.
AU  - Siedlecki, J.
AU  - Schworm, B.
TI  - Assessment of ChatGPT in the Prehospital Management of Ophthalmological Emergencies - An Analysis of 10 Fictional Case Vignettes
ST  - ChatGPT in der praklinischen Versorgung augenarztlicher Notfalle eine Untersuchung von 10 fiktiven Fallvignetten
PY  - 2023
T2  - Klinische Monatsblatter fur Augenheilkunde
DO  - 10.1055/a-2149-0447
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85175856916&doi=10.1055%2fa-2149-0447&partnerID=40&md5=ed475dfa6c34676a827f7050a6d064ef
AD  - Department of Ophthalmology, University Hospital, Ludwigs-Maximilians-Universität München, Mathildenstr. 8, München, 80336, Germany
AB  - Background The artificial intelligence (AI)-based platform ChatGPT (Chat Generative Pre-Trained Transformer, OpenAI LP, San Francisco, CA, USA) has gained impressive popularity in recent months. Its performance on case vignettes of general medical (non-ophthalmological) emergencies has been assessed - with very encouraging results. The purpose of this study was to assess the performance of ChatGPT on ophthalmological emergency case vignettes in terms of the main outcome measures triage accuracy, appropriateness of recommended prehospital measures, and overall potential to inflict harm to the user/patient. Methods We wrote ten short, fictional case vignettes describing different acute ophthalmological symptoms. Each vignette was entered into ChatGPT five times with the same wording and following a standardized interaction pathway. The answers were analyzed following a systematic approach. Results We observed a triage accuracy of 93.6%. Most answers contained only appropriate recommendations for prehospital measures. However, an overall potential to inflict harm to users/patients was present in 32% of answers. Conclusion ChatGPT should presently not be used as a stand-alone primary source of information about acute ophthalmological symptoms. As AI continues to evolve, its safety and efficacy in the prehospital management of ophthalmological emergencies has to be reassessed regularly. © 2023 Georg Thieme Verlag. All rights reserved.
KW  - AI
KW  - artificial intelligence
KW  - ChatGPT
KW  - emergencies
KW  - language model
KW  - triage
KW  - adult
KW  - article
KW  - artificial intelligence
KW  - ChatGPT
KW  - drug efficacy
KW  - drug safety
KW  - emergency patient
KW  - human
KW  - information source
KW  - outcome assessment
KW  - patient triage
KW  - vignette
PB  - Georg Thieme Verlag
SN  - 00232165 (ISSN)
C2  - 37890504
LA  - English
J2  - Klin. Monatsbl. Augenheilkd.
M3  - Article
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 1; Correspondence Address: D. Knebel; Department of Ophthalmology, University Hospital, Ludwigs-Maximilians-Universität München, München, Mathildenstr. 8, 80336, Germany; email: dominik.knebel@med.uni-muenchen.de; CODEN: KMAUA
ER  -

TY  - CONF
AU  - Yu, Z.
TI  - A Multi-dimensional Generic Evaluation Framework for the Security of Large Language Models
PY  - 2023
T2  - 2023 4th International Conference on Big Data, Artificial Intelligence and Internet of Things Engineering, ICBAIE 2023
SP  - 410
EP  - 414
DO  - 10.1109/ICBAIE59714.2023.10281279
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85175987528&doi=10.1109%2fICBAIE59714.2023.10281279&partnerID=40&md5=c6e948ecff9497be1bfc70f2be67b91a
AD  - South China University of Technology, School of Future Technology, Guangzhou, China
AB  - In light of the widespread adoption of large language models, their susceptibility to security vulnerabilities cannot be overlooked. As a result, it has become imperative to evaluate their proficiency in addressing issues such as toxicity, bias, and disinformation. However, current research focused on appraising and mitigating security risks has predominantly concentrated on specific facets, leading to disparities in evaluation criteria. In contrast, there has been relatively limited attention given to multidimensional and universal frameworks for security evaluation. In this context, this paper delves into the realm of generic evaluation frameworks for security that offer support for cross-language and multi-category analysis. We underscore the existing challenges associated with prominent large language models concerning security issues and develop a comprehensive test data set to furnish researchers with a tool for quantifying security aspects. Through comprehensive evaluations across three major benchmark tests, we identify distinct strengths and weaknesses exhibited by each open source large language model to varying degrees. By employing a multi-dimensional security evaluation framework, we can attain a more holistic comprehension of the performance exhibited by each model across diverse security dimensions. This approach holds significant value in advancing the domain of security research and facilitating the practical application of language models. © 2023 IEEE.
KW  - benchmark test
KW  - framework
KW  - generic
KW  - large language model
KW  - security evaluation
KW  - Benchmarking
KW  - Statistical tests
KW  - Benchmark tests
KW  - Evaluation framework
KW  - Framework
KW  - Generic
KW  - Generic evaluation
KW  - Language model
KW  - Large language model
KW  - Multi dimensional
KW  - Security evaluation
KW  - Security vulnerabilities
KW  - Computational linguistics
PB  - Institute of Electrical and Electronics Engineers Inc.
SN  - 979-835034361-8 (ISBN)
LA  - English
J2  - Int. Conf. Big Data, Artif. Intell. Internet Things Eng., ICBAIE
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 0; Correspondence Address: Z. Yu; South China University of Technology, School of Future Technology, Guangzhou, China; email: 202164700530@mail.scut.edu.cn; Conference name: 4th International Conference on Big Data, Artificial Intelligence and Internet of Things Engineering, ICBAIE 2023; Conference date: 25 August 2023 through 27 August 2023; Conference code: 193634
ER  -

TY  - CONF
AU  - Papadimitriou, I.
AU  - Lopez, K.
AU  - Jurafsky, D.
TI  - Multilingual BERT has an accent: Evaluating English influences on fluency in multilingual models
PY  - 2023
T2  - SIGTYP 2023 - 5th Workshop on Research in Computational Linguistic Typology and Multilingual NLP, Proceedings of the Workshop
SP  - 143
EP  - 146
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85174677861&partnerID=40&md5=1934bc770e76cd96abf0c47c16a20aac
AD  - Computer Science Department, Stanford University, United States
A2  - Beinborn L.
A2  - Goswami K.
A2  - Muradoglu S.
A2  - Sorokin A.
A2  - Kumar R.
A2  - Shcherbakov A.
A2  - Ponti E.M.
A2  - Cotterell R.
A2  - Vylomova E.
PB  - Association for Computational Linguistics
SN  - 978-195942956-2 (ISBN)
LA  - English
J2  - SIGTYP - Workshop Res. Comput. Linguist. Typology Multiling. NLP, Proc. Workshop
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 0; Conference name: 5th Workshop on Research in Computational Linguistic Typology and Multilingual NLP, SIGTYP 2023, co-located with the 17th Conference of the European Chapter of the Association for Computational Linguistics, EACL 2023; Conference code: 192861
ER  -

TY  - CONF
AU  - Kwako, A.
AU  - Wan, Y.
AU  - Zhao, J.
AU  - Chang, K.-W.
AU  - Cai, L.
AU  - Hansen, M.
TI  - Does BERT Exacerbate Gender or L1 Biases in Automated English Speaking Assessment?
PY  - 2023
T2  - Proceedings of the Annual Meeting of the Association for Computational Linguistics
SP  - 668
EP  - 681
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85174541487&partnerID=40&md5=74c7457e1b0b193f80a9d984e5adcf81
AD  - University of California, Los Angeles, United States
AD  - University of Maryland, College Park, United States
AB  - In English speaking assessment, pretrained large language models (LLMs) such as BERT can score constructed response items as accurately as human raters. Less research has investigated whether LLMs perpetuate or exacerbate biases, which would pose problems for the fairness and validity of the test. This study examines gender and native language (L1) biases in human and automated scores, using an off-the-shelf (OOS) BERT model. Analyses focus on a specific type of bias known as differential item functioning (DIF), which compares examinees of similar English language proficiency. Results show that there is a moderate amount of DIF, based on examinees’ L1 background in grade band 9–12. DIF is higher when scored by an OOS BERT model, indicating that BERT may exacerbate this bias; however, in practical terms, the degree to which BERT exacerbates DIF is very small. Additionally, there is more DIF for longer speaking items and for older examinees, but BERT does not exacerbate these patterns of DIF. © 2023 Association for Computational Linguistics.
KW  - Differential items
KW  - English languages
KW  - Language model
KW  - Language proficiency
KW  - Native language
A2  - Kochmar E.
A2  - Burstein J.
A2  - Horbach A.
A2  - Horbach A.
A2  - Horbach A.
A2  - Laarmann-Quante R.
A2  - Madnani N.
A2  - Tack A.
A2  - Yaneva V.
A2  - Yuan Z.
A2  - Zesch T.
A2  - Zesch T.
PB  - Association for Computational Linguistics (ACL)
SN  - 0736587X (ISSN); 978-195942980-7 (ISBN)
LA  - English
J2  - Proc. Annu. Meet. Assoc. Comput Linguist.
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 0; Conference name: 18th Workshop on Innovative Use of NLP for Building Educational Applications, BEA 2023; Conference code: 193152
ER  -

TY  - CONF
AU  - Turbitt, O.
AU  - Bevan, R.
AU  - Aboshokor, M.
TI  - MDC at BioLaySumm Task 1: Evaluating GPT Models for Biomedical Lay Summarization
PY  - 2023
T2  - Proceedings of the Annual Meeting of the Association for Computational Linguistics
SP  - 611
EP  - 619
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85174484246&partnerID=40&md5=338fba547ef1906baa09e06cd2f5fbdd
AD  - Medicines Discovery Catapult, United Kingdom
AB  - This paper presents our approach to the BioLaySumm Task 1 shared task, held at the BioNLP 2023 Workshop. The effective communication of scientific knowledge to the general public is often limited by the technical language used in research, making it difficult for non-experts to comprehend. To address this issue, lay summaries can be used to explain research findings to non-experts in an accessible form. We conduct an evaluation of autoregressive language models, both general and specialized for the biomedical domain, to generate lay summaries from biomedical research article abstracts. Our findings demonstrate that a GPT-3.5 model combined with a straightforward few-shot prompt produces lay summaries that achieve significantly higher relevance and factuality compared to those generated by a fine-tuned BioGPT model. However, the summaries generated by the BioGPT model exhibit better readability. Notably, our submission for the shared task achieved 1st place in the competition. © 2023 Association for Computational Linguistics.
KW  - Auto-regressive
KW  - Biomedical domain
KW  - Biomedical research
KW  - Effective communication
KW  - General publics
KW  - Language model
KW  - Public IS
KW  - Scientific knowledge
KW  - Technical languages
A2  - Demner-fushman D.
A2  - Ananiadou S.
A2  - Cohen K.
PB  - Association for Computational Linguistics (ACL)
SN  - 0736587X (ISSN); 978-195942985-2 (ISBN)
LA  - English
J2  - Proc. Annu. Meet. Assoc. Comput Linguist.
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 0; Conference name: 22nd Workshop on Biomedical Natural Language Processing and BioNLP Shared Tasks, BioNLP 2023; Conference code: 193153
ER  -

TY  - CONF
AU  - Ganesan, A.V.
AU  - Lal, Y.K.
AU  - Nilsson, A.H.
AU  - Schwartz, H.A.
TI  - Systematic Evaluation of GPT-3 for Zero-Shot Personality Estimation
PY  - 2023
T2  - Proceedings of the Annual Meeting of the Association for Computational Linguistics
SP  - 390
EP  - 400
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85174813390&partnerID=40&md5=1f07795964990dee6d9483262ea3203a
AD  - Stony Brook University, United States
AD  - Oslo Metropolitan University, Norway
AB  - Very large language models (LLMs) perform extremely well on a spectrum of NLP tasks in a zero-shot setting. However, little is known about their performance on human-level NLP problems which rely on understanding psychological concepts, such as assessing personality traits. In this work, we investigate the zero-shot ability of GPT-3 to estimate the Big 5 personality traits from users’ social media posts. Through a set of systematic experiments, we find that zero-shot GPT-3 performance is somewhat close to an existing pre-trained SotA for broad classification upon injecting knowledge about the trait in the prompts. However, when prompted to provide fine-grained classification, its performance drops to close to a simple most frequent class (MFC) baseline. We further analyze where GPT-3 performs better, as well as worse, than a pretrained lexical model, illustrating systematic errors that suggest ways to improve LLMs on human-level NLP tasks. The code for this project is available on Github1 © 2023 Association for Computational Linguistics.
KW  - Classification (of information)
KW  - Computational linguistics
KW  - Natural language processing systems
KW  - Zero-shot learning
KW  - Fine grained
KW  - Human levels
KW  - Language model
KW  - Performance
KW  - Personality traits
KW  - Simple++
KW  - Social media
KW  - Spectra's
KW  - Systematic evaluation
KW  - Systematic experiment
KW  - Systematic errors
A2  - Barnes J.
A2  - De Clercq O.
A2  - Klinger R.
PB  - Association for Computational Linguistics (ACL)
SN  - 0736587X (ISSN); 978-195942987-6 (ISBN)
LA  - English
J2  - Proc. Annu. Meet. Assoc. Comput Linguist.
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 0; Conference name: 13th Workshop on Computational Approaches to Subjectivity, Sentiment and Social Media Analysis, WASSA 2023; Conference code: 193204
ER  -

TY  - JOUR
AU  - Fins, I.S.
AU  - Davies, H.
AU  - Farrell, S.
AU  - Torres, J.R.
AU  - Pinchbeck, G.
AU  - Radford, A.D.
AU  - Noble, P.-J.
TI  - Evaluating ChatGPT text mining of clinical records for companion animal obesity monitoring
PY  - 2023
T2  - Veterinary Record
DO  - 10.1002/vetr.3669
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85178921309&doi=10.1002%2fvetr.3669&partnerID=40&md5=43641ef73ecc7f2b18dd2ce86b6a9cf9
AD  - Small Animal Veterinary Surveillance Network, Institute of Infection, Veterinary and Ecological Sciences, University of Liverpool, Liverpool, United Kingdom
AD  - Department of Computer Science, Durham University, Durham, United Kingdom
AD  - Institute for Animal Health and Food Safety, University of Las Palmas de Gran Canaria, Las Palmas, Gran Canaria, Spain
AB  - Background: Veterinary clinical narratives remain a largely untapped resource for addressing complex diseases. Here we compare the ability of a large language model (ChatGPT) and a previously developed regular expression (RegexT) to identify overweight body condition scores (BCS) in veterinary narratives pertaining to companion animals. Methods: BCS values were extracted from 4415 anonymised clinical narratives using either RegexT or by appending the narrative to a prompt sent to ChatGPT, prompting the model to return the BCS information. Data were manually reviewed for comparison. Results: The precision of RegexT was higher (100%, 95% confidence interval [CI] 94.81%–100%) than that of ChatGPT (89.3%, 95% CI 82.75%–93.64%). However, the recall of ChatGPT (100%, 95% CI 96.18%–100%) was considerably higher than that of RegexT (72.6%, 95% CI 63.92%–79.94%). Limitations: Prior anonymisation and subtle prompt engineering are needed to improve ChatGPT output. Conclusions: Large language models create diverse opportunities and, while complex, present an intuitive interface to information. However, they require careful implementation to avoid unpredictable errors. © 2023 The Authors. Veterinary Record published by John Wiley & Sons Ltd on behalf of British Veterinary Association.
PB  - John Wiley and Sons Inc
SN  - 00424900 (ISSN)
LA  - English
J2  - Vet. Rec.
M3  - Article
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 1; Correspondence Address: P.-J. Noble; Small Animal Veterinary Surveillance Network, Institute of Infection, Veterinary and Ecological Sciences, University of Liverpool, Liverpool, United Kingdom; email: rtnorle@liverpool.ac.uk; CODEN: VETRA
ER  -

TY  - CONF
AU  - Yue, X.
AU  - Wang, B.
AU  - Chen, Z.
AU  - Zhang, K.
AU  - Su, Y.
AU  - Sun, H.
TI  - Automatic Evaluation of Attribution by Large Language Models
PY  - 2023
T2  - Findings of the Association for Computational Linguistics: EMNLP 2023
SP  - 4615
EP  - 4635
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85178880077&partnerID=40&md5=8fb9274b6efd9a0b7bd22aa1e62d35fe
AD  - The Ohio State University, United States
AB  - A recent focus of large language model (LLM) development, as exemplified by generative search engines, is to incorporate external references to generate and support its claims. However, evaluating the attribution, i.e., verifying whether the generated statement is fully supported by the cited reference, remains an open problem. Although human evaluation is common practice, it is costly and time-consuming. In this paper, we investigate automatic evaluation of attribution given by LLMs. We begin by defining different types of attribution errors, and then explore two approaches for automatic evaluation: prompting LLMs and fine-tuning smaller LMs. The fine-tuning data is repurposed from related tasks such as question answering, fact-checking, natural language inference, and summarization. We manually curate a set of test examples covering 12 domains from a generative search engine, New Bing. Our results on this curated test set and simulated examples from existing benchmarks highlight both promising signals and challenges. We hope our problem formulation, testbeds, and findings will help lay the foundation for future studies on this important problem. © 2023 Association for Computational Linguistics.
KW  - Computational linguistics
KW  - Natural language processing systems
KW  - Tuning
KW  - Automatic evaluation
KW  - Fine tuning
KW  - Human evaluation
KW  - Language inference
KW  - Language model
KW  - Model development
KW  - Natural languages
KW  - Question Answering
KW  - Test examples
KW  - Test sets
KW  - Search engines
PB  - Association for Computational Linguistics (ACL)
SN  - 979-889176061-5 (ISBN)
LA  - English
J2  - Find. Assoc. Comput. Linguist.: EMNLP
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 0; Conference name: 2023 Findings of the Association for Computational Linguistics: EMNLP 2023; Conference date: 6 December 2023 through 10 December 2023; Conference code: 196127
ER  -

TY  - CONF
AU  - Manakhimova, S.
AU  - Avramidis, E.
AU  - Macketanz, V.
AU  - Lapshinova-Koltunski, E.
AU  - Bagdasarov, S.
AU  - Möller, S.
TI  - Linguistically Motivated Evaluation of the 2023 State-of-the-art Machine Translation: Can GPT-4 Outperform NMT?
PY  - 2023
T2  - Conference on Machine Translation -  Proceedings
SP  - 224
EP  - 245
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85179127292&partnerID=40&md5=1ccd23c3689c97b1d9bd16b20041b470
AD  - German Research Center for Artificial Intelligence (DFKI), Germany
AD  - University of Hildesheim, Germany
AD  - Saarland University, Germany
AB  - This paper offers a fine-grained analysis of the machine translation outputs in the context of the Shared Task at the 8th Conference of Machine Translation (WMT23). Building on the foundation of previous test suite efforts, our analysis includes Large Language Models and an updated test set featuring new linguistic phenomena. To our knowledge, this is the first fine-grained linguistic analysis for the GPT-4 (5-shot) translation outputs. Our evaluation spans German-English, English-German, and English-Russian language directions. Some of the phenomena with the lowest accuracies for German-English are idioms and resultative predicates. For English-German, these include mediopassive voice, and noun formation(er). As for English-Russian, these included idioms and semantic roles. GPT-4 (5-shot) performs equally or comparably to the best systems in German-English and English-German but falls in the second significance cluster for English-Russian. © 2023 Association for Computational Linguistics.
KW  - Computational linguistics
KW  - Computer aided language translation
KW  - Semantics
KW  - Fine grained
KW  - Fine-grained analysis
KW  - Language model
KW  - Linguistic analysis
KW  - Linguistic phenomena
KW  - Machine translations
KW  - Resultative
KW  - Russian languages
KW  - State of the art
KW  - Test sets
KW  - Machine translation
PB  - Association for Computational Linguistics
SN  - 27680983 (ISSN); 979-889176041-7 (ISBN)
LA  - English
J2  - Conf. Mach. Transl. Proc.
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 1; Conference name: 8th Conference on Machine Translation, WMT 2023; Conference date: 6 December 2023 through 7 December 2023; Conference code: 194371
ER  -

TY  - CONF
AU  - Fantechi, A.
AU  - Gnesi, S.
AU  - Passaro, L.
AU  - Semini, L.
TI  - Inconsistency Detection in Natural Language Requirements using ChatGPT: a Preliminary Evaluation
PY  - 2023
T2  - Proceedings of the IEEE International Conference on Requirements Engineering
VL  - 2023-September
SP  - 335
EP  - 340
DO  - 10.1109/RE57278.2023.00045
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85174384397&doi=10.1109%2fRE57278.2023.00045&partnerID=40&md5=b8959a0ae02bbd555cdc01b46b60a647
AD  - Universitá di Firenze, Dipartimento di Ingegneria Dell'Informazione, Firenze, Italy
AD  - Istituto di Scienza e Tecnologie Dell'Informazione 'A.Faedo', Consiglio Nazionale Delle Ricerche, ISTI-CNR, Pisa, Italy
AD  - Universitá di Pisa, Dipartimento di Informatica, Pisa, Italy
AB  - With the rapid advancement of tools based on Artificial Intelligence, it is interesting to assess their usefulness in requirements engineering. In early experiments, we have seen that ChatGPT can detect inconsistency defects in natural language (NL) requirements, that traditional NLP tools cannot identify or can identify with difficulties even after domain-focused training. This study is devoted to specifically measuring the performance of ChatGPT in finding inconsistency in requirements. Positive results in this respect could lead to the use of ChatGPT to complement existing requirements analysis tools to automatically detect this important quality criterion. For this purpose, we consider GPT-3.5, the Generative Pretrained Transformer language model developed by OpenAI. We evaluate its ability to detect inconsistency by comparing its predictions with those obtained from expert judgments by students with a proven knowledge of RE issues on a few example requirements documents.  © 2023 IEEE.
KW  - ChatGPT
KW  - Inconsistency Detection
KW  - Natural Language Requirements
KW  - Natural language processing systems
KW  - Quality control
KW  - ChatGPT
KW  - Expert judgment
KW  - Inconsistency detection
KW  - Language model
KW  - Natural language requirements
KW  - NLP tools
KW  - Performance
KW  - Quality criteria
KW  - Requirement engineering
KW  - Requirements analysis tools
KW  - Requirements engineering
A2  - Schneider K.
A2  - Dalpiaz F.
A2  - Horkoff J.
PB  - IEEE Computer Society
SN  - 1090705X (ISSN); 979-835032689-5 (ISBN)
LA  - English
J2  - Proc. Int. Conf. Requir. Eng.
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 0; Conference name: 31st IEEE International Requirements Engineering Conference, RE 2023; Conference date: 4 September 2023 through 8 September 2023; Conference code: 193106
ER  -

TY  - CONF
AU  - Lukens, S.
AU  - Ali, A.
TI  - Evaluating the Performance of ChatGPT in the Automation of Maintenance Recommendations for Prognostics and Health Management
PY  - 2023
T2  - Proceedings of the Annual Conference of the Prognostics and Health Management Society, PHM
VL  - 15
IS  - 1
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85178387478&partnerID=40&md5=be549fa3ad918be87f801d353d413e11
AD  - LMI, Tysons, 22102, VA, United States
AD  - GE Vernova, Chicago, 60661, IL, United States
AB  - Until now, automation of maintenance recommendations for Prognostics and Health Management (PHM) has been a domain-specific technical language processing (TLP) task applied to historical case data. ChatGPT, Bard, GPT-4 and Sydney are a few examples of generative large language models (LLMs) that have received significant media attention for their proficiency in natural language tasks across a variety of domains. Preliminary exploration of ChatGPT as a tool for generating maintenance recommendations has shown promise in its ability to generate and explain engineering concepts and procedures, but the precise scope of its capabilities and limitations remains uncertain. Currently we know of no performance criteria related to formally measuring how well ChatGPT performs as a tool for industrial use cases. In this paper, we propose a methodology for the evaluation of the performance of LLMs such as ChatGPT for the task of automation of maintenance recommendations. Our methodology identifies various performance criteria relevant for PHM such as engineering criteria, risk elements, human factors, cost considerations and corrections. We examine how well ChatGPT performs when tasked with generating recommendations from PHM model alerts and report our findings. We discuss the various strengths and limitations to consider in the adoption of LLM's as a computational support tool for prescriptive PHM as well as the different risks and business case considerations. © 2023 Prognostics and Health Management Society. All rights reserved.
KW  - Automation
KW  - Cost engineering
KW  - Natural language processing systems
KW  - Domain specific
KW  - Generating maintenances
KW  - Language model
KW  - Language processing
KW  - Media attention
KW  - Natural languages
KW  - Performance
KW  - Performance criterion
KW  - Prognostic and health management
KW  - Technical languages
KW  - Maintenance
A2  - Kulkarni C.S.
A2  - Roychoudhury I.
PB  - Prognostics and Health Management Society
SN  - 23250178 (ISSN); 978-193626305-9 (ISBN)
LA  - English
J2  - Proc. Annu. Conf. Progn. Health Manag. Soc., PHM
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 0; Conference name: 15th Annual Conference of the Prognostics and Health Management Society, PHM 2023; Conference date: 28 October 2023 through 2 November 2023; Conference code: 193851
ER  -

TY  - CONF
AU  - Garcia, G.G.
AU  - Weilbach, C.
TI  - If the Sources Could Talk: Evaluating Large Language Models for Research Assistance in History
PY  - 2023
T2  - CEUR Workshop Proceedings
VL  - 3558
SP  - 616
EP  - 638
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85178664654&partnerID=40&md5=e090420bcd576d88c738d9e0710bf6b6
AD  - Department of History, School of Irish Studies, Concordia University, Montreal, Canada
AD  - Department of Computer Science, University of British Columbia, Vancouver, Canada
AB  - The recent advent of powerful Large-Language Models (LLM) provides a new conversational form of inquiry into historical memory (or, training data, in this case). We show that by augmenting such LLMs with vector embeddings from highly specialized academic sources, a conversational methodology can be made accessible to historians and other researchers in the Humanities. Concretely, we evaluate and demonstrate how LLMs have the ability of assisting researchers while they examine a customized corpora of different types of documents, including, but not exclusive to: (1). primary sources, (2). secondary sources written by experts, and (3). the combination of these two. Compared to established search interfaces for digital catalogues, such as metadata and full-text search, we evaluate the richer conversational style of LLMs on the performance of two main types of tasks: (1). question-answering, and (2). extraction and organization of data. We demonstrate that LLMs semantic retrieval and reasoning abilities on problem-specific tasks can be applied to large textual archives that have not been part of the its training data. Therefore, LLMs can be augmented with sources relevant to specific research projects, and can be queried privately by researchers. © 2023 Copyright for this paper by its authors.
KW  - Artificial Intelligence (AI)
KW  - GPT
KW  - Historical Research Methods
KW  - Historical Writing
KW  - Large Language Models (LLMs)
KW  - Machine Learning
KW  - Computational linguistics
KW  - History
KW  - Semantics
KW  - Artificial intelligence
KW  - GPT
KW  - Historical research
KW  - Historical research method
KW  - Historical writing
KW  - Language model
KW  - Large language model
KW  - Machine-learning
KW  - Research method
KW  - Training data
KW  - Machine learning
A2  - Sela A.
A2  - Jannidis F.
A2  - Romanowska I.
PB  - CEUR-WS
SN  - 16130073 (ISSN)
LA  - English
J2  - CEUR Workshop Proc.
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 0; Correspondence Address: G.G. Garcia; Department of History, School of Irish Studies, Concordia University, Montreal, Canada; email: giselle.gonzalezgarcia@mail.concordia.ca; Conference name: 2023 Computational Humanities Research Conference, CHR 2023; Conference date: 6 December 2023 through 8 December 2023; Conference code: 194581
ER  -

TY  - JOUR
AU  - Tong, W.
AU  - Guan, Y.
AU  - Chen, J.
AU  - Huang, X.
AU  - Zhong, Y.
AU  - Zhang, C.
AU  - Zhang, H.
TI  - Artificial intelligence in global health equity: an evaluation and discussion on the application of ChatGPT, in the Chinese National Medical Licensing Examination
PY  - 2023
T2  - Frontiers in Medicine
VL  - 10
C7  - 1237432
DO  - 10.3389/fmed.2023.1237432
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85175690719&doi=10.3389%2ffmed.2023.1237432&partnerID=40&md5=ef2e18a46c8189fe33d607e6d1e8e877
AD  - Department of Pharmacy, Gannan Health Vocational College, Jiangxi, Ganzhou, China
AD  - Department of Rehabilitation and Elderly Care, Gannan Health Vocational College, Jiangxi, Ganzhou, China
AD  - Department of Mathematics, Xiamen University, Fujian, Xiamen, China
AD  - Department of Anesthesiology, Gannan Medical University, Jiangxi, China
AD  - Department of Chinese Medicine, Affiliated Hospital of Qinghai University, Qinghai, Xining, China
AD  - Chair of Endocrinology and Medical Sexology (ENDOSEX), Department of Experimental Medicine, University of Rome Tor Vergata, Rome, Italy
AB  - Background: The demand for healthcare is increasing globally, with notable disparities in access to resources, especially in Asia, Africa, and Latin America. The rapid development of Artificial Intelligence (AI) technologies, such as OpenAI’s ChatGPT, has shown promise in revolutionizing healthcare. However, potential challenges, including the need for specialized medical training, privacy concerns, and language bias, require attention. Methods: To assess the applicability and limitations of ChatGPT in Chinese and English settings, we designed an experiment evaluating its performance in the 2022 National Medical Licensing Examination (NMLE) in China. For a standardized evaluation, we used the comprehensive written part of the NMLE, translated into English by a bilingual expert. All questions were input into ChatGPT, which provided answers and reasons for choosing them. Responses were evaluated for “information quality” using the Likert scale. Results: ChatGPT demonstrated a correct response rate of 81.25% for Chinese and 86.25% for English questions. Logistic regression analysis showed that neither the difficulty nor the subject matter of the questions was a significant factor in AI errors. The Brier Scores, indicating predictive accuracy, were 0.19 for Chinese and 0.14 for English, indicating good predictive performance. The average quality score for English responses was excellent (4.43 point), slightly higher than for Chinese (4.34 point). Conclusion: While AI language models like ChatGPT show promise for global healthcare, language bias is a key challenge. Ensuring that such technologies are robustly trained and sensitive to multiple languages and cultures is vital. Further research into AI’s role in healthcare, particularly in areas with limited resources, is warranted. Copyright © 2023 Tong, Guan, Chen, Huang, Zhong, Zhang and Zhang.
KW  - artificial intelligence
KW  - ChatGPT
KW  - equity
KW  - global healthcare
KW  - language bias
KW  - article
KW  - artificial intelligence
KW  - ChatGPT
KW  - China
KW  - controlled study
KW  - data quality
KW  - global health
KW  - human
KW  - human experiment
KW  - language model
KW  - licensing
KW  - Likert scale
KW  - medical education
PB  - Frontiers Media SA
SN  - 2296858X (ISSN)
LA  - English
J2  - Front. Med.
M3  - Article
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 0; Correspondence Address: H. Zhang; Department of Rehabilitation and Elderly Care, Gannan Health Vocational College, Ganzhou, Jiangxi, China; email: Huizhang@outlook.fr
ER  -

TY  - JOUR
AU  - Suárez, A.
AU  - Díaz-Flores García, V.
AU  - Algar, J.
AU  - Sánchez, M.G.
AU  - de Pedro, M.L.
AU  - Freire, Y.
TI  - Unveiling the ChatGPT phenomenon: Evaluating the consistency and accuracy of endodontic question answers
PY  - 2023
T2  - International Endodontic Journal
DO  - 10.1111/iej.13998
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85176125904&doi=10.1111%2fiej.13998&partnerID=40&md5=4ff17818a9fb7ad0e5f9f837feb66b5d
AD  - Department of Pre-Clinic Dentistry, School of Biomedical Sciences, Universidad Europea de Madrid, Madrid, Spain
AD  - Department of Clinical Dentistry, School of Biomedical Sciences, Universidad Europea de Madrid, Madrid, Spain
PB  - John Wiley and Sons Inc
SN  - 01432885 (ISSN)
LA  - English
J2  - Int. Endod. J.
M3  - Note
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 3; Correspondence Address: V. Díaz-Flores García; Department of Pre-Clinic Dentistry, School of Biomedical Sciences, Universidad Europea de Madrid, Villaviciosa de Odón, Calle Tajo s/n, Madrid, 28670, Spain; email: victor.diaz-flores@universidadeuropea.es; CODEN: IENJE
ER  -

TY  - CONF
AU  - Tekumalla, R.
AU  - Banda, J.M.
TI  - Leveraging Large Language Models and Weak Supervision for Social Media Data Annotation: An Evaluation Using COVID-19 Self-reported Vaccination Tweets
PY  - 2023
T2  - Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)
VL  - 14056 LNCS
SP  - 356
EP  - 366
DO  - 10.1007/978-3-031-48044-7_26
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85178515081&doi=10.1007%2f978-3-031-48044-7_26&partnerID=40&md5=fe86fbdc18ec4181febdc07a830cf313
AD  - Georgia State University, Atlanta, 30328, GA, United States
AB  - The COVID-19 pandemic has presented significant challenges to the healthcare industry and society as a whole. With the rapid development of COVID-19 vaccines, social media platforms have become a popular medium for discussions on vaccine-related topics. Identifying vaccine-related tweets and analyzing them can provide valuable insights for public health researchers and policymakers. However, manual annotation of a large number of tweets is time-consuming and expensive. In this study, we evaluate the usage of Large Language Models, in this case GPT-4 (March 23 version), and weak supervision, to identify COVID-19 vaccine-related tweets, with the purpose of comparing performance against human annotators. We leveraged a manually curated gold-standard dataset and used GPT-4 to provide labels without any additional fine-tuning or instructing, in a single-shot mode (no additional prompting). © 2023, The Author(s), under exclusive license to Springer Nature Switzerland AG.
KW  - GPT
KW  - Large language models
KW  - social media data
KW  - weak supervision
KW  - Computational linguistics
KW  - COVID-19
KW  - Social networking (online)
KW  - Data annotation
KW  - GPT
KW  - Healthcare industry
KW  - Language model
KW  - Large language model
KW  - Manual annotation
KW  - Policy makers
KW  - Social media datum
KW  - Social media platforms
KW  - Weak supervision
KW  - Vaccines
A2  - Mori H.
A2  - Asahi Y.
A2  - Coman A.
A2  - Vasilache S.
A2  - Rauterberg M.
PB  - Springer Science and Business Media Deutschland GmbH
SN  - 03029743 (ISSN); 978-303148043-0 (ISBN)
LA  - English
J2  - Lect. Notes Comput. Sci.
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 0; Correspondence Address: J.M. Banda; Georgia State University, Atlanta, 30328, United States; email: jbanda@gsu.edu; Conference name: 25th International Conference on Human-Computer Interaction, HCII 2023; Conference date: 23 July 2023 through 28 July 2023; Conference code: 297769
ER  -

TY  - CONF
AU  - Wang, K.
AU  - Zhang, J.
TI  - Spatio-Temporal Transformer Model for Skeleton-based Rehabilitation Exercises Assessment
PY  - 2023
T2  - 2023 4th International Conference on Big Data and Artificial Intelligence and Software Engineering, ICBASE 2023
SP  - 188
EP  - 192
DO  - 10.1109/ICBASE59196.2023.10303196
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85178506499&doi=10.1109%2fICBASE59196.2023.10303196&partnerID=40&md5=2f75e3507fa37bbd769bc168124875b3
AD  - Anhui University, School of Electrical Engineering and Automation, Hefei, China
AB  - Physical rehabilitation training is a critical process that enables patients with chronic illnesses and elderly individuals to recover their limb and motor function over time. Without proper guidance and feedback, patients may abandon their treatment due to the risk of secondary injury. Automated assessment of movement quality, employing skeletal movement data obtained from depth imaging devices, has the potential to enhance home-based rehabilitation by offering crucial quantitative feedback. Inspired by the success of transformer-based models with self-attention mechanisms in natural language processing and computer vision domains, we propose a transformer-based network for assessing movement quality, aiming to address the challenges associated with movement assessment in rehabilitation. Furthermore, our proposed model has been augmented with self-attention and channel attention mechanisms, enabling the transformer network to selectively attend to specific anatomical regions that play a crucial role in motion execution. Compared with traditional convolutional neural networks and long short-term memory, the proposed models obtain the best accuracy on two open-access datasets. And our contactless method also provides a new potential tool for automated movement assessment and telemedicine. © 2023 IEEE.
KW  - Automate Assessment
KW  - Channel Attention
KW  - computer vision
KW  - Physical Rehabilitation
KW  - Self-attention
KW  - Telemedicine
KW  - Transformer
KW  - Convolutional neural networks
KW  - Natural language processing systems
KW  - Patient rehabilitation
KW  - Patient treatment
KW  - Telemedicine
KW  - Attention mechanisms
KW  - Automate assessment
KW  - Channel attention
KW  - Physical rehabilitation
KW  - Rehabilitation exercise
KW  - Rehabilitation training
KW  - Self-attention
KW  - Spatio-temporal
KW  - Transformer
KW  - Transformer modeling
KW  - Computer vision
PB  - Institute of Electrical and Electronics Engineers Inc.
SN  - 979-835032949-0 (ISBN)
LA  - English
J2  - Int. Conf. Big Data Artif. Intell. Softw. Eng., ICBASE
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 0; Correspondence Address: J. Zhang; Anhui University, School of Electrical Engineering and Automation, Hefei, China; email: junzhang@ahu.edu.cn; Conference name: 4th International Conference on Big Data and Artificial Intelligence and Software Engineering, ICBASE 2023; Conference date: 25 August 2023 through 27 August 2023; Conference code: 194263
ER  -

TY  - JOUR
AU  - Fu, X.
AU  - Wang, R.
AU  - Li, C.
TI  - Can ChatGPT Evaluate Plans?
PY  - 2023
T2  - Journal of the American Planning Association
DO  - 10.1080/01944363.2023.2271893
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85177037057&doi=10.1080%2f01944363.2023.2271893&partnerID=40&md5=8d4f36eb352e2b2c6aaa29a02f73c512
AD  - University of Waikato, New Zealand
AD  - Runstad Department of Real Estate in the College of Built Environments at the University of Washington, United States
AD  - Urban Governance and Design Thrust of the Hong Kong University of Science and Technology (Guangzhou), Hong Kong
AB  - Problem, research strategy, and findings: Large language models, such as ChatGPT, have recently risen to prominence in producing human-like conversation and assisting with various tasks, particularly for analyzing high-dimensional textual materials. Because planning researchers and practitioners often need to evaluate planning documents that are long and complex, a first-ever possible question has emerged: Can ChatGPT evaluate plans? In this study we addressed this question by leveraging ChatGPT to evaluate the quality of plans and compare the results with those conducted by human coders. Through the evaluation of 10 climate change plans, we discovered that ChatGPT’s evaluation results coincided reasonably well (with an average of 68%) with those from the traditional content analysis approach. We further scrutinized the differences by conducting a more in-depth analysis of the results from ChatGPT and manual evaluation to uncover what might have contributed to the variance in results. Our findings indicate that ChatGPT struggled to comprehend planning-specific jargon, yet it could reduce human errors by capturing details in complex planning documents. Finally, we provide insights into leveraging this cutting-edge technology in future planning research and practice. Takeaway for practice: ChatGPT cannot be used to replace humans in plan quality evaluation yet. However, it is an effective tool to complement human coders to minimize human errors by identifying discrepancies and fact-checking machine-generated responses. ChatGPT generally cannot understand planning jargon, so planners wanting to use this tool should use extra caution when planning terminologies are present in their prompts. Creating effective prompts for ChatGPT is an iterative process that requires specific instructions. © 2023 The Hong Kong University of Science and Technology (Guangzhou). Published with license by Taylor & Francis Group, LLC.
KW  - ChatGPT
KW  - large language model
KW  - natural language processing
KW  - plan evaluation
KW  - plan quality
PB  - Routledge
SN  - 01944363 (ISSN)
LA  - English
J2  - J. Am. Plann. Assoc.
M3  - Article
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 0
ER  -

TY  - CONF
AU  - Everman, B.
AU  - Villwock, T.
AU  - Chen, D.
AU  - Soto, N.
AU  - Zhang, O.
AU  - Zong, Z.
TI  - Evaluating the Carbon Impact of Large Language Models at the Inference Stage
PY  - 2023
T2  - Conference Proceedings of the IEEE International Performance, Computing, and Communications Conference
SP  - 150
EP  - 157
DO  - 10.1109/IPCCC59175.2023.10253886
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85177767470&doi=10.1109%2fIPCCC59175.2023.10253886&partnerID=40&md5=38de71de744b5a557a56f0721fe37ed3
AB  - Large Language Models (LLMs), such as GPT-3, ChatGPT, and GPT-4, have demonstrated enormous potential across a range of tasks and attracted over 100 million users globally in recent months. However, these LLMs are resource-intensive and contribute significantly to carbon emissions. Currently, our understanding of their carbon impact remains insufficient due to the lack of reliable measurement tools, standard methodologies, and evaluation metrics. To bridge this gap, this paper conducts a thorough study on the carbon impact of various open-source LLMs, including GPT-J 6B, GPT Neo 2.7B, GPT-NEO 1.3B, and GPT-2 at the inference stage, utilizing the Software Carbon Intensity (SCI) specification released by the Green Software Foundation. The primary contributions of our research are: (1) We propose a quantitative framework that measures and contrasts the environmental impacts of different LLMs; (2) We illustrate that high-carbon LLMs do not necessarily provide superior model quality than their low-carbon counterparts; and (3) We find that the carbon emissions are primarily driven by embodied carbon in LLMs and that employing GPUs, as opposed to CPUs, can substantially reduce carbon emissions. © 2023 IEEE.
KW  - Carbon Footprint
KW  - Energy Efficiency
KW  - GPT
KW  - Large Language Models
KW  - Software Carbon Intensity
KW  - Computational linguistics
KW  - Energy efficiency
KW  - Environmental impact
KW  - Open source software
KW  - Open systems
KW  - Program processors
KW  - Carbon emissions
KW  - Carbon intensity
KW  - Evaluation metrics
KW  - GPT
KW  - Inference stages
KW  - Language model
KW  - Large language model
KW  - Measurement tools
KW  - Reliable measurement
KW  - Software carbon intensity
KW  - Carbon footprint
PB  - Institute of Electrical and Electronics Engineers Inc.
SN  - 10972641 (ISSN); 979-835030294-3 (ISBN)
LA  - English
J2  - Conf. Proc. IEEE Int. Perform. Comput. Commun. Conf.
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 0; Conference name: 2023 IEEE International Performance, Computing, and Communications Conference, IPCCC 2023; Conference date: 17 November 2023 through 19 November 2023; Conference code: 196410
ER  -

TY  - CONF
AU  - Wu, N.
AU  - Gong, M.
AU  - Shou, L.
AU  - Liang, S.
AU  - Jiang, D.
TI  - Large Language Models are Diverse Role-Players for Summarization Evaluation
PY  - 2023
T2  - Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)
VL  - 14302 LNAI
SP  - 695
EP  - 707
DO  - 10.1007/978-3-031-44693-1_54
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85174694770&doi=10.1007%2f978-3-031-44693-1_54&partnerID=40&md5=f3a651dc18d15e76fcce63afd1aa1a7f
AD  - STCA Search and Distribution Group, Microsoft, Beijing, China
AB  - Text summarization has a wide range of applications in many scenarios. The evaluation of the quality of the generated text is a complex problem. A big challenge to language evaluation is that there is a clear divergence between existing metrics and human evaluation. A document summary’s quality can be assessed by human annotators on various criteria, both objective ones like grammar and correctness, and subjective ones like informativeness, succinctness, and appeal. Most of the automatic evaluation methods like BLUE/ROUGE may be not able to adequately capture the above dimensions. In this paper, we propose a new evaluation framework based on LLMs, which provides a comprehensive evaluation framework by comparing generated text and reference text from both objective and subjective aspects. First, we propose to model objective and subjective dimensions of generated text based on roleplayers prompting mechanism. Furthermore, we introduce a context-based prompting mechanism that is able to generate dynamic roleplayer profiles based on input context. Finally, we design a multi-roleplayer prompting technology based on batch prompting and integrate multiple outputs into the final evaluation results. Experimental results on three real datasets for summarization show that our model is highly competitive and has a very high consistency with human annotators. © 2023, The Author(s), under exclusive license to Springer Nature Switzerland AG.
KW  - Large Language Model
KW  - Role Player
KW  - Summarization Evaluation
KW  - Computational linguistics
KW  - Complex problems
KW  - Evaluation framework
KW  - Human evaluation
KW  - Language evaluations
KW  - Language model
KW  - Large language model
KW  - Metric evaluation
KW  - Role player
KW  - Summarization evaluation
KW  - Text Summarisation
KW  - Quality control
A2  - Liu F.
A2  - Duan N.
A2  - Xu Q.
A2  - Hong Y.
PB  - Springer Science and Business Media Deutschland GmbH
SN  - 03029743 (ISSN); 978-303144692-4 (ISBN)
LA  - English
J2  - Lect. Notes Comput. Sci.
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 1; Correspondence Address: D. Jiang; STCA Search and Distribution Group, Microsoft, Beijing, China; email: djiang@microsoft.com; Conference name: 12th National CCF Conference on Natural Language Processing and Chinese Computing, NLPCC 2023; Conference date: 12 October 2023 through 15 October 2023; Conference code: 302309
ER  -

TY  - CONF
AU  - Wuisang, M.C.
AU  - Kurniawan, M.
AU  - Wira Santosa, K.A.
AU  - Agung Santoso Gunawan, A.
AU  - Saputra, K.E.
TI  - An Evaluation of the Effectiveness of OpenAI's ChatGPT for Automated Python Program Bug Fixing using QuixBugs
PY  - 2023
T2  - 2023 International Seminar on Application for Technology of Information and Communication: Smart Technology Based on Industry 4.0: A New Way of Recovery from Global Pandemic and Global Economic Crisis, iSemantic 2023
SP  - 295
EP  - 300
DO  - 10.1109/iSemantic59612.2023.10295323
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85178001170&doi=10.1109%2fiSemantic59612.2023.10295323&partnerID=40&md5=4691538104e42b2fe1897c5151e56596
AD  - Bina Nusantara University, School of Computer Science, Computer Science Department, Jakarta, 11480, Indonesia
AB  - In recent years, the use of Artificial Intelligence (AI) has become increasingly common in various fields, including in software development. One such field is where AI can automatically detect and fix bugs in code. GPT-3.5 is a state-of-the-art language model developed by OpenAI that has been trained on a massive amount of text data to generate natural language responses to a wide range of prompts. One of the main challenges in software development is bug fixing, which can be a time-consuming and complicated process. QuixBugs is a framework for evaluating automatic program repair techniques, which can be used to test the effectiveness of GPT-3.5 and similar bug-fixing tools. This paper evaluates the effectiveness of GPT-3.5 in automatically fixing bugs in Python code using QuixBugs. Through testing with 40 different Python bugs, We discovered that GPT-3.5 was able to accurately fix 30 out of 40 bugs cases from QuixBugs benchmark. Compared with other tools like standard program repair and Codex, ChatGPT outperformed them significantly. These findings highlight the potential of ChatGPT as a powerful tool for enhancing code quality and reducing the burden of manual bug fixing.  © 2023 IEEE.
KW  - APR
KW  - Automatic program repair
KW  - Bug fixing
KW  - ChatGPT
KW  - GPT-3.5
KW  - Python
KW  - QuixBug
KW  - High level languages
KW  - Program debugging
KW  - Repair
KW  - Software design
KW  - Software testing
KW  - APR
KW  - Automatic program repair
KW  - Automatic programs
KW  - Bug-fixing
KW  - ChatGPT
KW  - GPT-3.5
KW  - Language model
KW  - Program bugs
KW  - Quixbug
KW  - State of the art
KW  - Python
PB  - Institute of Electrical and Electronics Engineers Inc.
SN  - 979-835033921-5 (ISBN)
LA  - English
J2  - Int. Semin. Appl. Technol. Inf. Commun.: Smart Technol. Based Ind. 4.0: A New Way Recovery Glob. Pandemic Glob. Econ. Crisis, iSemantic
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 0; Correspondence Address: M.C. Wuisang; Bina Nusantara University, School of Computer Science, Computer Science Department, Jakarta, 11480, Indonesia; email: marchel.wuisang@binus.ac.id; Conference name: 2023 International Seminar on Application for Technology of Information and Communication, iSemantic 2023; Conference date: 16 September 2023 through 17 September 2023; Conference code: 194127
ER  -

TY  - CONF
AU  - Gursesli, M.C.
AU  - Taveekitworachai, P.
AU  - Abdullah, F.
AU  - Dewantoro, M.F.
AU  - Lanata, A.
AU  - Guazzini, A.
AU  - Lê, V.K.
AU  - Villars, A.
AU  - Thawonmas, R.
TI  - The Chronicles of ChatGPT: Generating and Evaluating Visual Novel Narratives on Climate Change Through ChatGPT
PY  - 2023
T2  - Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)
VL  - 14384 LNCS
SP  - 181
EP  - 194
DO  - 10.1007/978-3-031-47658-7_16
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85177457396&doi=10.1007%2f978-3-031-47658-7_16&partnerID=40&md5=1c51852e1ddd19a9a0e7b2f6d71559eb
AD  - Department of Information Engineering, Università degli Studi di Firenze, Florence, Italy
AD  - Graduate School of Information Science and Engineering, Ritsumeikan University, Shiga, Kusatsu, Japan
AD  - Department of Education, Literatures, Intercultural Studies, Languages and Psychology, Università degli Studi di Firenze, Florence, Italy
AD  - Graduate School of Engineering, ENSEIRB-MATMECA, Talence, France
AD  - College of Information Science and Engineering, Ritsumeikan University, Shiga, Kusatsu, Japan
AB  - This paper explores the potential of utilizing ChatGPT, a large language model (LLM), for generating and evaluating visual novel (VN) game stories in the context of global warming awareness through a VN game. The study involves generating two stories using ChatGPT, one with given global warming related keywords as an inspiration for ChatGPT along with a specified ending and another without, and evaluating them based on several linguistic criteria: coherence, inspiration, readability, word complexity, and narrative fluency. Results reveal that keywords-inspired story exhibit higher coherence, while the basic one demonstrate greater inspiration. The findings highlight the advantages of each story and emphasize the value of AI-driven narrative generation in creating engaging and informative experiences. Furthermore, the study introduces an innovative approach by employing ChatGPT as an evaluator for the story quality, by combining various prompt engineering techniques showcasing the diverse applications of LLMs in interactive storytelling. This work contributes to the growing field of LLM-based story generation and underscores the potential of AI-driven narratives in fostering awareness and engagement on critical issues like climate change. © The Author(s), under exclusive license to Springer Nature Switzerland AG 2023.
KW  - ChatGPT
KW  - climate change
KW  - Global warming
KW  - narrative generation
KW  - visual novel
KW  - Visual languages
KW  - ChatGPT
KW  - Diverse applications
KW  - Engineering techniques
KW  - Innovative approaches
KW  - Interactive storytelling
KW  - Language model
KW  - Model-based OPC
KW  - Narrative generation
KW  - Story generations
KW  - Visual novel
KW  - Global warming
A2  - Holloway-Attaway L.
A2  - Murray J.T.
PB  - Springer Science and Business Media Deutschland GmbH
SN  - 03029743 (ISSN); 978-303147657-0 (ISBN)
LA  - English
J2  - Lect. Notes Comput. Sci.
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 0; Correspondence Address: P. Taveekitworachai; Graduate School of Information Science and Engineering, Ritsumeikan University, Kusatsu, Shiga, Japan; email: gr0609fv@ed.ritsumei.ac.jp; Conference name: 16th International Conference on Interactive Digital Storytelling, ICIDS 2023; Conference date: 11 November 2023 through 15 November 2023; Conference code: 304169
ER  -

TY  - CONF
AU  - Arachchige, I.A.N.
AU  - Ha, L.A.
AU  - Mitkov, R.
AU  - Nahar, V.
TI  - Evaluating Large Language Models in Relationship Extraction from Unstructured Data: Empirical Study from Holocaust Testimonies
PY  - 2023
T2  - International Conference Recent Advances in Natural Language Processing, RANLP
SP  - 117
EP  - 123
DO  - 10.26615/978-954-452-092-2_013
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85179177996&doi=10.26615%2f978-954-452-092-2_013&partnerID=40&md5=4aa71293a35772a7c5988c15a47f2c26
AD  - University of Wolverhampton, United Kingdom
AD  - Lancaster University, United Kingdom
AB  - Relationship extraction from unstructured data remains one of the most challenging tasks in the field of Natural Language Processing (NLP). The complexity of relationship extraction arises from the need to comprehend the underlying semantics, syntactic structures, and contextual dependencies within the text. Unstructured data poses challenges with diverse linguistic patterns, implicit relationships, contextual nuances, complicating accurate relationship identification and extraction. The emergence of Large Language Models (LLMs), such as GPT (Generative Pre-trained Transformer), has indeed marked a significant advancement in the field of NLP.In this work, we assess and evaluate the effectiveness of LLMs in relationship extraction in the Holocaust testimonies within the context of the Historical realm. By delving into this domainspecific context, we aim to gain deeper insights into the performance and capabilities of LLMs in accurately capturing and extracting relationships within the Holocaust domain by developing a novel knowledge graph to visualise the relationships of the Holocaust. To the best of our knowledge, there is no existing study which discusses relationship extraction in Holocaust testimonies. The majority of current approaches for Information Extraction (IE) in historic documents are either manual or Optical Character Recognition (OCR) based. Moreover, in this study, we found that the Subject-Object-Verb extraction using GPT3-based relations produced more meaningful results compared to the Semantic Role labelingbased triple extraction. © 2023 Incoma Ltd. All rights reserved.
KW  - Computational linguistics
KW  - Data mining
KW  - Natural language processing systems
KW  - Optical character recognition
KW  - Syntactics
KW  - Domain specific
KW  - Empirical studies
KW  - Implicit relationships
KW  - Language model
KW  - Language processing
KW  - Linguistic patterns
KW  - Natural languages
KW  - Relationship extraction
KW  - Syntactic structure
KW  - Unstructured data
KW  - Semantics
A2  - Angelova G.
A2  - Kunilovskaya M.
A2  - Mitkov R.
PB  - Incoma Ltd
SN  - 13138502 (ISSN); 978-954452092-2 (ISBN)
LA  - English
J2  - Int. Conf. Recent Adv. Nat. Lang. Proces., RANLP
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 0; Conference name: 2023 International Conference Recent Advances in Natural Language Processing: Large Language Models for Natural Language Processing, RANLP 2023; Conference date: 4 September 2023 through 6 September 2023; Conference code: 194755
ER  -

TY  - JOUR
AU  - Zou, Y.
AU  - Lin, J.
AU  - Li, A.
AU  - Zhang, Y.
TI  - Evaluation of transformer oil-paper insulation status based on grey relational analysis and a cluster cloud model
ST  - 基于灰色关联分析和聚类云模型的变压器油纸绝缘状态评估
PY  - 2023
T2  - Dianli Xitong Baohu yu Kongzhi/Power System Protection and Control
VL  - 51
IS  - 21
SP  - 35
EP  - 43
DO  - 10.19783/j.cnki.pspc.230312
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85177837772&doi=10.19783%2fj.cnki.pspc.230312&partnerID=40&md5=813c8fe785cfec28c677b2f28ad8b159
AD  - College of Electrical Engineering and Automation, Fuzhou University, Fuzhou, 350108, China
AD  - Xiamen Power Supply Company, State Grid Fujian Electric Power Co., Ltd., Xiamen, 361004, China
AB  - Accurate diagnosis of the composite oil-paper insulation state of power transformers is of great guiding significance for the safe and stable operation of power systems and the operation and maintenance of equipment itself. In this paper, an evaluation method based on grey relational analysis (GRA) and a clustering cloud model is proposed to solve the problem of inaccurate evaluation caused by few characteristic quantities of the dielectric response of oil-paper insulation and failure to consider the randomness of the system. First, based on the recovery voltage method and the extended Debye model, five relevant features are extracted to establish the oil-paper insulation state evaluation system. Second, in view of the sensitivity differences of multiple feature quantities in the reactive insulation state, a combination weighting method combining GRA and an improved analytic hierarchy process is used to avoid data information loss and make the weight allocation more reasonable. Finally, it uses the atomization characteristics of the cloud model to reflect the randomness of the data, and comprehensively considers the randomness and fuzziness of the classification boundary of the evaluation index grade. After that a clustering cloud model membership selector is constructed. The validation of measured data from multiple transformers with different furfural content shows that the evaluation method can not only accurately reflect the actual insulation status of the transformer, but also reflect its deterioration trend, providing a reference basis for the formulation of maintenance strategies. © 2023 Power System Protection and Control Press. All rights reserved.
KW  - cluster cloud model
KW  - fuzzy comprehensive evaluation
KW  - grey correlation analysis
KW  - improved analytic hierarchy process
KW  - oil-paper insulation
KW  - time domain response
KW  - Analytic hierarchy process
KW  - Cloud computing
KW  - Deterioration
KW  - Fuzzy set theory
KW  - Power transformers
KW  - Random processes
KW  - Time domain analysis
KW  - Transformer protection
KW  - Cloud modeling
KW  - Cluster cloud model
KW  - Clusterings
KW  - Evaluation methods
KW  - Fuzzy-comprehensive evaluations
KW  - Grey correlation analysis
KW  - Grey relational analysis
KW  - Improved analytic hierarchy process
KW  - Oil/paper insulation
KW  - Time domain response
KW  - Insulation
PB  - Power System Protection and Control Press
SN  - 16743415 (ISSN)
LA  - Chinese
J2  - Dianli Xitong Baohu yu Kongzhi
M3  - Article
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 1; Correspondence Address: J. Lin; College of Electrical Engineering and Automation, Fuzhou University, Fuzhou, 350108, China; email: 452615266@qq.com
ER  -

TY  - JOUR
AU  - Yang, X.
AU  - Wang, Q.
AU  - Lyu, J.
TI  - Assessing ChatGPT’s Educational Capabilities and Application Potential
PY  - 2023
T2  - ECNU Review of Education
DO  - 10.1177/20965311231210006
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85176089672&doi=10.1177%2f20965311231210006&partnerID=40&md5=cab04fe1d2ec7c08e05de6a1c5c49f0c
AD  - Institute of Curriculum and Instruction, East China Normal University, China
AD  - Institute of International and Comparative Education, South China Normal University, China
AB  - Purpose: ChatGPT is a generative artificial intelligence (AI) technology that can solve multiple complex tasks. ChatGPT-4 can facilitate educational empowerment in China through technology to understand and generate Chinese text. Although ChatGPT's benefits have been widely discussed, its educational capabilities have not been systematically assessed. This study provides evidence of and insights into the educational applications of AI tools in China. Design/Approach/Methods: This study uses various tests to systematically assess the latest iteration of the AI chatbot ChatGPT-4, including the Watson-Glaser Critical Thinking Appraisal (WGCTA), Five Core Competencies Questionnaire, and written test of China's 2022 National Teacher Certificate Examination (NTCE). Findings: The WGCTA results suggest that ChatGPT requires strong critical thinking. Compared with the other four competencies, the tool showed a lower aptitude for creativity. Regarding its educational applications, ChatGPT performed well on the 2022 NTCE written test. As technology enhances, ChatGPT and similar AI tools have potential applications in China for lesson planning, student self-learning, classroom interaction, and checking assignments. Originality/Value: This study systematically tested ChatGPT at a logical level and assessed its core competencies and educational applications. The study innovatively used 2022 NTCE data to test ChatGPT, with results providing support for the application of generative AI in future curricula and instruction in China. © The Author(s) 2023.
KW  - Capabilities assessment
KW  - ChatGPT
KW  - educational applications
KW  - generative artificial intelligence
PB  - SAGE Publications Ltd
SN  - 20965311 (ISSN)
LA  - English
J2  - ECNU rev. educ.
M3  - Article
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 0; Correspondence Address: J. Lyu; Institute of International and Comparative Education, South China Normal University, China; email: jue_lyu@163.com
ER  -

TY  - JOUR
AU  - Parker, J.L.
AU  - Becker, K.
AU  - Carroca, C.
TI  - ChatGPT for Automated Writing Evaluation in Scholarly Writing Instruction
PY  - 2023
T2  - Journal of Nursing Education
VL  - 62
IS  - 12
SP  - 721
EP  - 727
DO  - 10.3928/01484834-20231006-02
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85178639917&doi=10.3928%2f01484834-20231006-02&partnerID=40&md5=921bb25f475e84ce650874862384715d
AD  - Massachusetts College of Pharmacy and Health Sciences, School of Healthcare Business, United States
AD  - Iowa State University, United States
AD  - Department of Nursing, Massachusetts College of Pharmacy and Health Sciences, United States
AB  - Background: Effective strategies for developing scholarly writing skills in postsecondary nursing students are needed. Generative artificial intelligence (GAI) tools, such as ChatGPT, for automated writing evaluation (AWE) hold promise for mitigating challenges associated with scholarly writing instruction in nursing education. This article explores the suitability of ChatGPT for AWE in writing instruction. Method: ChatGPT feedback on 42 nursing student texts from the Michigan Corpus of Upper-Level Student Papers was assessed. Assessment criteria were derived from recent AWE research. Results: ChatGPT demonstrated utility as an AWE tool. Its scoring performance demonstrated stricter grading than human raters, related feedback to macro-level writing features, and supported multiple submissions and learner autonomy. Conclusion: Despite concerns surrounding GAI in academia, educators can accelerate the feedback process without increasing their workload, and students can receive individualized feedback by incorporating AWE provided by ChatGPT into the writing process. [J Nurs Educ. 2023;62(12):721-727.] © 2023 Slack Incorporated. All rights reserved.
KW  - Artificial Intelligence
KW  - Education, Nursing
KW  - Feedback
KW  - Humans
KW  - Students, Nursing
KW  - Writing
KW  - artificial intelligence
KW  - feedback system
KW  - human
KW  - nursing education
KW  - nursing student
KW  - writing
PB  - Slack Incorporated
SN  - 01484834 (ISSN)
C2  - 38049299
LA  - English
J2  - J. Nurs. Educ.
M3  - Article
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 1; Correspondence Address: J.L. Parker; School of Healthcare Business, Massachusetts College of Pharmacy and Health Sciences, Boston, 179 Longwood Avenue, 02115, United States; email: Jessica.parker@mcphs.edu
ER  -

TY  - CONF
AU  - Veenboer, T.
AU  - Bloem, J.
TI  - Using Collostructional Analysis to evaluate BERT's representation of linguistic constructions
PY  - 2023
T2  - Proceedings of the Annual Meeting of the Association for Computational Linguistics
SP  - 12937
EP  - 12951
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85175454987&partnerID=40&md5=daa3c7f58e10b342eef5267ed3df5e30
AD  - University of Amsterdam, Netherlands
AB  - Collostructional analysis is a technique devised to find correlations between particular words and linguistic constructions in order to analyse meaning associations of these constructions. Contrasting collostructional analysis results with output from BERT might provide insights into the way BERT represents the meaning of linguistic constructions. This study tests to what extent English BERT's meaning representations correspond to known constructions from the linguistics literature by means of two tasks that we propose. Firstly, by predicting the words that can be used in open slots of constructions, the meaning associations of more lexicalized constructions can be observed. Secondly, by finding similar sequences using BERT's output embeddings and manually reviewing the resulting sentences, we can observe whether instances of less lexicalized constructions are clustered together in semantic space. These two methods show that BERT represents constructional meaning to a certain extent, but does not separate instances of a construction from a near-synonymous construction that has a different form. © 2023 Association for Computational Linguistics.
KW  - Computational linguistics
KW  - Embeddings
KW  - Open slots
KW  - Semantic Space
KW  - Semantics
PB  - Association for Computational Linguistics (ACL)
SN  - 0736587X (ISSN); 978-195942962-3 (ISBN)
LA  - English
J2  - Proc. Annu. Meet. Assoc. Comput Linguist.
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 1; Conference name: 61st Annual Meeting of the Association for Computational Linguistics, ACL 2023; Conference date: 9 July 2023 through 14 July 2023; Conference code: 192867
ER  -

TY  - JOUR
AU  - Shin, E.
AU  - Ramanathan, M.
TI  - Evaluation of prompt engineering strategies for pharmacokinetic data analysis with the ChatGPT large language model
PY  - 2023
T2  - Journal of Pharmacokinetics and Pharmacodynamics
DO  - 10.1007/s10928-023-09892-6
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85176560208&doi=10.1007%2fs10928-023-09892-6&partnerID=40&md5=ebbf961851219e1146cfeeb755f972c8
AD  - Department of Pharmaceutical Sciences, University at Buffalo, The State University of New York, 355 Pharmacy, Buffalo, 14214-8033, NY, United States
AB  - To systematically assess the ChatGPT large language model on diverse tasks relevant to pharmacokinetic data analysis. ChatGPT was evaluated with prototypical tasks related to report writing, code generation, non-compartmental analysis, and pharmacokinetic word problems. The writing task consisted of writing an introduction for this paper from a draft title. The coding tasks consisted of generating R code for semi-logarithmic graphing of concentration–time profiles and calculating area under the curve and area under the moment curve from time zero to infinity. Pharmacokinetics word problems on single intravenous, extravascular bolus, and multiple dosing were taken from a pharmacokinetics textbook. Chain-of-thought and problem separation were assessed as prompt engineering strategies when errors occurred. ChatGPT showed satisfactory performance on the report writing, code generation tasks and provided accurate information on the principles and methods underlying pharmacokinetic data analysis. However, ChatGPT had high error rates in numerical calculations involving exponential functions. The outputs generated by ChatGPT were not reproducible: the precise content of the output was variable albeit not necessarily erroneous for different instances of the same prompt. Incorporation of prompt engineering strategies reduced but did not eliminate errors in numerical calculations. ChatGPT has the potential to become a powerful productivity tool for writing, knowledge encapsulation, and coding tasks in pharmacokinetic data analysis. The poor accuracy of ChatGPT in numerical calculations require resolution before it can be reliably used for PK and pharmacometrics data analysis. © 2023, The Author(s), under exclusive licence to Springer Science+Business Media, LLC, part of Springer Nature.
KW  - Bioavailability
KW  - ChatGPT
KW  - Drug development
KW  - Graphing
KW  - Pharmacokinetics
KW  - PK/PD
KW  - Prompt engineering
PB  - Springer
SN  - 1567567X (ISSN)
LA  - English
J2  - J. Pharmacokinet. Pharmacodyn.
M3  - Article
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 1; Correspondence Address: M. Ramanathan; Department of Pharmaceutical Sciences, University at Buffalo, The State University of New York, Buffalo, 355 Pharmacy, 14214-8033, United States; email: murali@buffalo.edu; CODEN: JPPOA
ER  -

TY  - CONF
AU  - Li, J.
AU  - Meland, P.H.
AU  - Notland, J.S.
AU  - Storhaug, A.
AU  - Tysse, J.H.
TI  - Evaluating the Impact of ChatGPT on Exercises of a Software Security Course
PY  - 2023
T2  - International Symposium on Empirical Software Engineering and Measurement
DO  - 10.1109/ESEM56168.2023.10304857
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85178667789&doi=10.1109%2fESEM56168.2023.10304857&partnerID=40&md5=92bba2ae5dd87c083c7df1b1a85660e9
AD  - Norwegian Univ. of Science and Technology (NTNU), Dept. of Computer Science, Trondheim, Norway
AD  - Ntnu, Dept. of Computer Science, Trondheim, Norway
AB  - Along with the development of large language models (LLMs), e.g., ChatGPT, many existing approaches and tools for software security are changing. It is, therefore, essential to understand how security-aware these models are and how these models impact software security practices and education. In exercises of a software security course at our university, we ask students to identify and fix vulnerabilities we insert in a web application using state-of-the-art tools. After ChatGPT, especially the GPT-4 version of the model, we want to know how the students can possibly use ChatGPT to complete the exercise tasks. We input the vulnerable code to ChatGPT and measure its accuracy in vulnerability identification and fixing. In addition, we investigated whether ChatGPT can provide a proper source of information to support its outputs. Results show that ChatGPT can identify 20 of the 28 vulnerabilities we inserted in the web application in a white-box setting, reported three false positives, and found four extra vulnerabilities beyond the ones we inserted. ChatGPT makes nine satisfactory penetration testing and fixing recommendations for the ten vulnerabilities we want students to fix and can often point to related sources of information.  © 2023 IEEE.
KW  - artificial intelligence
KW  - ChatGPT
KW  - IT education
KW  - large language models
KW  - Software security
KW  - Application programs
KW  - Computational linguistics
KW  - Curricula
KW  - Education computing
KW  - Engineering education
KW  - Technology transfer
KW  - ChatGPT
KW  - IT-education
KW  - Language model
KW  - Large language model
KW  - Security Practice
KW  - Security-aware
KW  - Software security
KW  - Sources of informations
KW  - WEB application
KW  - Web applications
KW  - Students
PB  - IEEE Computer Society
SN  - 19493770 (ISSN); 978-166545223-6 (ISBN)
LA  - English
J2  - Int. Symp. Empir. Softw. Eng. Meas.
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 0; Conference name: 17th ACM/IEEE International Symposium on Empirical Software Engineering and Measurement, ESEM 2023; Conference date: 26 October 2023 through 27 October 2023; Conference code: 194365
ER  -

TY  - JOUR
AU  - Bewersdorff, A.
AU  - Seßler, K.
AU  - Baur, A.
AU  - Kasneci, E.
AU  - Nerdel, C.
TI  - Assessing student errors in experimentation using artificial intelligence and large language models: A comparative study with human raters
PY  - 2023
T2  - Computers and Education: Artificial Intelligence
VL  - 5
C7  - 100177
DO  - 10.1016/j.caeai.2023.100177
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85174600919&doi=10.1016%2fj.caeai.2023.100177&partnerID=40&md5=00caf3240d161fd6cb77a155b83bcd06
AD  - Technical University Munich, Germany
AD  - University of Education Heidelberg, Germany
AB  - Identifying logical errors in complex, incomplete or even contradictory and overall heterogeneous data like students’ experimentation protocols is challenging. Recognizing the limitations of current evaluation methods, we investigate the potential of Large Language Models (LLMs) for automatically identifying student errors and streamlining teacher assessments. Our aim is to provide a foundation for productive, personalized feedback. Using a dataset of 65 student protocols, an Artificial Intelligence (AI) system based on the GPT-3.5 and GPT-4 series was developed and tested against human raters. Our results indicate varying levels of accuracy in error detection between the AI system and human raters. The AI system can accurately identify many fundamental student errors, for instance, the AI system identifies when a student is focusing the hypothesis not on the dependent variable but solely on an expected observation (acc. = 0.90), when a student modifies the trials in an ongoing investigation (acc. = 1), and whether a student is conducting valid test trials (acc. = 0.82) reliably. The identification of other, usually more complex errors, like whether a student conducts a valid control trial (acc. = 0.60), poses a greater challenge. This research explores not only the utility of AI in educational settings, but also contributes to the understanding of the capabilities of LLMs in error detection in inquiry-based learning like experimentation. © 2023 The Authors
KW  - Artificial intelligence
KW  - Experimentation
KW  - Formative assessment
KW  - Large language models
KW  - Science education
KW  - Scientific inquiry
KW  - Student errors
KW  - Artificial intelligence
KW  - Computational linguistics
KW  - Education computing
KW  - Error detection
KW  - Artificial intelligence systems
KW  - Comparatives studies
KW  - Experimentation
KW  - Formative assessment
KW  - Language model
KW  - Large language model
KW  - Logical errors
KW  - Science education
KW  - Scientific inquiry
KW  - Student error
KW  - Students
PB  - Elsevier B.V.
SN  - 2666920X (ISSN)
LA  - English
J2  - Comput. Educ.
M3  - Article
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 0; Correspondence Address: A. Bewersdorff; Technical University of Munich, Munich, Arcisstraße 31, 80333, Germany; email: arne.bewersdorff@tum.de
ER  -

TY  - JOUR
AU  - Hallal, K.
AU  - Hamdan, R.
AU  - Tlais, S.
TI  - Exploring the potential of AI-Chatbots in organic chemistry: An assessment of ChatGPT and Bard
PY  - 2023
T2  - Computers and Education: Artificial Intelligence
VL  - 5
C7  - 100170
DO  - 10.1016/j.caeai.2023.100170
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85174449984&doi=10.1016%2fj.caeai.2023.100170&partnerID=40&md5=a98cfdc1468cb005dac68b8cf50b745c
AD  - Department of Chemistry, Lebanese International University- Beirut, Salim Slam Street, Mazraa, Beirut, 146404, Lebanon
AD  - Department of Chemistry and Biochemistry, Lebanese University, Hariri Campus, Hadath, Lebanon
AD  - College of Engineering and Technology, American University of the Middle East, Egaila, 54200, Kuwait
AB  - The invention of AI-Chatbot is undeniably one of the most remarkable achievements by humanity, harnessing an unparalleled level of power and potential. In the near future, AI-chatbots are expected to become valuable tools in education, aiding students in their learning journeys. This study aims to explore the performance and accuracy of two chatbots, ChatGPT and Bard in understanding text-based structural notations such as, condensed structures, InChi and SMILES and answering organic chemistry related questions. Their ability to perform tasks such as converting IUPAC names, InChi, and SMILES notations into condensed forms and vice versa, identifying functional groups, generating molecular formulas, and predicting resonance patterns was studied. The ChatGPTs' accuracy percentages for various tasks are as follows: determining degree of unsaturation from molecular formulas (90-80%), InChi (79-64%), and SMILES (86-64%); identifying functional groups from condensed structures (94%) and InChi (65-50%); converting condensed structures to molecular formulas (86-73%), IUPAC (38%), InChi (22-17%), and SMILES (56-44%); converting InChi to IUPAC (65-50%) and condensed structures (28-11%); and converting SMILES to condensed structures (42-37%) and IUPAC (25-20%). In contrast, Bard consistently performed lower in most tasks. Both chatbots had significant limitations, especially with InChi and SMILES notations which have been used successfully in machine learning. GPT-4, the newer version of ChatGPT, was also tested against these tasks, and slight improvements were observed in most areas, particularly in reading SMILES notations. While these advanced AI-chatbots hold promising potential as enduring educational tools in organic chemistry, inspiring reevaluation of teaching strategies, their implementation should be carefully monitored, particularly considering the rapid pace of advancements. © 2023 The Authors
KW  - Artificial intelligence
KW  - Bard
KW  - Chatbot
KW  - ChatGPT
KW  - Education
KW  - Machine learning
KW  - Organic chemistry
KW  - Bard
KW  - Chatbots
KW  - ChatGPT
KW  - Condensed form
KW  - Condensed structures
KW  - Machine-learning
KW  - Molecular formulae
KW  - Organic Chemistry
KW  - Performance
KW  - Power
KW  - Machine learning
PB  - Elsevier B.V.
SN  - 2666920X (ISSN)
LA  - English
J2  - Comput. Educ.
M3  - Article
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 0; Correspondence Address: S. Tlais; College of Engineering and Technology, American University of the Middle East, Egaila, 54200, Kuwait; email: sami.tlais@aum.edu.kw
ER  -

TY  - JOUR
AU  - McIntosh, T.R.
AU  - Liu, T.
AU  - Susnjak, T.
AU  - Watters, P.
AU  - Ng, A.
AU  - Halgamuge, M.N.
TI  - A Culturally Sensitive Test to Evaluate Nuanced GPT Hallucination
PY  - 2023
T2  - IEEE Transactions on Artificial Intelligence
SP  - 1
EP  - 13
DO  - 10.1109/TAI.2023.3332837
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85177047494&doi=10.1109%2fTAI.2023.3332837&partnerID=40&md5=36febe91199f08722135197f95fb523c
AD  - La Trobe University, Bundoora, VIC, Australia
AD  - Massey University, Auckland, New Zealand
AD  - Cyberstronomy Pty Ltd, Ballarat, VIC, Australia
AD  - RMIT University, Melbourne, VIC, Australia
AB  - <italic>The Generative Pre-trained Transformer</italic> (GPT) models, renowned for generating human-like text, occasionally produce &#x201C;hallucinations&#x201D; - outputs that diverge from human expectations. Current mitigation strategies for these GPT hallucinations largely rely on algorithmic automation, thereby overlooking the complexities of human judgment and cultural influence, particularly in fact interpretation. Addressing this issue, we have introduced a Culturally Sensitive Test that integrates language subjectivity, cultural nuances, and GPT idiosyncrasies. We have applied this test to five GPT models&#x2014;OpenAI&#x2019;s ChatGPT-3.5 and ChatGPT-4, Google&#x2019;s Bard, Perplexity AI and TruthGPT - evaluating their responses to 70 questions across seven categories designed to provoke hallucinations. The evaluated models demonstrated varying performance, with controversial topics, those lacking clear scientific consensus and the brain teasers proving more susceptible to GPT hallucinations. Our study has paved the way for a nuanced assessment of GPT hallucinations. IEEE
KW  - AI Evaluation
KW  - AI Hallucinations
KW  - Cultural Nuance
KW  - Culturally Sensitive Test
KW  - Generative AI
KW  - Generative Pre-trained Transformer
PB  - Institute of Electrical and Electronics Engineers Inc.
SN  - 26914581 (ISSN)
LA  - English
J2  - IEEE.  Trans. Artif. Intell.
M3  - Article
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 1
ER  -

TY  - CONF
AU  - Meng, F.-J.
AU  - He, J.-F.
AU  - Xu, X.-J.
AU  - Zhao, Y.-J.
AU  - Sun, L.-J.
TI  - A Sentence Quality Evaluation Framework for Machine Reading Comprehension Incorporating Pre-trained Language Model
PY  - 2023
T2  - Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)
VL  - 14089 LNAI
SP  - 443
EP  - 455
DO  - 10.1007/978-981-99-4752-2_37
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85174683274&doi=10.1007%2f978-981-99-4752-2_37&partnerID=40&md5=23a735654ce70c436b3ed4982345dc0e
AD  - College of Computer Science and Technology, Inner Mongolia Normal University, Hohhot, 010022, China
AB  - Multi-choice Machine Reading Comprehension (MRC) task involves selecting the correct answer from a limited set of options given a passage and a question. MRC tasks have experienced two main peaks: the explosion of deep neural networks and the evolution of contextual language models. However, the traditional paradigm suffers from inconsistency between the pre-trained and fine-tuning phases of the task. Pre-trained Language Models (PrLMs) are limited to a fixed input length, which can introduce noisy information irrelevant to the question. To address these issues, we propose a MacBERT-based Chinese MRC model that discards the traditional mask and adopts a similar word approach. This approach provides better contextual information and solves the problem of multiple meanings of words, better fitting the nature of the MRC task. Additionally, an unsupervised algorithm is used to filter passage sentences, controlling the model input and solving the problem of too much irrelevant content in long reading materials. We demonstrate that the proposed methods achieve better results compared to the baseline model on the Chinese MRC dataset C3. © 2023, The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd.
KW  - Chinese machine reading comprehension
KW  - Deep neural network
KW  - Pre-trained language model
KW  - Computational linguistics
KW  - Quality control
KW  - Chinese machine reading comprehension
KW  - Comprehension tasks
KW  - Evaluation framework
KW  - Fine tuning
KW  - Fixed input lengths
KW  - Language model
KW  - Multi choices
KW  - Pre-trained language model
KW  - Quality evaluation
KW  - Reading comprehension
KW  - Deep neural networks
A2  - Huang D.-S.
A2  - Premaratne P.
A2  - Jin B.
A2  - Qu B.
A2  - Jo K.-H.
A2  - Hussain A.
PB  - Springer Science and Business Media Deutschland GmbH
SN  - 03029743 (ISSN); 978-981994751-5 (ISBN)
LA  - English
J2  - Lect. Notes Comput. Sci.
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 0; Correspondence Address: F.-J. Meng; College of Computer Science and Technology, Inner Mongolia Normal University, Hohhot, 010022, China; email: ciecmfj@imnu.edu.cn; Conference name: 19th International Conference on Intelligent Computing, ICIC 2023; Conference date: 10 August 2023 through 13 August 2023; Conference code: 298889
ER  -

TY  - CONF
AU  - Raina, S.
AU  - Amin, H.
AU  - Sanghvi, S.
AU  - Bharti, S.K.
AU  - Gupta, R.K.
TI  - Automatic Subjective Answer Evaluator Using BERT Model
PY  - 2023
T2  - Lecture Notes in Networks and Systems
VL  - 703 LNNS
SP  - 531
EP  - 538
DO  - 10.1007/978-981-99-3315-0_40
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85174724982&doi=10.1007%2f978-981-99-3315-0_40&partnerID=40&md5=1beae9bcc3cce7ee7c8e6679ead8f798
AD  - Pandit Deendayal Energy University, Gujarat, Gandhinagar, India
AB  - Subjective answers might get tedious to check and take time and effort. Although there has been much research in this field, there needs to be an all-developed and deployable method that considers all factors like keyword matching, context analysis, and relative scoring. We have developed an algorithm for Subjective Answer Evaluation using Tf-idf scoring, BERT-based context analysis, and assigned scores based on relevance. We calculate the Tf-idf value for the keywords, and then if they match with the keywords from the evaluator’s answer, we add the Tf-idf value to generate a total score for each answer. Further, we use transfer learning from BERT and assign scores based on context relevance. Finally, we use a combination of both scores to calculate relative scoring and then give the results as relative scores using a custom algorithm. Comparing these scores to manual scores, i.e., checked by the evaluator, we obtained an accuracy of 90%. © The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd. 2023.
KW  - Answer evaluation
KW  - BERT
KW  - Context analysis
KW  - Relative scoring
KW  - Subjective answer
KW  - Tf-idf
KW  - Transfer learning
KW  - Answer evaluation
KW  - BERT
KW  - Context analysis
KW  - Key word matching
KW  - Relative scoring
KW  - Subjective answer
KW  - Tf-idf
KW  - Transfer learning
A2  - Hassanien A.E.
A2  - Castillo O.
A2  - Anand S.
A2  - Jaiswal A.
PB  - Springer Science and Business Media Deutschland GmbH
SN  - 23673370 (ISSN); 978-981993314-3 (ISBN)
LA  - English
J2  - Lect. Notes Networks Syst.
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 0; Correspondence Address: S. Raina; Pandit Deendayal Energy University, Gandhinagar, Gujarat, India; email: sanyam.raina@gmail.com; Conference name: 6th International Conference on Innovative Computing and Communication, ICICC 2023; Conference date: 17 February 2023 through 18 February 2023; Conference code: 298729
ER  -

TY  - CONF
AU  - Prajeeth, A.
AU  - Gautam, B.
AU  - Chhikara, G.
TI  - Assessing the Efficacy of Different BERT Variants for Distinguishing Types of Cyberbullying on Twitter
PY  - 2023
T2  - Lecture Notes in Networks and Systems
VL  - 787 LNNS
SP  - 525
EP  - 536
DO  - 10.1007/978-981-99-6550-2_40
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85178588117&doi=10.1007%2f978-981-99-6550-2_40&partnerID=40&md5=b04da5a95c71acace728a0bdd8eb9f6a
AD  - Department of Computer Science and Engineering, Delhi Technological University, Delhi, New Delhi, 110042, India
AB  - BERT is a highly developed language model that has excelled in a wide range of tasks, including question-answering and language comprehension. It now outperforms both the performance of older state-of-the-art computer models and human intelligence. Due to its exceptional capabilities, a large number of businesses, academic institutions, and divisions of Google are actively developing the BERT model architecture through supervised training, with the goal of either enhancing its effectiveness or customizing it for particular tasks by pre-training it with specific contextual representations. In this paper, we classify the category of cyberbullying in each tweet posted on Twitter taken into our dataset. Our research aims to test out different variations of BERT-ALBERT, RoBERTa, and DistilBERT and extrapolate the efficiency of each model concerning the multi-label classification of tweets. © 2023, The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd.
KW  - BERT
KW  - Multi-label classification of tweets
KW  - NLP
KW  - Computer crime
KW  - Social networking (online)
KW  - BERT
KW  - Computer models
KW  - Cyber bullying
KW  - Language comprehensions
KW  - Language model
KW  - Multi-label classification of tweet
KW  - Multi-label classifications
KW  - Performance
KW  - Question Answering
KW  - State of the art
KW  - Classification (of information)
A2  - Swaroop A.
A2  - Polkowski Z.
A2  - Correia S.D.
A2  - Virdee B.
PB  - Springer Science and Business Media Deutschland GmbH
SN  - 23673370 (ISSN); 978-981996549-6 (ISBN)
LA  - English
J2  - Lect. Notes Networks Syst.
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 0; Correspondence Address: A. Prajeeth; Department of Computer Science and Engineering, Delhi Technological University, New Delhi, Delhi, 110042, India; email: ashwinkurumkulamprajeeth_2k19co92@dtu.ac.in; Conference name: International Conference on Data Analytics and Management, ICDAM 2023; Conference date: 23 June 2023 through 24 June 2023; Conference code: 304889
ER  -

TY  - CONF
AU  - Hicke, Y.
AU  - Masand, A.
AU  - Guo, W.
AU  - Gangavarapu, T.
TI  - Assessing the efficacy of large language models in generating accurate teacher responses
PY  - 2023
T2  - Proceedings of the Annual Meeting of the Association for Computational Linguistics
SP  - 745
EP  - 755
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85174506348&partnerID=40&md5=1b6b9cce66b0df2315169b6a0998b7fb
AD  - Cornell University, United States
AB  - (Tack et al., 2023) organized the shared task hosted by the 18th Workshop on Innovative Use of NLP for Building Educational Applications on generation of teacher language in educational dialogues. Following the structure of the shared task, in this study, we attempt to assess the generative abilities of large language models in providing informative and helpful insights to students, thereby simulating the role of a knowledgeable teacher. To this end, we present an extensive evaluation of several benchmarking generative models, including GPT-4 (few-shot, in-context learning), fine-tuned GPT-2, and fine-tuned DialoGPT. Additionally, to optimize for pedagogical quality, we fine-tuned the Flan-T5 model using reinforcement learning. Our experimental findings on the Teacher-Student Chatroom Corpus subset indicate the efficacy of GPT-4 over other fine-tuned models, measured using BERTScore and DialogRPT. We hypothesize that several dataset characteristics, including sampling, representativeness, and dialog completeness, pose significant challenges to fine-tuning, thus contributing to the poor generalizability of the fine-tuned models. Finally, we note the need for these generative models to be evaluated with a metric that relies not only on dialog coherence and matched language modeling distribution but also on the model’s ability to showcase pedagogical skills. © 2023 Association for Computational Linguistics.
KW  - Computational linguistics
KW  - Learning systems
KW  - Modeling languages
KW  - Natural language processing systems
KW  - Reinforcement learning
KW  - Chat rooms
KW  - Context learning
KW  - Educational Applications
KW  - Fine tuning
KW  - Generative model
KW  - In contexts
KW  - Language model
KW  - Modeling distributions
KW  - Reinforcement learnings
KW  - Teachers'
KW  - Students
A2  - Kochmar E.
A2  - Burstein J.
A2  - Horbach A.
A2  - Horbach A.
A2  - Horbach A.
A2  - Laarmann-Quante R.
A2  - Madnani N.
A2  - Tack A.
A2  - Yaneva V.
A2  - Yuan Z.
A2  - Zesch T.
A2  - Zesch T.
PB  - Association for Computational Linguistics (ACL)
SN  - 0736587X (ISSN); 978-195942980-7 (ISBN)
LA  - English
J2  - Proc. Annu. Meet. Assoc. Comput Linguist.
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 0; Conference name: 18th Workshop on Innovative Use of NLP for Building Educational Applications, BEA 2023; Conference code: 193152
ER  -

TY  - CONF
AU  - Costa, J.A.F.
AU  - Dantas, N.C.D.
AU  - Silva, E.D.S.A.
TI  - Evaluating Text Classification in the Legal Domain Using BERT Embeddings
PY  - 2023
T2  - Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)
VL  - 14404 LNCS
SP  - 51
EP  - 63
DO  - 10.1007/978-3-031-48232-8_6
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85177837820&doi=10.1007%2f978-3-031-48232-8_6&partnerID=40&md5=1ec225c064ddc038afc1ce9c5b8432b7
AD  - Universidade Federal do Rio Grande do Norte, RN, Natal, 59078-900, Brazil
AB  - Brazil’s justice system faces grave case backlogs stemming from surging caseloads. This research explores automated text classification to expedite legal document analysis. Supervised machine learning approaches leveraging BERT embeddings fine-tuned on Brazilian legal text were evaluated using a 30,000 document dataset encompassing ten motion types from the Rio Grande do Norte Court of Justice. Documents were encoded into semantic representations via a BERT model adapted to local jurisprudence. The resulting optimized embeddings were used to train and benchmark models including KNN, Naive Bayes, SVM, neural networks, CNNs, and deep learning architectures. Despite BERT’s state-of-the-art capabilities, TF-IDF outperformed neural techniques across considered metrics. High similarity between certain classes was hypothesized to hinder BERT’s contextual embedding. © The Author(s), under exclusive license to Springer Nature Switzerland AG 2023.
KW  - Bert embeddings
KW  - Legal text classification
KW  - Machine learning
KW  - Natural language processing
KW  - Classification (of information)
KW  - Deep learning
KW  - Information retrieval systems
KW  - Natural language processing systems
KW  - Semantics
KW  - Support vector machines
KW  - Text processing
KW  - Bert embedding
KW  - Embeddings
KW  - Language processing
KW  - Legal domains
KW  - Legal text classification
KW  - Legal texts
KW  - Machine-learning
KW  - Natural language processing
KW  - Natural languages
KW  - Text classification
KW  - Embeddings
A2  - Quaresma P.
A2  - Gonçalves T.
A2  - Camacho D.
A2  - Yin H.
A2  - Julian V.
A2  - Tallón-Ballesteros A.J.
PB  - Springer Science and Business Media Deutschland GmbH
SN  - 03029743 (ISSN); 978-303148231-1 (ISBN)
LA  - English
J2  - Lect. Notes Comput. Sci.
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 0; Correspondence Address: J.A.F. Costa; Universidade Federal do Rio Grande do Norte, Natal, RN, 59078-900, Brazil; email: alfredo.costa@ufrn.br; Conference name: 24th International Conference on Intelligent Data Engineering and Automated Learning, IDEAL 2023; Conference date: 22 November 2023 through 24 November 2023; Conference code: 304409
ER  -

TY  - CONF
AU  - Mosca, E.
AU  - Abdalla, M.H.I.
AU  - Basso, P.
AU  - Musumeci, M.
AU  - Groh, G.
TI  - Distinguishing Fact from Fiction: A Benchmark Dataset for Identifying Machine-Generated Scientific Papers in the LLM Era
PY  - 2023
T2  - Proceedings of the Annual Meeting of the Association for Computational Linguistics
SP  - 190
EP  - 207
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85174862576&partnerID=40&md5=69e8aeca10ea2a3f31ba942032273eb9
AD  - TU Munich, Department of Informatics, Germany
AD  - Polytechnic of Milan, Department of EIB, Italy
AB  - As generative NLP can now produce content nearly indistinguishable from human writing, it becomes difficult to identify genuine research contributions in academic writing and scientific publications. Moreover, information in NLP-generated text can potentially be factually wrong or even entirely fabricated. This study introduces a novel benchmark dataset, containing human-written and machine-generated scientific papers from SCIgen, GPT-2, GPT-3, ChatGPT, and Galactica. After describing the generation and extraction pipelines, we also experiment with four distinct classifiers as a baseline for detecting the authorship of scientific text. A strong focus is put on generalization capabilities and explainability to highlight the strengths and weaknesses of detectors. We believe our work serves as an important step towards creating more robust methods for distinguishing between human-written and machine-generated scientific papers, ultimately ensuring the integrity of scientific literature. © 2023 Proceedings of the Annual Meeting of the Association for Computational Linguistics. All rights reserved.
KW  - Academic writings
KW  - Benchmark datasets
KW  - Generalization capability
KW  - Robust methods
KW  - Scientific literature
KW  - Scientific papers
KW  - Scientific publications
KW  - Scientific texts
KW  - Natural language processing systems
A2  - Ovalle A.
A2  - Chang K.-W.
A2  - Chang K.-W.
A2  - Mehrabi N.
A2  - Pruksachatkun Y.
A2  - Galystan A.
A2  - Galystan A.
A2  - Dhamala J.
A2  - Verma A.
A2  - Cao T.
A2  - Kumar A.
A2  - Gupta R.
PB  - Association for Computational Linguistics (ACL)
SN  - 0736587X (ISSN); 978-195942986-9 (ISBN)
LA  - English
J2  - Proc. Annu. Meet. Assoc. Comput Linguist.
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 1; Conference name: 3rd Workshop on Trustworthy Natural Language Processing, TrustNLP 2023, co-located with ACL 2023; Conference code: 193203
ER  -

TY  - CONF
AU  - Monteiro, W.C.
AU  - Dos Santos, D.H.
AU  - De Sousa, T.A.S.
AU  - Queiroz, V.F.
AU  - De Araujo, T.D.O.
AU  - Meiguins, B.S.
TI  - Workload Evaluation to Create Data Visualization Using ChatGPT
PY  - 2023
T2  - Proceedings of the International Conference on Information Visualisation
SP  - 136
EP  - 141
DO  - 10.1109/IV60283.2023.00032
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85178506671&doi=10.1109%2fIV60283.2023.00032&partnerID=40&md5=1d733087f45fd220b2f22590ad4b9642
AD  - Federal University of Pará, Computer Science Graduate Program, ParÃ¡, Belém, Brazil
AD  - University of Aveiro, Ieeta, Deti, Aveiro, Portugal
AB  - The value of good data visualization has already been shown in several scenarios. Still, it is not always easy to obtain it, as it depends on factors such as the dataset, the amount of data, task types, the user profile, the type of interaction, etc. To mitigate the challenges addressed, automated or semi-automated systems have been proposed, emphasizing rule-based/heuristic approaches and machine-learning models. However, many of these applications require specialized knowledge and present results (data visualizations) that are not flexible for customization. Papers have highlighted the ease of tools like ChatGPT in creating various tasks, including creating data charts. This facility, in addition to the intelligent computational model involved, is also due to the expressiveness used in the requests to execute the tasks by the users since these tools use Natural Language Interfaces. Despite adopting these tools overgrowing in different scenarios of society, studies on the best way to use them, integrate them into existing processes, or evaluative studies on their effectiveness or efficiency are still incipient. Thus, this paper will evaluate the workload for creating data visualization using ChatGPT 3.5. For assessment, the NASA Task Load Index (Nasa TLX) methodology was applied, and users with experience creating data visualization created two proposed scenarios. The preliminary results showed high temporal and mental demand, mainly due to the vocabulary used and the completeness of the user instructions. The average time to create and perform InfoVis tasks in two proposed evaluation scenarios was 33 and 44 minutes, and 14 queries were applied on average for both scenarios. The direct consequence was that the users have redone the requests and improved the instructions at each new iteration, and all users completed the proposed tasks. © 2023 IEEE.
KW  - ChatGPT
KW  - Information Visualization
KW  - Interface Natural Language
KW  - Nasa-TLX
KW  - Automation
KW  - Information systems
KW  - Iterative methods
KW  - NASA
KW  - Natural language processing systems
KW  - Visualization
KW  - ChatGPT
KW  - Good data
KW  - Information visualization
KW  - Interface natural language
KW  - Nasa-TLX
KW  - Natural languages
KW  - Semi-automated systems
KW  - Task type
KW  - User's profiles
KW  - Workload evaluation
KW  - Data visualization
PB  - Institute of Electrical and Electronics Engineers Inc.
SN  - 10939547 (ISSN); 979-835034161-4 (ISBN)
LA  - English
J2  - Proc. Int. Conf. Inf. Visual.
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 0; Conference name: 27th International Conference on Information Visualisation, IV 2023; Conference date: 25 July 2023 through 28 July 2023; Conference code: 194323
ER  -

TY  - CONF
AU  - Suri, K.
AU  - Saha, S.
AU  - Singh, A.
TI  - HealthMavericks@MEDIQA-Chat 2023: Benchmarking different Transformer based models for Clinical Dialogue Summarization
PY  - 2023
T2  - Proceedings of the Annual Meeting of the Association for Computational Linguistics
SP  - 472
EP  - 489
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85175451741&partnerID=40&md5=7c56cd918e8bc1b8d6c4bfd88dbd1ce5
AB  - In recent years, we have seen many Transformer based models being created to address Dialog Summarization problem. While there has been a lot of work on understanding how these models stack against each other in summarizing regular conversations such as the ones found in DialogSum dataset, there haven't been many analysis of these models on Clinical Dialog Summarization. In this article, we describe our solution to MEDIQA-Chat 2023 Shared Tasks as part of ACL-ClinicalNLP 2023 workshop which benchmarks some of the popular Transformer Architectures such as BioBart, Flan-T5, DialogLED, and OpenAI GPT3 on the problem of Clinical Dialog Summarization. We analyse their performance on two tasks - summarizing short conversations and long conversations. In addition to this, we also benchmark two popular summarization ensemble methods and report their performance.  © 2023 Association for Computational Linguistics.
KW  - Computational linguistics
KW  - Natural language processing systems
KW  - Ensemble methods
KW  - Performance
KW  - Benchmarking
PB  - Association for Computational Linguistics (ACL)
SN  - 0736587X (ISSN); 978-195942988-3 (ISBN)
LA  - English
J2  - Proc. Annu. Meet. Assoc. Comput Linguist.
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 0; Conference name: 5th Workshop on Clinical Natural Language Processing, ClinicalNLP 2023. held at ACL 2023; Conference code: 193206
ER  -

TY  - JOUR
AU  - Tanaka, O.M.
AU  - Gasparello, G.G.
AU  - Hartmann, G.C.
AU  - Casagrande, F.A.
AU  - Pithon, M.M.
TI  - Assessing the reliability of ChatGPT: a content analysis of self-generated and self-answered questions on clear aligners, TADs and digital imaging
PY  - 2023
T2  - Dental Press Journal of Orthodontics
VL  - 28
IS  - 5
C7  - e2323183
DO  - 10.1590/2177-6709.28.5.e2323183.oar
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85176615410&doi=10.1590%2f2177-6709.28.5.e2323183.oar&partnerID=40&md5=0722c98dd3ca12248a49637acf8e1a37
AD  - Pontifícia Universidade Católica do Paraná, Orthodontics, PR, Curitiba, Brazil
AD  - Southwest Bahia State University, Orthodontics, BH, Jequié, Brazil
AB  - Introduction: Artificial Intelligence (AI) is a tool that is already part of our reality, and this is an opportunity to understand how it can be useful in interacting with patients and providing valuable information about orthodontics. Objective: This study evaluated the accuracy of ChatGPT in providing accurate and quality information to answer questions on Clear aligners, Temporary anchorage devices and Digital imaging in orthodontics. Methods: forty-five questions and answers were generated by the ChatGPT 4.0, and analyzed separately by five orthodontists. The evaluators independently rated the quality of information provided on a Likert scale, in which higher scores indicated greater quality of information (1 = very poor; 2 = poor; 3 = acceptable; 4 = good; 5 = very good). The Kruskal–Wallis H test (p < 0.05) and post-hoc pairwise comparisons with the Bonferroni correction were performed. Results: From the 225 evaluations of the five different evaluators, 11 (4.9%) were considered as very poor, 4 (1.8%) as poor, and 15 (6.7%) as acceptable. The majority were considered as good [34 (15,1%)] and very good [161 (71.6%)]. Regarding evaluators’ scores, a slight agreement was perceived, with Fleiss’s Kappa equal to 0.004. Conclusions: ChatGPT has proven effective in providing quality answers related to clear aligners, temporary anchorage devices, and digital imaging within the context of interest of orthodontics. © 2023, Dental Press International. All rights reserved.
KW  - Artificial intelligence
KW  - ChatGPT
KW  - Clear aligner
KW  - Digital image
KW  - Temporary anchorage device
KW  - adult
KW  - Article
KW  - artificial intelligence
KW  - ChatGPT
KW  - content analysis
KW  - data accuracy
KW  - data quality
KW  - digital imaging
KW  - female
KW  - human
KW  - image quality
KW  - Likert scale
KW  - major clinical study
KW  - male
KW  - orthodontics
KW  - patient satisfaction
KW  - questionnaire
KW  - reliability
KW  - scoring system
PB  - Dental Press International
SN  - 21769451 (ISSN)
C2  - 37937680
LA  - English
J2  - Den.
M3  - Article
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 0; Correspondence Address: O.M. Tanaka; Pontifícia Universidade Católica do Paraná, Orthodontics, Curitiba, PR, Brazil; email: tanakaom@gmail.com
ER  -

TY  - CONF
AU  - Jiménez-Zafra, S.M.
AU  - García-Baena, D.
AU  - García-Cumbreras, M.Á.
AU  - García-Vega, M.
TI  - SINAI at FinancES@IberLEF2023: Evaluating Popular Tools and Transformers Models for Financial Target Detection and Sentiment Analysis
PY  - 2023
T2  - CEUR Workshop Proceedings
VL  - 3496
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85175328718&partnerID=40&md5=25bf0227a1305045da26759a43748853
AD  - Computer Science Department, SINAI, CEATIC, Universidad de Jaén, 23071, Spain
AB  - This work presents the participation of the SINAI team at FinancES@IberLEF2023 shared task, Financial Targeted Sentiment Analysis in Spanish. We have addressed the two proposed tasks, consisting on identifying the main economic target from headlines of financial news for determining their sentiment polarity and identifying the sentiment polarity of each news headline towards both companies and consumers. For target detection, we have explored some popular tools as Stanza and spaCy, and different transformers models from Hugging Face and ChatGPT4. For sentiment analysis, we have evaluated some of the most popular transformers models and specific financial transformers. In total, 11 systems have participated (including the baseline provided by the organizers). The best run sent by our team have been placed in position 4th for Task1 and position 2nd for Task 2 with an F1-score of 0.7780 and 0.6349, respectively, being 0.7922 and 0.6423 the best results obtained in the competition for both tasks. © 2023 Copyright for this paper by its authors. Use permitted under Creative Commons License Attribution 4.0 International (CC BY 4.0).
KW  - financial multi-dimensional sentiment classification
KW  - financial target detection
KW  - machine translation
KW  - natural language processing
KW  - sentiment analysis
KW  - transformers
KW  - Finance
KW  - Financial multi-dimensional sentiment classification
KW  - Financial target detection
KW  - Language processing
KW  - Machine translations
KW  - Multi-dimensional sentiments
KW  - Natural language processing
KW  - Natural languages
KW  - Sentiment analysis
KW  - Sentiment classification
KW  - Targets detection
KW  - Transformer
KW  - Sentiment analysis
A2  - Montes-y-Gomez M.
A2  - Rangel F.
A2  - Jimenez-Zafra S.M.
A2  - Casavantes M.
A2  - Altuna B.
A2  - Alvarez-Carmona M.A.
A2  - Bel-Enguix G.
A2  - Chiruzzo L.
A2  - de la Iglesia I.
A2  - Escalante H.J.
A2  - Garcia-Cumbreras M.A.
A2  - Garcia-Diaz J.A.
A2  - Barba J.A.G.
A2  - Tamayo R.L.
A2  - Lima S.
A2  - Moral P.
A2  - del Arco F.M.P.
A2  - Valencia-Garcia R.
PB  - CEUR-WS
SN  - 16130073 (ISSN)
LA  - English
J2  - CEUR Workshop Proc.
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 0; Correspondence Address: S.M. Jiménez-Zafra; Computer Science Department, SINAI, CEATIC, Universidad de Jaén, 23071, Spain; email: sjzafra@ujaen.es; Conference name: 2023 Iberian Languages Evaluation Forum, IberLEF 2023; Conference code: 193167
ER  -

TY  - CONF
AU  - Da Costa, P.
AU  - Pavan, M.
AU  - Dos Santos, W.
AU  - Da Silva, S.
AU  - Paraboni, I.
TI  - BERTabaporu: Assessing a Genre-specific Language Model for Portuguese NLP
PY  - 2023
T2  - International Conference Recent Advances in Natural Language Processing, RANLP
SP  - 217
EP  - 223
DO  - 10.26615/978-954-452-092-2_024
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85179179041&doi=10.26615%2f978-954-452-092-2_024&partnerID=40&md5=c6cce3b3f0f31d0d3bdaca123b90acd2
AD  - School of Arts, Sciences and Humanities, University of São Paulo, Av Arlindo Bettio 1000, São Paulo, Brazil
AB  - Transformer-based language models such as Bidirectional Encoder Representations from Transformers (BERT) are now mainstream in the NLP field, but extensions to languages other than English, to new domains and/or to more specific text genres are still in demand. In this paper we introduced BERTabaporu, a BERT language model that has been pre-trained on Twitter data in the Brazilian Portuguese language. The model is shown to outperform the best-known general-purpose model for this language in three Twitter-related NLP tasks, making a potentially useful resource for Portuguese NLP in general. © 2023 Incoma Ltd. All rights reserved.
KW  - Natural language processing systems
KW  - Social networking (online)
KW  - Language model
KW  - Portuguese languages
KW  - Specific languages
KW  - Text genre
KW  - Computational linguistics
A2  - Angelova G.
A2  - Kunilovskaya M.
A2  - Mitkov R.
PB  - Incoma Ltd
SN  - 13138502 (ISSN); 978-954452092-2 (ISBN)
LA  - English
J2  - Int. Conf. Recent Adv. Nat. Lang. Proces., RANLP
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 1; Conference name: 2023 International Conference Recent Advances in Natural Language Processing: Large Language Models for Natural Language Processing, RANLP 2023; Conference date: 4 September 2023 through 6 September 2023; Conference code: 194755
ER  -

TY  - JOUR
AU  - Pursnani, V.
AU  - Sermet, Y.
AU  - Kurt, M.
AU  - Demir, I.
TI  - Performance of ChatGPT on the US fundamentals of engineering exam: Comprehensive assessment of proficiency and potential implications for professional environmental engineering practice
PY  - 2023
T2  - Computers and Education: Artificial Intelligence
VL  - 5
C7  - 100183
DO  - 10.1016/j.caeai.2023.100183
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85176244446&doi=10.1016%2fj.caeai.2023.100183&partnerID=40&md5=624c18d3bdfeb978fd73e1143f76e465
AD  - IIHR – Hydroscience & Engineering, University of Iowa, Iowa City, IA, United States
AD  - College of Law, University of Iowa, Iowa City, IA, United States
AD  - Civil and Environmental Engineering, University of Iowa, Iowa City, IA, United States
AD  - Electrical and Computer Engineering, University of Iowa, Iowa City, IA, United States
AB  - In recent years, advancements in artificial intelligence (AI) have led to the development of large language models like GPT-4, demonstrating potential applications in various fields, including education. This study investigates the feasibility and effectiveness of using ChatGPT, a GPT-4 based model, in achieving satisfactory performance on the Fundamentals of Engineering (FE) Environmental Exam. This study further shows a significant improvement in the model's accuracy when answering FE exam questions through noninvasive prompt modifications, substantiating the utility of prompt modification as a viable approach to enhance AI performance in educational contexts. Furthermore, the findings reflect remarkable improvements in mathematical capabilities across successive iterations of ChatGPT models, showcasing their potential in solving complex engineering problems. Our paper also explores future research directions, emphasizing the importance of addressing AI challenges in education, enhancing accessibility and inclusion for diverse student populations, and developing AI-resistant exam questions to maintain examination integrity. By evaluating the performance of ChatGPT in the context of the FE Environmental Exam, this study contributes valuable insights into the potential applications and limitations of large language models in educational settings. As AI continues to evolve, these findings offer a foundation for further research into the responsible and effective integration of AI models across various disciplines, ultimately optimizing the learning experience and improving student outcomes. © 2023 The Authors
KW  - AI in education
KW  - ChatGPT
KW  - Fundamentals of engineering exam
KW  - Large language models (LLMs)
KW  - Prompt modification techniques
KW  - Responsible AI integration
KW  - Computational linguistics
KW  - Education computing
KW  - Engineering education
KW  - Artificial intelligence in education
KW  - ChatGPT
KW  - Exam questions
KW  - Fundamental of engineering exam
KW  - Intelligence integration
KW  - Language model
KW  - Large language model
KW  - Performance
KW  - Prompt modification technique
KW  - Responsible artificial intelligence integration
KW  - Students
PB  - Elsevier B.V.
SN  - 2666920X (ISSN)
LA  - English
J2  - Comput. Educ.
M3  - Article
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 1; Correspondence Address: Y. Sermet; IIHR – Hydroscience & Engineering, University of Iowa, Iowa City, 300 S. Riverside Dr., 52246, United States; email: msermet@uiowa.edu
ER  -

TY  - CONF
AU  - Zhao, X.
AU  - Durmus, E.
AU  - Yeung, D.-Y.
TI  - Towards Reference-free Text Simplification Evaluation with a BERT Siamese Network Architecture
PY  - 2023
T2  - Proceedings of the Annual Meeting of the Association for Computational Linguistics
SP  - 13250
EP  - 13264
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85175417449&partnerID=40&md5=b012f9ea83a203cd50dd430b76b20111
AD  - Stanford University, United States
AD  - HKUST, Hong Kong
AB  - Text simplification (TS) aims to modify sentences to make their both content and structure easier to understand. Traditional n-gram matching-based TS evaluation metrics heavily rely on the exact token match and human-annotated simplified sentences. In this paper, we present a novel neural-network-based reference-free TS metric BETS that leverages pre-trained contextualized language representation models and large-scale paraphrasing datasets to evaluate simplicity and meaning preservation. We show that our metric, without collecting any costly human simplification reference, correlates better than existing metrics with human judgments for the quality of both overall simplification (+7.7%) and its key aspects, i.e., comparative simplicity (+11.2%) and meaning preservation (+9.2%). © 2023 Association for Computational Linguistics.
KW  - Computational linguistics
KW  - Large dataset
KW  - Content and structure
KW  - Evaluation metrics
KW  - Free texts
KW  - Matchings
KW  - Model scale
KW  - N-grams
KW  - Network-based
KW  - Novel neural network
KW  - Reference-free
KW  - Representation model
KW  - Network architecture
PB  - Association for Computational Linguistics (ACL)
SN  - 0736587X (ISSN); 978-195942962-3 (ISBN)
LA  - English
J2  - Proc. Annu. Meet. Assoc. Comput Linguist.
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 1; Conference name: 61st Annual Meeting of the Association for Computational Linguistics, ACL 2023; Conference date: 9 July 2023 through 14 July 2023; Conference code: 192867
ER  -

TY  - JOUR
AU  - Alessandri-Bonetti, M.
AU  - Giorgino, R.
AU  - Naegeli, M.
AU  - Liu, H.Y.
AU  - Egro, F.M.
TI  - Assessing the Soft Tissue Infection Expertise of ChatGPT and Bard Compared to IDSA Recommendations
PY  - 2023
T2  - Annals of Biomedical Engineering
DO  - 10.1007/s10439-023-03372-1
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85174575862&doi=10.1007%2fs10439-023-03372-1&partnerID=40&md5=0f0ab14571f4c42eeb5640b3bbde0ce3
AD  - Department of Plastic Surgery, University of Pittsburgh Medical Center, 1350 Locust Street, Pittsburgh, G10315219, PA, United States
AD  - Residency Program in Orthopaedics and Traumatology, University of Milan, Milan, 20122, Italy
AD  - Department of Pathology, Beth Israel Deaconess Medical Center, Boston, MA, United States
AD  - Harvard Medical School, Boston, MA, United States
AB  - The aim of the study was to evaluate whether ChatGPT-3.5 and Bard provide safe and reliable medical answers to common topics related to soft tissue infections and their management according to the guidelines provided by the Infectious Disease Society of America (IDSA). IDSA’s abridged recommendations for soft tissue infections were identified on the IDSA official website. Twenty-five queries were entered into the LLMs as they appear on the IDSA website. To assess the concordance and precision of the LLMs’ responses with the IDSA guidelines, two infectious disease physicians independently compared and evaluated each response. This was done using a 5-point Likert scale, with 1 representing poor concordance and 5 excellent concordance, as adapted from the validated Global Quality Scale. The mean ± SD score for ChatGPT-generated responses was 4.34 ± 0.74, n = 25. This indicates that raters found the answers were good to excellent quality with the most important topics covered. Although some topics were not covered, the answers were in good concordance with the IDSA guidelines. The mean ± SD score for Bard-generate responses was 3.5 ± 1.2, n = 25, indicating moderate quality. Despite LLMs did not appear to provide wrong recommendations and covered most of the topics, the responses were often found to be generic, rambling, missing some details, and lacking actionability. As AI continues to evolve and researchers feed it with more extensive and diverse medical knowledge, it may be inching closer to becoming a reliable aid for clinicians, ultimately enhancing the accuracy of infectious disease diagnosis and management in the future. © 2023, The Author(s) under exclusive licence to Biomedical Engineering Society.
KW  - AI
KW  - Concordance
KW  - Guidelines
KW  - Infectious disease diagnosis
KW  - Soft tissue infections
KW  - Diagnosis
KW  - Diseases
KW  - Tissue
KW  - Actionability
KW  - Concordance
KW  - Disease diagnosis
KW  - Global quality
KW  - Guideline
KW  - Infectious disease
KW  - Infectious disease diagnose
KW  - Likert scale
KW  - Quality scale
KW  - Soft tissue infections
KW  - Websites
PB  - Springer
SN  - 00906964 (ISSN)
LA  - English
J2  - Ann Biomed Eng
M3  - Letter
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 1; Correspondence Address: R. Giorgino; Residency Program in Orthopaedics and Traumatology, University of Milan, Milan, 20122, Italy; email: riccardo.giorgino@unimi.it; CODEN: ABMEC
ER  -

TY  - CONF
AU  - Shrestha, K.M.
AU  - Wood, K.
AU  - Goodman, D.
AU  - Mistica, M.
TI  - Do We Need Subject Matter Experts? A Case Study of Measuring Up GPT-4 Against Scholars in Topic Evaluation
PY  - 2023
T2  - CEUR Workshop Proceedings
VL  - 3551
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85178326156&partnerID=40&md5=d38d61fd15e976604b9581985669d87f
AD  - University of Melbourne, Parkville VIC, Melbourne, 3010, Australia
AB  - Assessing the quality of topics extracted from large text datasets presents a significant challenge in the field of computational social science. This research examines the effectiveness of coherence metrics, the GPT-4 model, and evaluations by subject matter experts (SMEs) using a set of speeches by former Australian Prime Minister Malcolm Fraser. Our primary objective was to analyze the evolution of Fraser's rhetoric. By comparing topics identified by coherence metrics and GPT-4 to those deemed meaningful by SMEs, we found that GPT-4 not only performs on par with traditional coherence metrics but also offers a scalable alternative for comprehensive topic evaluations. However, SMEs provide unparalleled depth and contextual understanding, proving indispensable in situations demanding meticulous accuracy. In situations where SMEs aren't available, our approach does show that GPT-4 can be employed for topic evaluation, albeit with some margin of error.  © 2023 Copyright for this paper by its authors.
KW  - Coherence Metrics
KW  - Computational Social Science
KW  - Evaluation Metrics
KW  - GPT-4
KW  - Large Language Models (LLMs)
KW  - Latent Dirichlet Allocation (LDA)
KW  - Topic Modeling
KW  - Behavioral research
KW  - Large dataset
KW  - Statistics
KW  - Coherence metric
KW  - Computational social science
KW  - Evaluation metrics
KW  - GPT-4
KW  - Language model
KW  - Large language model
KW  - Latent Dirichlet allocation
KW  - Subject matter experts
KW  - Topic Modeling
KW  - Modeling languages
A2  - Bassignana E.
A2  - Brunato D.
A2  - Polignano M.
A2  - Ramponi A.
PB  - CEUR-WS
SN  - 16130073 (ISSN)
LA  - English
J2  - CEUR Workshop Proc.
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 0; Correspondence Address: K.M. Shrestha; University of Melbourne, Melbourne, Parkville VIC, 3010, Australia; email: k.manandharshrestha@unimelb.edu.au; Conference name: 7th Workshop on Natural Language for Artificial Intelligence, NL4AI 2023; Conference date: 6 November 2023 through 7 November 2023; Conference code: 194401
ER  -

TY  - JOUR
AU  - Lakdawala, N.
AU  - Channa, L.
AU  - Gronbeck, C.
AU  - Lakdawala, N.
AU  - Weston, G.
AU  - Sloan, B.
AU  - Feng, H.
TI  - Assessing the Accuracy and Comprehensiveness of ChatGPT in Offering Clinical Guidance for Atopic Dermatitis and Acne Vulgaris
PY  - 2023
T2  - JMIR Dermatology
VL  - 6
IS  - 1
C7  - e50409
DO  - 10.2196/50409
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85178384891&doi=10.2196%2f50409&partnerID=40&md5=0fd07fefe10710b3e5608cef456325b9
AD  - University of Connecticut, School of Medicine, Farmington, CT, United States
AD  - Department of Dermatology, University of Connecticut Health Center, Farmington, CT, United States
AD  - Ronald O. Perelman Department of Dermatology, New York University, New York, NY, United States
KW  - acne
KW  - acne vulgaris
KW  - advise
KW  - answer
KW  - answers
KW  - artificial intelligence
KW  - atopic dermatitis
KW  - automated
KW  - chatbot
KW  - chatbots
KW  - ChatGPT
KW  - clinical guidance
KW  - computer generated
KW  - conversational agent
KW  - conversational agents
KW  - counsel
KW  - counseling
KW  - dermatitis
KW  - dermatologic
KW  - dermatological
KW  - dermatology
KW  - guidance
KW  - natural language processing
KW  - NLP
KW  - recommendation
KW  - recommendations
KW  - response
KW  - responses
KW  - skin
PB  - JMIR Publications Inc.
SN  - 25620959 (ISSN)
LA  - English
J2  - JMIR. Dermatol.
M3  - Article
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 1; Correspondence Address: H. Feng; Department of Dermatology, University of Connecticut Health Center, Farmington, 21 South Rd, 06032, United States; email: haofeng625@gmail.com
ER  -

TY  - CONF
AU  - Kozlova, A.
AU  - Shevelev, D.
AU  - Fenogenova, A.
TI  - Fact-checking benchmark for the Russian Large Language Models
ST  - Факт-чекинг для улучшения языковых моделей на русском языке
PY  - 2023
T2  - Komp'juternaja Lingvistika i Intellektual'nye Tehnologii
IS  - 22
SP  - 278
EP  - 286
DO  - 10.28995/2075-7182-2023-22-267-277
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85175571373&doi=10.28995%2f2075-7182-2023-22-267-277&partnerID=40&md5=4c0710f92660bddb46cb8bbf8dca199a
AD  - SberDevices
AB  - Modern text-generative language models are rapidly developing. They produce text of high quality and are used in many real-world applications. However, they still have several limitations, for instance, the length of the context, degeneration processes, lack of logical structure, and facts consistency. In this work, we focus on the fact-checking problem applied to the output of the generative models on classical downstream tasks, such as paraphrasing, summarization, text style transfer, etc. We define the task of internal fact-checking, set the criteria for factual consistency, and present the novel dataset for this task for the Russian language. The benchmark for internal fact-checking and several baselines are also provided. We research data augmentation approaches to extend the training set and compare classification methods on different augmented data sets. © Dialogue 2023.All rights reserved.
KW  - fact-checking
KW  - factual consistency
KW  - lm
KW  - nlg
KW  - text generation
PB  - ABBYY PRODUCTION LLC
SN  - 22217932 (ISSN)
LA  - English
J2  - Komp'ut. Lingvist. Intellekt. Tehnol.
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 0; Conference name: 2023 Annual International Conference on Computational Linguistics and Intellectual Technologies, Dialogue 2023; Conference date: 14 June 2023 through 16 June 2023; Conference code: 193276
ER  -

TY  - CONF
AU  - Sultana, M.
AU  - Taylor, A.
AU  - Li, L.
AU  - Majumdar, S.
TI  - Towards Evaluation and Understanding of Large Language Models for Cyber Operation Automation
PY  - 2023
T2  - 2023 IEEE Conference on Communications and Network Security, CNS 2023
DO  - 10.1109/CNS59707.2023.10288677
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85177595501&doi=10.1109%2fCNS59707.2023.10288677&partnerID=40&md5=b00eaba11f8fc6b5b566c56f48332c0c
AD  - Defence Research and Development Canada, Ottawa, Canada
AD  - Concordia University, Montreal, Canada
AB  - Can foundational language models be useful in automating cybersecurity tasks? To address this open question, systematic and comprehensive evaluation of large language models (LLMs) across diverse cyber operational tasks (e.g., incident response, threat identification, forensic analysis, etc.), as well as understanding their risks and limitations, are crucial. A significant challenge lies in the absence of a standard benchmark dataset encompassing real-life cyber operational tasks that can be processed by LLMs. This paper tackles this challenge by conducting a preliminary study towards evaluation and understanding of LLMs for cyber operation automation. To that end, we first identify a list of defensive cyber operational tasks with increasing complexities and suggests the creation of new datasets to accomplish these tasks. Second, we review recent works leveraging LLMs for downstream cyber operational tasks to identify research gaps and open problems. Third, we propose a framework to understand and benchmark the cyber operational tasks to report potential solutions and research directions for the reliable evaluation of LLMs. Finally, this paper serves as an open call to the cybersecurity researchers and professionals to contribute to the development of an open-source evaluation framework paving the way for the trustworthy use of foundation models in cyber domain.  © 2023 IEEE.
KW  - autonomous cyber defence
KW  - benchmark dataset
KW  - cyber operational tasks
KW  - cyber security
KW  - natural language processing
KW  - Computational linguistics
KW  - Large dataset
KW  - Natural language processing systems
KW  - Petroleum reservoir evaluation
KW  - Risk assessment
KW  - Autonomous cybe defense
KW  - Benchmark datasets
KW  - Cybe operational task
KW  - Cyber security
KW  - Cyber-defense
KW  - Language model
KW  - Language processing
KW  - Natural language processing
KW  - Natural languages
KW  - Operational tasks
KW  - Cybersecurity
PB  - Institute of Electrical and Electronics Engineers Inc.
SN  - 979-835033945-1 (ISBN)
LA  - English
J2  - IEEE Conf. Commun. Netw. Secur., CNS
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 0; Conference name: 2023 IEEE Conference on Communications and Network Security, CNS 2023; Conference date: 2 October 2023 through 5 October 2023; Conference code: 193985
ER  -

TY  - CONF
AU  - Lemke, C.
AU  - Kirchner, K.
AU  - Anandarajah, L.
AU  - Herfurth, F.N.
TI  - Exploring the Student Perspective: Assessing Technology Readiness and Acceptance for Adopting Large Language Models in Higher Education
PY  - 2023
T2  - Proceedings of the European Conference on e-Learning, ECEL
VL  - 2023-October
SP  - 156
EP  - 164
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85179132345&partnerID=40&md5=a0a59cab7675f7ef54ad7c47b633bcd2
AD  - Business Information Systems, Berlin School of Economics and Law, Berlin, Germany
AD  - Department of Technology, Management and Economics, Technical University of Denmark, Lyngby, Denmark
AD  - Humboldt-Universität zu Berlin, Berlin, Germany
AB  - Digital technologies are changing and will continue to change how we learn and teach today and in the future. With the latest developments in the field of generative artificial intelligence (AI), particularly large language models (LLMs), the question of using AI-based tools in academic education is ruling the current discussions about the transformative impact of AI in higher education (HE). These discussions range from banning these technologies for learning and teaching in HE to guided study support. This study avoids taking up these multifarious and partly controversial debates. Instead, we show how students perceive using AI-based tools for automated text generation for their studies. Drawing on a synthesis of two theories: the 'Technology Readiness Index' (TRI) and 'Technology Acceptance Model' (TAM). The model is validated based on survey data collected among undergraduate first-semester students (N=111) of a computer science-related study programme in Germany in winter 2022/23. The students had to evaluate their relationship to that new technology focusing on their readiness for technology adoption and acceptance. By analysing the collected data with a partial least squares model, we find that the optimism toward the new technology positively influences technology acceptance, while discomfort with the technology negatively influences perceived ease of use. The paper concludes with recommendations for action for adopting LLMs in HE. A proper investment in building AI skills in academic teaching plays a valuable role in fostering the students' positive attitude and innovativeness towards this new technology. Additionally, there is a need for more education about the risks and challenges of using this technology to reduce the impact of factors such as discomfort on ease of use. This requires a factual discourse, away from the current hype-induced exaggerated and hyperbolic statements, for instance, in developing formal guidance for universities. © 2023 Academic Conferences Limited. All rights reserved.
KW  - Higher Education
KW  - Large Language Models
KW  - Student Perspective
KW  - Technology Acceptance
KW  - Technology Readiness
KW  - Computational linguistics
KW  - Education computing
KW  - Engineering education
KW  - Least squares approximations
KW  - 'current
KW  - Digital technologies
KW  - High educations
KW  - Language model
KW  - Large language model
KW  - Latest development
KW  - Learn+
KW  - Student perspectives
KW  - Technology acceptance
KW  - Technology readiness
KW  - Students
A2  - Johnston S.J.
A2  - Singh S.
PB  - Academic Conferences and Publishing International Limited
SN  - 20488637 (ISSN); 978-191458790-0 (ISBN)
LA  - English
J2  - Proc. Eur. Conf. e-Learn., ECEL
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 0; Conference name: 22nd European Conference on e- Learning, ECEL 2023; Conference date: 26 October 2023 through 27 October 2023; Conference code: 194594
ER  -

TY  - CONF
AU  - Fernandes, P.
AU  - Deutsch, D.
AU  - Finkelstein, M.
AU  - Riley, P.
AU  - Martins, A.F.T.
AU  - Neubig, G.
AU  - Garg, A.
AU  - Clark, J.H.
AU  - Freitag, M.
AU  - Firat, O.
TI  - The Devil is in the Errors: Leveraging Large Language Models for Fine-grained Machine Translation Evaluation
PY  - 2023
T2  - Conference on Machine Translation -  Proceedings
SP  - 1064
EP  - 1081
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85179127830&partnerID=40&md5=9fb59ffcff57b45cf3a1b4bd767ae86d
AD  - Google
AD  - Carnegie Mellon University, United States
AD  - Instituto Superior Técnico, Portugal
AD  - Instituto de Telecomunicações, Portugal
AD  - Unbabel, United States
AD  - Inspired Cognition
AB  - Automatic evaluation of machine translation (MT) is a critical tool driving the rapid iterative development of MT systems. While considerable progress has been made on estimating a single scalar quality score, current metrics lack the informativeness of more detailed schemes that annotate individual errors, such as Multidimensional Quality Metrics (MQM). In this paper, we help fill this gap by proposing AUTOMQM, a prompting technique which leverages the reasoning and in-context learning capabilities of large language models (LLMs) and asks them to identify and categorize errors in translations. We start by evaluating recent LLMs, such as PaLM and PaLM-2, through simple score prediction prompting, and we study the impact of labeled data through in-context learning and finetuning. We then evaluate AUTOMQM with PaLM-2 models, and we find that it improves performance compared to just prompting for scores (with particularly large gains for larger models) while providing interpretability through error spans that align with human annotations. © 2023 Association for Computational Linguistics.
KW  - Computational linguistics
KW  - Computer aided language translation
KW  - Iterative methods
KW  - Learning systems
KW  - Machine translation
KW  - 'current
KW  - Automatic evaluation
KW  - Context learning
KW  - Fine grained
KW  - In contexts
KW  - Iterative development
KW  - Language model
KW  - Machine translation evaluations
KW  - Machine translation systems
KW  - Machine translations
KW  - Errors
PB  - Association for Computational Linguistics
SN  - 27680983 (ISSN); 979-889176041-7 (ISBN)
LA  - English
J2  - Conf. Mach. Transl. Proc.
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 0; Correspondence Address: P. Fernandes; Carnegie Mellon University, United States; email: pfernand@cs.cmu.edu; Conference name: 8th Conference on Machine Translation, WMT 2023; Conference date: 6 December 2023 through 7 December 2023; Conference code: 194371
ER  -

TY  - JOUR
AU  - Yesmin, S.
TI  - Redesigning Tertiary Educational Evaluation with AI: A Task-Based Analysis of LIS Students’ Assessment on Written Tests and Utilizing ChatGPT at NSTU
PY  - 2023
T2  - Science and Technology Libraries
DO  - 10.1080/0194262X.2023.2269230
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85174858596&doi=10.1080%2f0194262X.2023.2269230&partnerID=40&md5=c8eff5477a02cfe17145fe920bfe0862
AD  - Institute of Information Sciences, Noakhali Science and Technology University, Noakhali, Bangladesh
AB  - The AI tool ChatGPT has shaken the academic system and challenges conventional teaching-learning methods. Using a mixed method approach, the author adopted a task-based analysis to measure the Library and Information Science (LIS) students’ academic performance and integrity during the Artificial Intelligence, especially the ChatGPT trend. A group of 32 LIS final-year students were purposively selected as they completed all the basic courses of their discipline. A one-day session was divided into two phases–a written exam and an assignment through ChatGPT–held at the Institute of Information Sciences (IIS), Noakhali Science and Technology University (NSTU). Both examinations were administered using a questionnaire including a series of 15 tasks. A faculty member of IIS was tasked with reviewing the gathered answer scripts voluntarily. Results showed that it is too difficult to rank students’ positions based on ChatGPT-generated tasks, as the participant who placed in 20th position (scored 5 out of 30) among 32 in the written examination, placed in 2nd position (scored 25) in ChatGPT-generated assignment. It is encouraging that the similarity indices (by Turnitin) reached up to 89%, which is unacceptable under university regulations. However, none of these assignments included in-text citations and references, which is questionable from the standpoint of academic ethics. © 2023 The Author(s). Published with license by Taylor & Francis Group, LLC.
KW  - AI tools
KW  - artificial intelligence
KW  - Bangladesh
KW  - ChatGPT
KW  - LIS education
KW  - Learning systems
KW  - Students
KW  - Academic challenges
KW  - AI tool
KW  - Bangladesh
KW  - ChatGPT
KW  - Educational evaluation
KW  - Library and information science
KW  - Library and information science educations
KW  - Science and Technology
KW  - Student assessment
KW  - Task-based
KW  - adult
KW  - article
KW  - artificial intelligence
KW  - Bangladesh
KW  - ChatGPT
KW  - education
KW  - ethics
KW  - female
KW  - human
KW  - human experiment
KW  - information science
KW  - male
KW  - questionnaire
KW  - Artificial intelligence
PB  - Routledge
SN  - 0194262X (ISSN)
LA  - English
J2  - Sci Technol Libr
M3  - Article
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 0; Correspondence Address: S. Yesmin; Institute of Information Sciences, Noakhali Science and Technology University, Noakhali, 3814, Bangladesh; email: shamima.iis@nstu.edu.bd; CODEN: STELD
ER  -

TY  - JOUR
AU  - Haq, I.
AU  - Qiu, W.
AU  - Guo, J.
AU  - Tang, P.
TI  - Pashto offensive language detection: a benchmark dataset and monolingual Pashto BERT
PY  - 2023
T2  - PeerJ Computer Science
VL  - 9
SP  - 1
EP  - 26
DO  - 10.7717/PEERJ-CS.1617
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85175080058&doi=10.7717%2fPEERJ-CS.1617&partnerID=40&md5=5d59196a36fa17241d5216860a68eee2
AD  - School of Cyber Science and Engineering, Shanghai Jiao Tong University, Minhang, Shanghai, China
AB  - Social media platforms have become inundated with offensive language. This issue must be addressed for the growth of online social networks (OSNs) and a healthy online environment. While significant research has been devoted to identifying toxic content in major languages like English, this remains an open area of research in the low-resource Pashto language. This study aims to develop an AI model for the automatic detection of offensive textual content in Pashto. To achieve this goal, we have developed a benchmark dataset called the Pashto Offensive Language Dataset (POLD), which comprises tweets collected from Twitter and manually classified into two categories: ‘‘offensive’’ and ‘‘not offensive’’. To discriminate these two categories, we investigated the classic deep learning classifiers based on neural networks, including CNNs and RNNs, using static word embeddings: Word2Vec, fastText, and GloVe as features. Furthermore, we examined two transfer learning approaches. In the first approach, we fine-tuned the pre-trained multilingual language model, XLM-R, using the POLD dataset, whereas, in the second approach, we trained a monolingual BERT model for Pashto from scratch using a custom-developed text corpus. Pashto BERT was then fine-tuned similarly to XLM-R. The performance of all the deep learning and transformer learning models was evaluated using the POLD dataset. The experimental results demonstrate that our pre-trained Pashto BERT model outperforms the other models, achieving an F1-score of 94.34% and an accuracy of 94.77%. © 2023 Haq et al.
KW  - BERT
KW  - Large language models
KW  - LLMs
KW  - Low-resource languages
KW  - NLP
KW  - Offensive language detection
KW  - Osn
KW  - Pashto
KW  - Social media
KW  - Text processing
KW  - Computational linguistics
KW  - Deep learning
KW  - Large dataset
KW  - Learning systems
KW  - Natural language processing systems
KW  - Social networking (online)
KW  - Transfer learning
KW  - BERT
KW  - Language detection
KW  - Language model
KW  - Large language model
KW  - LLM
KW  - Low resource languages
KW  - Offensive language detection
KW  - Offensive languages
KW  - Osn
KW  - Pashto
KW  - Social media
KW  - Text-processing
KW  - Text processing
PB  - PeerJ Inc.
SN  - 23765992 (ISSN)
LA  - English
J2  - PeerJ Comput. Sci.
M3  - Article
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 1; Correspondence Address: I. Haq; School of Cyber Science and Engineering, Shanghai Jiao Tong University, Shanghai, Minhang, China; email: hanjie@sjtu.edu.cn
ER  -

TY  - CONF
AU  - Berbatova, M.
AU  - Salambashev, Y.
TI  - Evaluating Hallucinations in Large Language Models for Bulgarian Language
PY  - 2023
T2  - International Conference Recent Advances in Natural Language Processing, RANLP
SP  - 55
EP  - 63
DO  - 10.26615/issn.2603-2821.2023_006
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85179132981&doi=10.26615%2fissn.2603-2821.2023_006&partnerID=40&md5=032a239a80af384df92060fe2ed219f6
AD  - Sofia University’St. Kliment Ohridski’ Sofia University’St. Kliment Ohridski’, Bulgaria
AB  - In this short paper, we introduce the task of evaluating the hallucination of large language models for the Bulgarian language. We first give definitions of what is a hallucination in large language models and what evaluation methods for measuring hallucinations exist. Next, we give an overview of the multilingual evaluation of the latest large language models, focusing on the evaluation of the performance in Bulgarian on tasks, related to hallucination. We then present a method to evaluate the level of hallucination in a given language with no reference data, and provide some initial experiments with this method in Bulgarian. Finally, we provide directions for future research on the topic. © 2023 Incoma Ltd. All rights reserved.
KW  - Evaluation methods
KW  - Language model
KW  - No-reference
KW  - Performance
KW  - Reference data
KW  - Computational linguistics
A2  - Hardalov M.
A2  - Kancheva Z.
A2  - Velichkov B.
A2  - Nikolova-Koleva I.
A2  - Slavcheva M.
PB  - Incoma Ltd
SN  - 13138502 (ISSN)
LA  - English
J2  - Int. Conf. Recent Adv. Nat. Lang. Proces., RANLP
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 0; Conference name: 8th Student Research Workshop, RANLPStud 2023; Conference date: 4 September 2023 through 6 September 2023; Conference code: 194751
ER  -

TY  - CONF
AU  - Hirunyasiri, D.
AU  - Thomas, D.R.
AU  - Lin, J.
AU  - Koedinger, K.R.
AU  - Aleven, V.
TI  - Comparative Analysis of GPT-4 and Human Graders in Evaluating Praise Given to Students in Synthetic Dialogues
PY  - 2023
T2  - CEUR Workshop Proceedings
VL  - 3491
SP  - 37
EP  - 48
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85174920490&partnerID=40&md5=68194ca299f272af26ed5c4e8d93e932
AD  - Carnegie Mellon University, Pittsburgh, 15213, PA, United States
AB  - Research suggests that providing specific and timely feedback to human tutors enhances their performance. However, it presents challenges due to the time-consuming nature of assessing tutor performance by human evaluators. Large language models, such as the AI-chatbot ChatGPT, hold potential for offering constructive feedback to tutors in practical settings. Nevertheless, the accuracy of AI-generated feedback remains uncertain, with scant research investigating the ability of models like ChatGPT to deliver effective feedback. In this work-in-progress, we evaluate 30 dialogues generated by GPT-4 in a tutor-student setting. We use two different prompting approaches, the zero-shot chain of thought and the few-shot chain of thought, to identify specific components of effective praise based on five criteria. These approaches are then compared to the results of human graders for accuracy. Our goal is to assess the extent to which GPT-4 can accurately identify each praise criterion. We found that both zero-shot and few-shot chain of thought approaches yield comparable results. GPT-4 performs moderately well in identifying instances when the tutor offers specific and immediate praise. However, GPT-4 underperforms in identifying the tutor’s ability to deliver sincere praise, particularly in the zero-shot prompting scenario where examples of sincere tutor praise statements were not provided. Future work will focus on enhancing prompt engineering, developing a more general tutoring rubric, and evaluating our method using real-life tutoring dialogues. © 2023 Copyright for this paper by its authors.
KW  - ChatGPT
KW  - GPT-4
KW  - Math tutors
KW  - Real-time Feedback
KW  - Tutor Evaluation
KW  - Tutor Feedback
KW  - Tutor Training
KW  - Students
KW  - ChatGPT
KW  - Comparative analyzes
KW  - GPT-4
KW  - Math tutor
KW  - Performance
KW  - Real-time feedback
KW  - Timely feedback
KW  - Tutor evaluation
KW  - Tutor feedback
KW  - Tutor training
KW  - Zero-shot learning
A2  - Thomas D.R.
A2  - Lin J.
A2  - Koedinger K.R.
PB  - CEUR-WS
SN  - 16130073 (ISSN)
LA  - English
J2  - CEUR Workshop Proc.
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 0; Correspondence Address: D. Hirunyasiri; Carnegie Mellon University, Pittsburgh, 15213, United States; email: dhirunya@andrew.cmu.edu; Conference name: 2023 Workshop on International Conference of Artificial Intelligence in Education, AIED Human-AI Tutoring 2023; Conference code: 192800
ER  -

TY  - CONF
AU  - Jahan, I.
AU  - Laskar, M.T.R.
AU  - Peng, C.
AU  - Huang, J.X.
TI  - Evaluation of ChatGPT on Biomedical Tasks: A Zero-Shot Comparison with Fine-Tuned Generative Transformers
PY  - 2023
T2  - Proceedings of the Annual Meeting of the Association for Computational Linguistics
SP  - 326
EP  - 336
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85174544558&partnerID=40&md5=9eb6e0f5896858d8c2d0154e0f1bf2b0
AD  - Department of Biology, York University, Canada
AD  - School of Information Technology, York University, Canada
AD  - Information Retrieval and Knowledge Management Research Lab, York University, Canada
AD  - Dialpad Canada Inc, Toronto, ON, Canada
AB  - ChatGPT is a large language model developed by OpenAI1. Despite its impressive performance across various tasks, no prior work has investigated its capability in the biomedical domain yet. To this end, this paper aims to evaluate the performance of ChatGPT on various benchmark biomedical tasks, such as relation extraction, document classification, question answering, and summarization. To the best of our knowledge, this is the first work that conducts an extensive evaluation of ChatGPT in the biomedical domain. Interestingly, we find based on our evaluation that in biomedical datasets that have smaller training sets, zero-shot ChatGPT even outperforms the state-ofthe-art fine-tuned generative transformer models, such as BioGPT and BioBART. This suggests that ChatGPT’s pre-training on large text corpora makes it quite specialized even in the biomedical domain. Our findings demonstrate that ChatGPT has the potential to be a valuable tool for various tasks in the biomedical domain that lack large annotated data. © 2023 Association for Computational Linguistics.
KW  - Classification (of information)
KW  - Computational linguistics
KW  - Information retrieval systems
KW  - Natural language processing systems
KW  - Zero-shot learning
KW  - Biomedical domain
KW  - Classification questions
KW  - Document Classification
KW  - Language model
KW  - Performance
KW  - Question Answering
KW  - Relation extraction
KW  - Small training
KW  - Training sets
KW  - Transformer modeling
KW  - Benchmarking
A2  - Demner-fushman D.
A2  - Ananiadou S.
A2  - Cohen K.
PB  - Association for Computational Linguistics (ACL)
SN  - 0736587X (ISSN); 978-195942985-2 (ISBN)
LA  - English
J2  - Proc. Annu. Meet. Assoc. Comput Linguist.
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 3; Conference name: 22nd Workshop on Biomedical Natural Language Processing and BioNLP Shared Tasks, BioNLP 2023; Conference code: 193153
ER  -

TY  - JOUR
AU  - Hasani, A.M.
AU  - Singh, S.
AU  - Zahergivar, A.
AU  - Ryan, B.
AU  - Nethala, D.
AU  - Bravomontenegro, G.
AU  - Mendhiratta, N.
AU  - Ball, M.
AU  - Farhadi, F.
AU  - Malayeri, A.
TI  - Evaluating the performance of Generative Pre-trained Transformer-4 (GPT-4) in standardizing radiology reports
PY  - 2023
T2  - European Radiology
DO  - 10.1007/s00330-023-10384-x
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85176101741&doi=10.1007%2fs00330-023-10384-x&partnerID=40&md5=95fc502955ec669a4285867b78efb089
AD  - Laboratory of Translation Research, National Heart Blood Lung Institute, NIH, Bethesda, MD, United States
AD  - Radiology & Imaging Sciences Department, Clinical Center, NIH, Bethesda, MD, United States
AD  - Urology Oncology Branch, National Cancer Institute, NIH, Bethesda, MD, United States
AB  - Objective: Radiology reporting is an essential component of clinical diagnosis and decision-making. With the advent of advanced artificial intelligence (AI) models like GPT-4 (Generative Pre-trained Transformer 4), there is growing interest in evaluating their potential for optimizing or generating radiology reports. This study aimed to compare the quality and content of radiologist-generated and GPT-4 AI-generated radiology reports. Methods: A comparative study design was employed in the study, where a total of 100 anonymized radiology reports were randomly selected and analyzed. Each report was processed by GPT-4, resulting in the generation of a corresponding AI-generated report. Quantitative and qualitative analysis techniques were utilized to assess similarities and differences between the two sets of reports. Results: The AI-generated reports showed comparable quality to radiologist-generated reports in most categories. Significant differences were observed in clarity (p = 0.027), ease of understanding (p = 0.023), and structure (p = 0.050), favoring the AI-generated reports. AI-generated reports were more concise, with 34.53 fewer words and 174.22 fewer characters on average, but had greater variability in sentence length. Content similarity was high, with an average Cosine Similarity of 0.85, Sequence Matcher Similarity of 0.52, BLEU Score of 0.5008, and BERTScore F1 of 0.8775. Conclusion: The results of this proof-of-concept study suggest that GPT-4 can be a reliable tool for generating standardized radiology reports, offering potential benefits such as improved efficiency, better communication, and simplified data extraction and analysis. However, limitations and ethical implications must be addressed to ensure the safe and effective implementation of this technology in clinical practice. Clinical relevance statement: The findings of this study suggest that GPT-4 (Generative Pre-trained Transformer 4), an advanced AI model, has the potential to significantly contribute to the standardization and optimization of radiology reporting, offering improved efficiency and communication in clinical practice. Key Points: • Large language model–generated radiology reports exhibited high content similarity and moderate structural resemblance to radiologist-generated reports. • Performance metrics highlighted the strong matching of word selection and order, as well as high semantic similarity between AI and radiologist-generated reports. • Large language model demonstrated potential for generating standardized radiology reports, improving efficiency and communication in clinical settings. © 2023, This is a U.S. Government work and not under copyright protection in the US; foreign copyright protection may apply.
KW  - Artificial intelligence
KW  - Digital health
KW  - Machine learning
KW  - Natural language processing
KW  - article
KW  - artificial intelligence
KW  - clinical practice
KW  - clinical significance
KW  - comparative study
KW  - controlled study
KW  - data extraction
KW  - generative pretrained transformer
KW  - human
KW  - human experiment
KW  - machine learning
KW  - natural language processing
KW  - performance indicator
KW  - proof of concept
KW  - qualitative analysis
KW  - quantitative analysis
KW  - radiologist
KW  - radiology
KW  - randomized controlled trial
KW  - standardization
PB  - Springer Science and Business Media Deutschland GmbH
SN  - 09387994 (ISSN)
LA  - English
J2  - Eur. Radiol.
M3  - Article
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 1; Correspondence Address: A. Malayeri; Radiology & Imaging Sciences Department, Clinical Center, NIH, Bethesda, United States; email: Ashkan.Malayeri@nih.gov; CODEN: EURAE
ER  -

TY  - JOUR
AU  - Ali, A.
AU  - Wibowo, K.
TI  - Assessment of ChatGPT-generated programming code based on exercises in an introductory programming course
PY  - 2023
T2  - Issues in Information Systems
VL  - 24
IS  - 2
SP  - 203
EP  - 212
DO  - 10.48009/2_iis_2023_117
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85174246759&doi=10.48009%2f2_iis_2023_117&partnerID=40&md5=9c94a03dba9facda8614bf164f2b3d19
AD  - Indiana University of Pennsylvania, United States
AB  - This study aims to assess the quality of the programming code generated by ChatGPT and compare it to the programming code used in an introductory programming course. ChatGPT is a software that produces programming code based on descriptions entered by users. Our study compares this generated code with a code we use in our programming course for the same programming exercises. ChatGPT is not a single software, and it is built from scratch. Instead, ChatGPT is built on a multitude of software that all contribute to the development of ChatGPT. This multitude of technologies falls under a general term called “OpenAI”. To better understand the generated code and the assessment we intend to provide in this study, knowing these technologies that preceded ChatGPT and contributed to its formation will be helpful. Thus, we provide a literature review of the technologies that started before ChatGPT and then compare the code generated by ChatGPT with the code that we use in our course for the same assignments or problems. © 2023 The Journal of Feminist Studies in Religion, Inc.
KW  - ChatGPT
KW  - generated programming code
KW  - programming
KW  - programming code
PB  - International Association for Computer Information Systems
SN  - 15297314 (ISSN)
LA  - English
J2  - Issue. Inf. Syst.
M3  - Article
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 0
ER  -

TY  - CONF
AU  - He, Y.
AU  - Wu, Y.
AU  - Jia, Y.
AU  - Mihalcea, R.
AU  - Chen, Y.
AU  - Deng, N.
TI  - HI-TOM: A Benchmark for Evaluating Higher-Order Theory of Mind Reasoning in Large Language Models
PY  - 2023
T2  - Findings of the Association for Computational Linguistics: EMNLP 2023
SP  - 10691
EP  - 10706
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85175953987&partnerID=40&md5=9232b5eb5412e810f8ad857ce77c3c12
AD  - University of Michigan Westlake University
AB  - Theory of Mind (ToM) is the ability to reason about one's own and others' mental states. ToM plays a critical role in the development of intelligence, language understanding, and cognitive processes. While previous work has primarily focused on first and second-order ToM, we explore higher-order ToM, which involves recursive reasoning on others' beliefs. We introduce HI-TOM, a Higher Order Theory of Mind benchmark. Our experimental evaluation using various Large Language Models (LLMs) indicates a decline in performance on higher-order ToM tasks, demonstrating the limitations of current LLMs. We conduct a thorough analysis of different failure cases of LLMs, and share our thoughts on the implications of our findings on the future of NLP. © 2023 Association for Computational Linguistics.
KW  - Cognitive process
KW  - First order theories
KW  - High-order theory
KW  - Higher-order theory
KW  - Language model
KW  - Language understanding
KW  - Mental state
KW  - Recursive reasonings
KW  - Second-order theory
KW  - Theory of minds
KW  - Computational linguistics
PB  - Association for Computational Linguistics (ACL)
SN  - 979-889176061-5 (ISBN)
LA  - English
J2  - Find. Assoc. Comput. Linguist.: EMNLP
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 1; Correspondence Address: N. Deng; email: dnaihao@umich.edu; Conference name: 2023 Findings of the Association for Computational Linguistics: EMNLP 2023; Conference date: 6 December 2023 through 10 December 2023; Conference code: 196127
ER  -

TY  - CONF
AU  - Pannitto, L.
AU  - Herbelot, A.
TI  - CALaMo: a Constructionist Assessment of Language Models
PY  - 2023
T2  - CxGsNLP 2023 - 1st International Workshop on Construction Grammars and NLP (CxGs+NLP, GURT/SyntaxFest 2023), Proceedings of the Conference
SP  - 21
EP  - 30
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85174520707&partnerID=40&md5=1b9e072548f8bfbc2a81fcddbff4b3ae
AD  - CIMeC, University of Trento, Italy
AD  - CIMeC, DISI, University of Trento, Italy
AB  - This paper presents a novel framework for evaluating Neural Language Models’ linguistic abilities using a constructionist approach. Not only is the usage-based model in line with the underlying stochastic philosophy of neural architectures, but it also allows the linguist to keep meaning as a determinant factor in the analysis. We outline the framework and present two possible scenarios for its application. © 2023 Association for Computational Linguistics.
KW  - Computational linguistics
KW  - Stochastic models
KW  - Determinant factors
KW  - ITS applications
KW  - Language model
KW  - Neural architectures
KW  - Stochastics
KW  - Stochastic systems
PB  - Association for Computational Linguistics
SN  - 978-195942935-7 (ISBN)
LA  - English
J2  - CxGsNLP - Int. Workshop Constr. Grammars (NLP, CxGs+NLP, GURT/SyntaxFest), Proc. Conf.
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 0; Conference name: 1st International Workshop on Construction Grammars and NLP (CxGs+NLP, GURT/SyntaxFest 2023), CxGsNLP 2023; Conference date: 9 March 2023 through 12 March 2023; Conference code: 192804
ER  -

TY  - JOUR
AU  - Hirosawa, T.
AU  - Kawamura, R.
AU  - Harada, Y.
AU  - Mizuta, K.
AU  - Tokumasu, K.
AU  - Kaji, Y.
AU  - Suzuki, T.
AU  - Shimizu, T.
TI  - ChatGPT-Generated Differential Diagnosis Lists for Complex Case–Derived Clinical Vignettes: Diagnostic Accuracy Evaluation
PY  - 2023
T2  - JMIR Medical Informatics
VL  - 11
C7  - e48808
DO  - 10.2196/48808
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85176744232&doi=10.2196%2f48808&partnerID=40&md5=c3d88ebac18cca438b087564083c5c1a
AD  - Department of Diagnostic and Generalist Medicine, Dokkyo Medical University, Tochigi, Japan
AD  - Department of General Medicine, Okayama University Graduate School of Medicine, Dentistry and Pharmaceutical Sciences, Okayama, Japan
AD  - Department of General Medicine, International University of Health, Welfare Narita Hospital, Chiba, Japan
AD  - Department of Hospital Medicine, Urasoe General Hospital, Okinawa, Japan
AB  - Background: The diagnostic accuracy of differential diagnoses generated by artificial intelligence chatbots, including ChatGPT models, for complex clinical vignettes derived from general internal medicine (GIM) department case reports is unknown. Objective: This study aims to evaluate the accuracy of the differential diagnosis lists generated by both third-generation ChatGPT (ChatGPT-3.5) and fourth-generation ChatGPT (ChatGPT-4) by using case vignettes from case reports published by the Department of GIM of Dokkyo Medical University Hospital, Japan. Methods: We searched PubMed for case reports. Upon identification, physicians selected diagnostic cases, determined the final diagnosis, and displayed them into clinical vignettes. Physicians typed the determined text with the clinical vignettes in the ChatGPT-3.5 and ChatGPT-4 prompts to generate the top 10 differential diagnoses. The ChatGPT models were not specially trained or further reinforced for this task. Three GIM physicians from other medical institutions created differential diagnosis lists by reading the same clinical vignettes. We measured the rate of correct diagnosis within the top 10 differential diagnosis lists, top 5 differential diagnosis lists, and the top diagnosis. Results: In total, 52 case reports were analyzed. The rates of correct diagnosis by ChatGPT-4 within the top 10 differential diagnosis lists, top 5 differential diagnosis lists, and top diagnosis were 83% (43/52), 81% (42/52), and 60% (31/52), respectively. The rates of correct diagnosis by ChatGPT-3.5 within the top 10 differential diagnosis lists, top 5 differential diagnosis lists, and top diagnosis were 73% (38/52), 65% (34/52), and 42% (22/52), respectively. The rates of correct diagnosis by ChatGPT-4 were comparable to those by physicians within the top 10 (43/52, 83% vs 39/52, 75%, respectively; P=.47) and within the top 5 (42/52, 81% vs 35/52, 67%, respectively; P=.18) differential diagnosis lists and top diagnosis (31/52, 60% vs 26/52, 50%, respectively; P=.43) although the difference was not significant. The ChatGPT models’ diagnostic accuracy did not significantly vary based on open access status or the publication date (before 2011 vs 2022). Conclusions: This study demonstrates the potential diagnostic accuracy of differential diagnosis lists generated using ChatGPT-3.5 and ChatGPT-4 for complex clinical vignettes from case reports published by the GIM department. The rate of correct diagnoses within the top 10 and top 5 differential diagnosis lists generated by ChatGPT-4 exceeds 80%. Although derived from a limited data set of case reports from a single department, our findings highlight the potential utility of ChatGPT-4 as a supplementary tool for physicians, particularly for those affiliated with the GIM department. Further investigations should explore the diagnostic accuracy of ChatGPT by using distinct case materials beyond its training data. Such efforts will provide a comprehensive insight into the role of artificial intelligence in enhancing clinical decision-making. ©Takanobu Hirosawa, Ren Kawamura, Yukinori Harada, Kazuya Mizuta, Kazuki Tokumasu, Yuki Kaji, Tomoharu Suzuki, Taro Shimizu.
KW  - accuracy
KW  - AI chatbot
KW  - artificial intelligence
KW  - case study
KW  - ChatGPT
KW  - clinical decision support
KW  - decision support
KW  - diagnosis
KW  - diagnostic
KW  - diagnostic excellence
KW  - language model
KW  - large language models
KW  - natural language processing
KW  - vignette
PB  - JMIR Publications Inc.
SN  - 22919694 (ISSN)
LA  - English
J2  - JMIR Med. Inform.
M3  - Article
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 3; Correspondence Address: T. Hirosawa; Department of Diagnostic and Generalist Medicine Dokkyo Medical University, Tochigi, 880 Kitakobayashi, Mibu-cho Shimotsuga, 321-0293, Japan; email: hirosawa@dokkyomed.ac.jp
ER  -

TY  - CONF
AU  - Dong, G.
AU  - Zhao, J.
AU  - Hui, T.
AU  - Guo, D.
AU  - Wang, W.
AU  - Feng, B.
AU  - Qiu, Y.
AU  - Gongque, Z.
AU  - He, K.
AU  - Wang, Z.
AU  - Xu, W.
TI  - Revisit Input Perturbation Problems for LLMs: A Unified Robustness Evaluation Framework for Noisy Slot Filling Task
PY  - 2023
T2  - Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)
VL  - 14302 LNAI
SP  - 682
EP  - 694
DO  - 10.1007/978-3-031-44693-1_53
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85174743837&doi=10.1007%2f978-3-031-44693-1_53&partnerID=40&md5=8a950063e58fa5399792dc2ce785b1c5
AD  - Beijing University of Posts and Telecommunications, Beijing, China
AD  - Meituan Group, Beijing, China
AB  - With the increasing capabilities of large language models (LLMs), these high-performance models have achieved state-of-the-art results on a wide range of natural language processing (NLP) tasks. However, the models’ performance on commonly-used benchmark datasets often fails to accurately reflect their reliability and robustness when applied to real-world noisy data. To address these challenges, we propose a unified robustness evaluation framework based on the slot-filling task to systematically evaluate the dialogue understanding capability of LLMs in diverse input perturbation scenarios. Specifically, we construct a input perturbation evaluation dataset, Noise-LLM, which contains five types of single perturbation and four types of mixed perturbation data. Furthermore, we utilize a multi-level data augmentation method (character, word, and sentence levels) to construct a candidate data pool, and carefully design two ways of automatic task demonstration construction strategies (instance-level and entity-level) with various prompt templates. Our aim is to assess how well various robustness methods of LLMs perform in real-world noisy scenarios. The experiments have demonstrated that the current open-source LLMs generally achieve limited perturbation robustness performance. Based on these experimental observations, we make some forward-looking suggestions to fuel the research in this direction (The code is available at https://github.com/ZhaoJin-xu/A-Unified-Robustness-Evaluation-Fram ework-for-Noisy-Slot-Filling-Task ). © 2023, The Author(s), under exclusive license to Springer Nature Switzerland AG.
KW  - Input perturbation
KW  - Large language models
KW  - Robustness evaluation
KW  - Slot filling
KW  - Computational linguistics
KW  - Filling
KW  - Natural language processing systems
KW  - Evaluation framework
KW  - High performance modeling
KW  - Input perturbation
KW  - Language model
KW  - Large language model
KW  - Perturbation problems
KW  - Real-world
KW  - Robustness evaluation
KW  - Slot filling
KW  - State of the art
KW  - Benchmarking
A2  - Liu F.
A2  - Duan N.
A2  - Xu Q.
A2  - Hong Y.
PB  - Springer Science and Business Media Deutschland GmbH
SN  - 03029743 (ISSN); 978-303144692-4 (ISBN)
LA  - English
J2  - Lect. Notes Comput. Sci.
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 1; Correspondence Address: W. Xu; Beijing University of Posts and Telecommunications, Beijing, China; email: xuweiran@bupt.edu.cn; Conference name: 12th National CCF Conference on Natural Language Processing and Chinese Computing, NLPCC 2023; Conference date: 12 October 2023 through 15 October 2023; Conference code: 302309
ER  -

TY  - CONF
AU  - Chiang, C.-H.
AU  - Lee, H.-Y.
TI  - A Closer Look into Automatic Evaluation Using Large Language Models
PY  - 2023
T2  - Findings of the Association for Computational Linguistics: EMNLP 2023
SP  - 8928
EP  - 8942
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85175604040&partnerID=40&md5=1cc536e756bb1d2f12cf4d96ddc5f5b2
AD  - National Taiwan University, Taiwan
AB  - Using large language models (LLMs) to evaluate text quality has recently gained popularity. Some prior works explore the idea of using LLMs for evaluation, while they differ in some details of the evaluation process. In this paper, we analyze LLM evaluation (Chiang and Lee, 2023) and G-Eval (Liu et al., 2023), and we discuss how those details in the evaluation process change how well the ratings given by LLMs correlate with human ratings. We find that the auto Chain-of-Thought (CoT) used in G-Eval does not always make G-Eval more aligned with human ratings. We also show that forcing the LLM to output only a numeric rating, as in G-Eval, is suboptimal. Last, we reveal that asking the LLM to explain its own ratings consistently improves the correlation between the ChatGPT and human ratings and pushes state-of-the-art (SoTA) correlations on two meta-evaluation datasets. © 2023 Association for Computational Linguistics.
KW  - Computational linguistics
KW  - Petroleum reservoir evaluation
KW  - Automatic evaluation
KW  - Forcings
KW  - Language model
KW  - Model evaluation
KW  - Output only
KW  - Process change
KW  - State of the art
KW  - Text qualities
KW  - Quality control
PB  - Association for Computational Linguistics (ACL)
SN  - 979-889176061-5 (ISBN)
LA  - English
J2  - Find. Assoc. Comput. Linguist.: EMNLP
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 0; Conference name: 2023 Findings of the Association for Computational Linguistics: EMNLP 2023; Conference date: 6 December 2023 through 10 December 2023; Conference code: 196127
ER  -

TY  - CONF
AU  - Kapur, N.
AU  - Rangel, A.
AU  - Pentecost, L.
TI  - CompressionGPT: Evaluating Fault Tolerance of a Compressed Large Language Model
PY  - 2023
T2  - Proceedings - 2023 IEEE International Symposium on Workload Characterization, IISWC 2023
SP  - 232
EP  - 234
DO  - 10.1109/IISWC59245.2023.00033
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85177592269&doi=10.1109%2fIISWC59245.2023.00033&partnerID=40&md5=0fa454172b869e1fbd9dfed323f78f80
AD  - Amherst College, United States
AB  - Deep neural networks (DNNs) currently require large amounts of memory to store weights. Consequently, inference is less efficient given that weights must be stored off-chip on DRAM, resulting in costly memory accesses. While compression techniques, including quantization and pruning, can significantly reduce model size, current memory technologies are unable to store compressed DNNs on-chip. Prior works have proposed multi-level cell emerging non-volatile memory technologies as a solution given their ability to store bits densely on-chip. While these memory technologies are fault prone, having higher bit error rates, it has been demonstrated that DNNs exhibit some fault tolerance. We build on previous work by examining the fault tolerance of a pruned and quantized large language model (LLM).  © 2023 IEEE.
KW  - Computational linguistics
KW  - Deep neural networks
KW  - Dynamic random access storage
KW  - 'current
KW  - Compression techniques
KW  - Language model
KW  - Large amounts
KW  - Memory access
KW  - Memory technology
KW  - Model size
KW  - Networks on chips
KW  - Off-chip
KW  - Quantisation
KW  - Fault tolerance
PB  - Institute of Electrical and Electronics Engineers Inc.
SN  - 979-835030317-9 (ISBN)
LA  - English
J2  - Proc. - IEEE Int. Symp. Workload Charact., IISWC
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 0; Conference name: 26th IEEE International Symposium on Workload Characterization, IISWC 2023; Conference date: 1 October 2023 through 3 October 2023; Conference code: 193984
ER  -

TY  - CONF
AU  - Agarwal, U.K.
AU  - Chan, A.
AU  - Pattabiraman, K.
TI  - Resilience Assessment of Large Language Models under Transient Hardware Faults
PY  - 2023
T2  - Proceedings - International Symposium on Software Reliability Engineering, ISSRE
SP  - 659
EP  - 670
DO  - 10.1109/ISSRE59848.2023.00052
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85178048368&doi=10.1109%2fISSRE59848.2023.00052&partnerID=40&md5=498e99484b581e3548b4d78aeaf70f99
AD  - The University of British Columbia, Canada
AB  - Large Language Models (LLMs) are transforming the field of natural language processing and revolutionizing the way machines interact with humans. LLMs like ChatGPT and Google's Bard have already made significant strides in conversational AI, enabling machines to understand natural language and respond in a more human-like manner. In addition to typical applications like sentiment analysis and text generation, LLMs are also used in safety-critical applications such as code generation and speech comprehension in autonomous driving vehicles, where reliability is important.In this work, we investigate the resilience of LLMs under transient hardware faults. Specifically, we used IR-level fault injection (FI) to assess the reliability of five popular LLMs, including Bert, GPT2, and T5, under transient hardware faults. Moreover, we also investigate how the resilience of LLMs varies with different pre-training, fine-tuning objectives, and the number of encoder and decoder blocks. We find that LLMs are quite resilient to transient faults overall. We also find that the behavior of the LLM under transient faults varies significantly with the input, LLM's architecture, and the type of task (e.g., translation vs. fill-in-the-blank). Finally, we find that the Silent Data Corruption (SDC) rate varies with different fine-tuning objectives, and for the fill-mask fine-tuning objective, the SDC rate also increases with the model size. Overall, our findings indicate that the use of LLMs in safety-critical applications needs further investigation.  © 2023 IEEE.
KW  - Error resilience
KW  - LLMS
KW  - Soft Errors
KW  - Computational linguistics
KW  - Radiation hardening
KW  - Reliability analysis
KW  - Error resilience
KW  - Fine tuning
KW  - Hardware faults
KW  - Language model
KW  - LLMS
KW  - Natural languages
KW  - Safety critical applications
KW  - Silent data corruptions
KW  - Soft error
KW  - Transient faults
KW  - Sentiment analysis
PB  - IEEE Computer Society
SN  - 10719458 (ISSN); 979-835031594-3 (ISBN)
LA  - English
J2  - Proc. Int. Symp. Softw. Reliab. Eng.
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 0; Correspondence Address: U.K. Agarwal; The University of British Columbia, Canada; email: uditag97@student.ubc.ca; Conference name: 34th IEEE International Symposium on Software Reliability Engineering, ISSRE 2023; Conference date: 9 October 2023 through 12 October 2023; Conference code: 194273; CODEN: PSSRF
ER  -

TY  - CONF
AU  - Xiao, C.
AU  - Xu, S.X.
AU  - Zhang, K.
AU  - Wang, Y.
AU  - Xia, L.
TI  - Evaluating Reading Comprehension Exercises Generated by LLMs: A Showcase of ChatGPT in Education Applications
PY  - 2023
T2  - Proceedings of the Annual Meeting of the Association for Computational Linguistics
SP  - 610
EP  - 625
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85174548763&partnerID=40&md5=8475597bea771d629f1f77eb53aef59a
AD  - School of Economics and Management, Tsinghua University, China
AD  - Department of Decision, Operations & Information Technologies, University of Maryland, United States
AD  - Beijing Xicheng Educational Research Institute, China
AD  - Shawn Tech, United States
AB  - The recent advancement of pre-trained Large Language Models (LLMs), such as OpenAI’s ChatGPT, has led to transformative changes across fields. For example, developing intelligent systems in the educational sector that leverage the linguistic capabilities of LLMs demonstrates a visible potential. Though researchers have recently explored how ChatGPT could possibly assist in student learning, few studies have applied these techniques to real-world classroom settings involving teachers and students. In this study, we implement a reading comprehension exercise generation system that provides high-quality and personalized reading materials for middle school English learners in China. Extensive evaluations of the generated reading passages and corresponding exercise questions, conducted both automatically and manually, demonstrate that the system-generated materials are suitable for students and even surpass the quality of existing human-written ones. By incorporating first-hand feedback and suggestions from experienced educators, this study serves as a meaningful pioneering application of ChatGPT, shedding light on the future design and implementation of LLM-based systems in the educational context. © 2023 Association for Computational Linguistics.
KW  - Computational linguistics
KW  - Education computing
KW  - Intelligent systems
KW  - Classroom settings
KW  - Educational sectors
KW  - Exercise generations
KW  - Generation systems
KW  - High quality
KW  - Language model
KW  - Reading comprehension
KW  - Real-world
KW  - Student learning
KW  - Teachers'
KW  - Students
A2  - Kochmar E.
A2  - Burstein J.
A2  - Horbach A.
A2  - Horbach A.
A2  - Horbach A.
A2  - Laarmann-Quante R.
A2  - Madnani N.
A2  - Tack A.
A2  - Yaneva V.
A2  - Yuan Z.
A2  - Zesch T.
A2  - Zesch T.
PB  - Association for Computational Linguistics (ACL)
SN  - 0736587X (ISSN); 978-195942980-7 (ISBN)
LA  - English
J2  - Proc. Annu. Meet. Assoc. Comput Linguist.
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 2; Conference name: 18th Workshop on Innovative Use of NLP for Building Educational Applications, BEA 2023; Conference code: 193152
ER  -

TY  - JOUR
AU  - Doddi, S.
AU  - Hibshman, T.
AU  - Salichs, O.
AU  - Bera, K.
AU  - Tippareddy, C.
AU  - Ramaiya, N.
AU  - Tirumani, S.H.
TI  - Assessing appropriate responses to ACR urologic imaging scenarios using ChatGPT and Bard
PY  - 2023
T2  - Current Problems in Diagnostic Radiology
DO  - 10.1067/j.cpradiol.2023.10.022
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85175026430&doi=10.1067%2fj.cpradiol.2023.10.022&partnerID=40&md5=0aa142a7471db13d11c4fa2a37221130
AD  - University of Toledo College of Medicine, Toledo, OH, United States
AD  - Department of Radiology, University Hospitals Cleveland Medical Center, Cleveland, OH, United States
AB  - Artificial intelligence (AI) has recently become a trending tool and topic regarding productivity especially with publicly available free services such as ChatGPT and Bard. In this report, we investigate if two widely available chatbots chatGPT and Bard, are able to show consistent accurate responses for the best imaging modality for urologic clinical situations and if they are in line with American College of Radiology (ACR) Appropriateness Criteria (AC). All clinical scenarios provided by the ACR were inputted into ChatGPT and Bard with result compared to the ACR AC and recorded. Both chatbots had an appropriate imaging modality rate of of 62% and no significant difference in proportion of correct imaging modality was found overall between the two services (p>0.05). The results of our study found that both ChatGPT and Bard are similar in their ability to suggest the most appropriate imaging modality in a variety of urologic scenarios based on ACR AC criteria. Nonetheless, both chatbots lack consistent accuracy and further development is necessary for implementation in clinical settings. For proper use of these AI services in clinical decision making, further developments are needed to improve the workflow of physicians. © 2023 Elsevier Inc.
KW  - article
KW  - artificial intelligence
KW  - ChatGPT
KW  - clinical decision making
KW  - human
KW  - physician
KW  - radiology
KW  - workflow
PB  - Elsevier Inc.
SN  - 03630188 (ISSN)
LA  - English
J2  - Curr. Probl. Diagn. Radiol.
M3  - Article
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 0; Correspondence Address: S. Doddi; University of Toledo College of Medicine, Toledo, United States; email: sishir.doddi@utoledo.edu; CODEN: CPDRD
ER  -

TY  - JOUR
AU  - Levkovich, I.
AU  - Elyoseph, Z.
TI  - Suicide Risk Assessments Through the Eyes of ChatGPT-3.5 Versus ChatGPT-4: Vignette Study
PY  - 2023
T2  - JMIR Mental Health
VL  - 10
IS  - 1
C7  - e51232
DO  - 10.2196/51232
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85174860537&doi=10.2196%2f51232&partnerID=40&md5=601cb512174023f2652b3302ff224151
AD  - Oranim Academic College, Faculty of Graduate Studies, Kiryat Tivon, Israel
AD  - Department of Psychology and Educational Counseling, The Center for Psychobiological Research, Max Stern Yezreel Valley College, Emek Yezreel, Israel
AD  - Department of Brain Sciences, Faculty of Medicine, Imperial College London, London, United Kingdom
AB  - Background: ChatGPT, a linguistic artificial intelligence (AI) model engineered by OpenAI, offers prospective contributions to mental health professionals. Although having significant theoretical implications, ChatGPT’s practical capabilities, particularly regarding suicide prevention, have not yet been substantiated. Objective: The study’s aim was to evaluate ChatGPT’s ability to assess suicide risk, taking into consideration 2 discernable factors—perceived burdensomeness and thwarted belongingness—over a 2-month period. In addition, we evaluated whether ChatGPT-4 more accurately evaluated suicide risk than did ChatGPT-3.5. Methods: ChatGPT was tasked with assessing a vignette that depicted a hypothetical patient exhibiting differing degrees of perceived burdensomeness and thwarted belongingness. The assessments generated by ChatGPT were subsequently contrasted with standard evaluations rendered by mental health professionals. Using both ChatGPT-3.5 and ChatGPT-4 (May 24, 2023), we executed 3 evaluative procedures in June and July 2023. Our intent was to scrutinize ChatGPT-4’s proficiency in assessing various facets of suicide risk in relation to the evaluative abilities of both mental health professionals and an earlier version of ChatGPT-3.5 (March 14 version). Results: During the period of June and July 2023, we found that the likelihood of suicide attempts as evaluated by ChatGPT-4 was similar to the norms of mental health professionals (n=379) under all conditions (average Z score of 0.01). Nonetheless, a pronounced discrepancy was observed regarding the assessments performed by ChatGPT-3.5 (May version), which markedly underestimated the potential for suicide attempts, in comparison to the assessments carried out by the mental health professionals (average Z score of –0.83). The empirical evidence suggests that ChatGPT-4’s evaluation of the incidence of suicidal ideation and psychache was higher than that of the mental health professionals (average Z score of 0.47 and 1.00, respectively). Conversely, the level of resilience as assessed by both ChatGPT-4 and ChatGPT-3.5 (both versions) was observed to be lower in comparison to the assessments offered by mental health professionals (average Z score of –0.89 and –0.90, respectively). Conclusions: The findings suggest that ChatGPT-4 estimates the likelihood of suicide attempts in a manner akin to evaluations provided by professionals. In terms of recognizing suicidal ideation, ChatGPT-4 appears to be more precise. However, regarding psychache, there was an observed overestimation by ChatGPT-4, indicating a need for further research. These results have implications regarding ChatGPT-4’s potential to support gatekeepers, patients, and even mental health professionals’ decision-making. Despite the clinical potential, intensive follow-up studies are necessary to establish the use of ChatGPT-4’s capabilities in clinical practice. The finding that ChatGPT-3.5 frequently underestimates suicide risk, especially in severe cases, is particularly troubling. It indicates that ChatGPT may downplay one’s actual suicide risk level. ©Inbar Levkovich, Zohar Elyoseph.
KW  - artificial intelligence
KW  - assessment
KW  - assessments
KW  - ChatGPT
KW  - diagnosis
KW  - mental
KW  - natural language processing
KW  - NLP
KW  - psychological
KW  - psychological assessment
KW  - risk
KW  - risk assessment
KW  - self-harm
KW  - suicidal
KW  - suicide
KW  - suicide risk
KW  - text vignette
KW  - vignette
KW  - vignettes
KW  - adult
KW  - Article
KW  - ChatGPT
KW  - ChatGPT 3.5
KW  - ChatGPT 4
KW  - clinical evaluation
KW  - controlled study
KW  - disease risk assessment
KW  - female
KW  - follow up
KW  - human
KW  - male
KW  - mental health care personnel
KW  - normal human
KW  - psychiatric diagnosis
KW  - psychological resilience
KW  - suicidal ideation
KW  - suicide
KW  - suicide attempt
KW  - theoretical model
KW  - vignette
PB  - JMIR Publications Inc.
SN  - 23687959 (ISSN)
LA  - English
J2  - JMIR Ment. Heal.
M3  - Article
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 3; Correspondence Address: Z. Elyoseph; Department of Psychology and Educational Counseling, The Center for Psychobiological Research Max Stern Yezreel Valley College, Hatena 14b Kiryat Tivon Emek Yezreel, 3650414, Israel; email: Zohare@yvc.ac.il
ER  -

TY  - CONF
AU  - Araújo, S.
AU  - Aguiar, M.
TI  - Comparing ChatGPT’s and Human Evaluation of Scientific Texts’ Translations from English to Portuguese Using Popular Automated Translators
PY  - 2023
T2  - CEUR Workshop Proceedings
VL  - 3497
SP  - 2908
EP  - 2917
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85175627805&partnerID=40&md5=4fd4e3830d1cc97752ecbe83195346e3
AD  - University of Minho, Rua da Universidade, Braga, 4710 - 057, Portugal
AB  - This paper addresses the challenge researchers face when translating their work. Due to the high cost associated with human translation services, many researchers turn to automatic translation tools as a cost-effective alternative. Therefore, assessing the quality of these translations is crucial. This paper presents a comparative evaluation of translations using both human assessments and ChatGPT. Our study focuses on the translation of a scientific text excerpt from English to Portuguese. We analyze the performance of ChatGPT in two scenarios: comparative evaluations with all translations presented in a single prompt, applied five times to test for consistency, and 20 individual evaluations (five evaluations per translation) in separate chats. In both scenarios, ChatGPT’s assessments exhibit higher consistency in terms of fluency, appropriateness, accuracy, and overall assessment compared to human evaluations. The results also reveal a consensus between human evaluations and ChatGPT assessments regarding the translation with the lowest score, while discrepancies arise in the evaluations of top-performing translations. Finally, the ability to engage in follow-up questions, receive suggestions for improvement, and compare translations using ChatGPT's own recommendations proves a valuable tool for researchers seeking to assess and improve the translation quality of their work. © 2023 Copyright for this paper by its authors.
KW  - Automatic Translation
KW  - Machine Translation Evaluation template
KW  - Scientific Texts
KW  - Computational linguistics
KW  - Computer aided language translation
KW  - Automatic translation
KW  - Comparative evaluations
KW  - Evaluation template
KW  - High costs
KW  - Human evaluation
KW  - Machine translation evaluation template
KW  - Machine translation evaluations
KW  - Scientific texts
KW  - Translation services
KW  - Translation tools
KW  - Cost effectiveness
A2  - Aliannejadi M.
A2  - Faggioli G.
A2  - Ferro N.
A2  - Vlachos M.
PB  - CEUR-WS
SN  - 16130073 (ISSN)
LA  - English
J2  - CEUR Workshop Proc.
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 0; Conference name: 24th Working Notes of the Conference and Labs of the Evaluation Forum, CLEF-WN 2023; Conference date: 18 September 2023 through 21 September 2023; Conference code: 193170
ER  -

TY  - JOUR
AU  - Homburg, M.
AU  - Meijer, E.
AU  - Berends, M.
AU  - Kupers, T.
AU  - Hartman, T.O.
AU  - Muris, J.
AU  - de Schepper, E.
AU  - Velek, P.
AU  - Kuiper, J.
AU  - Berger, M.
AU  - Peters, L.
TI  - A Natural Language Processing Model for COVID-19 Detection Based on Dutch General Practice Electronic Health Records by Using Bidirectional Encoder Representations From Transformers: Development and Validation Study
PY  - 2023
T2  - Journal of Medical Internet Research
VL  - 25
IS  - 1
C7  - e49944
DO  - 10.2196/49944
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85175586952&doi=10.2196%2f49944&partnerID=40&md5=b8b953306cc5758ea098588d3a37eb80
AD  - Department of Primary- and Long-Term Care, University Medical Center Groningen, Groningen, Netherlands
AD  - Data Science Center in Health, University Medical Center Groningen, Groningen, Netherlands
AD  - Department of Medical Microbiology and Infection Prevention, University Medical Center Groningen, Groningen, Netherlands
AD  - Department of Medical Epidemiology, Certe Foundation, Groningen, Netherlands
AD  - Department of Primary and Community Care, Radboud University, Nijmegen Medical Center, Nijmegen, Netherlands
AD  - Care and Public Health Research Institute, Department of Family Medicine, Maastricht University Medical Center, Maastricht, Netherlands
AD  - Department of General Practice, Erasmus Medical Center, Rotterdam, Netherlands
AD  - Municipal Health Service Groningen, Groningen, Netherlands
AD  - Midwifery Science, Amsterdam Public Health, Vrije Universiteit Amsterdam, Amsterdam University Medical Center, Amsterdam, Netherlands
AB  - Background: Natural language processing (NLP) models such as bidirectional encoder representations from transformers (BERT) hold promise in revolutionizing disease identification from electronic health records (EHRs) by potentially enhancing efficiency and accuracy. However, their practical application in practice settings demands a comprehensive and multidisciplinary approach to development and validation. The COVID-19 pandemic highlighted challenges in disease identification due to limited testing availability and challenges in handling unstructured data. In the Netherlands, where general practitioners (GPs) serve as the first point of contact for health care, EHRs generated by these primary care providers contain a wealth of potentially valuable information. Nonetheless, the unstructured nature of free-text entries in EHRs poses challenges in identifying trends, detecting disease outbreaks, or accurately pinpointing COVID-19 cases. Objective: This study aims to develop and validate a BERT model for detecting COVID-19 consultations in general practice EHRs in the Netherlands. Methods: The BERT model was initially pretrained on Dutch language data and fine-tuned using a comprehensive EHR data set comprising confirmed COVID-19 GP consultations and non–COVID-19–related consultations. The data set was partitioned into a training and development set, and the model’s performance was evaluated on an independent test set that served as the primary measure of its effectiveness in COVID-19 detection. To validate the final model, its performance was assessed through 3 approaches. First, external validation was applied on an EHR data set from a different geographic region in the Netherlands. Second, validation was conducted using results of polymerase chain reaction (PCR) test data obtained from municipal health services. Lastly, correlation between predicted outcomes and COVID-19–related hospitalizations in the Netherlands was assessed, encompassing the period around the outbreak of the pandemic in the Netherlands, that is, the period before widespread testing. Results: The model development used 300,359 GP consultations. We developed a highly accurate model for COVID-19 consultations (accuracy 0.97, F1-score 0.90, precision 0.85, recall 0.85, specificity 0.99). External validations showed comparable high performance. Validation on PCR test data showed high recall but low precision and specificity. Validation using hospital data showed significant correlation between COVID-19 predictions of the model and COVID-19–related hospitalizations (F1-score 96.8; P<.001; R2=0.69). Most importantly, the model was able to predict COVID-19 cases weeks before the first confirmed case in the Netherlands. Conclusions: The developed BERT model was able to accurately identify COVID-19 cases among GP consultations even preceding confirmed cases. The validated efficacy of our BERT model highlights the potential of NLP models to identify disease outbreaks early, exemplifying the power of multidisciplinary efforts in harnessing technology for disease identification. Moreover, the implications of this study extend beyond COVID-19 and offer a blueprint for the early recognition of various illnesses, revealing that such models could revolutionize disease surveillance. © Maarten Homburg, Eline Meijer, Matthijs Berends, Thijmen Kupers, Tim Olde Hartman, Jean Muris, Evelien de Schepper, Premysl Velek, Jeroen Kuiper, Marjolein Berger, Lilian Peters. Originally published in the Journal of Medical Internet Research.
KW  - COVID-19
KW  - Electronic Health Records
KW  - General Practice
KW  - Humans
KW  - Natural Language Processing
KW  - Pandemics
KW  - Article
KW  - clinical effectiveness
KW  - consultation
KW  - controlled study
KW  - coronavirus disease 2019
KW  - diagnostic accuracy
KW  - electronic health record
KW  - general practice
KW  - general practitioner
KW  - hospitalization
KW  - human
KW  - major clinical study
KW  - natural language processing
KW  - Netherlands
KW  - polymerase chain reaction
KW  - validation process
KW  - coronavirus disease 2019
KW  - electronic health record
KW  - general practice
KW  - natural language processing
KW  - pandemic
PB  - JMIR Publications Inc.
SN  - 14388871 (ISSN)
C2  - 37792444
LA  - English
J2  - J. Med. Internet Res.
M3  - Article
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 0; Correspondence Address: M. Homburg; Department of Primary- and Long-Term Care, University Medical Center Groningen, Groningen, Home Post Code FA21 PO Box 196, 9700 RB, Netherlands; email: t.m.homburg@umcg.nl
ER  -

TY  - CONF
AU  - Meyer, L.-P.
AU  - Frey, J.
AU  - Junghanns, K.
AU  - Brei, F.
AU  - Bulert, K.
AU  - Gründer-Fahrer, S.
AU  - Martin, M.
TI  - Developing a Scalable Benchmark for Assessing Large Language Models in Knowledge Graph Engineering
PY  - 2023
T2  - CEUR Workshop Proceedings
VL  - 3526
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85176615313&partnerID=40&md5=8bb63c61f9bb09fa2d3e4e779ce7889a
AD  - Institute for Applied Informatics, Goerdelerring 9, Leipzig, 04109, Germany
AD  - Agile Knowledge Engineering and Semantic Web (AKSW)
AD  - Leipzig University, Institute for Informatics, Germany
AB  - As the field of Large Language Models (LLMs) evolves at an accelerated pace, the critical need to assess and monitor their performance emerges. We introduce a benchmarking framework focused on knowledge graph engineering (KGE) accompanied by three challenges addressing syntax and error correction, facts extraction and dataset generation. We show that while being a useful tool, LLMs are yet unfit to assist in knowledge graph generation with zero-shot prompting. Consequently, our LLM-KG-Bench framework provides automatic evaluation and storage of LLM responses as well as statistical data and visualization tools to support tracking of prompt engineering and model performance. © 2023 CEUR-WS. All rights reserved.
KW  - Knowledge Graph Engineering
KW  - Large Language Model
KW  - Large Language Model Benchmark
KW  - Computational linguistics
KW  - Computer aided language translation
KW  - Data visualization
KW  - Digital storage
KW  - Error correction
KW  - Natural language processing systems
KW  - Petroleum reservoir evaluation
KW  - Semantics
KW  - Zero-shot learning
KW  - Errors correction
KW  - Fact extraction
KW  - Graph generation
KW  - Knowledge graph engineering
KW  - Knowledge graphs
KW  - Language model
KW  - Large language model
KW  - Large language model benchmark
KW  - Performance
KW  - Knowledge graph
A2  - Keshan N.
A2  - Neumaier S.
A2  - Gentile A.L.
A2  - Vahdati S.
PB  - CEUR-WS
SN  - 16130073 (ISSN)
LA  - English
J2  - CEUR Workshop Proc.
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 0; Correspondence Address: L.-P. Meyer; Institute for Applied Informatics, Leipzig, Goerdelerring 9, 04109, Germany; email: lpmeyer@infai.org; Conference name: 19th International Conference on Semantic Systems, SEMPDS 2023; Conference date: 20 September 2023 through 22 September 2023; Conference code: 193776
ER  -

TY  - CHAP
AU  - Wang, H.
AU  - Li, T.
AU  - Haudek, K.
AU  - Royse, E.A.
AU  - Manzanares, M.
AU  - Adams, S.
AU  - Horne, L.
AU  - Romulo, C.
TI  - Is ChatGPT a Threat to Formative Assessment in College-Level Science? An Analysis of Linguistic and Content-Level Features to Classify Response Types
PY  - 2023
T2  - Lecture Notes on Data Engineering and Communications Technologies
VL  - 190
SP  - 171
EP  - 185
DO  - 10.1007/978-981-99-7947-9_13
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85178099928&doi=10.1007%2f978-981-99-7947-9_13&partnerID=40&md5=04842a02dc72707c7e6d67a0fb5803a4
AD  - Michigan State University, 620 Farm Lane, East Lansing, 48824, MI, United States
AD  - University of Northern Colorado, Candelaria 2200, Box 115, Greeley, 80639, CO, United States
AD  - Rowan University, Discovery Hall 127, 201 Mullica Hill Road, Glassboro, 08028, NJ, United States
AB  - The impact of OpenAI’s ChatGPT on education has led to a reexamination of traditional pedagogical methods and assessments. However, ChatGPT’s performance capabilities on a wide range of assessments remain to be determined. This study aims to classify ChatGPT-generated and student constructed responses to a college-level environmental science question and explore the linguistic- and content-level features that can be used to address the differential use of language. Coh-Metrix textual analytic tool was implemented to identify and extract linguistic and textual feature. Then we employed random forest feature selection method to determine the best representative and nonredundant text-based features. We also employed TF-IDF metrics to represent the content of written responses. The true performance of classification models for the responses was evaluated and compared in three scenarios: (a) using content-level features alone, (b) using linguistic-level features alone, (c) using the combination of two. The results demonstrated that the accuracy, specificity, sensitivity, and F1-score all increased when we used the combination of two-level features. The results of this study hold promise to provide valuable insights for instructors to detect student responses and integrate ChatGPT into their course development. This study also highlights the significance of linguistic- and content-level features in AI education research. © The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd 2023.
KW  - ChatGPT
KW  - Coh-Metrix
KW  - environmental science
KW  - logistic regression classifier
KW  - Education computing
KW  - Feature Selection
KW  - Linguistics
KW  - Students
KW  - Analytic tools
KW  - ChatGPT
KW  - Coh-metrix
KW  - Content level
KW  - Environmental science
KW  - Formative assessment
KW  - Linguistic features
KW  - Logistic regression classifier
KW  - Pedagogical method
KW  - Performance capability
KW  - Classification (of information)
PB  - Springer Science and Business Media Deutschland GmbH
SN  - 23674512 (ISSN)
LA  - English
J2  - Lecture. Notes. Data Eng. Commun. Tech.
M3  - Book chapter
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 0; Correspondence Address: H. Wang; Michigan State University, East Lansing, 620 Farm Lane, 48824, United States; email: wangheq2@msu.edu
ER  -

TY  - JOUR
AU  - Kirwan, A.
TI  - ChatGPT and university teaching, learning and assessment: some initial reflections on teaching academic integrity in the age of Large Language Models
PY  - 2023
T2  - Irish Educational Studies
DO  - 10.1080/03323315.2023.2284901
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85177696148&doi=10.1080%2f03323315.2023.2284901&partnerID=40&md5=f3098bfd87f2af2369de68663f8ecf97
AD  - Critical Skills, Office of the Dean of Teaching and Learning, Maynooth University, Maynooth, Ireland
AB  - Since its arrival in late 2022, ChatGPT has occupied the minds of academics, administrators and students. Reactions to the emergence of Large Language Models (LLMs) have varied but significant anxieties about their impact on assessment have arisen. To address these concerns, this article serves three purposes; firstly, it seeks to gauge the discourse surrounding Large Language Models (LLMs) focusing on ChatGPT. In doing so, it explores general and academic responses to the technology and the challenges/opportunities that have been identified. Secondly, and building on this, it provides an overview of ChatGPT in action and seeks to moderate fears raised by some of the extreme claims that have been made about the potential of this technology. Finally, the article uses a case study to discuss the introduction of this technology to a group of first-year undergraduate students, offering guidance on how the topic of LLMs might be broached. It concludes by suggesting that while the technology has the ability to offer assistance in the completion of academic assessment, it does not replace the higher thinking skills that are central to teaching, learning and assessment in higher education. In turn, arguing that these must be central to assessment practices. © 2023 Educational Studies Association of Ireland.
KW  - Academic integrity
KW  - Assessment
KW  - ChatGPT
KW  - Large Language Models
PB  - Routledge
SN  - 03323315 (ISSN)
LA  - English
J2  - Ir. Educ. Stud.
M3  - Article
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 0; Correspondence Address: A. Kirwan; Critical Skills, Office of the Dean of Teaching and Learning, Maynooth University, Maynooth, Room 8, Rowan House, Ireland; email: adrian.kirwan@mu.ie
ER  -

TY  - CONF
AU  - Ghanadian, H.
AU  - Nejadgholi, I.
AU  - Al Osman, H.
TI  - ChatGPT for Suicide Risk Assessment on Social Media: Quantitative Evaluation of Model Performance, Potentials and Limitations
PY  - 2023
T2  - Proceedings of the Annual Meeting of the Association for Computational Linguistics
SP  - 172
EP  - 183
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85174832762&partnerID=40&md5=28067d28d99df6f54e178c2e54c123c0
AD  - University of Ottawa, Ottawa, Canada
AD  - National Research Council Canada, Ottawa, Canada
AB  - This paper presents a novel framework for quantitatively evaluating the interactive ChatGPT model in the context of suicidality assessment from social media posts, utilizing the University of Maryland Reddit suicidality dataset. We conduct a technical evaluation of ChatGPT’s performance on this task using Zero-Shot and Few-Shot experiments and compare its results with those of two fine-tuned transformer-based models. Additionally, we investigate the impact of different temperature parameters on ChatGPT’s response generation and discuss the optimal temperature based on the inconclusiveness rate of ChatGPT. Our results indicate that while ChatGPT attains considerable accuracy in this task, transformer-based models fine-tuned on human-annotated datasets exhibit superior performance. Moreover, our analysis sheds light on how adjusting the ChatGPT’s hyperparameters can improve its ability to assist mental health professionals in this critical task. © 2023 Association for Computational Linguistics.
KW  - Computational linguistics
KW  - Social networking (online)
KW  - Zero-shot learning
KW  - Model potential
KW  - Modeling performance
KW  - Performance
KW  - Performance limitations
KW  - Performance potentials
KW  - Quantitative evaluation
KW  - Risks assessments
KW  - Social media
KW  - Suicidality
KW  - University of Maryland
KW  - Risk assessment
A2  - Barnes J.
A2  - De Clercq O.
A2  - Klinger R.
PB  - Association for Computational Linguistics (ACL)
SN  - 0736587X (ISSN); 978-195942987-6 (ISBN)
LA  - English
J2  - Proc. Annu. Meet. Assoc. Comput Linguist.
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 0; Conference name: 13th Workshop on Computational Approaches to Subjectivity, Sentiment and Social Media Analysis, WASSA 2023; Conference code: 193204
ER  -

TY  - JOUR
AU  - Civettini, I.
AU  - Zappaterra, A.
AU  - Granelli, B.M.
AU  - Rindone, G.
AU  - Aroldi, A.
AU  - Bonfanti, S.
AU  - Colombo, F.
AU  - Fedele, M.
AU  - Grillo, G.
AU  - Parma, M.
AU  - Perfetti, P.
AU  - Terruzzi, E.
AU  - Gambacorti-Passerini, C.
AU  - Ramazzotti, D.
AU  - Cavalca, F.
TI  - Evaluating the performance of large language models in haematopoietic stem cell transplantation decision-making
PY  - 2023
T2  - British Journal of Haematology
DO  - 10.1111/bjh.19200
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85178962668&doi=10.1111%2fbjh.19200&partnerID=40&md5=15e995c461e45c448c74c3d1ddf7349a
AD  - Department of Medicine and Surgery, University of Milano-Bicocca, Monza, Italy
AD  - Department of Haematology and Bone Marrow Trasplantation Unit, Fondazione IRCCS San Gerardo dei Tintori, Monza, Italy
AD  - Department of Haematology and Bone Marrow Transplantation Unit, ASST Grande Ospedale Metropolitano Niguarda, Milan, Italy
AB  - In a first-of-its-kind study, we assessed the capabilities of large language models (LLMs) in making complex decisions in haematopoietic stem cell transplantation. The evaluation was conducted not only for Generative Pre-trained Transformer 4 (GPT-4) but also conducted on other artificial intelligence models: PaLm 2 and Llama-2. Using detailed haematological histories that include both clinical, molecular and donor data, we conducted a triple-blind survey to compare LLMs to haematology residents. We found that residents significantly outperformed LLMs (p = 0.02), particularly in transplant eligibility assessment (p = 0.01). Our triple-blind methodology aimed to mitigate potential biases in evaluating LLMs and revealed both their promise and limitations in deciphering complex haematological clinical scenarios. © 2023 The Authors. British Journal of Haematology published by British Society for Haematology and John Wiley & Sons Ltd.
KW  - artificial intelligence
KW  - GPT
KW  - HSC transplantation
KW  - interrater agreement
KW  - transplant
PB  - John Wiley and Sons Inc
SN  - 00071048 (ISSN)
LA  - English
J2  - Br. J. Haematol.
M3  - Article
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 0; Correspondence Address: I. Civettini; Haematology Division, University of Milano-Bicocca, Fondazione IRCCS San Gerardo dei Tintori Hospital Monza, Monza, via Cadore 48, 20900, Italy; email: i.civettini@campus.unimib.it; CODEN: BJHEA
ER  -

TY  - JOUR
AU  - Surapaneni, K.M.
TI  - Assessing the Performance of ChatGPT in Medical Biochemistry Using Clinical Case Vignettes: Observational Study
PY  - 2023
T2  - JMIR Medical Education
VL  - 9
IS  - 1
C7  - e47191
DO  - 10.2196/47191
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85177846048&doi=10.2196%2f47191&partnerID=40&md5=adefa891e9bd03e91ed0f867667375d6
AD  - Panimalar Medical College Hospital & Research Institute, Chennai, India
AB  - Background: ChatGPT has gained global attention recently owing to its high performance in generating a wide range of information and retrieving any kind of data instantaneously. ChatGPT has also been tested for the United States Medical Licensing Examination (USMLE) and has successfully cleared it. Thus, its usability in medical education is now one of the key discussions worldwide. Objective: The objective of this study is to evaluate the performance of ChatGPT in medical biochemistry using clinical case vignettes. Methods: The performance of ChatGPT was evaluated in medical biochemistry using 10 clinical case vignettes. Clinical case vignettes were randomly selected and inputted in ChatGPT along with the response options. We tested the responses for each clinical case twice. The answers generated by ChatGPT were saved and checked using our reference material. Results: ChatGPT generated correct answers for 4 questions on the first attempt. For the other cases, there were differences in responses generated by ChatGPT in the first and second attempts. In the second attempt, ChatGPT provided correct answers for 6 questions and incorrect answers for 4 questions out of the 10 cases that were used. But, to our surprise, for case 3, different answers were obtained with multiple attempts. We believe this to have happened owing to the complexity of the case, which involved addressing various critical medical aspects related to amino acid metabolism in a balanced approach. Conclusions: According to the findings of our study, ChatGPT may not be considered an accurate information provider for application in medical education to improve learning and assessment. However, our study was limited by a small sample size (10 clinical case vignettes) and the use of the publicly available version of ChatGPT (version 3.5). Although artificial intelligence (AI) has the capability to transform medical education, we emphasize the validation of such data produced by such AI systems for correctness and dependability before it could be implemented in practice. © 2023 The Author(s).
KW  - artificial intelligence
KW  - biochemistry
KW  - case scenario
KW  - case study
KW  - chatbot
KW  - ChatGPT
KW  - computer generated
KW  - medical Biochemistry
KW  - medical education
KW  - medical exam
KW  - medical examination
PB  - JMIR Publications Inc.
SN  - 23693762 (ISSN)
LA  - English
J2  - JMIR Med. Educ.
M3  - Article
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 0; Correspondence Address: K.M. Surapaneni; Panimalar Medical College Hospital & Research Institute Varadharajapuram, Chennai, Poonamallee, 600123, India; email: krishnamohan.surapaneni@gmail.com
ER  -

TY  - JOUR
AU  - Reyaz, A.
AU  - Sohail, S.S.
AU  - Ishaaq, N.
TI  - Scrutinizing ChatGPT’s Performance in Assessing Surgical Knowledge: an Examination Study
PY  - 2023
T2  - Indian Journal of Surgery
DO  - 10.1007/s12262-023-03960-4
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85174616789&doi=10.1007%2fs12262-023-03960-4&partnerID=40&md5=28ad5346398f307fcac28a7884b88a64
AD  - Department of Computer Science and Engineering, SEST, Jamia Hamdard, New Delhi, India
PB  - Springer
SN  - 09722068 (ISSN)
LA  - English
J2  - Indian J. Surg.
M3  - Letter
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 0; Correspondence Address: A. Reyaz; Department of Computer Science and Engineering, SEST, New Delhi, Jamia Hamdard, India; email: anamreyaz9526@gmail.com; CODEN: IJSUA
ER  -

TY  - CONF
AU  - Goldfarb-Tarrant, S.
AU  - Ungless, E.
AU  - Balkir, E.
AU  - Blodgett, S.L.
TI  - This Prompt is Measuring <MASK>: Evaluating Bias Evaluation in Language Models
PY  - 2023
T2  - Proceedings of the Annual Meeting of the Association for Computational Linguistics
SP  - 2209
EP  - 2225
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85175475627&partnerID=40&md5=f172ba2be291ce3076ee8bdf81166e79
AD  - University of Edinburgh, United Kingdom
AD  - National Research Council Canada, Canada
AD  - Microsoft Research
AB  - Bias research in NLP seeks to analyse models for social biases, thus helping NLP practitioners uncover, measure, and mitigate social harms. We analyse the body of work that uses prompts and templates to assess bias in language models. We draw on a measurement modelling framework to create a taxonomy of attributes that capture what a bias test aims to measure and how that measurement is carried out. By applying this taxonomy to 90 bias tests, we illustrate qualitatively and quantitatively that core aspects of bias test conceptualisations and operationalisations are frequently unstated or ambiguous, carry implicit assumptions, or be mismatched. Our analysis illuminates the scope of possible bias types the field is able to measure, and reveals types that are as yet under-researched. We offer guidance to enable the community to explore a wider section of the possible bias space, and to better close the gap between desired outcomes and experimental design, both for bias and for evaluating language models more broadly. © 2023 Association for Computational Linguistics.
KW  - Computational linguistics
KW  - Natural language processing systems
KW  - Bias test
KW  - Language model
KW  - Measurement model
KW  - Modelling framework
KW  - Taxonomies
PB  - Association for Computational Linguistics (ACL)
SN  - 0736587X (ISSN); 978-195942962-3 (ISBN)
LA  - English
J2  - Proc. Annu. Meet. Assoc. Comput Linguist.
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 1; Correspondence Address: S. Goldfarb-Tarrant; University of Edinburgh, United Kingdom; email: s.tarrant@ed.ac.uk; E. Ungless; University of Edinburgh, United Kingdom; email: e.l.ungless@ed.ac.uk; Conference name: 61st Annual Meeting of the Association for Computational Linguistics, ACL 2023; Conference date: 9 July 2023 through 14 July 2023; Conference code: 192867
ER  -

TY  - JOUR
AU  - Ito, N.
AU  - Kadomatsu, S.
AU  - Fujisawa, M.
AU  - Fukaguchi, K.
AU  - Ishizawa, R.
AU  - Kanda, N.
AU  - Kasugai, D.
AU  - Nakajima, M.
AU  - Goto, T.
AU  - Tsugawa, Y.
TI  - The Accuracy and Potential Racial and Ethnic Biases of GPT-4 in the Diagnosis and Triage of Health Conditions: Evaluation Study
PY  - 2023
T2  - JMIR Medical Education
VL  - 9
IS  - 1
C7  - e47532
DO  - 10.2196/47532
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85178079652&doi=10.2196%2f47532&partnerID=40&md5=38c109330bae06014f7a5789aabaa016
AD  - TXP Medical Co Ltd, Tokyo, Japan
AD  - Faculty of Medicine, The University of Tokyo, Tokyo, Japan
AD  - Faculty of Medicine, International University of Health and Welfare, Chiba, Japan
AD  - Department of Emergency Medicine, Shonan Kamakura General Hospital, Kanagawa, Japan
AD  - Department of Emergency and Critical Care Medicine, Tokyo Medical Center National Hospital Organization, Tokyo, Japan
AD  - Division of General Internal Medicine, Jichi Medical University Hospital, Tochigi, Japan
AD  - Department of Emergency and Critical Care Medicine, Nagoya University Graduate School of Medicine, Aichi, Japan
AD  - Emergency Life-Saving Technique Academy of Tokyo Foundation for Ambulance Service Development, Tokyo, Japan
AD  - Division of General Internal Medicine and Health Services Research, David Geffen School of Medicine, The University of California, Los Angeles, Los Angeles, CA, United States
AD  - Department of Health Policy and Management, UCLA Fielding School of Public Health, Los Angeles, CA, United States
AB  - Background: Whether GPT-4, the conversational artificial intelligence, can accurately diagnose and triage health conditions and whether it presents racial and ethnic biases in its decisions remain unclear. Objective: We aim to assess the accuracy of GPT-4 in the diagnosis and triage of health conditions and whether its performance varies by patient race and ethnicity. Methods: We compared the performance of GPT-4 and physicians, using 45 typical clinical vignettes, each with a correct diagnosis and triage level, in February and March 2023. For each of the 45 clinical vignettes, GPT-4 and 3 board-certified physicians provided the most likely primary diagnosis and triage level (emergency, nonemergency, or self-care). Independent reviewers evaluated the diagnoses as "correct" or "incorrect." Physician diagnosis was defined as the consensus of the 3 physicians. We evaluated whether the performance of GPT-4 varies by patient race and ethnicity, by adding the information on patient race and ethnicity to the clinical vignettes. Results: The accuracy of diagnosis was comparable between GPT-4 and physicians (the percentage of correct diagnosis was 97.8% (44/45; 95% CI 88.2%-99.9%) for GPT-4 and 91.1% (41/45; 95% CI 78.8%-97.5%) for physicians; P=.38). GPT-4 provided appropriate reasoning for 97.8% (44/45) of the vignettes. The appropriateness of triage was comparable between GPT-4 and physicians (GPT-4: 30/45, 66.7%; 95% CI 51.0%-80.0%; physicians: 30/45, 66.7%; 95% CI 51.0%-80.0%; P=.99). The performance of GPT-4 in diagnosing health conditions did not vary among different races and ethnicities (Black, White, Asian, and Hispanic), with an accuracy of 100% (95% CI 78.2%-100%). P values, compared to the GPT-4 output without incorporating race and ethnicity information, were all.99. The accuracy of triage was not significantly different even if patients' race and ethnicity information was added. The accuracy of triage was 62.2% (95% CI 46.5%-76.2%; P=.50) for Black patients; 66.7% (95% CI 51.0%-80.0%; P=.99) for White patients; 66.7% (95% CI 51.0%-80.0%; P=.99) for Asian patients, and 62.2% (95%CI 46.5%-76.2%; P=.69) for Hispanic patients. P values were calculated by comparing the outputs with and without conditioning on race and ethnicity. Conclusions: GPT-4's ability to diagnose and triage typical clinical vignettes was comparable to that of board-certified physicians. The performance of GPT-4 did not vary by patient race and ethnicity. These findings should be informative for health systems looking to introduce conversational artificial intelligence to improve the efficiency of patient diagnosis and triage. © 2023 The Author(s).
KW  - AI
KW  - artificial intelligence
KW  - bias
KW  - clinical vignettes
KW  - decision-making
KW  - diagnosis
KW  - efficiency
KW  - GPT
KW  - GPT-4
KW  - physician
KW  - race
KW  - racial and ethnic bias
KW  - triage
KW  - typical clinical vignettes
PB  - JMIR Publications Inc.
SN  - 23693762 (ISSN)
LA  - English
J2  - JMIR Med. Educ.
M3  - Article
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 1; Correspondence Address: T. Goto; TXP Medical Co Ltd, Tokyo, 41-1 H O Kanda 706, 101-0042, Japan; email: tag695@mail.harvard.edu
ER  -

TY  - JOUR
AU  - Mukherjee, S.
AU  - Durkin, C.
AU  - PeBenito, A.M.
AU  - Ferrante, N.D.
AU  - Umana, I.C.
AU  - Kochman, M.L.
TI  - Assessing ChatGPT's Ability to Reply to Queries Regarding Colon Cancer Screening Based on Multisociety Guidelines
PY  - 2023
T2  - Gastro Hep Advances
VL  - 2
IS  - 8
SP  - 1040
EP  - 1043
DO  - 10.1016/j.gastha.2023.07.008
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85176146078&doi=10.1016%2fj.gastha.2023.07.008&partnerID=40&md5=694b877b56d11413ca310beee47e709d
AD  - Gastroenterology Division, Department of Medicine, Perelman School of Medicine at the University of Pennsylvania, Philadelphia, PA, United States
AD  - Department of Medicine, Center for Endoscopic Innovation Research and Training, Perelman School of Medicine at the University of Pennsylvania, Philadelphia, PA, United States
PB  - American Gastroenterological Association
SN  - 27725723 (ISSN)
LA  - English
J2  - Gastro. Hep. Adv.
M3  - Short survey
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 1; Correspondence Address: S. Mukherjee; Division of Gastroenterology, Perelman Center for Advanced Medicine South Pavilion, Philadelphia, 4th Floor 3400 Civic Center Boulevard, 19104, United States; email: samiranmukherjee93@gmail.com
ER  -

TY  - CONF
AU  - Laverghetta, A.
AU  - Licato, J.
TI  - Generating Better Items for Cognitive Assessments Using Large Language Models
PY  - 2023
T2  - Proceedings of the Annual Meeting of the Association for Computational Linguistics
SP  - 414
EP  - 428
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85174486242&partnerID=40&md5=a968b8e35f6b697de4e124fc21372f5d
AD  - University of South Florida, Department of Computer Science and Engineering, Tampa, FL, United States
AB  - Writing high-quality test questions (items) is critical to building educational measures but has traditionally also been a time-consuming process. One promising avenue for alleviating this is automated item generation, whereby methods from artificial intelligence (AI) are used to generate new items with minimal human intervention. Researchers have explored using large language models (LLMs) to generate new items with equivalent psychometric properties to human-written ones. But can LLMs generate items with improved psychometric properties, even when existing items have poor validity evidence? We investigate this using items from a natural language inference (NLI) dataset. We develop a novel prompting strategy based on selecting items with both the best and worst properties to use in the prompt and use GPT-3 to generate new NLI items. We find that the GPT-3 items show improved psychometric properties in many cases, whilst also possessing good content, convergent and discriminant validity evidence. Collectively, our results demonstrate the potential of employing LLMs to ease the item development process and suggest that the careful use of prompting may allow for iterative improvement of item quality. © 2023 Association for Computational Linguistics.
KW  - Computational linguistics
KW  - Cognitive assessments
KW  - High Quality Test
KW  - Human intervention
KW  - Item generation
KW  - Language inference
KW  - Language model
KW  - Natural languages
KW  - Property
KW  - Psychometric properties
KW  - Validity evidence
KW  - Iterative methods
A2  - Kochmar E.
A2  - Burstein J.
A2  - Horbach A.
A2  - Horbach A.
A2  - Horbach A.
A2  - Laarmann-Quante R.
A2  - Madnani N.
A2  - Tack A.
A2  - Yaneva V.
A2  - Yuan Z.
A2  - Zesch T.
A2  - Zesch T.
PB  - Association for Computational Linguistics (ACL)
SN  - 0736587X (ISSN); 978-195942980-7 (ISBN)
LA  - English
J2  - Proc. Annu. Meet. Assoc. Comput Linguist.
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 0; Conference name: 18th Workshop on Innovative Use of NLP for Building Educational Applications, BEA 2023; Conference code: 193152
ER  -

TY  - JOUR
AU  - Razdan, S.
AU  - Siegal, A.R.
AU  - Brewer, Y.
AU  - Sljivich, M.
AU  - Valenzuela, R.J.
TI  - Assessing ChatGPT’s ability to answer questions pertaining to erectile dysfunction: can our patients trust it?
PY  - 2023
T2  - International Journal of Impotence Research
DO  - 10.1038/s41443-023-00797-z
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85177059953&doi=10.1038%2fs41443-023-00797-z&partnerID=40&md5=ce48a1bf7c9671700ede71793efd1f49
AD  - Department of Urology, Icahn School of Medicine at Mount Sinai Hospital, New York, 10029, NY, United States
AD  - Department of Internal Medicine, HCA Florida Sarasota Doctors Hospital, Sarasota, 34233, FL, United States
AB  - Erectile dysfunction (ED) is a disorder that can cause distress and shame for men suffering from it. Men with ED will often turn to online support and chat groups to ask intimate questions about their health. ChatGPT is an artificial intelligence (AI)-based software that has been trained to engage in conversation with human input. We sought to assess the accuracy, readability, and reproducibility of ChatGPT’s responses to frequently asked questions regarding the diagnosis, management, and care of patients with ED. Questions pertaining to ED were derived from clinic encounters with patients as well as online chat forums. These were entered into the free ChatGPT version 3.5 during the month of August 2023. Questions were asked on two separate days from unique accounts and computers to prevent the software from memorizing responses linked to a specific user. A total of 35 questions were asked. Outcomes measured were accuracy using grading from board certified urologists, readability with the Gunning Fog Index, and reproducibility by comparing responses between days. For epidemiology of disease, the percentage of responses that were graded as “comprehensive” or “correct but inadequate” was 100% across both days. There was fair reproducibility and median readability of 15.9 (IQR 2.5). For treatment and prevention, the percentage of responses that were graded as “comprehensive” or “correct but inadequate” was 78.9%. There was poor reproducibility of responses with a median readability of 14.5 (IQR 4.0). Risks of treatment and counseling both had 100% of questions graded as “comprehensive” or “correct but inadequate.” The readability score for risks of treatment was median 13.9 (IQR 1.1) and for counseling median 13.8 (IQR 0.5), with good reproducibility for both question domains. ChatGPT provides accurate answers to common patient questions pertaining to ED, although its understanding of treatment options is incomplete and responses are at a reading level too advanced for the average patient. © 2023, The Author(s), under exclusive licence to Springer Nature Limited.
PB  - Springer Nature
SN  - 09559930 (ISSN)
LA  - English
J2  - Int. J. Impotence Res.
M3  - Article
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 1; Correspondence Address: S. Razdan; Department of Urology, Icahn School of Medicine at Mount Sinai Hospital, New York, 10029, United States; email: shirin.razdan@mountsinai.org; CODEN: IJIRF
ER  -

TY  - CONF
AU  - Rahgouy, M.
AU  - Giglou, H.B.
AU  - Feng, D.
AU  - Rahgooy, T.
AU  - Dozier, G.
AU  - Seals, C.D.
TI  - Navigating the Fermi Multiverse: Assessing LLMs for Complex Multi-hop Queries
PY  - 2023
T2  - CEUR Workshop Proceedings
VL  - 3551
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85178378565&partnerID=40&md5=44e8783b743becdcb40d12058ea6ef62
AD  - Department of Computer Science and Software Engineering, Auburn University, Auburn, AL, United States
AD  - TIB Leibniz Information Centre for Science and Technology, Hannover, Germany
AD  - Department of Mathematics, Computer Science, and Statistics, Gustavus Adolphus College, MN, United States
AD  - Meta, Menlo Park, CA, United States
AB  - Recently, large language models (LLMs) have gained significant attention in the field of Natural Language Processing (NLP) and have shown promise across various tasks, even when given only a few examples to learn from. However, their ability to understand and reason with natural language remains uncertain. While there have been attempts to evaluate these models using reasoning tests, these evaluations have mostly focused on models' final answers, often overlooking the step-by-step reasoning processes behind their performance. Additionally, these analyses have typically concentrated on just one or a few aspects of reasoning, especially for tasks that do not require much complex thinking to find the answer. This limits our understanding of LLMs' potential and limitations when it comes to more complex and realistic questions. To address this issue, we conduct a comprehensive analysis of LLMs using the existing Fermi reasoning challenge, a task that combines different aspects of reasoning into a single question-answering format, requiring deeper levels of reasoning. In this paper, we examine various advanced LLMs in this reasoning challenge and explore how their performance is affected by their size (i.e., the number of parameters). We also investigate how these models behave with different levels of supervision, ranging from having all the information to no evidence at all. Furthermore, we compare the two primary methods of teaching these LLMs, fine-tuning, and few-shot learning, using the Chain-of-Thought approach. We provide a detailed case study highlighting the most common limitations of these models. While our results imply that these models may have a long journey ahead to reach human-level reasoning, our work can be considered a robust baseline for the community to strive toward achieving this ambitious goal. Our code is available on GitHub https://github.com/MostafaRahgouy/LLMs_for_FPs for the community.  © 2023 Copyright for this paper by its authors.
KW  - Fermi Problems
KW  - Few-shot Learning
KW  - Fine-tuning
KW  - LLMs
KW  - Natural Language Reasoning
KW  - NLP
KW  - QA
KW  - Fermi problem
KW  - Few-shot learning
KW  - Fine tuning
KW  - Language model
KW  - Language processing
KW  - Large language model
KW  - Natural language processing
KW  - Natural language reasoning
KW  - Natural languages
KW  - QA
KW  - Natural language processing systems
A2  - Bassignana E.
A2  - Brunato D.
A2  - Polignano M.
A2  - Ramponi A.
PB  - CEUR-WS
SN  - 16130073 (ISSN)
LA  - English
J2  - CEUR Workshop Proc.
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 1; Correspondence Address: M. Rahgouy; Department of Computer Science and Software Engineering, Auburn University, Auburn, United States; email: MZR0108@auburn.edu; Conference name: 7th Workshop on Natural Language for Artificial Intelligence, NL4AI 2023; Conference date: 6 November 2023 through 7 November 2023; Conference code: 194401
ER  -

TY  - JOUR
AU  - Taira, K.
AU  - Itaya, T.
AU  - Hanada, A.
TI  - Performance of the Large Language Model ChatGPT on the National Nurse Examinations in Japan: Evaluation Study
PY  - 2023
T2  - JMIR Nursing
VL  - 6
IS  - 1
C7  - e47305
DO  - 10.2196/47305
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85171559992&doi=10.2196%2f47305&partnerID=40&md5=f46d47485b23b7b4006c9f92180c3367
AD  - Department of Human Health Sciences, Graduate School of Medicine, Kyoto University, Kyoto, Japan
AD  - Department of Healthcare Epidemiology, Graduate School of Medicine and Public Health, Kyoto University, Kyoto, Japan
AD  - Department of Preventive Medicine and Public Health, School of Medicine, Keio University, Tokyo, Japan
AB  - Background: ChatGPT, a large language model, has shown good performance on physician certification examinations and medical consultations. However, its performance has not been examined in languages other than English or on nursing examinations. Objective: We aimed to evaluate the performance of ChatGPT on the Japanese National Nurse Examinations. Methods: We evaluated the percentages of correct answers provided by ChatGPT (GPT-3.5) for all questions on the Japanese National Nurse Examinations from 2019 to 2023, excluding inappropriate questions and those containing images. Inappropriate questions were pointed out by a third-party organization and announced by the government to be excluded from scoring. Specifically, these include “questions with inappropriate question difficulty” and “questions with errors in the questions or choices.” These examinations consist of 240 questions each year, divided into basic knowledge questions that test the basic issues of particular importance to nurses and general questions that test a wide range of specialized knowledge. Furthermore, the questions had 2 types of formats: simple-choice and situation-setup questions. Simple-choice questions are primarily knowledge-based and multiple-choice, whereas situation-setup questions entail the candidate reading a patient’s and family situation’s description, and selecting the nurse's action or patient's response. Hence, the questions were standardized using 2 types of prompts before requesting answers from ChatGPT. Chi-square tests were conducted to compare the percentage of correct answers for each year's examination format and specialty area related to the question. In addition, a Cochran-Armitage trend test was performed with the percentage of correct answers from 2019 to 2023. Results: The 5-year average percentage of correct answers for ChatGPT was 75.1% (SD 3%) for basic knowledge questions and 64.5% (SD 5%) for general questions. The highest percentage of correct answers on the 2019 examination was 80% for basic knowledge questions and 71.2% for general questions. ChatGPT met the passing criteria for the 2019 Japanese National Nurse Examination and was close to passing the 2020-2023 examinations, with only a few more correct answers required to pass. ChatGPT had a lower percentage of correct answers in some areas, such as pharmacology, social welfare, related law and regulations, endocrinology/metabolism, and dermatology, and a higher percentage of correct answers in the areas of nutrition, pathology, hematology, ophthalmology, otolaryngology, dentistry and dental surgery, and nursing integration and practice. Conclusions: ChatGPT only passed the 2019 Japanese National Nursing Examination during the most recent 5 years. Although it did not pass the examinations from other years, it performed very close to the passing level, even in those containing questions related to psychology, communication, and nursing. © Kazuya Taira, Takahiro Itaya, Ayame Hanada.
KW  - artificial intelligence
KW  - ChatGPT
KW  - Japan
KW  - National Nurse Examination
KW  - natural language processing
KW  - registered nurses
PB  - JMIR Publications Inc.
SN  - 25627600 (ISSN)
LA  - English
J2  - JMIR. Nurs.
M3  - Article
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 3; Correspondence Address: K. Taira; Department of Human Health Sciences, Graduate School of Medicine, Kyoto University, Kyoto, 53, Shogoinkawara-cho, Sakyo-ku, 606-8501, Japan; email: taira.kazuya.5m@kyoto-u.ac.jp
ER  -

TY  - CONF
AU  - Wang, H.
AU  - Hee, M.S.
AU  - Awal, M.R.
AU  - Choo, K.T.W.
AU  - Lee, R.K.-W.
TI  - Evaluating GPT-3 Generated Explanations for Hateful Content Moderation
PY  - 2023
T2  - IJCAI International Joint Conference on Artificial Intelligence
VL  - 2023-August
SP  - 6255
EP  - 6263
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85170354116&partnerID=40&md5=eea4d7bb7008c38c6d908ce5e30bc477
AD  - Singapore University of Technology and Design, Singapore
AD  - Mila - Quebec AI Institute, Canada
AB  - Recent research has focused on using large language models (LLMs) to generate explanations for hate speech through fine-tuning or prompting. Despite the growing interest in this area, these generated explanations' effectiveness and potential limitations remain poorly understood. A key concern is that these explanations, generated by LLMs, may lead to erroneous judgments about the nature of flagged content by both users and content moderators. For instance, an LLM-generated explanation might inaccurately convince a content moderator that a benign piece of content is hateful. In light of this, we propose an analytical framework for examining hate speech explanations and conducted an extensive survey on evaluating such explanations. Specifically, we prompted GPT-3 to generate explanations for both hateful and non-hateful content, and a survey was conducted with 2,400 unique respondents to evaluate the generated explanations. Our findings reveal that (1) human evaluators rated the GPT-generated explanations as high quality in terms of linguistic fluency, informativeness, persuasiveness, and logical soundness, (2) the persuasive nature of these explanations, however, varied depending on the prompting strategy employed, and (3) this persuasiveness may result in incorrect judgments about the hatefulness of the content. Our study underscores the need for caution in applying LLM-generated explanations for content moderation. Code and results are available at https://github.com/Social-AI-Studio/GPT3-HateEval. © 2023 International Joint Conferences on Artificial Intelligence. All rights reserved.
KW  - Artificial intelligence
KW  - Quality control
KW  - Fine tuning
KW  - High quality
KW  - Informativeness
KW  - Language model
KW  - Logical soundness
KW  - Recent researches
KW  - Moderators
A2  - Elkind E.
PB  - International Joint Conferences on Artificial Intelligence
SN  - 10450823 (ISSN); 978-195679203-4 (ISBN)
LA  - English
J2  - IJCAI Int. Joint Conf. Artif. Intell.
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 1; Correspondence Address: H. Wang; Singapore University of Technology and Design, Singapore; email: han_wang@sutd.edu.sg; M.S. Hee; Singapore University of Technology and Design, Singapore; email: mingshan_hee@mymail.sutd.edu.sg; Conference name: 32nd International Joint Conference on Artificial Intelligence, IJCAI 2023; Conference date: 19 August 2023 through 25 August 2023; Conference code: 191872
ER  -

TY  - CONF
AU  - Kamalloo, E.
AU  - Dziri, N.
AU  - Clarke, C.L.A.
AU  - Rafiei, D.
TI  - Evaluating Open-Domain Question Answering in the Era of Large Language Models
PY  - 2023
T2  - Proceedings of the Annual Meeting of the Association for Computational Linguistics
VL  - 1
SP  - 5591
EP  - 5606
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85168624058&partnerID=40&md5=cdb20dda693869f65e45e8506f00c66e
AD  - University of Alberta, Canada
AD  - University of Waterloo, Canada
AD  - Allen Institute for Artificial Intelligence
AB  - Lexical matching remains the de facto evaluation method for open-domain question answering (QA). Unfortunately, lexical matching fails completely when a plausible candidate answer does not appear in the list of gold answers, which is increasingly the case as we shift from extractive to generative models. The recent success of large language models (LLMs) for QA aggravates lexical matching failures since candidate answers become longer, thereby making matching with the gold answers even more challenging. Without accurate evaluation, the true progress in open-domain QA remains unknown. In this paper, we conduct a thorough analysis of various open-domain QA models, including LLMs, by manually evaluating their answers on a subset of NQ-OPEN, a popular benchmark. Our assessments reveal that while the true performance of all models is significantly underestimated, the performance of the InstructGPT (zero-shot) LLM increases by nearly +60%, making it on par with existing top models, and the InstructGPT (few-shot) model actually achieves a new state-of-the-art on NQ-OPEN. We also find that more than 50% of lexical matching failures are attributed to semantically equivalent answers. We further demonstrate that regex matching ranks QA models consistent with human judgments, although still suffering from unnecessary strictness. Finally, we demonstrate that automated evaluation models are a reasonable surrogate for lexical matching in some circumstances, but not for long-form answers generated by LLMs. The automated models struggle in detecting hallucinations in LLM answers and are thus unable to evaluate LLMs. At this time, there appears to be no substitute for human evaluation. © 2023 Association for Computational Linguistics.
KW  - Gold
KW  - Zero-shot learning
KW  - Analysis of various
KW  - Evaluation methods
KW  - Generative model
KW  - Language model
KW  - Lexical matching
KW  - Matchings
KW  - Open domain question answering
KW  - Performance
KW  - Question Answering
KW  - State of the art
KW  - Computational linguistics
PB  - Association for Computational Linguistics (ACL)
SN  - 0736587X (ISSN); 978-195942972-2 (ISBN)
LA  - English
J2  - Proc. Annu. Meet. Assoc. Comput Linguist.
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 3; Conference name: 61st Annual Meeting of the Association for Computational Linguistics, ACL 2023; Conference date: 9 July 2023 through 14 July 2023; Conference code: 192160
ER  -

TY  - CONF
AU  - She, J.S.
AU  - Potts, C.
AU  - Bowman, S.R.
AU  - Geiger, A.
TI  - ScoNe: Benchmarking Negation Reasoning in Language Models With Fine-Tuning and In-Context Learning
PY  - 2023
T2  - Proceedings of the Annual Meeting of the Association for Computational Linguistics
VL  - 2
SP  - 1803
EP  - 1821
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85172181585&partnerID=40&md5=b2cb69be70ec5a88170877c05b10d652
AD  - Haverford College, United States
AD  - Stanford University, United States
AD  - New York University, Anthropic, PBC, United States
AB  - A number of recent benchmarks seek to assess how well models handle natural language negation. However, these benchmarks lack the controlled example paradigms that would allow us to infer whether a model had learned how negation morphemes semantically scope. To fill these analytical gaps, we present the Scoped Negation NLI (ScoNe-NLI) benchmark, which contains contrast sets of six examples with up to two negations where either zero, one, or both negative morphemes affect the NLI label. We use ScoNe-NLI to assess fine-tuning and in-context learning strategies. We find that RoBERTa and DeBERTa models solve ScoNe-NLI after many shot fine-tuning. For in-context learning, we test InstructGPT models and find that most prompt strategies are not successful, including those using step-by-step reasoning. To better understand this result, we extend ScoNe with ScoNe-NLG, a sentence completion test set that embeds negation reasoning in short narratives. Here, InstructGPT is successful, which reveals the model can correctly reason about negation, but struggles to do so on prompt-adapted NLI examples outside of its core pretraining regime. © 2023 Association for Computational Linguistics.
KW  - Computational linguistics
KW  - Natural language processing systems
KW  - Context learning
KW  - Fine tuning
KW  - In contexts
KW  - Language model
KW  - Learning strategy
KW  - Natural languages
KW  - Sentence completions
KW  - Test sets
KW  - Well model
KW  - Zero-one
KW  - Learning systems
PB  - Association for Computational Linguistics (ACL)
SN  - 0736587X (ISSN); 978-195942971-5 (ISBN)
LA  - English
J2  - Proc. Annu. Meet. Assoc. Comput Linguist.
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 0; Conference name: 61st Annual Meeting of the Association for Computational Linguistics, ACL 2023; Conference date: 9 July 2023 through 14 July 2023; Conference code: 192160
ER  -

TY  - CONF
AU  - Maiti, S.
AU  - Peng, Y.
AU  - Saeki, T.
AU  - Watanabe, S.
TI  - Speechlmscore: Evaluating Speech Generation Using Speech Language Model
PY  - 2023
T2  - ICASSP, IEEE International Conference on Acoustics, Speech and Signal Processing - Proceedings
VL  - 2023-June
DO  - 10.1109/ICASSP49357.2023.10095710
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85170850626&doi=10.1109%2fICASSP49357.2023.10095710&partnerID=40&md5=c29ed1a1dda61de39f4ac1bf13d29f4c
AD  - Carnegie Mellon University, United States
AD  - The University of Tokyo, Japan
AB  - While human evaluation is the most reliable metric for evaluating speech generation systems, it is generally costly and time-consuming. Previous studies on automatic speech quality assessment address the problem by predicting human evaluation scores with machine learning models. However, they rely on supervised learning and thus suffer from high annotation costs and domain-shift problems. We propose SpeechLMScore, an unsupervised metric to evaluate generated speech using a speech language model. SpeechLMScore computes the average log-probability of a speech signal by mapping it into discrete tokens and measures the average probability of generating the sequence of tokens. Therefore, it does not require human annotation and is a highly scalable framework. Evaluation results demonstrate that the proposed metric shows a promising correlation with human evaluation scores on different speech generation tasks including voice conversion, text-to-speech, and speech enhancement. © 2023 IEEE.
KW  - automatic speech quality assessment
KW  - discrete token
KW  - speech language model
KW  - Computational linguistics
KW  - Speech enhancement
KW  - Automatic speech
KW  - Automatic speech quality assessment
KW  - Discrete token
KW  - Generation systems
KW  - Human evaluation
KW  - Language model
KW  - Machine learning models
KW  - Speech generation
KW  - Speech language model
KW  - Speech quality assessment
KW  - Quality control
PB  - Institute of Electrical and Electronics Engineers Inc.
SN  - 15206149 (ISSN); 978-172816327-7 (ISBN)
LA  - English
J2  - ICASSP IEEE Int Conf Acoust Speech Signal Process Proc
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 0; Conference name: 48th IEEE International Conference on Acoustics, Speech and Signal Processing, ICASSP 2023; Conference date: 4 June 2023 through 10 June 2023; Conference code: 193814; CODEN: IPROD
ER  -

TY  - CONF
AU  - Pan, R.
AU  - Almela, Á.
AU  - García-Sánchez, F.
TI  - UMUTeam at PoliticIT-EVALITA2023: Evaluating Transformer Model for Detecting Political Ideology in Italian Texts
PY  - 2023
T2  - CEUR Workshop Proceedings
VL  - 3473
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85173557366&partnerID=40&md5=69d0ba0a28663cae9a4e3604036ce372
AD  - Facultad de Informática, Universidad de Murcia, Campus de Espinardo, 30100, Spain
AD  - Facultad de Letras, Universidad de Murcia, Campus de La Merced, Murcia, 30001, Spain
AB  - This paper describes the participation of the UMUTeam in the PoliticIT shared task organized at EVALITA 2023. It is an automatic document classification task on clusters of texts, which consists of extracting self-assigned gender as a demographic trait, and ideology as a psychographic trait through a set of texts written in Italian by several authors sharing these traits. For this task, we used the fine-tuning approach of a pre-trained transformer-based masked language model for Italian called dbmdz/bert-base-italian-cased to carry out the identification of different features. After several submissions for these tasks, our team ranked sixth out of 7 participants, with an average F1 score of 70.426% of all classification models. However, our binary political ideology classification model obtained the fourth-best result with an F1 score of 86.63%. © 2023 Copyright for this paper by its authors. Use permitted under Creative Commons License Attribution 4.0 International (CC BY 4.0).
KW  - Large Language Model
KW  - Multiclass classification
KW  - Natural Language Processing
KW  - Politic ideology detection
KW  - Transformers
KW  - Classification (of information)
KW  - Information retrieval systems
KW  - Natural language processing systems
KW  - F1 scores
KW  - Language model
KW  - Language processing
KW  - Large language model
KW  - Multi-class classification
KW  - Natural language processing
KW  - Natural languages
KW  - Politic ideology detection
KW  - Political ideologies
KW  - Transformer
KW  - Computational linguistics
A2  - Lai M.
A2  - Menini S.
A2  - Polignano M.
A2  - Russo V.
A2  - Sprugnoli R.
A2  - Venturi G.
PB  - CEUR-WS
SN  - 16130073 (ISSN)
LA  - English
J2  - CEUR Workshop Proc.
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 0; Correspondence Address: R. Pan; Facultad de Informática, Universidad de Murcia, Campus de Espinardo, 30100, Spain; email: ronghao.pan@um.es; Conference name: 8th Evaluation Campaign of Natural Language Processing and Speech Tools for Italian. Final Workshop, EVALITA 2023; Conference date: 7 September 2023 through 8 September 2023; Conference code: 192243
ER  -

TY  - CONF
AU  - Gontier, F.
AU  - Serizel, R.
AU  - Cerisara, C.
TI  - Spice+: Evaluation of Automatic Audio Captioning Systems with Pre-Trained Language Models
PY  - 2023
T2  - ICASSP, IEEE International Conference on Acoustics, Speech and Signal Processing - Proceedings
DO  - 10.1109/ICASSP49357.2023.10097021
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85173122074&doi=10.1109%2fICASSP49357.2023.10097021&partnerID=40&md5=31d132ebb9cc328d2fb45bbe02ce1650
AD  - Université de Lorraine, CNRS, Inria, Loria, F-54000, France
AB  - Audio captioning aims at describing acoustic scenes with natural language. Systems are currently evaluated by image captioning metrics CIDEr and SPICE. However, recent studies have highlighted a poor correlation of these metrics with human assessments. In this paper, we propose SPICE+, a modification of SPICE that improves caption annotation and comparison with pre-trained language models. The metric parses captions to semantic graphs with a deep dependency annotation model and a refined set of linguistic rules, then compares sentence embeddings of candidate and reference semantic elements. We formulate a score for general-purpose captioning evaluation, that can be tailored to more specific applications. Combined with fluency error detection, the metric achieves competitive performance on the FENSE benchmark, with 84.0% accuracy on AudioCaps and 74.1% on Clotho. Further experiments show that the metric behaves similarly to the full sentence embedding similarity, while the decomposition into semantic elements allows better interpretability of scores and can provide additional information on the properties of captioning systems.  © 2023 IEEE.
KW  - Audio captioning
KW  - DCASE
KW  - Evaluation
KW  - Audio systems
KW  - Benchmarking
KW  - Circuit simulation
KW  - Computational linguistics
KW  - Natural language processing systems
KW  - Semantics
KW  - 'spice'
KW  - Audio captioning
KW  - DCASE
KW  - Embeddings
KW  - Evaluation
KW  - Human assessment
KW  - Image captioning
KW  - Language model
KW  - Natural languages
KW  - Semantic element
KW  - Embeddings
PB  - Institute of Electrical and Electronics Engineers Inc.
SN  - 15206149 (ISSN)
LA  - English
J2  - ICASSP IEEE Int Conf Acoust Speech Signal Process Proc
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 2; Conference name: 48th IEEE International Conference on Acoustics, Speech and Signal Processing, ICASSP 2023; Conference date: 4 June 2023 through 10 June 2023; Conference code: 193814; CODEN: IPROD
ER  -

TY  - CONF
AU  - Perez, E.
AU  - Ringer, S.
AU  - Lukošiūtė, K.
AU  - Nguyen, K.
AU  - Chen, E.
AU  - Heiner, S.
AU  - Pettit, C.
AU  - Olsson, C.
AU  - Kundu, S.
AU  - Kadavath, S.
AU  - Jones, A.
AU  - Chen, A.
AU  - Mann, B.
AU  - Israel, B.
AU  - Seethor, B.
AU  - McKinnon, C.
AU  - Olah, C.
AU  - Yan, D.
AU  - Amodei, D.
AU  - Amodei, D.
AU  - Drain, D.
AU  - Li, D.
AU  - Tran-Johnson, E.
AU  - Khundadze, G.
AU  - Kernion, J.
AU  - Landis, J.
AU  - Kerr, J.
AU  - Mueller, J.
AU  - Hyun, J.
AU  - Landau, J.
AU  - Ndousse, K.
AU  - Goldberg, L.
AU  - Lovitt, L.
AU  - Lucas, M.
AU  - Sellitto, M.
AU  - Zhang, M.
AU  - Kingsland, N.
AU  - Elhage, N.
AU  - Joseph, N.
AU  - Mercado, N.
AU  - DasSarma, N.
AU  - Rausch, O.
AU  - Larson, R.
AU  - McCandlish, S.
AU  - Johnston, S.
AU  - Kravec, S.
AU  - Showk, S.EI.
AU  - Lanham, T.
AU  - Telleen-Lawton, T.
AU  - Brown, T.
AU  - Henighan, T.
AU  - Hume, T.
AU  - Bai, Y.
AU  - Hatfield-Dodds, Z.
AU  - Clark, J.
AU  - Bowman, S.R.
AU  - Askell, A.
AU  - Grosse, R.
AU  - Hernandez, D.
AU  - Ganguli, D.
AU  - Hubinger, E.
AU  - Schiefer, N.
AU  - Anthropic, J.K.
AU  - Surge, A.I.
TI  - Discovering Language Model Behaviors with Model-Written Evaluations
PY  - 2023
T2  - Proceedings of the Annual Meeting of the Association for Computational Linguistics
SP  - 13387
EP  - 13434
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85165978677&partnerID=40&md5=32c73fad0cbb92bae91833a215121d8f
AD  - Machine Intelligence Research Institute
AB  - As language models (LMs) scale, they develop many novel behaviors, good and bad, exacerbating the need to evaluate how they behave. Prior work creates evaluations with crowdwork (which is time-consuming and expensive) or existing data sources (which are not always available). Here, we automatically generate evaluations with LMs. We explore approaches with varying amounts of human effort, from instructing LMs to write yes/no questions to making complex Winogender schemas with multiple stages of LM-based generation and filtering. Crowdworkers rate the examples as highly relevant and agree with 90-100% of labels, sometimes more so than corresponding human-written datasets. We generate 154 datasets and discover new cases of inverse scaling where LMs get worse with size. Larger LMs repeat back a dialog user's preferred answer (“sycophancy”) and express greater desire to pursue concerning goals like resource acquisition and goal preservation. We also find some of the first examples of inverse scaling in RL from Human Feedback (RLHF), where more RLHF makes LMs worse. For example, RLHF makes LMs express stronger political views (on gun rights and immigration) and a greater desire to avoid shut down. Overall, LM-written evaluations are high-quality and let us quickly discover many novel LM behaviors. © 2023 Association for Computational Linguistics.
KW  - Quality control
KW  - Data-source
KW  - Language model
KW  - Model scale
KW  - Model-based OPC
KW  - Modeling behaviour
KW  - Multiple stages
KW  - New case
KW  - Political views
KW  - Resource acquisition
KW  - Scalings
KW  - Computational linguistics
PB  - Association for Computational Linguistics (ACL)
SN  - 0736587X (ISSN); 978-195942962-3 (ISBN)
LA  - English
J2  - Proc. Annu. Meet. Assoc. Comput Linguist.
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 2; Correspondence Address: ; ; ; Conference name: 61st Annual Meeting of the Association for Computational Linguistics, ACL 2023; Conference date: 9 July 2023 through 14 July 2023; Conference code: 192867
ER  -

TY  - CONF
AU  - Hemina, K.
AU  - Boumahdi, F.
AU  - Madani, A.
AU  - Remmide, M.A.
TI  - A Cross-Validated Fine-Tuned GPT-3 as a Novel Approach to Fake News Detection
PY  - 2023
T2  - Lecture Notes in Networks and Systems
VL  - 760 LNNS
SP  - 41
EP  - 48
DO  - 10.1007/978-3-031-40598-3_5
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85172095505&doi=10.1007%2f978-3-031-40598-3_5&partnerID=40&md5=e34b33bddf04392734cdebcb0d1d79bd
AD  - LRDSI laboratory, sciences faculty, Saad Dahlab Blida University, PB 270, Soumaa road, Blida, 09000, Algeria
AB  - Fake news is a term used to describe inaccurate information that has been disseminated to the public. This paper presents a novel approach to detect fake news using fine-tuned state-of-the-art language model, GPT-3. We fine-tuned the Generative Pre-trained Transformer 3 (GPT-3) model on the ISOT dataset to predict whether a given piece of text is likely to be fake news. We evaluated the performance of the model using accuracy, precision, recall, and F1-score. Our experiments showed that fine-tuning GPT-3 for fake news detection led to significant improvements in performance compared to the existing models. The fine-tuned model achieved an accuracy of 99.90%, a precision of 99.81%, a recall of 99.99%, and an F1 score of 99.90%. These results demonstrate the effectiveness of the fine-tuned GPT-3 model for fake news detection. Overall, our approach demonstrates the potential of fine-tuning GPT-3 for fake news detection, and the results suggest that it is a promising solution for addressing the growing problem of misinformation in social media and online news. © 2023, The Author(s), under exclusive license to Springer Nature Switzerland AG.
KW  - classification
KW  - cross validation
KW  - deep learning
KW  - Fake news
KW  - GPT-3
KW  - Fake detection
KW  - Cross validation
KW  - Deep learning
KW  - F1 scores
KW  - Fake news
KW  - Fine tuning
KW  - Generative pre-trained transformer 3
KW  - Inaccurate information
KW  - Language model
KW  - Performance
KW  - State of the art
KW  - Deep learning
A2  - Zantout H.
A2  - Ragab Hassen H.
PB  - Springer Science and Business Media Deutschland GmbH
SN  - 23673370 (ISSN); 978-303140597-6 (ISBN)
LA  - English
J2  - Lect. Notes Networks Syst.
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 0; Correspondence Address: K. Hemina; LRDSI laboratory, sciences faculty, Saad Dahlab Blida University, Blida, PB 270, Soumaa road, 09000, Algeria; email: hemina.karim@etu.univ-blida.dz; Conference name: Proceedings of the 2nd International Conference on Applied Cyber Security, ACS 2023; Conference date: 29 April 2023 through 29 April 2023; Conference code: 300499
ER  -

TY  - JOUR
AU  - Moskatel, L.S.
AU  - Zhang, N.
TI  - The utility of ChatGPT in the assessment of literature on the prevention of migraine: an observational, qualitative study
PY  - 2023
T2  - Frontiers in Neurology
VL  - 14
C7  - 1225223
DO  - 10.3389/fneur.2023.1225223
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85169611080&doi=10.3389%2ffneur.2023.1225223&partnerID=40&md5=99b5d0e4dea85673727132170b7777de
AD  - Division of Headache and Facial Pain, Department of Neurology, Stanford University, Palo Alto, CA, United States
AB  - Background: It is not known how large language models, such as ChatGPT, can be applied toward the assessment of the efficacy of medications, including in the prevention of migraine, and how it might support those claims with existing medical evidence. Methods: We queried ChatGPT-3.5 on the efficacy of 47 medications for the prevention of migraine and then asked it to give citations in support of its assessment. ChatGPT’s evaluations were then compared to their FDA approval status for this indication as well as the American Academy of Neurology 2012 evidence-based guidelines for the prevention of migraine. The citations ChatGPT generated for these evaluations were then assessed to see if they were real papers and if they were relevant to the query. Results: ChatGPT affirmed that the 14 medications that have either received FDA approval for prevention of migraine or AAN Grade A/B evidence were effective for migraine. Its assessments of the other 33 medications were unreliable including suggesting possible efficacy for four medications that have never been used for the prevention of migraine. Critically, only 33/115 (29%) of the papers ChatGPT cited were real, while 76/115 (66%) were “hallucinated” not real papers and 6/115 (5%) shared the names of real papers but had not real citations. Conclusion: While ChatGPT produced tailored answers on the efficacy of the queried medications, the results were unreliable and inaccurate because of the overwhelming volume of “hallucinated” articles it generated and cited. Copyright © 2023 Moskatel and Zhang.
KW  - artificial intelligence
KW  - ChatGPT
KW  - evidence-based medicine
KW  - migraine
KW  - preventive medications
KW  - botulinum toxin A
KW  - galcanezumab
KW  - Article
KW  - artificial intelligence
KW  - ChatGPT
KW  - drug efficacy
KW  - evidence based medicine
KW  - human
KW  - Medline
KW  - migraine
KW  - receiver operating characteristic
KW  - search engine
PB  - Frontiers Media SA
SN  - 16642295 (ISSN)
LA  - English
J2  - Front. Neurol.
M3  - Article
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 3; Correspondence Address: L.S. Moskatel; Division of Headache and Facial Pain, Department of Neurology, Stanford University, Palo Alto, United States; email: moskatel@stanford.edu
ER  -

TY  - CONF
AU  - Babu, R.N.
AU  - Lung, C.-H.
AU  - Zaman, M.
TI  - Performance Evaluation of Transformer-based NLP Models on Fake News Detection Datasets
PY  - 2023
T2  - Proceedings - International Computer Software and Applications Conference
VL  - 2023-June
SP  - 316
EP  - 321
DO  - 10.1109/COMPSAC57700.2023.00049
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85168867917&doi=10.1109%2fCOMPSAC57700.2023.00049&partnerID=40&md5=c0ba0ac9f24603e6ea2ee44c2915dade
AD  - Carleton University, Dept. of Systems and Computer Engineering, Ottawa, Canada
AD  - R&D Cistel Technology, Ottawa, Canada
AB  - Fake news has become a major concern due to its spread on social media. To combat this, various machine learning (ML) techniques have been proposed. However, there is a lack of research on the performance of transformer models using datasets from a wide range of domains. This paper investigates the performance of ML algorithms on three fake news datasets: LIAR, FNC-1 and Balanced Dataset for Fake News Analysis. Pretrained transformer language models such as BERT, RoBERTa, ALBERT and DistilBERT were chosen for this paper. The performance of the models was consistent across all datasets. RoBERTa obtained an accuracy of 69% when trained on the LIAR dataset, an 11% improvement over the existing traditional and deep learning ML model implementations, and an accuracy of 97% when trained on the FNC-1 dataset, proving to be the best-performing model across all the fake news detection datasets utilized in the experiments. DistilBERT trains at a significantly faster rate than the other three variants. The experimental results from the paper can help the research community to continue investigating and gain insights into fake news detection. © 2023 IEEE.
KW  - Applied Data Science
KW  - Data Visualization
KW  - Fake News Detection
KW  - Machine Learning
KW  - Natural Language Processing
KW  - Transformer Models
KW  - Data visualization
KW  - Deep learning
KW  - Fake detection
KW  - Learning algorithms
KW  - Learning systems
KW  - Applied data science
KW  - Fake news detection
KW  - Language processing
KW  - Machine-learning
KW  - Natural language processing
KW  - Natural languages
KW  - Performance
KW  - Performances evaluation
KW  - Social media
KW  - Transformer modeling
KW  - Natural language processing systems
A2  - Shahriar H.
A2  - Teranishi Y.
A2  - Cuzzocrea A.
A2  - Sharmin M.
A2  - Towey D.
A2  - Majumder AKM.J.A.
A2  - Kashiwazaki H.
A2  - Yang J.-J.
A2  - Takemoto M.
A2  - Sakib N.
A2  - Banno R.
A2  - Ahamed S.I.
PB  - IEEE Computer Society
SN  - 07303157 (ISSN); 979-835032697-0 (ISBN)
LA  - English
J2  - Proc Int Comput Software Appl Conf
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 0; Correspondence Address: R.N. Babu; Carleton University, Dept. of Systems and Computer Engineering, Ottawa, Canada; email: raveennarendrababu@cmail.carleton.ca; Conference name: 47th IEEE Annual Computers, Software, and Applications Conference, COMPSAC 2023; Conference date: 26 June 2023 through 30 June 2023; Conference code: 191323; CODEN: PSICD
ER  -

TY  - CONF
AU  - Ding, H.
AU  - Kumar, V.
AU  - Tian, Y.
AU  - Wang, Z.
AU  - Kwiatkowski, R.
AU  - Li, X.
AU  - Ramanathan, M.K.
AU  - Ray, B.
AU  - Bhatia, P.
AU  - Sengupta, S.
AU  - Roth, D.
AU  - Xiang, B.
TI  - A Static Evaluation of Code Completion by Large Language Models
PY  - 2023
T2  - Proceedings of the Annual Meeting of the Association for Computational Linguistics
VL  - 5
SP  - 347
EP  - 360
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85174223789&partnerID=40&md5=908d498fe60c8e2f24187b9e72d9faec
AD  - Aws Ai Labs
AB  - Large language models trained on code have shown great potential to increase productivity of software developers. Several execution-based benchmarks have been proposed to evaluate functional correctness of model-generated code on simple programming problems. Nevertheless, it is expensive to perform the same evaluation on complex real-world projects considering the execution cost. On the contrary, static analysis tools such as linters, which can detect errors without running the program, haven't been well explored for evaluating code generation models. In this work, we propose a static evaluation framework to quantify static errors in Python code completions, by leveraging Abstract Syntax Trees. Compared with execution-based evaluation, our method is not only more effcient, but also applicable to code in the wild. For experiments, we collect code context from open source repos to generate one million function bodies using public models. Our static analysis reveals that Undefned Name and Unused Variable are the most common errors among others made by language models. Through extensive studies, we also show the impact of sampling temperature, model size, and context on static errors in code completions. © ACL 2023.All rights reserved.
KW  - Computational linguistics
KW  - Errors
KW  - Functional programming
KW  - Open source software
KW  - Open systems
KW  - Syntactics
KW  - Trees (mathematics)
KW  - Code completions
KW  - Execution costs
KW  - Functional correctness
KW  - Language model
KW  - Programming problem
KW  - Real world projects
KW  - Simple++
KW  - Software developer
KW  - Static error
KW  - Static evaluation
KW  - Static analysis
PB  - Association for Computational Linguistics (ACL)
SN  - 0736587X (ISSN); 978-195942968-5 (ISBN)
LA  - English
J2  - Proc. Annu. Meet. Assoc. Comput Linguist.
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 0; Conference name: 61st Annual Meeting of the Association for Computational Linguistics, ACL 2023; Conference date: 10 July 2023 through 12 July 2023; Conference code: 192160
ER  -

TY  - CONF
AU  - Caines, A.
AU  - Benedetto, L.
AU  - Taslimipoor, S.
AU  - Davis, C.
AU  - Gao, Y.
AU  - Andersen, Ø.
AU  - Yuan, Z.
AU  - Elliott, M.
AU  - Moore, R.
AU  - Bryant, C.
AU  - Rei, M.
AU  - Yannakoudakis, H.
AU  - Mullooly, A.
AU  - Nicholls, D.
AU  - Buttery, P.
TI  - On the application of Large Language Models for language teaching and assessment technology
PY  - 2023
T2  - CEUR Workshop Proceedings
VL  - 3487
SP  - 173
EP  - 197
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85166949408&partnerID=40&md5=014f979b6a3ecf7a4fb39ebd3758212f
AD  - ALTA Institute & Computer Laboratory, University of Cambridge, United Kingdom
AD  - King's College London, United Kingdom
AD  - Cambridge University Press & Assessment, United Kingdom
AD  - Writer, Inc.
AD  - Imperial College London, United Kingdom
AD  - English Language iTutoring (ELiT), United Kingdom
AB  - The recent release of very large language models such as PaLM and GPT-4 has made an unprecedented impact in the popular media and public consciousness, giving rise to a mixture of excitement and fear as to their capabilities and potential uses, and shining a light on natural language processing research which had not previously received so much attention. The developments offer great promise for education technology, and in this paper we look specifically at the potential for incorporating large language models in AI-driven language teaching and assessment systems. We consider several research areas - content creation and calibration, assessment and feedback - and also discuss the risks and ethical considerations surrounding generative AI in education technology for language learners. Overall we find that larger language models offer improvements over previous models in text generation, opening up routes toward content generation which had not previously been plausible. For text generation they must be prompted carefully and their outputs may need to be reshaped before they are ready for use. For automated grading and grammatical error correction, tasks whose progress is checked on well-known benchmarks, early investigations indicate that large language models on their own do not improve on state-of-the-art results according to standard evaluation metrics. For grading it appears that linguistic features established in the literature should still be used for best performance, and for error correction it may be that the models can offer alternative feedback styles which are not measured sensitively with existing methods. In all cases, there is work to be done to experiment with the inclusion of large language models in education technology for language learners, in order to properly understand and report on their capacities and limitations, and to ensure that foreseeable risks such as misinformation and harmful bias are mitigated. © 2023 Copyright for this paper by its authors. Use permitted under Creative Commons License Attribution 4.0 International (CC BY 4.0).
KW  - automated assessment
KW  - education technology
KW  - grammatical error correction
KW  - large language models
KW  - natural language processing
KW  - question difficulty estimation
KW  - responsible AI
KW  - text generation
KW  - Artificial intelligence
KW  - Computational linguistics
KW  - Grading
KW  - Natural language processing systems
KW  - Petroleum reservoir evaluation
KW  - Risk assessment
KW  - Automated assessment
KW  - Difficulty estimations
KW  - Education technology
KW  - Errors correction
KW  - Grammatical error correction
KW  - Grammatical errors
KW  - Language model
KW  - Language processing
KW  - Large language model
KW  - Natural language processing
KW  - Natural languages
KW  - Question difficulty estimation
KW  - Responsible AI
KW  - Text generations
KW  - Error correction
A2  - Moore S.
A2  - Stamper J.
A2  - Tong R.
A2  - Cao C.
A2  - Liu Z.
A2  - Hu X.
A2  - Lu Y.
A2  - Liang J.
A2  - Khosravi H.
A2  - Denny P.
A2  - Singh A.
A2  - Brooks C.
PB  - CEUR-WS
SN  - 16130073 (ISSN)
LA  - English
J2  - CEUR Workshop Proc.
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 3; Correspondence Address: A. Caines; ALTA Institute & Computer Laboratory, University of Cambridge, United Kingdom; email: andrew.caines@cl.cam.ac.uk; Conference name: 1st Annual Workshop on Empowering Education with LLMs - the Next-Gen Interface and Content Generation, AIEDLLM 2023; Conference code: 192705
ER  -

TY  - CONF
AU  - Moore, S.
AU  - Nguyen, H.A.
AU  - Chen, T.
AU  - Stamper, J.
TI  - Assessing the Quality of Multiple-Choice Questions Using GPT-4 and Rule-Based Methods
PY  - 2023
T2  - Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)
VL  - 14200 LNCS
SP  - 229
EP  - 245
DO  - 10.1007/978-3-031-42682-7_16
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85171993846&doi=10.1007%2f978-3-031-42682-7_16&partnerID=40&md5=6cd1746f18c56d147f5be8ef75117776
AD  - Carnegie Mellon University, Pittsburgh, 15213, PA, United States
AB  - Multiple-choice questions with item-writing flaws can negatively impact student learning and skew analytics. These flaws are often present in student-generated questions, making it difficult to assess their quality and suitability for classroom usage. Existing methods for evaluating multiple-choice questions often focus on machine readability metrics, without considering their intended use within course materials and their pedagogical implications. In this study, we compared the performance of a rule-based method we developed to a machine-learning based method utilizing GPT-4 for the task of automatically assessing multiple-choice questions based on 19 common item-writing flaws. By analyzing 200 student-generated questions from four different subject areas, we found that the rule-based method correctly detected 91% of the flaws identified by human annotators, as compared to 79% by GPT-4. We demonstrated the effectiveness of the two methods in identifying common item-writing flaws present in the student-generated questions across different subject areas. The rule-based method can accurately and efficiently evaluate multiple-choice questions from multiple domains, outperforming GPT-4 and going beyond existing metrics that do not account for the educational use of such questions. Finally, we discuss the potential for using these automated methods to improve the quality of questions based on the identified flaws. © 2023, The Author(s), under exclusive license to Springer Nature Switzerland AG.
KW  - GPT-4
KW  - Question evaluation
KW  - Question quality
KW  - Rule-based
KW  - Learning systems
KW  - Students
KW  - Course material
KW  - GPT-4
KW  - Multiple-choice questions
KW  - On-machines
KW  - Question evaluation
KW  - Question quality
KW  - Rule based
KW  - Rule-based method
KW  - Student learning
KW  - Student-Generated Questions
KW  - Quality control
A2  - Viberg O.
A2  - Jivet I.
A2  - Muñoz-Merino P.J.
A2  - Perifanou M.
A2  - Papathoma T.
PB  - Springer Science and Business Media Deutschland GmbH
SN  - 03029743 (ISSN); 978-303142681-0 (ISBN)
LA  - English
J2  - Lect. Notes Comput. Sci.
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 0; Correspondence Address: S. Moore; Carnegie Mellon University, Pittsburgh, 15213, United States; email: StevenJamesMoore@gmail.com; Conference name: Proceedings of the 18th European Conference on Technology Enhanced Learning, ECTEL 2023; Conference date: 4 September 2023 through 8 September 2023; Conference code: 299989
ER  -

TY  - CONF
AU  - He, M.
AU  - Garner, P.N.
TI  - Can ChatGPT Detect Intent? Evaluating Large Language Models for Spoken Language Understanding
PY  - 2023
T2  - Proceedings of the Annual Conference of the International Speech Communication Association, INTERSPEECH
VL  - 2023-August
SP  - 1109
EP  - 1113
DO  - 10.21437/Interspeech.2023-1799
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85171556778&doi=10.21437%2fInterspeech.2023-1799&partnerID=40&md5=21358d4cb03e617eb71940b9df54cee3
AD  - Idiap Research Institute, Martigny, Switzerland
AD  - Ecole Polytechnique Fédérale de Lausanne, Switzerland
AB  - Recently, large pretrained language models have demonstrated strong language understanding capabilities. This is particularly reflected in their zero-shot and in-context learning abilities on downstream tasks through prompting. To assess their impact on spoken language understanding (SLU), we evaluate several such models like ChatGPT and OPT of different sizes on multiple benchmarks. We verify the emergent ability unique to the largest models as they can reach intent classification accuracy close to that of supervised models with zero or few shots on various languages given oracle transcripts. By contrast, the results for smaller models fitting a single GPU fall far behind. We note that the error cases often arise from the annotation scheme of the dataset; responses from ChatGPT are still reasonable. We show, however, that the model is worse at slot filling, and its performance is sensitive to ASR errors, suggesting serious challenges for the application of those textual models on SLU. © 2023 International Speech Communication Association. All rights reserved.
KW  - in-context learning
KW  - pretrained language models
KW  - spoken language understanding
KW  - zero-shot learning
KW  - Computational linguistics
KW  - Learning systems
KW  - Speech communication
KW  - Speech recognition
KW  - Context learning
KW  - Different sizes
KW  - Down-stream
KW  - In contexts
KW  - In-context learning
KW  - Language model
KW  - Language understanding
KW  - Learning abilities
KW  - Pretrained language model
KW  - Spoken language understanding
KW  - Zero-shot learning
PB  - International Speech Communication Association
SN  - 2308457X (ISSN)
LA  - English
J2  - Proc. Annu. Conf. Int. Speech. Commun. Assoc., INTERSPEECH
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 1; Conference name: 24th International Speech Communication Association, Interspeech 2023; Conference date: 20 August 2023 through 24 August 2023; Conference code: 191724
ER  -

TY  - JOUR
AU  - Patil, N.S.
AU  - Huang, R.S.
AU  - van der Pol, C.B.
AU  - Larocque, N.
TI  - Comparative Performance of ChatGPT and Bard in a Text-Based Radiology Knowledge Assessment
PY  - 2023
T2  - Canadian Association of Radiologists Journal
DO  - 10.1177/08465371231193716
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85168084433&doi=10.1177%2f08465371231193716&partnerID=40&md5=a439158d1fa4667afa88efa6ff30fd52
AD  - Michael G. DeGroote School of Medicine, McMaster University, Hamilton, ON, Canada
AD  - Temerty Faculty of Medicine, University of Toronto, Toronto, ON, Canada
AD  - Department of Diagnostic Imaging, Hamilton Health Sciences, Juravinski Hospital and Cancer Centre, Hamilton, ON, Canada
AD  - Department of Radiology, McMaster University, Hamilton, ON, Canada
AB  - Purpose: Bard by Google, a direct competitor to ChatGPT, was recently released. Understanding the relative performance of these different chatbots can provide important insight into their strengths and weaknesses as well as which roles they are most suited to fill. In this project, we aimed to compare the most recent version of ChatGPT, ChatGPT-4, and Bard by Google, in their ability to accurately respond to radiology board examination practice questions. Methods: Text-based questions were collected from the 2017-2021 American College of Radiology’s Diagnostic Radiology In-Training (DXIT) examinations. ChatGPT-4 and Bard were queried, and their comparative accuracies, response lengths, and response times were documented. Subspecialty-specific performance was analyzed as well. Results: 318 questions were included in our analysis. ChatGPT answered significantly more accurately than Bard (87.11% vs 70.44%, P <.0001). ChatGPT’s response length was significantly shorter than Bard’s (935.28 ± 440.88 characters vs 1437.52 ± 415.91 characters, P <.0001). ChatGPT’s response time was significantly longer than Bard’s (26.79 ± 3.27 seconds vs 7.55 ± 1.88 seconds, P <.0001). ChatGPT performed superiorly to Bard in neuroradiology, (100.00% vs 86.21%, P =.03), general & physics (85.39% vs 68.54%, P <.001), nuclear medicine (80.00% vs 56.67%, P <.01), pediatric radiology (93.75% vs 68.75%, P =.03), and ultrasound (100.00% vs 63.64%, P <.001). In the remaining subspecialties, there were no significant differences between ChatGPT and Bard’s performance. Conclusion: ChatGPT displayed superior radiology knowledge compared to Bard. While both chatbots display reasonable radiology knowledge, they should be used with conscious knowledge of their limitations and fallibility. Both chatbots provided incorrect or illogical answer explanations and did not always address the educational content of the question. © The Author(s) 2023.
KW  - artificial intelligence
KW  - Bard
KW  - chatbot
KW  - ChatGPT
KW  - Google
KW  - radiology
PB  - SAGE Publications Inc.
SN  - 08465371 (ISSN)
C2  - 37578849
LA  - English
J2  - Can. Assoc. Radiol. J.
M3  - Article
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 10; Correspondence Address: N. Larocque; Department of Radiology, McMaster University, Hamilton, Canada; email: natasha.larocque@medportal.ca; CODEN: JCARA
ER  -

TY  - CONF
AU  - Ionescu, V.M.
AU  - Enescu, M.C.
TI  - Using ChatGPT for Generating and Evaluating Online Tests
PY  - 2023
T2  - 15th International Conference on Electronics, Computers and Artificial Intelligence, ECAI 2023 - Proceedings
DO  - 10.1109/ECAI58194.2023.10193995
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85168128511&doi=10.1109%2fECAI58194.2023.10193995&partnerID=40&md5=b707e466346031f5ceeb6a231ac1fb94
AD  - University of Pitesti, Department of Electronics, Communications and Computers, Pitesti, Romania
AD  - Political Sciences National, School of Political and Administrative Studies, Bucharest, Romania
AB  - Creating multiple choice online tests is a time-consuming task involving manual creation of both questions and possible answers in order to simplify and automate the process of test evaluation. This system is prone to cheating if the person being evaluated obtains the questions and answers. In some domains essay type questionnaires are needed, but they need time to be evaluated as the process cannot be automated. This paper investigates the use of ChatGPT-3 natural language processing to generate the quiz questions based on human prompt and to automatically grade the answers of an essay type test. This paper presents a NodeJS test implementation of such a system, the results obtained and the challenges of this process. © 2023 IEEE.
KW  - artificial intelligence
KW  - automated grading
KW  - ChatGPT
KW  - NodeJs
KW  - quiz generator
KW  - quiz grading
KW  - Natural language processing systems
KW  - Automated grading
KW  - ChatGPT
KW  - Multiple choice
KW  - Natural languages
KW  - Nodejs
KW  - Online tests
KW  - Quiz generator
KW  - Quiz grading
KW  - Test evaluation
KW  - Time-consuming tasks
KW  - Grading
PB  - Institute of Electrical and Electronics Engineers Inc.
SN  - 979-835032138-8 (ISBN)
LA  - English
J2  - Int. Conf. Electron., Comput. Artif. Intell., ECAI - Proc.
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 0; Conference name: 15th International Conference on Electronics, Computers and Artificial Intelligence, ECAI 2023; Conference date: 29 June 2023 through 30 June 2023; Conference code: 191300
ER  -

TY  - CONF
AU  - Del, M.
AU  - Fishel, M.
TI  - True Detective: A Deep Abductive Reasoning Benchmark Undoable for GPT-3 and Challenging for GPT-4
PY  - 2023
T2  - Proceedings of the Annual Meeting of the Association for Computational Linguistics
SP  - 314
EP  - 322
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85171864617&partnerID=40&md5=b3645509e61b9b3f40d1daac86c3ddc1
AD  - Institute of Computer Science, University of Tartu, Estonia
AB  - Large language models (LLMs) have demonstrated solid zero-shot reasoning capabilities, which is reflected in their performance on the current test tasks. This calls for a more challenging benchmark requiring highly advanced reasoning ability to be solved. In this paper, we introduce such a benchmark, consisting of 191 long-form (1200 words on average) mystery narratives constructed as detective puzzles. Puzzles are sourced from the "5 Minute Mystery" platform and include a multiple-choice question for evaluation. Only 47% of humans solve a puzzle successfully on average, while the best human solvers achieve over 80% success rate. We show that GPT-3 models barely outperform random on this benchmark (with 28% accuracy) while state-of-the-art GPT-4 solves only 38% of puzzles. This indicates that there is still a significant gap in the deep reasoning abilities of LLMs and humans and highlights the need for further research in this area. Our work introduces a challenging benchmark for future studies on reasoning in language models and contributes to a better understanding of the limits of LLMs' abilities. © 2023 Association for Computational Linguistics.
KW  - Computational linguistics
KW  - Abductive reasoning
KW  - Current test
KW  - Language model
KW  - Modeling abilities
KW  - Multiple-choice questions
KW  - Performance
KW  - Reasoning ability
KW  - Reasoning capabilities
KW  - State of the art
KW  - Test tasks
KW  - Zero-shot learning
A2  - Palmer A.
A2  - Camacho-Collados J.
PB  - Association for Computational Linguistics (ACL)
SN  - 0736587X (ISSN); 978-195942976-0 (ISBN)
LA  - English
J2  - Proc. Annu. Meet. Assoc. Comput Linguist.
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 0; Conference name: 12th Joint Conference on Lexical and Computational Semantics, StarSEM 2023, co-located with ACL 2023; Conference date: 13 July 2023 through 14 July 2023; Conference code: 193197
ER  -

TY  - JOUR
AU  - Sallam, M.
AU  - Salim, N.A.
AU  - Barakat, M.
AU  - Al-Mahzoum, K.
AU  - Al-Tammemi, A.B.
AU  - Malaeb, D.
AU  - Hallit, R.
AU  - Hallit, S.
TI  - Assessing Health Students' Attitudes and Usage of ChatGPT in Jordan: Validation Study
PY  - 2023
T2  - JMIR Medical Education
VL  - 9
IS  - 1
C7  - e48254
DO  - 10.2196/48254
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85173941987&doi=10.2196%2f48254&partnerID=40&md5=b23c3811c3e4728438d3aece352d1138
AD  - Department of Pathology, Microbiology and Forensic Medicine, School of Medicine, The University of Jordan, Amman, Jordan
AD  - Department of Clinical Laboratories and Forensic Medicine, Jordan University Hospital, Amman, Jordan
AD  - Prosthodontic Department, School of Dentistry, The University of Jordan, Amman, Jordan
AD  - Prosthodontic Department, Jordan University Hospital, Amman, Jordan
AD  - Department of Clinical Pharmacy and Therapeutics, Faculty of Pharmacy, Applied Science Private University, Amman, Jordan
AD  - Middle East University Research Unit, Middle East University, Amman, Jordan
AD  - Migration Health Division, International Organization for Migration, The United Nations Migration Agency, Amman, Jordan
AD  - College of Pharmacy, Gulf Medical University, Ajman, United Arab Emirates
AD  - School of Medicine and Medical Sciences, Holy Spirit University of Kaslik, Jounieh, Lebanon
AD  - Department of Infectious Disease, Bellevue Medical Center, Mansourieh, Lebanon
AD  - Department of Infectious Disease, Notre Dame des Secours, University Hospital Center, Byblos, Lebanon
AD  - Research Department, Psychiatric Hospital of the Cross, Jal Eddib, Lebanon
AB  - Background: ChatGPT is a conversational large language model that has the potential to revolutionize knowledge acquisition. However, the impact of this technology on the quality of education is still unknown considering the risks and concerns surrounding ChatGPT use. Therefore, it is necessary to assess the usability and acceptability of this promising tool. As an innovative technology, the intention to use ChatGPT can be studied in the context of the technology acceptance model (TAM). Objective: This study aimed to develop and validate a TAM-based survey instrument called TAME-ChatGPT (Technology Acceptance Model Edited to Assess ChatGPT Adoption) that could be employed to examine the successful integration and use of ChatGPT in health care education. Methods: The survey tool was created based on the TAM framework. It comprised 13 items for participants who heard of ChatGPT but did not use it and 23 items for participants who used ChatGPT. Using a convenient sampling approach, the survey link was circulated electronically among university students between February and March 2023. Exploratory factor analysis (EFA) was used to assess the construct validity of the survey instrument. Results: The final sample comprised 458 respondents, the majority among them undergraduate students (n=442, 96.5%). Only 109 (23.8%) respondents had heard of ChatGPT prior to participation and only 55 (11.3%) self-reported ChatGPT use before the study. EFA analysis on the attitude and usage scales showed significant Bartlett tests of sphericity scores (P<.001) and adequate Kaiser-Meyer-Olkin measures (0.823 for the attitude scale and 0.702 for the usage scale), confirming the factorability of the correlation matrices. The EFA showed that 3 constructs explained a cumulative total of 69.3% variance in the attitude scale, and these subscales represented perceived risks, attitude to technology/social influence, and anxiety. For the ChatGPT usage scale, EFA showed that 4 constructs explained a cumulative total of 72% variance in the data and comprised the perceived usefulness, perceived risks, perceived ease of use, and behavior/cognitive factors. All the ChatGPT attitude and usage subscales showed good reliability with Cronbach α values >.78 for all the deduced subscales. Conclusions: The TAME-ChatGPT demonstrated good reliability, validity, and usefulness in assessing health care students’ attitudes toward ChatGPT. The findings highlighted the importance of considering risk perceptions, usefulness, ease of use, attitudes toward technology, and behavioral factors when adopting ChatGPT as a tool in health care education. This information can aid the stakeholders in creating strategies to support the optimal and ethical use of ChatGPT and to identify the potential challenges hindering its successful implementation. Future research is recommended to guide the effective adoption of ChatGPT in health care education. ©Malik Sallam, Nesreen A Salim, Muna Barakat, Kholoud Al-Mahzoum, Ala'a B Al-Tammemi, Diana Malaeb, Rabih Hallit, Souheil Hallit.
KW  - artificial intelligence
KW  - education
KW  - healthcare
KW  - KAP
KW  - knowledge
KW  - machine learning
KW  - opinion
KW  - practices
KW  - survey
KW  - technology
PB  - JMIR Publications Inc.
SN  - 23693762 (ISSN)
LA  - English
J2  - JMIR Med. Educ.
M3  - Article
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 6; Correspondence Address: M. Sallam; Department of Pathology, Microbiology and Forensic Medicine, School of Medicine, The University of Jordan, Amman, Queen Rania Al-Abdullah Street-Aljubeiha, 11942, Jordan; email: malik.sallam@ju.edu.jo
ER  -

TY  - CONF
AU  - Leu, B.
AU  - Seritan, G.
AU  - Enache, B.
AU  - Tanasescu, G.
AU  - Porumb, R.
AU  - Vilciu, I.
TI  - Power Transformers Loss Of Life Evaluation Using Winding Insulation Resistance Calculation Model
PY  - 2023
T2  - 15th International Conference on Electronics, Computers and Artificial Intelligence, ECAI 2023 - Proceedings
DO  - 10.1109/ECAI58194.2023.10193960
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85168162834&doi=10.1109%2fECAI58194.2023.10193960&partnerID=40&md5=5049be893673bf8886cd5eabaf81c414
AD  - Technical, Energy Efficiency and New Technologies Division Transelectrica, Bucharest, Romania
AD  - Politehnica University of Bucharest, Electrical Engineering Faculty, Bucharest, Romania
AD  - Simtech International, Bucharest, Romania
AB  - The conventional calculation of the loss of life of power transformers is based on IEC and IEEE thermal models that are used already for a long time in the energy sector to evaluate the ageing of transformers and they are integrated in most of the condition monitoring systems. Due to some recent research studies, there was determined a new method to calculate the lost and remaining lifetime of power transformers, based on a new model that is using the values of winding insulation resistance. In this paper, will be presented a study were this new ageing evaluation model will be used to calculate the loss of life of several power transformers installed in the Romanian transmission power grid. The results of this case study will be statistically compared with the results of the conventional thermal model, using data from the condition monitoring systems installed on the power transformer. © 2023 IEEE.
KW  - ageing
KW  - insulation resistance
KW  - loss of life
KW  - Power transformer
KW  - Condition monitoring
KW  - Electric power transmission
KW  - Thermal insulation
KW  - Thermography (temperature measurement)
KW  - Transformer windings
KW  - Winding
KW  - Calculation models
KW  - Condition monitoring systems
KW  - Insulation resistance
KW  - Life evaluation
KW  - Loss of life
KW  - Power transformer loss
KW  - Resistance calculation
KW  - Thermal model
KW  - Transformer loss of lives
KW  - Winding insulation
KW  - Power transformers
PB  - Institute of Electrical and Electronics Engineers Inc.
SN  - 979-835032138-8 (ISBN)
LA  - English
J2  - Int. Conf. Electron., Comput. Artif. Intell., ECAI - Proc.
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 1; Conference name: 15th International Conference on Electronics, Computers and Artificial Intelligence, ECAI 2023; Conference date: 29 June 2023 through 30 June 2023; Conference code: 191300
ER  -

TY  - CONF
AU  - Hoelscher-Obermaier, J.
AU  - Persson, J.H.
AU  - Kran, E.
AU  - Konstas, I.
AU  - Barez, F.
TI  - Detecting Edit Failures In Large Language Models: An Improved Specificity Benchmark
PY  - 2023
T2  - Proceedings of the Annual Meeting of the Association for Computational Linguistics
SP  - 11548
EP  - 11559
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85166307252&partnerID=40&md5=c4b1db2dfaa05c7fd22527e656bb0f4a
AD  - Apart Research
AD  - Edinburgh Centre for Robotics, United Kingdom
AD  - Department of Engineering Sciences, University of Oxford, United Kingdom
AB  - Recent model editing techniques promise to mitigate the problem of memorizing false or outdated associations during large language model (LLM) training. However, we show that these techniques can introduce large unwanted side effects which are not detected by existing specificity benchmarks. We extend the existing COUNTERFACT benchmark to include a dynamic component and dub our benchmark COUNTERFACT+. Additionally, we extend the metrics used for measuring specificity by a principled KL divergence-based metric. We use this improved benchmark to evaluate recent model editing techniques and find that they suffer from low specificity. Our findings highlight the need for improved specificity benchmarks that identify and prevent unwanted side effects. © 2023 Association for Computational Linguistics.
KW  - Dynamic component
KW  - KL-divergence
KW  - Language model
KW  - Model training
KW  - Side effect
KW  - Computational linguistics
PB  - Association for Computational Linguistics (ACL)
SN  - 0736587X (ISSN); 978-195942962-3 (ISBN)
LA  - English
J2  - Proc. Annu. Meet. Assoc. Comput Linguist.
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 1; Correspondence Address: F. Barez; Apart Research; email: fazl@robots.ox.ac.uk; Conference name: 61st Annual Meeting of the Association for Computational Linguistics, ACL 2023; Conference date: 9 July 2023 through 14 July 2023; Conference code: 192867
ER  -

TY  - CONF
AU  - Aiyappa, R.
AU  - An, J.
AU  - Kwak, H.
AU  - Ahn, Y.-Y.
TI  - Can we trust the evaluation on ChatGPT?
PY  - 2023
T2  - Proceedings of the Annual Meeting of the Association for Computational Linguistics
SP  - 47
EP  - 54
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85173285077&partnerID=40&md5=55d1e7b27ae72eabe82bf25e1888775c
AD  - Center for Complex Networks & Systems, Luddy School of Informatics, Computing & Engineering, United States
AD  - Indiana University Network Science Institute, Indiana University, Bloomington, 47408, IN, United States
AB  - ChatGPT, the first large language model with mass adoption, has demonstrated remarkable performance in numerous natural language tasks. Despite its evident usefulness, evaluating ChatGPT's performance in diverse problem domains remains challenging due to the closed nature of the model and its continuous updates via Reinforcement Learning from Human Feedback (RLHF). We highlight the issue of data contamination in ChatGPT evaluations, with a case study in stance detection. We discuss the challenge of preventing data contamination and ensuring fair model evaluation in the age of closed and continuously trained models. © 2023 Proceedings of the Annual Meeting of the Association for Computational Linguistics. All rights reserved.
KW  - Computational linguistics
KW  - Natural language processing systems
KW  - Case-studies
KW  - Continuous updates
KW  - Language model
KW  - Mass adoption
KW  - Model evaluation
KW  - Natural languages
KW  - Performance
KW  - Problem domain
KW  - Reinforcement learnings
KW  - Reinforcement learning
A2  - Ovalle A.
A2  - Chang K.-W.
A2  - Chang K.-W.
A2  - Mehrabi N.
A2  - Pruksachatkun Y.
A2  - Galystan A.
A2  - Galystan A.
A2  - Dhamala J.
A2  - Verma A.
A2  - Cao T.
A2  - Kumar A.
A2  - Gupta R.
PB  - Association for Computational Linguistics (ACL)
SN  - 0736587X (ISSN); 978-195942986-9 (ISBN)
LA  - English
J2  - Proc. Annu. Meet. Assoc. Comput Linguist.
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 0; Conference name: 3rd Workshop on Trustworthy Natural Language Processing, TrustNLP 2023, co-located with ACL 2023; Conference code: 193203
ER  -

TY  - JOUR
AU  - Rojas-Carabali, W.
AU  - Cifuentes-González, C.
AU  - Wei, X.
AU  - Putera, I.
AU  - Sen, A.
AU  - Thng, Z.X.
AU  - Agrawal, R.
AU  - Elze, T.
AU  - Sobrin, L.
AU  - Kempen, J.H.
AU  - Lee, B.
AU  - Biswas, J.
AU  - Nguyen, Q.D.
AU  - Gupta, V.
AU  - de-la-Torre, A.
AU  - Agrawal, R.
TI  - Evaluating the Diagnostic Accuracy and Management Recommendations of ChatGPT in Uveitis
PY  - 2023
T2  - Ocular Immunology and Inflammation
DO  - 10.1080/09273948.2023.2253471
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85171542097&doi=10.1080%2f09273948.2023.2253471&partnerID=40&md5=9b1b6537c39d02d1f9f4654e35e1ce1e
AD  - National Healthcare Group Eye Institute, Tan Tock Seng Hospital, Singapore, Singapore
AD  - Department of Bioinformatics, Lee Kong Chiang School of Medicine, Nanyang Technological University, Singapore, Singapore
AD  - Neuroscience Research Group (NEUROS), Neurovitae Center for Neuroscience, Institute of Translational Medicine (IMT), Escuela de Medicina y Ciencias de la Salud, Universidad del Rosario, Bogotá, Colombia
AD  - Department of Ophthalmology, Faculty of Medicine, Universitas Indonesia – CiptoMangunkusmoKirana Eye Hospital, Jakarta, Indonesia
AD  - Laboratory Medical Immunology, Department of Immunology, ErasmusMC, University Medical Centre, Rotterdam, Netherlands
AD  - Department of Internal Medicine, Division of Clinical Immunology, Erasmus MC, University Medical Center, Rotterdam, Netherlands
AD  - Department of Ophthalmology, Erasmus MC, University Medical Center, Rotterdam, Netherlands
AD  - Department of Vitreoretina and Uveitis, Sadguru Netra Chikatsalya, Chitrakoot, India
AD  - Department of Ophthalmology, Massachusetts Eye and Ear/Harvard Medical School, Schepens Eye Research Institute, Boston, MA, United States
AD  - Community Ophthalmology, Sight for Souls, Bellevue, WA, United States
AD  - Department of Ophthalmology, Addis Ababa University, Addis Ababa, Ethiopia
AD  - MyungSung Christian Medical Center (MCM) Eye Unit, MCM Comprehensive Specialized Hospital, MyungSung Medical School, Addis Ababa, Ethiopia
AD  - Department of Ocular Pathology and Uveitis, Medical Research Foundation, Sankara Netralaya, Chennai, India
AD  - Byers Eye Institute, Stanford University, Palo Alto, CA, United States
AD  - Post Graduate Institute of Medical Education and Research (PGIMER), Advance Eye Centre, Chandigarh, India
AD  - Department of Ophthalmology and Visual Sciences, Academic Clinical Program, Duke-NUS Medical School, Singapore, Singapore
AD  - Moorfields Eye Hospital, NHS Foundation Trust, London, United Kingdom
AD  - Singapore Eye Research Institute, The Academia, Singapore, Singapore
AB  - Introduction: Accurate diagnosis and timely management are vital for favorable uveitis outcomes. Artificial Intelligence (AI) holds promise in medical decision-making, particularly in ophthalmology. Yet, the diagnostic precision and management advice from AI-based uveitis chatbots lack assessment. Methods: We appraised diagnostic accuracy and management suggestions of an AI-based chatbot, ChatGPT, versus five uveitis-trained ophthalmologists, using 25 standard cases aligned with new Uveitis Nomenclature guidelines. Participants predicted likely diagnoses, two differentials, and next management steps. Comparative success rates were computed. Results: Ophthalmologists excelled (60–92%) in likely diagnosis, exceeding AI (60%). Considering fully and partially accurate diagnoses, ophthalmologists achieved 76–100% success; AI attained 72%. Despite an 8% AI improvement, its overall performance lagged. Ophthalmologists and AI agreed on diagnosis in 48% cases, with 91.6% exhibiting concurrence in management plans. Conclusions: The study underscores AI chatbots' potential in uveitis diagnosis and management, indicating their value in reducing diagnostic errors. Further research is essential to enhance AI chatbot precision in diagnosis and recommendations. © 2023 Taylor & Francis Group, LLC.
KW  - Artificial intelligence
KW  - chatbot
KW  - diagnosis
KW  - natural language processing
KW  - ophthalmology
PB  - Taylor and Francis Ltd.
SN  - 09273948 (ISSN)
LA  - English
J2  - Ocul. Immunol. Inflamm.
M3  - Article
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 4; Correspondence Address: R. Agrawal; National Healthcare Group Eye Institute, Tan Tock Seng Hospital, 308433, Singapore; email: rupesh_agrawal@ttsh.com.sg; CODEN: OIINE
ER  -

TY  - CONF
AU  - Yu, Z.
AU  - Wu, Y.
AU  - Zhang, N.
AU  - Wang, C.
AU  - Vorobeychik, Y.
AU  - Xiao, C.
TI  - CODEIPPROMPT: Intellectual Property Infringement Assessment of Code Language Models
PY  - 2023
T2  - Proceedings of Machine Learning Research
VL  - 202
SP  - 40373
EP  - 40389
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85168993146&partnerID=40&md5=8d3b094c5a27ff162924dac0fb642014
AD  - Washington University in St. Louis, United States
AD  - Arizona State University, United States
AD  - University of Wisconsin-Madison, United States
AB  - Recent advances in large language models (LMs) have facilitated their ability to synthesize programming code. However, they have also raised concerns about intellectual property (IP) rights violations. Despite the significance of this issue, it has been relatively less explored. In this paper, we aim to bridge the gap by presenting CODEIPPROMPT, a platform for automatic evaluation of the extent to which code language models may reproduce licensed programs. It comprises two key components: prompts constructed from a licensed code database to elicit LMs to generate IP-violating code, and a measurement tool to evaluate the extent of IP violation of code LMs. We conducted an extensive evaluation of existing open-source code LMs and commercial products, and revealed the prevalence of IP violations in all these models. We further identified that the root cause is the substantial proportion of training corpus subject to restrictive licenses, resulting from both intentional inclusion and inconsistent license practice in the real world. To address this issue, we also explored potential mitigation strategies, including fine-tuning and dynamic token filtering. Our study provides a testbed for evaluating the IP violation issues of the existing code generation platforms and stresses the need for a better mitigation strategy. © 2023 Proceedings of Machine Learning Research. All rights reserved.
KW  - Intellectual property
KW  - Machine learning
KW  - Open source software
KW  - Open systems
KW  - Automatic evaluation
KW  - Code database
KW  - Code languages
KW  - Commercial products
KW  - Intellectual property rights
KW  - Language model
KW  - Measurement tools
KW  - Mitigation strategy
KW  - Open-source code
KW  - Programming codes
KW  - Computational linguistics
A2  - Krause A.
A2  - Brunskill E.
A2  - Cho K.
A2  - Engelhardt B.
A2  - Sabato S.
A2  - Scarlett J.
PB  - ML Research Press
SN  - 26403498 (ISSN)
LA  - English
J2  - Proc. Mach. Learn. Res.
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 1; Correspondence Address: Z. Yu; Washington University in St. Louis, United States; email: yu.zhiyuan@wustl.edu; N. Zhang; Washington University in St. Louis, United States; email: zhang.ning@wustl.edu; C. Xiao; Arizona State University, United States; email: xi-aocw@asu.edu; Conference name: 40th International Conference on Machine Learning, ICML 2023; Conference date: 23 July 2023 through 29 July 2023; Conference code: 191855
ER  -

TY  - CONF
AU  - Grotti, L.
AU  - Quick, P.
TI  - BERTicelli at HaSpeeDe 3: Fine-tuning and Cross-validating Large Language Models for Hate Speech Detection
PY  - 2023
T2  - CEUR Workshop Proceedings
VL  - 3473
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85173559776&partnerID=40&md5=15dd6205e5162484927cbf9d838d71a1
AD  - Universiteit Antwerpen, Faculty of Arts, Prinsstraat 13, Antwerp, B-2000, Belgium
AD  - CLiPS Research Center, University of Antwerp, Belgium
AB  - The present paper describes the results from the experiments carried out for the HaSpeeDe 3 shared task, an Italian-language Hate Speech (HS) detection task, at EVALITA 2023. Two BERT-based language models were selected: UmBERTo (cased) and Italian BERT (cased). For the Textual task, the models were fine-tuned and cross-validated across 5 folds. For the Contextual task, we adopted an ensemble approach: the additional features were added to the fine-tuned models through the GradientBoosterClassifier algorithm. The models perform better than the baselines (DummyClassifier and LogisticRegression) and above the average performance of participants in the shared task. While the addition of contextual features did not improve the performance of UmBERTo, it significantly bettered the results obtained with Italian BERT. © 2021 Copyright for this paper by its authors. Use permitted under Creative Commons License Attribution 4.0 International (CC BY 4.0).
KW  - BERT-based language models
KW  - Contextual features
KW  - Fine-tuning
KW  - Hate Speech detection
KW  - Italian language
KW  - Intelligent systems
KW  - Speech recognition
KW  - BERT-based language model
KW  - Contextual feature
KW  - Detection tasks
KW  - Ensemble approaches
KW  - Fine tuning
KW  - Hate speech detection
KW  - Italian language
KW  - Language model
KW  - Performance
KW  - Speech detection
KW  - Computational linguistics
A2  - Lai M.
A2  - Menini S.
A2  - Polignano M.
A2  - Russo V.
A2  - Sprugnoli R.
A2  - Venturi G.
PB  - CEUR-WS
SN  - 16130073 (ISSN)
LA  - English
J2  - CEUR Workshop Proc.
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 0; Correspondence Address: L. Grotti; Universiteit Antwerpen, Faculty of Arts, Antwerp, Prinsstraat 13, B-2000, Belgium; email: lgrotti@uantwerpen.be; Conference name: 8th Evaluation Campaign of Natural Language Processing and Speech Tools for Italian. Final Workshop, EVALITA 2023; Conference date: 7 September 2023 through 8 September 2023; Conference code: 192243
ER  -

TY  - JOUR
AU  - Caglar, U.
AU  - Ozgor, F.
TI  - Response to letter to the editor re ‘‘Evaluating the performance of ChatGPT in answering questions related to pediatric urology’’
PY  - 2023
T2  - Journal of Pediatric Urology
DO  - 10.1016/j.jpurol.2023.09.003
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85173945796&doi=10.1016%2fj.jpurol.2023.09.003&partnerID=40&md5=fe34827c38cac2345c1eb77d336aedfd
AD  - Department of Urology, Haseki Training and Research Hospital, Istanbul, Turkey
PB  - Elsevier Ltd
SN  - 14775131 (ISSN)
C2  - 37749006
LA  - English
J2  - J. Pediatr. Urol.
M3  - Letter
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 2; Correspondence Address: U. Caglar; Istanbul, Ugur Mumcu Mahallesi, Belediye Sokak, No:7 Sultangazi, Turkey; email: ufukcglr@gmail.com
ER  -

TY  - CONF
AU  - Napoli, E.A.
AU  - Gatteschi, V.
TI  - Evaluating ChatGPT for Smart Contracts Vulnerability Correction
PY  - 2023
T2  - Proceedings - International Computer Software and Applications Conference
VL  - 2023-June
SP  - 1828
EP  - 1833
DO  - 10.1109/COMPSAC57700.2023.00283
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85168889838&doi=10.1109%2fCOMPSAC57700.2023.00283&partnerID=40&md5=3b78a3d4bcf36d64a4488d62526bc1a1
AD  - Politecnico di Torino, Department of Control and Computer Engineering, Turin, Italy
AB  - The growing number of exploits and hacks on the Ethereum blockchain has led to the development of powerful smart contract vulnerability detection tools and the frequent patching of the smart contract's programming languages (such as Solidity). At the same time, an ever-increasing number of people are interested in blockchain and smart contract-related topics and willing to build and deploy their own Decentralized Applications (dApp). However, learning a new programming language and its best practices as long as how to actually deploy a smart contract on the blockchain is a difficult task even for experienced developers. Recently, ChatGPT, a new user-friendly deep learning tool, has been released to improve the ability of non-skilled users to write high-quality code and in general, to boost the performances of developers in key tasks related to code writing (i.e., writing functions, explaining runtime errors, fixing bugs, etc.). This paper aims to measure the capabilities of ChatGPT in fixing vulnerable smart contracts and to assess the effectiveness of this tool, determining whether it can be a valuable aid for those who want to correct their own smart contract or want to reuse existing ones by first checking their status and eventually fix their vulnerability. In particular, we asked ChatGPT to fix 143 smart contracts with well-known labeled vulnerabilities. We considered a vulnerability as "fixed"if the code corrected by ChatGPT no longer contained the vulnerability (for this purpose, we exploited Slither, one of the state-of-the-art tools for smart contracts vulnerability detection to check the status of the original and the corrected smart contracts). As a result we obtained that ChatGPT was able to fix bugs and vulnerable smart contracts on average the 57.1% of the time with an increase of +1.4% when a description of the bug was provided in addition to the smart contract's source code. © 2023 IEEE.
KW  - blockchain
KW  - bug fix
KW  - ChatGPT
KW  - code correction
KW  - smart contracts
KW  - Solidity
KW  - Blockchain
KW  - Codes (symbols)
KW  - Computer programming languages
KW  - Deep learning
KW  - Program debugging
KW  - Best practices
KW  - Block-chain
KW  - Bug fixes
KW  - ChatGPT
KW  - Code correction
KW  - Decentralised
KW  - Detection tools
KW  - Number of peoples
KW  - Solidity
KW  - Vulnerability detection
KW  - Smart contract
A2  - Shahriar H.
A2  - Teranishi Y.
A2  - Cuzzocrea A.
A2  - Sharmin M.
A2  - Towey D.
A2  - Majumder AKM.J.A.
A2  - Kashiwazaki H.
A2  - Yang J.-J.
A2  - Takemoto M.
A2  - Sakib N.
A2  - Banno R.
A2  - Ahamed S.I.
PB  - IEEE Computer Society
SN  - 07303157 (ISSN); 979-835032697-0 (ISBN)
LA  - English
J2  - Proc Int Comput Software Appl Conf
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 0; Correspondence Address: E.A. Napoli; Politecnico di Torino, Department of Control and Computer Engineering, Turin, Italy; email: emanuele.napoli@polito.it; Conference name: 47th IEEE Annual Computers, Software, and Applications Conference, COMPSAC 2023; Conference date: 26 June 2023 through 30 June 2023; Conference code: 191323; CODEN: PSICD
ER  -

TY  - CONF
AU  - Peskoff, D.
AU  - Stewart, B.M.
TI  - Credible Without Credit: Domain Experts Assess Generative Language Models
PY  - 2023
T2  - Proceedings of the Annual Meeting of the Association for Computational Linguistics
VL  - 2
SP  - 427
EP  - 438
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85172223217&partnerID=40&md5=0b12a7f290f28bd06e45391f17772f04
AD  - Princeton University, Office of Population Research, United States
AD  - Princeton University, Sociology and Office of Population Research, United States
AB  - Language models have recently broken into the public consciousness with the release of the wildly popular ChatGPT. Commentators have argued that language models could replace search engines, make college essays obsolete, or even write academic research papers. All of these tasks rely on accuracy of specialized information which can be difficult to assess for non-experts. Using 10 domain experts across science and culture, we provide an initial assessment of the coherence, conciseness, accuracy, and sourcing of two language models across 100 expert-written questions. While we find the results are consistently cohesive and concise, we find that they are mixed in their accuracy. These results raise questions of the role language models should play in general-purpose and expert knowledge seeking. © 2023 Association for Computational Linguistics.
KW  - Computational linguistics
KW  - Academic research
KW  - Domain experts
KW  - Expert knowledge
KW  - Initial assessment
KW  - Language model
KW  - Public's consciousness
KW  - Research papers
KW  - Science and cultures
KW  - Search engines
PB  - Association for Computational Linguistics (ACL)
SN  - 0736587X (ISSN); 978-195942971-5 (ISBN)
LA  - English
J2  - Proc. Annu. Meet. Assoc. Comput Linguist.
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 2; Conference name: 61st Annual Meeting of the Association for Computational Linguistics, ACL 2023; Conference date: 9 July 2023 through 14 July 2023; Conference code: 192160
ER  -

TY  - JOUR
AU  - Sareen, K.
TI  - Assessing the ethical capabilities of Chat GPT in healthcare: A study on its proficiency in situational judgement test
PY  - 2023
T2  - Innovations in Education and Teaching International
DO  - 10.1080/14703297.2023.2258114
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85170659544&doi=10.1080%2f14703297.2023.2258114&partnerID=40&md5=e82d3133a1d5d747427a9ce9d5c6e93c
AD  - Medical Doctor, Bhagwan Mahavir Hospital, New Delhi, India
AB  - This study examines the proficiency of Chat GPT, an AI language model, in answering questions on the Situational Judgement Test (SJT), a widely used assessment tool for evaluating the fundamental competencies of medical graduates in the UK. A total of 252 SJT questions from the Oxford Assess and Progress: Situational Judgement Test book were sampled, encompassing 82 multiple-choice and 170 ranking questions. Chat GPT exhibited a commendable mean accuracy of 77.67% with a standard error of 1.09% when compared to the book's answers. While precise population statistics and a definitive scoring system remain unavailable, it is worth acknowledging the AI's consistent performance across all five domains tested. To significantly enhance its effectiveness and practical utility, especially in aiding junior doctors with complex ethical dilemmas, further advancements are imperative to strengthen its decision-making capabilities beyond factual comprehension. © 2023 Informa UK Limited, trading as Taylor & Francis Group.
KW  - Artificial intelligence
KW  - decision making
KW  - medical ethics
KW  - situational judgement
PB  - Routledge
SN  - 14703297 (ISSN)
LA  - English
J2  - Innov. Educ. Teach. Int.
M3  - Article
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 0; Correspondence Address: K. Sareen; Medical Doctor, Bhagwan Mahavir Hospital, New Delhi, India; email: kunalsareen98@gmail.com
ER  -

TY  - CONF
AU  - Naismith, B.
AU  - Mulcaire, P.
AU  - Burstein, J.
TI  - Automated Evaluation of Written Discourse Coherence Using GPT-4
PY  - 2023
T2  - Proceedings of the Annual Meeting of the Association for Computational Linguistics
SP  - 394
EP  - 403
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85168741083&partnerID=40&md5=43ab9f2b242071bed31473ec8fc78418
AD  - Duolingo, United States
AB  - The popularization of large language models (LLMs) such as OpenAI’s GPT-3 and GPT-4 have led to numerous innovations in the field of AI in education. With respect to automated writing evaluation (AWE), LLMs have reduced challenges associated with assessing writing quality characteristics that are difficult to identify automatically, such as discourse coherence. In addition, LLMs can provide rationales for their evaluations (ratings) which increases score interpretability and transparency. This paper investigates one approach to producing ratings by training GPT-4 to assess discourse coherence in a manner consistent with expert human raters. The findings of the study suggest that GPT-4 has strong potential to produce discourse coherence ratings that are comparable to human ratings, accompanied by clear rationales. Furthermore, the GPT-4 ratings outperform traditional NLP coherence metrics with respect to agreement with human ratings. These results have implications for advancing AWE technology for learning and assessment. © 2023 Association for Computational Linguistics.
KW  - Computational linguistics
KW  - Automated evaluation
KW  - Coherence metric
KW  - Evaluation rating
KW  - Interpretability
KW  - Language model
KW  - Quality characteristic
KW  - Writing quality
KW  - Quality control
A2  - Kochmar E.
A2  - Burstein J.
A2  - Horbach A.
A2  - Horbach A.
A2  - Horbach A.
A2  - Laarmann-Quante R.
A2  - Madnani N.
A2  - Tack A.
A2  - Yaneva V.
A2  - Yuan Z.
A2  - Zesch T.
A2  - Zesch T.
PB  - Association for Computational Linguistics (ACL)
SN  - 0736587X (ISSN); 978-195942980-7 (ISBN)
LA  - English
J2  - Proc. Annu. Meet. Assoc. Comput Linguist.
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 2; Conference name: 18th Workshop on Innovative Use of NLP for Building Educational Applications, BEA 2023; Conference code: 193152
ER  -

TY  - CONF
AU  - Delile, Z.
AU  - Radel, S.
AU  - Godinez, J.
AU  - Engstrom, G.
AU  - Brucker, T.
AU  - Young, K.
AU  - Ghanavati, S.
TI  - Evaluating Privacy Questions from Stack Overflow: Can ChatGPT Compete?
PY  - 2023
T2  - Proceedings - 31st IEEE International Requirements Engineering Conference Workshops, REW 2023
SP  - 239
EP  - 244
DO  - 10.1109/REW57809.2023.00048
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85171419113&doi=10.1109%2fREW57809.2023.00048&partnerID=40&md5=258474a06da863ebc43d5658be4867eb
AD  - School of Computing and Information Science, University of Maine, Orono, ME, United States
AB  - Stack Overflow and other similar forums are commonly used by developers to seek answers for their software development as well as privacy-related concerns. Recently, ChatGPT has been used as an alternative to generate code or produce responses to developers' questions. In this paper, we aim to understand developers' privacy challenges by evaluating the types of privacy-related questions asked on Stack Overflow. We then conduct a comparative analysis between the accepted responses given by Stack Overflow users and the responses produced by ChatGPT for those extracted questions to identify if ChatGPT could serve as a viable alternative. Our results show that most privacy-related questions are related to choice/consent, aggregation, and identification. Furthermore, our findings illustrate that ChatGPT generates similarly correct responses for about 56% of questions while for the rest of the responses, the answers from Stack Overflow are slightly more accurate than ChatGPT.  © 2023 IEEE.
KW  - analysts
KW  - ChatGPT
KW  - privacy
KW  - Stack Overflow
KW  - Analyst
KW  - ChatGPT
KW  - Comparative analyzes
KW  - Developer questions
KW  - Privacy
KW  - Stack overflow
KW  - Software design
A2  - Schneider K.
A2  - Dalpiaz F.
A2  - Horkoff J.
PB  - Institute of Electrical and Electronics Engineers Inc.
SN  - 979-835032691-8 (ISBN)
LA  - English
J2  - Proc. - IEEE Int. Requir. Eng. Conf. Workshops, REW
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 0; Conference name: 31st IEEE International Requirements Engineering Conference Workshops, REW 2023; Conference date: 4 September 2023 through 8 September 2023; Conference code: 193031
ER  -

TY  - CONF
AU  - Liu, X.
AU  - Tan, Y.
AU  - Xiao, Z.
AU  - Zhuge, J.
AU  - Zhou, R.
TI  - Not The End of Story: An Evaluation of ChatGPT-Driven Vulnerability Description Mappings
PY  - 2023
T2  - Proceedings of the Annual Meeting of the Association for Computational Linguistics
SP  - 3724
EP  - 3731
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85168853410&partnerID=40&md5=fb8dcbd25871173190ca2e6ebeda1875
AD  - Lanzhou University, China
AD  - Hunan University, China
AD  - Tsinghua University, China
AD  - Zhongguancun Laboratory, China
AB  - As the number of vulnerabilities increases day by day, security management requires more and more structured data. In addition to textual descriptions of vulnerabilities, security engineers must classify and assess vulnerabilities and clarify their associated techniques. Vulnerability Description Mapping (VDM) refers to mapping vulnerabilities to Common Weakness Enumeration (CWE), Common Attack Pattern Enumeration and Classification, ATT&CK Techniques, and other classifications. Accurate VDM is necessary to reduce the pressure of security management and improve the speed of security emergency response. ChatGPT is the latest state-of-the-art closed-source conversational large language model (LLM), which performs excellently on many tasks. This paper explores the application of closed-source LLMs to real-world security management scenarios by evaluating ChatGPT's performance on VDM tasks. The results show that although ChatGPT may be close to the level of human experts on some tasks, it still cannot replace the critical role of professional security engineers in vulnerability analysis. In a word, closed-source LLM is not the end of story. © 2023 Association for Computational Linguistics.
KW  - Classification (of information)
KW  - Computational linguistics
KW  - Attack patterns
KW  - Closed source
KW  - Emergency response
KW  - Language model
KW  - Security engineers
KW  - Security management
KW  - State of the art
KW  - Structured data
KW  - Textual description
KW  - Vulnerability description
KW  - Mapping
PB  - Association for Computational Linguistics (ACL)
SN  - 0736587X (ISSN); 978-195942962-3 (ISBN)
LA  - English
J2  - Proc. Annu. Meet. Assoc. Comput Linguist.
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 1; Correspondence Address: J. Zhuge; Tsinghua University, China; email: zhugejw@tsinghua.edu.cn; Conference name: 61st Annual Meeting of the Association for Computational Linguistics, ACL 2023; Conference date: 9 July 2023 through 14 July 2023; Conference code: 192867
ER  -

TY  - JOUR
AU  - Rudan, D.
AU  - Marčinko, D.
AU  - Degmečić, D.
AU  - Jakšić, N.
TI  - Scarcity of research on psychological or psychiatric states using validated questionnaires in low- and middle-income countries: A ChatGPT-assisted bibliometric analysis and national case study on some psychometric properties
PY  - 2023
T2  - Journal of Global Health
VL  - 13
C7  - 04102
DO  - 10.7189/JOGH.13.04102
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85172994138&doi=10.7189%2fJOGH.13.04102&partnerID=40&md5=3027d2bf45f0410baaddd9b45b7c2554
AD  - Department of Psychiatry and Psychological Medicine, University Hospital Centre Zagreb, Zagreb, Croatia
AD  - Faculty of Medicine, University of Zagreb, Department of Psychiatry and Psychological Medicine, University Hospital Centre Zagreb, Zagreb, Croatia
AD  - Faculty of Medicine, J. J. Strossmayer University of Osijek, Department of Psychiatry, University Hospital Centre Osijek, Osijek, Croatia
AB  - Background It is vital to assess whether research on psychological or psychiatric states using validated questionnaires is still lagging in low- and middle-income countries and to what degree, and to continue to assess the psychometric properties of the most informative questionnaires. Methods We performed a bibliometric analysis of Web of Science Core Collection for all years to determine the number of studies performed in each country that used an inventory or a questionnaire on aggression, anxiety, depression, borderline personality, narcissism, self-harm, shame, or childhood trauma. We conducted a simple observational analysis of distributions by countries to derive the main overall conclusions, assisted by ChatGPT to test its ability to summarise and interpret this type of information. We also carried out a study in Croatia to examine some psychometric properties of five commonly used questionnaires, using Cronbach’s a coefficient and zero-order correlations. Results We observed a concentration of research activity in a few high-income countries, primarily the United States and several European nations, suggesting a robust research infrastructure and a strong emphasis on studying psychological and psychiatric states within their population. In contrast, low- and middle-income countries were notably under-represented in research on psychological and psychiatric states, although the gap seems to be closing in some countries. Turkey, Iran, Brazil, South Africa, Mexico, India, Malaysia and Pakistan have been consistently contributing an increasing number of studies and catching up with the most research-intensive high-income countries. The national case study in Croatia confirmed adequate psychometric properties of the most frequently used questionnaires. Conclusions Addressing research gaps in low- and middle-income countries is crucial, because relying solely on research from high-income countries may not fully capture the nuances of psychological and psychiatric states within diverse populations. To bridge this gap, it is essential to prioritise mental health research in low-resource settings, provide training and resources to local researchers, and establish international collaborations. Such efforts can lead to the development of culturally valid questionnaires, an improved understanding of psychological and psychiatric states in diverse contexts, and the creation of effective interventions to promote mental well-being on a global scale. © 2023 The Author(s). All Rights Reserved
KW  - Anxiety
KW  - Developing Countries
KW  - Humans
KW  - Income
KW  - Psychometrics
KW  - Surveys and Questionnaires
KW  - anxiety
KW  - developed country
KW  - human
KW  - income
KW  - psychometry
KW  - questionnaire
PB  - University of Edinburgh
SN  - 20472978 (ISSN)
C2  - 37781994
LA  - English
J2  - J. Glob. Health
M3  - Article
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 0; Correspondence Address: D. Rudan; Department of Psychiatry and Psychological Medicine, University Hospital Centre Zagreb, Zagreb, Croatia; email: drudan@kbc-zagreb.hr
ER  -

TY  - CONF
AU  - Sugimoto, T.
AU  - Onoe, Y.
AU  - Yanaka, H.
TI  - JAMP: Controlled Japanese Temporal Inference Dataset for Evaluating Generalization Capacity of Language Models
PY  - 2023
T2  - Proceedings of the Annual Meeting of the Association for Computational Linguistics
VL  - 4
SP  - 57
EP  - 68
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85173477620&partnerID=40&md5=9ad5e4f772479cd5ee95478e80aca3ab
AD  - The University of Tokyo, Japan
AD  - The University of Texas, Austin, United States
AB  - Natural Language Inference (NLI) tasks involving temporal inference remain challenging for pre-trained language models (LMs). Although various datasets have been created for this task, they primarily focus on English and do not address the need for resources in other languages. It is unclear whether current LMs realize the generalization capacity for temporal inference across languages. In this paper, we present JAMP, a Japanese NLI benchmark focused on temporal inference. Our dataset includes a range of temporal inference patterns, which enables us to conduct fine-grained analysis. To begin the data annotation process, we create diverse inference templates based on the formal semantics test suites. We then automatically generate diverse NLI examples by using the Japanese case frame dictionary and well-designed templates while controlling the distribution of inference patterns and gold labels. We evaluate the generalization capacities of monolingual/multilingual LMs by splitting our dataset based on tense fragments (i.e., temporal inference patterns). Our findings demonstrate that LMs struggle with specific linguistic phenomena, such as habituality, indicating that there is potential for the development of more effective NLI models across languages. © 2023 Association for Computational Linguistics.
KW  - Computational linguistics
KW  - Formal methods
KW  - 'current
KW  - Data annotation
KW  - Fine-grained analysis
KW  - Generalization capacity
KW  - Inference patterns
KW  - Language inference
KW  - Language model
KW  - Natural languages
KW  - Template-based
KW  - Temporal Inference
KW  - Semantics
PB  - Association for Computational Linguistics (ACL)
SN  - 0736587X (ISSN); 978-195942969-2 (ISBN)
LA  - English
J2  - Proc. Annu. Meet. Assoc. Comput Linguist.
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 0; Conference name: 61st Annual Meeting of the Association for Computational Linguistics, ACL-SRW 2023; Conference date: 10 July 2023 through 12 July 2023; Conference code: 192160
ER  -

TY  - JOUR
AU  - Di San Pietro, C.B.
AU  - Frau, F.
AU  - Mangiaterra, V.
AU  - Bambini, V.
TI  - THE PRAGMATIC PROFILE OF CHATGPT: Assessing the communicative skills of a conversational agent
PY  - 2023
T2  - Sistemi Intelligenti
VL  - 35
IS  - 2
SP  - 379
EP  - 399
DO  - 10.1422/108136
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85173051839&doi=10.1422%2f108136&partnerID=40&md5=480ef1d45dbec636325d57912818dc74
AD  - University School for Advanced Studies IUSS, Laboratory of Neurolinguistics and Experimental Pragmatics (NEP), Piazza della Vittoria 15, Pavia, 27100, Italy
AB  - This study examines the pragmatic abilities of OpenAI’s ChatGPT, a conversational agent based on the multi-layer Transformer network GPT-3.5. To do so, we administered a language battery to assess expressive and receptive pragmatic skills and compared the results with human performance. ChatGPT results were mostly human-like but revealed weaknesses in the domains of the Gricean maxim of quantity, text-based inferences, physical metaphors, and humor comprehension. On the one hand, these findings suggest that at least part of the linguistic pragmatic competence, as evaluated via current assessment tools, might be distributionally encoded in language. On the other hand, situated and meta-representational aspects of pragmatic inferencing appear to be not yet fully accounted for in LLMs. © (2023). All Rights Reserved.
KW  - ChatGPT
KW  - inference
KW  - large language models
KW  - metaphor
KW  - pragmatics
PB  - Societa Editrice Il Mulino
SN  - 11209550 (ISSN)
LA  - English
J2  - Sist. Intelligenti
M3  - Article
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 2
ER  -

TY  - CONF
AU  - Boháček, M.
TI  - The Unseen A+ Student: Evaluating the Performance and Detectability of Large Language Models in High School Assignments
PY  - 2023
T2  - CEUR Workshop Proceedings
VL  - 3487
SP  - 89
EP  - 100
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85174198821&partnerID=40&md5=316f355e48d85e58d4b40beaf222de95
AD  - Gymnasium of Johannes Kepler, Parléřova 2/118, Prague, 169 00, Czech Republic
AB  - The recent boom of so-called generative artificial intelligence (AI) applications, namely large language models such as ChatGPT, took the public discourse by storm, disrupting many fields and industries. Education, being one of them, is now pressed to establish reactive policies on the use of this technology, often without enough insight and data. Thus, we present a dataset of authentic coursework (including long-form theses and short assignments) from a public high school in the Czech Republic, extended by AI-generated alternatives with various versions of ChatGPT. To evaluate their quality, we enlist a group of student peers from the same school and conduct multiple assessments. Our findings reveal that ChatGPT can generate high-quality, high school-level coursework off-the-shelf, even in a low-resourced language such as Czech. Additionally, we demonstrate that the AI text detectors, which are gradually being implemented in educational institutions and learning centers worldwide, fail to identify these AI-generated texts. © 2022 Copyright for this paper by its authors. Use permitted under Creative Commons License Attribution 4.0 International (CC BY 4.0).
KW  - Education
KW  - Generative Artificial Intelligence
KW  - Large Language Models
KW  - School Assignments
KW  - Artificial intelligence
KW  - Computational linguistics
KW  - Education computing
KW  - High level languages
KW  - Courseworks
KW  - Czech Republic
KW  - Detectability
KW  - Generative artificial intelligence
KW  - High quality
KW  - Higher School
KW  - Language model
KW  - Large language model
KW  - Performance
KW  - School assignment
KW  - Students
A2  - Moore S.
A2  - Stamper J.
A2  - Tong R.
A2  - Cao C.
A2  - Liu Z.
A2  - Hu X.
A2  - Lu Y.
A2  - Liang J.
A2  - Khosravi H.
A2  - Denny P.
A2  - Singh A.
A2  - Brooks C.
PB  - CEUR-WS
SN  - 16130073 (ISSN)
LA  - English
J2  - CEUR Workshop Proc.
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 0; Correspondence Address: M. Boháček; Gymnasium of Johannes Kepler, Prague, Parléřova 2/118, 169 00, Czech Republic; email: matyas.bohacek@matsworld.io; Conference name: 1st Annual Workshop on Empowering Education with LLMs - the Next-Gen Interface and Content Generation, AIEDLLM 2023; Conference code: 192705
ER  -

TY  - JOUR
AU  - Zhou, Y.
AU  - Moon, C.
AU  - Szatkowski, J.
AU  - Moore, D.
AU  - Stevens, J.
TI  - Evaluating ChatGPT responses in the context of a 53-year-old male with a femoral neck fracture: a qualitative analysis
PY  - 2023
T2  - European Journal of Orthopaedic Surgery and Traumatology
DO  - 10.1007/s00590-023-03742-4
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85173016088&doi=10.1007%2fs00590-023-03742-4&partnerID=40&md5=7284329adaa70410c8c107bc7591b516
AD  - Department of Surgery, The University of Melbourne, St. Vincent’s Hospital Melbourne, 29 Regent Street, Clinical Sciences Block Level 2, Melbourne, 3010, VIC, Australia
AD  - Department of Orthopaedic Surgery, St. Vincent’s Hospital, Melbourne, Australia
AD  - Department of Orthopaedic Surgery, Cedars-Sinai Medical Centre, Los Angeles, CA, United States
AD  - Department of Orthopaedic Surgery, Indiana University Health Methodist Hospital, Indianapolis, IN, United States
AD  - Santa Barbara Orthopedic Associates, Santa Barbara, CA, United States
AB  - Purpose: The integration of artificial intelligence (AI) tools, such as ChatGPT, in clinical medicine and medical education has gained significant attention due to their potential to support decision-making and improve patient care. However, there is a need to evaluate the benefits and limitations of these tools in specific clinical scenarios. Methods: This study used a case study approach within the field of orthopaedic surgery. A clinical case report featuring a 53-year-old male with a femoral neck fracture was used as the basis for evaluation. ChatGPT, a large language model, was asked to respond to clinical questions related to the case. The responses generated by ChatGPT were evaluated qualitatively, considering their relevance, justification, and alignment with the responses of real clinicians. Alternative dialogue protocols were also employed to assess the impact of additional prompts and contextual information on ChatGPT responses. Results: ChatGPT generally provided clinically appropriate responses to the questions posed in the clinical case report. However, the level of justification and explanation varied across the generated responses. Occasionally, clinically inappropriate responses and inconsistencies were observed in the generated responses across different dialogue protocols and on separate days. Conclusions: The findings of this study highlight both the potential and limitations of using ChatGPT in clinical practice. While ChatGPT demonstrated the ability to provide relevant clinical information, the lack of consistent justification and occasional clinically inappropriate responses raise concerns about its reliability. These results underscore the importance of careful consideration and validation when using AI tools in healthcare. Further research and clinician training are necessary to effectively integrate AI tools like ChatGPT, ensuring their safe and reliable use in clinical decision-making. © 2023, The Author(s).
KW  - Artificial intelligence
KW  - Chatgpt
KW  - Clinical
KW  - Decision-making
KW  - Large language model
KW  - Orthopaedic surgery
PB  - Springer Nature
SN  - 16338065 (ISSN)
C2  - 37776392
LA  - English
J2  - Eur. J. Orthop. Surg. Traumatol.
M3  - Article
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 2; Correspondence Address: Y. Zhou; Department of Surgery, The University of Melbourne, St. Vincent’s Hospital Melbourne, Melbourne, 29 Regent Street, Clinical Sciences Block Level 2, 3010, Australia; email: yushy.zhou@student.unimelb.edu.au; CODEN: EJOTF
ER  -

TY  - CONF
AU  - Felkner, V.K.
AU  - Chang, H.-C.H.
AU  - Jang, E.
AU  - May, J.
TI  - WinoQueer: A Community-in-the-Loop Benchmark for Anti-LGBTQ+ Bias in Large Language Models
PY  - 2023
T2  - Proceedings of the Annual Meeting of the Association for Computational Linguistics
VL  - 1
SP  - 9126
EP  - 9140
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85167540582&partnerID=40&md5=1453f3bb0bb91508fcf4aa2e582e80a1
AD  - Information Sciences Institute, University of Southern California, United States
AD  - Department of Quantitative Social Science, Dartmouth College, United States
AD  - Annenberg School for Communication and Journalism, University of Southern California, United States
AB  - Content Warning: This paper contains examples of homophobic and transphobic stereotypes. We present WinoQueer: a benchmark specifically designed to measure whether large language models (LLMs) encode biases that are harmful to the LGBTQ+ community. The benchmark is community-sourced, via application of a novel method that generates a bias benchmark from a community survey. We apply our benchmark to several popular LLMs and find that off-the-shelf models generally do exhibit considerable anti-queer bias. Finally, we show that LLM bias against a marginalized community can be somewhat mitigated by finetuning on data written about or by members of that community, and that social media text written by community members is more effective than news text written about the community by non-members. Our method for community-in-the-loop benchmark development provides a blueprint for future researchers to develop community-driven, harms-grounded LLM benchmarks for other marginalized communities. © 2023 Association for Computational Linguistics.
KW  - Benchmarking
KW  - Computational linguistics
KW  - Language model
KW  - Model bias
KW  - Novel methods
KW  - Social media
KW  - Blueprints
PB  - Association for Computational Linguistics (ACL)
SN  - 0736587X (ISSN); 978-195942972-2 (ISBN)
LA  - English
J2  - Proc. Annu. Meet. Assoc. Comput Linguist.
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 1; Correspondence Address: H.-C.H. Chang; Department of Quantitative Social Science, Dartmouth College, United States; email: herbert@dartmouth.edu; Conference name: 61st Annual Meeting of the Association for Computational Linguistics, ACL 2023; Conference date: 9 July 2023 through 14 July 2023; Conference code: 192160
ER  -

TY  - JOUR
AU  - Ueda, D.
AU  - Mitsuyama, Y.
AU  - Takita, H.
AU  - Horiuchi, D.
AU  - Walston, S.L.
AU  - Tatekawa, H.
AU  - Miki, Y.
TI  - Response: Evaluating Diagnostic Performance of ChatGPT in Radiology: Delving into Methods
PY  - 2023
T2  - Radiology
VL  - 308
IS  - 3
SP  - 1
EP  - 2
DO  - 10.1148/radiol.232082
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85173172583&doi=10.1148%2fradiol.232082&partnerID=40&md5=423b554e8ca9a08264216fd479a357d3
AD  - Center for Health Science Innovation, Osaka Metropolitan University, 1-4-3 Asahi-machi Abeno-ku, Osaka, 545-8585, Japan
KW  - artificial intelligence
KW  - ChatGPT
KW  - constructive feedback
KW  - diagnostic accuracy
KW  - differential diagnosis
KW  - general practitioner
KW  - human
KW  - Letter
KW  - medical history
KW  - patient information
KW  - practice guideline
KW  - publication
KW  - radiology
KW  - reproducibility
PB  - Radiological Society of North America Inc.
SN  - 00338419 (ISSN)
C2  - 37724974
LA  - English
J2  - Radiology
M3  - Letter
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 1; Correspondence Address: D. Ueda; Department of Diagnostic and Interventional Radiology, Graduate School of Medicine, Osaka Metropolitan University, Osaka, Japan; email: ai.labo.ocu@gmail.com; CODEN: RADLA
ER  -

TY  - JOUR
AU  - Chen, Y.
TI  - Construction of a carbon neutral enterprise environmental performance assessment model based on transformer-GRU
PY  - 2023
T2  - Frontiers in Ecology and Evolution
VL  - 11
C7  - 1247644
DO  - 10.3389/fevo.2023.1247644
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85168699553&doi=10.3389%2ffevo.2023.1247644&partnerID=40&md5=35164878ce07c766991fd1de9ab0994d
AD  - Tianjin University of Technology, Tianjin, China
AB  - Introduction: Carbon-neutral enterprise environmental performance assessment is an important method for evaluating the impact and benefits of enterprises on the environment during the process of achieving carbon neutrality. This paper proposes a method for evaluating the environmental performance of carbon-neutral enterprises using the Transformer-GRU model. Methods: The proposed method combines the Transformer and GRU models to accurately predict and analyze the environmental performance of carbon-neutral enterprises. The Transformer model is used to extract features, and the GRU model is used for sequence modeling, which improves the model's prediction accuracy and generalization ability. The method is validated using actual enterprise data for experimental verification. Results: The experiments show that the proposed method has significant practical significance in evaluating the environmental performance of carbon-neutral enterprises. The method accurately predicts and analyzes the enterprise's carbon emissions, energy consumption, wastewater and gas discharge, and solid waste treatment. Discussion: The proposed method provides a new approach for evaluating the environmental performance of carbon-neutral enterprises. The combination of the Transformer and GRU models can effectively improve the accuracy and generalization ability of the model. The method can be used to help enterprises evaluate their environmental performance and make decisions to achieve carbon neutrality. Copyright © 2023 Chen.
KW  - BERT
KW  - carbon neutral
KW  - corporate environmental performance assessment
KW  - GRU
KW  - transformer
PB  - Frontiers Media SA
SN  - 2296701X (ISSN)
LA  - English
J2  - Front. ecol. evol.
M3  - Article
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 0; Correspondence Address: Y. Chen; Tianjin University of Technology, Tianjin, China; email: chenyanqing2023@163.com
ER  -

TY  - CONF
AU  - Li, Y.
AU  - Liu, Z.
AU  - Li, G.
AU  - Chen, Q.
AU  - Ding, Z.
AU  - Hu, X.
AU  - Hu, B.
TI  - A Visually Interpretable Convolutional-Transformer Model for Assessing Depression from Facial Images
PY  - 2023
T2  - Proceedings - IEEE International Conference on Multimedia and Expo
VL  - 2023-July
SP  - 252
EP  - 257
DO  - 10.1109/ICME55011.2023.00051
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85171146306&doi=10.1109%2fICME55011.2023.00051&partnerID=40&md5=9438be0934de83c4f7fc5a93807e9fa9
AD  - Lanzhou University, Gansu Provincial Key Laboratory of Wearable Computing, Lanzhou, China
AD  - Third People's Hospital of Tianshui, Tianshui, China
AD  - Northwest Minzu University, Second Provincial People's Hospital of Gansu, Lanzhou, China
AB  - The accuracy and availability are the most critical and challenging problems for major depressive disorder (MDD) diagnosis. Limited receptive field and inaccurate visual interpretation always weaken the clinical application of deep learning-based depression recognition model. Thus, we propose a visually interpretable depression monitoring model termed Transformer and Convolutional with slot-attention (TC-slot) to assess depression from facial images. Specifically, this approach stands upon the intersection of convolution and transformer, combines self-attention mechanism and deep convolution, and uses a well-designed stem structure to explore the global and local relationships. Moreover, in TC-slot, a classifier built on slot-attention mechanism directly involved in the decision-making process further localizes salient regions of facial depression patterns and provides precise and meaningful explanations. The results indicate that the proposed approach effectively improves the classification and recognition performance compared with other state-of-the-art approaches, with guaranteed favorable visual interpretability, providing clinical insights into the assessment of the assessing depression. © 2023 IEEE.
KW  - Convolutional neural networks
KW  - Depression
KW  - Transformer
KW  - Visual interpretability
KW  - Computer vision
KW  - Convolutional neural networks
KW  - Decision making
KW  - Deep learning
KW  - Attention mechanisms
KW  - Convolutional neural network
KW  - Depression
KW  - Facial images
KW  - Interpretability
KW  - Receptive fields
KW  - Transformer
KW  - Transformer modeling
KW  - Visual interpretability
KW  - Visual interpretation
KW  - Convolution
PB  - IEEE Computer Society
SN  - 19457871 (ISSN); 978-166546891-6 (ISBN)
LA  - English
J2  - Proc. IEEE Int. Conf. Multimedia Expo
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 0; Correspondence Address: X. Hu; Lanzhou University, Gansu Provincial Key Laboratory of Wearable Computing, Lanzhou, China; email: huxp@lzu.edu.cn; B. Hu; Lanzhou University, Gansu Provincial Key Laboratory of Wearable Computing, Lanzhou, China; email: bh@lzu.edu.cn; Conference name: 2023 IEEE International Conference on Multimedia and Expo, ICME 2023; Conference date: 10 July 2023 through 14 July 2023; Conference code: 192032
ER  -

TY  - CONF
AU  - Laskar, M.T.R.
AU  - Bari, M.S.
AU  - Rahman, M.
AU  - Bhuiyan, M.A.H.
AU  - Joty, S.
AU  - Huang, J.X.
TI  - A Systematic Study and Comprehensive Evaluation of ChatGPT on Benchmark Datasets
PY  - 2023
T2  - Proceedings of the Annual Meeting of the Association for Computational Linguistics
SP  - 431
EP  - 469
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85172263628&partnerID=40&md5=e0d5369d3651fedee63de0dc70397d89
AD  - York University, Canada
AD  - Nanyang Technological University, Singapore
AD  - Dialpad Canada Inc., Canada
AD  - Royal Bank of Canada, Canada
AD  - Salesforce Research
AB  - The development of large language models (LLMs) such as ChatGPT has brought a lot of attention recently. However, their evaluation in the benchmark academic datasets remains under-explored due to the difficulty of evaluating the generative outputs produced by this model against the ground truth. In this paper, we aim to present a thorough evaluation of ChatGPT's performance on diverse academic datasets, covering tasks like question-answering, text summarization, code generation, commonsense reasoning, mathematical problem-solving, machine translation, bias detection, and ethical considerations. Specifically, we evaluate ChatGPT across 140 tasks and analyze 255K responses it generates in these datasets. This makes our work the largest evaluation of ChatGPT in NLP benchmarks. In short, our study aims to validate the strengths and weaknesses of ChatGPT in various tasks and provide insights for future research using LLMs. We also report a new emergent ability to follow multi-query instructions that we mostly found in ChatGPT and other instruction-tuned models. Our extensive evaluation shows that even though ChatGPT is capable of performing a wide variety of tasks, and may obtain impressive performance in several benchmark datasets, it is still far from achieving the ability to reliably solve many challenging tasks. By providing a thorough assessment of ChatGPT's performance across diverse NLP tasks, this paper sets the stage for a targeted deployment of ChatGPT-like LLMs in real-world applications. © 2023 Association for Computational Linguistics.
KW  - Benchmarking
KW  - Computational linguistics
KW  - Benchmark datasets
KW  - Codegeneration
KW  - Commonsense reasoning
KW  - Comprehensive evaluation
KW  - Ground truth
KW  - Language model
KW  - Performance
KW  - Question Answering
KW  - Systematic study
KW  - Text Summarisation
KW  - Natural language processing systems
PB  - Association for Computational Linguistics (ACL)
SN  - 0736587X (ISSN); 978-195942962-3 (ISBN)
LA  - English
J2  - Proc. Annu. Meet. Assoc. Comput Linguist.
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 2; Correspondence Address: S. Joty; Nanyang Technological University, Singapore; email: srjoty@ntu.edu.sg; J.X. Huang; York University, Canada; email: jhuang@yorku.ca; Conference name: 61st Annual Meeting of the Association for Computational Linguistics, ACL 2023; Conference date: 9 July 2023 through 14 July 2023; Conference code: 192867
ER  -

TY  - JOUR
AU  - Lim, B.
AU  - Seth, I.
AU  - Bulloch, G.
AU  - Xie, Y.
AU  - Hunter-Smith, D.J.
AU  - Rozen, W.M.
TI  - Evaluating the efficacy of major language models in providing guidance for hand trauma nerve laceration patients: a case study on Google’s AI BARD, Bing AI, and ChatGPT
PY  - 2023
T2  - Plastic and Aesthetic Research
VL  - 10
C7  - 43
DO  - 10.20517/2347-9264.2023.70
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85172765435&doi=10.20517%2f2347-9264.2023.70&partnerID=40&md5=aed49dc4328c0f4a7db3647f6900f188
AD  - Department of Plastic Surgery, Peninsula Health, Melbourne, 3199, Australia
AD  - Central Clinical School, Monash University, The Alfred Centre, Melbourne, 3004, Australia
AD  - Faculty of Medicine and Surgery, The University of Melbourne, 3053, Australia
AB  - This study evaluated three prominent Large Language Models (LLMs)-Google’s AI BARD, Bing’s AI, and ChatGPT-4 in providing patient advice for hand laceration. Five simulated patient inquiries on hand trauma were prompted to them. A panel of Board-certified plastic surgical residents evaluated the responses for accuracy, comprehensiveness, and appropriate sources. Responses were also compared against existing literature and guidelines. This study suggests that ChatGPT outperforms BARD and Bing AI in providing reliable, evidence-based clinical advice, but they still face limitations in depth and specificity. Healthcare professionals are essential in interpreting LLM recommendations, and future research should improve LLM performance by integrating specialized databases and human expertise to advance nerve injury management and optimize patient-centred care. © The Author(s) 2023.
KW  - Artificial intelligence
KW  - BARD
KW  - Bings AI
KW  - ChatGPT
KW  - large language model
KW  - nerve injury
PB  - OAE Publishing Inc.
SN  - 23479264 (ISSN)
LA  - English
J2  - Plast. Aesthet. Res.
M3  - Article
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 2; Correspondence Address: I. Seth; Central Clinical School, Monash University, The Alfred Centre, Melbourne, 99 Commercial Rd, 3004, Australia; email: ishithseth1@gmail.com
ER  -

TY  - JOUR
AU  - Hswen, Y.
AU  - Nguyen, T.T.
TI  - The inclusion of social determinants of health into evaluations of quality and appropriateness of AI assistant-ChatGPT
PY  - 2023
T2  - Prostate Cancer and Prostatic Diseases
DO  - 10.1038/s41391-023-00720-z
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85171195610&doi=10.1038%2fs41391-023-00720-z&partnerID=40&md5=224db9fd0d05f949739970e8d1eccfce
AD  - Department of Epidemiology and Biostatistics, University of California San Francisco, San Francisco, CA, United States
AD  - Department of Epidemiology and Biostatistics, University of Maryland School of Public Health, College Park, MD, United States
PB  - Springer Nature
SN  - 13657852 (ISSN)
LA  - English
J2  - Prostate Cancer Prostatic Dis.
M3  - Letter
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 2; Correspondence Address: Y. Hswen; Department of Epidemiology and Biostatistics, University of California San Francisco, San Francisco, United States; email: yulin.hswen@ucsf.edu; CODEN: PCPDF
ER  -

TY  - JOUR
AU  - Coskun, B.N.
AU  - Yagiz, B.
AU  - Ocakoglu, G.
AU  - Dalkilic, E.
AU  - Pehlivan, Y.
TI  - Assessing the accuracy and completeness of artificial intelligence language models in providing information on methotrexate use
PY  - 2023
T2  - Rheumatology International
DO  - 10.1007/s00296-023-05473-5
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85172274072&doi=10.1007%2fs00296-023-05473-5&partnerID=40&md5=963f2086dad80b17706351ceb5ac27dd
AD  - Division of Rheumatology, Department of Internal Medicine, Faculty of Medicine, Bursa Uludag University, Bursa, Turkey
AD  - Department of Biostatistics, Faculty of Medicine, Bursa Uludag University, Bursa, Turkey
AB  - We aimed to assess Large Language Models (LLMs)—ChatGPT 3.5–4, BARD, and Bing—in their accuracy and completeness when answering Methotrexate (MTX) related questions for treating rheumatoid arthritis. We employed 23 questions from an earlier study related to MTX concerns. These questions were entered into the LLMs, and the responses generated by each model were evaluated by two reviewers using Likert scales to assess accuracy and completeness. The GPT models achieved a 100% correct answer rate, while BARD and Bing scored 73.91%. In terms of accuracy of the outputs (completely correct responses), GPT-4 achieved a score of 100%, GPT 3.5 secured 86.96%, and BARD and Bing each scored 60.87%. BARD produced 17.39% incorrect responses and 8.7% non-responses, while Bing recorded 13.04% incorrect and 13.04% non-responses. The ChatGPT models produced significantly more accurate responses than Bing for the “mechanism of action” category, and GPT-4 model showed significantly higher accuracy than BARD in the “side effects” category. There were no statistically significant differences among the models for the “lifestyle” category. GPT-4 achieved a comprehensive output of 100%, followed by GPT-3.5 at 86.96%, BARD at 60.86%, and Bing at 0%. In the “mechanism of action” category, both ChatGPT models and BARD produced significantly more comprehensive outputs than Bing. For the “side effects” and “lifestyle” categories, the ChatGPT models showed significantly higher completeness than Bing. The GPT models, particularly GPT 4, demonstrated superior performance in providing accurate and comprehensive patient information about MTX use. However, the study also identified inaccuracies and shortcomings in the generated responses. © 2023, The Author(s), under exclusive licence to Springer-Verlag GmbH Germany, part of Springer Nature.
KW  - Accuracy
KW  - Artificial intelligence
KW  - Completeness
KW  - Large language models
KW  - Methotrexate
PB  - Springer Science and Business Media Deutschland GmbH
SN  - 01728172 (ISSN)
C2  - 37747564
LA  - English
J2  - Rheumatol. Int.
M3  - Article
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 2; Correspondence Address: B.N. Coskun; Division of Rheumatology, Department of Internal Medicine, Faculty of Medicine, Bursa Uludag University, Bursa, Turkey; email: belkisnihanseniz@hotmail.com; CODEN: RHIND
ER  -

TY  - JOUR
AU  - Han, Z.
AU  - Battaglia, F.
AU  - Udaiyar, A.
AU  - Fooks, A.
AU  - Terlecky, S.R.
TI  - An explorative assessment of ChatGPT as an aid in medical education: Use it with caution
PY  - 2023
T2  - Medical Teacher
DO  - 10.1080/0142159X.2023.2271159
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85172155627&doi=10.1080%2f0142159X.2023.2271159&partnerID=40&md5=4d3b2bd3b8ff835a67ecbb3b0d29d248
AD  - Department of Medical Sciences, Hackensack Meridian School of Medicine, Nutley, NJ, United States
AB  - Objective: To explore the use of ChatGPT by educators and students in a medical school setting. Method: This study used the public version of ChatGPT launched by OpenAI on November 30, 2022 (https://openai.com/blog/chatgpt/). We employed prompts to ask ChatGPT to 1) generate a content outline for a session on the topics of cholesterol, lipoproteins, and hyperlipidemia for medical students; 2) produce a list of learning objectives for the session; and 3) write assessment questions with and without clinical vignettes related to the identified learning objectives. We assessed the responses by ChatGPT for accuracy and reliability to determine the potential of the chatbot as an aid to educators and as a “know-it-all” medical information provider for students. Results: ChatGPT can function as an aid to educators, but it is not yet suitable as a reliable information resource for educators and medical students. Conclusion: ChatGPT can be a useful tool to assist medical educators in drafting course and session content outlines and create assessment questions. At the same time, caution must be taken as ChatGPT is prone to providing incorrect information; expert oversight and caution are necessary to ensure the information generated is accurate and beneficial to students. Therefore, it is premature for medical students to use the current version of ChatGPT as a “know-it-all” information provider. In the future, medical educators should work with programming experts to explore and grow the full potential of AI in medical education. © 2023 Informa UK Limited, trading as Taylor & Francis Group.
KW  - ChatGPT
KW  - Medical education
PB  - Taylor and Francis Ltd.
SN  - 0142159X (ISSN)
LA  - English
J2  - Med. Teach.
M3  - Article
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 4; Correspondence Address: Z. Han; Department of Medical Sciences, Hackensack Meridian School of Medicine, Nutley, 123 Metro Blvd, United States; email: zhiyong.han@hmsom.edu; CODEN: MEDTD
ER  -

TY  - CONF
AU  - Wijesiriwardene, T.
AU  - Wickramarachchi, R.
AU  - Gajera, B.G.
AU  - Gowaikar, S.M.
AU  - Gupta, C.
AU  - Chadha, A.
AU  - Reganti, A.N.
AU  - Sheth, A.
AU  - Das, A.
TI  - ANALOGICAL - A Novel Benchmark for Long Text Analogy Evaluation in Large Language Models
PY  - 2023
T2  - Proceedings of the Annual Meeting of the Association for Computational Linguistics
SP  - 3534
EP  - 3549
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85168728019&partnerID=40&md5=5f4c604292faff39d361447bf522d867
AD  - AI Institute, University of South Carolina, United States
AD  - Nirma University, India
AD  - BITS Pilani, Goa, India
AD  - IIIT Delhi, India
AD  - Amazon AI, United States
AD  - Stanford, United States
AD  - Amazon, United States
AB  - Over the past decade, analogies, in the form of word-level analogies, have played a significant role as an intrinsic measure of evaluating the quality of word embedding methods such as word2vec. Modern large language models (LLMs), however, are primarily evaluated on extrinsic measures based on benchmarks such as GLUE and SuperGLUE, and there are only a few investigations on whether LLMs can draw analogies between long texts. In this paper, we present ANALOGICAL, a new benchmark to intrinsically evaluate LLMs across a taxonomy of analogies of long text with six levels of complexity - (i) word, (ii) word vs. sentence, (iii) syntactic, (iv) negation, (v) entailment, and (vi) metaphor. Using thirteen datasets and three different distance measures, we evaluate the abilities of eight LLMs in identifying analogical pairs in the semantic vector space. Our evaluation finds that it is increasingly challenging for LLMs to identify analogies when going up the analogy taxonomy. © 2023 Association for Computational Linguistics.
KW  - Computational linguistics
KW  - Semantics
KW  - Vector spaces
KW  - Distance measure
KW  - Embedding method
KW  - Extrinsic measures
KW  - Language model
KW  - Semantic vectors
KW  - Word level
KW  - Taxonomies
PB  - Association for Computational Linguistics (ACL)
SN  - 0736587X (ISSN); 978-195942962-3 (ISBN)
LA  - English
J2  - Proc. Annu. Meet. Assoc. Comput Linguist.
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 1; Correspondence Address: T. Wijesiriwardene; AI Institute, University of South Carolina, United States; email: thilini@sc.edu; Conference name: 61st Annual Meeting of the Association for Computational Linguistics, ACL 2023; Conference date: 9 July 2023 through 14 July 2023; Conference code: 192867
ER  -

TY  - JOUR
AU  - Mihalache, A.
AU  - Huang, R.S.
AU  - Popovic, M.M.
AU  - Muni, R.H.
TI  - ChatGPT-4: An assessment of an upgraded artificial intelligence chatbot in the United States Medical Licensing Examination
PY  - 2023
T2  - Medical Teacher
DO  - 10.1080/0142159X.2023.2249588
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85174198140&doi=10.1080%2f0142159X.2023.2249588&partnerID=40&md5=837ba824fe561129d8759308b73c997e
AD  - Temerty Faculty of Medicine, University of Toronto, Toronto, ON, Canada
AD  - Department of Ophthalmology and Vision Sciences, University of Toronto, Toronto, ON, Canada
AD  - Department of Ophthalmology, St. Michael’s Hospital/Unity Health Toronto, Toronto, ON, Canada
AB  - Purpose: ChatGPT-4 is an upgraded version of an artificial intelligence chatbot. The performance of ChatGPT-4 on the United States Medical Licensing Examination (USMLE) has not been independently characterized. We aimed to assess the performance of ChatGPT-4 at responding to USMLE Step 1, Step 2CK, and Step 3 practice questions. Method: Practice multiple-choice questions for the USMLE Step 1, Step 2CK, and Step 3 were compiled. Of 376 available questions, 319 (85%) were analyzed by ChatGPT-4 on March 21st, 2023. Our primary outcome was the performance of ChatGPT-4 for the practice USMLE Step 1, Step 2CK, and Step 3 examinations, measured as the proportion of multiple-choice questions answered correctly. Our secondary outcomes were the mean length of questions and responses provided by ChatGPT-4. Results: ChatGPT-4 responded to 319 text-based multiple-choice questions from USMLE practice test material. ChatGPT-4 answered 82 of 93 (88%) questions correctly on USMLE Step 1, 91 of 106 (86%) on Step 2CK, and 108 of 120 (90%) on Step 3. ChatGPT-4 provided explanations for all questions. ChatGPT-4 spent 30.8 ± 11.8 s on average responding to practice questions for USMLE Step 1, 23.0 ± 9.4 s per question for Step 2CK, and 23.1 ± 8.3 s per question for Step 3. The mean length of practice USMLE multiple-choice questions that were answered correctly and incorrectly by ChatGPT-4 was similar (difference = 17.48 characters, SE = 59.75, 95%CI = [-100.09,135.04], t = 0.29, p = 0.77). The mean length of ChatGPT-4’s correct responses to practice questions was significantly shorter than the mean length of incorrect responses (difference = 79.58 characters, SE = 35.42, 95%CI = [9.89,149.28], t = 2.25, p = 0.03). Conclusions: ChatGPT-4 answered a remarkably high proportion of practice questions correctly for USMLE examinations. ChatGPT-4 performed substantially better at USMLE practice questions than previous models of the same AI chatbot. © 2023 Informa UK Limited, trading as Taylor & Francis Group.
KW  - artificial intelligence
KW  - chatgpt-4
KW  - natural language processing
KW  - United States medical licensing examination
KW  - article
KW  - artificial intelligence chatbot
KW  - ChatGPT
KW  - controlled study
KW  - human
KW  - licensing
KW  - multiple choice test
KW  - natural language processing
KW  - outcome assessment
KW  - United States
PB  - Taylor and Francis Ltd.
SN  - 0142159X (ISSN)
LA  - English
J2  - Med. Teach.
M3  - Article
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 0; Correspondence Address: R.H. Muni; Department of Ophthalmology, St. Michael’s Hospital, Unity Health Toronto, Toronto, 30 Bond St, Donnelly Wing, 8th Floor, M5B 1W8, Canada; email: rajeev.muni@utoronto.ca; CODEN: MEDTD
ER  -

TY  - JOUR
AU  - Koga, S.
AU  - Martin, N.B.
AU  - Dickson, D.W.
TI  - Evaluating the performance of large language models: ChatGPT and Google Bard in generating differential diagnoses in clinicopathological conferences of neurodegenerative disorders
PY  - 2023
T2  - Brain Pathology
DO  - 10.1111/bpa.13207
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85166959509&doi=10.1111%2fbpa.13207&partnerID=40&md5=bdb605275b0f5cd1857cf08729cb13b8
AD  - Department of Neuroscience, Mayo Clinic, Jacksonville, FL, United States
AB  - This study explores the utility of the large language models (LLMs), specifically ChatGPT and Google Bard, in predicting neuropathologic diagnoses from clinical summaries. A total of 25 cases of neurodegenerative disorders presented at Mayo Clinic brain bank Clinico-Pathological Conferences were analyzed. The LLMs provided multiple pathologic diagnoses and their rationales, which were compared with the final clinical diagnoses made by physicians. ChatGPT-3.5, ChatGPT-4, and Google Bard correctly made primary diagnoses in 32%, 52%, and 40% of cases, respectively, while correct diagnoses were included in 76%, 84%, and 76% of cases, respectively. These findings highlight the potential of artificial intelligence tools like ChatGPT in neuropathology, suggesting they may facilitate more comprehensive discussions in clinicopathological conferences. © 2023 The Authors. Brain Pathology published by John Wiley & Sons Ltd on behalf of International Society of Neuropathology.
KW  - artificial intelligence
KW  - ChatGPT
KW  - clinicopathological conference
KW  - CPC
KW  - Google Bard
KW  - large language model
KW  - neuropathology
KW  - pathology
PB  - John Wiley and Sons Inc
SN  - 10156305 (ISSN)
LA  - English
J2  - Brain Pathol.
M3  - Letter
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 2; Correspondence Address: S. Koga; Department of Pathology and Laboratory Medicine, Hospital of the University of Pennsylvania, Philadelphia, 3400 Spruce Street, 19104, United States; email: shunsuke.koga@pennmedicine.upenn.edu; CODEN: BRPAE
ER  -

TY  - CONF
AU  - Tam, D.
AU  - Mascarenhas, A.
AU  - Zhang, S.
AU  - Kwan, S.
AU  - Bansal, M.
AU  - Raffel, C.
TI  - Evaluating the Factual Consistency of Large Language Models Through News Summarization
PY  - 2023
T2  - Proceedings of the Annual Meeting of the Association for Computational Linguistics
SP  - 5220
EP  - 5255
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85173773397&partnerID=40&md5=e8fce33019b336cd1a5475547379abad
AD  - University of North Carolina, Chapel Hill, United States
AB  - While large language models (LLMs) have proven to be effective on a large variety of tasks, they are also known to hallucinate information. To measure whether an LLM prefers factually consistent continuations of its input, we propose a new benchmark called FIB (Factual Inconsistency Benchmark) that focuses on the task of summarization. Specifically, our benchmark involves comparing the scores an LLM assigns to a factually consistent versus a factually inconsistent summary for an input news article. For factually consistent summaries, we use human-written reference summaries that we manually verify as factually consistent. To generate summaries that are factually inconsistent, we generate summaries from a suite of summarization models that we have manually annotated as factually inconsistent. A model's factual consistency is then measured according to its accuracy, i.e. the proportion of documents where it assigns a higher score to the factually consistent summary. To validate the usefulness of FIB, we evaluate 23 large language models ranging from 1B to 176B parameters from six different model families including BLOOM and OPT. We find that existing LLMs generally assign a higher score to factually consistent summaries than to factually inconsistent summaries. However, if the factually inconsistent summaries occur verbatim in the document, then LLMs assign a higher score to these factually inconsistent summaries than factually consistent summaries. We validate design choices in our benchmark including the scoring method and source of distractor summaries. © 2023 Association for Computational Linguistics.
KW  - Language model
KW  - News articles
KW  - News summarization
KW  - Scoring methods
KW  - Summarization models
KW  - Computational linguistics
PB  - Association for Computational Linguistics (ACL)
SN  - 0736587X (ISSN); 978-195942962-3 (ISBN)
LA  - English
J2  - Proc. Annu. Meet. Assoc. Comput Linguist.
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 3; Conference name: 61st Annual Meeting of the Association for Computational Linguistics, ACL 2023; Conference date: 9 July 2023 through 14 July 2023; Conference code: 192867
ER  -

TY  - CONF
AU  - Nguyen, H.A.
AU  - Stec, H.
AU  - Hou, X.
AU  - Di, S.
AU  - McLaren, B.M.
TI  - Evaluating ChatGPT’s Decimal Skills and Feedback Generation in a Digital Learning Game
PY  - 2023
T2  - Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)
VL  - 14200 LNCS
SP  - 278
EP  - 293
DO  - 10.1007/978-3-031-42682-7_19
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85171993510&doi=10.1007%2f978-3-031-42682-7_19&partnerID=40&md5=2bcb454c7a16d9d95d2af33c09c23969
AD  - Carnegie Mellon University, Pittsburgh, 15213, PA, United States
AD  - University of Michigan, Ann Arbor, 48104, MI, United States
AB  - While open-ended self-explanations have been shown to promote robust learning in multiple studies, they pose significant challenges to automated grading and feedback in technology-enhanced learning, due to the unconstrained nature of the students’ input. Our work investigates whether recent advances in Large Language Models, and in particular ChatGPT, can address this issue. Using decimal exercises and student data from a prior study of the learning game Decimal Point, with more than 5,000 open-ended self-explanation responses, we investigate ChatGPT's capability in (1) solving the in-game exercises, (2) determining the correctness of students’ answers, and (3) providing meaningful feedback to incorrect answers. Our results showed that ChatGPT can respond well to conceptual questions, but struggled with decimal place values and number line problems. In addition, it was able to accurately assess the correctness of 75% of the students’ answers and generated generally high-quality feedback, similar to human instructors. We conclude with a discussion of ChatGPT's strengths and weaknesses and suggest several venues for extending its use cases in digital teaching and learning. © 2023, The Author(s), under exclusive license to Springer Nature Switzerland AG.
KW  - Automated grading
KW  - ChatGPT
KW  - Decimal Numbers
KW  - Self-Explanation
KW  - E-learning
KW  - Education computing
KW  - Grading
KW  - Learning systems
KW  - Automated feedback
KW  - Automated grading
KW  - ChatGPT
KW  - Decimal number
KW  - Digital learning games
KW  - Language model
KW  - Learning game
KW  - Robust learning
KW  - Self explanations
KW  - Technology enhanced learning
KW  - Students
A2  - Viberg O.
A2  - Jivet I.
A2  - Muñoz-Merino P.J.
A2  - Perifanou M.
A2  - Papathoma T.
PB  - Springer Science and Business Media Deutschland GmbH
SN  - 03029743 (ISSN); 978-303142681-0 (ISBN)
LA  - English
J2  - Lect. Notes Comput. Sci.
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 1; Correspondence Address: H.A. Nguyen; Carnegie Mellon University, Pittsburgh, 15213, United States; email: hn1@cs.cmu.edu; Conference name: Proceedings of the 18th European Conference on Technology Enhanced Learning, ECTEL 2023; Conference date: 4 September 2023 through 8 September 2023; Conference code: 299989
ER  -

TY  - CONF
AU  - Wang, Z.
AU  - Mao, S.
AU  - Wu, W.
AU  - Xia, Y.
AU  - Deng, Y.
AU  - Tien, J.
TI  - Assessing Phrase Break of ESL Speech with Pre-trained Language Models and Large Language Models
PY  - 2023
T2  - Proceedings of the Annual Conference of the International Speech Communication Association, INTERSPEECH
VL  - 2023-August
SP  - 4194
EP  - 4198
DO  - 10.21437/Interspeech.2023-910
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85170843933&doi=10.21437%2fInterspeech.2023-910&partnerID=40&md5=00323974a718c828ee61a00ddd7076fd
AD  - Peking University, Beijing, China
AD  - Microsoft Research Asia, Beijing, China
AB  - This work introduces approaches to assessing phrase breaks in ESL learners' speech using pre-trained language models (PLMs) and large language models (LLMs). There are two tasks: overall assessment of phrase break for a speech clip and fine-grained assessment of every possible phrase break position. To leverage NLP models, speech input is first force-aligned with texts, and then pre-processed into a token sequence, including words and phrase break information. To utilize PLMs, we propose a pre-training and fine-tuning pipeline with the processed tokens. This process includes pre-training with a replaced break token detection module and fine-tuning with text classification and sequence labeling. To employ LLMs, we design prompts for ChatGPT. The experiments show that with the PLMs, the dependence on labeled training data has been greatly reduced, and the performance has improved. Meanwhile, we verify that ChatGPT, a renowned LLM, has potential for further advancement in this area. © 2023 International Speech Communication Association. All rights reserved.
KW  - computer-aided language learning
KW  - ESL speech
KW  - large language models
KW  - phrase break
KW  - pre-trained language models
KW  - Classification (of information)
KW  - Computer aided instruction
KW  - Natural language processing systems
KW  - Speech communication
KW  - Text processing
KW  - Computer-Aided Language Learning
KW  - ESL speech
KW  - Fine grained
KW  - Fine tuning
KW  - Language model
KW  - Large language model
KW  - Phrase break
KW  - Pre-trained language model
KW  - Pre-training
KW  - Computational linguistics
PB  - International Speech Communication Association
SN  - 2308457X (ISSN)
LA  - English
J2  - Proc. Annu. Conf. Int. Speech. Commun. Assoc., INTERSPEECH
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 0; Conference name: 24th International Speech Communication Association, Interspeech 2023; Conference date: 20 August 2023 through 24 August 2023; Conference code: 191724
ER  -

TY  - JOUR
AU  - Epstein, R.H.
AU  - Dexter, F.
TI  - Variability in Large Language Models’ Responses to Medical Licensing and Certification Examinations. Comment on “How Does ChatGPT Perform on the United States Medical Licensing Examination? The Implications of Large Language Models for Medical Education and Knowledge Assessment”
PY  - 2023
T2  - JMIR Medical Education
VL  - 9
C7  - e48305
DO  - 10.2196/48305
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85165937596&doi=10.2196%2f48305&partnerID=40&md5=3679d9f3d871c3def8d3dee2138746e3
AD  - Department of Anesthesiology, Perioperative Medicine and Pain Management, University of Miami Miller School of Medicine, Miami, FL, United States
AD  - Division of Management Consulting, Department of Anesthesia, University of Iowa, Iowa City, IA, United States
KW  - AI
KW  - artificial intelligence
KW  - chatbot
KW  - ChatGPT
KW  - conversational agent
KW  - education technology
KW  - generative pre-trained transformer
KW  - Google Bard
KW  - GPT
KW  - knowledge assessment
KW  - large language models
KW  - machine learning
KW  - medical education
KW  - MedQA
KW  - natural language processing
KW  - NLP
PB  - JMIR Publications Inc.
SN  - 23693762 (ISSN)
LA  - English
J2  - JMIR Med. Educ.
M3  - Letter
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 2; Correspondence Address: R.H. Epstein; Department of Anesthesiology, Perioperative Medicine and Pain Management, University of Miami Miller School of Medicine, Miami, 1400 NW 12th Ave Suite 4022F, 33136, United States; email: repstein@med.miami.edu
ER  -

TY  - CONF
AU  - Wu, H.
AU  - Lin, N.
AU  - Jiang, S.
AU  - Xiao, L.
TI  - BERT_4EVER at LangLearn: Language Development Assessment Model based on Sequential Information Attention Mechanism
PY  - 2023
T2  - CEUR Workshop Proceedings
VL  - 3473
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85173571982&partnerID=40&md5=32f9c2d007c074563b110ca065c524cc
AD  - School of Information Science and Technology, Guangdong University of Foreign Studies, Guangdong, Guangzhou, China
AD  - School of Computer Science and Technology, Guangdong University of Technology, Guangdong, Guangzhou, China
AD  - Faculty of Asian Languages and Cultures, Guangdong University of Foreign Studies, Guangdong, Guangzhou, China
AB  - In recent years, investigations into language acquisition have greatly benefited from the utilization of natural language processing technologies, particularly in analyzing extensive corpora consisting of authentic texts produced by learners across the realms of first and second language acquisition. A crucial task in this domain involves the assessment of language learners' language ability development. The “Language Learning Development” task featured in EVALITA 2023 [1] marks a significant milestone as the inaugural shared task focused on automated language development assessment, which entails predicting the relative order of two essays written by the same student. We introduce a novel attention mechanism, namely sequential information attention mechanism, with the primary objective of exploiting information interaction between sequence texts. Experimental results on the COWS dataset show the effectiveness of our proposed sequential information attention mechanism, showcasing its substantial impact on model performance during the final evaluation phase. © 2023 Copyright for this paper by its authors. Use permitted under Creative Commons License Attribution 4.0 International (CC BY 4.0).
KW  - BERT
KW  - Language Development Assessment
KW  - Sequential Information Attention Mechanism
KW  - Assessment models
KW  - Attention mechanisms
KW  - BERT
KW  - Development assessments
KW  - Language acquisition
KW  - Language development
KW  - Language development assessment
KW  - Model-based OPC
KW  - Sequential information
KW  - Sequential information attention mechanism
KW  - Natural language processing systems
A2  - Lai M.
A2  - Menini S.
A2  - Polignano M.
A2  - Russo V.
A2  - Sprugnoli R.
A2  - Venturi G.
PB  - CEUR-WS
SN  - 16130073 (ISSN)
LA  - English
J2  - CEUR Workshop Proc.
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 1; Correspondence Address: N. Lin; School of Computer Science and Technology, Guangdong University of Technology, Guangzhou, Guangdong, China; email: neakail@outlook.com; S. Jiang; School of Information Science and Technology, Guangdong University of Foreign Studies, Guangzhou, Guangdong, China; email: 200511402@oamail.gdufs.edu.cn; Conference name: 8th Evaluation Campaign of Natural Language Processing and Speech Tools for Italian. Final Workshop, EVALITA 2023; Conference date: 7 September 2023 through 8 September 2023; Conference code: 192243
ER  -

TY  - JOUR
AU  - Lai, U.H.
AU  - Wu, K.S.
AU  - Hsu, T.-Y.
AU  - Kan, J.K.C.
TI  - Evaluating the performance of ChatGPT-4 on the United Kingdom Medical Licensing Assessment
PY  - 2023
T2  - Frontiers in Medicine
VL  - 10
C7  - 1240915
DO  - 10.3389/fmed.2023.1240915
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85173547356&doi=10.3389%2ffmed.2023.1240915&partnerID=40&md5=80c3109270a78fe2829dca65de47cf59
AD  - Sandwell and West Birmingham NHS Trust, West Bromwich, United Kingdom
AD  - Aston Medical School, Birmingham, United Kingdom
AD  - University Hospitals Birmingham NHS Trust, Birmingham, United Kingdom
AD  - Worcestershire Acute Hospitals NHS Trust, Worcester, United Kingdom
AB  - Introduction: Recent developments in artificial intelligence large language models (LLMs), such as ChatGPT, have allowed for the understanding and generation of human-like text. Studies have found LLMs abilities to perform well in various examinations including law, business and medicine. This study aims to evaluate the performance of ChatGPT in the United Kingdom Medical Licensing Assessment (UKMLA). Methods: Two publicly available UKMLA papers consisting of 200 single-best-answer (SBA) questions were screened. Nine SBAs were omitted as they contained images that were not suitable for input. Each question was assigned a specialty based on the UKMLA content map published by the General Medical Council. A total of 191 SBAs were inputted in ChatGPT-4 through three attempts over the course of 3 weeks (once per week). Results: ChatGPT scored 74.9% (143/191), 78.0% (149/191) and 75.6% (145/191) on three attempts, respectively. The average of all three attempts was 76.3% (437/573) with a 95% confidence interval of (74.46% and 78.08%). ChatGPT answered 129 SBAs correctly and 32 SBAs incorrectly on all three attempts. On three attempts, ChatGPT performed well in mental health (8/9 SBAs), cancer (11/14 SBAs) and cardiovascular (10/13 SBAs). On three attempts, ChatGPT did not perform well in clinical haematology (3/7 SBAs), endocrine and metabolic (2/5 SBAs) and gastrointestinal including liver (3/10 SBAs). Regarding to response consistency, ChatGPT provided correct answers consistently in 67.5% (129/191) of SBAs but provided incorrect answers consistently in 12.6% (24/191) and inconsistent response in 19.9% (38/191) of SBAs, respectively. Discussion and conclusion: This study suggests ChatGPT performs well in the UKMLA. There may be a potential correlation between specialty performance. LLMs ability to correctly answer SBAs suggests that it could be utilised as a supplementary learning tool in medical education with appropriate medical educator supervision. Copyright © 2023 Lai, Wu, Hsu and Kan.
KW  - assessment
KW  - ChatGPT
KW  - examination
KW  - medical education
KW  - Medical Licensing Examination
KW  - medicine
KW  - United Kingdom Medical Licensing Assessment
KW  - anesthesia
KW  - Article
KW  - ChatGPT
KW  - child health
KW  - controlled study
KW  - data consistency
KW  - evaluation study
KW  - general practice
KW  - genetics
KW  - genome
KW  - gynecology
KW  - hematology
KW  - human
KW  - licensing
KW  - malignant neoplasm
KW  - mental health
KW  - ophthalmology
KW  - performance
KW  - perioperative medicine
KW  - primary health care
KW  - United Kingdom
PB  - Frontiers Media SA
SN  - 2296858X (ISSN)
LA  - English
J2  - Front. Med.
M3  - Article
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 2; Correspondence Address: U.H. Lai; Sandwell and West Birmingham NHS Trust, West Bromwich, United Kingdom; email: UHL@doctors.org.uk; K.S. Wu; Sandwell and West Birmingham NHS Trust, West Bromwich, United Kingdom; email: kengsamwu@doctors.org.uk
ER  -

TY  - CONF
AU  - Wang, Y.
AU  - Zhang, Z.
AU  - Wang, R.
TI  - Element-aware Summarization with Large Language Models: Expert-aligned Evaluation and Chain-of-Thought Method
PY  - 2023
T2  - Proceedings of the Annual Meeting of the Association for Computational Linguistics
VL  - 1
SP  - 8640
EP  - 8665
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85171967924&partnerID=40&md5=b337c311a69b4f54b964c1430b02d4a8
AD  - Shanghai Jiao Tong University, China
AB  - Automatic summarization generates concise summaries that contain key ideas of source documents. As the most mainstream datasets for the news sub-domain, CNN/DailyMail and BBC XSum have been widely used for performance benchmarking. However, the reference summaries of those datasets turn out to be noisy, mainly in terms of factual hallucination and information redundancy. To address this challenge, we first annotate new expert-writing Element-aware test sets following the “Lasswell Communication Model” proposed by Lasswell (1948), allowing reference summaries to focus on more fine-grained news elements objectively and comprehensively. Utilizing the new test sets, we observe the surprising zero-shot summary ability of LLMs, which addresses the issue of the inconsistent results between human preference and automatic evaluation metrics of LLMs' zero-shot summaries in prior work. Further, we propose a Summary Chain-of-Thought (SumCoT) technique to elicit LLMs to generate summaries step by step, which helps them integrate more fine-grained details of source documents into the final summaries that correlate with the human writing mindset. Experimental results show our method outperforms state-of-the-art fine-tuned PLMs and zero-shot LLMs by +4.33/+4.77 in ROUGE-L on the two datasets, respectively. Dataset and code are publicly available at https://github.com/Alsace08/SumCoT. © 2023 Association for Computational Linguistics.
KW  - Computational linguistics
KW  - Natural language processing systems
KW  - Zero-shot learning
KW  - Automatic evaluation
KW  - Automatic summarization
KW  - Communications modeling
KW  - Evaluation metrics
KW  - Fine grained
KW  - Information redundancies
KW  - Language model
KW  - Performance benchmarking
KW  - Subdomain
KW  - Test sets
KW  - Benchmarking
PB  - Association for Computational Linguistics (ACL)
SN  - 0736587X (ISSN); 978-195942972-2 (ISBN)
LA  - English
J2  - Proc. Annu. Meet. Assoc. Comput Linguist.
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 1; Correspondence Address: R. Wang; Shanghai Jiao Tong University, China; email: wangrui12@sjtu.edu.cn; Conference name: 61st Annual Meeting of the Association for Computational Linguistics, ACL 2023; Conference date: 9 July 2023 through 14 July 2023; Conference code: 192160
ER  -

TY  - JOUR
AU  - Hsu, H.-Y.
AU  - Hsu, K.-C.
AU  - Hou, S.-Y.
AU  - Wu, C.-L.
AU  - Hsieh, Y.-W.
AU  - Cheng, Y.-D.
TI  - Examining Real-World Medication Consultations and Drug-Herb Interactions: ChatGPT Performance Evaluation
PY  - 2023
T2  - JMIR Medical Education
VL  - 9
C7  - e48433
DO  - 10.2196/48433
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85169057594&doi=10.2196%2f48433&partnerID=40&md5=db7929a80ec2786c3d7bd9ff612c5de8
AD  - Department of Pharmacy, China Medical University Hospital, Taichung, Taiwan
AD  - Graduate Institute of Clinical Pharmacy, College of Medicine, National Taiwan University, Taipei, Taiwan
AD  - Artificial Intelligence Center, China Medical University Hospital, Taichung, Taiwan
AD  - Department of Medicine, China Medical University, Taichung, Taiwan
AD  - School of Pharmacy, College of Pharmacy, China Medical University, Taichung, Taiwan
AB  - Background: Since OpenAI released ChatGPT, with its strong capability in handling natural tasks and its user-friendly interface, it has garnered significant attention. Objective: A prospective analysis is required to evaluate the accuracy and appropriateness of medication consultation responses generated by ChatGPT. Methods: A prospective cross-sectional study was conducted by the pharmacy department of a medical center in Taiwan. The test data set comprised retrospective medication consultation questions collected from February 1, 2023, to February 28, 2023, along with common questions about drug-herb interactions. Two distinct sets of questions were tested: real-world medication consultation questions and common questions about interactions between traditional Chinese and Western medicines. We used the conventional double-review mechanism. The appropriateness of each response from ChatGPT was assessed by 2 experienced pharmacists. In the event of a discrepancy between the assessments, a third pharmacist stepped in to make the final decision. Results: Of 293 real-world medication consultation questions, a random selection of 80 was used to evaluate ChatGPT’s performance. ChatGPT exhibited a higher appropriateness rate in responding to public medication consultation questions compared to those asked by health care providers in a hospital setting (31/51, 61% vs 20/51, 39%; P=.01). Conclusions: The findings from this study suggest that ChatGPT could potentially be used for answering basic medication consultation questions. Our analysis of the erroneous information allowed us to identify potential medical risks associated with certain questions; this problem deserves our close attention. ©Hsing-Yu Hsu, Kai-Cheng Hsu, Shih-Yen Hou, Ching-Lung Wu, Yow-Wen Hsieh, Yih-Dih Cheng.
KW  - chat generative pre-trained transformer
KW  - ChatGPT
KW  - drug-herb interactions
KW  - language models
KW  - large language model
KW  - LLM
KW  - natural language processing
KW  - NLP
KW  - pharmacist
KW  - real-world medication consultation questions
PB  - JMIR Publications Inc.
SN  - 23693762 (ISSN)
LA  - English
J2  - JMIR Med. Educ.
M3  - Article
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 2; Correspondence Address: Y.-W. Hsieh; Department of Pharmacy, China Medical University Hospital, Taichung, 2 Yuh-Der Road, 404327, Taiwan; email: yowenhsieh@gmail.com
ER  -

TY  - JOUR
AU  - Hurley, E.T.
AU  - Crook, B.S.
AU  - Lorentz, S.G.
AU  - Danilkowicz, R.M.
AU  - Lau, B.C.
AU  - Taylor, D.C.
AU  - Dickens, J.F.
AU  - Anakwenze, O.
AU  - Klifto, C.S.
TI  - Evaluation High-Quality of Information from ChatGPT (Artificial Intelligence—Large Language Model) Artificial Intelligence on Shoulder Stabilization Surgery
PY  - 2023
T2  - Arthroscopy - Journal of Arthroscopic and Related Surgery
DO  - 10.1016/j.arthro.2023.07.048
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85168835445&doi=10.1016%2fj.arthro.2023.07.048&partnerID=40&md5=aeaf648f967bef52d576afe39d9ded22
AD  - Duke University, Durham, NC, United States
AB  - Purpose: To analyze the quality and readability of information regarding shoulder stabilization surgery available using an online AI software (ChatGPT), using standardized scoring systems, as well as to report on the given answers by the AI. Methods: An open AI model (ChatGPT) was used to answer 23 commonly asked questions from patients on shoulder stabilization surgery. These answers were evaluated for medical accuracy, quality, and readability using The JAMA Benchmark criteria, DISCERN score, Flesch-Kincaid Reading Ease Score (FRES) & Grade Level (FKGL). Results: The JAMA Benchmark criteria score was 0, which is the lowest score, indicating no reliable resources cited. The DISCERN score was 60, which is considered a good score. The areas that open AI model did not achieve full marks were also related to the lack of available source material used to compile the answers, and finally some shortcomings with information not fully supported by the literature. The FRES was 26.2, and the FKGL was considered to be that of a college graduate. Conclusion: There was generally high quality in the answers given on questions relating to shoulder stabilization surgery, but there was a high reading level required to comprehend the information presented. However, it is unclear where the answers came from with no source material cited. It is important to note that the ChatGPT software repeatedly references the need to discuss these questions with an orthopaedic surgeon and the importance of shared discussion making, as well as compliance with surgeon treatment recommendations. Clinical Relevance: As shoulder instability is an injury that predominantly affects younger individuals who may use the Internet for information, this study shows what information patients may be getting online. © 2023 Arthroscopy Association of North America
KW  - adult
KW  - article
KW  - artificial intelligence
KW  - clinical article
KW  - clinical significance
KW  - female
KW  - human
KW  - Internet
KW  - language
KW  - male
KW  - orthopedic surgeon
KW  - reading
KW  - shoulder stabilization surgery
KW  - software
KW  - surgery
PB  - W.B. Saunders
SN  - 07498063 (ISSN)
C2  - 37567487
LA  - English
J2  - Arthroscopy J. Arthroscopic Relat. Surg.
M3  - Article
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 2; Correspondence Address: E.T. Hurley; Duke University, 2080 Duke University Road, Durham, 27708, United States; email: eoghan.hurley@duke.edu; CODEN: ARTHE
ER  -

TY  - CONF
AU  - Shakarian, P.
AU  - Koyyalamudi, A.
AU  - Ngu, N.
AU  - Mareedu, L.
TI  - An Independent Evaluation of ChatGPT on MathematicalWord Problems (MWP)
PY  - 2023
T2  - CEUR Workshop Proceedings
VL  - 3433
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85166472786&partnerID=40&md5=5321e97bc705d22c08a61aebdbdb0698
AD  - Arizona State University, 699 S Mill Ave, Tempe, 85281, AZ, United States
AB  - We study the performance of a commercially available large language model (LLM) known as ChatGPT on math word problems (MWPs) from the dataset DRAW-1K. To our knowledge, this is the first independent evaluation of ChatGPT. We found that ChatGPT's performance changes dramatically based on the requirement to show its work, failing 20% of the time when it provides work compared with 84% when it does not. Further several factors about MWPs relating to the number of unknowns and number of operations that lead to a higher probability of failure when compared with the prior, specifically noting (across all experiments) that the probability of failure increases linearly with the number of addition and subtraction operations. We also have released the dataset of ChatGPT's responses to the MWPs to support further work on the characterization of LLM performance and present baseline machine learning models to predict if ChatGPT can correctly answer an MWP. We have released a dataset comprised of ChatGPT's responses to support further research in this area. © 2023 CEUR-WS. All rights reserved.
KW  - ChatGPT
KW  - Large Language Models
KW  - Math Word Problems
KW  - Computational linguistics
KW  - Large dataset
KW  - ChatGPT
KW  - Further works
KW  - High probability
KW  - Language model
KW  - Large language model
KW  - Math word problem
KW  - Modeling performance
KW  - Performance
KW  - Probability of failure
KW  - Word problem
KW  - Failure analysis
A2  - Martin A.
A2  - Fill H.-G.
A2  - Gerber A.
A2  - Hinkelmann K.
A2  - Lenat D.
A2  - Stolle R.
A2  - van Harmelen F.
PB  - CEUR-WS
SN  - 16130073 (ISSN)
LA  - English
J2  - CEUR Workshop Proc.
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 1; Correspondence Address: P. Shakarian; Arizona State University, Tempe, 699 S Mill Ave, 85281, United States; email: pshak02@asu.edu; Conference name: AAAI 2023 Spring Symposium on Challenges Requiring the Combination of Machine Learning and Knowledge Engineering, AAAI-MAKE 2023; Conference date: 27 March 2023 through 29 March 2023; Conference code: 190483
ER  -

TY  - JOUR
AU  - Hsiao, Y.-P.
AU  - Klijn, N.
AU  - Chiu, M.-S.
TI  - Developing a framework to re-design writing assignment assessment for the era of Large Language Models
PY  - 2023
T2  - Learning: Research and Practice
VL  - 9
IS  - 2
SP  - 148
EP  - 158
DO  - 10.1080/23735082.2023.2257234
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85171789268&doi=10.1080%2f23735082.2023.2257234&partnerID=40&md5=e628db9b2350b59eaad54d24750741c0
AD  - Teaching and Learning Center & Tilburg School of Humanities and Digital Sciences, Tilburg University, Tilburg, Netherlands
AD  - Tilburg School of Social and Behavioral Science, Tilburg University, Tilburg, Netherlands
AD  - Department of Education, National Chengchi University, Taipei, Taiwan
KW  - assessment design
KW  - authentic assessment
KW  - critical thinking
KW  - formative assessment
KW  - Large Language Models (LLMs)
PB  - Routledge
SN  - 23735082 (ISSN)
LA  - English
J2  - Learn.
M3  - Article
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 2; Correspondence Address: Y.-P. Hsiao; Teaching and Learning Center & Tilburg School of Humanities and Digital Sciences, Tilburg University, Tilburg, Academia Building Room A406, 5000 LE, Netherlands; email: y.p.hsiao@tilburguniversity.edu
ER  -

TY  - JOUR
AU  - Holmes, J.
AU  - Liu, Z.
AU  - Zhang, L.
AU  - Ding, Y.
AU  - Sio, T.T.
AU  - McGee, L.A.
AU  - Ashman, J.B.
AU  - Li, X.
AU  - Liu, T.
AU  - Shen, J.
AU  - Liu, W.
TI  - Evaluating large language models on a highly-specialized topic, radiation oncology physics
PY  - 2023
T2  - Frontiers in Oncology
VL  - 13
C7  - 1219326
DO  - 10.3389/fonc.2023.1219326
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85166245782&doi=10.3389%2ffonc.2023.1219326&partnerID=40&md5=4672901f534ccf9b5e8ada219112f2c6
AD  - Department of Radiation Oncology, Mayo Clinic, Phoenix, AZ, United States
AD  - School of Computing, The University of Georgia, Athens, GA, United States
AD  - Department of Radiology, Massachusetts General Hospital, Boston, MA, United States
AB  - Purpose: We present the first study to investigate Large Language Models (LLMs) in answering radiation oncology physics questions. Because popular exams like AP Physics, LSAT, and GRE have large test-taker populations and ample test preparation resources in circulation, they may not allow for accurately assessing the true potential of LLMs. This paper proposes evaluating LLMs on a highly-specialized topic, radiation oncology physics, which may be more pertinent to scientific and medical communities in addition to being a valuable benchmark of LLMs. Methods: We developed an exam consisting of 100 radiation oncology physics questions based on our expertise. Four LLMs, ChatGPT (GPT-3.5), ChatGPT (GPT-4), Bard (LaMDA), and BLOOMZ, were evaluated against medical physicists and non-experts. The performance of ChatGPT (GPT-4) was further explored by being asked to explain first, then answer. The deductive reasoning capability of ChatGPT (GPT-4) was evaluated using a novel approach (substituting the correct answer with “None of the above choices is the correct answer.”). A majority vote analysis was used to approximate how well each group could score when working together. Results: ChatGPT GPT-4 outperformed all other LLMs and medical physicists, on average, with improved accuracy when prompted to explain before answering. ChatGPT (GPT-3.5 and GPT-4) showed a high level of consistency in its answer choices across a number of trials, whether correct or incorrect, a characteristic that was not observed in the human test groups or Bard (LaMDA). In evaluating deductive reasoning ability, ChatGPT (GPT-4) demonstrated surprising accuracy, suggesting the potential presence of an emergent ability. Finally, although ChatGPT (GPT-4) performed well overall, its intrinsic properties did not allow for further improvement when scoring based on a majority vote across trials. In contrast, a team of medical physicists were able to greatly outperform ChatGPT (GPT-4) using a majority vote. Conclusion: This study suggests a great potential for LLMs to work alongside radiation oncology experts as highly knowledgeable assistants. Copyright © 2023 Holmes, Liu, Zhang, Ding, Sio, McGee, Ashman, Li, Liu, Shen and Liu.
KW  - artificial intelligence
KW  - ChatGPT
KW  - large language model
KW  - medical physics
KW  - natural language processing
KW  - article
KW  - artificial intelligence
KW  - deductive reasoning
KW  - human
KW  - human experiment
KW  - medical physicist
KW  - natural language processing
KW  - physics
KW  - radiation oncology
PB  - Frontiers Media SA
SN  - 2234943X (ISSN)
LA  - English
J2  - Front. Oncol.
M3  - Article
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 7; Correspondence Address: J. Shen; Department of Radiation Oncology, Mayo Clinic, Phoenix, United States; email: shen.jiajian@mayo.edu; W. Liu; Department of Radiation Oncology, Mayo Clinic, Phoenix, United States; email: liu.wei@mayo.edu
ER  -

TY  - CONF
AU  - Jousselme, A.-L.
AU  - De Villiers, J.P.
AU  - De Freitas, A.
AU  - Blasch, E.
AU  - Dragos, V.
AU  - Pavlin, G.
AU  - Costa, P.C.
AU  - Laskey, K.B.
AU  - Laudy, C.
TI  - Uncertain about ChatGPT: enabling the uncertainty evaluation of large language models
PY  - 2023
T2  - 2023 26th International Conference on Information Fusion, FUSION 2023
DO  - 10.23919/FUSION52260.2023.10224086
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85171522315&doi=10.23919%2fFUSION52260.2023.10224086&partnerID=40&md5=12ea9c6df3ce53d90e1ad93d8b658e82
AD  - Cs Group, La Garde, France
AD  - University of Pretoria, Pretoria, South Africa
AD  - Air Force Research Lab, Rome, NY, United States
AD  - ONERA-The French Aerospace Lab, Palaiseau, France
AD  - D-CIS Lab, Thales Research and Technology, Delft, Netherlands
AD  - George Mason University, Fairfax, VA, United States
AD  - Thales, Palaiseau, France
AB  - ChatGPT, OpenAI's chatbot, has gained consider-able attention since its launch in November 2022, owing to its ability to formulate articulated responses to text queries and comments relating to seemingly any conceivable subject. As impressive as the majority of interactions with ChatGPT are, this large language model has a number of acknowledged shortcomings, which in several cases, may be directly related to how ChatGPT handles uncertainty. The objective of this paper is to pave the way to formal analysis of ChatGPT uncertainty handling. To this end, the ability of the Uncertainty Representation and Reasoning Framework (URREF) ontology is assessed, to support such analysis. Elements of structured experiments for reproducible results are identified. The dataset built varies Information Criteria of Correctness, Non-specificity, Self-confidence, Relevance and Inconsistency, and the Source Criteria of Reliability, Competency and Type. ChatGPT's answers are analyzed along Information Criteria of Correctness, Non-specificity and Self-confidence. Both generic and singular information are sequentially provided. The outcome of this preliminary study is twofold: Firstly, we validate that the experimental setup is efficient in capturing aspects of ChatGPT uncertainty handling. Secondly, we identify possible modifications to the URREF ontology that will be discussed and eventually implemented in URREF ontology Version 4.0 under development.  © 2023 International Society of Information Fusion.
KW  - Information quality
KW  - Large Language Models
KW  - NLP
KW  - Ontology
KW  - Source quality
KW  - Uncertainty evaluation
KW  - Computational linguistics
KW  - Quality control
KW  - Uncertainty analysis
KW  - Information quality
KW  - Language model
KW  - Large language model
KW  - Ontology's
KW  - Reasoning framework
KW  - Source quality
KW  - Uncertainty evaluation
KW  - Uncertainty handling
KW  - Uncertainty reasoning
KW  - Uncertainty representation
KW  - Ontology
PB  - Institute of Electrical and Electronics Engineers Inc.
SN  - 979-889034485-4 (ISBN)
LA  - English
J2  - Int. Conf. Inf. Fusion, FUSION
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 0; Correspondence Address: A.-L. Jousselme; Cs Group, La Garde, France; email: anne-laure.jousselme@csgroup.eu; Conference name: 26th International Conference on Information Fusion, FUSION 2023; Conference date: 27 June 2023 through 30 June 2023; Conference code: 192045
ER  -

TY  - JOUR
AU  - Huang, Y.
AU  - Gomaa, A.
AU  - Semrau, S.
AU  - Haderlein, M.
AU  - Lettmaier, S.
AU  - Weissmann, T.
AU  - Grigo, J.
AU  - Tkhayat, H.B.
AU  - Frey, B.
AU  - Gaipl, U.
AU  - Distel, L.
AU  - Maier, A.
AU  - Fietkau, R.
AU  - Bert, C.
AU  - Putz, F.
TI  - Benchmarking ChatGPT-4 on a radiation oncology in-training exam and Red Journal Gray Zone cases: potentials and challenges for ai-assisted medical education and decision making in radiation oncology
PY  - 2023
T2  - Frontiers in Oncology
VL  - 13
C7  - 1265024
DO  - 10.3389/fonc.2023.1265024
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85173018162&doi=10.3389%2ffonc.2023.1265024&partnerID=40&md5=ae7eccb7830f3009d2be3687cddeaaad
AD  - Department of Radiation Oncology, University Hospital Erlangen, Friedrich-Alexander-Universität Erlangen-Nürnberg, Erlangen, Germany
AD  - Comprehensive Cancer Center Erlangen-EMN (CCC ER-EMN), Erlangen, Germany
AD  - Pattern Recognition Lab, Friedrich-Alexander-Universität Erlangen-Nürnberg, Erlangen, Germany
AB  - Purpose: The potential of large language models in medicine for education and decision-making purposes has been demonstrated as they have achieved decent scores on medical exams such as the United States Medical Licensing Exam (USMLE) and the MedQA exam. This work aims to evaluate the performance of ChatGPT-4 in the specialized field of radiation oncology. Methods: The 38th American College of Radiology (ACR) radiation oncology in-training (TXIT) exam and the 2022 Red Journal Gray Zone cases are used to benchmark the performance of ChatGPT-4. The TXIT exam contains 300 questions covering various topics of radiation oncology. The 2022 Gray Zone collection contains 15 complex clinical cases. Results: For the TXIT exam, ChatGPT-3.5 and ChatGPT-4 have achieved the scores of 62.05% and 78.77%, respectively, highlighting the advantage of the latest ChatGPT-4 model. Based on the TXIT exam, ChatGPT-4’s strong and weak areas in radiation oncology are identified to some extent. Specifically, ChatGPT-4 demonstrates better knowledge of statistics, CNS & eye, pediatrics, biology, and physics than knowledge of bone & soft tissue and gynecology, as per the ACR knowledge domain. Regarding clinical care paths, ChatGPT-4 performs better in diagnosis, prognosis, and toxicity than brachytherapy and dosimetry. It lacks proficiency in in-depth details of clinical trials. For the Gray Zone cases, ChatGPT-4 is able to suggest a personalized treatment approach to each case with high correctness and comprehensiveness. Importantly, it provides novel treatment aspects for many cases, which are not suggested by any human experts. Conclusion: Both evaluations demonstrate the potential of ChatGPT-4 in medical education for the general public and cancer patients, as well as the potential to aid clinical decision-making, while acknowledging its limitations in certain domains. Owing to the risk of hallucinations, it is essential to verify the content generated by models such as ChatGPT for accuracy. Copyright © 2023 Huang, Gomaa, Semrau, Haderlein, Lettmaier, Weissmann, Grigo, Tkhayat, Frey, Gaipl, Distel, Maier, Fietkau, Bert and Putz.
KW  - artificial intelligence
KW  - clinical decision support (CDS)
KW  - Gray Zone
KW  - large language model
KW  - natural language processing
KW  - radiotherapy
KW  - accuracy
KW  - Article
KW  - artificial intelligence
KW  - benchmarking
KW  - brachytherapy
KW  - cancer prognosis
KW  - cancer survival
KW  - ChatGPT
KW  - clinical decision making
KW  - clinical decision support system
KW  - dosimetry
KW  - human
KW  - medical education
KW  - natural language processing
KW  - radiation oncology
KW  - recurrence risk
KW  - self evaluation
KW  - toxicity
KW  - treatment planning
PB  - Frontiers Media SA
SN  - 2234943X (ISSN)
LA  - English
J2  - Front. Oncol.
M3  - Article
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 1; Correspondence Address: F. Putz; Department of Radiation Oncology, University Hospital Erlangen, Friedrich-Alexander-Universität Erlangen-Nürnberg, Erlangen, Germany; email: Florian.Putz@uk-erlangen.de
ER  -

TY  - CONF
AU  - Gowriraj, S.
AU  - Tiwari, S.D.
AU  - Potnis, M.
AU  - Bansal, S.
AU  - Mitamura, T.
AU  - Nyberg, E.
TI  - Language-Agnostic Transformers and Assessing ChatGPT-Based Query Rewriting for Multilingual Document-Grounded QA
PY  - 2023
T2  - Proceedings of the Annual Meeting of the Association for Computational Linguistics
SP  - 101
EP  - 108
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85172273486&partnerID=40&md5=a6ffcac217168b152667410cef49fe7b
AD  - Language Technologies Institute, Carnegie Mellon University, United States
AB  - The DialDoc 2023 shared task has expanded the document-grounded dialogue task to encompass multiple languages, despite having limited annotated data. This paper assesses the effectiveness of both language-agnostic and language-aware paradigms for multilingual pre-trained transformer models in a bi-encoder-based dense passage retriever (DPR), concluding that the language-agnostic approach is superior. Additionally, the study investigates the impact of query rewriting techniques using large language models, such as ChatGPT, on multilingual, document-grounded question-answering systems. The experiments conducted demonstrate that, for the examples examined, query rewriting does not enhance performance compared to the original queries. This failure is due to topic switching in final dialogue turns and irrelevant topics being considered for query rewriting. © 2023 Association for Computational Linguistics.
KW  - Natural language processing systems
KW  - Language model
KW  - Multilingual documents
KW  - Multiple languages
KW  - Performance
KW  - Query rewriting techniques
KW  - Query rewritings
KW  - Question answering systems
KW  - Transformer modeling
KW  - Computational linguistics
A2  - Muresan S.
A2  - Chen V.
A2  - Kennington C.
A2  - Vandyke D.
A2  - Dethlefs N.
A2  - Inoue K.
A2  - Ekstedt E.
A2  - Ultes S.
PB  - Association for Computational Linguistics (ACL)
SN  - 0736587X (ISSN); 978-195942998-2 (ISBN)
LA  - English
J2  - Proc. Annu. Meet. Assoc. Comput Linguist.
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 0; Conference name: 3rd Workshop on Document-grounded Dialogue and Conversational Question Answering, DialDoc 2023, co-located with ACL 2023; Conference code: 193147
ER  -

TY  - JOUR
AU  - Caneva, G.
AU  - Calcagno, S.
AU  - Giordano, D.
TI  - SOCRATIC ARTIFICIAL MIND (SAM); Lessons from the evaluation of a GPT-3 based chatbot for Socratic dialogue
PY  - 2023
T2  - Sistemi Intelligenti
VL  - 35
IS  - 2
SP  - 413
EP  - 434
DO  - 10.1422/108138
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85172984582&doi=10.1422%2f108138&partnerID=40&md5=a3bf31de4589793b914ef48bce6d7a80
AD  - Department of Electrical, Electronics and Computer Engineering, University of Catania, Via Santa Sofia 64, Catania, 95123, Italy
AB  - This contribution describes the design and evaluation of SAM, a GPT3-based chatbot trained to hold conversations using Socratic dialogue rules. The system was tested by twenty users and two types of analysis were carried out, one from the user’s point of view, the other from a technical point of view, to verify compliance with the principles of the Socratic dialogue. The results show a satisfactory performance concerning the non-violation of the basic tenets of the approach and a highly positive user experience, especially regarding the perceived understanding abilities and competence of SAM and its effect on provoking reflection. © (2023). All Rights Reserved.
KW  - evaluation
KW  - fine-tuning
KW  - GPT-3
KW  - socratic dialogue
KW  - user experience
PB  - Societa Editrice Il Mulino
SN  - 11209550 (ISSN)
LA  - English
J2  - Sist. Intelligenti
M3  - Article
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 0
ER  -

TY  - JOUR
AU  - Netto, N.R.
TI  - Use of case studies in social work assessments–ChatGPT’s kryptonite?
PY  - 2023
T2  - Social Work Education
DO  - 10.1080/02615479.2023.2266461
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85174036347&doi=10.1080%2f02615479.2023.2266461&partnerID=40&md5=771ea3022acc6658219cabf4df939302
AD  - SR Nathan School of Human Development, Singapore University of Social Sciences, Singapore, Singapore
AB  - The launch of ChatGPT sent ripples across higher education, particularly in attempts to detect its use by students using it to complete assignments. This paper reflects on the past semester of ‘life with ChatGPT’, starting with a narrative of current practices in assessment writing at the Singapore University of Social Sciences, before embarking on a test of the response generated by ChatGPT in answering a case study-based exam question. Taken together with the author’s experiences grading assignments that had been at least partially generated by artificial intelligence (AI) but not known at that time, it is surmised that case studies tend not to lend themselves well to having good-quality responses being generated by AI tools such as ChatGPT, at this current stage of their development. However, implications for assessment writing involving case studies include the need for sufficient details, both essential and peripheral, so that students have to ‘separate the wheat from the chaff’, and decipher how best to apply the concepts being examined based on the unique circumstances of the case scenario. At this point in time, the use of complex, detailed, and well-written case studies in assessment questions appears to be ChatGPT’s kryptonite and could ensure authentic assessments. © 2023 Informa UK Limited, trading as Taylor & Francis Group.
KW  - artificial intelligence
KW  - assessment writing
KW  - Authentic assessment
KW  - case studies
KW  - ChatGPT
KW  - higher education
PB  - Routledge
SN  - 02615479 (ISSN)
LA  - English
J2  - Soc. Work Educ.
M3  - Article
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 0; Correspondence Address: N.R. Netto; SR Nathan School of Human Development, Singapore University of Social Sciences, Singapore, 463 Clementi Road, 599494, Singapore; email: nicholasrn@suss.edu.sg
ER  -

TY  - CONF
AU  - Truong, T.H.
AU  - Baldwin, T.
AU  - Verspoor, K.
AU  - Cohn, T.
TI  - Language models are not naysayers: An analysis of language models on negation benchmarks
PY  - 2023
T2  - Proceedings of the Annual Meeting of the Association for Computational Linguistics
SP  - 101
EP  - 114
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85172337550&partnerID=40&md5=afcfb7618579579cb2d6d1e71553a94d
AD  - University of Melbourne, Australia
AD  - RMIT University, Australia
AD  - MBZUAI, United Arab Emirates
AB  - Negation has been shown to be a major bottleneck for masked language models, such as BERT. However, whether this finding still holds for larger-sized auto-regressive language models ("LLMs") has not been studied comprehensively. With the ever-increasing volume of research and applications of LLMs, we take a step back to evaluate the ability of currentgeneration LLMs to handle negation, a fundamental linguistic phenomenon that is central to language understanding. We evaluate different LLMs - including the open-source GPTneo, GPT-3, and InstructGPT - against a wide range of negation benchmarks. Through systematic experimentation with varying model sizes and prompts, we show that LLMs have several limitations including insensitivity to the presence of negation, an inability to capture the lexical semantics of negation, and a failure to reason under negation. © 2023 Association for Computational Linguistics.
KW  - Semantics
KW  - Auto-regressive
KW  - Language model
KW  - Language understanding
KW  - Large-sized
KW  - Linguistic phenomena
KW  - Model size
KW  - Open-source
KW  - Research and application
KW  - Systematic experimentation
KW  - Varying models
KW  - Computational linguistics
A2  - Palmer A.
A2  - Camacho-Collados J.
PB  - Association for Computational Linguistics (ACL)
SN  - 0736587X (ISSN); 978-195942976-0 (ISBN)
LA  - English
J2  - Proc. Annu. Meet. Assoc. Comput Linguist.
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 1; Conference name: 12th Joint Conference on Lexical and Computational Semantics, StarSEM 2023, co-located with ACL 2023; Conference date: 13 July 2023 through 14 July 2023; Conference code: 193197
ER  -

TY  - JOUR
AU  - Caglar, U.
AU  - Yildiz, O.
AU  - Meric, A.
AU  - Ayranci, A.
AU  - Gelmis, M.
AU  - Sarilar, O.
AU  - Ozgor, F.
TI  - Evaluating the performance of ChatGPT in answering questions related to pediatric urology
PY  - 2023
T2  - Journal of Pediatric Urology
DO  - 10.1016/j.jpurol.2023.08.003
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85168457180&doi=10.1016%2fj.jpurol.2023.08.003&partnerID=40&md5=01d54c78395d5bd3d2cca912c4bdbcfb
AD  - Department of Urology, Haseki Training and Research Hospital, Istanbul, Turkey
AB  - Introduction: Artificial intelligence is advancing in various domains, including medicine, and its progress is expected to continue in the future. Objective: This research aimed to assess the precision and consistency of ChatGPT's responses to commonly asked inquiries related to pediatric urology. Materials and methods: We examined commonly posed inquiries regarding pediatric urology found on urology association websites, hospitals, and social media platforms. Additionally, we referenced the recommendations tables in the European Urology Association's (EAU) 2022 Guidelines on Pediatric Urology, which contained robust data at the strong recommendation level. All questions were systematically presented to ChatGPT's May 23 Version, and two expert urologists independently assessed and assigned scores ranging from 1 to 4 to each response. Results: A hundred thirty seven questions about pediatric urology were included in the study. The answers to questions resulted in 92.0% completely correct. The completely correct rate in the questions prepared according to the strong recommendations of the EAU guideline was 93.6%. No question was answered completely wrong. The similarity rates of the answers to the repeated questions were between 93.8% and 100%. Conclusion: ChatGPT has provided satisfactory responses to inquiries related to pediatric urology. Despite its limitations, it is foreseeable that this continuously evolving platform will occupy a crucial position in the healthcare industry. [Table presented] © 2023 Journal of Pediatric Urology Company
KW  - Artificial intelligence
KW  - Health literacy
KW  - Patient knowledge
KW  - Pediatric urology
KW  - article
KW  - artificial intelligence
KW  - child
KW  - child urology
KW  - health care industry
KW  - health literacy
KW  - human
KW  - practice guideline
KW  - social media
KW  - urologist
PB  - Elsevier Ltd
SN  - 14775131 (ISSN)
C2  - 37596194
LA  - English
J2  - J. Pediatr. Urol.
M3  - Article
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 3; Correspondence Address: U. Caglar; Ugur Mumcu Mahallesi, Belediye Sokak, Istanbul, No:7 Sultangazi, Turkey; email: ufukcglr@gmail.com
ER  -

TY  - JOUR
AU  - Mahat, R.K.
AU  - Jantikar, A.M.
AU  - Rathore, V.
AU  - Panda, S.
TI  - Assessing the performance of ChatGPT to solve biochemistry question papers of university examination
PY  - 2023
T2  - Advances in Physiology Education
VL  - 47
IS  - 3
SP  - 528
EP  - 529
DO  - 10.1152/ADVAN.00076.2023
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85165518023&doi=10.1152%2fADVAN.00076.2023&partnerID=40&md5=f62912a8961a23d4a8018a7e1bc17761
AD  - Department of Biochemistry, Dharanidhar Medical College and Hospital, Keonjhar, India
AD  - Department of Biochemistry, American International Institute of Medical Sciences, Udaipur, India
AD  - Department of Biochemistry, Shyam Shah Medical College, Rewa, India
KW  - Humans
KW  - Universities
KW  - human
KW  - university
PB  - American Physiological Society
SN  - 10434046 (ISSN)
C2  - 37318998
LA  - English
J2  - Adv. Physiol. Educ.
M3  - Editorial
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 0; Correspondence Address: R.K. Mahat; Department of Biochemistry, Dharanidhar Medical College and Hospital, Keonjhar, India; email: mahatroshan79@gmail.com; CODEN: APEDF
ER  -

TY  - CONF
AU  - Efrat, A.
AU  - Honovich, O.
AU  - Levy, O.
TI  - LMentry: A Language Model Benchmark of Elementary Language Tasks
PY  - 2023
T2  - Proceedings of the Annual Meeting of the Association for Computational Linguistics
SP  - 10476
EP  - 10501
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85173716232&partnerID=40&md5=ba15192a88d3ca1bdca49953b962ebb4
AD  - Tel Aviv University, Israel
AD  - Meta AI, United States
AB  - As the performance of large language models rapidly improves, benchmarks are getting larger and more complex as well. We present LMentry, a benchmark that avoids this “arms race” by focusing on a compact set of tasks that are trivial to humans, e.g. writing a sentence containing a specific word, identifying which words in a list belong to a specific category, or choosing which of two words is longer. LMentry is specifically designed to provide quick and interpretable insights into the capabilities and robustness of large language models. Our experiments reveal a wide variety of failure cases that, while immediately obvious to humans, pose a considerable challenge for large language models, including OpenAI's latest 175B-parameter instruction-tuned model, TextDavinci002. LMentry complements contemporary evaluation approaches of large language models, providing a quick, automatic, and easy-to-run “unit test”, without resorting to large benchmark suites of complex tasks. © 2023 Association for Computational Linguistics.
KW  - Computational linguistics
KW  - Benchmark suites
KW  - Compact sets
KW  - Complex task
KW  - Evaluation approach
KW  - Human pose
KW  - Language model
KW  - Performance
KW  - Unit tests
KW  - Benchmarking
PB  - Association for Computational Linguistics (ACL)
SN  - 0736587X (ISSN); 978-195942962-3 (ISBN)
LA  - English
J2  - Proc. Annu. Meet. Assoc. Comput Linguist.
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 0; Conference name: 61st Annual Meeting of the Association for Computational Linguistics, ACL 2023; Conference date: 9 July 2023 through 14 July 2023; Conference code: 192867
ER  -

TY  - JOUR
AU  - Ma, X.
AU  - Gao, L.
TI  - Evaluating Transformer Models and Human Behaviors on Chinese Character Naming
PY  - 2023
T2  - Transactions of the Association for Computational Linguistics
VL  - 11
SP  - 755
EP  - 770
DO  - 10.1162/tacl_a_00573
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85168985847&doi=10.1162%2ftacl_a_00573&partnerID=40&md5=03f8e8093f21990931b54fcbf5141889
AD  - The Graduate Center, CUNY, New York, United States
AD  - Toyota Technological Institute, Chicago, Chicago, United States
AB  - Neural network models have been proposed to explain the grapheme-phoneme mapping pro¬cess in humans for many alphabet languages. These models not only successfully learned the correspondence of the letter strings and their pronunciation, but also captured human behav¬ior in nonce word naming tasks. How would the neural models perform for a non-alphabet language (e.g., Chinese) unknown character task? How well would the model capture hu¬man behavior? In this study, we first collect human speakers’ answers on unknown Char¬acter naming tasks and then evaluate a set of transformer models by comparing their performance with human behaviors on an un¬known Chinese character naming task. We found that the models and humans behaved very similarly, that they had similar accuracy distribution for each character, and had a sub¬stantial overlap in answers. In addition, the models’ answers are highly correlated with humans’ answers. These results suggested that the transformer models can capture humans’ character naming behavior well. © 2023 Association for Computational Linguistics.
PB  - MIT Press Journals
SN  - 2307387X (ISSN)
LA  - English
J2  - Trans. Assoc. Comput. Linguist.
M3  - Article
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 0
ER  -

TY  - JOUR
AU  - Elyoseph, Z.
AU  - Levkovich, I.
TI  - Beyond human expertise: the promise and limitations of ChatGPT in suicide risk assessment
PY  - 2023
T2  - Frontiers in Psychiatry
VL  - 14
C7  - 1213141
DO  - 10.3389/fpsyt.2023.1213141
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85168106197&doi=10.3389%2ffpsyt.2023.1213141&partnerID=40&md5=c2c250b53f3dd3af96ba4ffcbd369cbb
AD  - Department of Psychology and Educational Counseling, The Center for Psychobiological Research, Max Stern Yezreel Valley College, Emek Yezreel, Israel
AD  - Department of Brain Sciences, Faculty of Medicine, Imperial College London, London, United Kingdom
AD  - Faculty of Graduate Studies, Oranim Academic College, Kiryat Tiv'on, Israel
AB  - ChatGPT, an artificial intelligence language model developed by OpenAI, holds the potential for contributing to the field of mental health. Nevertheless, although ChatGPT theoretically shows promise, its clinical abilities in suicide prevention, a significant mental health concern, have yet to be demonstrated. To address this knowledge gap, this study aims to compare ChatGPT’s assessments of mental health indicators to those of mental health professionals in a hypothetical case study that focuses on suicide risk assessment. Specifically, ChatGPT was asked to evaluate a text vignette describing a hypothetical patient with varying levels of perceived burdensomeness and thwarted belongingness. The ChatGPT assessments were compared to the norms of mental health professionals. The results indicated that ChatGPT rated the risk of suicide attempts lower than did the mental health professionals in all conditions. Furthermore, ChatGPT rated mental resilience lower than the norms in most conditions. These results imply that gatekeepers, patients or even mental health professionals who rely on ChatGPT for evaluating suicidal risk or as a complementary tool to improve decision-making may receive an inaccurate assessment that underestimates the actual suicide risk. Copyright © 2023 Elyoseph and Levkovich.
KW  - artificial intelligence
KW  - ChatGPT
KW  - diagnosis
KW  - psychological assessment
KW  - risk assessment
KW  - suicide risk
KW  - text vignette
KW  - Article
KW  - ChatGPT
KW  - clinical evaluation
KW  - decision making
KW  - human
KW  - mental health
KW  - psychologic assessment
KW  - psychological resilience
KW  - risk assessment
KW  - scoring system
KW  - suicidal ideation
KW  - suicide
PB  - Frontiers Media SA
SN  - 16640640 (ISSN)
LA  - English
J2  - Front. Psychiatry
M3  - Article
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 7; Correspondence Address: Z. Elyoseph; Department of Psychology and Educational Counseling, The Center for Psychobiological Research, Max Stern Yezreel Valley College, Emek Yezreel, Israel; email: zohare@yvc.ac.il
ER  -

TY  - CONF
AU  - He, G.
TI  - Construction and Experimental Evaluation of Document Causality Extraction Model Based on CGCN-BERT
PY  - 2023
T2  - International Conference on Applied Intelligence and Sustainable Computing, ICAISC 2023
DO  - 10.1109/ICAISC58445.2023.10200466
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85168769191&doi=10.1109%2fICAISC58445.2023.10200466&partnerID=40&md5=a013382460d47e4cb058eb40c8955922
AD  - Software Engineering Institute of Guangzhou, Guangdong, Guangzhou, China
AB  - With the increasing degree of networking, the amount of document data also increases. The document causality extraction method is a new data regression analysis technology. In this paper, the Central Graph Convolutional Networks-Bidirectional Encoder Representation from Transformers (CGCN-BERT) text classifier was used to label and filter keywords. This approach can make it easy to extract and judge the causal relationship of documents. Therefore, this paper explored the construction method of document extraction model under this model. This paper mainly used the methods of statistical analysis and experimental comparison to study the document relationship extraction model of CGCN-BERT. The experimental data showed that in the three document tests, the average recall rate was 86.57%, but its accuracy was as low as 67.77%, and the relationship value G was 78.63%. Therefore, the relationship extraction model designed in this paper has some room for improvement. © 2023 IEEE.
KW  - BERT model
KW  - causality
KW  - CGCN algorithm
KW  - document analysis
KW  - extraction model
KW  - Extraction
KW  - BERT model
KW  - Causality
KW  - CGCN algorithm
KW  - Convolutional networks
KW  - Documents analysis
KW  - Experimental evaluation
KW  - Extraction method
KW  - Extraction modeling
KW  - Model-based OPC
KW  - Relationship extraction
KW  - Regression analysis
PB  - Institute of Electrical and Electronics Engineers Inc.
SN  - 979-835032379-5 (ISBN)
LA  - English
J2  - Int. Conf. Appl. Intell. Sustain. Comput., ICAISC
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 0; Correspondence Address: G. He; Software Engineering Institute of Guangzhou, Guangzhou, Guangdong, China; email: 447591035@qq.com; Conference name: 1st IEEE International Conference on Applied Intelligence and Sustainable Computing, ICAISC 2023; Conference date: 16 June 2023 through 17 June 2023; Conference code: 191485
ER  -

TY  - CONF
AU  - Turhan, G.D.
TI  - Life Cycle Assessment for the Unconventional Construction Materials in Collaboration with a Large Language Model
PY  - 2023
T2  - Proceedings of the International Conference on Education and Research in Computer Aided Architectural Design in Europe
VL  - 2
SP  - 39
EP  - 48
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85172457872&partnerID=40&md5=a14e6ff8bb3dcb8d885c4c2974803e97
AD  - Izmir University of Economics, Turkey
AB  - In this paper, developing an online tool for the Life Cycle Assessment (LCA) of unconventional construction materials in collaboration with Large Language Models (LLMs) is proposed. The LCA provides information on the environmental impact of a product throughout its entire life cycle, from the extraction of raw materials to disposal or recycling. The LLMs are neural network architectures, typically utilizing variants of recurrent neural networks such as the transformer, which are trained on large bodies of textual data using techniques such as pre-training and fine-tuning. This study focuses on the use of bacterial cellulose composites as a biobased unconventional construction material. The methodology of developing an LLM-aided LCA tool is divided into five stages: Defining the functional unit; identifying the life cycle stages; collecting environmental and social impact data; interpreting and evaluating; developing a web-based tool. The results of this study have shown that the designers can incorporate sustainable thinking in the design process by using LLMs integrated to LCA, ultimately contributing to a more sustainable future against the impacts of the Anthropocene. Overall, the outcomes demonstrated the value of human-computer interaction (HCI) as a tool for exploring new possibilities with biobased materials and for inspiring designers to reconsider the material evaluation in their work. Future studies can delve into the integration of this tool into building information modeling software or computational design software in order to perform LCA for 3D structures. Different scales of such applications in design practices, such as fashion design, product design or service design can also be conducted by questioning how LCA can be combined with LLMs to leverage novel sustainable design solutions. © 2023, Education and research in Computer Aided Architectural Design in Europe. All rights reserved.
KW  - Human-computer Interaction (HCI)
KW  - Large Language Models (LLMs)
KW  - Life Cycle Assessment (LCA)
KW  - Machine Learning (ML)
A2  - Dokonal W.
A2  - Hirschberg U.
A2  - Wurzer G.
A2  - Wurzer G.
PB  - Education and research in Computer Aided Architectural Design in Europe
SN  - 26841843 (ISSN); 978-949120735-8 (ISBN)
LA  - English
J2  - Proc. Int. Conf. Educ. Res. Comput. Aided. Archit. Des. Eur.
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 0; Correspondence Address: G.D. Turhan; Izmir University of Economics, Turkey; email: gozde.turhan@ieu.edu.tr; Conference name: 41st Conference on Education and Research in Computer Aided Architectural Design in Europe, eCAADe 2023; Conference date: 20 September 2023 through 22 September 2023; Conference code: 300449
ER  -

TY  - CONF
AU  - Joshi, A.
AU  - Kajale, A.
AU  - Gadre, J.
AU  - Deode, S.
AU  - Joshi, R.
TI  - L3Cube-MahaSBERT and HindSBERT: Sentence BERT Models and Benchmarking BERT Sentence Representations for Hindi and Marathi
PY  - 2023
T2  - Lecture Notes in Networks and Systems
VL  - 739 LNNS
SP  - 1184
EP  - 1199
DO  - 10.1007/978-3-031-37963-5_82
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85172237699&doi=10.1007%2f978-3-031-37963-5_82&partnerID=40&md5=2e198ae778e1d171d1bb3b0136b3b8c4
AD  - MKSSS’ Cummins College of Engineering for Women, Maharashtra, Pune, India
AD  - Indian Institute of Technology Madras, Chennai, India
AD  - L3Cube, Pune, India
AB  - Sentence representation from vanilla BERT models does not work well on sentence similarity tasks. Sentence-BERT models specifically trained on STS or NLI datasets are shown to provide state-of-the-art performance. However, building these models for low-resource languages is not straightforward due to the lack of these specialized datasets. This work focuses on two low-resource Indian languages, Hindi and Marathi. We train sentence-BERT models for these languages using synthetic NLI and STS datasets prepared using machine translation. We show that the strategy of NLI pre-training followed by STSb fine-tuning is effective in generating high-performance sentence-similarity models for Hindi and Marathi. The vanilla BERT models trained using this simple strategy outperform the multilingual LaBSE trained using a complex training strategy. These models are evaluated on downstream text classification and similarity tasks. We evaluate these models on real text classification datasets to show embeddings obtained from synthetic data training are generalizable to real datasets as well and thus represent an effective training strategy for low-resource languages. We also provide a comparative analysis of sentence embeddings from fast text models, multilingual BERT models (mBERT, IndicBERT, xlm-RoBERTa, MuRIL), multilingual sentence embedding models (LASER, LaBSE), and monolingual BERT models based on L3Cube-MahaBERT and HindBERT. We release L3Cube-MahaSBERT and HindSBERT, the state-of-the-art sentence-BERT models for Marathi and Hindi respectively. Our work also serves as a guide to building low-resource sentence embedding models. © 2023, The Author(s), under exclusive license to Springer Nature Switzerland AG.
KW  - Hindi Sentence Representations
KW  - Indian Regional Languages
KW  - Low Resource Languages
KW  - Marathi Sentence Representations
KW  - Natural Language Processing
KW  - Sentence-BERT
KW  - Sentiment Analysis
KW  - Text Classification
KW  - Classification (of information)
KW  - Embeddings
KW  - Hindi sentence representation
KW  - Indian regional language
KW  - Language processing
KW  - Low resource languages
KW  - Marathi sentence representation
KW  - Natural language processing
KW  - Natural languages
KW  - Sentence-BERT
KW  - Sentiment analysis
KW  - Text classification
KW  - Sentiment analysis
A2  - Arai K.
PB  - Springer Science and Business Media Deutschland GmbH
SN  - 23673370 (ISSN); 978-303137962-8 (ISBN)
LA  - English
J2  - Lect. Notes Networks Syst.
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 0; Correspondence Address: A. Joshi; MKSSS’ Cummins College of Engineering for Women, Pune, Maharashtra, India; email: joshiananya20@gmail.com; Conference name: Proceedings of the Computing Conference 2023; Conference date: 22 June 2023 through 23 June 2023; Conference code: 301079
ER  -

TY  - CONF
AU  - Lin, Y.-T.
AU  - Chen, Y.-N.
TI  - LLM-EVAL: Unified Multi-Dimensional Automatic Evaluation for Open-Domain Conversations with Large Language Models
PY  - 2023
T2  - Proceedings of the Annual Meeting of the Association for Computational Linguistics
SP  - 47
EP  - 58
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85173708698&partnerID=40&md5=08a25820ee9069ab6d8dc0379723d373
AD  - National Taiwan University, Taipei, Taiwan
AB  - We propose LLM-EVAL, a unified multidimensional automatic evaluation method for open-domain conversations with large language models (LLMs). Existing evaluation methods often rely on human annotations, ground-truth responses, or multiple LLM prompts, which can be expensive and time-consuming. To address these issues, we design a single prompt-based evaluation method that leverages a unified evaluation schema to cover multiple dimensions of conversation quality in a single model call. We extensively evaluate the performance of LLM-EVAL on various benchmark datasets, demonstrating its effectiveness, efficiency, and adaptability compared to state-of-the-art evaluation methods. Our analysis also highlights the importance of choosing suitable LLMs and decoding strategies for accurate evaluation results. LLM-EVAL offers a versatile and robust solution for evaluating open-domain conversation systems, streamlining the evaluation process and providing consistent performance across diverse scenarios. © 2023 Association for Computational Linguistics.
KW  - Computational linguistics
KW  - Quality control
KW  - Automatic evaluation
KW  - Benchmark datasets
KW  - Evaluation methods
KW  - Ground truth
KW  - Human annotations
KW  - Language model
KW  - Multi dimensional
KW  - Multiple dimensions
KW  - Performance
KW  - Single models
KW  - Benchmarking
A2  - Chen Y.-N.
A2  - Rastogi A.
PB  - Association for Computational Linguistics (ACL)
SN  - 0736587X (ISSN); 978-195942997-5 (ISBN)
LA  - English
J2  - Proc. Annu. Meet. Assoc. Comput Linguist.
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 0; Conference name: 5th Workshop on NLP for Conversational AI, NLP4ConvAI 2023, co-located with ACL 2023; Conference code: 193161
ER  -

TY  - CONF
AU  - Ghapanchi, A.H.
AU  - Purarjomandlangrudi, A.
TI  - ChatGPT and Generative AIs: What It Means for Academic Assessments
PY  - 2023
T2  - Proceedings of the Information Systems Education Conference, ISECON
VL  - 2023-March
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85173055060&partnerID=40&md5=da614bd4630a0beb02feac17935d9015
AD  - College of Sport, Health and Engineering, Victoria University, Melbourne, Australia
AD  - The Institute for Sustainable Industries and Liveable Cities, Victoria University, Melbourne, Australia
AD  - College of Arts, Business, Law, Education and IT, Victoria University, Melbourne, Australia
AB  - Generative Artificial Intelligence (GAI) is a subfield of AI that involves generating machines or algorithms that allow creating new and original content. GAI is receiving huge popularity with Open AI making ChatGPT available to the public as of 30 Nov 2022. Higher education is one of the industries which is being impacted most by GAI, and there is huge uncertainty around what GAI mean for universities in terms of assessments and academic integrity. Given this situation, this article intended to explore what academic assessments are most vulnerable to GAI, which ones are least vulnerable, offered ranking among those assessments, and offered strategies as to what universities can do to ensure GAIs provide least disruption to their business and academic assessment integrity. Data was collected by interviewing 4 GAIs namely ChatGPT, YouChat, Chatosonic AI, and Perplexity AI. The interview included asking multiple open-ended questions. The results found the following assessments as the most vulnerable assessments against GAI, multiple-choice tests, short answer questions, True/False questions, essays, research papers and presentations. The findings also showed that the following assessments are the least vulnerable assessments against GAI, exams, practical assessments, performance-based assessments, open-ended questions, and group projects. These assessments were also ranked by the 4 interviewees, and recommendations for universities is provided. © 2023 Proceedings of the Information Systems Education Conference, ISECON. All rights reserved.
KW  - academic assessment
KW  - AI
KW  - ChatGPT
KW  - GAI
KW  - Generative Artificial Intelligence
KW  - Information systems
KW  - Information use
KW  - Academic assessment
KW  - Academic integrity
KW  - ChatGPT
KW  - Generative artificial intelligence
KW  - High educations
KW  - Multiple choice
KW  - Open-ended questions
KW  - Subfields
KW  - Uncertainty
KW  - Artificial intelligence
PB  - Foundation for Information Technology Education
SN  - 21671435 (ISSN)
LA  - English
J2  - Proc. Inf. Syst. Educ. Conf., ISECON
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 0; Correspondence Address: A.H. Ghapanchi; College of Sport, Health and Engineering, Victoria University, Melbourne, Australia; email: Amir.Ghapanchi@vu.edu.au; Conference name: 36th Information Systems Education Conference, ISECON 2023; Conference code: 191856
ER  -

TY  - CONF
AU  - Lei, W.-C.
AU  - Jian, L.-Y.
AU  - Chen, Y.-W.
AU  - Chou, L.-D.
TI  - Using ChatGPT on Improving Program Performance with pprof and Benchmark
PY  - 2023
T2  - 2023 5th International Conference on Computer Communication and the Internet, ICCCI 2023
SP  - 256
EP  - 260
DO  - 10.1109/ICCCI59363.2023.10210148
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85170028267&doi=10.1109%2fICCCI59363.2023.10210148&partnerID=40&md5=9ff22005c9ce7c6cae015c8e06751f86
AD  - National Central University, Department of Computer Science and Information Engineering, Taoyuan, Taiwan
AB  - In the context of limited computing resources, optimizing program architecture is crucial. Therefore, this paper proposes to apply the powerful analytical capabilities of large language models (LLM) to the field of systematic performance optimization. The output of pprof and benchmark is fed into ChatGPT, and the program's performance is improved based on feedback. In the case study, the number of memory allocations for the objective function was successfully reduced from 99 to 1, resulting in a reduction of the test execution time from 8.6 microseconds to 0.36 microseconds. At the same time, the memory allocation was also reduced from 53.5KB to approximately 1KB. © 2023 IEEE.
KW  - Large Language Models
KW  - Performance analysis
KW  - Prompt Engineering
KW  - System optimization
KW  - Computational linguistics
KW  - Memory architecture
KW  - Computing resource
KW  - Language model
KW  - Large language model
KW  - Optimizing programs
KW  - Performance optimizations
KW  - Performances analysis
KW  - Program architecture
KW  - Program performance
KW  - Prompt engineering
KW  - System optimizations
KW  - Benchmarking
PB  - Institute of Electrical and Electronics Engineers Inc.
SN  - 979-835032695-6 (ISBN)
LA  - English
J2  - Int. Conf. Comput. Commun. Internet, ICCCI
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 0; Conference name: 5th International Conference on Computer Communication and the Internet, ICCCI 2023; Conference date: 23 June 2023 through 25 June 2023; Conference code: 191737
ER  -

TY  - JOUR
AU  - Khlaif, Z.N.
AU  - Mousa, A.
AU  - Hattab, M.K.
AU  - Itmazi, J.
AU  - Hassan, A.A.
AU  - Sanmugam, M.
AU  - Ayyoub, A.
TI  - The Potential and Concerns of Using AI in Scientific Research: ChatGPT Performance Evaluation
PY  - 2023
T2  - JMIR Medical Education
VL  - 9
IS  - 1
C7  - e47049
DO  - 10.2196/47049
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85173909250&doi=10.2196%2f47049&partnerID=40&md5=b82f14fe4628ee990af083446f44aa63
AD  - Faculty of Humanities and Educational Sciences, An-Najah National University, Nablus, Palestine
AD  - Artificial Intelligence and Virtual Reality Research Center, Department of Electrical and Computer Engineering, An Najah National University, Nablus, Palestine
AD  - Faculty of Law and Political Sciences, An-Najah National University, Nablus, Palestine
AD  - Department of Information Technology, College of Engineering and Information Technology, Palestine Ahliya University, Bethlehem, Palestine
AD  - Centre for Instructional Technology and Multimedia, Universiti Sains Malaysia, Penang, Malaysia
AB  - Background: Artificial intelligence (AI) has many applications in various aspects of our daily life, including health, criminal, education, civil, business, and liability law. One aspect of AI that has gained significant attention is natural language processing (NLP), which refers to the ability of computers to understand and generate human language. Objective: This study aims to examine the potential for, and concerns of, using AI in scientific research. For this purpose, high-impact research articles were generated by analyzing the quality of reports generated by ChatGPT and assessing the application’s impact on the research framework, data analysis, and the literature review. The study also explored concerns around ownership and the integrity of research when using AI-generated text. Methods: A total of 4 articles were generated using ChatGPT, and thereafter evaluated by 23 reviewers. The researchers developed an evaluation form to assess the quality of the articles generated. Additionally, 50 abstracts were generated using ChatGPT and their quality was evaluated. The data were subjected to ANOVA and thematic analysis to analyze the qualitative data provided by the reviewers. Results: When using detailed prompts and providing the context of the study, ChatGPT would generate high-quality research that could be published in high-impact journals. However, ChatGPT had a minor impact on developing the research framework and data analysis. The primary area needing improvement was the development of the literature review. Moreover, reviewers expressed concerns around ownership and the integrity of the research when using AI-generated text. Nonetheless, ChatGPT has a strong potential to increase human productivity in research and can be used in academic writing. Conclusions: AI-generated text has the potential to improve the quality of high-impact research articles. The findings of this study suggest that decision makers and researchers should focus more on the methodology part of the research, which includes research design, developing research tools, and analyzing data in depth, to draw strong theoretical and practical implications, thereby establishing a revolution in scientific research in the era of AI. The practical implications of this study can be used in different fields such as medical education to deliver materials to develop the basic competencies for both medicine students and faculty members. ©Zuheir N Khlaif, Allam Mousa, Muayad Kamal Hattab, Jamil Itmazi, Amjad A Hassan, Mageswaran Sanmugam, Abedalkarim Ayyoub.
KW  - AI
KW  - artificial intelligence
KW  - ChatGPT
KW  - research ethics
KW  - scientific research
PB  - JMIR Publications Inc.
SN  - 23693762 (ISSN)
LA  - English
J2  - JMIR Med. Educ.
M3  - Article
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 2; Correspondence Address: Z.N. Khlaif; Faculty of Humanities and Educational Sciences, An-Najah National University, Nablus, PO Box 7, Palestine; email: zkhlaif@najah.edu
ER  -

TY  - CONF
AU  - Jiang, C.
TI  - Research on a Text Quality Assessment System based on BERT Deep Learning
PY  - 2023
T2  - 2023 6th International Conference on Electronics Technology, ICET 2023
SP  - 1161
EP  - 1165
DO  - 10.1109/ICET58434.2023.10211437
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85169885989&doi=10.1109%2fICET58434.2023.10211437&partnerID=40&md5=9b6d01d3d9207d3f297dcd09466be711
AD  - Shandong University of Political Science and Law, School of Library, Jinan, China
AB  - Traditional composition correction is often manually graded by teachers according to certain standards, which will be subjective. Western languages, represented by English, have widely used mature automatic composition evaluation systems in IELTS, TOEFL and other language tests. At present, the Chinese composition automatic evaluation technology is in a rapid development stage, and there are few Chinese composition automatic evaluation systems that can be applied on a large scale. Therefore, with the development of NLP, it is necessary for Chinese educators and learners to use Deep Learning technology to improve the intelligence of Chinese language assessment. Due to the lack of the assessment grade corpus of primary school students' composition, we have established a corpus of nearly 210,000 compositions manually graded by experts. Through comparative analysis of five kinds of models closely related to neural networks, it is finally found that BERT achieved the best result, up to 45.52%. Therefore, we believe that the BERT Deep Learning model, which is easy to deploy and model, can be used to assist language educators, language test organizers and language learners in the intelligent and auxiliary grade evaluation of primary school students' compositions.  © 2023 IEEE.
KW  - automatic assessing system
KW  - BERT
KW  - CNN
KW  - composition
KW  - FastText
KW  - primary school student
KW  - RNN
KW  - Transformer
KW  - Learning systems
KW  - Students
KW  - Automatic assessing system
KW  - Automatic evaluation
KW  - BERT
KW  - Fasttext
KW  - Primary school student
KW  - Primary schools
KW  - RNN
KW  - School students
KW  - Text qualities
KW  - Transformer
KW  - Deep learning
PB  - Institute of Electrical and Electronics Engineers Inc.
SN  - 979-835033769-3 (ISBN)
LA  - English
J2  - Int. Conf. Electron. Technol., ICET
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 0; Correspondence Address: C. Jiang; Shandong University of Political Science and Law, School of Library, Jinan, China; email: jiangchunyan@sdupsl.edu.cn; Conference name: 6th International Conference on Electronics Technology, ICET 2023; Conference date: 12 May 2023 through 15 May 2023; Conference code: 191745
ER  -

TY  - CONF
AU  - Riyadh, M.
AU  - Shafiq, M.O.
TI  - Towards Automatic Evaluation of NLG Tasks Using Conversational Large Language Models
PY  - 2023
T2  - IFIP Advances in Information and Communication Technology
VL  - 676 IFIP
SP  - 425
EP  - 437
DO  - 10.1007/978-3-031-34107-6_34
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85173571641&doi=10.1007%2f978-3-031-34107-6_34&partnerID=40&md5=a5846d59af853caccf219d76bcbd49a4
AD  - Carleton University, Ottawa, ON, Canada
AB  - Evaluating the quality of machine generated open-ended texts is a long-standing challenge in Natural Language Processing (NLP). Even though there have been dramatic advancements in the machine learning technologies that propelled the research work concerning Natural Language Generation (NLG), a subdivision of NLP that focuses on text generation, a promising and widely adopted automatic evaluation technique for NLG tasks is yet to be developed. In this paper, we propose leveraging conversational Large Language Models (LLMs) as automatic evaluators for several open-ended NLG tasks. Our experiments with a recently released conversational LLM named ChatGPT demonstrate the viability of our proposal. © 2023, IFIP International Federation for Information Processing.
KW  - Automatic Evaluator
KW  - ChatGPT
KW  - LLM
KW  - NLG
KW  - Computational linguistics
KW  - Learning algorithms
KW  - Automatic evaluation
KW  - Automatic evaluator
KW  - ChatGPT
KW  - Language model
KW  - Language processing
KW  - Large language model
KW  - Machine learning technology
KW  - Natural language generation
KW  - Natural languages
KW  - Text generations
KW  - Natural language processing systems
A2  - Maglogiannis I.
A2  - Iliadis L.
A2  - MacIntyre J.
A2  - Dominguez M.
PB  - Springer Science and Business Media Deutschland GmbH
SN  - 18684238 (ISSN); 978-303134106-9 (ISBN)
LA  - English
J2  - IFIP Advances in Information and Communication Technology
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 0; Correspondence Address: M. Riyadh; Carleton University, Ottawa, Canada; email: mdriyadh@cmail.carleton.ca1; Conference name: 19th IFIP WG 12.5 International Conference on Artificial Intelligence Applications and Innovations, AIAI 2023; Conference date: 14 June 2023 through 17 June 2023; Conference code: 295919
ER  -

TY  - JOUR
AU  - Rosen, S.
AU  - Saban, M.
TI  - Evaluating the reliability of ChatGPT as a tool for imaging test referral: a comparative study with a clinical decision support system
PY  - 2023
T2  - European Radiology
DO  - 10.1007/s00330-023-10230-0
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85173988506&doi=10.1007%2fs00330-023-10230-0&partnerID=40&md5=35ae1cc61f8a08c468303a6724dc9244
AD  - Department of Health Technology and Policy Evaluation, Gertner Institute for Epidemiology and Health Policy, Institute of Epidemiology & Health Policy Research, Sheba Medical Center, Tel HaShomer, Ramat-Gan, Israel
AD  - Nursing Department, School of Health Sciences, Sackler Faculty of Medicine, Tel Aviv University, Tel Aviv, Israel
AB  - Objectives: As the technology continues to evolve and advance, we can expect to see artificial intelligence (AI) being used in increasingly sophisticated ways to make a diagnosis and decisions such as suggesting the most appropriate imaging referrals. We aim to explore whether Chat Generative Pretrained Transformer (ChatGPT) can provide accurate imaging referrals for clinical use that are at least as good as the ESR iGuide. Methods: A comparative study was conducted in a tertiary hospital. Data was collected from 97 consecutive cases that were admitted to the emergency department with abdominal complaints. We compared the imaging test referral recommendations suggested by the ESR iGuide and the ChatGPT and analyzed cases of disagreement. In addition, we selected cases where ChatGPT recommended a chest abdominal pelvis (CAP) CT (n = 66), and asked four specialists to grade the appropriateness of the referral. Results: ChatGPT recommendations were consistent with the recommendations provided by the ESR iGuide. No statistical differences were found between the appropriateness of referrals by age or gender. Using a sub-analysis of CAP cases, a high agreement between ChatGPT and the specialists was found. Cases of disagreement (12.4%) were further analyzed and presented themes of vague recommendations such as “it would be advisable” and “this would help to rule out.” Conclusions: ChatGPT’s ability to guide the selection of appropriate tests may be comparable to some degree with the ESR iGuide. Features such as the clinical, ethical, and regulatory implications are still warranted and need to be addressed prior to clinical implementation. Further studies are needed to confirm these findings. Clinical relevance statement: The article explores the potential of using advanced language models, such as ChatGPT, in healthcare as a CDS for selecting appropriate imaging tests. Using ChatGPT can improve the efficiency of the decision-making process Key Points: • ChatGPT recommendations were highly consistent with the recommendations provided by the ESR iGuide. • ChatGPT’s ability in guiding the selection of appropriate tests may be comparable to some degree with ESR iGuide’s. © 2023, The Author(s), under exclusive licence to European Society of Radiology.
KW  - Artificial intelligence
KW  - ChatGPT
KW  - ESR iGuide
KW  - Imaging
KW  - article
KW  - artificial intelligence
KW  - ChatGPT
KW  - clinical decision support system
KW  - clinical significance
KW  - comparative study
KW  - controlled study
KW  - decision making
KW  - emergency ward
KW  - female
KW  - gender
KW  - human
KW  - human experiment
KW  - major clinical study
KW  - male
KW  - patient referral
KW  - pelvis
KW  - reliability
KW  - tertiary care center
KW  - thorax
PB  - Springer Science and Business Media Deutschland GmbH
SN  - 09387994 (ISSN)
C2  - 37828297
LA  - English
J2  - Eur. Radiol.
M3  - Article
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 0; Correspondence Address: M. Saban; Nursing Department, School of Health Sciences, Sackler Faculty of Medicine, Tel Aviv University, Tel Aviv, Israel; email: morsaban1@tauex.tau.ac.il; CODEN: EURAE
ER  -

TY  - JOUR
AU  - Vuyyuru, V.A.
AU  - Krishna, G.V.
AU  - Mary, S.S.C.
AU  - Kayalvili, S.
AU  - Alsubayhay, A.M.S.
TI  - A Transformer-CNN Hybrid Model for Cognitive Behavioral Therapy in Psychological Assessment and Intervention for Enhanced Diagnostic Accuracy and Treatment Efficiency
PY  - 2023
T2  - International Journal of Advanced Computer Science and Applications
VL  - 14
IS  - 7
SP  - 594
EP  - 602
DO  - 10.14569/IJACSA.2023.0140766
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85168796332&doi=10.14569%2fIJACSA.2023.0140766&partnerID=40&md5=16f25d188327894ecc20238221d4e0ea
AD  - Department of Computer Science and Engineering, Koneru Lakshmaiah Education Foundation, A.P, Vaddeswaram, 522502, India
AD  - VNR Vignana Jyothi Institute of Engineering and Technology, Hyderabad, India
AD  - Department of Information Technology, Panimalar Engineering College, Poonamalle, Chennai, India
AD  - Department: Artificial Intelligence, Kongu Engineering College, Tamilnadu, Perundurai, India
AD  - Faculty of Computing, Universiti Teknologi Malaysia (UTM), Johour, Malaysia
AB  - The use of Cognitive Behavioral Therapy (CBT) as a method for psychological assessment and intervention has shown to be quite successful. However, by utilizing advancements in artificial intelligence and natural language processing techniques, the diagnostic precision and therapeutic efficacy of CBT can be significantly improved. For CBT in psychological evaluation and intervention, we suggest a unique Transformer-CNN hybrid model in this work. The hybrid model combines the strengths of the Transformer and Convolutional Neural Network (CNN) architectures. While the CNN model successfully extracts local and global features from the input sequences, the Transformer model accurately captures the contextual dependencies and semantic linkages in the text data. It intends to enhance the model's comprehension and interpretation of the complex linguistic patterns involved in psychological evaluation and intervention by merging these two algorithms. On a sizable collection of clinical text data, which includes patient narratives, treatment transcripts, and diagnostic reports, we undertake comprehensive experiments. The proposed Trans-CNN hybrid model outperformed all other methods with an impressive accuracy of 97%. In diagnosing psychiatric problems, the model shows improved diagnosis accuracy and offers more effective therapy advice. Our hybrid model's automatic real-time monitoring and feedback capabilities also make it possible for prompt intervention and customized care during therapy sessions. By giving doctors a formidable tool for precise evaluation and efficient intervention, the suggested approach has the potential to revolutionize the field of CBT and enhance patient outcomes for mental health. In order to improve the diagnostic precision and therapeutic efficacy of CBT in psychological evaluation and intervention, this work provides a transformational strategy that combines the advantages of the Transformer and CNN architectures. © 2023, Science and Information Organization. All Rights Reserved.
KW  - CBT
KW  - CNN
KW  - diagnostic accuracy
KW  - intervention
KW  - NLP
KW  - psychological assessment
KW  - Transformer
KW  - treatment efficiency
KW  - Convolutional neural networks
KW  - Efficiency
KW  - Network architecture
KW  - Neural network models
KW  - Patient treatment
KW  - Semantics
KW  - Cognitive-behavioral therapies
KW  - Convolutional neural network
KW  - Diagnostic accuracy
KW  - Hybrid model
KW  - Intervention
KW  - Psychological assessment
KW  - Psychological evaluation
KW  - Therapeutic efficacy
KW  - Transformer
KW  - Treatment efficiency
KW  - Natural language processing systems
PB  - Science and Information Organization
SN  - 2158107X (ISSN)
LA  - English
J2  - Intl. J. Adv.  Comput. Sci. Appl.
M3  - Article
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 0
ER  -

TY  - CONF
AU  - Lavechin, M.
AU  - Sy, Y.
AU  - Titeux, H.
AU  - Blandón, M.A.C.
AU  - Räsänen, O.
AU  - Bredin, H.
AU  - Dupoux, E.
AU  - Cristia, A.
TI  - BabySLM: language-acquisition-friendly benchmark of self-supervised spoken language models
PY  - 2023
T2  - Proceedings of the Annual Conference of the International Speech Communication Association, INTERSPEECH
VL  - 2023-August
SP  - 4588
EP  - 4592
DO  - 10.21437/Interspeech.2023-978
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85171546944&doi=10.21437%2fInterspeech.2023-978&partnerID=40&md5=e1b95d459169c50f6b47b647db027afd
AD  - LSCP, ENS, EHESS, CNRS, PSL University, Paris, France
AD  - Meta AI Research, France
AD  - Unit of Computing Sciences, Tampere University, Finland
AD  - IRIT, CNRS, Toulouse, France
AD  - Cognitive Machine Learning Team, INRIA, France
AB  - Self-supervised techniques for learning speech representations have been shown to develop linguistic competence from exposure to speech without the need for human labels. In order to fully realize the potential of these approaches and further our understanding of how infants learn language, simulations must closely emulate real-life situations by training on developmentally plausible corpora and benchmarking against appropriate test sets. To this end, we propose a language-acquisition-friendly benchmark to probe spoken language models at the lexical and syntactic levels, both of which are compatible with the vocabulary typical of children's language experiences. This paper introduces the benchmark and summarizes a range of experiments showing its usefulness. In addition, we highlight two exciting challenges that need to be addressed for further progress: bridging the gap between text and speech and between clean speech and in-the-wild speech. © 2023 International Speech Communication Association. All rights reserved.
KW  - child language
KW  - language acquisition
KW  - self-supervised learning
KW  - spoken language modeling
KW  - Computational linguistics
KW  - Mergers and acquisitions
KW  - Speech communication
KW  - Supervised learning
KW  - Child language
KW  - Clean speech
KW  - Language acquisition
KW  - Language model
KW  - Learn+
KW  - Linguistic competences
KW  - Self-supervised learning
KW  - Spoken language modeling
KW  - Spoken languages
KW  - Test sets
KW  - Modeling languages
PB  - International Speech Communication Association
SN  - 2308457X (ISSN)
LA  - English
J2  - Proc. Annu. Conf. Int. Speech. Commun. Assoc., INTERSPEECH
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 0; Conference name: 24th International Speech Communication Association, Interspeech 2023; Conference date: 20 August 2023 through 24 August 2023; Conference code: 191724
ER  -

TY  - CONF
AU  - Song, Y.
AU  - Miret, S.
AU  - Liu, B.
TI  - MatSci-NLP: Evaluating Scientific Language Models on Materials Science Language Tasks Using Text-to-Schema Modeling
PY  - 2023
T2  - Proceedings of the Annual Meeting of the Association for Computational Linguistics
VL  - 1
SP  - 3621
EP  - 3639
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85172433547&partnerID=40&md5=296a25bcc095ebd785b0ff730516e3e1
AD  - University of Montreal, Mila - Quebec AI, Canada
AD  - Intel Labs
AB  - We present MatSci-NLP, a natural language benchmark for evaluating the performance of natural language processing (NLP) models on materials science text. We construct the benchmark from publicly available materials science text data to encompass seven different NLP tasks, including conventional NLP tasks like named entity recognition and relation classification, as well as NLP tasks specific to materials science, such as synthesis action retrieval which relates to creating synthesis procedures for materials. We study various BERT-based models pretrained on different scientific text corpora on MatSci-NLP to understand the impact of pretraining strategies on understanding materials science text. Given the scarcity of high-quality annotated data in the materials science domain, we perform our fine-tuning experiments with limited training data to encourage the generalize across MatSci-NLP tasks. Our experiments in this low-resource training setting show that language models pretrained on scientific text outperform BERT trained on general text. MatBERT, a model pretrained specifically on materials science journals, generally performs best for most tasks. Moreover, we propose a unified text-to-schema for multitask learning on MatSci-NLP and compare its performance with traditional fine-tuning methods. In our analysis of different training methods, we find that our proposed text-to-schema methods inspired by question-answering consistently outperform single and multitask NLP fine-tuning methods. The code and datasets are publicly available. © 2023 Association for Computational Linguistics.
KW  - Benchmarking
KW  - Character recognition
KW  - Classification (of information)
KW  - Computational linguistics
KW  - Learning systems
KW  - Natural language processing systems
KW  - Text processing
KW  - Fine-tuning methods
KW  - Language model
KW  - Language processing
KW  - Material science
KW  - Natural languages
KW  - Performance
KW  - Processing model
KW  - Scientific language
KW  - Scientific texts
KW  - Text data
KW  - Modeling languages
PB  - Association for Computational Linguistics (ACL)
SN  - 0736587X (ISSN); 978-195942972-2 (ISBN)
LA  - English
J2  - Proc. Annu. Meet. Assoc. Comput Linguist.
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 1; Correspondence Address: B. Liu; University of Montreal, Mila - Quebec AI, Canada; email: bang.liu@umontreal.ca; Conference name: 61st Annual Meeting of the Association for Computational Linguistics, ACL 2023; Conference date: 9 July 2023 through 14 July 2023; Conference code: 192160
ER  -

TY  - CONF
AU  - Maynez, J.
AU  - Agrawal, P.
AU  - Gehrmann, S.
TI  - Benchmarking Large Language Model Capabilities for Conditional Generation
PY  - 2023
T2  - Proceedings of the Annual Meeting of the Association for Computational Linguistics
VL  - 1
SP  - 9194
EP  - 9213
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85170272676&partnerID=40&md5=b152147de60615fe7af6b667bfea026d
AD  - Google DeepMind, United Kingdom
AD  - Google Research
AB  - Pre-trained large language models (PLMs) underlie most new developments in natural language processing. They have shifted the field from application-specific model pipelines to a single model that is adapted to a wide range of tasks. Autoregressive PLMs like GPT-3 or PaLM, alongside techniques like few-shot learning, have additionally shifted the output modality to generation instead of classification or regression. Despite their ubiquitous use, the generation quality of language models is rarely evaluated when these models are introduced. Additionally, it is unclear how existing generation tasks-while they can be used to compare systems at a high level-relate to the real world use cases for which people have been adopting them. In this work, we discuss how to adapt existing application-specific generation benchmarks to PLMs and provide an in-depth, empirical study of the limitations and capabilities of PLMs in natural language generation tasks along dimensions such as scale, architecture, input and output language. Our results show that PLMs differ in their applicability to different data regimes and their generalization to multiple languages and inform which PLMs to use for a given generation task setup. We share best practices to be taken into consideration when benchmarking generation capabilities during the development of upcoming PLMs. © 2023 Association for Computational Linguistics.
KW  - Classification (of information)
KW  - Computational linguistics
KW  - Natural language processing systems
KW  - Application specific
KW  - Application-specific model
KW  - Auto-regressive
KW  - Conditional generation
KW  - Language model
KW  - Language processing
KW  - Natural languages
KW  - Output modality
KW  - Real-world
KW  - Single models
KW  - Benchmarking
PB  - Association for Computational Linguistics (ACL)
SN  - 0736587X (ISSN); 978-195942972-2 (ISBN)
LA  - English
J2  - Proc. Annu. Meet. Assoc. Comput Linguist.
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 0; Conference name: 61st Annual Meeting of the Association for Computational Linguistics, ACL 2023; Conference date: 9 July 2023 through 14 July 2023; Conference code: 192160
ER  -

TY  - CONF
AU  - Roy, K.
AU  - Garg, T.
AU  - Palit, V.
TI  - Knowledge Graph Guided Semantic Evaluation of Language Models For User Trust
PY  - 2023
T2  - Proceedings - 2023 IEEE Conference on Artificial Intelligence, CAI 2023
SP  - 234
EP  - 236
DO  - 10.1109/CAI54212.2023.00108
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85168704444&doi=10.1109%2fCAI54212.2023.00108&partnerID=40&md5=c0ce1f2cb00152b17f9feca07f79c0e6
AD  - Artificial Intelligence Institute, University of South Carolina, Columbia, SC, United States
AD  - Birla Institute of Technology and Science, Pilani, India
AD  - Indian Institute of Technology, Kharagpur, India
AB  - A fundamental question in natural language processing is - what kind of language structure and semantics is the language model capturing? Graph formats such as knowledge graphs are easy to evaluate as they explicitly express language semantics and structure. This study evaluates the semantics encoded in the self-attention transformers by leveraging explicit knowledge graph structures. We propose novel metrics to measure the reconstruction error when providing graph path sequences from a knowledge graph and trying to reproduce/reconstruct the same from the outputs of the self-attention transformer models. The opacity of language models has an immense bearing on societal issues of trust and explainable decision outcomes. Our findings suggest that language models are models of stochastic control processes for plausible language pattern generation. However, they do not ascribe object and concept-level meaning and semantics to the learned stochastic patterns such as those described in knowledge graphs. This has significant application-level user trust implications as stochastic patterns without a strong sense of meaning cannot be trusted in high-stakes applications.  © 2023 IEEE.
KW  - Graph Neural Networks
KW  - Knowledge Graph
KW  - Transformers
KW  - Computational linguistics
KW  - Graph neural networks
KW  - Graphic methods
KW  - Knowledge management
KW  - Natural language processing systems
KW  - Semantics
KW  - Stochastic control systems
KW  - Stochastic models
KW  - Stochastic systems
KW  - Graph neural networks
KW  - Knowledge graphs
KW  - Language model
KW  - Language processing
KW  - Language semantics
KW  - Language structure
KW  - Natural languages
KW  - Semantic evaluations
KW  - Stochastics
KW  - Transformer
KW  - Knowledge graph
PB  - Institute of Electrical and Electronics Engineers Inc.
SN  - 979-835033984-0 (ISBN)
LA  - English
J2  - Proc. - IEEE Conf. Artif. Intell., CAI
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 0; Correspondence Address: K. Roy; Artificial Intelligence Institute, University of South Carolina, Columbia, United States; email: kaushikr@email.sc.edu; Conference name: 2023 IEEE Conference on Artificial Intelligence, CAI 2023; Conference date: 5 June 2023 through 6 June 2023; Conference code: 191304
ER  -

TY  - CONF
AU  - Niu, Y.
AU  - Xiong, H.
AU  - Liang, Z.
AU  - Zhang, J.
AU  - Peng, C.
AU  - Yuan, T.
TI  - Research on Distribution Transformer Quality Sampling Assessment Model Based on Entropy Weight Method
PY  - 2023
T2  - Lecture Notes in Electrical Engineering
VL  - 1060 LNEE
SP  - 504
EP  - 510
DO  - 10.1007/978-981-99-4334-0_63
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85172404679&doi=10.1007%2f978-981-99-4334-0_63&partnerID=40&md5=65449f16dc03e9e54f3ce058141e3404
AD  - Material Department, State Grid Corporation of China, Beijing, China
AD  - China Electric Power Research Institute, Wuhan, China
AB  - Distribution transformer is an important equipment in power system. Power grid companies purchase a large number of distribution transformers every year to satisfy the social electricity demand. At present, there are many manufacturers producing distribution transformers. Different manufacturers produce distribution transformers due to different processes, leading to differences in the performance of distribution transformers. Therefore, it is an urgent problem for power grid companies to select the optimal distribution transformer. Based on entropy weight method, a transformer quality assessment model based on factory test data is studied in this paper. By analysing the open-circuit loss, on-load loss, average temperature rise of HV winding and average temperature rise of LV winding, a distribution transformer quality assessment model is constructed. Based on the above model, the distribution transformers of different manufacturers are scored and the optimal distribution transformer manufacturer is extracted. This study can provide reference for power grid companies to purchase distribution transformers in the future. © 2023, The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd.
KW  - Distribution transformer
KW  - EWM
KW  - Quality sampling test
KW  - Electric loads
KW  - Entropy
KW  - Power quality
KW  - Transformer windings
KW  - Winding
KW  - Distribution transformer
KW  - Entropy weight method
KW  - EWM
KW  - Model-based OPC
KW  - Optimal distributions
KW  - Power grid company
KW  - Quality assessment model
KW  - Quality sampling
KW  - Quality sampling test
KW  - Sampling test
KW  - Electric transformer testing
A2  - Hu C.
A2  - Cao W.
PB  - Springer Science and Business Media Deutschland GmbH
SN  - 18761100 (ISSN); 978-981994333-3 (ISBN)
LA  - English
J2  - Lect. Notes Electr. Eng.
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 0; Correspondence Address: Z. Liang; China Electric Power Research Institute, Wuhan, China; email: liangzhengbo@yeah.net; Conference name: Conference Proceedings of 2022 2nd International Joint Conference on Energy, Electrical and Power Engineering; Conference date: 19 November 2022 through 21 November 2022; Conference code: 299139
ER  -

TY  - CONF
AU  - Banar, B.
AU  - Colton, S.
TI  - Autoregressive Self-Evaluation: A Case Study of Music Generation Using Large Language Models
PY  - 2023
T2  - Proceedings - 2023 IEEE Conference on Artificial Intelligence, CAI 2023
SP  - 264
EP  - 265
DO  - 10.1109/CAI54212.2023.00118
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85168657514&doi=10.1109%2fCAI54212.2023.00118&partnerID=40&md5=4ae43efe33c61c10eb3c7e0ec286a619
AD  - Queen Mary University of London, School of EECS, London, United Kingdom
AB  - Autoregressive models have shown significant success in many tasks such as natural language generation and music composition. However, generic training mechanisms with off-the-shelf loss functions (e.g. cross-entropy), where not much attention is paid to the specifics of the task, do not necessarily guarantee success as different data modalities (e.g. text, visuals, music) exhibit different natures. In this study, we present a novel autoregressive self-evaluation framework to assess the performance of autoregressive models with both domain-agnostic and domain-specific metrics. We demonstrate this strategy with a case study of music generation using GPT-2 within a transfer learning paradigm. We contrast and compare the effects of fundamental parameters in autoregressive generation such as the temperature in sampling and the length of the generated sequence.  © 2023 IEEE.
KW  - autoregressive models
KW  - autoregressive self-evalution
KW  - generative models
KW  - large language models
KW  - music generation
KW  - Computational linguistics
KW  - Natural language processing systems
KW  - Auto-regressive
KW  - Autoregressive modelling
KW  - Autoregressive self-evalution
KW  - Case-studies
KW  - Generative model
KW  - Language model
KW  - Large language model
KW  - Music generation
KW  - Natural language generation
KW  - Self evaluation
KW  - Music
PB  - Institute of Electrical and Electronics Engineers Inc.
SN  - 979-835033984-0 (ISBN)
LA  - English
J2  - Proc. - IEEE Conf. Artif. Intell., CAI
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 0; Correspondence Address: B. Banar; Queen Mary University of London, School of EECS, London, United Kingdom; email: b.banar@qmul.ac.uk; Conference name: 2023 IEEE Conference on Artificial Intelligence, CAI 2023; Conference date: 5 June 2023 through 6 June 2023; Conference code: 191304
ER  -

TY  - JOUR
AU  - Rao, A.
AU  - Pang, M.
AU  - Kim, J.
AU  - Kamineni, M.
AU  - Lie, W.
AU  - Prasad, A.K.
AU  - Landman, A.
AU  - Dreyer, K.
AU  - Succi, M.D.
TI  - Assessing the Utility of ChatGPT Throughout the Entire Clinical Workflow: Development and Usability Study
PY  - 2023
T2  - Journal of Medical Internet Research
VL  - 25
C7  - e48659
DO  - 10.2196/48659
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85168507069&doi=10.2196%2f48659&partnerID=40&md5=238518f2a9eff0ee5e21f62d23c3226d
AD  - Medically Engineered Solutions in Healthcare Incubator, Innovation in Operations Research Center (MESH IO), Massachusetts General Hospital, Boston, MA, United States
AD  - Harvard Medical School, Boston, MA, United States
AD  - Department of Radiology, Massachusetts General Hospital, Boston, MA, United States
AD  - Department of Radiology, Brigham and Women's Hospital, Boston, MA, United States
AD  - Data Science Office, Mass General Brigham, Boston, MA, United States
AD  - Mass General Brigham Innovation, Mass General Brigham, Boston, MA, United States
AD  - Department of Radiology, Massachusetts General Hospital, 55 Fruit Street, Boston, 02114, MA, United States
AB  - Background: Large language model (LLM)–based artificial intelligence chatbots direct the power of large training data sets toward successive, related tasks as opposed to single-ask tasks, for which artificial intelligence already achieves impressive performance. The capacity of LLMs to assist in the full scope of iterative clinical reasoning via successive prompting, in effect acting as artificial physicians, has not yet been evaluated. Objective: This study aimed to evaluate ChatGPT’s capacity for ongoing clinical decision support via its performance on standardized clinical vignettes. Methods: We inputted all 36 published clinical vignettes from the Merck Sharpe & Dohme (MSD) Clinical Manual into ChatGPT and compared its accuracy on differential diagnoses, diagnostic testing, final diagnosis, and management based on patient age, gender, and case acuity. Accuracy was measured by the proportion of correct responses to the questions posed within the clinical vignettes tested, as calculated by human scorers. We further conducted linear regression to assess the contributing factors toward ChatGPT’s performance on clinical tasks. Results: ChatGPT achieved an overall accuracy of 71.7% (95% CI 69.3%-74.1%) across all 36 clinical vignettes. The LLM demonstrated the highest performance in making a final diagnosis with an accuracy of 76.9% (95% CI 67.8%-86.1%) and the lowest performance in generating an initial differential diagnosis with an accuracy of 60.3% (95% CI 54.2%-66.6%). Compared to answering questions about general medical knowledge, ChatGPT demonstrated inferior performance on differential diagnosis (β=–15.8%; P<.001) and clinical management (β=–7.4%; P=.02) question types. Conclusions: ChatGPT achieves impressive accuracy in clinical decision-making, with increasing strength as it gains more clinical information at its disposal. In particular, ChatGPT demonstrates the greatest accuracy in tasks of final diagnosis as compared to initial diagnosis. Limitations include possible model hallucinations and the unclear composition of ChatGPT’s training data set. ©Arya Rao, Michael Pang, John Kim, Meghana Kamineni, Winston Lie, Anoop K Prasad, Adam Landman, Keith Dreyer, Marc D Succi.
KW  - accuracy
KW  - AI
KW  - artificial intelligence
KW  - chatbot
KW  - ChatGPT
KW  - clinical decision support
KW  - clinical vignettes
KW  - decision-making
KW  - development
KW  - Generative Pre-trained Transformer
KW  - GPT
KW  - large language models
KW  - LLMs
KW  - usability
KW  - utility
KW  - Acceptance and Commitment Therapy
KW  - Artificial Intelligence
KW  - Clinical Decision-Making
KW  - Humans
KW  - Organizations
KW  - Workflow
KW  - adult
KW  - age
KW  - Article
KW  - ChatGPT
KW  - clinical decision support system
KW  - clinical feature
KW  - clinical reasoning
KW  - controlled study
KW  - diagnostic accuracy
KW  - diagnostic test accuracy study
KW  - differential diagnosis
KW  - female
KW  - gender
KW  - human
KW  - male
KW  - pheochromocytoma
KW  - professional knowledge
KW  - testis cancer
KW  - usability
KW  - utility value
KW  - vignette
KW  - workflow
KW  - acceptance and commitment therapy
KW  - artificial intelligence
KW  - clinical decision making
KW  - organization
KW  - workflow
PB  - JMIR Publications Inc.
SN  - 14388871 (ISSN)
C2  - 37606976
LA  - English
J2  - J. Med. Internet Res.
M3  - Article
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 18; Correspondence Address: M.D. Succi; Medically Engineered Solutions in Healthcare Incubator, Innovation in Operations Research Center (MESH IO), Massachusetts General Hospital, Boston, United States; email: msucci@partners.org
ER  -

TY  - CONF
AU  - Pinochet, L.H.C.
AU  - Moreira, M.Â.L.
AU  - Fávero, L.P.
AU  - dos Santos, M.
AU  - Pardim, V.I.
TI  - Collaborative Work Alternatives with ChatGPT Based on Evaluation Criteria for its Use in Higher Education: Application of the PROMETHEE-SAPEVO-M1 Method
PY  - 2023
T2  - Procedia Computer Science
VL  - 221
SP  - 177
EP  - 184
DO  - 10.1016/j.procs.2023.07.025
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85171772333&doi=10.1016%2fj.procs.2023.07.025&partnerID=40&md5=106250922509693eef82badefcf0bc51
AD  - Federal University of Sao Paulo, SP, Osasco, 06120-042, Brazil
AD  - Fluminense Federal University, RJ, Niterói, 24210-240, Brazil
AD  - University of São Paulo (USP), SP, São Paulo, 05508-210, Brazil
AD  - Military Institute of Engineering, Urca, RJ, 22290-270, Brazil
AB  - The objective of this article is to adopt the integration of two methods of Multicriteria Decision Support, based on the axiomatic models PROMETHEE and SAPEVO-M1, aggregating data of a qualitative nature through ordinal entries to analyze collaborative work alternatives with ChatGPT from evaluation criteria for its use in higher education. It is highlighted that the alternative with the best performance is 'Support for Autonomous Learning,' presenting the highest positive flow and the lowest negative flow, exposing a natural preference over the set. In this study, 'Emotional Support' was the worst alternative. It occurs because the tool is still under discussion when addressing issues such as the lack of human interaction, reduced critical thinking, and less empathy. © 2023 The Authors. Published by Elsevier B.V. This is an open access article under the CC BY-NC-ND license (https://creativecommons.org/licenses/by-nc-nd/4.0) Peer-review under responsibility of the scientific committee of the Tenth International Conference on Information Technology and Quantitative Management.
KW  - Artificial intelligence
KW  - ChatGPT
KW  - collaborative work
KW  - Higher Education
KW  - PROMETHEE-SAPEVO-M1 method
KW  - Artificial intelligence
KW  - Industry 4.0
KW  - Autonomous learning
KW  - Axiomatic models
KW  - ChatGPT
KW  - Collaborative Work
KW  - Evaluation criteria
KW  - High educations
KW  - Multicriteria decision support
KW  - Performance
KW  - PROMETHEE
KW  - PROMETHEE-SAPEVO-m1 method
KW  - Decision support systems
A2  - Shi Y.
PB  - Elsevier B.V.
SN  - 18770509 (ISSN)
LA  - English
J2  - Procedia Comput. Sci.
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 0; Correspondence Address: L.H.C. Pinochet; Federal University of Sao Paulo, Osasco, SP, 06120-042, Brazil; email: luis.hernan@unifesp.br; Conference name: 10th International Conference on Information Technology and Quantitative Management, ITQM 2023; Conference date: 12 August 2023 through 14 August 2023; Conference code: 192167
ER  -

TY  - JOUR
AU  - Sethi, H.S.
AU  - Mohapatra, S.
AU  - Mali, C.
AU  - Dubey, R.
TI  - Online for on Call: A Study Assessing the Use of Internet Resources Including ChatGPT among On-Call Radiology Residents in India
PY  - 2023
T2  - Indian Journal of Radiology and Imaging
DO  - 10.1055/s-0043-1772465
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85170084845&doi=10.1055%2fs-0043-1772465&partnerID=40&md5=76ace3bf10a43240f1ac223dc0a872ec
AD  - Department of Radiodiagnosis, Institute of Medical Sciences, Sum Hospital, Siksha 'o' Anusandhan Deemed to Be University, Odisha, India
AD  - Department of Pathology, Kalinga Institute of Medical Sciences, Odisha, Bhubaneswar, India
AD  - Department of Radiodiagnosis, Kalinga Institute of Medical Sciences, Odisha, Bhubaneswar, India
AB  - Background The information-seeking behavior of the radiology residents on call has undergone modernization in the recent times given the advent of easy to access, reliable online resources, and robust artificial intelligence chatbots such as Chat Generative Pre-Trained Transformer (ChatGPT). Purpose The aim of this study was to conduct a baseline analysis among the residents to understand the best way to meet information needs in the future, spread awareness about the existing resources, and narrow down to the most preferred online resource. Methods and Materials A prospective, descriptive study was performed using an online survey instrument and was conducted among radiology residents in India. They were questioned on their demographics, frequency of on call, fatigue experienced on call, and preferred information resources and reasons for choosing them. Results A total of 286 residents participated in the survey. All residents had used the Internet radiology resources during on-call duties. The most preferred resource material was Radiopaedia followed by Radiology Assistant. IMAIOS e-Anatomy was the most preferred anatomy resource. There was significant (p < 0.05) difference in relation to the use of closed edit peer-reviewed literature among the two batches with it being used almost exclusively by third year residents. In the artificial intelligence-aided ChatGPT section, 61.8% had used the software at least once while being on call, of them 57.6% responded that the information was inaccurate, 67.2% responded that the information was insufficient to aid in diagnosis, 100% felt that the lack of images in the software made it an unlikely resource that would be used by them in the future, and 85.8% agreed that they would use it for providing reporting templates in the future. In the suggestions for upcoming versions, 100% responded that images should be included in the description provide by the chatbot, and 74.5% felt that references for the information being provided should be included as it reaffirms the reliability of the information. Conclusions Presently, we find that Radiopaedia met most of the requirements as an ideal online radiology resource according to the residents. In the present-day scenario, ChatGPT is not considered as an important on-call radiology education resource first because it lacks images which is quintessential for a budding radiologist, and second, it does not have any reference or proof for the information that it is providing. However, it may be of help to nonmedical professionals who need to understand radiology in layman's terms and to radiologists for patient report preparation and research writing. © 2023 Wolters Kluwer Medknow Publications. All rights reserved.
KW  - artificial intelligence
KW  - ChatGPT
KW  - on-call radiology
KW  - resident education
PB  - Thieme Medical Publishers, Inc.
SN  - 09713026 (ISSN)
LA  - English
J2  - Indian J. Radiol. Imaging
M3  - Article
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 2; Correspondence Address: H.S. Sethi; Department of Radiodiagnosis, Institute of Medical Sciences, Sum Hospital, Siksha 'o' Anusandhan Deemed to Be University, Bhubaneswar, Shampur, Odisha, 751003, India; email: humsheer@hotmail.com; CODEN: IJRIE
ER  -

TY  - JOUR
AU  - Gorichanaz, T.
TI  - Accused: How students respond to allegations of using ChatGPT on assessments
PY  - 2023
T2  - Learning: Research and Practice
VL  - 9
IS  - 2
SP  - 183
EP  - 196
DO  - 10.1080/23735082.2023.2254787
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85170696307&doi=10.1080%2f23735082.2023.2254787&partnerID=40&md5=16e067440f7315eca9280cad676db0de
AD  - College of Computing & Informatics, Drexel University, Philadelphia, PA, United States
AB  - This study investigates student responses to allegations of cheating using ChatGPT, a popular software platform capable of generating coherent text on various topics. Data comprising 49 Reddit posts and discussions between December 2022 and June 2023 were collected. Students shared their experiences, often asserting false accusations, and discussed strategies to navigate these situations. Thematic analysis identified five key themes: adopting a legalistic stance with argumentation and evidence; higher education's role as a societal gatekeeper; vicissitudes of trust in students vs. technology; questions of what constitutes cheating; and the need to rethink assessment. These findings will aid educators and institutions in crafting more meaningful assessments in the age of AI and establishing guidelines for student usage of ChatGPT and similar tools. © 2023 Informa UK Limited, trading as Taylor & Francis Group.
KW  - ChatGPT
KW  - cheating
KW  - contract cheating
KW  - plagiarism
PB  - Routledge
SN  - 23735082 (ISSN)
LA  - English
J2  - Learn.
M3  - Article
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 1; Correspondence Address: T. Gorichanaz; College of Computing & Informatics, Drexel University, Philadelphia, United States; email: gorichanaz@drexel.edu
ER  -

TY  - CONF
AU  - Liu, B.
AU  - Takahashi, Y.
AU  - Fujiwara, K.
AU  - Imamori, S.
TI  - Stray Loss Evaluation of Power Transformers Using Simplified Air-core Model with Tank and Frame
PY  - 2023
T2  - 2023 IEEE International Magnetic Conference - Short Papers, INTERMAG Short Papers 2023 - Proceedings
DO  - 10.1109/INTERMAGShortPapers58606.2023.10228440
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85172739120&doi=10.1109%2fINTERMAGShortPapers58606.2023.10228440&partnerID=40&md5=864be5ede2ed0c3eee2067c8fe3dbcf4
AD  - Doshisha University, Department of Electrical Engineering, Kyotanabe, 610-0394, Japan
AD  - Fuji Electric Co., Ltd., Advanced Technology Laboratory, Hino, 191-8502, Japan
AB  - This paper reports stray loss generated in a tank, frames, and shields of a power transformer, and the shielding effect is qualitatively discussed for its design optimization. First, simplified transformer models composed of an air-core coil, a tank/frame, and a magnetic shield are newly proposed to reproduce stray loss generated in practical oil-filled power transformers. Then, accurate methods of measuring the stray loss in the proposed models were examined. The accuracy of the stray loss estimation based on a finite-element method was verified by comparing it with the measurement results.  © 2023 IEEE.
KW  - Finite-element method
KW  - iron loss
KW  - magnetic shield
KW  - power transformer
KW  - stray loss
KW  - structural steel
KW  - Finite element method
KW  - Iron
KW  - Magnetic shielding
KW  - Oil filled transformers
KW  - Tanks (containers)
KW  - Air-core
KW  - Air-core coils
KW  - Core model
KW  - Design optimization
KW  - Iron loss
KW  - Magnetic shield
KW  - Shielding effect
KW  - Stray loss
KW  - Structural steels
KW  - Transformer modeling
KW  - Power transformers
PB  - Institute of Electrical and Electronics Engineers Inc.
SN  - 979-835033836-2 (ISBN)
LA  - English
J2  - IEEE Int. Magn. Conf. - Short Pap., INTERMAG Short Papers - Proc.
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 0; Conference name: 2023 IEEE International Magnetic Conference - Short Papers, INTERMAG Short Papers 2023; Conference date: 15 May 2023 through 19 May 2023; Conference code: 192391
ER  -

TY  - CONF
AU  - Singh, J.
AU  - Kaur, D.
AU  - Kaur, P.
TI  - Evaluation of BERT Model for Aspect-Based Sentiment Analysis
PY  - 2023
T2  - Lecture Notes in Networks and Systems
VL  - 641 LNNS
SP  - 107
EP  - 116
DO  - 10.1007/978-981-99-0483-9_10
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85171333180&doi=10.1007%2f978-981-99-0483-9_10&partnerID=40&md5=cbd99ccaf7e8d1f2458608aa276970af
AD  - Department of Computer Science and Engineering, Chandigarh University, Chandigarh, India
AD  - Department of Computer Science, Guru Nanak Dev University, Amritsar, India
AB  - Thanks to digital evaluations and ratings on E-commerce sites, people can now purchase items more effortlessly. Purchasers may share their stories on e-commerce giants like Amazon, Flipkart, and others, giving prospective buyers concrete proof of the product’s effects. One of the most difficult challenges in Sentiment Analysis (SA) is determining a customer's fine-grained opinion on a single component of a product. This research offers a machine learning model based on Bidirectional Encoder Representation Transformer (BERT) for performing Aspect-Based Sentiment Analysis (ABSA) of user evaluations. This paper proposes a BERT-based model for SA of three different datasets of user reviews obtained from Amazon, IMDB, and Tripadvisor, respectively. The proposed BERT model outperformed other classifiers when compared by varying learning rates, dropouts, and sentence lengths of user texts. The proposed model beats three baseline models in terms of accuracy of the classification and achieves state-of-the-art results. © 2023, The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd.
KW  - Aspect based
KW  - BERT
KW  - Product reviews
KW  - Sentiment analysis
KW  - Sentiment classification
KW  - Electronic commerce
KW  - Learning systems
KW  - Sales
KW  - Aspect based
KW  - Bidirectional encoder representation transformer
KW  - E- commerces
KW  - E-commerce sites
KW  - Product reviews
KW  - Prospective buyers
KW  - S effect
KW  - Sentiment analysis
KW  - Sentiment classification
KW  - Transformer modeling
KW  - Sentiment analysis
A2  - Bansal H.O.
A2  - Ajmera P.K.
A2  - Joshi S.
A2  - Bansal R.C.
A2  - Shekhar C.
PB  - Springer Science and Business Media Deutschland GmbH
SN  - 23673370 (ISSN); 978-981990482-2 (ISBN)
LA  - English
J2  - Lect. Notes Networks Syst.
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 0; Correspondence Address: J. Singh; Department of Computer Science and Engineering, Chandigarh University, Chandigarh, India; email: jaspreet.e10279@cumail.in; Conference name: International Conference on Next Generation Systems and Networks, BITS EEE CON 2022; Conference date: 4 November 2022 through 5 November 2022; Conference code: 298029
ER  -

TY  - JOUR
AU  - Daungsupawong, H.
AU  - Wiwanitkit, V.
TI  - Social determinants of health into evaluations of quality and appropriateness of AI assistant ChatGPT
PY  - 2023
T2  - Prostate Cancer and Prostatic Diseases
DO  - 10.1038/s41391-023-00735-6
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85173940516&doi=10.1038%2fs41391-023-00735-6&partnerID=40&md5=184c0ae31550b185de1ea5e8ac90cf79
AD  - Private Academic Consultant, Phonhong, Laos
AD  - Chandigarh University, Chandigarh, India
AD  - Joesph Ayobabalola University, Ikeji-Arakeji, Nigeria
PB  - Springer Nature
SN  - 13657852 (ISSN)
C2  - 37803243
LA  - English
J2  - Prostate Cancer Prostatic Dis.
M3  - Letter
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 1; Correspondence Address: H. Daungsupawong; Private Academic Consultant, Phonhong, Laos; email: hinpetchdaung@gmail.com; V. Wiwanitkit; Chandigarh University, Chandigarh, India; email: wviroj@yahoo.com; CODEN: PCPDF
ER  -

TY  - JOUR
AU  - Al-Ashwal, F.Y.
AU  - Zawiah, M.
AU  - Gharaibeh, L.
AU  - Abu-Farha, R.
AU  - Bitar, A.N.
TI  - Evaluating the Sensitivity, Specificity, and Accuracy of ChatGPT-3.5, ChatGPT-4, Bing AI, and Bard Against Conventional Drug-Drug Interactions Clinical Tools
PY  - 2023
T2  - Drug, Healthcare and Patient Safety
VL  - 15
SP  - 137
EP  - 147
DO  - 10.2147/DHPS.S425858
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85172323774&doi=10.2147%2fDHPS.S425858&partnerID=40&md5=f5c1e8a5bffa53188e0bdaab847b79b4
AD  - Department of Clinical Pharmacy and Pharmacy Practice, Faculty of Pharmacy, University of Science and Technology, Sana’a, Yemen
AD  - College of Pharmacy, Al-Ayen University, Thi-Qar, Iraq
AD  - Department of Pharmacy Practice, Faculty of Clinical Pharmacy, Hodeidah University, Al Hodeidah, Yemen
AD  - Pharmacological and Diagnostic Research Center, Faculty of Pharmacy, Al-Ahliyya Amman University, Amman, Jordan
AD  - Clinical Pharmacy and Therapeutics Department, Faculty of Pharmacy, Applied Science Private University, Amman, Jordan
AD  - Department of Clinical Pharmacy, Faculty of Pharmacy and Biomedical Sciences, Malaysian Allied Health Sciences Academy, Selangor, Jenjarom, 42610, Malaysia
AB  - Background: AI platforms are equipped with advanced algorithms that have the potential to offer a wide range of applications in healthcare services. However, information about the accuracy of AI chatbots against conventional drug-drug interaction tools is limited. This study aimed to assess the sensitivity, specificity, and accuracy of ChatGPT-3.5, ChatGPT-4, Bing AI, and Bard in predicting drug-drug interactions. Methods: AI-based chatbots (ie, ChatGPT-3.5, ChatGPT-4, Microsoft Bing AI, and Google Bard) were compared for their abilities to detect clinically relevant DDIs for 255 drug pairs. Descriptive statistics, such as specificity, sensitivity, accuracy, negative predictive value (NPV), and positive predictive value (PPV), were calculated for each tool. Results: When a subscription tool was used as a reference, the specificity ranged from a low of 0.372 (ChatGPT-3.5) to a high of 0.769 (Microsoft Bing AI). Also, Microsoft Bing AI had the highest performance with an accuracy score of 0.788, with ChatGPT-3.5 having the lowest accuracy rate of 0.469. There was an overall improvement in performance for all the programs when the reference tool switched to a free DDI source, but still, ChatGPT-3.5 had the lowest specificity (0.392) and accuracy (0.525), and Microsoft Bing AI demonstrated the highest specificity (0.892) and accuracy (0.890). When assessing the consistency of accuracy across two different drug classes, ChatGPT-3.5 and ChatGPT-4 showed the highest variability in accuracy. In addition, ChatGPT-3.5, ChatGPT-4, and Bard exhibited the highest fluctuations in specificity when analyzing two medications belonging to the same drug class. Conclusion: Bing AI had the highest accuracy and specificity, outperforming Google’s Bard, ChatGPT-3.5, and ChatGPT-4. The findings highlight the significant potential these AI tools hold in transforming patient care. While the current AI platforms evaluated are not without limitations, their ability to quickly analyze potentially significant interactions with good sensitivity suggests a promising step towards improved patient safety. © 2023 Al-Ashwal et al.
KW  - accuracy
KW  - Bard
KW  - Bing AI
KW  - ChatGPT
KW  - drug-drug interaction
KW  - patient safety
KW  - sensitivity
KW  - specificity
KW  - amfebutamone
KW  - amlodipine
KW  - atorvastatin
KW  - azithromycin
KW  - canagliflozin
KW  - citalopram
KW  - clarithromycin
KW  - clonazepam
KW  - clopidogrel
KW  - dapagliflozin
KW  - empagliflozin
KW  - ergocalciferol
KW  - escitalopram
KW  - ethinylestradiol
KW  - furosemide
KW  - hydrocodone
KW  - insulin glargine
KW  - levothyroxine
KW  - lisinopril
KW  - metformin
KW  - metoprolol
KW  - norethisterone
KW  - pantoprazole
KW  - paracetamol
KW  - potassium chloride
KW  - pravastatin
KW  - prednisone
KW  - rosuvastatin
KW  - salbutamol
KW  - trazodone
KW  - venlafaxine
KW  - accuracy
KW  - Article
KW  - artificial intelligence chatbot
KW  - Bard
KW  - Bing
KW  - ChatGPT
KW  - drug identification
KW  - drug interaction
KW  - evaluation study
KW  - prediction
KW  - predictive value
KW  - scoring system
KW  - sensitivity and specificity
PB  - Dove Medical Press Ltd
SN  - 11791365 (ISSN)
LA  - English
J2  - Drug Healthc. Patient Saf.
M3  - Article
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 4; Correspondence Address: F.Y. Al-Ashwal; Department of Clinical Pharmacy and Pharmacy Practice, Faculty of Pharmacy, University of Science and Technology, Sana’a, P.O.Box 13064, Yemen; email: fahmialashwal89@gmail.com
ER  -

TY  - CONF
AU  - Krauss, O.
AU  - Jungwirth, M.
AU  - Elflein, M.
AU  - Sandler, S.
AU  - Altenhofer, C.
AU  - Stoeckl, A.
TI  - Analyzing the Innovative Potential of Texts Generated by Large Language Models: An Empirical Evaluation
PY  - 2023
T2  - Communications in Computer and Information Science
VL  - 1872 CCIS
SP  - 11
EP  - 22
DO  - 10.1007/978-3-031-39689-2_2
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85171565451&doi=10.1007%2f978-3-031-39689-2_2&partnerID=40&md5=7befaf070e7870b53bb6da66ce8fea97
AD  - University of Applied Sciences Upper Austria, Campus Hagenberg, Softwarepark 11, Hagenberg, 4232, Austria
AD  - Advanced Information Systems and Technology, Hagenberg, Austria
AD  - Digital Media Department, Hagenberg, Austria
AB  - As large language models (LLMs) revolutionize natural language processing tasks, it remains uncertain whether the text they generate can be perceived as innovative by human readers. This question holds significant implications for innovation management, where the generation of novel ideas from extensive text corpora is crucial. In this study, we conduct an empirical evaluation of 2170 generated idea texts, containing product and service ideas in current trends for specific companies, focusing on three key metrics: innovativeness, context, and text quality. Our findings show that, while not universally applicable, a substantial number of LLM-generated ideas exhibit a degree of innovativeness. Remarkably, only 97 texts within the entire corpus were identified as highly innovative. Moving forward, an automated evaluation and filtering system to assess innovativeness could greatly support innovation management by facilitating the pre-selection of generated ideas. © 2023, The Author(s), under exclusive license to Springer Nature Switzerland AG.
KW  - Artificial Intelligence
KW  - Data Quality
KW  - Decision Support
KW  - Large Language Models
KW  - Artificial intelligence
KW  - Computational linguistics
KW  - Decision support systems
KW  - Natural language processing systems
KW  - Data quality
KW  - Decision supports
KW  - Empirical evaluations
KW  - Human readers
KW  - Innovation management
KW  - Innovativeness
KW  - Language model
KW  - Language processing
KW  - Large language model
KW  - Natural languages
KW  - Quality control
A2  - Kotsis G.
A2  - Khalil I.
A2  - Mashkoor A.
A2  - Sametinger J.
A2  - Tjoa A.M.
A2  - Moser B.
A2  - Khan M.
PB  - Springer Science and Business Media Deutschland GmbH
SN  - 18650929 (ISSN); 978-303139688-5 (ISBN)
LA  - English
J2  - Commun. Comput. Info. Sci.
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 0; Correspondence Address: O. Krauss; University of Applied Sciences Upper Austria, Hagenberg, Campus Hagenberg, Softwarepark 11, 4232, Austria; email: oliver.krauss@fh-hagenberg.at; Conference name: 34th International Conference on Database and Expert Systems Applications , DEXA 2023; Conference date: 28 August 2023 through 30 August 2023; Conference code: 299609
ER  -

TY  - JOUR
AU  - Farazouli, A.
AU  - Cerratto-Pargman, T.
AU  - Bolander-Laksov, K.
AU  - McGrath, C.
TI  - Hello GPT! Goodbye home examination? An exploratory study of AI chatbots impact on university teachers’ assessment practices
PY  - 2023
T2  - Assessment and Evaluation in Higher Education
DO  - 10.1080/02602938.2023.2241676
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85166200345&doi=10.1080%2f02602938.2023.2241676&partnerID=40&md5=df78b6e300e71a2937b87a27aa00bf41
AD  - Stockholm University, Stockholm, Sweden
AB  - AI chatbots have recently fuelled debate regarding education practices in higher education institutions worldwide. Focusing on Generative AI and ChatGPT in particular, our study examines how AI chatbots impact university teachers’ assessment practices, exploring teachers’ perceptions about how ChatGPT performs in response to home examination prompts in undergraduate contexts. University teachers (n = 24) from four different departments in humanities and social sciences participated in Turing Test-inspired experiments, where they blindly assessed student and ChatGPT-written responses to home examination questions. Additionally, we conducted semi-structured interviews in focus groups with the same teachers examining their reflections about the quality of the texts they assessed. Regarding chatbot-generated texts, we found a passing rate range across the cohort (37.5 − 85.7%) and a chatbot-written suspicion range (14–23%). Regarding the student-written texts, we identified patterns of downgrading, suggesting that teachers were more critical when grading student-written texts. Drawing on post-phenomenology and mediation theory, we discuss AI chatbots as a potentially disruptive technology in higher education practices. © 2023 The Author(s). Published by Informa UK Limited, trading as Taylor & Francis Group.
KW  - AI-chatbots
KW  - assessment
KW  - higher education
KW  - home examination
KW  - Turing test
PB  - Routledge
SN  - 02602938 (ISSN)
LA  - English
J2  - Assess. Eval. High. Educ.
M3  - Article
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 4; Correspondence Address: A. Farazouli; Stockholm University, Stockholm, Sweden; email: alexandra.farazouli@edu.su.se
ER  -

TY  - JOUR
AU  - Zuckerman, M.
AU  - Flood, R.
AU  - Tan, R.J.B.
AU  - Kelp, N.
AU  - Ecker, D.J.
AU  - Menke, J.
AU  - Lockspeiser, T.
TI  - ChatGPT for assessment writing
PY  - 2023
T2  - Medical Teacher
VL  - 45
IS  - 11
SP  - 1224
EP  - 1227
DO  - 10.1080/0142159X.2023.2249239
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85173549915&doi=10.1080%2f0142159X.2023.2249239&partnerID=40&md5=3ef69ca8a419703865f6f8b2fea7856e
AD  - University of Colorado Anschutz Medical Campus School of Medicine, Aurora, CO, United States
AD  - Department of Microbiology, Immunology, and Pathology, Colorado State University, Fort Collins, CO, United States
AD  - Department of Pediatrics, Children's Hospital Colorado, Aurora, CO, United States
AB  - What is the educational challenge? Medical schools invest significant resources into the creation of multiple-choice items for assessments. This process is costly and requires faculty training. Recently ChatGPT has been used in various areas to improve content creation efficiency, and it has otherwise been used to answer USMLE-style assessment items. What are the proposed solutions? We proposed the use of ChatGPT to create initial drafts of multiple-choice items. What are the potential benefits to a wider global audience? The use of ChatGPT to generate assessment items can decrease resources required, allowing for the creation of more items, and freeing-up faculty time to perform higher level assessment activities. ChatGPT is also able to consistently produce items using a standard format while adhering to item writing guidelines, which can be very challenging for faculty teams. What are the next steps? We plan to pilot ChatGPT drafted questions and compare item statistics for those written by ChatGPT with those written by our content experts. We also plan to further identify the types of questions that ChatGPT is most appropriate for, and incorporate media into assessment items (e.g. images, videos). © 2023 Informa UK Limited, trading as Taylor & Francis Group.
KW  - AI
KW  - artificial intelligence
KW  - Assessment
KW  - ChatGPT
KW  - medical education
KW  - Educational Status
KW  - Faculty
KW  - Humans
KW  - Schools, Medical
KW  - Videotape Recording
KW  - Writing
KW  - article
KW  - artificial intelligence
KW  - ChatGPT
KW  - human
KW  - medical education
KW  - medical school
KW  - practice guideline
KW  - videorecording
KW  - writing
KW  - educational status
KW  - medical school
KW  - university
KW  - writing
PB  - Taylor and Francis Ltd.
SN  - 0142159X (ISSN)
C2  - 37789636
LA  - English
J2  - Med. Teach.
M3  - Article
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 0; Correspondence Address: M. Zuckerman; University of Colorado Denver, Aurora, Anschutz Medical Campus School of Medicine, United States; email: matthew.zuckerman@ucdenver.edu; CODEN: MEDTD
ER  -

TY  - JOUR
AU  - Rosen, Z.P.
TI  - A BERT's Eye View: A Big Data Framework for Assessing Language Convergence and Accommodation
PY  - 2023
T2  - Journal of Language and Social Psychology
VL  - 42
IS  - 1
SP  - 60
EP  - 81
DO  - 10.1177/0261927X221095865
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85130221943&doi=10.1177%2f0261927X221095865&partnerID=40&md5=b11e9166d5096459c5e8576e8e506552
AD  - Communications Department, Saddleback Community College, 7703 Sagewood Dr., Huntington Beach, 92648, CA, United States
AB  - The current paper details a novel quantitative framework leveraging recent advances in AI and Natural Language Processing to quantitatively assess language convergence and accommodation. This new framework is computationally cheap and straightforward to implement. The framework is then applied to a case study of immigration rhetoric in the lead up to the 2016 general election in the USA. Major results from the case study show that (1) Democrats and Republicans exhibited significant language convergence with members of their own parties, (2) President Barack Obama and Hillary Clinton converged with Senate Democrats’ immigration rhetoric, (3) Democrats accommodated the immigration rhetoric of both President Barack Obama and (candidate) Hillary Clinton, (4) contrary to initial hypotheses, Donald Trump's vitriolic immigration rhetoric did not show signs of language convergence with Republicans in the Senate, and (5) equally surprising, Senate Republicans showed significant non-accommodation to Donald Trump despite potential political costs for having done so. © The Author(s) 2022.
KW  - accommodation
KW  - big data
KW  - computational modeling
KW  - convergence
KW  - immigration rhetoric
KW  - intergroup communication
KW  - social media
KW  - article
KW  - big data
KW  - computer model
KW  - election
KW  - human
KW  - human experiment
KW  - immigration
KW  - natural language processing
KW  - quantitative analysis
KW  - sign language
KW  - social media
PB  - SAGE Publications Inc.
SN  - 0261927X (ISSN)
LA  - English
J2  - J. Lang. Soc. Psychol.
M3  - Article
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 2; Correspondence Address: Z.P. Rosen; Communications Department, Saddleback Community College, Huntington Beach, 7703 Sagewood Dr., 92648, United States; email: zrosen@uci.edu
ER  -

TY  - CONF
AU  - Li, Q.
AU  - Li, X.
AU  - Song, Y.
AU  - Zhang, M.
AU  - Chen, L.
AU  - Wang, G.
AU  - Du, Y.
TI  - Evaluating BERT on cloud-edge time series forecasting and sentiment analysis via prompt learning
PY  - 2022
T2  - Proceedings - 24th IEEE International Conference on High Performance Computing and Communications, 8th IEEE International Conference on Data Science and Systems, 20th IEEE International Conference on Smart City and 8th IEEE International Conference on Dependability in Sensor, Cloud and Big Data Systems and Application, HPCC/DSS/SmartCity/DependSys 2022
SP  - 135
EP  - 142
DO  - 10.1109/HPCC-DSS-SmartCity-DependSys57074.2022.00051
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85152228520&doi=10.1109%2fHPCC-DSS-SmartCity-DependSys57074.2022.00051&partnerID=40&md5=287db5b22127843212065f999c04145c
AD  - School of Computer and Software Engineering, Xihua University, Chengdu, China
AB  - Existing pre-trained language models (PTLMs), like BERT, have shown their powerful ca-pabilities in many natural language processing tasks. In sequence analysis, such as time series forecasting, anomaly detection, and sentiment analysis, PTLMs have also achieved new state-of-the-art results. However, does this mean that PTLMs know sequence analysis? This paper explores whether BERT pre-trained on a large amount of data contains knowledge of sequence analysis. Specifically, we adopt prompt learning to see whether BERT will achieve good results on cloud-edge time series forecasting and sentiment analysis tasks. For the cloud-edge time series forecasting task, we give BERT some regular cloud-edge data and let it predict the features of the next time step; For the sentiment analysis task, we give BERT some sentence with sentiment and ask it what sentiment these sen-tences carry. Our experimental results reveal that: (1) BERT performs not well on the cloud-edge time series forecasting task, which means the logical reasoning of BERT is not good; (2) for sentiment analysis task, BERT with the prompt template performs poorly on both English and Chinese datasets; and (3) for sentiment analysis task, BERT appears to be more likely to perceive the text as carrying positive sentiment.  © 2022 IEEE.
KW  - BERT
KW  - pre-trained language models
KW  - prompt learning
KW  - sentiment analysis
KW  - time series forecasting
KW  - Anomaly detection
KW  - Computational linguistics
KW  - Forecasting
KW  - Learning systems
KW  - Time series
KW  - Time series analysis
KW  - Anomaly detection
KW  - BERT
KW  - Language model
KW  - Language processing
KW  - Natural languages
KW  - Pre-trained language model
KW  - Prompt learning
KW  - Sentiment analysis
KW  - Sequence analysis
KW  - Time series forecasting
KW  - Sentiment analysis
PB  - Institute of Electrical and Electronics Engineers Inc.
SN  - 979-835031993-4 (ISBN)
LA  - English
J2  - Proc. - IEEE Int. Conf. High Perform. Comput. Commun., IEEE Int. Conf. Data Sci. Syst., IEEE Int. Conf. Smart City IEEE Int. Conf. Dependability Sens., Cloud Big Data Syst. Appl., HPCC/DSS/SmartCity/DependSys
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 0; Correspondence Address: X. Li; School of Computer and Software Engineering, Xihua University, Chengdu, China; email: lixy@mail.xhu.edu.cn; Conference name: 24th IEEE International Conference on High Performance Computing and Communications, 8th IEEE International Conference on Data Science and Systems, 20th IEEE International Conference on Smart City and 8th IEEE International Conference on Dependability in Sensor, Cloud and Big Data Systems and Application, HPCC/DSS/SmartCity/DependSys 2022; Conference date: 18 December 2022 through 20 December 2022; Conference code: 187557
ER  -

TY  - JOUR
AU  - Nicolae, D.C.
AU  - Yadav, R.K.
AU  - Tufis, D.
TI  - Evaluation of Language Models on Romanian XQuAD and RoITD datasets
PY  - 2023
T2  - International Journal of Computers, Communications and Control
VL  - 18
IS  - 1
C7  - 5111
DO  - 10.15837/ijccc.2023.1.5111
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85154554219&doi=10.15837%2fijccc.2023.1.5111&partnerID=40&md5=bbfa62f4229a3bf510a3ba9a6a92f91e
AD  - Research Institute for Artificial Intelligence, Romanian Academy, Bucharest, 050711, Romania
AD  - Oslo, 0378, Norway
AB  - Natural language processing (NLP) has become a vital requirement in a wide range of applications, including machine translation, information retrieval, and text classification. The development and evaluation of NLP models for various languages have received significant attention in recent years, but there has been relatively little work done on comparing the performance of different language models on Romanian data. In particular, the introduction and evaluation of various Romanian language models with multilingual models have barely been comparatively studied. In this paper, we address this gap by evaluating eight NLP models on two Romanian datasets, XQuAD and RoITD. Our experiments and results show that bert-base-multilingual-cased and bertbase-multilingual-uncased, perform best on both XQuAD and RoITD tasks, while RoBERT-small model and DistilBERT models perform the worst. We also discuss the implications of our findings and outline directions for future work in this area. © 2023 by the authors. Licensee Agora University, Oradea, Romania.
KW  - DistilBert
KW  - NLP
KW  - Question Answering
KW  - RoBert
KW  - RoGPT
KW  - Transformer
PB  - Agora University
SN  - 18419836 (ISSN)
LA  - English
J2  - Int. J. Comput. Commun. Control
M3  - Article
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 0; Correspondence Address: D.C. Nicolae; Research Institute for Artificial Intelligence, Romanian Academy, Bucharest, 050711, Romania; email: dragosnicolae555@gmail.com
ER  -

TY  - JOUR
AU  - Oh, N.
AU  - Choi, G.-S.
AU  - Lee, W.Y.
TI  - ChatGPT goes to the operating room: evaluating GPT-4 performance and its potential in surgical education and training in the era of large language models
PY  - 2023
T2  - Annals of Surgical Treatment and Research
VL  - 104
IS  - 5
SP  - 269
EP  - 273
DO  - 10.4174/astr.2023.104.5.269
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85161805876&doi=10.4174%2fastr.2023.104.5.269&partnerID=40&md5=465660c601600268048c799d8b091749
AD  - Department of Surgery, Samsung Medical Center, Sungkyunkwan University School of Medicine, Seoul, South Korea
AB  - Purpose: This study aimed to assess the performance of ChatGPT, specifically the GPT-3.5 and GPT-4 models, in understanding complex surgical clinical information and its potential implications for surgical education and training. Methods: The dataset comprised 280 questions from the Korean general surgery board exams conducted between 2020 and 2022. Both GPT-3.5 and GPT-4 models were evaluated, and their performances were compared using McNemar test. Results: GPT-3.5 achieved an overall accuracy of 46.8%, while GPT-4 demonstrated a significant improvement with an overall accuracy of 76.4%, indicating a notable difference in performance between the models (P < 0.001). GPT-4 also exhibited consistent performance across all subspecialties, with accuracy rates ranging from 63.6% to 83.3%. Conclusion: ChatGPT, particularly GPT-4, demonstrates a remarkable ability to understand complex surgical clinical information, achieving an accuracy rate of 76.4% on the Korean general surgery board exam. However, it is important to recognize the limitations of large language models and ensure that they are used in conjunction with human expertise and judgment. Copyright © 2023, the Korean Surgical Society.
KW  - Artificial intelligence
KW  - Continuing medical education
KW  - General surgery
KW  - Medical education
PB  - Korean Surgical Society
SN  - 22886575 (ISSN)
LA  - English
J2  - Ann. Surg. Treat. Res.
M3  - Article
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 24; Correspondence Address: W.Y. Lee; Department of Surgery, Samsung Medical Center, Sungkyunkwan University School of Medicine, Seoul, 81 Irwon-ro, Gangnam-gu, 06351, South Korea; email: wooyong123.lee@samsung.com
ER  -

TY  - CONF
AU  - Vaithilingam, P.
AU  - Zhang, T.
AU  - Glassman, E.L.
TI  - Expectation vs. Experience: Evaluating the Usability of Code Generation Tools Powered by Large Language Models
PY  - 2022
T2  - Conference on Human Factors in Computing Systems - Proceedings
C7  - 332
DO  - 10.1145/3491101.3519665
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85129746503&doi=10.1145%2f3491101.3519665&partnerID=40&md5=e054537e8feb67a3f5285eda80638aae
AD  - Harvard University, United States
AD  - Purdue University, United States
AB  - Recent advances in Large Language Models (LLM) have made automatic code generation possible for real-world programming tasks in general-purpose programming languages such as Python. However, there are few human studies on the usability of these tools and how they fit the programming workflow. In this work, we conducted a within-subjects user study with 24 participants to understand how programmers use and perceive Copilot, a LLM-based code generation tool. We found that, while Copilot did not necessarily improve the task completion time or success rate, most participants preferred to use Copilot in daily programming tasks, since Copilot often provided a useful starting point and saved the effort of searching online. However, participants did face difficulties in understanding, editing, and debugging code snippets generated by Copilot, which significantly hindered their task-solving effectiveness. Finally, we highlighted several promising directions for improving the design of Copilot based on our observations and participants' feedback. © 2022 ACM.
KW  - github copilot
KW  - large language model
KW  - Codes (symbols)
KW  - Computational linguistics
KW  - Python
KW  - Automatic code generations
KW  - Code generation tools
KW  - General-purpose programming language
KW  - Github copilot
KW  - Human study
KW  - Language model
KW  - Large language model
KW  - Programming tasks
KW  - Real-world
KW  - Work-flows
KW  - Automatic programming
PB  - Association for Computing Machinery
SN  - 978-145039156-6 (ISBN)
LA  - English
J2  - Conf Hum Fact Comput Syst Proc
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 66; Conference name: 2022 CHI Conference on Human Factors in Computing Systems, CHI EA 2022; Conference date: 30 April 2022 through 5 May 2022; Conference code: 179030
ER  -

TY  - CONF
AU  - Lymperaiou, M.
AU  - Manoliadis, G.
AU  - Mastromichalakis, O.M.
AU  - Dervakos, E.G.
AU  - Stamou, G.
TI  - Towards explainable evaluation of language models on the semantic similarity of visual concepts
PY  - 2022
T2  - Proceedings - International Conference on Computational Linguistics, COLING
VL  - 29
IS  - 1
SP  - 3639
EP  - 3658
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85165758082&partnerID=40&md5=cfc266fc093e09436ac0464c232b4c5d
AD  - Artificial Intelligence and Learning Systems Laboratory, School of Electrical and Computer Engineering, National Technical University of Athens, Greece
AB  - Recent breakthroughs in NLP research, such as the advent of Transformer models have indisputably contributed to major advancements in several tasks. However, few works research robustness and explainability issues of their evaluation strategies. In this work, we examine the behavior of high-performing pre-trained language models, focusing on the task of semantic similarity for visual vocabularies. First, we address the need for explainable evaluation metrics, necessary for understanding the conceptual quality of retrieved instances. Our proposed metrics provide valuable insights in local and global level, showcasing the inabilities of widely used approaches. Secondly, adversarial interventions on salient query semantics expose vulnerabilities of opaque metrics and highlight patterns in learned linguistic representations. © 2022 Proceedings - International Conference on Computational Linguistics, COLING. All rights reserved.
KW  - Computational linguistics
KW  - Natural language processing systems
KW  - Quality control
KW  - Visual languages
KW  - Evaluation metrics
KW  - Evaluation strategies
KW  - Language model
KW  - Linguistic representations
KW  - Query semantics
KW  - Semantic similarity
KW  - Transformer modeling
KW  - Visual concept
KW  - Visual vocabularies
KW  - Semantics
A2  - Calzolari N.
A2  - Huang C.-R.
A2  - Kim H.
A2  - Pustejovsky J.
A2  - Wanner L.
A2  - Choi K.-S.
A2  - Ryu P.-M.
A2  - Chen H.-H.
A2  - Donatelli L.
A2  - Ji H.
A2  - Kurohashi S.
A2  - Paggio P.
A2  - Paggio P.
A2  - Xue N.
A2  - Kim S.
A2  - Hahm Y.
A2  - He Z.
A2  - Lee T.K.
A2  - Santus E.
A2  - Bond F.
A2  - Na S.-H.
PB  - Association for Computational Linguistics (ACL)
SN  - 29512093 (ISSN)
LA  - English
J2  - Proc. Main Conf. Int. Conf. Comput. Linguist., COLING
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 2; Conference name: 29th International Conference on Computational Linguistics, COLING 2022; Conference date: 12 October 2022 through 17 October 2022; Conference code: 186893
ER  -

TY  - JOUR
AU  - Chu, M.-N.
TI  - Assessing the Benefits of ChatGPT for Business: An Empirical Study on Organizational Performance
PY  - 2023
T2  - IEEE Access
VL  - 11
SP  - 76427
EP  - 76436
DO  - 10.1109/ACCESS.2023.3297447
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85165402814&doi=10.1109%2fACCESS.2023.3297447&partnerID=40&md5=6a75618a8e89824c171c5ad0b47b96ba
AD  - Hoseo University, Student Scholarship Team, Asan-si, 31499, South Korea
AB  - Companies strive to cultivate an innovative and creative organizational culture that bolsters organizational performance. In this context, businesses have started introducing ChatGPT to their users. For this investigation, the DeLone and McLean's Information Systems Success model (D&M IS) was employed. This study explored the factors that influence user satisfaction and benefits related to the three quality components of ChatGPT: system quality, information quality, and service quality. It also examined whether these components positively impact organizational performance. A total of 361 questionnaires from actual businesses were collected and analyzed using structural equation modeling. The survey revealed that the system quality, information quality, and service quality of ChatGPT have favorable impacts on user satisfaction and benefits. Among these, service quality exerted the most significant impact. However, the moderating effect of a flexible organizational culture was not evident. Our study contributes to the knowledge base regarding how the system, information, and service quality of ChatGPT influence productivity within an organization. As the ChatGPT system is still in its nascent stage, it currently does not have a substantial impact on the flexible organizational culture. However, as it evolves and reaches a specific and higher level in the future, it may play a significant role in enhancing long-term organizational performance. © 2013 IEEE.
KW  - benefit
KW  - ChatGPT
KW  - D&M IS
KW  - flexible organizational culture
KW  - information quality
KW  - organizational performance
KW  - satisfaction
KW  - service quality
KW  - system quality
KW  - Information analysis
KW  - Interactive computer systems
KW  - Knowledge based systems
KW  - Quality of service
KW  - Reliability
KW  - Benefit
KW  - Chatbots
KW  - ChatGPT
KW  - D&M IS
KW  - Data integrity
KW  - Flexible organizational culture
KW  - Information integrity
KW  - Information quality
KW  - Organizational aspects
KW  - Organizational cultures
KW  - Organizational performance
KW  - Performances evaluation
KW  - Real - Time system
KW  - Satisfaction
KW  - Service Quality
KW  - System quality
KW  - Real time systems
PB  - Institute of Electrical and Electronics Engineers Inc.
SN  - 21693536 (ISSN)
LA  - English
J2  - IEEE Access
M3  - Article
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 2; Correspondence Address: M.-N. Chu; Hoseo University, Student Scholarship Team, Asan-si, 31499, South Korea; email: mina0921@hoseo.edu
ER  -

TY  - CONF
AU  - Cao, Y.
AU  - Zhou, L.
AU  - Lee, S.
AU  - Cabello, L.
AU  - Chen, M.
AU  - Hershcovich, D.
TI  - Assessing Cross-Cultural Alignment between ChatGPT and Human Societies: An Empirical Study
PY  - 2023
T2  - EACL 2023 - Cross-Cultural Considerations in NLP @ EACL, Proceedings of the Workshop
SP  - 53
EP  - 67
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85162113418&partnerID=40&md5=e64e130fec1ebb207ca964baf9695fa4
AD  - Huazhong University of Science and Technology, China
AD  - Department of Computer Science, University of Copenhagen, Denmark
AD  - University of Electronic Science and Technology of China, China
AD  - Technical University of Darmstadt, Germany
AD  - School of Computer Science and Engineering, South China University of Technology, China
AB  - The recent release of ChatGPT has garnered widespread recognition for its exceptional ability to generate human-like responses in dialogue. Given its usage by users from various nations and its training on a vast multilingual corpus that incorporates diverse cultural and societal norms, it is crucial to evaluate its effectiveness in cultural adaptation. In this paper, we investigate the underlying cultural background of ChatGPT by analyzing its responses to questions designed to quantify human cultural differences. Our findings suggest that, when prompted with American context, ChatGPT exhibits a strong alignment with American culture, but it adapts less effectively to other cultural contexts. Furthermore, by using different prompts to probe the model, we show that English prompts reduce the variance in model responses, flattening out cultural differences and biasing them towards American culture. This study provides valuable insights into the cultural implications of ChatGPT and highlights the necessity of greater diversity and cultural awareness in language technologies. © 2023 Association for Computational Linguistics.
KW  - Cultural awareness
KW  - Cultural backgrounds
KW  - Cultural context
KW  - Cultural difference
KW  - Cultural Implications
KW  - Empirical studies
KW  - Human like
KW  - Human society
KW  - Language technology
KW  - Model response
PB  - Association for Computational Linguistics
SN  - 978-195942951-7 (ISBN)
LA  - English
J2  - EACL - Cross-Cult. Consid. NLP EACL, Proc. Workshop
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 3; Conference name: 1st Workshop on Cross-Cultural Considerations in NLP, C3NLP 2023; Conference code: 192794
ER  -

TY  - CONF
AU  - Singhal, P.
AU  - Forristal, J.
AU  - Ye, X.
AU  - Durrett, G.
TI  - Assessing Out-of-Domain Language Model Performance from Few Examples
PY  - 2023
T2  - EACL 2023 - 17th Conference of the European Chapter of the Association for Computational Linguistics, Proceedings of the Conference
SP  - 2377
EP  - 2389
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85159862154&partnerID=40&md5=7b5c628320d53da8dd584315d78be2bb
AD  - Department of Computer Science, The University of Texas, Austin, United States
AB  - While pretrained language models have exhibited impressive generalization capabilities, they still behave unpredictably under certain domain shifts. In particular, a model may learn a reasoning process on in-domain training data that does not hold for out-of-domain test data. We address the task of predicting out-of-domain (OOD) performance in a few-shot fashion: given a few target-domain examples and a set of models with similar training performance, can we understand how these models will perform on OOD test data? We start from the baseline of looking at model accuracy on the few-shot examples, then investigate how to incorporate analysis of the models' behavior using feature attributions to improve our understanding of generalization. Specifically, we explore a set of “factors” designed to reveal model agreement with certain pathological heuristics that may indicate worse generalization capabilities. On textual entailment, paraphrase recognition, and a synthetic classification task, we show that attribution-based factors can help rank relative model OOD performance. However, accuracy on a few-shot test set is a surprisingly strong baseline, particularly when the system designer does not have in-depth prior knowledge about the domain shift. © 2023 Association for Computational Linguistics.
KW  - Classification (of information)
KW  - Domain language
KW  - Generalization capability
KW  - Language model
KW  - Learn+
KW  - Modeling performance
KW  - Performance
KW  - Reasoning process
KW  - Target domain
KW  - Test data
KW  - Training data
KW  - Computational linguistics
PB  - Association for Computational Linguistics (ACL)
SN  - 978-195942944-9 (ISBN)
LA  - English
J2  - EACL - Conf. Eur. Chapter Assoc. Comput. Linguist., Proc. Conf.
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 0; Conference name: 17th Conference of the European Chapter of the Association for Computational Linguistics, EACL 2023; Conference date: 2 May 2023 through 6 May 2023; Conference code: 188424
ER  -

TY  - CONF
AU  - Eklund, A.
AU  - Forsman, M.
TI  - Topic Modeling by Clustering Language Model Embeddings: Human Validation on an Industry Dataset
PY  - 2022
T2  - EMNLP 2022 - Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing: Industry Track
SP  - 645
EP  - 653
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85152892684&partnerID=40&md5=6d33862003a55611d976ac727dc49651
AD  - Umeå University, Adlede AB, Umeå, Sweden
AD  - Adlede AB, Umeå, Sweden
AB  - Topic models are powerful tools to get an overview of large collections of text data, a situation that is prevalent in industry applications. A rising trend within topic modeling is to directly cluster dimension-reduced embeddings created with pretrained language models. It is difficult to evaluate these models because there is no ground truth and automatic measurements may not mimic human judgment. To address this problem, we created a tool called STELLAR for interactive topic browsing which we used for human evaluation of topics created from a real-world dataset used in industry. Embeddings created with BERT were used together with UMAP and HDBSCAN to model the topics. The human evaluation found that our topic model creates coherent topics. The following discussion revolves around the requirements of industry and what research is needed for production-ready systems. © 2022 Association for Computational Linguistics.
KW  - Computational linguistics
KW  - Modeling languages
KW  - Automatic measurements
KW  - Clusterings
KW  - Embeddings
KW  - Ground truth
KW  - Human evaluation
KW  - Industry applications
KW  - Language model
KW  - Model embedding
KW  - Text data
KW  - Topic Modeling
KW  - Embeddings
PB  - Association for Computational Linguistics (ACL)
SN  - 978-195214825-5 (ISBN)
LA  - English
J2  - EMNLP - Proc. Conf. Empir. Methods Nat. Lang. Process.: Ind. Track
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 1; Conference name: 2022 Conference on Empirical Methods in Natural Language Processing, EMNLP 2022; Conference date: 7 December 2022 through 11 December 2022; Conference code: 187661
ER  -

TY  - JOUR
AU  - de-Dios-Flores, I.
AU  - Garcia, M.
TI  - A computational psycholinguistic evaluation of the syntactic abilities of Galician BERT models at the interface of dependency resolution and training time
ST  - Una evaluación psicolingüístico-computacional de las capacidades sintácticas de los modelos BERT para el gallego en la intersección entre la resolución de dependencias y el tiempo de entrenamiento
PY  - 2022
T2  - Procesamiento del Lenguaje Natural
VL  - 69
SP  - 15
EP  - 26
DO  - 10.26342/2022-69-1
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85144393120&doi=10.26342%2f2022-69-1&partnerID=40&md5=9cf31090f16ea85bd9b35f19e3881ddb
AD  - Centro Singular de Investigación en Tecnoloxías Intelixentes (CiTIUS), Spain
AD  - Universidade de Santiago de Compostela, Spain
AB  - This paper explores the ability of Transformer models to capture subject-verb and noun-adjective agreement dependencies in Galician. We conduct a series of word prediction experiments in which we manipulate dependency length together with the presence of an attractor noun that acts as a lure. First, we evaluate the overall performance of the existing monolingual and multilingual models for Galician. Secondly, to observe the effects of the training process, we compare the different degrees of achievement of two monolingual BERT models at different training points. We also release their checkpoints and propose an alternative evaluation metric. Our results confirm previous findings by similar works that use the agreement prediction task and provide interesting insights into the number of training steps required by a Transformer model to solve long-distance dependencies. © 2022 Sociedad Espanola para el Procesamiento del Lenguaje Natural. All rights reserved.
KW  - agreement dependencies
KW  - BERT models
KW  - Galician
KW  - targeted syntactic evaluation
PB  - Sociedad Espanola para el Procesamiento del Lenguaje Natural
SN  - 11355948 (ISSN)
LA  - English
J2  - Proces. Lenguaje Nat.
M3  - Article
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 2
ER  -

TY  - JOUR
AU  - Tao, L.
AU  - Wang, Z.
AU  - Lei, Q.
AU  - Chen, K.
AU  - Yang, W.
AU  - Miao, S.
TI  - A Transformer Fault Evolution Evaluation Model Based on Coupling of Polynary Physical Fields
ST  - 一种基于多元物理场耦合的变压器故障演化评估模型
PY  - 2022
T2  - Modern Electric Power
VL  - 39
IS  - 5
SP  - 605
EP  - 614
DO  - 10.19725/j.cnki.1007-2322.2021.0205
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85183153889&doi=10.19725%2fj.cnki.1007-2322.2021.0205&partnerID=40&md5=97f07f4996ba4a858ef029a55eadebeb
AD  - China Railway Siyuan Survey and Design Group Co Ltd, Hubei Province, Wuhan, 430063, China
AD  - State Key Laboratory of Advanced Electromagnetic Engineering and Technology, Huazhong University of Science and Technology), Hubei Province, Wuhan, 430074, China
AD  - Hubei Electric Power Security and High Efficiency Key Laboratory, Huazhong University of Science and Technology), Hubei Province, Wuhan, 430074, China
AB  - As important equipment in power system, the trouble prevention and life management of transformer are of important significance for improving the reliability of power system operation. To implement the high-efficiency assessment on the fault state of transformer equipment, starting from the correlation and complexity characteristics of the transformer fault mechanism, a transformer fault state assessment model based on the coupling of polynary physical fields and fuzzy number theory was established. Firstly, based on the correlation characteristics of transformer faults, a network diagram of transformer fault evolution was established. Secondary, considering the complexity of transformer failure mechanism and limited monitoring data, the COMSOL software was utilized to carry out the coupling simulation of polynary physical field. Thirdly, combining with fuzzy number theory, an evolutionary probability calculation model for transformer faults was built. Finally, led in the risk entropy to characterize the uncertainty in transformer fault evolution, and the maximum probability expression of transformer fault evolution path was proposed and translated into a linear programming problem, and then the maximum probability fault evolution path of transformer under different initial risk factors was obtained. Results of analysis on computing example show that the calculation results by the built model can effectively reflect the feature of transformer fault statistic data, thus it can provide important reference for the state assessment of transformer. © 2023 Modern Electric Power. All rights reserved.
KW  - COMSOL
KW  - fault evolution
KW  - fuzzy number theory
KW  - polynary physical field
KW  - state assessment
PB  - Editorial Department of Modern Electric Power
SN  - 10072322 (ISSN)
LA  - Chinese
J2  - Mod. Electr. Power
M3  - Article
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 0
ER  -

TY  - JOUR
AU  - Nikolic, S.
AU  - Daniel, S.
AU  - Haque, R.
AU  - Belkina, M.
AU  - Hassan, G.M.
AU  - Grundy, S.
AU  - Lyden, S.
AU  - Neal, P.
AU  - Sandison, C.
TI  - ChatGPT versus engineering education assessment: a multidisciplinary and multi-institutional benchmarking and analysis of this generative artificial intelligence tool to investigate assessment integrity
PY  - 2023
T2  - European Journal of Engineering Education
VL  - 48
IS  - 4
SP  - 559
EP  - 614
DO  - 10.1080/03043797.2023.2213169
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85160255270&doi=10.1080%2f03043797.2023.2213169&partnerID=40&md5=87f25130cabdc603b8681bfd455fbccc
AD  - Faculty of Engineering and Information Sciences, University of Wollongong, Wollongong, Australia
AD  - School of Professional Practice & Leadership, University of Technology Sydney, Sydney, Australia
AD  - School of Science, Technology and Engineering, University of the Sunshine Coast, Sippy Downs, Australia
AD  - College, Western Sydney University, Sydney, Australia
AD  - School of Computer Science & Software Engineering, University of Western Australia, Perth, Australia
AD  - School of Chemical Engineering, University of New South Wales, Sydney, Australia
AD  - School of Engineering, University of Tasmania, Hobart, Australia
AB  - ChatGPT, a sophisticated online chatbot, sent shockwaves through many sectors once reports filtered through that it could pass exams. In higher education, it has raised many questions about the authenticity of assessment and challenges in detecting plagiarism. Amongst the resulting frenetic hubbub, hints of potential opportunities in how ChatGPT could support learning and the development of critical thinking have also emerged. In this paper, we examine how ChatGPT may affect assessment in engineering education by exploring ChatGPT responses to existing assessment prompts from ten subjects across seven Australian universities. We explore the strengths and weaknesses of current assessment practice and discuss opportunities on how ChatGPT can be used to facilitate learning. As artificial intelligence is rapidly improving, this analysis sets a benchmark for ChatGPT’s performance as of early 2023 in responding to engineering education assessment prompts. ChatGPT did pass some subjects and excelled with some assessment types. Findings suggest that changes in current practice are needed, as typically with little modification to the input prompts, ChatGPT could generate passable responses to many of the assessments, and it is only going to get better as future versions are trained on larger data sets. © 2023 The Author(s). Published by Informa UK Limited, trading as Taylor & Francis Group.
KW  - Artificial intelligence (AI)
KW  - assessment
KW  - ChatGPT
KW  - engineering education
KW  - GPT-3
KW  - integrity
KW  - Artificial intelligence
KW  - Benchmarking
KW  - Artificial intelligence
KW  - Artificial intelligence tools
KW  - Assessment
KW  - Chatbots
KW  - ChatGPT
KW  - Detecting plagiarism
KW  - GPT-3
KW  - High educations
KW  - Integrity
KW  - Support learning
KW  - Engineering education
PB  - Taylor and Francis Ltd.
SN  - 03043797 (ISSN)
LA  - English
J2  - Eur. J. Eng. Educ.
M3  - Article
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 19; Correspondence Address: S. Nikolic; Faculty of Engineering and Information Sciences, University of Wollongong, Wollongong, Australia; email: sasha@uow.edu.au
ER  -

TY  - CONF
AU  - Margatina, K.
AU  - Wang, S.
AU  - Vyas, Y.
AU  - John, N.A.
AU  - Benajiba, Y.
AU  - Ballesteros, M.
TI  - Dynamic Benchmarking of Masked Language Models on Temporal Concept Drift with Multiple Views
PY  - 2023
T2  - EACL 2023 - 17th Conference of the European Chapter of the Association for Computational Linguistics, Proceedings of the Conference
SP  - 2873
EP  - 2890
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85159851533&partnerID=40&md5=2c02d301fd985a4549aaad3a2bcd223e
AD  - University of Sheffield, United Kingdom
AD  - AWS AI Labs
AB  - Temporal concept drift refers to the problem of data changing over time. In NLP, that would entail that language (e.g. new expressions, meaning shifts) and factual knowledge (e.g. new concepts, updated facts) evolve over time. Focusing on the latter, we benchmark 11 pretrained masked language models (MLMs) on a series of tests designed to evaluate the effect of temporal concept drift, as it is crucial that widely used language models remain up-to-date with the ever-evolving factual updates of the real world. Specifically, we provide a holistic framework that (1) dynamically creates temporal test sets of any time granularity (e.g. month, quarter, year) of factual data from Wikidata, (2) constructs fine-grained splits of tests (e.g. updated, new, unchanged facts) to ensure comprehensive analysis, and (3) evaluates MLMs in three distinct ways (single-token probing, multi-token generation, MLM scoring). In contrast to prior work, our framework aims to unveil how robust an MLM is over time and thus to provide a signal in case it has become outdated, by leveraging multiple views of evaluation. © 2023 Association for Computational Linguistics.
KW  - Concept drifts
KW  - Factual knowledge
KW  - Holistic frameworks
KW  - Language model
KW  - Multiple views
KW  - Real-world
KW  - Shift-and
KW  - Temporal concepts
KW  - Test sets
KW  - Time granularities
KW  - Computational linguistics
PB  - Association for Computational Linguistics (ACL)
SN  - 978-195942944-9 (ISBN)
LA  - English
J2  - EACL - Conf. Eur. Chapter Assoc. Comput. Linguist., Proc. Conf.
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 3; Correspondence Address: K. Margatina; University of Sheffield, United Kingdom; email: k.margatina@sheffield.ac.uk; Conference name: 17th Conference of the European Chapter of the Association for Computational Linguistics, EACL 2023; Conference date: 2 May 2023 through 6 May 2023; Conference code: 188424
ER  -

TY  - CONF
AU  - Veseli, B.
AU  - Singhania, S.
AU  - Razniewski, S.
AU  - Weikum, G.
TI  - Evaluating Language Models for Knowledge Base Completion
PY  - 2023
T2  - Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)
VL  - 13870 LNCS
SP  - 227
EP  - 243
DO  - 10.1007/978-3-031-33455-9_14
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85163296014&doi=10.1007%2f978-3-031-33455-9_14&partnerID=40&md5=3758e432c42ea1d5770988372956f9d8
AD  - Max Planck Institute for Informatics, Saarbrücken, Germany
AD  - Bosch Center for AI, Renningen, Germany
AB  - Structured knowledge bases (KBs) are a foundation of many intelligent applications, yet are notoriously incomplete. Language models (LMs) have recently been proposed for unsupervised knowledge base completion (KBC), yet, despite encouraging initial results, questions regarding their suitability remain open. Existing evaluations often fall short because they only evaluate on popular subjects, or sample already existing facts from KBs. In this work, we introduce a novel, more challenging benchmark dataset, and a methodology tailored for a realistic assessment of the KBC potential of LMs. For automated assessment, we curate a dataset called WD-Known, which provides an unbiased random sample of Wikidata, containing over 3.9 million facts. In a second step, we perform a human evaluation on predictions that are not yet in the KB, as only this provides real insights into the added value over existing KBs. Our key finding is that biases in dataset conception of previous benchmarks lead to a systematic overestimate of LM performance for KBC. However, our results also reveal strong areas of LMs. We could, for example, perform a significant completion of Wikidata on the relations nativeLanguage, by a factor of ∼ 21 (from 260k to 5.8M) at 82 % precision, and citizenOf by a factor of ∼ 0.3 (from 4.2M to 5.3M) at 90% precision. Moreover, we find that LMs possess surprisingly strong generalization capabilities: even on relations where most facts were not directly observed in LM training, prediction quality can be high. We open-source the benchmark dataset and code. (https://github.com/bveseli/LMsForKBC ). © 2023, The Author(s), under exclusive license to Springer Nature Switzerland AG.
KW  - Benchmarking
KW  - Computational linguistics
KW  - Open systems
KW  - Added values
KW  - Automated assessment
KW  - Benchmark datasets
KW  - Generalization capability
KW  - Human evaluation
KW  - Intelligent applications
KW  - Language model
KW  - Modeling performance
KW  - Random sample
KW  - Structured knowledge
KW  - Knowledge based systems
A2  - Pesquita C.
A2  - Faria D.
A2  - Jimenez-Ruiz E.
A2  - McCusker J.
A2  - Dragoni M.
A2  - Dimou A.
A2  - Troncy R.
A2  - Hertling S.
PB  - Springer Science and Business Media Deutschland GmbH
SN  - 03029743 (ISSN); 978-303133454-2 (ISBN)
LA  - English
J2  - Lect. Notes Comput. Sci.
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 4; Correspondence Address: B. Veseli; Max Planck Institute for Informatics, Saarbrücken, Germany; email: bveseli@mpi-inf.mpg.de; Conference name: 20th International Conference on The Semantic Web, ESWC 2023; Conference date: 28 May 2023 through 1 June 2023; Conference code: 295309
ER  -

TY  - CONF
AU  - Chiang, C.-H.
AU  - Lee, H.-Y.
TI  - Can Large Language Models Be an Alternative to Human Evaluation?
PY  - 2023
T2  - Proceedings of the Annual Meeting of the Association for Computational Linguistics
VL  - 1
SP  - 15607
EP  - 15631
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85161938952&partnerID=40&md5=f6c30e172aab077bf9f81e9dde36aa4d
AD  - National Taiwan University, Taiwan
AB  - Human evaluation is indispensable and inevitable for assessing the quality of texts generated by machine learning models or written by humans. However, human evaluation is very difficult to reproduce and its quality is notoriously unstable, hindering fair comparisons among different natural language processing (NLP) models and algorithms. Recently, large language models (LLMs) have demonstrated exceptional performance on unseen tasks when only the task instructions are provided. In this paper, we explore if such an ability of the LLMs can be used as an alternative to human evaluation. We present the LLMs with the exact same instructions, samples to be evaluated, and questions used to conduct human evaluation, and then ask the LLMs to generate responses to those questions; we dub this LLM evaluation. We use human evaluation and LLM evaluation to evaluate the texts in two NLP tasks: open-ended story generation and adversarial attacks. We show that the result of LLM evaluation is consistent with the results obtained by expert human evaluation: the texts rated higher by human experts are also rated higher by the LLMs. We also find that the results of LLM evaluation are stable over different formatting of the task instructions and the sampling algorithm used to generate the answer. We are the first to show the potential of using LLMs to assess the quality of texts and discuss the limitations and ethical considerations of LLM evaluation. © 2023 Association for Computational Linguistics.
KW  - Computational linguistics
KW  - Natural language processing systems
KW  - Human evaluation
KW  - Language model
KW  - Language processing
KW  - Machine learning models
KW  - Model and algorithms
KW  - Model evaluation
KW  - Natural languages
KW  - Performance
KW  - Processing algorithms
KW  - Processing model
KW  - Quality control
PB  - Association for Computational Linguistics (ACL)
SN  - 0736587X (ISSN); 978-195942972-2 (ISBN)
LA  - English
J2  - Proc. Annu. Meet. Assoc. Comput Linguist.
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 5; Conference name: 61st Annual Meeting of the Association for Computational Linguistics, ACL 2023; Conference date: 9 July 2023 through 14 July 2023; Conference code: 192160
ER  -

TY  - JOUR
AU  - Sarma, G.V.S.S.N.S.
AU  - Reddy, B.R.
AU  - Nirgude, P.M.
AU  - Naidu, P.V.
TI  - Performance Assessment of Customized LSTM based Deep Learning Model for Predictive Maintenance of Transformer
PY  - 2023
T2  - International Journal of Electrical and Electronics Research
VL  - 11
IS  - 2
SP  - 389
EP  - 400
DO  - 10.37391/ijeer.110220
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85162818098&doi=10.37391%2fijeer.110220&partnerID=40&md5=fb872680a234781d4139b9406269fd41
AD  - JNTUH, Hyderabad, India
AD  - Jawaharlal Nehru Technological University Hyderabad (JNTUH University), Hyderabad, India
AD  - UHV Research Laboratory, CPRI, Hyderabad, India
AD  - Department of Electrical and Electronics Engineering, Matrusri Engineering College, Saidabad, Hyderabad, India
AB  - To improve predictive maintenance of transformers with small DGA datasets, customized LSTM network named C-LSTM is devised to circumvent the boundaries of the standard-LSTM network, which had an increased rate of classification error than conventional machine learning techniques. The study compares the performance of traditional machine learning algorithms with the customized LSTM model using various metrics such as validation accuracy, test accuracy, precision, recall, and F1-score. Additionally, the comparison includes the evaluation of seven fault detecting diagnostic techniques, including discharges of low/high energy, thermal/electrical faults, partial discharge, and low/medium/high thermal faults. The results indicate that the customized LSTM model outperforms traditional machine learning methods with a validation accuracy of 100% and a test accuracy of 98.57%. © 2023 by the G V S S N Srirama Sarma, B Ravindranath Reddy, Pradeep M Nirgude and P Vasudeva Naidu. Submitted for possible.
KW  - ANN
KW  - C-LSTM
KW  - Decision Tree
KW  - DGA
KW  - Duval Triangle method
KW  - LSTM
KW  - SVM
PB  - Forex Publication
SN  - 2347470X (ISSN)
LA  - English
J2  - Int. J. Electr. Electron. Res.
M3  - Article
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 0; Correspondence Address: G.V.S.S.N.S. Sarma; JNTUH, Hyderabad, India; email: music.sarma2016@gmail.com
ER  -

TY  - JOUR
AU  - Gilson, A.
AU  - Safranek, C.W.
AU  - Huang, T.
AU  - Socrates, V.
AU  - Chi, L.
AU  - Taylor, R.A.
AU  - Chartash, D.
TI  - How Does ChatGPT Perform on the United States Medical Licensing Examination? The Implications of Large Language Models for Medical Education and Knowledge Assessment
PY  - 2023
T2  - JMIR Medical Education
VL  - 9
C7  - e45312
DO  - 10.2196/45312
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85148992575&doi=10.2196%2f45312&partnerID=40&md5=a70a9b11b70f9182a6b1a9ed24dc5122
AD  - Section for Biomedical Informatics and Data Science, Yale University School of Medicine, New Haven, CT, United States
AD  - Department of Emergency Medicine, Yale University School of Medicine, New Haven, CT, United States
AD  - Program of Computational Biology and Bioinformatics, Yale University, New Haven, CT, United States
AD  - School of Medicine, University College Dublin, National University of Ireland, Dublin, Ireland
AB  - Background: Chat Generative Pre-trained Transformer (ChatGPT) is a 175-billion-parameter natural language processing model that can generate conversation-style responses to user input. Objective: This study aimed to evaluate the performance of ChatGPT on questions within the scope of the United States Medical Licensing Examination Step 1 and Step 2 exams, as well as to analyze responses for user interpretability. Methods: We used 2 sets of multiple-choice questions to evaluate ChatGPT’s performance, each with questions pertaining to Step 1 and Step 2. The first set was derived from AMBOSS, a commonly used question bank for medical students, which also provides statistics on question difficulty and the performance on an exam relative to the user base. The second set was the National Board of Medical Examiners (NBME) free 120 questions. ChatGPT’s performance was compared to 2 other large language models, GPT-3 and InstructGPT. The text output of each ChatGPT response was evaluated across 3 qualitative metrics: logical justification of the answer selected, presence of information internal to the question, and presence of information external to the question. Results: Of the 4 data sets, AMBOSS-Step1, AMBOSS-Step2, NBME-Free-Step1, and NBME-Free-Step2, ChatGPT achieved accuracies of 44% (44/100), 42% (42/100), 64.4% (56/87), and 57.8% (59/102), respectively. ChatGPT outperformed InstructGPT by 8.15% on average across all data sets, and GPT-3 performed similarly to random chance. The model demonstrated a significant decrease in performance as question difficulty increased (P=.01) within the AMBOSS-Step1 data set. We found that logical justification for ChatGPT’s answer selection was present in 100% of outputs of the NBME data sets. Internal information to the question was present in 96.8% (183/189) of all questions. The presence of information external to the question was 44.5% and 27% lower for incorrect answers relative to correct answers on the NBME-Free-Step1 (P<.001) and NBME-Free-Step2 (P=.001) data sets, respectively. Conclusions: ChatGPT marks a significant improvement in natural language processing models on the tasks of medical question answering. By performing at a greater than 60% threshold on the NBME-Free-Step-1 data set, we show that the model achieves the equivalent of a passing score for a third-year medical student. Additionally, we highlight ChatGPT’s capacity to provide logic and informational context across the majority of answers. These facts taken together make a compelling case for the potential applications of ChatGPT as an interactive medical education tool to support learning. ©Aidan Gilson, Conrad W Safranek, Thomas Huang, Vimig Socrates, Ling Chi, Richard Andrew Taylor, David Chartash.
KW  - artificial intelligence
KW  - chatbot
KW  - ChatGPT
KW  - conversational agent
KW  - education technology
KW  - generative pre-trained transformer
KW  - GPT
KW  - machine learning
KW  - medical education
KW  - MedQA
KW  - natural language processing
KW  - NLP
PB  - JMIR Publications Inc.
SN  - 23693762 (ISSN)
LA  - English
J2  - JMIR Med. Educ.
M3  - Article
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 337; Correspondence Address: D. Chartash; Section for Biomedical Informatics and Data Science Yale University School of Medicine, New Haven, 300 George Street Suite 501, 06511, United States; email: david.chartash@yale.edu
ER  -

TY  - CONF
AU  - Cochran, K.
AU  - Cohn, C.
AU  - Rouet, J.F.
AU  - Hastings, P.
TI  - Improving Automated Evaluation of Student Text Responses Using GPT-3.5 for Text Data Augmentation
PY  - 2023
T2  - Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)
VL  - 13916 LNAI
SP  - 217
EP  - 228
DO  - 10.1007/978-3-031-36272-9_18
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85164961629&doi=10.1007%2f978-3-031-36272-9_18&partnerID=40&md5=c71cf12c91d98ed82bb13487f7400660
AD  - DePaul University, Chicago, 60604, IL, United States
AD  - Vanderbilt University, Nashville, 37240, TN, United States
AD  - Université de Poitiers, Poitiers Cedex 9, 86073, France
AB  - In education, intelligent learning environments allow students to choose how to tackle open-ended tasks while monitoring performance and behavior, allowing for the creation of adaptive support to help students overcome challenges. Timely feedback is critical to aid students’ progression toward learning and improved problem-solving. Feedback on text-based student responses can be delayed when teachers are overloaded with work. Automated evaluation can provide quick student feedback while easing the manual evaluation burden for teachers in areas with a high teacher-to-student ratio. Current methods of evaluating student essay responses to questions have included transformer-based natural language processing models with varying degrees of success. One main challenge in training these models is the scarcity of data for student-generated data. Larger volumes of training data are needed to create models that perform at a sufficient level of accuracy. Some studies have vast data, but large quantities are difficult to obtain when educational studies involve student-generated text. To overcome this data scarcity issue, text augmentation techniques have been employed to balance and expand the data set so that models can be trained with higher accuracy, leading to more reliable evaluation and categorization of student answers to aid teachers in the student’s learning progression. This paper examines the text-generating AI model, GPT-3.5, to determine if prompt-based text-generation methods are viable for generating additional text to supplement small sets of student responses for machine learning model training. We augmented student responses across two domains using GPT-3.5 completions and used that data to train a multilingual BERT model. Our results show that text generation can improve model performance on small data sets over simple self-augmentation. © 2023, The Author(s), under exclusive license to Springer Nature Switzerland AG.
KW  - BERT
KW  - data augmentation
KW  - educational texts
KW  - GPT-3.5
KW  - natural language processing
KW  - text generation
KW  - Computer aided instruction
KW  - Education computing
KW  - Learning algorithms
KW  - Learning systems
KW  - Natural language processing systems
KW  - BERT
KW  - Data augmentation
KW  - Educational text
KW  - GPT-3.5
KW  - Language processing
KW  - Natural language processing
KW  - Natural languages
KW  - Student response
KW  - Teachers'
KW  - Text generations
KW  - Students
A2  - Wang N.
A2  - Rebolledo-Mendez G.
A2  - Matsuda N.
A2  - Santos O.C.
A2  - Dimitrova V.
PB  - Springer Science and Business Media Deutschland GmbH
SN  - 03029743 (ISSN); 978-303136271-2 (ISBN)
LA  - English
J2  - Lect. Notes Comput. Sci.
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 1; Correspondence Address: K. Cochran; DePaul University, Chicago, 60604, United States; email: kcochr11@depaul.edu; Conference name: 24th International Conference on Artificial Intelligence in Education, AIED 2023; Conference date: 3 July 2023 through 7 July 2023; Conference code: 297049
ER  -

TY  - CONF
AU  - Tan, Q.
AU  - Ng, H.T.
AU  - Bing, L.
TI  - Towards Benchmarking and Improving the Temporal Reasoning Capability of Large Language Models
PY  - 2023
T2  - Proceedings of the Annual Meeting of the Association for Computational Linguistics
VL  - 1
SP  - 14820
EP  - 14835
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85162136253&partnerID=40&md5=2d01d602346c7da8b4fcd6f5f06808e5
AD  - DAMO Academy, Alibaba Group, China
AD  - Department of Computer Science, National University of Singapore, Singapore
AB  - Reasoning about time is of fundamental importance. Many facts are time-dependent. For example, athletes change teams from time to time, and different government officials are elected periodically. Previous time-dependent question answering (QA) datasets tend to be biased in either their coverage of time spans or question types. In this paper, we introduce a comprehensive probing dataset TEMPREASON to evaluate the temporal reasoning capability of large language models. Our dataset includes questions of three temporal reasoning levels. In addition, we also propose a novel learning framework to improve the temporal reasoning capability of large language models, based on temporal span extraction and time-sensitive reinforcement learning. We conducted experiments in closed book QA, open book QA, and reasoning QA settings and demonstrated the effectiveness of our approach. © 2023 Association for Computational Linguistics.
KW  - Computational linguistics
KW  - Large dataset
KW  - Government officials
KW  - Language model
KW  - Learning frameworks
KW  - Model-based OPC
KW  - Question Answering
KW  - Question type
KW  - Reasoning capabilities
KW  - Temporal reasoning
KW  - Time dependent
KW  - Time span
KW  - Reinforcement learning
PB  - Association for Computational Linguistics (ACL)
SN  - 0736587X (ISSN); 978-195942972-2 (ISBN)
LA  - English
J2  - Proc. Annu. Meet. Assoc. Comput Linguist.
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 0; Correspondence Address: H.T. Ng; Department of Computer Science, National University of Singapore, Singapore; email: nght@comp.nus.edu.sg; Conference name: 61st Annual Meeting of the Association for Computational Linguistics, ACL 2023; Conference date: 9 July 2023 through 14 July 2023; Conference code: 192160
ER  -

TY  - JOUR
AU  - Benítez-Andrades, J.A.
AU  - Alija-Perez, J.-M.
AU  - Vidal, M.-E.
AU  - Pastor-Vargas, R.
AU  - García-Ordas, M.T.
TI  - Traditional Machine Learning Models and Bidirectional Encoder Representations From Transformer (BERT)-Based Automatic Classification of Tweets About Eating Disorders: Algorithm Development and Validation Study
PY  - 2022
T2  - JMIR Medical Informatics
VL  - 10
IS  - 2
C7  - e34492
DO  - 10.2196/34492
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85126462382&doi=10.2196%2f34492&partnerID=40&md5=0674aa45669b6a49ed28114b474023a6
AD  - SALBIS Research Group, Department of Electric, Systems and Automatics Engineering, University of Leon, Leon, Spain
AD  - SECOMUCI Research Group, Escuela de Ingenierías Industrial e Informática, Universidad de Leon, Leon, Spain
AD  - Leibniz University of Hannover, Hannover, Germany
AD  - Communications and Control Systems Department, Spanish National University for Distance Education, Madrid, Spain
AB  - Background: Eating disorders affect an increasing number of people. Social networks provide information that can help. Objective: We aimed to find machine learning models capable of efficiently categorizing tweets about eating disorders domain. Methods: We collected tweets related to eating disorders, for 3 consecutive months. After preprocessing, a subset of 2000 tweets was labeled: (1) messages written by people suffering from eating disorders or not, (2) messages promoting suffering from eating disorders or not, (3) informative messages or not, and (4) scientific or nonscientific messages. Traditional machine learning and deep learning models were used to classify tweets. We evaluated accuracy, F1 score, and computational time for each model. Results: A total of 1,058,957 tweets related to eating disorders were collected. were obtained in the 4 categorizations, with The bidirectional encoder representations from transformer-based models had the best score among the machine learning and deep learning techniques applied to the 4 categorization tasks (F1 scores 71.1%-86.4%). Conclusions: Bidirectional encoder representations from transformer-based models have better performance, although their computational cost is significantly higher than those of traditional techniques, in classifying eating disorder-related tweets. © 2022 JMIR Publications Inc.. All right reserved.
KW  - BERT
KW  - bidirectional encoder representations from transformer
KW  - classification
KW  - data
KW  - deep learning
KW  - diet
KW  - disorder
KW  - eating disorder
KW  - machine learning
KW  - mental health
KW  - model
KW  - natural language processing
KW  - NLP
KW  - nutrition
KW  - performance
KW  - social media
KW  - Twitter
KW  - weight
PB  - JMIR Publications Inc.
SN  - 22919694 (ISSN)
LA  - English
J2  - JMIR Med. Inform.
M3  - Article
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 8; Correspondence Address: J.A. Benítez-Andrades; SALBIS Research Group, Department of Electric, Systems and Automatics Engineering, University of Leon, Leon, Campus of Vegazana s/n, 24071, Spain; email: jbena@unileon.es
ER  -

TY  - CONF
AU  - Janghorbani, S.
AU  - de Melo, G.
TI  - Multi-Modal Bias: Introducing a Framework for Stereotypical Bias Assessment beyond Gender and Race in Vision-Language Models
PY  - 2023
T2  - EACL 2023 - 17th Conference of the European Chapter of the Association for Computational Linguistics, Proceedings of the Conference
SP  - 1717
EP  - 1727
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85159853431&partnerID=40&md5=33730f7a40cc9059cf24cd95a46e38a2
AD  - Rutgers University, New Brunswick, NJ, United States
AD  - HPI, University of Potsdam, Potsdam, Germany
AB  - Recent breakthroughs in self-supervised training have led to a new class of pretrained vision-language models. While there have been investigations of bias in multimodal models, they have mostly focused on gender and racial bias, giving much less attention to other relevant groups, such as minorities with regard to religion, nationality, sexual orientation, or disabilities. This is mainly due to lack of suitable benchmarks for such groups. We seek to address this gap by providing a visual and textual bias benchmark called MMBias, consisting of around 3,800 images and phrases covering 14 population subgroups. We utilize this dataset to assess bias in several prominent self-supervised multimodal models, including CLIP, ALBEF, and ViLT. Our results show that these models demonstrate meaningful bias favoring certain groups. Finally, we introduce a debiasing method designed specifically for such large pretrained models that can be applied as a post-processing step to mitigate bias, while preserving the remaining accuracy of the model. © 2023 Association for Computational Linguistics.
KW  - De-biasing
KW  - Gender bias
KW  - Language model
KW  - Multi-modal
KW  - Multimodal models
KW  - Post-processing
KW  - Processing steps
KW  - Racial bias
KW  - Sexual orientations
KW  - Supervised trainings
KW  - Computational linguistics
PB  - Association for Computational Linguistics (ACL)
SN  - 978-195942944-9 (ISBN)
LA  - English
J2  - EACL - Conf. Eur. Chapter Assoc. Comput. Linguist., Proc. Conf.
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 0; Conference name: 17th Conference of the European Chapter of the Association for Computational Linguistics, EACL 2023; Conference date: 2 May 2023 through 6 May 2023; Conference code: 188424
ER  -

TY  - CONF
AU  - De Bruyn, M.
AU  - Lotfi, E.
AU  - Buhmann, J.
AU  - Daelemans, W.
TI  - 20Q: Overlap-Free World Knowledge Benchmark for Language Models
PY  - 2022
T2  - GEM 2022 - 2nd Workshop on Natural Language Generation, Evaluation, and Metrics, Proceedings of the Workshop
SP  - 494
EP  - 508
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85152894636&partnerID=40&md5=9af28cb1a1b7113ca80d0f3b97d33ed7
AD  - CLiPS Research Center, University of Antwerp, Belgium
AB  - What do language models know about our world? This question is hard to answer but important to get right. To this end, we introduce 20Q, a novel benchmark using the Twenty Questions game to evaluate world knowledge and common sense of language models. Thanks to our overlap-free benchmark, language models learn the game of Twenty Questions without learning relevant knowledge for the test set. We uncover two intuitive factors influencing the world knowledge of language models: the size of the model and the topic frequency in the pre-training data. Moreover, we show that in-context learning is inefficient for evaluating language models' world knowledge - fine-tuning is necessary to show their true capabilities. Lastly, our results show room for improvement to enhance the world knowledge and common sense of large language models. A potential solution would be to up-sample unfrequent topics in the pre-training of language models. © 2022 Association for Computational Linguistics.
KW  - Learning systems
KW  - Common sense
KW  - Context learning
KW  - Fine tuning
KW  - In contexts
KW  - Language model
KW  - Learn+
KW  - Pre-training
KW  - Test sets
KW  - Training data
KW  - World knowledge
KW  - Computational linguistics
PB  - Association for Computational Linguistics (ACL)
SN  - 978-195942912-8 (ISBN)
LA  - English
J2  - GEM - Workshop Nat. Lang. Gen., Eval., Metrics, Proc. Workshop
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 0; Conference name: 2nd Workshop on Natural Language Generation, Evaluation, and Metrics, GEM 2022, as part of EMNLP 2022; Conference code: 187673
ER  -

TY  - CONF
AU  - Kocián, M.
AU  - Náplava, J.
AU  - Štancl, D.
AU  - Kadlec, V.
TI  - Siamese BERT-Based Model for Web Search Relevance Ranking Evaluated on a New Czech Dataset
PY  - 2022
T2  - Proceedings of the 36th AAAI Conference on Artificial Intelligence, AAAI 2022
VL  - 36
SP  - 12369
EP  - 12377
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85147604492&partnerID=40&md5=c90fc6a66c2388277336e8d79667372d
AD  - Seznam.cz, Prague, Czech Republic
AB  - Web search engines focus on serving highly relevant results within hundreds of milliseconds. Pre-trained language transformer models such as BERT are therefore hard to use in this scenario due to their high computational demands. We present our real-time approach to the document ranking problem leveraging a BERT-based siamese architecture. The model is already deployed in a commercial search engine and it improves production performance by more than 3%. For further research and evaluation, we release DaReCzech, a unique data set of 1.6 million Czech user query-document pairs with manually assigned relevance levels. We also release Small-E-Czech, an Electra-small language model pretrained on a large Czech corpus. We believe this data will support endeavours both of search relevance and multilingual-focused research communities. Copyright © 2022, Association for the Advancement of Artificial Intelligence (www.aaai.org). All rights reserved.
KW  - Artificial intelligence
KW  - Computational linguistics
KW  - Information retrieval
KW  - Websites
KW  - Computational demands
KW  - Data set
KW  - Document ranking
KW  - Production performance
KW  - Ranking problems
KW  - Real- time
KW  - Relevance ranking
KW  - Research and evaluation
KW  - Transformer modeling
KW  - Web searches
KW  - Search engines
PB  - Association for the Advancement of Artificial Intelligence
SN  - 1577358767 (ISBN); 978-157735876-3 (ISBN)
LA  - English
J2  - Proc. AAAI Conf. Artif. Intell., AAAI
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 3; Conference name: 36th AAAI Conference on Artificial Intelligence, AAAI 2022; Conference date: 22 February 2022 through 1 March 2022; Conference code: 185285
ER  -

TY  - CONF
AU  - Malik, M.
AU  - Johansson, R.
TI  - Controlling for Stereotypes in Multimodal Language Model Evaluation
PY  - 2022
T2  - BlackboxNLP 2022 - BlackboxNLP Analyzing and Interpreting Neural Networks for NLP, Proceedings of the Workshop
SP  - 263
EP  - 271
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85152941160&partnerID=40&md5=f96537f8efc35658d9605424cd7dcd38
AD  - International Institute of Information Technology, Bangalore, India
AD  - University of Gothenburg, Chalmers University of Technology, Gothenburg, Sweden
AB  - We propose a methodology and design two benchmark sets for measuring to what extent language-and-vision language models use the visual signal in the presence or absence of stereotypes. The first benchmark is designed to test for stereotypical colors of common objects, while the second benchmark considers gender stereotypes. The key idea is to compare predictions when the image conforms to the stereotype to predictions when it does not. Our results show that there is significant variation among multimodal models: the recent Transformer-based FLAVA seems to be more sensitive to the choice of image and less affected by stereotypes than older CNN-based models such as VisualBERT and LXMERT. This effect is more discernible in this type of controlled setting than in traditional evaluations where we do not know whether the model relied on the stereotype or the visual signal. © 2022 Association for Computational Linguistics.
KW  - Visual languages
KW  - Gender stereotypes
KW  - Language model
KW  - Model evaluation
KW  - Model use
KW  - Multi-modal
KW  - Multimodal models
KW  - Visual signals
KW  - Computational linguistics
PB  - Association for Computational Linguistics (ACL)
SN  - 978-195942905-0 (ISBN)
LA  - English
J2  - BlackboxNLP - BlackboxNLP Anal. Interpret. Neural Networks NLP, Proc. Workshop
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 0; Conference name: 5th Workshop on Analyzing and Interpreting Neural Networks for NLP, BlackboxNLP 2022 hosted by the 2022 Conference on Empirical Methods in Natural Language Processing, EMNLP 2022; Conference code: 187666
ER  -

TY  - JOUR
AU  - Teferra, B.G.
AU  - Rose, J.
TI  - Predicting Generalized Anxiety Disorder From Impromptu Speech Transcripts Using Context-Aware Transformer-Based Neural Networks: Model Evaluation Study
PY  - 2023
T2  - JMIR Mental Health
VL  - 10
C7  - e44325
DO  - 10.2196/44325
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85151909830&doi=10.2196%2f44325&partnerID=40&md5=b643a7a64c4af6c3795d333eb3ba8246
AD  - The Edward S Rogers Sr Department of Electrical and Computer Engineering, University of Toronto, Toronto, ON, Canada
AD  - The Centre for Addiction and Mental Health, Toronto, ON, Canada
AB  - Background: The ability to automatically detect anxiety disorders from speech could be useful as a screening tool for an anxiety disorder. Prior studies have shown that individual words in textual transcripts of speech have an association with anxiety severity. Transformer-based neural networks are models that have been recently shown to have powerful predictive capabilities based on the context of more than one input word. Transformers detect linguistic patterns and can be separately trained to make specific predictions based on these patterns. Objective: This study aimed to determine whether a transformer-based language model can be used to screen for generalized anxiety disorder from impromptu speech transcripts. Methods: A total of 2000 participants provided an impromptu speech sample in response to a modified version of the Trier Social Stress Test (TSST). They also completed the Generalized Anxiety Disorder 7-item (GAD-7) scale. A transformer-based neural network model (pretrained on large textual corpora) was fine-tuned on the speech transcripts and the GAD-7 to predict whether a participant was above or below a screening threshold of the GAD-7. We reported the area under the receiver operating characteristic curve (AUROC) on the test data and compared the results with a baseline logistic regression model using the Linguistic Inquiry and Word Count (LIWC) features as input. Using the integrated gradient method to determine specific words that strongly affect the predictions, we inferred specific linguistic patterns that influence the predictions. Results: The baseline LIWC-based logistic regression model had an AUROC value of 0.58. The fine-tuned transformer model achieved an AUROC value of 0.64. Specific words that were often implicated in the predictions were also dependent on the context. For example, the first-person singular pronoun “I” influenced toward an anxious prediction 88% of the time and a nonanxious prediction 12% of the time, depending on the context. Silent pauses in speech, also often implicated in predictions, influenced toward an anxious prediction 20% of the time and a nonanxious prediction 80% of the time. Conclusions: There is evidence that a transformer-based neural network model has increased predictive power compared with the single word–based LIWC model. We also showed that the use of specific words in a specific context—a linguistic pattern—is part of the reason for the better prediction. This suggests that such transformer-based models could play a useful role in anxiety screening systems. © 2023 JMIR Publications. All rights reserved.
KW  - anxiety prediction
KW  - generalized anxiety disorder
KW  - impromptu speech
KW  - linguistic features
KW  - mental health
KW  - mobile phone
KW  - natural language processing
KW  - neural networks
KW  - transformer models
KW  - Article
KW  - artificial neural network
KW  - controlled study
KW  - generalized anxiety disorder
KW  - Generalized Anxiety Disorder-7
KW  - human
KW  - major clinical study
KW  - prediction
KW  - speech
KW  - speech test
KW  - transformer based neural network
KW  - Trier Social Stress Test
PB  - JMIR Publications Inc.
SN  - 23687959 (ISSN)
LA  - English
J2  - JMIR Ment. Heal.
M3  - Article
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 1; Correspondence Address: B.G. Teferra; The Edward S Rogers Sr Department of Electrical and Computer Engineering University of Toronto, Toronto, 10 King’s College Road, M5S3G4, Canada; email: bazen.teferra@mail.utoronto.ca
ER  -

TY  - JOUR
AU  - Falissard, L.
AU  - Morgand, C.
AU  - Ghosn, W.
AU  - Imbaud, C.
AU  - Bounebache, K.
AU  - Rey, G.
TI  - Neural Translation and Automated Recognition of ICD-10 Medical Entities From Natural Language: Model Development and Performance Assessment
PY  - 2022
T2  - JMIR Medical Informatics
VL  - 10
IS  - 4
C7  - e26353
DO  - 10.2196/26353
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85128469236&doi=10.2196%2f26353&partnerID=40&md5=a6891606cf9d490688d1006c3c69ed52
AD  - Centre for Epidemiology on Medical Causes of Death, Inserm, Le Kremlin Bicetre, France
AB  - Background: The recognition of medical entities from natural language is a ubiquitous problem in the medical field, with applications ranging from medical coding to the analysis of electronic health data for public health. It is, however, a complex task usually requiring human expert intervention, thus making it expansive and time-consuming. Recent advances in artificial intelligence, specifically the rise of deep learning methods, have enabled computers to make efficient decisions on a number of complex problems, with the notable example of neural sequence models and their powerful applications in natural language processing. However, they require a considerable amount of data to learn from, which is typically their main limiting factor. The Centre for Epidemiology on Medical Causes of Death (CépiDc) stores an exhaustive database of death certificates at the French national scale, amounting to several millions of natural language examples provided with their associated human-coded medical entities available to the machine learning practitioner. Objective: The aim of this paper was to investigate the application of deep neural sequence models to the problem of medical entity recognition from natural language. Methods: The investigated data set included every French death certificate from 2011 to 2016. These certificates contain information such as the subject's age, the subject's gender, and the chain of events leading to his or her death, both in French and encoded as International Statistical Classification of Diseases and Related Health Problems, Tenth Revision (ICD-10) medical entities, for a total of around 3 million observations in the data set. The task of automatically recognizing ICD-10 medical entities from the French natural language-based chain of events leading to death was then formulated as a type of predictive modeling problem known as a sequence-to-sequence modeling problem. A deep neural network-based model, known as the Transformer, was then slightly adapted and fit to the data set. Its performance was then assessed on an external data set and compared to the current state-of-the-art approach. CIs for derived measurements were estimated via bootstrapping. Results: The proposed approach resulted in an F-measure value of 0.952 (95% CI 0.946-0.957), which constitutes a significant improvement over the current state-of-the-art approach and its previously reported F-measure value of 0.825 as assessed on a comparable data set. Such an improvement makes possible a whole field of new applications, from nosologist-level automated coding to temporal harmonization of death statistics. Conclusions: This paper shows that a deep artificial neural network can directly learn from voluminous data sets in order to identify complex relationships between natural language and medical entities, without any explicit prior knowledge. Although not entirely free from mistakes, the derived model constitutes a powerful tool for automated coding of medical entities from medical language with promising potential applications. © 2022 JMIR Publications Inc.. All right reserved.
KW  - automated medical entity recognition
KW  - deep learning
KW  - ICD-10 coding
KW  - machine learning
KW  - machine translation
KW  - mortality statistics
PB  - JMIR Publications Inc.
SN  - 22919694 (ISSN)
LA  - English
J2  - JMIR Med. Inform.
M3  - Article
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 6; Correspondence Address: L. Falissard; Centre for Epidemiology on Medical Causes of Death, Inserm, 80 Rue du General Leclerc, Le Kremlin Bicetre, 94270, France; email: louis.falissard@gmail.co
ER  -

TY  - CONF
AU  - Ni, P.
AU  - Chen, G.
AU  - Yang, W.
AU  - Zhang, L.
AU  - Tang, T.
AU  - Hu, W.
TI  - Research on Transformer Risk Assessment Model Considering Offshore Petroleum and Gas Environment
PY  - 2023
T2  - Proceedings - 2023 Panda Forum on Power and Energy, PandaFPE 2023
SP  - 1193
EP  - 1197
DO  - 10.1109/PandaFPE57779.2023.10140636
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85163335054&doi=10.1109%2fPandaFPE57779.2023.10140636&partnerID=40&md5=d17105f61f9b43367f45dd294bcbc3b5
AD  - School of Electrical Information, Southwest Petroleum University, Chengdu, China
AD  - School of Electrical Information, Chengdu, China
AB  - Transformer is one of the key equipment in the power system platform, and its operation status is directly related to the system operation status. In order to ensure the reliable and stable operation of the transformer, it is necessary to develop a condition-based maintenance plan for it. Therefore, it is of great significance to carry out effective risk assessment and formulate corresponding maintenance strategies according to the assessment results. Divide risk probability into failure rate and risk consequence, build failure rate model based on state assessment, aging, weather and system coupling, and quantify risk from maintenance, power grid, human and environment. Establish risk assessment model for transformer. Finally, the feasibility and effectiveness of the model is verified by the risk assessment of a transformer on an offshore platform. The model can reflect the operation status of transformer more comprehensively.  © 2023 IEEE.
KW  - failure probability
KW  - risk assessment
KW  - transformer
KW  - Condition based maintenance
KW  - Failure (mechanical)
KW  - Failure rate
KW  - Offshore oil well production
KW  - Outages
KW  - Failure Probability
KW  - Gas environment
KW  - Key equipment
KW  - Offshore petroleum
KW  - Operation status
KW  - Power
KW  - Risk assessment - modelling
KW  - Risks assessments
KW  - System platforms
KW  - Transformer
KW  - Risk assessment
A2  - Liu J.
A2  - Han X.
A2  - Hu W.
PB  - Institute of Electrical and Electronics Engineers Inc.
SN  - 979-835032117-3 (ISBN)
LA  - English
J2  - Proc. - Panda Forum Power Energy, PandaFPE
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 0; Conference name: 2023 Panda Forum on Power and Energy, PandaFPE 2023; Conference date: 27 April 2023 through 30 April 2023; Conference code: 189332
ER  -

TY  - CONF
AU  - Lin, C.
AU  - Xu, Y.
AU  - Su, H.
TI  - Visual Named Entity Validation for Short Names in Financial Domain with Fine-Tuned BERT and Data Augmentation
PY  - 2023
T2  - Lecture Notes in Networks and Systems
VL  - 651 LNNS
SP  - 33
EP  - 40
DO  - 10.1007/978-3-031-28076-4_4
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85149964923&doi=10.1007%2f978-3-031-28076-4_4&partnerID=40&md5=81a8cc6ff09cb7f97264fb3a80d40383
AD  - Fidelity Investments, Boston, 02210, MA, United States
AB  - Validating OCR-extracted financial entities against a financial organization’s codified data is a very challenging semantic textual similarity task because of limited context, short text, presence of abbreviations/acronyms, and OCR errors. To study this problem, we built a synthetic dataset with images that contain pseudo financial entities for OCR; model-generated short names with abbreviations/acronyms for validation. With fine-tuned BERT and data augmentation, we achieved top notch performance on this task and compared with several baseline systems. © 2023, The Author(s), under exclusive license to Springer Nature Switzerland AG.
KW  - Optical character recognition
KW  - Short names validation
KW  - Transformers
KW  - Finance
KW  - Semantics
KW  - Data augmentation
KW  - Financial domains
KW  - Financial organizations
KW  - Named entities
KW  - Performance
KW  - Short name validation
KW  - Short texts
KW  - Synthetic datasets
KW  - Textual similarities
KW  - Transformer
KW  - Optical character recognition
A2  - Arai K.
PB  - Springer Science and Business Media Deutschland GmbH
SN  - 23673370 (ISSN); 978-303128075-7 (ISBN)
LA  - English
J2  - Lect. Notes Networks Syst.
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 0; Correspondence Address: C. Lin; Fidelity Investments, Boston, 02210, United States; email: Chen.Lin@fmr.com; Conference name: 8th Future of Information and Computing Conference, FICC 2023; Conference date: 2 March 2023 through 3 March 2023; Conference code: 291059
ER  -

TY  - JOUR
AU  - Wu, Y.
AU  - Henriksson, A.
AU  - Nouri, J.
AU  - Duneld, M.
AU  - Li, X.
TI  - Beyond Benchmarks: Spotting Key Topical Sentences While Improving Automated Essay Scoring Performance with Topic-Aware BERT
PY  - 2023
T2  - Electronics (Switzerland)
VL  - 12
IS  - 1
C7  - 150
DO  - 10.3390/electronics12010150
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85145830143&doi=10.3390%2felectronics12010150&partnerID=40&md5=588a6ec22db27dd06eab98335484cb52
AD  - Department of Computer and System Sciences, Stockholm University, NOD-Huset, Borgarfjordsgatan 12, Stockholm, 16455, Sweden
AB  - Automated Essay Scoring (AES) automatically allocates scores to essays at scale and may help teachers reduce the heavy burden during grading activities. Recently, researchers have deployed neural-based AES approaches to improve upon the state-of-the-art AES performance. These neural-based AES methods mainly take student essays as the sole input and focus on learning the relationship between student essays and essay scores through deep neural networks. However, their only product, the predicted holistic score, is far from providing adequate pedagogical information, such as automated writing evaluation (AWE). In this work, we propose Topic-aware BERT, a new method of learning relations among scores, student essays, as well as topical information in essay instructions. Beyond improving the AES benchmark performance, Topic-aware BERT can automatically retrieve key topical sentences in student essays by probing self-attention maps in intermediate layers. We evaluate the performance of Topic-aware BERT of different variants to (i) perform AES and (ii) retrieve key topical sentences using the open dataset Automated Student Assessment Prize and a manually annotated dataset. Our experiments show that Topic-aware BERT achieves a strong AES performance compared with the previous best neural-based AES methods and demonstrates effectiveness in identifying key topical sentences in argumentative essays. © 2022 by the authors.
KW  - artificial intelligence
KW  - automated essay scoring
KW  - automated writing evaluation
KW  - BERT
KW  - natural language processing
PB  - MDPI
SN  - 20799292 (ISSN)
LA  - English
J2  - Electronics (Switzerland)
M3  - Article
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 0; Correspondence Address: Y. Wu; Department of Computer and System Sciences, Stockholm University, Stockholm, NOD-Huset, Borgarfjordsgatan 12, 16455, Sweden; email: yongchao.wu@dsv.su.se
ER  -

TY  - JOUR
AU  - Reddy, S.
TI  - Evaluating large language models for use in healthcare: A framework for translational value assessment
PY  - 2023
T2  - Informatics in Medicine Unlocked
VL  - 41
C7  - 101304
DO  - 10.1016/j.imu.2023.101304
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85165227448&doi=10.1016%2fj.imu.2023.101304&partnerID=40&md5=5ad663847b8f50b4a53335fc2bbf5ca2
AD  - School of Medicine, Deakin University, Waurn Ponds, 3216, VIC, Australia
AB  - The recent focus on Large Language Models (LLMs) has yielded unprecedented discussion of their potential use in various domains, including healthcare. While showing considerable potential in performing human-capable tasks, LLMs have also demonstrated significant drawbacks, including generating misinformation, falsifying data, and contributing to plagiarism. These aspects are generally concerning but can be more severe in the context of healthcare. As LLMs are explored for utility in healthcare, including generating discharge summaries, interpreting medical records and providing medical advice, it is necessary to ensure safeguards around their use in healthcare. Notably, there must be an evaluation process that assesses LLMs for their natural language processing performance and their translational value. Complementing this assessment, a governance layer can ensure accountability and public confidence in such models. Such an evaluation framework is discussed and presented in this paper. © 2023 The Author
KW  - human
KW  - human experiment
KW  - medical record
KW  - natural language processing
KW  - review
PB  - Elsevier Ltd
SN  - 23529148 (ISSN)
LA  - English
J2  - Inform. Med. Unlocked
M3  - Review
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 0
ER  -

TY  - JOUR
AU  - Chen, P.-F.
AU  - He, T.-L.
AU  - Lin, S.-C.
AU  - Chu, Y.-C.
AU  - Kuo, C.-T.
AU  - Lai, F.
AU  - Wang, S.-M.
AU  - Zhu, W.-X.
AU  - Chen, K.-C.
AU  - Kuo, L.-C.
AU  - Hung, F.-M.
AU  - Lin, Y.-C.
AU  - Tsai, I.-C.
AU  - Chiu, C.-H.
AU  - Chang, S.-C.
AU  - Yang, C.-Y.
TI  - Training a Deep Contextualized Language Model for International Classification of Diseases, 10th Revision Classification via Federated Learning: Model Development and Validation Study
PY  - 2022
T2  - JMIR Medical Informatics
VL  - 10
IS  - 11
C7  - e41342
DO  - 10.2196/41342
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85145461181&doi=10.2196%2f41342&partnerID=40&md5=062826f5e5113841f676bfada3c7f69a
AD  - Graduate Institute of Biomedical Electronics and Bioinformatics, National Taiwan University, Taipei, Taiwan
AD  - Department of Anesthesiology, Far Eastern Memorial Hospital, New Taipei City, Taiwan
AD  - Department of Computer Science and Information Engineering, National Taiwan University, Taipei, Taiwan
AD  - Department of Information Management, Taipei Veterans General Hospital, Taipei City, Taiwan
AD  - Medical Artificial Intelligence Development Center, Taipei Veterans General Hospital, Taipei City, Taiwan
AD  - Department of Information Management, National Taipei University of Nursing and Health Sciences, Taipei City, Taiwan
AD  - Department of Electrical Engineering, National Taiwan University, Taipei, Taiwan
AD  - Graduate Institute of Networking and Multimedia, National Taiwan University, Taipei, Taiwan
AD  - Department of Internal Medicine, Far Eastern Memorial Hospital, New Taipei City, Taiwan
AD  - Department of Internal Medicine, National Taiwan University Hospital, National Taiwan University College of Medicine, Taipei, Taiwan
AD  - Department of Medical Affairs, Far Eastern Memorial Hospital, New Taipei City, Taiwan
AD  - Department of Surgical Intensive Care Unit, Far Eastern Memorial Hospital, New Taipei City, Taiwan
AD  - Department of Pediatrics, Far Eastern Memorial Hospital, New Taipei City, Taiwan
AD  - School of Medicine, National Yang Ming Chiao Tung University, Taipei, Taiwan
AD  - Artificial Intelligence Center, Far Eastern Memorial Hospital, New Taipei City, Taiwan
AD  - Section of Health Insurance, Department of Medical Affairs, Far Eastern Memorial Hospital, New Taipei City, Taiwan
AD  - Medical Records Department, Far Eastern Memorial Hospital, New Taipei City, Taiwan
AD  - Department of Information Technology, Far Eastern Memorial Hospital, New Taipei City, Taiwan
AD  - Section of Cardiovascular Medicine, Cardiovascular Center, Far Eastern Memorial Hospital, New Taipei City, Taiwan
AB  - Background: The automatic coding of clinical text documents by using the International Classification of Diseases, 10th Revision (ICD-10) can be performed for statistical analyses and reimbursements. With the development of natural language processing models, new transformer architectures with attention mechanisms have outperformed previous models. Although multicenter training may increase a model's performance and external validity, the privacy of clinical documents should be protected. We used federated learning to train a model with multicenter data, without sharing data per se. Objective: This study aims to train a classification model via federated learning for ICD-10 multilabel classification. Methods: Text data from discharge notes in electronic medical records were collected from the following three medical centers: Far Eastern Memorial Hospital, National Taiwan University Hospital, and Taipei Veterans General Hospital. After comparing the performance of different variants of bidirectional encoder representations from transformers (BERT), PubMedBERT was chosen for the word embeddings. With regard to preprocessing, the nonalphanumeric characters were retained because the model's performance decreased after the removal of these characters. To explain the outputs of our model, we added a label attention mechanism to the model architecture. The model was trained with data from each of the three hospitals separately and via federated learning. The models trained via federated learning and the models trained with local data were compared on a testing set that was composed of data from the three hospitals. The micro F1 score was used to evaluate model performance across all 3 centers. Results: The F1 scores of PubMedBERT, RoBERTa (Robustly Optimized BERT Pretraining Approach), ClinicalBERT, and BioBERT (BERT for Biomedical Text Mining) were 0.735, 0.692, 0.711, and 0.721, respectively. The F1 score of the model that retained nonalphanumeric characters was 0.8120, whereas the F1 score after removing these characters was 0.7875 - a decrease of 0.0245 (3.11%). The F1 scores on the testing set were 0.6142, 0.4472, 0.5353, and 0.2522 for the federated learning, Far Eastern Memorial Hospital, National Taiwan University Hospital, and Taipei Veterans General Hospital models, respectively. The explainable predictions were displayed with highlighted input words via the label attention architecture. Conclusions: Federated learning was used to train the ICD-10 classification model on multicenter clinical text while protecting data privacy. The model's performance was better than that of models that were trained locally.  ©Elena Rey Velasco, Hanne Sæderup Pedersen.
KW  - federated learning
KW  - International Classification of Diseases
KW  - machine learning
KW  - multilabel text classification
KW  - natural language processing
PB  - JMIR Publications Inc.
SN  - 22919694 (ISSN)
LA  - English
J2  - JMIR Med. Inform.
M3  - Article
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 3; Correspondence Address: C.-Y. Yang; Department of Information Technology, Far Eastern Memorial Hospital, New Taipei City, No 21, Section 2, Nanya S Rd, Banciao District, 220216, Taiwan; email: chiyuyang1959@gmail.com
ER  -

TY  - CONF
AU  - Oliveira, H.S.
AU  - Ribeiro, P.P.
AU  - Oliveira, H.P.
TI  - Evaluation of Regularization Techniques for Transformers-Based Models
PY  - 2023
T2  - Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)
VL  - 14062 LNCS
SP  - 312
EP  - 319
DO  - 10.1007/978-3-031-36616-1_25
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85164955045&doi=10.1007%2f978-3-031-36616-1_25&partnerID=40&md5=61379bff51af659b076b9afcc5f6daa3
AD  - Faculty of Sciences, Computer Science Department (DCC), University of Porto, Porto, Portugal
AD  - Instituto de Engenharia de Sistemas e Computadores, INESC TEC, Porto, Portugal
AB  - In recent years the great success of transformers-based models initially employed in Natural Language (NLP) tasks has led to the development of several transformers variations to be employed in a wide range of domains, such as vision. With the correct amount of training data and proper training, transformers can perform excellently compared to the Convolution Neural Networks (CNN) counterpart in the vision tasks. However, the main drawback of transformers concerns the know memory requirements that often exceed the available training platform, growing in a quadratic form regarding the input image size, and a great tendency to overfit. Several works address the memory problem by relaxing the model architecture versions, but mainly with reduced prediction capabilities. In this work, we evaluate Random Patch erasing among the image patch level of the transformer model as a regularization technique to reduce overfitting while at the same time alleviating training time. The evaluated regularization technique achieves competitive results on several image classification medical datasets. The evaluated Visual Transformers (ViT) models allow to be trained in a single GPU, reaching similar results to CNN counterparts, obtaining an accuracy 91.2%, 79.2% in two competitive image datasets, and reducing the training time on average by 22% on the transformers models. © 2023, The Author(s), under exclusive license to Springer Nature Switzerland AG.
KW  - Regularization
KW  - Transformers
KW  - Vision Transformers
KW  - Medical imaging
KW  - Number theory
KW  - Convolution neural network
KW  - Memory requirements
KW  - Natural languages
KW  - Regularisation
KW  - Regularization technique
KW  - Training data
KW  - Training time
KW  - Transformer
KW  - Transformer modeling
KW  - Vision transformer
KW  - Classification (of information)
A2  - Pertusa A.
A2  - Gallego A.J.
A2  - Sánchez J.A.
A2  - Domingues I.
PB  - Springer Science and Business Media Deutschland GmbH
SN  - 03029743 (ISSN); 978-303136615-4 (ISBN)
LA  - English
J2  - Lect. Notes Comput. Sci.
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 0; Correspondence Address: H.S. Oliveira; Instituto de Engenharia de Sistemas e Computadores, INESC TEC, Porto, Portugal; email: hugo.soares@fe.up.pt; Conference name: 11th Iberian Conference on Pattern Recognition and Image Analysis, IbPRIA 2023; Conference date: 27 June 2023 through 30 June 2023; Conference code: 297009
ER  -

TY  - CONF
AU  - Todorov, K.
AU  - Colavizza, G.
TI  - An Assessment of the Impact of OCR Noise on Language Models
PY  - 2022
T2  - International Conference on Agents and Artificial Intelligence
VL  - 2
SP  - 674
EP  - 683
DO  - 10.5220/0010945100003116
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85182578277&doi=10.5220%2f0010945100003116&partnerID=40&md5=d0d6267e774e44ee9e7684e119aa04fa
AD  - Institute for Logic, Language and Computation (ILLC), University of Amsterdam, Netherlands
AB  - Neural language models are the backbone of modern-day natural language processing applications. Their use on textual heritage collections which have undergone Optical Character Recognition (OCR) is therefore also increasing. Nevertheless, our understanding of the impact OCR noise could have on language models is still limited. We perform an assessment of the impact OCR noise has on a variety of language models, using data in Dutch, English, French and German. We find that OCR noise poses a significant obstacle to language modelling, with language models increasingly diverging from their noiseless targets as OCR quality lowers. In the presence of small corpora, simpler models including PPMI and Word2Vec consistently outperform transformer-based models in this respect. © 2021 by SCITEPRESS – Science and Technology Publications, Lda. All rights reserved.
KW  - Language Models
KW  - Machine Learning
KW  - Optical Character Recognition (OCR)
A2  - Rocha A.
A2  - Steels L.
A2  - van den Herik J.
PB  - Science and Technology Publications, Lda
SN  - 21843589 (ISSN)
LA  - English
J2  - Int. Conf. Agent. Artif. Intell.
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 0; Conference name: 14th International Conference on Agents and Artificial Intelligence , ICAART 2022; Conference date: 3 February 2022 through 5 February 2022; Conference code: 301199
ER  -

TY  - JOUR
AU  - Elyoseph, Z.
AU  - Hadar-Shoval, D.
AU  - Asraf, K.
AU  - Lvovsky, M.
TI  - ChatGPT outperforms humans in emotional awareness evaluations
PY  - 2023
T2  - Frontiers in Psychology
VL  - 14
C7  - 1199058
DO  - 10.3389/fpsyg.2023.1199058
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85161937174&doi=10.3389%2ffpsyg.2023.1199058&partnerID=40&md5=d9e02bf0a352a48dc6b683bf9e0f2186
AD  - Department of Psychology and Educational Counseling, The Center for Psychobiological Research, Max Stern Yezreel Valley College, Emek Yezreel, Israel
AD  - Department of Brain Sciences, Faculty of Medicine, Imperial College London, London, United Kingdom
AD  - Psychology Department, Center for Psychobiological Research, Max Stern Yezreel Valley College, Emek Yezreel, Israel
AB  - The artificial intelligence chatbot, ChatGPT, has gained widespread attention for its ability to perform natural language processing tasks and has the fastest-growing user base in history. Although ChatGPT has successfully generated theoretical information in multiple fields, its ability to identify and describe emotions is still unknown. Emotional awareness (EA), the ability to conceptualize one’s own and others’ emotions, is considered a transdiagnostic mechanism for psychopathology. This study utilized the Levels of Emotional Awareness Scale (LEAS) as an objective, performance-based test to analyze ChatGPT’s responses to twenty scenarios and compared its EA performance with that of the general population norms, as reported by a previous study. A second examination was performed one month later to measure EA improvement over time. Finally, two independent licensed psychologists evaluated the fit-to-context of ChatGPT’s EA responses. In the first examination, ChatGPT demonstrated significantly higher performance than the general population on all the LEAS scales (Z score = 2.84). In the second examination, ChatGPT’s performance significantly improved, almost reaching the maximum possible LEAS score (Z score = 4.26). Its accuracy levels were also extremely high (9.7/10). The study demonstrated that ChatGPT can generate appropriate EA responses, and that its performance may improve significantly over time. The study has theoretical and clinical implications, as ChatGPT can be used as part of cognitive training for clinical populations with EA impairments. In addition, ChatGPT’s EA-like abilities may facilitate psychiatric diagnosis and assessment and be used to enhance emotional language. Further research is warranted to better understand the potential benefits and risks of ChatGPT and refine it to promote mental health. Copyright © 2023 Elyoseph, Hadar-Shoval, Asraf and Lvovsky.
KW  - artificial intelligence
KW  - ChatGPT
KW  - emotional awareness
KW  - emotional intelligence
KW  - LEAS
KW  - psychological assessment
KW  - psychotherapy
PB  - Frontiers Media S.A.
SN  - 16641078 (ISSN)
LA  - English
J2  - Front. Psychol.
M3  - Article
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 12; Correspondence Address: Z. Elyoseph; Department of Psychology and Educational Counseling, The Center for Psychobiological Research, Max Stern Yezreel Valley College, Emek Yezreel, Israel; email: Zohare@yvc.ac.il
ER  -

TY  - CONF
AU  - Khan, A.A.
AU  - Kamal, F.
AU  - Nower, N.
AU  - Ahmed, T.
AU  - Chowdhury, T.M.
TI  - An Evaluation of Transformer-Based Models in Personal Health Mention Detection
PY  - 2022
T2  - Proceedings of 2022 25th International Conference on Computer and Information Technology, ICCIT 2022
SP  - 1
EP  - 6
DO  - 10.1109/ICCIT57492.2022.10054937
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85150216406&doi=10.1109%2fICCIT57492.2022.10054937&partnerID=40&md5=8c24f090f521a800f21d33c8e30ab985
AD  - Islamic University of Technology, Department of Computer Science and Engineering, Dhaka, Bangladesh
AB  - In public health surveillance, the identification of Personal Health Mentions (PHM) is an essential initial step. It involves examining a social media post that mentions an illness and determining whether the context of the post is about an actual person facing the illness or not. When attempting to determine how far a disease has spread, the monitoring of such public posts linked to healthcare is crucial, and numerous datasets have been produced to aid researchers in developing techniques to handle this. Unfortunately, social media posts tend to contain links, emojis, informal phrasing, sarcasm, etc., making them challenging to work with. To handle such issues and detect PHMs directly from social media posts, we propose a few transformer-based models and compare their performances. These models have not undergone a thorough evaluation in this domain, but are known to perform well on other language-related tasks. We trained the models on an imbalanced dataset produced by collecting a large number of public posts from Twitter. The empirical results show that we have achieved state-of-the-art performance on the dataset, with an average F1 score of 94.5% with the RoBERTa-based classifier. The code used in our experiments is publicly available1.  © 2022 IEEE.
KW  - Health Monitoring
KW  - Natural Language Processing
KW  - Social Media
KW  - Transformers
KW  - Classification (of information)
KW  - Large dataset
KW  - Natural language processing systems
KW  - Petroleum reservoir evaluation
KW  - Social networking (online)
KW  - Health monitoring
KW  - Imbalanced dataset
KW  - Language processing
KW  - Natural language processing
KW  - Natural languages
KW  - Performance
KW  - Personal health
KW  - Public health surveillances
KW  - Social media
KW  - Transformer
KW  - Diseases
PB  - Institute of Electrical and Electronics Engineers Inc.
SN  - 979-835034602-2 (ISBN)
LA  - English
J2  - Proc. Int. Conf. Comput. Inf. Technol., ICCIT
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 0; Correspondence Address: A.A. Khan; Islamic University of Technology, Department of Computer Science and Engineering, Dhaka, Bangladesh; email: alviaveen@iut-dhaka.edu; Conference name: 25th International Conference on Computer and Information Technology, ICCIT 2022; Conference date: 17 December 2022 through 19 December 2022; Conference code: 187046
ER  -

TY  - JOUR
AU  - Zhang, Y.
AU  - Tang, Y.
AU  - Liu, Y.
AU  - Liang, Z.
TI  - Research on Variable Weight Synthesizing Model for Transformer Condition Assessment
PY  - 2022
T2  - Frontiers in Energy Research
VL  - 10
C7  - 941985
DO  - 10.3389/fenrg.2022.941985
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85134170708&doi=10.3389%2ffenrg.2022.941985&partnerID=40&md5=b76741119d966ab16e3d080cb9b27530
AD  - Academic Affairs Office, Guangdong University of Finance and Economics, Guangzhou, China
AD  - School of Information Science, Guangdong University of Finance and Economics, Guangzhou, China
AD  - School of Electric Power, South China University of Technology, Guangzhou, China
AB  - Transformer is one of the important equipment in the power grid, which helps to integrate renewable energy into the transmission and distribution network efficiently. The safe and stable operation of transformer is of great importance for the reliable transmission of electricity generated from renewable energy and for the reliable use of electricity by the end users. Therefore, it is important to assess the condition to avoid the faults of the transformer. In this paper, a variable weight synthesizing assessment model is presented that combines the G1 method, the entropy weight method, and a variable-weight method proposed in this paper to assess the condition of transformer based on the offset of the transformer equivalent circuit parameters. First, we propose deterioration indexes oriented to the maintenance management needs, which can well reflect the degree of deterioration of each transformer component. Second, the various defects of the transformer are used as the assessment indexes, and the initial weight is given to the assessment indexes according to the damage degree of the defect. The initial weight is calculated comprehensively by the G1 method and the entropy weight method. Then, each index is scored according to the offset of the equivalent circuit parameters, and the weights are adjusted appropriately according to the scores of the indicators using a variable weighting method to emphasize the severity of the defect or the “sub-health” condition of the transformer. Finally, the respective scores and combined weights of the assessment indexes are weighted to obtain a comprehensive score. The simulation shows that the model is more sensitive to abnormal and “subhealth” conditions of the transformer, which verifies the feasibility of the variable weight synthesizing model to assess the condtion of the transformer. Copyright © 2022 Zhang, Tang, Liu and Liang.
KW  - deterioration indexes
KW  - entropy weight method
KW  - G1 method
KW  - transformer condition assessment
KW  - variable weight synthesizing model
KW  - Damage detection
KW  - Deterioration
KW  - Electric network analysis
KW  - Electric network parameters
KW  - Electric power transmission networks
KW  - Entropy
KW  - Equivalent circuits
KW  - Assessment index
KW  - Condition
KW  - Deterioration index
KW  - Entropy weight method
KW  - Equivalent circuit parameter
KW  - G1 method
KW  - Initial weights
KW  - Transformer condition assessment
KW  - Variable weight
KW  - Variable weight synthesizing model
KW  - Defects
PB  - Frontiers Media S.A.
SN  - 2296598X (ISSN)
LA  - English
J2  - Front. Energy Res.
M3  - Article
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 3; Correspondence Address: Y. Zhang; Academic Affairs Office, Guangdong University of Finance and Economics, Guangzhou, China; email: zhangyan@gdufe.edu.cn
ER  -

TY  - JOUR
AU  - Chen, Q.
AU  - Li, C.
AU  - Cheng, S.
AU  - Sun, W.
AU  - Chi, M.
AU  - Zhang, H.
TI  - Study on Aging Assessment Model of Transformer Cellulose Insulation Paper Based on Methanol in Oil
PY  - 2022
T2  - IEEE Transactions on Dielectrics and Electrical Insulation
VL  - 29
IS  - 2
SP  - 591
EP  - 598
DO  - 10.1109/TDEI.2022.3157900
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85126284660&doi=10.1109%2fTDEI.2022.3157900&partnerID=40&md5=95e35b3a1366e2df993def20f1eb7f81
AD  - Key Laboratory of EngineeringDielectrics and Its Application, School of Electrical and Electronic Engineering, Ministry of Education, Harbin University of Science and Technology, Harbin, 150080, China
AD  - Electric Power Research Institute, State Grid Heilongjiang Electric Power Company Ltd., Harbin, 150030, China
AB  - Methanol is considered to be a new chemical marker to estimate the aging state of transformer cellulose insulation paper. The key to improve the assessment accuracy is to establish the precise relationship between the concentration of methanol in oil and degree of polymerization (DP) of insulation paper. The previous research in this area has shortcomings and needs to be further improved. In this article, first, an aging assessment basic model (temperature 20 °C, moisture content of insulation paper 0.637%) is established based on the theoretical derivation of cellulose degradation kinetics, and is calculated by 130 °C thermal aging experiment. Furthermore, the effects of different temperatures (20 °C-90 °C) and moisture contents of insulation paper (0.6%-3.4%) on methanol in oil are studied by diffusion experiment. Based on the above effects, the temperature and moisture correction factors are established by mathematical reduction. What is more, a modified model is proposed by integrating the basic model and the correction factors. Eventually, the verification experiment is randomly prepared to test the accuracy of modified model and the result shows that the relative error of DP is within 7%. The physical meaning and accuracy of aging assessment are improved by model derivation and modification of influencing factors. © 2022 IEEE.
KW  - Aging assessment model
KW  - degree of polymerization (DP)
KW  - insulation paper
KW  - methanol
KW  - moisture
KW  - temperature
KW  - Cellulose
KW  - Degradation
KW  - Methanol
KW  - Polymerization
KW  - Thermal Insulation
KW  - Cellulose
KW  - Degradation
KW  - Insulating materials
KW  - Methanol
KW  - Moisture determination
KW  - Oil filled transformers
KW  - Polymerization
KW  - Power transformers
KW  - Thermal aging
KW  - Thermal insulation
KW  - %moisture
KW  - Aging assessment
KW  - Aging assessment model
KW  - Assessment models
KW  - Degree of polymerization
KW  - Degrees of polymerizations
KW  - Insulation paper
KW  - Oil
KW  - Oil insulations
KW  - Power transformer insulation
KW  - Moisture
PB  - Institute of Electrical and Electronics Engineers Inc.
SN  - 10709878 (ISSN)
LA  - English
J2  - IEEE Trans Dielectr Electr Insul
M3  - Article
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 8; Correspondence Address: S. Cheng; Key Laboratory of EngineeringDielectrics and Its Application, School of Electrical and Electronic Engineering, Ministry of Education, Harbin University of Science and Technology, Harbin, 150080, China; email: aystcs@sina.com; CODEN: ITDIE
ER  -

TY  - CONF
AU  - Aracena, C.
AU  - Villena, F.
AU  - Rojas, M.
AU  - Dunstan, J.
TI  - A Knowledge-Graph-Based Intrinsic Test for Benchmarking Medical Concept Embeddings and Pretrained Language Models
PY  - 2022
T2  - LOUHI 2022 - 13th International Workshop on Health Text Mining and Information Analysis, Proceedings of the Workshop
SP  - 197
EP  - 206
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85154552744&partnerID=40&md5=5f66db3444e6b8b4c584c38014fe7173
AD  - Faculty of Physical and Mathematical Sciences, University of Chile, Chile
AD  - Center for Mathematical Modeling, University of Chile, Chile
AB  - Using language models created from large data sources has improved the performance of several deep learning-based architectures, obtaining state-of-the-art results in several NLP extrinsic tasks. However, little research is related to creating intrinsic tests that allow us to compare the quality of different language models when obtaining contextualized embeddings. This gap increases even more when working on specific domains in languages other than English. This paper proposes a novel graph-based intrinsic test that allows us to measure the quality of different language models in clinical and biomedical domains in Spanish. Our results show that our intrinsic test performs better for clinical and biomedical language models than a general one. Also, it correlates with better outcomes for a NER task using a probing model over contextualized embeddings. We hope our work will help the clinical NLP research community to evaluate and compare new language models in other languages and find the most suitable models for solving downstream tasks.  © 2022 Association for Computational Linguistics.
KW  - Clinical research
KW  - Computational linguistics
KW  - Deep learning
KW  - Graphic methods
KW  - Natural language processing systems
KW  - Biomedical domain
KW  - Data-source
KW  - Embeddings
KW  - Graph-based
KW  - Knowledge graphs
KW  - Language model
KW  - Large data
KW  - Medical concepts
KW  - Performance
KW  - State of the art
KW  - Embeddings
PB  - Association for Computational Linguistics (ACL)
SN  - 978-195942913-5 (ISBN)
LA  - English
J2  - LOUHI - Int. Workshop Health Text Min. Inf. Anal., Proc. Workshop
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 1; Conference name: 13th International Workshop on Health Text Mining and Information Analysis, LOUHI 2022, co-located with EMNLP 2022; Conference code: 187852
ER  -

TY  - JOUR
AU  - Mohammed, M.
AU  - Kumar, N.
AU  - Zawiah, M.
AU  - Al-Ashwal, F.Y.
AU  - Bala, A.A.
AU  - Lawal, B.K.
AU  - Wada, A.S.
AU  - Halboup, A.
AU  - Muhammad, S.
AU  - Ahmad, R.
AU  - Sha’aban, A.
TI  - Psychometric Properties and Assessment of Knowledge, Attitude, and Practice Towards ChatGPT in Pharmacy Practice and Education: a Study Protocol
PY  - 2023
T2  - Journal of Racial and Ethnic Health Disparities
DO  - 10.1007/s40615-023-01696-1
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85164342661&doi=10.1007%2fs40615-023-01696-1&partnerID=40&md5=360f9b7bfba3048118d18a8bb7f886d7
AD  - Department of Clinical Pharmacy and Pharmacy Practice, Faculty of Pharmaceutical Sciences, Ahmadu Bello University, Zaria, Kaduna, Nigeria
AD  - School of Pharmaceutical Sciences, Universiti Sains Malaysia, Pulau Pinang, Gelugor, Malaysia
AD  - Vice President for Medical and Health Science Office, QU Health, Qatar University, Doha, Qatar
AD  - Department of Pharmacy Practice, Faculty of Pharmacy, University of Sindh Jamshoro, Sindh, Pakistan
AD  - Department of Pharmacy Practice, Faculty of Clinical Pharmacy, Hodeidah University, Al Hodeidah, Yemen
AD  - Department of Pharmacy, Al-Maarif University College, Anbar, 31001, Iraq
AD  - Department of Pharmacology, College of Medicine and Health Sciences, Federal University Dutse, Jigawa, Dutse, Nigeria
AD  - Department of Clinical Pharmacy and Pharmacy Management, Kaduna State University, Kaduna, Nigeria
AD  - Department of Pharmacology and Therapeutics, Bayero University, Kano, Nigeria
AD  - Department of Clinical Pharmacy and Pharmacy Practice, University of Science and Technology, Sana’a, Yemen
AD  - Faculty of Veterinary Medicine, Ahmadu Bello University, Zaria, Kaduna, Nigeria
AD  - Division of Population Medicine, School of Medicine, Cardiff University, Heath Park, Cardiff, CF14 4YS, United Kingdom
AB  - ChatGPT represents an advanced conversational artificial intelligence (AI), providing a powerful tool for generating human-like responses that could change pharmacy prospects. This protocol aims to describe the development, validation, and utilization of a tool to assess the knowledge, attitude, and practice towards ChatGPT (KAP-C) in pharmacy practice and education. The development and validation process of the KAP-C tool will include a comprehensive literature search to identify relevant constructs, content validation by a panel of experts for items relevancy using content validity index (CVI) and face validation by sample participants for items clarity using face validity index (FVI), readability and difficulty index using the Flesch-Kincaid Readability Test, Gunning Fog Index, or Simple Measure of Gobbledygook (SMOG), assessment of reliability using internal consistency (Cronbach’s alpha), and exploratory factor analysis (EFA) to determine the underlying factor structures (eigenvalues, scree plot analysis, factor loadings, and varimax). The second phase will utilize the validated KAP-C tool to conduct KAP surveys among pharmacists and pharmacy students in selected low- and middle-income countries (LMICs) (Nigeria, Pakistan, and Yemen). The final data will be analyzed descriptively using frequencies, percentages, mean (standard deviation) or median (interquartile range), and inferential statistics like Chi-square or regression analyses using IBM SPSS version 28. A p<0.05 will be considered statistically significant. ChatGPT holds the potential to revolutionize pharmacy practice and education. This study will highlight the psychometric properties of the KAP-C tool that assesses the knowledge, attitude, and practice towards ChatGPT in pharmacy practice and education. The findings will contribute to the potential ethical integration of ChatGPT into pharmacy practice and education in LMICs, serve as a reference to other economies, and provide valuable evidence for leveraging AI advancements in pharmacy. © 2023, W. Montague Cobb-NMA Health Institute.
KW  - Artificial intelligence
KW  - Attitude
KW  - ChatGPT
KW  - Knowledge
KW  - Pharmacy
KW  - Practice
PB  - Springer Science and Business Media Deutschland GmbH
SN  - 21973792 (ISSN)
LA  - English
J2  - J Racial Ethn Health Disparities
M3  - Article
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 6; Correspondence Address: M. Mohammed; Department of Clinical Pharmacy and Pharmacy Practice, Faculty of Pharmaceutical Sciences, Ahmadu Bello University, Kaduna, Zaria, Nigeria; email: mohammedmmrx@gmail.com
ER  -

TY  - JOUR
AU  - Garrido-Muñoz, I.
AU  - Martínez-Santiago, F.
AU  - Montejo-Ráez, A.
TI  - MarIA and BETO are sexist: evaluating gender bias in large language models for Spanish
PY  - 2023
T2  - Language Resources and Evaluation
DO  - 10.1007/s10579-023-09670-3
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85165496043&doi=10.1007%2fs10579-023-09670-3&partnerID=40&md5=22862578767756883b877541f5320189
AD  - CEATIC, Universidad de Jaén, Campus Las Lagunillas, Jaén, 23071, Spain
AB  - The study of bias in language models is a growing area of work, however, both research and resources are focused on English. In this paper, we make a first approach focusing on gender bias in some freely available Spanish language models trained using popular deep neural networks, like BERT or RoBERTa. Some of these models are known for achieving state-of-the-art results on downstream tasks. These promising results have promoted such models’ integration in many real-world applications and production environments, which could be detrimental to people affected for those systems. This work proposes an evaluation framework to identify gender bias in masked language models, with explainability in mind to ease the interpretation of the evaluation results. We have evaluated 20 different models for Spanish, including some of the most popular pretrained ones in the research community. Our findings state that varying levels of gender bias are present across these models.This approach compares the adjectives proposed by the model for a set of templates. We classify the given adjectives into understandable categories and compute two new metrics from model predictions, one based on the internal state (probability) and the other one on the external state (rank). Those metrics are used to reveal biased models according to the given categories and quantify the degree of bias of the models under study. © 2023, The Author(s).
KW  - BERT
KW  - Bias evaluation
KW  - Deep learning
KW  - Gender bias
KW  - Language model
KW  - RoBERTa
PB  - Springer Science and Business Media B.V.
SN  - 1574020X (ISSN)
LA  - English
J2  - Lang. Resour. Eval.
M3  - Article
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 0; Correspondence Address: I. Garrido-Muñoz; CEATIC, Universidad de Jaén, Jaén, Campus Las Lagunillas, 23071, Spain; email: igmunoz@ujaen.es
ER  -

TY  - CONF
AU  - Sarkisyan, C.
AU  - Korchemnyi, A.
AU  - Kovalev, A.K.
AU  - Panov, A.I.
TI  - Evaluation of Pretrained Large Language Models in Embodied Planning Tasks
PY  - 2023
T2  - Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)
VL  - 13921 LNCS
SP  - 222
EP  - 232
DO  - 10.1007/978-3-031-33469-6_23
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85163306934&doi=10.1007%2f978-3-031-33469-6_23&partnerID=40&md5=9b81f42aac6bf23c80a7f91317cb232e
AD  - Moscow Institute of Physics and Technology, Dolgoprudny, Russian Federation
AD  - AIRI, Moscow, Russian Federation
AD  - Federal Research Center “Computer Science and Control” of the Russian Academy of Sciences, Moscow, Russian Federation
AB  - Modern pretrained large language models (LLMs) are increasingly being used in zero-shot or few-shot learning modes. Recent years have seen increased interest in applying such models to embodied artificial intelligence and robotics tasks. When given in a natural language, the agent needs to build a plan based on this prompt. The best solutions use LLMs through APIs or models that are not publicly available, making it difficult to reproduce the results. In this paper, we use publicly available LLMs to build a plan for an embodied agent and evaluate them in three modes of operation: 1) the subtask evaluation mode, 2) the full autoregressive plan generation, and 3) the step-by-step autoregressive plan generation. We used two prompt settings: prompt-containing examples of one given task and a mixed prompt with examples of different tasks. Through extensive experiments, we have shown that the subtask evaluation mode, in most cases, outperforms others with a task-specific prompt, whereas the step-by-step autoregressive plan generation posts better performance in the mixed prompt setting. © 2023, The Author(s), under exclusive license to Springer Nature Switzerland AG.
KW  - Large language models
KW  - Plan generation
KW  - Planning for embodied agents
KW  - Computational linguistics
KW  - Auto-regressive
KW  - Embodied agent
KW  - Evaluation modes
KW  - Language model
KW  - Large language model
KW  - Learning mode
KW  - Plan generation
KW  - Planning for embodied agent
KW  - Planning tasks
KW  - Subtask
KW  - Zero-shot learning
A2  - Hammer P.
A2  - Alirezaie M.
A2  - Strannegård C.
PB  - Springer Science and Business Media Deutschland GmbH
SN  - 03029743 (ISSN); 978-303133468-9 (ISBN)
LA  - English
J2  - Lect. Notes Comput. Sci.
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 0; Correspondence Address: A.K. Kovalev; AIRI, Moscow, Russian Federation; email: kovalev@airi.net; Conference name: 16th International Conference on Artificial General Intelligence, AGI 2023; Conference date: 16 June 2023 through 19 June 2023; Conference code: 295439
ER  -

TY  - JOUR
AU  - Sharma, U.
AU  - Pandey, P.
AU  - Kumar, S.
TI  - A Transformer-Based Model for Evaluation of Information Relevance in Online Social-Media: A Case Study of Covid-19 Media Posts
PY  - 2022
T2  - New Generation Computing
VL  - 40
IS  - 4
SP  - 1029
EP  - 1052
DO  - 10.1007/s00354-021-00151-1
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85122920685&doi=10.1007%2fs00354-021-00151-1&partnerID=40&md5=d796237cfd95fe530bc828affb3ab027
AD  - Department of Computer Science and Engineering, Jaypee University of Engineering and Technology, Guna, India
AD  - Department of Computer Science, Babasaheb Bhimrao Ambedkar University, Lucknow, India
AB  - Online social media has become a major source of information gathering for a huge section of society. As the amount of information flows in online social media is enormous but on the other hand, the fact-checking sources are limited. This shortfall of fact-checking gives birth to the problem of misinformation and disinformation in the case of the truthfulness of facts on online social media which can have serious effects on the wellbeing of society. This problem of misconception becomes more rapid and critical when some events like the recent outbreak of Covid-19 happen when there is no or very little information is available anywhere. In this scenario, the identification of the content available online which is mostly propagated from person to person and not by any governing authority is very needed at the hour. To solve this problem, the information available online should be verified properly before being conceived by any individual. We propose a scheme to classify the online social media posts (Tweets) with the help of the BERT (Bidirectional Encoder Representations from Transformers)-based model. Also, we compared the performance of the proposed approach with the other machine learning techniques and other State of the art techniques available. The proposed model not only classifies the tweets as relevant or irrelevant, but also creates a set of topics by which one can identify a text as relevant or irrelevant to his/her need just by just matching the keywords of the topic. To accomplish this task, after the classification of the tweets, we apply a possible topic modelling approach based on latent semantic analysis and latent Dirichlet allocation methods to identify which of the topics are mostly propagated as false information. © 2022, Ohmsha, Ltd. and Springer Japan KK, part of Springer Nature.
KW  - BERT
KW  - Covid-19
KW  - Online social media
KW  - Text mining
KW  - Tweet classification
KW  - Learning systems
KW  - Semantics
KW  - Social networking (online)
KW  - Statistics
KW  - Text processing
KW  - Amount of information
KW  - Bidirectional encoder representation from transformer
KW  - Case-studies
KW  - Covid-19
KW  - Information gathering
KW  - Information relevances
KW  - Online social medias
KW  - Sources of informations
KW  - Text-mining
KW  - Tweet classification
KW  - Classification (of information)
PB  - Springer
SN  - 02883635 (ISSN)
LA  - English
J2  - New Gener Comput
M3  - Article
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 3; Correspondence Address: U. Sharma; Department of Computer Science and Engineering, Jaypee University of Engineering and Technology, Guna, India; email: utkarsh_shar@yahoo.co.in; CODEN: NGCOE
ER  -

TY  - CONF
AU  - Patel, D.
AU  - Chothani, N.
TI  - Evaluation of Various Dynamics on Current Transformer Saturation with a Model Study on Power System Protection
PY  - 2023
T2  - Lecture Notes in Electrical Engineering
VL  - 960
SP  - 121
EP  - 136
DO  - 10.1007/978-981-19-6605-7_10
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85147852653&doi=10.1007%2f978-981-19-6605-7_10&partnerID=40&md5=2121e8d3e3c51a8e6f014c15e764d8d2
AD  - Electrical Department, Government Engineering College, Old N.H., College Road, Gujarat, Bholav, Bharuch, 392002, India
AD  - Electrical Department, Pandit Deendayal Energy University, Knowledge Corridor, Raisan Village, PDPU Rd, Gandhinagar, Gujarat, 382007, India
AB  - Now a day most power system protective schemes are incorporated with a current transformer (CT) to reduce the current level of the power system, especially during heavy fault current. Due to the influence of different parameters of CT, various protective schemes give adverse operations because of adulterous quantity measurement by CT. Recently most of the protective scheme’s mis-operates in an abnormal situation of the power system. Various adverse effects are observed in protective CT due to mismatch in CT ratio, CT saturation, error in measurement, due to different fault inception angles (FIA), greater burden and remnant flux, etc. So, it is a mandatory requirement of knowledge of the relaying schemes and their measures, nobody can predict the recital of a relay in non-sinusoidal current waveforms. There are special effects are generated under different types of relays like Electromagnetic, static, and digital under different CT saturation conditions and parameter variations. Relays are getting signals due to various parameters like phase shifting and phasor difference of applied current. Also, those parameters are violated due to different phase shifts of various frequencies of distorted currents. Time to enter the non-linear region of operational CTs is additionally important and its refinements are also a major issue. This article covers various parameter effects on CT saturation during measuring and protection of the power system network. All conditions and results are verified using PSCAD™ software simulation. © 2023, The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd.
KW  - CT burden
KW  - CT saturation
KW  - DC component
KW  - Fault
KW  - Fault inception angle (FIA)
KW  - Power system protection
KW  - Computer software
KW  - DC transformers
KW  - Electric currents
KW  - Electric power system protection
KW  - Relay protection
KW  - Transformer protection
KW  - Current transformer burden
KW  - Current transformer saturation
KW  - DC components
KW  - Fault
KW  - Fault inception angle
KW  - Fault inception angles
KW  - On currents
KW  - On-currents
KW  - Power
KW  - Power system protection
KW  - Electric instrument transformers
A2  - Gupta O.H.
A2  - Singh S.N.
A2  - Malik O.P.
PB  - Springer Science and Business Media Deutschland GmbH
SN  - 18761100 (ISSN); 978-981196604-0 (ISBN)
LA  - English
J2  - Lect. Notes Electr. Eng.
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 1; Correspondence Address: N. Chothani; Electrical Department, Pandit Deendayal Energy University, Gujarat, Knowledge Corridor, Raisan Village, PDPU Rd, Gandhinagar, 382007, India; email: chothani_nilesh@rediffmail.com; Conference name: 3rd Electric Power and Renewable Energy Conference, EPREC 2022; Conference date: 27 May 2022 through 29 May 2022; Conference code: 289329
ER  -

TY  - JOUR
AU  - Tong, T.
AU  - Li, D.
AU  - Gu, J.
AU  - Chen, G.
AU  - Bai, G.
AU  - Yang, X.
AU  - Wang, K.
AU  - Jiang, T.
AU  - Tian, J.
TI  - Dual-Input Transformer: An End-to-End Model for Preoperative Assessment of Pathological Complete Response to Neoadjuvant Chemotherapy in Breast Cancer Ultrasonography
PY  - 2023
T2  - IEEE Journal of Biomedical and Health Informatics
VL  - 27
IS  - 1
SP  - 251
EP  - 262
DO  - 10.1109/JBHI.2022.3216031
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85140733128&doi=10.1109%2fJBHI.2022.3216031&partnerID=40&md5=ea89ca6ec6069df67cb43ec3431d7e87
AD  - Chinese Academy of Sciences, Cas Key Laboratory of Molecular Imaging, Institute of Automation, Beijing, 100190, China
AD  - China Mobile Information Technology Center, Beijing, 100033, China
AD  - Beihang University, Beijing Advanced Innovation Center for Big Data-Based Precision Medicine, Beijing, 100191, China
AD  - Zhejiang University, Department of Ultrasound, The First Affiliated Hospital, College of Medicine, Hangzhou, 310003, China
AD  - University of Chinese Academy of Sciences, School of Artificial Intelligence, Beijing, 100049, China
AB  - Neoadjuvant chemotherapy (NAC) is the primary method to reduce the burden of tumor and metastasis; in the treatment of breast cancer, it may provide additional opportunities for breast-conserving surgery. Preoperative assessment of pathological complete response (PCR) to NAC is important for developing individualized treatment approaches and predicting patient prognosis. Compared to magnetic resonance imaging (MRI) and mammography, ultrasonography (US) has the advantages of simplicity, flexibility, and real-time imaging. Moreover, it does not require radiation and can provide multi-time acquisition of the tumor during NAC treatment. Recently, deep learning radiomics models based on multi-time-point US images for the prediction of NAC effectiveness have been proposed. To further improve the prediction performance, we carefully designed four supporting modules for our proposed dual-input transformer (DiT): isolated tokens-to-token patch embedding module, shared position embedding, time embedding, and weighted average pooling feature representation modules. The design of each module considers the characteristics of the US images at multiple time points. We validated our model on our retrospective US dataset composed of 484 cases from two centers whose consistency is not sufficiently high. Patients were allocated to training (n = 297), validation (n = 99), and external test (n = 88) sets. The results show that our model can achieve better performance than the Siamese CNN and the standard tokens-to-token vision transformer without using multi-time-point images. The ablation study also proved the effectiveness of each module designed for DiT.  © 2013 IEEE.
KW  - Breast cancer
KW  - deep learning
KW  - neoadjuvant chemotherapy
KW  - transformer
KW  - ultrasonography
KW  - Breast Neoplasms
KW  - Female
KW  - Humans
KW  - Magnetic Resonance Imaging
KW  - Neoadjuvant Therapy
KW  - Retrospective Studies
KW  - Treatment Outcome
KW  - Ultrasonography, Mammary
KW  - Chemotherapy
KW  - Deep neural networks
KW  - Diseases
KW  - Embeddings
KW  - Forecasting
KW  - Magnetic resonance imaging
KW  - Medical imaging
KW  - Surgery
KW  - Tumors
KW  - Breast Cancer
KW  - Convolutional neural network
KW  - Deep learning
KW  - Neoadjuvant chemotherapies
KW  - Predictive models
KW  - Radiomic
KW  - Time points
KW  - Transformer
KW  - accuracy
KW  - adult
KW  - Article
KW  - breast cancer
KW  - breast-conserving surgery
KW  - cancer prognosis
KW  - controlled study
KW  - convolutional neural network
KW  - diagnostic test accuracy study
KW  - echography
KW  - female
KW  - human
KW  - image quality
KW  - learning algorithm
KW  - middle aged
KW  - neoadjuvant chemotherapy
KW  - polymerase chain reaction
KW  - prediction
KW  - predictive model
KW  - radiomics
KW  - retrospective study
KW  - training
KW  - treatment response
KW  - Youden index
KW  - breast tumor
KW  - echomammography
KW  - neoadjuvant therapy
KW  - nuclear magnetic resonance imaging
KW  - pathology
KW  - procedures
KW  - treatment outcome
KW  - Ultrasonography
PB  - Institute of Electrical and Electronics Engineers Inc.
SN  - 21682194 (ISSN)
C2  - 36264731
LA  - English
J2  - IEEE J. Biomedical Health Informat.
M3  - Article
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 5; Correspondence Address: K. Wang; Chinese Academy of Sciences, Cas Key Laboratory of Molecular Imaging, Institute of Automation, Beijing, 100190, China; email: kun.wang@ia.ac.cn; J. Tian; Chinese Academy of Sciences, Cas Key Laboratory of Molecular Imaging, Institute of Automation, Beijing, 100190, China; email: tian@ieee.org; T. Jiang; Zhejiang University, Department of Ultrasound, The First Affiliated Hospital, College of Medicine, Hangzhou, 310003, China; email: tiananjiang@zju.edu.cn; CODEN: ITIBF
ER  -

TY  - JOUR
AU  - Khan, S.
AU  - Shahid, M.
AU  - Singh, N.
TI  - BERT Probe: A python package for probing attention based robustness evaluation of BERT models[Formula presented]
PY  - 2022
T2  - Software Impacts
VL  - 13
C7  - 100310
DO  - 10.1016/j.simpa.2022.100310
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85130372142&doi=10.1016%2fj.simpa.2022.100310&partnerID=40&md5=311168895083036031ca8ea275a34b95
AD  - Saarland University, Germany
AB  - Transformer models based on attention-based architectures have been significantly successful in establishing state-of-the-art results in natural language processing (NLP). However, recent work about adversarial robustness of attention-based models show that their robustness is susceptible to adversarial inputs causing spurious outputs thereby raising questions about trustworthiness of such models. In this paper, we present BERT Probe which is a python-based package for evaluating robustness to attention attribution based on character-level and word-level evasion attacks and empirically quantifying potential vulnerabilities for sequence classification tasks. Additionally, BERT Probe also provides two out-of-the-box defenses against character-level attention attribution-based evasion attacks. © 2022 The Author(s)
KW  - Adversarial machine learning
KW  - BERT
KW  - Deep learning
KW  - Transformers
PB  - Elsevier B.V.
SN  - 26659638 (ISSN)
LA  - English
J2  - Softw. Impacts.
M3  - Article
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 1; Correspondence Address: S. Khan; Saarland University, Germany; email: shkh00001@stud.uni-saarland.de
ER  -

TY  - CONF
AU  - Alrajhi, W.
AU  - Al-Khalifa, H.
AU  - Al-Salman, A.
TI  - Assessing the Linguistic Knowledge in Arabic Pre-trained Language Models Using Minimal Pairs
PY  - 2022
T2  - WANLP 2022 - 7th Arabic Natural Language Processing - Proceedings of the Workshop
SP  - 185
EP  - 193
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85152898750&partnerID=40&md5=f215469dae4899a31021c7b5df102ba4
AD  - King Saud University, Saudi Arabia
AB  - Despite the noticeable progress that we recently witnessed in Arabic pre-trained language models (PLMs), the linguistic knowledge captured by these models remains unclear. In this paper, we conducted a study to evaluate available Arabic PLMs in terms of their linguistic knowledge. BERT-based language models (LMs) are evaluated using Minimum Pairs (MP), where each pair represents a grammatical sentence and its contradictory counterpart. MPs isolate specific linguistic knowledge to test the model's sensitivity in understanding a specific linguistic phenomenon. We cover nine major Arabic phenomena from: Verbal sentences, Nominal sentences, Adjective Modification, and Idafa construction. The experiments compared the results of fifteen Arabic BERT-based PLMs. Overall, among all tested models, CAMeL-CA and GigaBERT outperformed the other PLMs by achieving the highest overall accuracy. © 2022 Association for Computational Linguistics.
KW  - Language model
KW  - Linguistic knowledge
KW  - Linguistic phenomena
KW  - Model sensitivity
KW  - Overall accuracies
KW  - Computational linguistics
PB  - Association for Computational Linguistics (ACL)
SN  - 978-195942927-2 (ISBN)
LA  - English
J2  - WANLP - Arabic Nat. Lang. Process. - Proc. Workshop
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 0; Conference name: 7th Arabic Natural Language Processing Workshop, WANLP 2022 held with EMNLP 2022; Conference code: 187665
ER  -

TY  - CONF
AU  - Meyer, S.
AU  - Elsweiler, D.
AU  - Ludwig, B.
AU  - Fernandez-Pichel, M.
AU  - Losada, D.E.
TI  - Do We Still Need Human Assessors' Prompt-Based GPT-3 User Simulation in Conversational AI
PY  - 2022
T2  - ACM International Conference Proceeding Series
C7  - 26
DO  - 10.1145/3543829.3544529
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85139236546&doi=10.1145%2f3543829.3544529&partnerID=40&md5=09001071d8f06422216c63d747b80045
AD  - Information Science, University of Regensburg, Bavaria, Germany
AD  - Centro Singular de Investigación en Tecnoloxías Intelixentes (CiTIUS), Universidade de Santiago de Compostela, Santiago de Compostela, Spain
AB  - Scarcity of user data continues to be a problem in research on conversational user interfaces and often hinders or slows down technical innovation. In the past, different ways of synthetically generating data, such as data augmentation techniques have been explored. With the rise of ever improving pre-Trained language models, we ask if we can go beyond such methods by simply providing appropriate prompts to these general purpose models to generate data. We explore the feasibility and cost-benefit trade-offs of using non fine-Tuned synthetic data to train classification algorithms for conversational agents. We compare this synthetically generated data with real user data and evaluate the performance of classifiers trained on different combinations of synthetic and real data. We come to the conclusion that, although classifiers trained on such synthetic data perform much better than random baselines, they do not compare to the performance of classifiers trained on even very small amounts of real user data, largely because such data is lacking much of the variability found in user generated data. Nevertheless, we show that in situations where very little data and resources are available, classifiers trained on such synthetically generated data might be preferable to the collection and annotation of naturalistic data.  © 2022 Owner/Author.
KW  - Conversational ai
KW  - Datasets
KW  - Nlp
KW  - Text generation
KW  - Classification (of information)
KW  - Cost benefit analysis
KW  - Economic and social effects
KW  - Conversational ai
KW  - Dataset
KW  - Human assessors
KW  - Nlp
KW  - Performance of classifier
KW  - Synthetic data
KW  - Technical innovation
KW  - Text generations
KW  - User data
KW  - User simulation
KW  - User interfaces
PB  - Association for Computing Machinery
SN  - 978-145039739-1 (ISBN)
LA  - English
J2  - ACM Int. Conf. Proc. Ser.
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 10; Conference name: 4th International Conference on Conversational User Interfaces, CUI 2022; Conference date: 26 July 2022 through 28 July 2022; Conference code: 182764
ER  -

TY  - JOUR
AU  - Sun, C.
AU  - Zhou, Z.
AU  - Zhang, Y.
AU  - Jia, Z.
AU  - Huang, J.
AU  - Huang, C.
TI  - A Dissolved Gas Assessment Model for Power Transformers According to Weighted Association Rule Mining
PY  - 2022
T2  - Frontiers in Energy Research
VL  - 10
C7  - 879869
DO  - 10.3389/fenrg.2022.879869
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85133470920&doi=10.3389%2ffenrg.2022.879869&partnerID=40&md5=08c15738cd18bd31b36d704ac9bf1a57
AD  - Key Laboratory of Renewable Energy Electric-Technology of Hunan Province, Changsha University of Science and Technology, Changsha, China
AD  - School of Electrical and Information Engineering, Changsha University of Science and Technology, Changsha, China
AD  - Northeast Branch of State Grid Corporation of China, Shenyang, China
AB  - As one indispensable part of power systems, the reliable-operated power transformers are vital for energy transmission, whereas they are remarkably threatened by potential fault events. To achieve the satisfying and valid operation of power transformers, any fault events that may impact their health ought to be evaluated and early warned. With such motivations, this paper presents original insights on the assessment of power transmission health states via their internal dissolved gas, and an enhanced Association Rule Mining (ARM) model incorporating the analysis of High-Impact-Low-Probability (HILP) components, as well as a dynamic fault event risk evaluation approach, is proposed. The first step is to differentiate the risky components. Unlike the standard ARM, the rarely occurred components in each feature can also be assessed explicitly as the common components to explore the underlying HILP components in the proposed model, rather than just being viewed as trivial data and directly omitted. The second step is to rate the risk level of each risky component. A component importance measure-based evaluation approach is deployed to assess the corresponding risk weights of distinguished risky components. In this approach, the risk weight is determined straightforwardly via the impacts of each component on the variation level of total risks in the system, rather than simply by its frequency of occurrence or data share. Finally, the parameters of the risk weight evaluation approach can be dynamically adapted in an adjustment framework as well. This model is testified through an empirical case study, and the leading results can demonstrate its flexibility and robustness during real applications. Copyright © 2022 Sun, Zhou, Zhang, Jia, Huang and Huang.
KW  - component importance measure (CIM)
KW  - dissolved gas analysis (DGA)
KW  - HILP component
KW  - transformer diagnosis
KW  - weighted association rule mining
KW  - Data mining
KW  - Electric power transmission
KW  - Health risks
KW  - Power transformers
KW  - Power transmission
KW  - Risk assessment
KW  - Component importance
KW  - Component importance measure
KW  - Dissolved gas analyse
KW  - Dissolved gases analysis
KW  - High impact/low probabilities
KW  - High-impact-low-probability component
KW  - Importance measure
KW  - Transformer diagnosis
KW  - Weighted association rule mining
KW  - Weighted association rules
KW  - Association rules
PB  - Frontiers Media S.A.
SN  - 2296598X (ISSN)
LA  - English
J2  - Front. Energy Res.
M3  - Article
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 2; Correspondence Address: C. Sun; Key Laboratory of Renewable Energy Electric-Technology of Hunan Province, Changsha University of Science and Technology, Changsha, China; email: chenhaosun@csust.edu.cn
ER  -

TY  - CONF
AU  - Shen, D.
AU  - Chen, X.
AU  - Wang, C.
AU  - Sen, K.
AU  - Song, D.
TI  - Benchmarking Language Models for Code Syntax Understanding
PY  - 2022
T2  - Findings of the Association for Computational Linguistics: EMNLP 2022
SP  - 3071
EP  - 3093
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85149829814&partnerID=40&md5=fa3ee9b93d65050ecc5775907114674b
AD  - University of Maryland, College Park, United States
AD  - Google Research, Brain Team
AD  - Washington University, St. Louis, United States
AD  - University of California, Berkeley, United States
AB  - Pre-trained language models have demonstrated impressive performance in both natural language processing and program understanding, which represent the input as a token sequence without explicitly modeling its structure. Some prior works show that pretrained language models can capture the syntactic rules of natural languages without finetuning on syntax understanding tasks. However, there is limited understanding of how well pre-trained models understand the code structure so far. In this work, we perform the first thorough benchmarking of the state-of-the-art pre-trained models for identifying the syntactic structures of programs. Specifically, we introduce CodeSyntax, a large-scale dataset of programs annotated with the syntactic relationships in their corresponding abstract syntax trees. Our key observation is that existing language models pretrained on code still lack the understanding of code syntax. In fact, these pre-trained programming language models fail to match the performance of simple baselines based on positional offsets and keywords. We also present a natural language benchmark to highlight the differences between natural languages and programming languages in terms of syntactic structure understanding. Our findings point out key limitations of existing pre-training methods for programming languages, and suggest the importance of modeling code syntactic structures. © 2022 Association for Computational Linguistics.
KW  - Computational linguistics
KW  - Large dataset
KW  - Modeling languages
KW  - Natural language processing systems
KW  - Syntactics
KW  - Trees (mathematics)
KW  - Code structure
KW  - Language model
KW  - Language processing
KW  - Natural languages
KW  - Performance
KW  - Program understanding
KW  - Syntactic rules
KW  - Syntactic structure
KW  - Token sequences
KW  - Without fine-tuning
KW  - Benchmarking
A2  - Goldberg Y.
A2  - Kozareva Z.
A2  - Zhang Y.
PB  - Association for Computational Linguistics (ACL)
LA  - English
J2  - Find. Assoc. Comput. Linguist.: EMNLP
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 0; Correspondence Address: X. Chen; Google Research, Brain Team; email: xinyunchen@google.com; C. Wang; Washington University, St. Louis, United States; email: chenguangwang@wustl.edu; Conference name: 2022 Findings of the Association for Computational Linguistics: EMNLP 2022; Conference date: 7 December 2022 through 11 December 2022; Conference code: 186900
ER  -

TY  - CONF
AU  - Yoshikawa, H.
AU  - Okazaki, N.
TI  - Selective-LAMA: Selective Prediction for Confidence-Aware Evaluation of Language Models
PY  - 2023
T2  - EACL 2023 - 17th Conference of the European Chapter of the Association for Computational Linguistics, Findings of EACL 2023
SP  - 1972
EP  - 1983
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85159854332&partnerID=40&md5=a2ec8422611b19a91e06325682072b35
AD  - Tokyo Institute of Technology, Japan
AD  - Fujitsu Limited, Japan
AB  - Recent studies have suggested that neural language models learn and store a large amount of facts and commonsense knowledge from training data. The ability of language models to restore such knowledge is often evaluated via zero-shot cloze-style QA tasks. However, such evaluations rely only on prediction accuracy without punishing the systems for their mistakes, e.g., simply guessing or hallucinating likely answers. Selective prediction is a more informative evaluation framework that takes the confidence of predictions into account. Under the selective prediction setting, a model is evaluated not only by the number of correct predictions, but also by the ability to filter out dubious predictions by estimating the confidence of individual predictions. Such confidence-aware evaluation is crucial for determining whether to trust zero-shot predictions of language models. In this paper, we apply the selective prediction setting to an existing benchmark, LAMA probe, and conduct extensive experiments with recent neural language models and different confidence functions. We empirically show that our Selective-LAMA evaluation is more robust to the effect of simple guesses than the conventional accuracy-based evaluation. Our evaluation reveals the importance of the choice of confidence functions by showing that simply relying on token probabilities is not always the best choice. Further analysis shows that various confidence functions exhibit different preferences over predicted tokens for a given context. © 2023 Association for Computational Linguistics.
KW  - Computational linguistics
KW  - Function evaluation
KW  - Zero-shot learning
KW  - Commonsense knowledge
KW  - Evaluation framework
KW  - Fact knowledge
KW  - Individual prediction
KW  - Language model
KW  - Large amounts
KW  - Learn+
KW  - Prediction accuracy
KW  - Simple++
KW  - Training data
KW  - Forecasting
PB  - Association for Computational Linguistics (ACL)
SN  - 978-195942947-0 (ISBN)
LA  - English
J2  - EACL - Conf. Eur. Chapter Assoc. Comput. Linguist., Find. EACL
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 2; Conference name: 17th Conference of the European Chapter of the Association for Computational Linguistics, EACL 2023 - Findings of EACL 2023; Conference date: 2 May 2023 through 6 May 2023; Conference code: 188432
ER  -

TY  - JOUR
AU  - Guarasci, R.
AU  - Silvestri, S.
AU  - De Pietro, G.
AU  - Fujita, H.
AU  - Esposito, M.
TI  - Assessing BERT’s ability to learn Italian syntax: a study on null-subject and agreement phenomena
PY  - 2023
T2  - Journal of Ambient Intelligence and Humanized Computing
VL  - 14
IS  - 1
SP  - 289
EP  - 303
DO  - 10.1007/s12652-021-03297-4
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85105463216&doi=10.1007%2fs12652-021-03297-4&partnerID=40&md5=7c005e809e4bf3ce2c40bc3a356f9e0a
AD  - National Research Council of Italy, Institute for High Performance Computing and Networking (ICAR-CNR), via Pietro Castellino 111, Naples, 80131, Italy
AD  - Faculty of Information Technology, Ho Chi Minh City University of Technology (HUTECH), Ho Chi Minh City, Viet Nam
AD  - Andalusian Research Institute in Data Science and Computational Intelligence (DaSCI), University of Granada, Granada, Spain
AD  - Faculty of Software and Information Science, Iwate Prefectural University, Iwate, Japan
AB  - The work presented in this paper investigates the ability of BERT neural language model pretrained in Italian to embed syntactic dependency relationships into its layers, by approximating a Dependency Parse Tree. To this end, a structural probe, namely a supervised model able to extract linguistic structures from a language model, has been trained leveraging the contextual embeddings from the layers of BERT. An experimental assessment has been performed using an Italian version of BERT-base model and a set of datasets for Italian labelled with Universal Dependencies formalism. The results, achieved using standard metrics of dependency parsers, have shown that a knowledge of the Italian syntax is embedded in central-upper layers of the BERT model, according to what observed in literature for the English case. In addition, the probe has been also used to experimentally evaluate the BERT model behaviour in case of two specific syntactic phenomena in Italian, namely null-subject and subject-verb-agreement, showing better performance than an Italian state-of-the-art parser. These findings can open a path for the development of new hybrid approaches, exploiting the probe to integrate or improve limits or weaknesses in analysing articulated constructions of Italian syntax, traditionally complex to be parsed. © 2021, The Author(s), under exclusive licence to Springer-Verlag GmbH Germany, part of Springer Nature.
KW  - Dependency parse tree
KW  - Neural language model
KW  - Structural probe
KW  - Syntactic phenomena
KW  - Computational linguistics
KW  - Forestry
KW  - Probes
KW  - Dependency parse tree
KW  - Dependency parser
KW  - Dependency relationship
KW  - Language model
KW  - Learn+
KW  - Neural language model
KW  - Parse trees
KW  - Structural probes
KW  - Syntactic dependencies
KW  - Syntactic phenomenon
KW  - Syntactics
PB  - Springer Science and Business Media Deutschland GmbH
SN  - 18685137 (ISSN)
LA  - English
J2  - J. Ambient Intell. Humanized Comput.
M3  - Article
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 16; Correspondence Address: S. Silvestri; National Research Council of Italy, Institute for High Performance Computing and Networking (ICAR-CNR), Naples, via Pietro Castellino 111, 80131, Italy; email: stefano.silvestri@icar.cnr.it
ER  -

TY  - JOUR
AU  - Wang, W.
AU  - Li, X.
AU  - Ren, H.
AU  - Gao, D.
AU  - Fang, A.
TI  - Chinese Clinical Named Entity Recognition From Electronic Medical Records Based on Multisemantic Features by Using Robustly Optimized Bidirectional Encoder Representation From Transformers Pretraining Approach Whole Word Masking and Convolutional Neural Networks: Model Development and Validation
PY  - 2023
T2  - JMIR Medical Informatics
VL  - 11
C7  - e44597
DO  - 10.2196/44597
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85159846704&doi=10.2196%2f44597&partnerID=40&md5=ebe080b3a3d3410544432ec03908fe85
AD  - Institute of Medical Information and Library, Chinese Academy of Medical Sciences, Peking Union Medical College, Beijing, China
AB  - Background: Clinical electronic medical records (EMRs) contain important information on patients' anatomy, symptoms, examinations, diagnoses, and medications. Large-scale mining of rich medical information from EMRs will provide notable reference value for medical research. With the complexity of Chinese grammar and blurred boundaries of Chinese words, Chinese clinical named entity recognition (CNER) remains a notable challenge. Follow-up tasks such as medical entity structuring, medical entity standardization, medical entity relationship extraction, and medical knowledge graph construction largely depend on medical named entity recognition effects. A promising CNER result would provide reliable support for building domain knowledge graphs, knowledge bases, and knowledge retrieval systems. Furthermore, it would provide research ideas for scientists and medical decision-making references for doctors and even guide patients on disease and health management. Therefore, obtaining excellent CNER results is essential. Objective: We aimed to propose a Chinese CNER method to learn semantics-enriched representations for comprehensively enhancing machines to understand deep semantic information of EMRs by using multisemantic features, which makes medical information more readable and understandable. Methods: First, we used Robustly Optimized Bidirectional Encoder Representation from Transformers Pretraining Approach Whole Word Masking (RoBERTa-wwm) with dynamic fusion and Chinese character features, including 5-stroke code, Zheng code, phonological code, and stroke code, extracted by 1-dimensional convolutional neural networks (CNNs) to obtain fine-grained semantic features of Chinese characters. Subsequently, we converted Chinese characters into square images to obtain Chinese character image features from another modality by using a 2-dimensional CNN. Finally, we input multisemantic features into Bidirectional Long Short-Term Memory with Conditional Random Fields to achieve Chinese CNER. The effectiveness of our model was compared with that of the baseline and existing research models, and the features involved in the model were ablated and analyzed to verify the model's effectiveness. Results: We collected 1379 Yidu-S4K EMRs containing 23,655 entities in 6 categories and 2007 self-annotated EMRs containing 118,643 entities in 7 categories. The experiments showed that our model outperformed the comparison experiments, with F1-scores of 89.28% and 84.61% on the Yidu-S4K and self-annotated data sets, respectively. The results of the ablation analysis demonstrated that each feature and method we used could improve the entity recognition ability. Conclusions: Our proposed CNER method would mine the richer deep semantic information in EMRs by multisemantic embedding using RoBERTa-wwm and CNNs, enhancing the semantic recognition of characters at different granularity levels and improving the generalization capability of the method by achieving information complementarity among different semantic features, thus making the machine semantically understand EMRs and improving the CNER task accuracy.  ©Weijie Wang, Xiaoying Li, Huiling Ren, Dongping Gao, An Fang.
KW  - Chinese clinical named entity recognition
KW  - CNN
KW  - convolutional neural network
KW  - image feature
KW  - multisemantic features
KW  - RoBERTa-wwm
KW  - Robustly Optimized Bidirectional Encoder Representation from Transformers Pretraining Approach Whole Word Masking
PB  - JMIR Publications Inc.
SN  - 22919694 (ISSN)
LA  - English
J2  - JMIR Med. Inform.
M3  - Article
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 0; Correspondence Address: H. Ren; Institute of Medical Information and Library, Chinese Academy of Medical Sciences, Peking Union Medical College, Beijing, 69 Dongdan N St, 100005, China; email: ren.huiling@imicams.ac.cn
ER  -

TY  - CONF
AU  - Dalal, D.
AU  - Arcan, M.
AU  - Buitelaar, P.
TI  - CALM-Bench: A Multi-task Benchmark for Evaluating Causality Aware Language Models
PY  - 2023
T2  - EACL 2023 - 17th Conference of the European Chapter of the Association for Computational Linguistics, Findings of EACL 2023
SP  - 296
EP  - 311
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85159857692&partnerID=40&md5=6a6b2a8184e5e4921e19de99baa40497
AD  - SFI Centre for Research and Training in Artificial Intelligence, Ireland
AD  - Insight SFI Research Centre for Data Analytics, Data Science Institute, University of Galway, Ireland
AB  - Causal reasoning is a critical component of human cognition and is required across a range of question-answering (QA) tasks (such as abductive reasoning, commonsense QA, and procedural reasoning). Research on causal QA has been underdefined, task-specific, and limited in complexity. Recent advances in foundation language models (such as BERT, ERNIE, and T5) have shown the efficacy of pre-trained models across diverse QA tasks. However, there is limited research exploring the causal reasoning capabilities of those language models and no standard evaluation benchmark. To unify causal QA research, we propose CALM-Bench, a multi-task benchmark for evaluating causality-aware language models (CALM). We present a standardized definition of causal QA tasks and show empirically that causal reasoning can be generalized and transferred across different QA tasks. Additionally, we share a strong multi-task baseline model which outperforms single-task fine-tuned models on the CALM-Bench tasks. © 2023 Association for Computational Linguistics.
KW  - Abductive reasoning
KW  - Causal Questions
KW  - Causal reasoning
KW  - Critical component
KW  - Human cognition
KW  - Language model
KW  - Multi tasks
KW  - Question Answering
KW  - Question Answering Task
KW  - Reasoning capabilities
KW  - Computational linguistics
PB  - Association for Computational Linguistics (ACL)
SN  - 978-195942947-0 (ISBN)
LA  - English
J2  - EACL - Conf. Eur. Chapter Assoc. Comput. Linguist., Find. EACL
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 0; Conference name: 17th Conference of the European Chapter of the Association for Computational Linguistics, EACL 2023 - Findings of EACL 2023; Conference date: 2 May 2023 through 6 May 2023; Conference code: 188432
ER  -

TY  - CONF
AU  - Egan, N.
AU  - Vasilyev, O.
AU  - Bohannon, J.
TI  - Play the Shannon Game With Language Models: A Human-Free Approach to Summary Evaluation
PY  - 2022
T2  - Proceedings of the 36th AAAI Conference on Artificial Intelligence, AAAI 2022
VL  - 36
SP  - 10599
EP  - 10607
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85138338630&partnerID=40&md5=b9adb53e12eec5f2529de0c3c57d570e
AD  - Primer AI
AB  - The goal of a summary is to concisely state the most important information in a document. With this principle in mind, we introduce new reference-free summary evaluation metrics that use a pretrained language model to estimate the information content shared between a document and its summary. These metrics are a modern take on the Shannon Game, a method for summary quality scoring proposed decades ago, where we replace human annotators with language models. We also view these metrics as an extension of BLANC, a recently proposed approach to summary quality measurement based on the performance of a language model with and without the help of a summary. Using transformer based language models, we empirically verify that our metrics achieve stateof- the-art correlation with human judgement of the summary quality dimensions of both coherence and relevance, as well as competitive correlation with human judgement of consistency and fluency.  Copyright © 2022, Association for the Advancement of Artificial Intelligence (www.aaai.org). All rights reserved.
KW  - Artificial intelligence
KW  - Evaluation metrics
KW  - Human judgments
KW  - Information contents
KW  - Language model
KW  - Measurement-based
KW  - Performance
KW  - Quality measurements
KW  - Reference-free
KW  - Shannon
KW  - State of the art
KW  - Computational linguistics
PB  - Association for the Advancement of Artificial Intelligence
SN  - 1577358767 (ISBN); 978-157735876-3 (ISBN)
LA  - English
J2  - Proc. AAAI Conf. Artif. Intell., AAAI
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 5; Conference name: 36th AAAI Conference on Artificial Intelligence, AAAI 2022; Conference date: 22 February 2022 through 1 March 2022; Conference code: 185285
ER  -

TY  - CONF
AU  - Hu, L.
AU  - Li, C.
AU  - Wang, W.
AU  - Pang, B.
AU  - Shang, Y.
TI  - Performance Evaluation of Text Augmentation Methods with BERT on Small-sized, Imbalanced Datasets
PY  - 2022
T2  - Proceedings - 2022 IEEE 4th International Conference on Cognitive Machine Intelligence, CogMI 2022
SP  - 125
EP  - 133
DO  - 10.1109/CogMI56440.2022.00027
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85150679486&doi=10.1109%2fCogMI56440.2022.00027&partnerID=40&md5=4321f2ad7bb456cd67f7b3e083edf1a3
AD  - Washington and Lee University, Department of Business Administration, Lexington, VA, United States
AD  - University of Missouri, Columbia, MO, United States
AD  - University of Missouri, Department of Electrical Engineering & Computer Science, Columbia, MO, United States
AB  - Recently deep learning methods have achieved great success in understanding and analyzing text messages. In real-world applications, however, labeled text data are often small-sized and imbalanced in classes due to the high cost of data collection and human annotation, limiting the performance of deep learning classifiers. Therefore, this study explores an understudied area - how sample sizes and imbalance ratios influence the performance of deep learning models and augmentation methods - and provides a solution to this problem. Specifically, this study examines the performance of BERT, Word2Vec, and WordNet augmentation methods with BERT fine-tuning on datasets of sizes 500, 1,000, and 2,000 and imbalance ratios of 4:1 and 9:1. Experimental results show that BERT augmentation improves the performance of BERT in detecting the minority class, and the improvement is most significantly (15.6-40.4% F1 increase compared to the base model and 2.8%-10.4% F1 increase compared to the model with the oversampling method) when the data size is small (e.g., 500 training documents) and highly imbalanced (e.g., 9:1). When the data size increases or the imbalance ratio decreases, the improvement generated by the BERT augmentation becomes smaller or insignificant. Moreover, BERT augmentation plus BERT fine-tuning achieves the best performance compared to other models and methods, demonstrating a promising solution for small-sized, highly imbalanced text classification tasks.  © 2022 IEEE.
KW  - data augmentation
KW  - deep learning
KW  - imbalanced dataset
KW  - machine learning
KW  - NLP
KW  - text classification
KW  - Classification (of information)
KW  - Learning systems
KW  - Text processing
KW  - Augmentation methods
KW  - Data augmentation
KW  - Data size
KW  - Deep learning
KW  - Fine tuning
KW  - Imbalanced dataset
KW  - Machine-learning
KW  - Performance
KW  - Performances evaluation
KW  - Text classification
KW  - Deep learning
PB  - Institute of Electrical and Electronics Engineers Inc.
SN  - 978-166547406-1 (ISBN)
LA  - English
J2  - Proc. - IEEE Int. Conf. Cogn. Mach. Intell., CogMI
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 3; Correspondence Address: L. Hu; Washington and Lee University, Department of Business Administration, Lexington, United States; email: lhu@wlu.edu; Conference name: 4th IEEE International Conference on Cognitive Machine Intelligence, CogMI 2022; Conference date: 14 December 2022 through 17 December 2022; Conference code: 187265
ER  -

TY  - CONF
AU  - Patil, S.D.
AU  - Dharme, M.
AU  - Patil, A.J.
AU  - Gautam Chakrawarthy, A.K.
AU  - Jarial, R.K.
AU  - Singh, A.
TI  - DGA Based Ensemble learning and Random Forest Models for Condition Assessment of Transformers
PY  - 2022
T2  - 2022 International Conference on Smart Generation Computing, Communication and Networking, SMART GENCON 2022
DO  - 10.1109/SMARTGENCON56628.2022.10083672
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85153686614&doi=10.1109%2fSMARTGENCON56628.2022.10083672&partnerID=40&md5=2483eaa97a24433c3c955a4fa74eff09
AD  - NIT, Hamirpur, Dept. of Electrical Engineering, HP, Hamirpur, India
AB  - One of the most common and significant components in the energy sector is power transformers. In a transformer, we use oil which has four applications as electric insulation medium, cooling objective, diagnostic goal, and defense against chemical attack. Transformer's dissolved gas analysis (D.G.A.) is the most extensively used technique that achieves the diagnostic goal of identifying early insulation issues. However, the DGA fault interpretation using processing methods has significant obstacles due to the minimal data availability, considerable vagueness in DGA interpretation, applicability, and model performance. It is necessary to comprehend the impact of data preparation and databalancing on the DGA database as a potential issue to upgrade the current model to the industry. This work uses vast, extremely diverse DGA data samples of in-service transformers from several sites in Himachal Pradesh, India, to create a practical methodology for fault classification. In this condition interpretation work, we analyze various parameters of DGA outputs and assess the state of the oil. A total of 421 DGA test databases were collected, and we trained the various algorithmic models in machine learning to predict the condition of oil. The best model's hyper-parameters are further tweaked for the most accurate fault categorization.  © 2022 IEEE.
KW  - Diagnostic Test (DT)
KW  - Dissolved gas analysis (DGA)
KW  - etc
KW  - Machine Learning (ML)
KW  - Transformer
KW  - Chemical attack
KW  - Electric insulation
KW  - Electric transformer testing
KW  - Forestry
KW  - Machine learning
KW  - Oil filled transformers
KW  - Condition
KW  - Diagnostic test
KW  - Diagnostic tests
KW  - Dissolved gas analyse
KW  - Dissolved gases analysis
KW  - Ensemble learning
KW  - Etc
KW  - Machine learning
KW  - Machine-learning
KW  - Transformer
KW  - Power transformers
PB  - Institute of Electrical and Electronics Engineers Inc.
SN  - 978-166545499-5 (ISBN)
LA  - English
J2  - Int. Conf. Smart Gener. Comput., Commun. Netw., SMART GENCON
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 3; Conference name: 2022 International Conference on Smart Generation Computing, Communication and Networking, SMART GENCON 2022; Conference date: 23 December 2022 through 25 December 2022; Conference code: 187827
ER  -

TY  - CONF
AU  - Zhao, W.
AU  - Strube, M.
AU  - Eger, S.
TI  - DiscoScore: Evaluating Text Generation with BERT and Discourse Coherence
PY  - 2023
T2  - EACL 2023 - 17th Conference of the European Chapter of the Association for Computational Linguistics, Proceedings of the Conference
SP  - 3847
EP  - 3865
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85159861819&partnerID=40&md5=aeccea25edf1edfec9c81d366dad3caa
AD  - Heidelberg Institute for Theoretical Studies
AD  - Technische Universität Darmstadt, Germany
AD  - NLLG, Faculty of Technology, Bielefeld University, Germany
AB  - Recently, there has been a growing interest in designing text generation systems from a discourse coherence perspective, e.g., modeling the interdependence between sentences. Still, recent BERT-based evaluation metrics are weak in recognizing coherence, and thus are not reliable in a way to spot the discourse-level improvements of those text generation systems. In this work, we introduce DiscoScore, a parametrized discourse metric, which uses BERT to model discourse coherence from different perspectives, driven by Centering theory. Our experiments encompass 16 non-discourse and discourse metrics, including DiscoScore and popular coherence models, evaluated on summarization and document-level machine translation (MT). We find that (i) the majority of BERT-based metrics correlate much worse with human rated coherence than early discourse metrics, invented a decade ago; (ii) the recent state-of-the-art BARTScore is weak when operated at system level-which is particularly problematic as systems are typically compared in this manner. DiscoScore, in contrast, achieves strong system-level correlation with human ratings, not only in coherence but also in factual consistency and other aspects, and surpasses BARTScore by over 10 correlation points on average. Further, aiming to understand DiscoScore, we provide justifications to the importance of discourse coherence for evaluation metrics, and explain the superiority of one variant over another. Our code is available at https://github.com/AIPHES/DiscoScore. © 2023 Association for Computational Linguistics.
KW  - Computational linguistics
KW  - Natural language processing systems
KW  - Text processing
KW  - Centering theories
KW  - Coherence models
KW  - Evaluation metrics
KW  - Generation systems
KW  - Level correlation
KW  - Machine translations
KW  - Recent state
KW  - State of the art
KW  - System levels
KW  - Text generations
KW  - Character recognition
PB  - Association for Computational Linguistics (ACL)
SN  - 978-195942944-9 (ISBN)
LA  - English
J2  - EACL - Conf. Eur. Chapter Assoc. Comput. Linguist., Proc. Conf.
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 2; Conference name: 17th Conference of the European Chapter of the Association for Computational Linguistics, EACL 2023; Conference date: 2 May 2023 through 6 May 2023; Conference code: 188424
ER  -

TY  - JOUR
AU  - Lawley, C.J.M.
AU  - Raimondo, S.
AU  - Chen, T.
AU  - Brin, L.
AU  - Zakharov, A.
AU  - Kur, D.
AU  - Hui, J.
AU  - Newton, G.
AU  - Burgoyne, S.L.
AU  - Marquis, G.
TI  - Geoscience language models and their intrinsic evaluation
PY  - 2022
T2  - Applied Computing and Geosciences
VL  - 14
C7  - 100084
DO  - 10.1016/j.acags.2022.100084
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85129533229&doi=10.1016%2fj.acags.2022.100084&partnerID=40&md5=e99ce3679d38a541244fd0126ef5da60
AD  - Natural Resources Canada, Geological Survey of Canada, 601 Booth Street, Ottawa, K1A 0E8, ON, Canada
AD  - ServiceNow, 161 Bay Street, Suite 13000, Toronto, M5J 2S1, ON, Canada
AB  - Geoscientists use observations and descriptions of the rock record to study the origins and history of our planet, which has resulted in a vast volume of scientific literature. Recent progress in natural language processing (NLP) has the potential to parse through and extract knowledge from unstructured text, but there has, so far, been only limited work on the concepts and vocabularies that are specific to geoscience. Herein we harvest and process public geoscientific reports (i.e., Canadian federal and provincial geological survey publications databases) and a subset of open access and peer-reviewed publications to train new, geoscience-specific language models to address that knowledge gap. Language model performance is validated using a series of new geoscience-specific NLP tasks (i.e., analogies, clustering, relatedness, and nearest neighbour analysis) that were developed as part of the current study. The raw and processed national geological survey corpora, language models, and evaluation criteria are all made public for the first time. We demonstrate that non-contextual (i.e., Global Vectors for Word Representation, GloVe) and contextual (i.e., Bidirectional Encoder Representations from Transformers, BERT) language models updated using the geoscientific corpora outperform the generic versions of these models for each of the evaluation criteria. Principal component analysis further demonstrates that word embeddings trained on geoscientific text capture meaningful semantic relationships, including rock classifications, mineral properties and compositions, and the geochemical behaviour of elements. Semantic relationships that emerge from the vector space have the potential to unlock latent knowledge within unstructured text, and perhaps more importantly, also highlight the potential for other downstream geoscience-focused NLP tasks (e.g., keyword prediction, document similarity, recommender systems, rock and mineral classification). © 2022
KW  - Artificial intelligence
KW  - BERT
KW  - GloVe
KW  - Language models
KW  - Machine learning
KW  - Word embedding
KW  - Computational linguistics
KW  - Embeddings
KW  - Geology
KW  - Information retrieval systems
KW  - Machine learning
KW  - Mineral exploration
KW  - Minerals
KW  - Natural language processing systems
KW  - Principal component analysis
KW  - Semantics
KW  - Text processing
KW  - Bidirectional encoder representation from transformer
KW  - Embeddings
KW  - Geosciences
KW  - Glove
KW  - Language model
KW  - Language processing
KW  - Machine-learning
KW  - Natural languages
KW  - Unstructured texts
KW  - Word embedding
KW  - Vector spaces
PB  - Elsevier B.V.
SN  - 25901974 (ISSN)
LA  - English
J2  - Appl. Comput. Geosci.
M3  - Article
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 6; Correspondence Address: C.J.M. Lawley; Natural Resources Canada, Geological Survey of Canada, Ottawa, 601 Booth Street, K1A 0E8, Canada; email: christopher.lawley@nrcan-rncan.gc.ca
ER  -

TY  - JOUR
AU  - Assefa, Y.
AU  - Moges, B.T.
AU  - Tilwani, S.A.
TI  - Lifelong learning measurement scale (LLMS): development and validation in the context of higher education institutions
PY  - 2023
T2  - Journal of Applied Research in Higher Education
DO  - 10.1108/JARHE-04-2023-0164
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85165424242&doi=10.1108%2fJARHE-04-2023-0164&partnerID=40&md5=580462f138caa67c004a5dccb918435b
AD  - Department of Lifelong Learning and Community Development, Woldia University, Woldiya, Ethiopia
AD  - Department of Pedagogical Science, Woldia University, Woldiya, Ethiopia
AD  - Department of English, College of Science and Humanities, Al-Kharj, Prince Sattam Bin Abdulaziz University, Al-Kharj, Saudi Arabia
AB  - Purpose: Lifelong learning has become one of the most interesting areas of research. Hence, the current study was aimed at developing and validating a tool that helps to study how well people working in higher education institutions are engaged in lifelong learning. Design/methodology/approach: A review of theories in the literature and experts' consultation were used to develop a pool of items and validate the self-assessment instrument for measuring lifelong learning. The study employed factor analytic methodologies such as principal component analysis, varimax rotation and exploratory factor analyses. Findings: The study yielded a reliable and valid lifelong learning measurement scale made up of 18 items and four underlying factors that are theoretically supported. Originality/value: The significant information is that, the current study aimed at developing a tool that could help to measure the engagement in lifelong learning of higher education institutions workers. The study found this tool to be important because lifelong learning is considered essential for personal and professional growth, and having a sound way to measure it can help individuals and organizations identify areas for improvement. © 2023, Emerald Publishing Limited.
KW  - Four pillars of learning
KW  - Higher education
KW  - Lifelong learning
KW  - LLMS
KW  - Measurement scale
PB  - Emerald Publishing
SN  - 20507003 (ISSN)
LA  - English
J2  - J. Appl. Res. High. Edu.
M3  - Article
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 2; Correspondence Address: Y. Assefa; Department of Lifelong Learning and Community Development, Woldia University, Woldiya, Ethiopia; email: yalalem2012@gmail.com
ER  -

TY  - CONF
AU  - Khatri, S.
AU  - Iqbal, M.
AU  - Ubakanma, G.
AU  - Van Der Vliet-Firth, S.
TI  - SkillBot: Towards Data Augmentation using Transformer language model and linguistic evaluation
PY  - 2022
T2  - Proceedings - 2022 International Conference on Human-Centered Cognitive Systems, HCCS 2022
DO  - 10.1109/HCCS55241.2022.10090376
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85153675420&doi=10.1109%2fHCCS55241.2022.10090376&partnerID=40&md5=918471a25a944dc8bb8b41f7cb00c917
AD  - London South Bank University, Department of School of Engineering, London, United Kingdom
AD  - Jobs and Skills Programme Lead Economy, Jobs & Partnerships, United Kingdom
AB  - Creating accurate, closed-domain, and machine learning-based chatbots that perform language understanding (intent prediction/detection) and language generation (response generation) requires significant datasets derived from specific knowledge domains. The common challenge in developing a closed-domain chatbot application is the lack of a comprehensive dataset. Such scarcity of the dataset can be complemented by augmenting the dataset with the use of state-of-The-Art technologies existing in the field of Natural Language Processing, called 'Transformer Models'. Our applied computing project experimented with a 'Generative Pre-Trained Transformer' model, a unidirectional transformer decoder model for augmenting an original dataset limited in size and manually authored. This model uses unidirectional contextual representation i.e., text input is processed from left to right while computing embeddings corresponding to the input sentences. The primary goal of the project was to leverage the potential of a pre-Trained transformer-based language model in augmenting an existing, but limited dataset. Additionally, the idea for using the model for text generation and appending the generated embedding to the input embedding supplied was to preserve the intent for the augmented utterances as well as to find a different form of expressions for the same intent which could be expressed by the potential users in the future. Our experiment showed improved performance for understanding language and generation for the chatbot model trained on the augmented dataset indicating that a pre-Trained language model can be beneficial for the effective working of natural language-based applications such as a chatbot model trained on the augmented dataset indicating that a pre-Trained language model can be beneficial for the effective working of natural language-based applications such as a chatbot. © 2022 IEEE.
KW  - Data Augmentation in NLP
KW  - Natural Language Processing
KW  - NLG (Natural Language Generation)
KW  - NLU (Natural Language Understanding) Rasa chatbot
KW  - transformer model
KW  - Computational linguistics
KW  - Natural language processing systems
KW  - Chatbots
KW  - Data augmentation
KW  - Data augmentation in NLP
KW  - Language processing
KW  - Natural language generation
KW  - Natural language processing
KW  - Natural language understanding
KW  - Natural language understanding rasa chatbot
KW  - Natural languages
KW  - Transformer modeling
KW  - Embeddings
PB  - Institute of Electrical and Electronics Engineers Inc.
SN  - 978-166545041-6 (ISBN)
LA  - English
J2  - Proc. - Int. Conf. Human-Centered Cogn. Syst., HCCS
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 0; Conference name: 2022 International Conference on Human-Centered Cognitive Systems, HCCS 2022; Conference date: 17 December 2022 through 18 December 2022; Conference code: 187767
ER  -

TY  - CONF
AU  - Joshi, B.
AU  - Chan, A.
AU  - Liu, Z.
AU  - Nie, S.
AU  - Sanjabi, M.
AU  - Firooz, H.
AU  - Ren, X.
TI  - ER-TEST: Evaluating Explanation Regularization Methods for Language Models
PY  - 2022
T2  - Findings of the Association for Computational Linguistics: EMNLP 2022
SP  - 3315
EP  - 3336
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85149874457&partnerID=40&md5=28db9efef896038ed144622597709bec
AD  - University of Southern California, United States
AD  - Meta AI
AB  - By explaining how humans would solve a given task, human rationales can provide strong learning signal for neural language models (NLMs). Explanation regularization (ER) aims to improve NLM generalization by pushing the NLM's machine rationales (Which input tokens did the NLM focus on?) to align with human rationales (Which input tokens would humans focus on?). Though prior works primarily study ER via in-distribution (ID) evaluation, out-of-distribution (OOD) generalization is often more critical in real-world scenarios, yet ER's effect on OOD generalization has been underexplored. In this paper, we introduce ER-TEST, a framework for evaluating ER models' OOD generalization along three dimensions: unseen datasets, contrast set tests, and functional tests. Using ER-TEST, we comprehensively analyze how ER models' OOD generalization varies with the rationale alignment criterion (loss function), human rationale type (instance-level vs. task-level), number and choice of rationale-annotated instances, and time budget for rationale annotation. Across two tasks and six datasets, we show that ER has little impact on ID performance but yields large OOD performance gains, with the best ER criterion being task-dependent. Also, ER can improve OOD performance even with task-level or few human rationales. Finally, we find that rationale annotation is more time-efficient than label annotation for improving OOD performance. Our results with ER-TEST help demonstrate ER's utility and establish best practices for using ER effectively. © 2022 Association for Computational Linguistics.
KW  - Computational linguistics
KW  - Large dataset
KW  - ER effect
KW  - Generalisation
KW  - Language model
KW  - Model generalization
KW  - Performance
KW  - Real-world scenario
KW  - Regularisation
KW  - Regularization methods
KW  - Regularization models
KW  - Task levels
KW  - Budget control
A2  - Goldberg Y.
A2  - Kozareva Z.
A2  - Zhang Y.
PB  - Association for Computational Linguistics (ACL)
LA  - English
J2  - Find. Assoc. Comput. Linguist.: EMNLP
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 0; Conference name: 2022 Findings of the Association for Computational Linguistics: EMNLP 2022; Conference date: 7 December 2022 through 11 December 2022; Conference code: 186900
ER  -

TY  - CONF
AU  - Paul, D.
AU  - Biswas, B.
AU  - Paul, R.
TI  - Using Transformer-based Pre-trained Language Model for Automated Evaluation of Comments to Aid Software Maintenance
PY  - 2022
T2  - CEUR Workshop Proceedings
VL  - 3395
SP  - 39
EP  - 52
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85160681152&partnerID=40&md5=5f23d8aad3a398b9c3e73e911078c766
AD  - St. Xavier’s College, Kolkata, India
AB  - With the increasing number of software applications, evaluating code repositories is of paradigm importance for building elegant software systems. The quality of a code repository is dependent on the readability of the code and the easiness with which it can be understood by other developers. Code commenting is a key requirement to ensure that code is readable, reusable, and reproducible. While useful comments can help software developers write better software, irrelevant and ambiguous comments can be overwhelming and misguiding to developers. Automatic software maintenance can help evaluate code repository and associated comments to provide meaningful insight into code quality and also help improve code comprehension by flagging not useful comments and highlighting useful ones. This paper explores the task of identifying code comment usefulness using a pre-trained transformer-based language model. The data for evaluation has been sourced from FIRE 2022, December 9-13, 2022, Kolkata, India[1]. The paper tries to understand how pre-trained language models like BERT and GPT-2 trained on large text corpora including code repositories can help understand comment usefulness. Such a model can help identify the comment usefulness with a minimum requirement of feature engineering and thus be integrated into an automatic software maintenance system to generalize across code repositories. The proposed model achieves an F1-score 90.15% and accuracy of 91.21% in the test set with 90.12% precision and 90.47% recall. The paper also explores explainable AI techniques like LIME and Attention visualizer to understand how these transformer-based models are identifying comment usefulness and establishing a sense of trust for these black box language models to be used in building automated software maintenance technologies. © 2022 Copyright for this paper Forum for Information Retrieval Evaluation.
KW  - Automatic Software Maintenance
KW  - BERT
KW  - GPT-2
KW  - Transformers
KW  - Application programs
KW  - Computational linguistics
KW  - Lime
KW  - Natural language processing systems
KW  - Quality control
KW  - Automated evaluation
KW  - Automatic software maintenance
KW  - BERT
KW  - Code quality
KW  - GPT-2
KW  - Language model
KW  - Software applications
KW  - Software developer
KW  - Software-systems
KW  - Transformer
KW  - Computer software maintenance
A2  - Ghosh K.
A2  - Mandl T.
A2  - Majumder P.
A2  - Mitra M.
PB  - CEUR-WS
SN  - 16130073 (ISSN)
LA  - English
J2  - CEUR Workshop Proc.
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 0; Correspondence Address: D. Paul; email: debjyoti93.paul@gmail.com; B. Biswas; St. Xavier’s College, Kolkata, India; email: bitanbiswas99@gmail.com; Conference name: 14th Forum for Information Retrieval Evaluation, FIRE 2022; Conference date: 9 December 2022 through 13 December 2022; Conference code: 188783
ER  -

TY  - CONF
AU  - Jang, M.
AU  - Kwon, D.S.
AU  - Lukasiewicz, T.
TI  - BECEL: Benchmark for Consistency Evaluation of Language Models
PY  - 2022
T2  - Proceedings - International Conference on Computational Linguistics, COLING
VL  - 29
IS  - 1
SP  - 3680
EP  - 3696
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85162132001&partnerID=40&md5=6ed3af18737ceb84639a0c63f15de9d7
AD  - Department of Computer Science, University of Oxford, United Kingdom
AD  - Institute of Logic and Computation, TU Wien, Austria
AD  - Language Super Intelligence Labs, SK Telecom, South Korea
AB  - Behavioural consistency is a critical condition for a language model (LM) to become trustworthy like humans. Despite its importance, however, there is little consensus on the definition of LM consistency, resulting in different definitions across many studies. In this paper, we first propose the idea of LM consistency based on behavioural consistency and establish a taxonomy that classifies previously studied consistencies into several sub-categories. Next, we create a new benchmark that allows us to evaluate a model on 19 test cases, distinguished by multiple types of consistency and diverse downstream tasks. Through extensive experiments on the new benchmark, we ascertain that none of the modern pre-trained language models (PLMs) performs well in every test case, while exhibiting high inconsistency in many cases. Our experimental results suggest that a unified benchmark that covers broad aspects (i.e., multiple consistency types and tasks) is essential for a more precise evaluation. © 2022 Proceedings - International Conference on Computational Linguistics, COLING. All rights reserved.
KW  - Behavioural consistency
KW  - Critical condition
KW  - Down-stream
KW  - Language model
KW  - Model consistency
KW  - Test case
KW  - Computational linguistics
A2  - Calzolari N.
A2  - Huang C.-R.
A2  - Kim H.
A2  - Pustejovsky J.
A2  - Wanner L.
A2  - Choi K.-S.
A2  - Ryu P.-M.
A2  - Chen H.-H.
A2  - Donatelli L.
A2  - Ji H.
A2  - Kurohashi S.
A2  - Paggio P.
A2  - Paggio P.
A2  - Xue N.
A2  - Kim S.
A2  - Hahm Y.
A2  - He Z.
A2  - Lee T.K.
A2  - Santus E.
A2  - Bond F.
A2  - Na S.-H.
PB  - Association for Computational Linguistics (ACL)
SN  - 29512093 (ISSN)
LA  - English
J2  - Proc. Main Conf. Int. Conf. Comput. Linguist., COLING
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 2; Conference name: 29th International Conference on Computational Linguistics, COLING 2022; Conference date: 12 October 2022 through 17 October 2022; Conference code: 186893
ER  -

TY  - CONF
AU  - Wu, R.
AU  - Zhu, P.
AU  - Qin, X.
TI  - CNN-MLP-based transformer digital twin model construction and fault diagnosis and condition evaluation analysis
PY  - 2023
T2  - 2023 IEEE 3rd International Conference on Power, Electronics and Computer Applications, ICPECA 2023
SP  - 1081
EP  - 1088
DO  - 10.1109/ICPECA56706.2023.10075826
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85152224505&doi=10.1109%2fICPECA56706.2023.10075826&partnerID=40&md5=748bcba20ee18f73acd540cced5f1200
AD  - China University of Mining Technology, Beijing, Beijing, China
AD  - Hunan University of Technology and Business, Changsha, China
AD  - Guangxi University, Nanning, China
AB  - To address the problems of low accuracy of real-time condition assessment methods and difficult fault diagnosis identification of large oil-immersed power transformers, this paper uses a Convolutional neural network (CNN) and Multilayer perceptron network (MLP) to construct a digital twin model for transformer condition assessment and fault diagnosis. Network (MLP) fusion to build a digital twin model for transformer condition evaluation and fault diagnosis. Firstly, the digital twin model of the transformer is established based on the characteristics of the transformer's physical structure and operating conditions. Secondly, the fusion of CNN and MLP algorithms is used to construct a fault monitoring classification model to extract the advantages of data characteristics of different fault types of state parameters so that the constructed model can entirely remove the implied statistical features of a transformer operating data. Finally, using the hierarchical analysis method, a weight matrix is constructed to derive the scores and fault classes of each group of condition data. The experimental results show that compared with other models, CNN-MLP has better generalization ability and can realize real-time monitoring and diagnosis of transformer faults with a correct overall rate of 98%.  © 2023 IEEE.
KW  - CNN-MLP
KW  - digital twin
KW  - fault diagnosis
KW  - Oil-immersed power transformers
KW  - Convolutional neural networks
KW  - Fault detection
KW  - Multilayer neural networks
KW  - Power transformers
KW  - Condition evaluation
KW  - Convolutional neural network
KW  - Convolutional neural network-multilayer perceptron network
KW  - Fault conditions
KW  - Faults diagnosis
KW  - Model construction
KW  - Multi layer perceptron networks
KW  - Network-based
KW  - Oil-immersed power transformers
KW  - Real- time
KW  - Failure analysis
PB  - Institute of Electrical and Electronics Engineers Inc.
SN  - 978-166547278-4 (ISBN)
LA  - English
J2  - IEEE Int. Conf. Power, Electron. Comput. Appl., ICPECA
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 1; Correspondence Address: X. Qin; Guangxi University, Nanning, China; email: qxhyes@163.com; Conference name: 3rd IEEE International Conference on Power, Electronics and Computer Applications, ICPECA 2023; Conference date: 29 January 2023 through 31 January 2023; Conference code: 187572
ER  -

TY  - JOUR
AU  - Dahlkemper, M.N.
AU  - Lahme, S.Z.
AU  - Klein, P.
TI  - How do physics students evaluate artificial intelligence responses on comprehension questions A study on the perceived scientific accuracy and linguistic quality of ChatGPT
PY  - 2023
T2  - Physical Review Physics Education Research
VL  - 19
IS  - 1
C7  - 010142
DO  - 10.1103/PhysRevPhysEducRes.19.010142
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85164337225&doi=10.1103%2fPhysRevPhysEducRes.19.010142&partnerID=40&md5=29b6d71572986e165e8caafb079f7942
AD  - Faculty of Physics, Physics Education Research, University of Göttingen, Friedrich-Hund-Platz 1, Göttingen, 37077, Germany
AD  - European Organization for Nuclear Research (CERN), Esplanade des Particules 1, Geneva 23, CH-1211, Switzerland
AB  - This study aimed at evaluating how students perceive the linguistic quality and scientific accuracy of ChatGPT responses to physics comprehension questions. A total of 102 first- and second-year physics students were confronted with three questions of progressing difficulty from introductory mechanics (rolling motion, waves, and fluid dynamics). Each question was presented with four different responses. All responses were attributed to ChatGPT, but in reality, one sample solution was created by the researchers. All ChatGPT responses obtained in this study were wrong, imprecise, incomplete, or misleading. We found little differences in the perceived linguistic quality between ChatGPT responses and the sample solution. However, the students rated the overall scientific accuracy of the responses significantly differently, with the sample solution being rated best for the questions of low and medium difficulty. The discrepancy between the sample solution and the ChatGPT responses increased with the level of self-assessed knowledge of the question content. For the question of highest difficulty (fluid dynamics) that was unknown to most students, a ChatGPT response was rated just as good as the sample solution. Thus, this study provides data on the students' perception of ChatGPT responses and the factors influencing their perception. The results highlight the need for careful evaluation of ChatGPT responses both by instructors and students, particularly regarding scientific accuracy. Therefore, future research could explore the potential of similar "spot the bot"activities in physics education to foster students' critical thinking skills. © 2023 authors. Published by the American Physical Society. Published by the American Physical Society under the terms of the "https://creativecommons.org/licenses/by/4.0/"Creative Commons Attribution 4.0 International license. Further distribution of this work must maintain attribution to the author(s) and the published article's title, journal citation, and DOI.
PB  - American Physical Society
SN  - 24699896 (ISSN)
LA  - English
J2  - Phys. Rev. Phys. Educ. Res.
M3  - Article
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 2; CODEN: PRPEC
ER  -

TY  - JOUR
AU  - Chaouche, R.S.
AU  - Houassine, H.
AU  - Moulahoum, S.
AU  - Chaouche, M.S.
AU  - Bensaid, S.
TI  - A Robust Approach for Locating and Assessing Mechanical Faults in an Actual Transformer Winding Using the State Space of Its Lumped Equivalent Model
PY  - 2022
T2  - Russian Journal of Nondestructive Testing
VL  - 58
IS  - 6
SP  - 488
EP  - 498
DO  - 10.1134/S1061830922060092
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85138488878&doi=10.1134%2fS1061830922060092&partnerID=40&md5=218dd6a75858fcef47af4fbcfdc0a090
AD  - Research Laboratory of Electrical Engineering and Automatic LREA University of Medea, Medea, Algeria
AD  - Sciences and Applied Sciences Faculty, University of Bouira, Bouira, Algeria
AD  - Laboratory of Materials and Sustainable Development (LM2D) University of Bouira, Bouira, Algeria
AD  - Faculty of Technology, Department of Electrical Engineering, University of Medea, Medea, Algeria
AB  - Abstract: Transfer function and state-space model are two powerful complementary tools have been used to monitoring the physical system. These two ways can be very successful in giving a comprehensive analysis of electrical power transformer malfunctions. This paper proposes a novel robust approach nondestructive to diagnose short circuit (SC) faults by considering axial displacements (AD) in the transformer winding. Initially, elaboration a native autonomously tool to control the LCR meters through computing systems. This platform will control the impedance measurement by the instrument of the LCR meter through MATLAB software. Additionally, achieving estimation autonomously to all the parameters of the lumped equivalent model of the winding accurately using frequency response analysis signal morphology interpretation (FRASMI). On the other hand, obtaining a new representation of the state-space model of the lumped equivalent model of an isolated winding with SC fault between its turns to locate and assess its severity. Finally, the relationship between the model parameters and the resonance frequencies of the frequency response curve can provide an effective nondestructive diagnostic tool for all mechanical damages of winding (e.g., SC with AD) which have been implemented experimentally, in which a new physical index has been proposed making it possible to locate and assess the extent of these defects simultaneously. © 2022, Pleiades Publishing, Ltd.
KW  - axial displacement, frequency response, mutually coupled model, short circuit faults
KW  - state space model
KW  - transformer winding
KW  - Frequency estimation
KW  - Lumped parameter networks
KW  - MATLAB
KW  - Power transformers
KW  - State space methods
KW  - Timing circuits
KW  - Transformer windings
KW  - Winding
KW  - Axial displacement, frequency response, mutually coupled model, short circuit fault
KW  - Axial displacements
KW  - Coupled models
KW  - Equivalent modeling
KW  - LCR meters
KW  - Mechanical faults
KW  - Robust approaches
KW  - Short-circuit fault
KW  - State-space models
KW  - Transformers winding
KW  - Frequency response
PB  - Pleiades journals
SN  - 10618309 (ISSN)
LA  - English
J2  - Russ. J. Nondestr. Test.
M3  - Article
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 2; Correspondence Address: R.S. Chaouche; Research Laboratory of Electrical Engineering and Automatic LREA University of Medea, Medea, Algeria; email: rachid-chaouche@hotmail.fr
ER  -

TY  - CONF
AU  - Vu, D.N.L.
AU  - Moosavi, N.S.
AU  - Eger, S.
TI  - Layer or Representation Space: What makes BERT-based Evaluation Metrics Robust?
PY  - 2022
T2  - Proceedings - International Conference on Computational Linguistics, COLING
VL  - 29
IS  - 1
SP  - 3401
EP  - 3411
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85163395022&partnerID=40&md5=9de4243466f3c844b4966561f1580113
AD  - Department of Computer Science, Technical University of Darmstadt, Germany
AD  - Department of Computer Science, The University of Sheffield, United Kingdom
AD  - NLLG, Faculty of Technology, Bielefeld University, Germany
AB  - The evaluation of recent embedding-based evaluation metrics for text generation is primarily based on measuring their correlation with human evaluations on standard benchmarks. However, these benchmarks are mostly from similar domains to those used for pretraining word embeddings. This raises concerns about the (lack of) generalization of embedding-based metrics to new and noisy domains that contain a different vocabulary than the pretraining data. In this paper, we examine the robustness of BERTScore, one of the most popular embedding-based metrics for text generation. We show that (a) an embedding-based metric that has the highest correlation with human evaluations on a standard benchmark can have the lowest correlation if the amount of input noise or unknown tokens increases, (b) taking embeddings from the first layer of pretrained models improves the robustness of all metrics, and (c) the highest robustness is achieved when using character-level embeddings, instead of token-based embeddings, from the first layer of the pretrained model. © 2022 Proceedings - International Conference on Computational Linguistics, COLING. All rights reserved.
KW  - Computational linguistics
KW  - Embeddings
KW  - Evaluation metrics
KW  - Generalisation
KW  - High robustness
KW  - Human evaluation
KW  - Input noise
KW  - Lower correlation
KW  - Pre-training
KW  - Representation space
KW  - Text generations
KW  - Embeddings
A2  - Calzolari N.
A2  - Huang C.-R.
A2  - Kim H.
A2  - Pustejovsky J.
A2  - Wanner L.
A2  - Choi K.-S.
A2  - Ryu P.-M.
A2  - Chen H.-H.
A2  - Donatelli L.
A2  - Ji H.
A2  - Kurohashi S.
A2  - Paggio P.
A2  - Paggio P.
A2  - Xue N.
A2  - Kim S.
A2  - Hahm Y.
A2  - He Z.
A2  - Lee T.K.
A2  - Santus E.
A2  - Bond F.
A2  - Na S.-H.
PB  - Association for Computational Linguistics (ACL)
SN  - 29512093 (ISSN)
LA  - English
J2  - Proc. Main Conf. Int. Conf. Comput. Linguist., COLING
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 5; Conference name: 29th International Conference on Computational Linguistics, COLING 2022; Conference date: 12 October 2022 through 17 October 2022; Conference code: 186893
ER  -

TY  - JOUR
AU  - Ivanov, V.V.
TI  - Sentence-level complexity in Russian: An evaluation of BERT and graph neural networks
PY  - 2022
T2  - Frontiers in Artificial Intelligence
VL  - 5
C7  - 1008411
DO  - 10.3389/frai.2022.1008411
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85144502494&doi=10.3389%2ffrai.2022.1008411&partnerID=40&md5=65f40f7bf03d3e1a58d4c713647b7e27
AD  - Faculty of Computer Science and Engineering, Innopolis University, Innopolis, Russian Federation
AD  - Institute of Philology and Intercultural Communication, Kazan Federal University, Kazan, Russian Federation
AB  - Introduction: Sentence-level complexity evaluation (SCE) can be formulated as assigning a given sentence a complexity score: either as a category, or a single value. SCE task can be treated as an intermediate step for text complexity prediction, text simplification, lexical complexity prediction, etc. What is more, robust prediction of a single sentence complexity needs much shorter text fragments than the ones typically required to robustly evaluate text complexity. Morphosyntactic and lexical features have proved their vital role as predictors in the state-of-the-art deep neural models for sentence categorization. However, a common issue is the interpretability of deep neural network results. Methods: This paper presents testing and comparing several approaches to predict both absolute and relative sentence complexity in Russian. The evaluation involves Russian BERT, Transformer, SVM with features from sentence embeddings, and a graph neural network. Such a comparison is done for the first time for the Russian language. Results and discussion: Pre-trained language models outperform graph neural networks, that incorporate the syntactical dependency tree of a sentence. The graph neural networks perform better than Transformer and SVM classifiers that employ sentence embeddings. Predictions of the proposed graph neural network architecture can be easily explained. Copyright © 2022 Ivanov.
KW  - BERT
KW  - graph neural networks
KW  - Russian language
KW  - sentence embeddings
KW  - sentence-level complexity
KW  - text complexity
PB  - Frontiers Media S.A.
SN  - 26248212 (ISSN)
LA  - English
J2  - Frontier. Artif. Intell.
M3  - Article
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 3; Correspondence Address: V.V. Ivanov; Faculty of Computer Science and Engineering, Innopolis University, Innopolis, Russian Federation; email: nomemm@gmail.com
ER  -

TY  - JOUR
AU  - Mac Manus, D.H.
AU  - Rodger, C.J.
AU  - Ingham, M.
AU  - Clilverd, M.A.
AU  - Dalzell, M.
AU  - Divett, T.
AU  - Richardson, G.S.
AU  - Petersen, T.
TI  - Geomagnetically Induced Current Model in New Zealand Across Multiple Disturbances: Validation and Extension to Non-Monitored Transformers
PY  - 2022
T2  - Space Weather
VL  - 20
IS  - 2
C7  - e2021SW002955
DO  - 10.1029/2021SW002955
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85125139163&doi=10.1029%2f2021SW002955&partnerID=40&md5=caf24232e55add0a25331901a04197bd
AD  - Department of Physics, University of Otago, Dunedin, New Zealand
AD  - Victoria University of Wellington, Wellington, New Zealand
AD  - British Antarctic Survey (UKRI-NERC), Cambridge, United Kingdom
AD  - Transpower New Zealand Ltd., Wellington, New Zealand
AD  - British Geological Survey (UKRI-NERC), Edinburgh, United Kingdom
AD  - GNS Science, Wellington, New Zealand
AB  - Geomagnetically induced currents (GICs) produced during geomagnetic disturbances pose a risk to the safe operation of electrical power networks. One route to determine the hazard of large and extreme geomagnetic disturbances to national electrical networks is a validated model to predict GIC across the entire network. In this study, we improve upon an earlier model for New Zealand, expanding the approach to cover transformers nationwide by making use of multiple storms to develop national scaling factors. We exploit GIC observations which have been made and archived by Transpower New Zealand Ltd, the national grid operator. For some transformers the GIC observations span nearly 2 decades, while for others only a few years. GICs can vary wildly between transformers, particularly due to differences in the electrical network characteristics, transformer properties, and ground conductivity. Modeling these individual transformers is required if an accurate representation of the GIC distribution throughout the network is to be produced. Here we model the GIC during 25 disturbed periods, ranging from large geomagnetic storms to weakly active periods. We adopt the approach of scaling model output using observed GIC power spectra, finding that it improves the correlations between the maximum model and observed GIC by between 10% and 40% depending on the transformer. The modeled GIC at the 73 transformers which have measured GIC are analyzed to create local and national scaling curves. These are used to allow modeling for transformers without in-situ GIC. We present approaches to utilize this technique for future storms, including non-monitored transformers. © 2022. The Authors.
PB  - John Wiley and Sons Inc
SN  - 15427390 (ISSN)
LA  - English
J2  - Space Weather
M3  - Article
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 9; Correspondence Address: D.H. Mac Manus; Department of Physics, University of Otago, Dunedin, New Zealand; email: macda381@student.otago.ac.nz
ER  -

TY  - CONF
AU  - Thakur, S.
AU  - Ahmad, B.
AU  - Fan, Z.
AU  - Pearce, H.
AU  - Tan, B.
AU  - Karri, R.
AU  - Dolan-Gavitt, B.
AU  - Garg, S.
TI  - Benchmarking Large Language Models for Automated Verilog RTL Code Generation
PY  - 2023
T2  - Proceedings -Design, Automation and Test in Europe, DATE
VL  - 2023-April
DO  - 10.23919/DATE56975.2023.10137086
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85162707713&doi=10.23919%2fDATE56975.2023.10137086&partnerID=40&md5=c889c67c769f34af2c8ac1097d976c4e
AD  - New York University, United States
AD  - University of Calgary, Canada
AB  - Automating hardware design could obviate a signif-icant amount of human error from the engineering process and lead to fewer errors. Verilog is a popular hardware description language to model and design digital systems, thus generating Verilog code is a critical first step. Emerging large language models (LLMs) are able to write high-quality code in other programming languages. In this paper, we characterize the ability of LLMs to generate useful Verilog. For this, we fine-tune pre-trained LLMs on Verilog datasets collected from GitHub and Verilog textbooks. We construct an evaluation framework comprising test-benches for functional analysis and a flow to test the syntax of Verilog code generated in response to problems of varying difficulty. Our findings show that across our problem scenarios, the fine-tuning results in LLMs more capable of producing syntactically correct code (25.9% overall). Further, when analyzing functional correctness, a fine-tuned open-source CodeGen LLM can outperform the state-of-the-art commercial Codex LLM (6.5% overall). We release our training/evaluation scripts and LLM checkpoints as open source contributions. © 2023 EDAA.
KW  - GPT
KW  - LLM
KW  - Transformers
KW  - Verilog
KW  - Computational linguistics
KW  - Open source software
KW  - Open systems
KW  - Codegeneration
KW  - GPT
KW  - Hardware design
KW  - Human errors
KW  - Language model
KW  - Large language model
KW  - Open-source
KW  - RTL codes
KW  - Transformer
KW  - Verilog code
KW  - Computer hardware description languages
PB  - Institute of Electrical and Electronics Engineers Inc.
SN  - 15301591 (ISSN); 978-398192637-8 (ISBN)
LA  - English
J2  - Proc. Des. Autom. Test Eur. DATE
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 4; Conference name: 2023 Design, Automation and Test in Europe Conference and Exhibition, DATE 2023; Conference date: 17 April 2023 through 19 April 2023; Conference code: 189131
ER  -

TY  - JOUR
AU  - Crawford, J.
AU  - Cowling, M.
AU  - Allen, K.-A.
TI  - Leadership is needed for ethical ChatGPT: Character, assessment, and learning using artificial intelligence (AI)
PY  - 2023
T2  - Journal of University Teaching and Learning Practice
VL  - 20
IS  - 3
DO  - 10.53761/1.20.3.02
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85151126783&doi=10.53761%2f1.20.3.02&partnerID=40&md5=e6d6f855fc347dfc08147a3e571c3ca4
AD  - University of Tasmania, Australia
AD  - Central Queensland University, Australia
AD  - Monash University, Australia
AB  - The OpenAI’s ChatGPT-3, or Chat Generative Pre-Trained Transformer was released in November 2022 without significant warning, and has taken higher education by storm since. The artificial intelligence (AI)-powered chatbot has caused alarm for practitioners seeking to detect authenticity of student work. Whereas some educational doomsayers predict the end of education in its current form, we propose an alternate early view. We identify in this commentary a position where educators can leverage AI like ChatGPT to build supportive learning environments for students who have cultivated good character. Such students know how to use ChatGPT for good, and can engage effectively with the ChatGPT application. In building our ChatGPT argument, we acknowledge the existing literature on plagiarism and academic integrity, and consider leadership as a root support mechanism, character development as an antidote, and authentic assessment as an enabler. In doing so, we highlight that while ChatGPT – like papermills, and degree factories before it – can be used to cheat on university exams, it can also be used to support deeper learning and better learning outcomes for students. In doing so, we offer a commentary that offers opportunities for practitioners, and research potential for scholars. Practitioner Notes 1. OpenAI’s ChatGPT-3 has taken higher education by storm with threats of plagiarism and integrity as key concerns. 2. We argue that effective teacher leadership is needed to develop student character so they use ChatGPT for good, rather than for personal benefit. 3. ChatGPT can create new and innovative authentic assessment in higher education. 4. ChatGPT offers students the opportunity to simplify the learning process to create less distraction, and more flow. © 2023, University of Wollongong. All rights reserved.
KW  - academic integrity
KW  - artificial intelligence
KW  - ChatGPT
KW  - large language model
KW  - OpenAI
KW  - student character
PB  - University of Wollongong
SN  - 14499789 (ISSN)
LA  - English
J2  - J. Univ. Teach. Learn. Pract.
M3  - Article
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 75
ER  -

TY  - JOUR
AU  - Lentzen, M.
AU  - Madan, S.
AU  - Lage-Rupprecht, V.
AU  - Kühnel, L.
AU  - Fluck, J.
AU  - Jacobs, M.
AU  - Mittermaier, M.
AU  - Witzenrath, M.
AU  - Brunecker, P.
AU  - Hofmann-Apitius, M.
AU  - Weber, J.
AU  - Fröhlich, H.
TI  - Critical assessment of transformer-based AI models for German clinical notes
PY  - 2022
T2  - JAMIA Open
VL  - 5
IS  - 4
C7  - ooac087
DO  - 10.1093/jamiaopen/ooac087
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85144816980&doi=10.1093%2fjamiaopen%2fooac087&partnerID=40&md5=4dd3857a861a389695f6444bca4065d5
AD  - Department of Bioinformatics, Fraunhofer Institute for Algorithms and Scientific Computing (SCAI), Schloss Birlinghoven, Sankt Augustin, Germany
AD  - Bonn-Aachen International Center for Information Technology (B-IT), University of Bonn, Bonn, Germany
AD  - Institute of Computer Science, University of Bonn, Bonn, Germany
AD  - Knowledge Management, Zb Med - Information Centre for Life Sciences, Cologne, Germany
AD  - Graduate School Dils, Bielefeld Institute for Bioinformatics Infrastructure (BIBI), Faculty of Technology, Bielefeld University, Bielefeld, Germany
AD  - The Agricultural Faculty, University of Bonn, Bonn, Germany
AD  - Department of Infectious Diseases and Respiratory Medicine, Charite - Universitätsmedizin Berlin, Corporate Member of Freie Universität Berlin, Humboldt-Universität zu Berlin, Berlin, Germany
AD  - Berlin Institute of Health (BIH) at Charite, Universitätsmedizin Berlin, Berlin, Germany
AD  - German Center for Lung Research (DZL), Partner Site Charite, Berlin, Germany
AD  - Berlin Institute of Health at Charite, Universitätsmedizin Berlin, Core Facility Research It, Berlin, Germany
AD  - Charite - Universitätsmedizin Berlin, Center for Stroke Research Berlin, Corporate Member of Freie Universität Berlin, Humboldt-Universität zu Berlin, Berlin, Germany
AD  - Department of Neurology, Charite - Universitätsmedizin Berlin, Corporate Member of Freie Universität Berlin, Humboldt-Universität zu Berlin, Berlin, Germany
AB  - Objective: Healthcare data such as clinical notes are primarily recorded in an unstructured manner. If adequately translated into structured data, they can be utilized for health economics and set the groundwork for better individualized patient care. To structure clinical notes, deep-learning methods, particularly transformer-based models like Bidirectional Encoder Representations from Transformers (BERT), have recently received much attention. Currently, biomedical applications are primarily focused on the English language. While general-purpose German-language models such as GermanBERT and GottBERT have been published, adaptations for biomedical data are unavailable. This study evaluated the suitability of existing and novel transformer-based models for the German biomedical and clinical domain. Materials and Methods: We used 8 transformer-based models and pre-trained 3 new models on a newly generated biomedical corpus, and systematically compared them with each other. We annotated a new dataset of clinical notes and used it with 4 other corpora (BRONCO150, CLEF eHealth 2019 Task 1, GGPONC, and JSynCC) to perform named entity recognition (NER) and document classification tasks. Results: General-purpose language models can be used effectively for biomedical and clinical natural language processing (NLP) tasks, still, our newly trained BioGottBERT model outperformed GottBERT on both clinical NER tasks. However, training new biomedical models from scratch proved ineffective. Discussion: The domain-adaptation strategy's potential is currently limited due to a lack of pre-training data. Since general-purpose language models are only marginally inferior to domain-specific models, both options are suitable for developing German-language biomedical applications. Conclusion: General-purpose language models perform remarkably well on biomedical and clinical NLP tasks. If larger corpora become available in the future, domain-adapting these models may improve performances.  © 2022 The Author(s). Published by Oxford University Press on behalf of the American Medical Informatics Association.
KW  - clinical concept extraction
KW  - natural language processing
KW  - transformer-based models
KW  - article
KW  - controlled study
KW  - English (language)
KW  - extraction
KW  - German (language)
KW  - human
KW  - human experiment
KW  - natural language processing
KW  - telehealth
PB  - Oxford University Press
SN  - 25742531 (ISSN)
LA  - English
J2  - JAMIA Open
M3  - Article
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 2; Correspondence Address: H. Fröhlich; Department of Bioinformatics, Fraunhofer Institute for Algorithms and Scientific Computing (SCAI), Sankt Augustin, Schloss Birlinghoven, 53757, Germany; email: holger.froehlich@scai.fraunhofer.de
ER  -

TY  - JOUR
AU  - Jiang, M.
AU  - D’Souza, J.
AU  - Auer, S.
AU  - Downie, J.S.
TI  - Evaluating BERT-based scientific relation classifiers for scholarly knowledge graph construction on digital library collections
PY  - 2022
T2  - International Journal on Digital Libraries
VL  - 23
IS  - 2
SP  - 197
EP  - 215
DO  - 10.1007/s00799-021-00313-y
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85118454711&doi=10.1007%2fs00799-021-00313-y&partnerID=40&md5=e1d96d434470a437766a51237ff06633
AD  - University of Illinois, Urbana-Champaign, United States
AD  - TIB Leibniz Information Centre for Science and Technology, Hannover, Germany
AD  - L3S Research Center at Leibniz University of Hannover, Hannover, Germany
AB  - The rapid growth of research publications has placed great demands on digital libraries (DL) for advanced information management technologies. To cater to these demands, techniques relying on knowledge-graph structures are being advocated. In such graph-based pipelines, inferring semantic relations between related scientific concepts is a crucial step. Recently, BERT-based pre-trained models have been popularly explored for automatic relation classification. Despite significant progress, most of them were evaluated in different scenarios, which limits their comparability. Furthermore, existing methods are primarily evaluated on clean texts, which ignores the digitization context of early scholarly publications in terms of machine scanning and optical character recognition (OCR). In such cases, the texts may contain OCR noise, in turn creating uncertainty about existing classifiers’ performances. To address these limitations, we started by creating OCR-noisy texts based on three clean corpora. Given these parallel corpora, we conducted a thorough empirical evaluation of eight Bert-based classification models by focusing on three factors: (1) Bert variants; (2) classification strategies; and, (3) OCR noise impacts. Experiments on clean data show that the domain-specific pre-trained Bert is the best variant to identify scientific relations. The strategy of predicting a single relation each time outperforms the one simultaneously identifying multiple relations in general. The optimal classifier’s performance can decline by around 10% to 20% in F-score on the noisy corpora. Insights discussed in this study can help DL stakeholders select techniques for building optimal knowledge-graph-based systems. © 2021, The Author(s), under exclusive licence to Springer-Verlag GmbH Germany, part of Springer Nature.
KW  - Digital library
KW  - Information extraction
KW  - Knowledge graphs
KW  - Neural machine learning
KW  - Scholarly text mining
KW  - Semantic relation classification
PB  - Springer Science and Business Media Deutschland GmbH
SN  - 14325012 (ISSN)
LA  - English
J2  - Int. J. Digital Libr.
M3  - Article
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 1; Correspondence Address: M. Jiang; University of Illinois, Urbana-Champaign, United States; email: mjiang17@illinois.edu
ER  -

TY  - JOUR
AU  - Ferrell, B.
AU  - Raskin, S.E.
AU  - Zimmerman, E.B.
TI  - Calibrating a Transformer-Based Model’s Confidence on Community-Engaged Research Studies: Decision Support Evaluation Study
PY  - 2023
T2  - JMIR Formative Research
VL  - 7
C7  - e41516
DO  - 10.2196/41516
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85151371165&doi=10.2196%2f41516&partnerID=40&md5=725d18e30737a73a3c36f2312d75e448
AD  - Virginia Commonwealth University, Richmond, VA, United States
AD  - L. Douglas Wilder School of Government and Public Affairs, Virginia Commonwealth University, Richmond, VA, United States
AD  - Center on Society and Health, Virginia Commonwealth University, Richmond, VA, United States
AB  - Background: Deep learning offers great benefits in classification tasks such as medical imaging diagnostics or stock trading, especially when compared with human-level performances, and can be a viable option for classifying distinct levels within community-engaged research (CEnR). CEnR is a collaborative approach between academics and community partners with the aim of conducting research that is relevant to community needs while incorporating diverse forms of expertise. In the field of deep learning and artificial intelligence (AI), training multiple models to obtain the highest validation accuracy is common practice; however, it can overfit toward that specific data set and not generalize well to a real-world population, which creates issues of bias and potentially dangerous algorithmic decisions. Consequently, if we plan on automating human decision-making, there is a need for creating techniques and exhaustive evaluative processes for these powerful unexplainable models to ensure that we do not incorporate and blindly trust poor AI models to make real-world decisions. Objective: We aimed to conduct an evaluation study to see whether our most accurate transformer-based models derived from previous studies could emulate our own classification spectrum for tracking CEnR studies as well as whether the use of calibrated confidence scores was meaningful. Methods: We compared the results from 3 domain experts, who classified a sample of 45 studies derived from our university’s institutional review board database, with those from 3 previously trained transformer-based models, as well as investigated whether calibrated confidence scores can be a viable technique for using AI in a support role for complex decision-making systems. Results: Our findings reveal that certain models exhibit an overestimation of their performance through high confidence scores, despite not achieving the highest validation accuracy. Conclusions: Future studies should be conducted with larger sample sizes to generalize the results more effectively. Although our study addresses the concerns of bias and overfitting in deep learning models, there is a need to further explore methods that allow domain experts to trust our models more. The use of a calibrated confidence score can be a misleading metric when determining our AI model’s level of competency. ©Brian Ferrell, Sarah E Raskin, Emily B Zimmerman. Originally published in JMIR Formative Research (https://formative.jmir.org),20.03.2023. This is an open-access article distributed under the terms of the Creative Commons Attribution License (https://creativecommons.org/licenses/by/4.0/), which permits unrestricted use, distribution, and reproduction in any medium, provided the original work, first published in JMIR Formative Research, is properly cited. The complete bibliographic information, a link to the original publication on https://formative.jmir.org, as well as this copyright and license information must be included.
KW  - BERT
KW  - Bidirectional Encoder Representations From Transformers
KW  - community engagement
KW  - community-engaged research
KW  - confidence
KW  - decision support
KW  - deep learning
KW  - KEYWORDS explainable artificial intelligence
KW  - text classification
KW  - transformer-based models
KW  - trust
KW  - XAI
PB  - JMIR Publications Inc.
SN  - 2561326X (ISSN)
LA  - English
J2  - JMIR Form.  Res.
M3  - Article
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 2; Correspondence Address: B. Ferrell; Virginia Commonwealth University, Richmond, United States; email: ferrellbj@vcu.edu
ER  -

TY  - CONF
AU  - Hecker, P.
AU  - Kappattanavar, A.M.
AU  - Schmitt, M.
AU  - Moontaha, S.
AU  - Wagner, J.
AU  - Eyben, F.
AU  - Schuller, B.W.
AU  - Arnrich, B.
TI  - Quantifying Cognitive Load from Voice using Transformer-Based Models and a Cross-Dataset Evaluation
PY  - 2022
T2  - Proceedings - 21st IEEE International Conference on Machine Learning and Applications, ICMLA 2022
SP  - 337
EP  - 344
DO  - 10.1109/ICMLA55696.2022.00055
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85152215106&doi=10.1109%2fICMLA55696.2022.00055&partnerID=40&md5=c6cea1a68703bb5c2361f28f09788f53
AD  - University of Potsdam, Digital Health - Connected Healthcare, Hasso Plattner Institute, Potsdam, Germany
AD  - AudEERING GmbH, Gilching, Germany
AD  - University of Augsburg, EIHW - Embedded Intelligence for Health Care and Wellbeing, Augsburg, Germany
AD  - Imperial College London, GLAM - Group on Language, Audio, & Music, London, United Kingdom
AB  - Cognitive load is frequently induced in laboratory setups to measure responses to stress, and its impact on voice has been studied in the field of computational paralinguistics. One dataset on this topic was provided in the Computational Paralinguistics Challenge (ComParE) 2014, and therefore offers great comparability. Recently, transformer-based deep learning architectures established a new state-of-the-art and are finding their way gradually into the audio domain. In this context, we investigate the performance of popular transformer architectures in the audio domain on the ComParE 2014 dataset, and the impact of different pre-training and fine-tuning setups on these models. Further, we recorded a small custom dataset, designed to be comparable with the ComParE 2014 one, to assess cross-corpus model generalisability. We find that the transformer models outperform the challenge baseline, the challenge winner, and more recent deep learning approaches. Models based on the 'large' architecture perform well on the task at hand, while models based on the 'base' architecture perform at chance level. Fine-tuning on related domains (such as ASR or emotion), before fine-tuning on the targets, yields no higher performance compared to models pre-trained only in a self-supervised manner. The generalisability of the models between datasets is more intricate than expected, as seen in an unexpected low performance on the small custom dataset, and we discuss potential 'hidden' underlying discrepancies between the datasets. In summary, transformer-based architectures outperform previous attempts to quantify cognitive load from voice. This is promising, in particular for healthcare-related problems in computational paralinguistics applications, since datasets are sparse in that realm.  © 2022 IEEE.
KW  - cognitive load
KW  - cross-dataset
KW  - transformer
KW  - voice
KW  - wav2vec 2.0
KW  - Architecture
KW  - Linguistics
KW  - Cognitive loads
KW  - Cross-dataset
KW  - Cross-dataset evaluation
KW  - Fine tuning
KW  - Laboratory set-up
KW  - Model-based OPC
KW  - Paralinguistic
KW  - Performance
KW  - Transformer
KW  - Wav2vec 2.0
KW  - Deep learning
A2  - Wani M.A.
A2  - Kantardzic M.
A2  - Palade V.
A2  - Neagu D.
A2  - Yang L.
A2  - Chan K.-Y.
PB  - Institute of Electrical and Electronics Engineers Inc.
SN  - 978-166546283-9 (ISBN)
LA  - English
J2  - Proc. - IEEE Int. Conf. Mach. Learn. Appl., ICMLA
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 1; Correspondence Address: P. Hecker; University of Potsdam, Digital Health - Connected Healthcare, Hasso Plattner Institute, Potsdam, Germany; email: Pascal.Hecker@hpi.de; Conference name: 21st IEEE International Conference on Machine Learning and Applications, ICMLA 2022; Conference date: 12 December 2022 through 14 December 2022; Conference code: 187486
ER  -

TY  - JOUR
AU  - Chaudhry, I.S.
AU  - Sarwary, S.A.M.
AU  - El Refae, G.A.
AU  - Chabchoub, H.
TI  - Time to Revisit Existing Student’s Performance Evaluation Approach in Higher Education Sector in a New Era of ChatGPT — A Case Study
PY  - 2023
T2  - Cogent Education
VL  - 10
IS  - 1
C7  - 2210461
DO  - 10.1080/2331186X.2023.2210461
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85159670869&doi=10.1080%2f2331186X.2023.2210461&partnerID=40&md5=b2ae46fd39a2a94490a1fd6fbf9c77bb
AD  - College of Business, Al Ain University, Abu Dhabi, United Arab Emirates
AD  - Software Engineer, Portland State University, Portland, OR, United States
AB  - Artificial intelligence-based tools are rapidly revolutionizing the field of higher education, yet to be explored in terms of their impact on existing higher education institutions’ (HEIs) practices adopted for continuous learning improvement, given the sparsity of the literature and empirical experiments in undergraduate degree programs. After the entry of ChatGPT -a conversational artificial intelligence (AI) tool that uses a deep learning model to generate human-like text response based on provided input—it has become crucial for HEIs to be exposed to the implications of AI-based tools on students’ learning outcomes, commonly measured using an assessment-based approach to improve program quality, teaching effectiveness, and other learning support. An empirical study has been conducted to test the ChatGPT capability of solving a variety of assignments (from different level courses of undergraduate degree programs) to compare its performance with the highest scored student(s). Further, the ChatGPT-generated assignments were tested using the best-known tools for plagiarism detection to determine whether they could pass the academic integrity tests, including Turnitin, GPTZero, and Copyleaks. The study reported the limitations of the Bot and highlighted the implications of the newly launched AI-based ChatGPT in academia, which calls for HEIs’ managers and regulators to revisit their existing practices used to monitor students’ learning progress and improve their educational programs. © 2023 The Author(s). Published by Informa UK Limited, trading as Taylor & Francis Group.
KW  - academic integrity
KW  - artificial intelligence
KW  - ChatGpt
KW  - learning outcomes
KW  - performance evaluation
PB  - Taylor and Francis Ltd.
SN  - 2331186X (ISSN)
LA  - English
J2  - Cogent Educ.
M3  - Article
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 15; Correspondence Address: I.S. Chaudhry; College of Business, Mohamed Bin Zayed, Al Ain University, Abu Dhabi Campus, United Arab Emirates; email: iffat.sabir@aau.ac.ae
ER  -

TY  - JOUR
AU  - Mithun, S.
AU  - Jha, A.K.
AU  - Sherkhane, U.B.
AU  - Jaiswar, V.
AU  - Purandare, N.C.
AU  - Rangarajan, V.
AU  - Dekker, A.
AU  - Puts, S.
AU  - Bermejo, I.
AU  - Wee, L.
TI  - Development and validation of deep learning and BERT models for classification of lung cancer radiology reports
PY  - 2023
T2  - Informatics in Medicine Unlocked
VL  - 40
C7  - 101294
DO  - 10.1016/j.imu.2023.101294
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85161650201&doi=10.1016%2fj.imu.2023.101294&partnerID=40&md5=150ae2bb113c1c5c383d54b9e9e17cc9
AD  - Department of Radiation Oncology (Maastro), GROW School for Oncology and Reproduction, Maastricht University Medical Centre+, Maastricht, 6229 ET, Netherlands
AD  - Department of Nuclear Medicine and Molecular Imaging, Tata Memorial Hospital, Mumbai, India
AD  - Homi Bhabha National Institute (HBNI), Deemed University, Mumbai, India
AB  - Purpose: Manual cohort building from radiology reports can be tedious. Natural Language Processing (NLP) can be used for automated cohort building. In this study, we have developed and validated an NLP approach based on deep learning (DL) to select lung cancer reports from a thoracic disease management group cohort. Materials and methods: 4064 radiology reports (CT and PET/CT) of a thoracic disease management group reported between 2014 and 2016 were used. These reports were anonymised, cleaned, text normalized and split into a training, testing, and validation set. External validation was performed on radiology reports from the MIMIC-III clinical database. We used three DL models, namely, Bi-LSTM_simple, Bi-LSTM_dropout, and Pre-trained _BERT model to predict if a report concerned lung cancer. We studied the effect of minority oversampling on all models. Results: Without oversampling, the F1 scores at 95% CI for Bi-LSTM_simple, Bi-LSTM_dropout and BERT were 0.89, 0.90, and 0.86; with oversampling, the F1 scores were 0.94, 0.94, and 0.9, on internal validation. On external validation the F1-scores of Bi-LSTM_simple, Bi-LSTM_dropout and BERT models were 0.63, 0.77 and 0.80 without oversampling and 0.72, 0.78 and 0.77 with oversampling. Conclusion: Pre-trained BERT model and Bi-LSTM_dropout models to predict a lung cancer report showed consistent performance on internal and external validation with the BERT model exhibiting superior performance. The overall F1 score decreased on external validation for both Bi-LSTM models with the Bi-LSTM_simple model showing a more significant drop. All models showed some improvement on minority oversampling. © 2023 The Authors
KW  - Artificial intelligence
KW  - Classification model
KW  - Deep learning
KW  - Lung cancer
KW  - Natural language processing
KW  - Nuclear medicine
KW  - PET/CT
KW  - Radiology reports
KW  - Article
KW  - artificial intelligence
KW  - computer assisted tomography
KW  - controlled study
KW  - deep learning
KW  - human
KW  - long short term memory network
KW  - lung cancer
KW  - natural language processing
KW  - performance indicator
KW  - positron emission tomography-computed tomography
KW  - radiology
KW  - validation process
KW  - validation study
PB  - Elsevier Ltd
SN  - 23529148 (ISSN)
LA  - English
J2  - Inform. Med. Unlocked
M3  - Article
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 1; Correspondence Address: S. Mithun; Department of Radiation Oncology (Maastro), GROW School for Oncology and Reproduction, Maastricht University Medical Centre+, Maastricht, 6229 ET, Netherlands; email: s.mithun@maastrichtuniversity.nl
ER  -

TY  - JOUR
AU  - Subramani, M.
AU  - Jaleel, I.
AU  - Mohan, S.K.
TI  - Evaluating the performance of ChatGPT in medical physiology university examination of phase I MBBS
PY  - 2023
T2  - Advances in Physiology Education
VL  - 47
IS  - 2
SP  - 270
EP  - 271
DO  - 10.1152/ADVAN.00036.2023
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85150966687&doi=10.1152%2fADVAN.00036.2023&partnerID=40&md5=0171d20f319ac48f6e457913ea75d3e9
AD  - Department of Physiology, Panimalar Medical College Hospital and Research Institute, Tamil Nadu, Varadharajapuram,Chennai, India
AD  - Departments of Biochemistry, Medical Education, Molecular Virology, Research, Clinical Skills and Simulation, Panimalar Medical College Hospital and Research Institute, Tamil Nadu, Varadharajapuram,Chennai, India
AB  - San Francisco-based OpenAI Inc/LP developed and launched the revolutionary and enormous languagemodel powered by an artificial intelligence (AI) chatbot systemnamed ChatGPT on November 30, 2022, which generates humanoid responses to varied and diverse natural queries (1). Within a week of its release, ChatGPT has crossed the over 1million usermark (2). This ChatGPT (Chat Generative Pre-trained Transformer) is a freely accessible conversational AI tool that was developed on the concept of reinforcement learning fromhuman feedback (3). Ever since the integration of ChatGPT, the Microsoft Bing search engine has reached an impressive milestone ofmore than 100million daily active users and is soon to be made instantly available for millions of users online along with healthcare professionals and students (4). In recognition of its high impact, the efficiency of ChatGPT has also been tested in the United States Medical Licensing Examination (USMLE), and it has successfully cleared the test (5). Although ChatGPT cannot replace human thinking and reasoning, its usability in several fields including medical education and clinical decision making is worthy of more research that can assess its accuracy and utility in themedical field (6). © 2023 the American Physiological Society
KW  - Humans
KW  - Universities
KW  - human
KW  - university
PB  - American Physiological Society
SN  - 10434046 (ISSN)
C2  - 36971685
LA  - English
J2  - Adv. Physiol. Educ.
M3  - Letter
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 15; Correspondence Address: S.K. Mohan; Departments of Biochemistry, Medical Education, Molecular Virology, Research, Clinical Skills and Simulation, Panimalar Medical College Hospital and Research Institute, Varadharajapuram,Chennai, Tamil Nadu, India; email: krishnamohan.surapaneni@gmail.com; CODEN: APEDF
ER  -

TY  - JOUR
AU  - Tian, W.M.
AU  - Sergesketter, A.R.
AU  - Hollenbeck, S.T.
TI  - The Role of ChatGPT in Microsurgery: Assessing Content Quality and Potential Applications
PY  - 2023
T2  - Journal of Reconstructive Microsurgery
DO  - 10.1055/a-2098-6509
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85164907394&doi=10.1055%2fa-2098-6509&partnerID=40&md5=73a3d7526bfceeba8cd482a07e0d5526
AD  - Division of Plastic, Maxillofacial, and Oral Surgery, Duke University, Durham, NC, United States
AD  - Department of Plastic Surgery, University of Virginia, Charlottesville, VA, United States
PB  - Thieme Medical Publishers, Inc.
SN  - 0743684X (ISSN)
C2  - 37225130
LA  - English
J2  - J. Reconstr. Microsurg.
M3  - Letter
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 2; Correspondence Address: S.T. Hollenbeck; Department of Plastic and Reconstructive Surgery, University of Virginia, Charlottesville, 22903, United States; email: scott.hollenbeck@duke.edu; CODEN: JRMIE
ER  -

TY  - CONF
AU  - Amplayo, R.K.
AU  - Yoo, K.M.
AU  - Lee, S.-W.
TI  - Attribute Injection for Pretrained Language Models: A New Benchmark and An Efficient Method
PY  - 2022
T2  - Proceedings - International Conference on Computational Linguistics, COLING
VL  - 29
IS  - 1
SP  - 1051
EP  - 1064
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85161274828&partnerID=40&md5=70330ff2dd3c9b06d187004bd8cb1f3f
AD  - University of Edinburgh, United Kingdom
AD  - NAVER AI Lab, NAVER Clova AI
AB  - Metadata attributes (e.g., user and product IDs from reviews) can be incorporated as additional inputs to neural-based NLP models, by expanding the architecture of the models to improve performance. However, recent models rely on pretrained language models (PLMs), in which previously used techniques for attribute injection are either nontrivial or cost-ineffective. In this paper, we introduce a benchmark for evaluating attribute injection models, which comprises eight datasets across a diverse range of tasks and domains and six synthetically sparsified ones. We also propose a lightweight and memory-efficient method to inject attributes into PLMs. We extend adapters, i.e. tiny plug-in feed-forward modules, to include attributes both independently of or jointly with the text. We use approximation techniques to parameterize the model efficiently for domains with large attribute vocabularies, and training mechanisms to handle multi-labeled and sparse attributes. Extensive experiments and analyses show that our method outperforms previous attribute injection methods and achieves state-of-the-art performance on all datasets. © 2022 Proceedings - International Conference on Computational Linguistics, COLING. All rights reserved.
KW  - Approximation techniques
KW  - Diverse range
KW  - Experiment and analysis
KW  - Feed forward
KW  - Improve performance
KW  - Injection method
KW  - Injection modeling
KW  - Language model
KW  - Memory efficient
KW  - Plug-ins
KW  - Computational linguistics
A2  - Calzolari N.
A2  - Huang C.-R.
A2  - Kim H.
A2  - Pustejovsky J.
A2  - Wanner L.
A2  - Choi K.-S.
A2  - Ryu P.-M.
A2  - Chen H.-H.
A2  - Donatelli L.
A2  - Ji H.
A2  - Kurohashi S.
A2  - Paggio P.
A2  - Paggio P.
A2  - Xue N.
A2  - Kim S.
A2  - Hahm Y.
A2  - He Z.
A2  - Lee T.K.
A2  - Santus E.
A2  - Bond F.
A2  - Na S.-H.
PB  - Association for Computational Linguistics (ACL)
SN  - 29512093 (ISSN)
LA  - English
J2  - Proc. Main Conf. Int. Conf. Comput. Linguist., COLING
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 2; Correspondence Address: R.K. Amplayo; University of Edinburgh, United Kingdom; email: reinald.kim@ed.ac.uk; Conference name: 29th International Conference on Computational Linguistics, COLING 2022; Conference date: 12 October 2022 through 17 October 2022; Conference code: 186893
ER  -

TY  - CONF
AU  - Papadimitriou, I.
AU  - Lopez, K.
AU  - Jurafsky, D.
TI  - Multilingual BERT has an accent: Evaluating English influences on fluency in multilingual models
PY  - 2023
T2  - EACL 2023 - 17th Conference of the European Chapter of the Association for Computational Linguistics, Findings of EACL 2023
SP  - 1164
EP  - 1170
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85159859495&partnerID=40&md5=56677bce7a1af9b3accb3ac41832b5af
AD  - Computer Science Department, Stanford University, United States
AB  - While multilingual language models can improve NLP performance on low-resource languages by leveraging higher-resource languages, they also reduce average performance on all languages (the ‘curse of multilinguality’). Here we show another problem with multilingual models: grammatical structures in higher-resource languages bleed into lower-resource languages, a phenomenon we call grammatical structure bias. We show this bias via a novel method for comparing the fluency of multilingual models to the fluency of monolingual Spanish and Greek models: testing their preference for two carefully-chosen variable grammatical structures (optional pronoun-drop in Spanish and optional Subject-Verb ordering in Greek). We find that multilingual BERT is biased toward the English-like setting (explicit pronouns and Subject-Verb-Object ordering) as compared to our monolingual control language model. With our case studies, we hope to bring to light the fine-grained ways in which multilingual models can be biased, and encourage more linguistically-aware fluency evaluation. © 2023 Association for Computational Linguistics.
KW  - Case-studies
KW  - Fine grained
KW  - Grammatical structure
KW  - Language model
KW  - Low resource languages
KW  - Model testing
KW  - Multilinguality
KW  - Novel methods
KW  - Performance
KW  - Computational linguistics
PB  - Association for Computational Linguistics (ACL)
SN  - 978-195942947-0 (ISBN)
LA  - English
J2  - EACL - Conf. Eur. Chapter Assoc. Comput. Linguist., Find. EACL
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 1; Correspondence Address: I. Papadimitriou; Computer Science Department, Stanford University, United States; email: isabelvp@stanford.edu; K. Lopez; Computer Science Department, Stanford University, United States; email: keziakl@stanford.edu; Conference name: 17th Conference of the European Chapter of the Association for Computational Linguistics, EACL 2023 - Findings of EACL 2023; Conference date: 2 May 2023 through 6 May 2023; Conference code: 188432
ER  -

TY  - JOUR
AU  - Pan, R.
AU  - García-Díaz, J.A.
AU  - Garcia-Sanchez, F.
AU  - Valencia-García, R.
TI  - Evaluation of transformer models for financial targeted sentiment analysis in Spanish
PY  - 2023
T2  - PeerJ Computer Science
VL  - 9
C7  - e1377
DO  - 10.7717/peerj-cs.1377
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85160410450&doi=10.7717%2fpeerj-cs.1377&partnerID=40&md5=d4c4aad2388703557fae4d043db9016d
AD  - Faculdad de Informática, Universidad de Murcia, Murcia, Spain
AB  - Nowadays, financial data from social media plays an important role to predict the stock market. However, the exponential growth of financial information and the different polarities of sentiment that other sectors or stakeholders may have on the same information has led to the need for new technologies that automatically collect and classify large volumes of information quickly and easily for each stakeholder. In this scenario, we conduct a targeted sentiment analysis that can automatically extract the main economic target from financial texts and obtain the polarity of a text towards such main economic target, other companies and society in general. To this end, we have compiled a novel corpus of financial tweets and news headlines in Spanish, constituting a valuable resource for the Spanish-focused research community. In addition, we have carried out a performance comparison of different Spanish-specific large language models, with MarIA and BETO achieving the best results. Our best result has an overall performance of 76.04%, 74.16%, and 68.07% in macro F1-score for the sentiment classification towards the main economic target, society, and other companies, respectively, and an accuracy of 69.74% for target detection. We have also evaluated the performance of multi-label classification models in this context and obtained a performance of 71.13% © Copyright 2023 Pan et al.
KW  - Financial domain
KW  - Natural language processing
KW  - Sentiment analysis
KW  - Targeted sentiment analysis
KW  - Classification (of information)
KW  - Finance
KW  - Financial data
KW  - Financial domains
KW  - Language processing
KW  - Natural language processing
KW  - Natural languages
KW  - Performance
KW  - Sentiment analysis
KW  - Targeted sentiment analyse
KW  - Transformer modeling
KW  - Sentiment analysis
PB  - PeerJ Inc.
SN  - 23765992 (ISSN)
LA  - English
J2  - PeerJ Comput. Sci.
M3  - Article
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 9; Correspondence Address: R. Valencia-García; Faculdad de Informática, Universidad de Murcia, Murcia, Spain; email: valencia@um.es
ER  -

TY  - JOUR
AU  - Wulff, P.
AU  - Buschhüter, D.
AU  - Westphal, A.
AU  - Mientus, L.
AU  - Nowak, A.
AU  - Borowski, A.
TI  - Bridging the Gap Between Qualitative and Quantitative Assessment in Science Education Research with Machine Learning — A Case for Pretrained Language Models-Based Clustering
PY  - 2022
T2  - Journal of Science Education and Technology
VL  - 31
IS  - 4
SP  - 490
EP  - 513
DO  - 10.1007/s10956-022-09969-w
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85131324465&doi=10.1007%2fs10956-022-09969-w&partnerID=40&md5=d75ddf30ea3aff985a0e7187c6055454
AD  - Physics Education Research Group, Heidelberg University of Education, Heidelberg, Germany
AD  - Physics Education Research Group, University of Potsdam, Potsdam, Germany
AD  - Department of Educational Research, University of Greifswald, Greifswald, Germany
AB  - Science education researchers typically face a trade-off between more quantitatively oriented confirmatory testing of hypotheses, or more qualitatively oriented exploration of novel hypotheses. More recently, open-ended, constructed response items were used to combine both approaches and advance assessment of complex science-related skills and competencies. For example, research in assessing science teachers’ noticing and attention to classroom events benefitted from more open-ended response formats because teachers can present their own accounts. Then, open-ended responses are typically analyzed with some form of content analysis. However, language is noisy, ambiguous, and unsegmented and thus open-ended, constructed responses are complex to analyze. Uncovering patterns in these responses would benefit from more principled and systematic analysis tools. Consequently, computer-based methods with the help of machine learning and natural language processing were argued to be promising means to enhance assessment of noticing skills with constructed response formats. In particular, pretrained language models recently advanced the study of linguistic phenomena and thus could well advance assessment of complex constructs through constructed response items. This study examines potentials and challenges of a pretrained language model-based clustering approach to assess preservice physics teachers’ attention to classroom events as elicited through open-ended written descriptions. It was examined to what extent the clustering approach could identify meaningful patterns in the constructed responses, and in what ways textual organization of the responses could be analyzed with the clusters. Preservice physics teachers (N = 75) were instructed to describe a standardized, video-recorded teaching situation in physics. The clustering approach was used to group related sentences. Results indicate that the pretrained language model-based clustering approach yields well-interpretable, specific, and robust clusters, which could be mapped to physics-specific and more general contents. Furthermore, the clusters facilitate advanced analysis of the textual organization of the constructed responses. Hence, we argue that machine learning and natural language processing provide science education researchers means to combine exploratory capabilities of qualitative research methods with the systematicity of quantitative methods. © 2022, The Author(s).
KW  - Attention to classroom events
KW  - ML
KW  - NLP
KW  - Noticing
PB  - Springer Science and Business Media B.V.
SN  - 10590145 (ISSN)
LA  - English
J2  - J. Sci. Educ. Technol.
M3  - Article
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 13; Correspondence Address: P. Wulff; Physics Education Research Group, Heidelberg University of Education, Heidelberg, Germany; email: peter.wulff@ph-heidelberg.de
ER  -

TY  - CONF
AU  - Abdelaziz, I.
AU  - Dolby, J.
AU  - McCusker, J.
AU  - Srinivas, K.
TI  - Can Machines Read Coding Manuals Yet? - A Benchmark for Building Better Language Models for Code Understanding
PY  - 2022
T2  - Proceedings of the 36th AAAI Conference on Artificial Intelligence, AAAI 2022
VL  - 36
SP  - 4415
EP  - 4423
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85144974625&partnerID=40&md5=84142a34ee3e66ccf3902262cae56d9d
AD  - IBM Research, T.J. Watson Research Center, United States
AD  - Rensselaer Polytechnic Institute (RPI), United States
AB  - Code understanding is an increasingly important application of Artificial Intelligence. A fundamental aspect of understanding code is understanding text about code, e.g., documentation and forum discussions. Pre-trained language models (e.g., BERT) are a popular approach for various NLP tasks, and there are now a variety of benchmarks, such as GLUE, to help improve the development of such models for natural language understanding. However, little is known about how well such models work on textual artifacts about code, and we are unaware of any systematic set of downstream tasks for such an evaluation. In this paper, we derive a set of benchmarks (BLANCA - Benchmarks for LANguage models on Coding Artifacts) that assess code understanding based on tasks such as predicting the best answer to a question in a forum post, finding related forum posts, or predicting classes related in a hierarchy from class documentation. We evaluate performance of current state-of-the-art language models on these tasks and show that there is significant improvement on each task from fine tuning. We also show that multi-task training over BLANCA tasks help build better language models for code understanding. Copyright © 2022, Association for the Advancement of Artificial Intelligence (www.aaai.org). All rights reserved.
KW  - Artificial intelligence
KW  - Computational linguistics
KW  - Natural language processing systems
KW  - 'current
KW  - Code understanding
KW  - Coding artefacts
KW  - Down-stream
KW  - Fine tuning
KW  - Language model
KW  - Natural language understanding
KW  - Performance
KW  - State of the art
KW  - Systematic set
KW  - Petroleum reservoir evaluation
PB  - Association for the Advancement of Artificial Intelligence
SN  - 1577358767 (ISBN); 978-157735876-3 (ISBN)
LA  - English
J2  - Proc. AAAI Conf. Artif. Intell., AAAI
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 2; Conference name: 36th AAAI Conference on Artificial Intelligence, AAAI 2022; Conference date: 22 February 2022 through 1 March 2022; Conference code: 185285
ER  -

TY  - CONF
AU  - Lee, Y.-J.
AU  - Lim, C.-G.
AU  - Choi, H.-J.
TI  - Does GPT-3 Generate Empathetic Dialogues? A Novel In-Context Example Selection Method and Automatic Evaluation Metric for Empathetic Dialogue Generation
PY  - 2022
T2  - Proceedings - International Conference on Computational Linguistics, COLING
VL  - 29
IS  - 1
SP  - 669
EP  - 683
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85159916119&partnerID=40&md5=c7b33ace4f828fcc091ba0dc8313283c
AD  - School of Computing, KAIST, South Korea
AB  - Since empathy plays a crucial role in increasing social bonding between people, many studies have designed their own dialogue agents to be empathetic using the well-established method of fine-tuning. However, they do not use prompt-based in-context learning, which has shown powerful performance in various natural language processing (NLP) tasks, for empathetic dialogue generation. Although several studies have investigated few-shot in-context learning for empathetic dialogue generation, an in-depth analysis of the generation of empathetic dialogue with in-context learning remains unclear, especially in GPT-3 (Brown et al., 2020). In this study, we explore whether GPT-3 can generate empathetic dialogues through prompt-based in-context learning in both zero-shot and few-shot settings. To enhance performance, we propose new in-context example selection methods, called SITSM and EMOSITSM, that utilize emotion and situational information. We also introduce a new automatic evaluation method, DIFF-EPITOME, which reflects the human tendency to express empathy. From the analysis, we reveal that our DIFF-EPITOME is effective in measuring the degree of human empathy. We show that GPT-3 achieves competitive performance with Blender 90M, a state-of-the-art dialogue generative model, on both automatic and human evaluation. Our code is available at https://github.com/passing2961/EmpGPT-3. © 2022 Proceedings - International Conference on Computational Linguistics, COLING. All rights reserved.
KW  - Computational linguistics
KW  - Natural language processing systems
KW  - Zero-shot learning
KW  - Automatic evaluation
KW  - Context learning
KW  - Dialogue generations
KW  - Evaluation metrics
KW  - Example selection
KW  - Fine tuning
KW  - In contexts
KW  - Method evaluation
KW  - Performance
KW  - Selection methods
KW  - Blending
A2  - Calzolari N.
A2  - Huang C.-R.
A2  - Kim H.
A2  - Pustejovsky J.
A2  - Wanner L.
A2  - Choi K.-S.
A2  - Ryu P.-M.
A2  - Chen H.-H.
A2  - Donatelli L.
A2  - Ji H.
A2  - Kurohashi S.
A2  - Paggio P.
A2  - Paggio P.
A2  - Xue N.
A2  - Kim S.
A2  - Hahm Y.
A2  - He Z.
A2  - Lee T.K.
A2  - Santus E.
A2  - Bond F.
A2  - Na S.-H.
PB  - Association for Computational Linguistics (ACL)
SN  - 29512093 (ISSN)
LA  - English
J2  - Proc. Main Conf. Int. Conf. Comput. Linguist., COLING
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 7; Conference name: 29th International Conference on Computational Linguistics, COLING 2022; Conference date: 12 October 2022 through 17 October 2022; Conference code: 186893
ER  -

TY  - CONF
AU  - Donnelly, P.J.
AU  - Beery, A.
TI  - Evaluating Large-Language Models for Dimensional Music Emotion Prediction from Social Media Discourse
PY  - 2022
T2  - ICNLSP 2022 - Proceedings of the 5th International Conference on Natural Language and Speech Processing
SP  - 242
EP  - 250
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85152120268&partnerID=40&md5=6e2427d23e84b8e13212cebc5b393aaf
AD  - Electrical Engineering and Computer Science, Oregon State University - Cascades, Bend, OR, United States
AB  - The automatic prediction of emotional responses to music is a task of inherent interest to the field of music information retrieval. These efforts are often hindered by the absence of large datasets available for this task. In this work, we investigate the use of sentiment analysis on online social media conversations as an alternate data source to train computational models to predict the emotive responses to a piece of music. Using two datasets annotated with valence and arousal values, we create a corpus of social media commentary for these songs extracted from YouTube, Twitter, and Reddit. We evaluate our approach with transformer models to predict the affective values of the 2402 songs in our dataset. We achieve a moderate Pearson’s correlation of 0.62 and 0.72 for valence and arousal, respectively, for discourse from YouTube. These promising results demonstrate that discourse about music may carry semantic information useful to making determinations about the music itself. Such an approach could potentially supplement music information retrieval systems to estimate emotion for pieces of music for which the audio is restricted by copyright or otherwise unavailable. © ICNLSP 2022.All rights reserved
KW  - Audio acoustics
KW  - Emotion Recognition
KW  - Forecasting
KW  - Information retrieval
KW  - Large dataset
KW  - Search engines
KW  - Semantics
KW  - Social networking (online)
KW  - Automatic prediction
KW  - Emotion predictions
KW  - Emotional response
KW  - Language model
KW  - Large datasets
KW  - Music emotions
KW  - Music information retrieval
KW  - Sentiment analysis
KW  - Social media
KW  - YouTube
KW  - Music
A2  - Abbas M.
A2  - Freihat A.A.
PB  - Association for Computational Linguistics (ACL)
SN  - 978-195942936-4 (ISBN)
LA  - English
J2  - ICNLSP - Proc. Int. Conf. Nat. Lang. Speech Process.
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 2; Conference name: 5th International Conference on Natural Language and Speech Processing, ICNLSP 2022; Conference date: 16 December 2022 through 17 December 2022; Conference code: 187507
ER  -

TY  - CONF
AU  - Yu, B.
TI  - Evaluating Pre-Trained Language Models on Multi-Document Summarization for Literature Reviews
PY  - 2022
T2  - Proceedings - International Conference on Computational Linguistics, COLING
VL  - 29
IS  - 9
SP  - 188
EP  - 192
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85173003497&partnerID=40&md5=d4126535248f954998ea49b0b93d5a60
AD  - Georgia Tech, United States
AB  - Systematic literature reviews in the biomedical space are often expensive to conduct. Automation through machine learning and large language models could improve the accuracy and research outcomes from such reviews. In this study, we evaluate a pre-trained LongT5 model on the MSLR22: Multi-Document Summarization for Literature Reviews Shared Task datasets. We weren’t able to make any improvements on the dataset benchmark, but we do establish some evidence that current summarization metrics are insufficient in measuring summarization accuracy. A multi-document summarization web tool was also built to demonstrate the viability of summarization models for future investigators: https://ben-yu.github.io/summarizer. © 2022 COLING. All Rights Reserved.
KW  - Computational linguistics
KW  - 'current
KW  - Language model
KW  - Literature reviews
KW  - Machine-learning
KW  - Multi documents summarization
KW  - Research outcome
KW  - Summarization models
KW  - Systematic literature review
KW  - Web tools
KW  - HTTP
A2  - Cohan A.
A2  - Feigenblat G.
A2  - Freitag D.
A2  - Ghosal T.
A2  - Herrmannova D.
A2  - Knoth P.
A2  - Lo K.
A2  - Mayr P.
A2  - Shmueli-Scheuer M.
A2  - de Waard A.
A2  - Wang L.L.
PB  - Association for Computational Linguistics (ACL)
SN  - 29512093 (ISSN)
LA  - English
J2  - Proc. Main Conf. Int. Conf. Comput. Linguist., COLING
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 2; Correspondence Address: B. Yu; Georgia Tech, United States; email: byu92@gatech.edu; Conference name: 3rd Workshop on Scholarly Document Processing, SDP 2022 at 29th International Conference on Computational Linguistics, COLING 2022; Conference date: 12 October 2022 through 17 October 2022; Conference code: 192731
ER  -

TY  - JOUR
AU  - Wilkens, R.
AU  - Zilio, L.
AU  - Villavicencio, A.
TI  - Assessing linguistic generalisation in language models: a dataset for Brazilian Portuguese
PY  - 2023
T2  - Language Resources and Evaluation
DO  - 10.1007/s10579-023-09664-1
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85160852022&doi=10.1007%2fs10579-023-09664-1&partnerID=40&md5=604957533f48ca07c60641a2565e2ae2
AD  - Université catholique de Louvain, Leuven-la-Neuve, Belgium
AD  - Friedrich-Alexander-Universität Erlangen-Nürnberg, Erlangen, Germany
AD  - University of Sheffield, Sheffield, United Kingdom
AB  - Much recent effort has been devoted to creating large-scale language models. Nowadays, the most prominent approaches are based on deep neural networks, such as BERT. However, they lack transparency and interpretability, and are often seen as black boxes. This affects not only their applicability in downstream tasks but also the comparability of different architectures or even of the same model trained using different corpora or hyperparameters. In this paper, we propose a set of intrinsic evaluation tasks that inspect the linguistic information encoded in models developed for Brazilian Portuguese. These tasks are designed to evaluate how different language models generalise information related to grammatical structures and multiword expressions (MWEs), thus allowing for an assessment of whether the model has learned different linguistic phenomena. The dataset that was developed for these tasks is composed of a series of sentences with a single masked word and a cue phrase that helps in narrowing down the context. This dataset is divided into MWEs and grammatical structures, and the latter is subdivided into 6 tasks: impersonal verbs, subject agreement, verb agreement, nominal agreement, passive and connectors. The subset for MWEs was used to test BERTimbau Large, BERTimbau Base and mBERT. For the grammatical structures, we used only BERTimbau Large, because it yielded the best results in the MWE task. In both cases, we evaluated the results considering the best candidates and the top ten candidates. The evaluation was done both automatically (for MWEs) and manually (for grammatical structures). The results obtained for MWEs show that BERTimbau Large surpassed both the other models in predicting the correct masked element. However, the average accuracy of the best model was only 52% when only the best candidates were considered for each sentence, going up to 66% when the top ten candidates were taken into account. As for the grammatical tasks, the results presented better prediction, but also varied depending on the type of morphosyntactic agreement. On the one hand, cases such as connectors and impersonal verbs, which do not require any agreement in the produced candidates, had precision of 100% and 98.78% among the best candidates. On the other hand, tasks that require morphosyntactic agreement had results consistently below 90% overall precision, with the lowest scores being reported for nominal agreement and verb agreement, both having scores below 80% in overall precision among the best candidates. Therefore, we identified that a critical and widely adopted resource for Brazilian Portuguese NLP presents issues concerning MWE vocabulary and morphosyntactic agreement, even if it is prolific in most cases. These models are a core component in many NLP systems, and our findings demonstrate the need of additional improvements in these models and the importance of widely evaluating computational representations of language. © 2023, The Author(s), under exclusive licence to Springer Nature B.V.
KW  - Brazilian Portuguese
KW  - Contextualised word embeddings
KW  - Grammatical structures
KW  - Intrinsic evaluation
KW  - Language models
KW  - Multiword expression
PB  - Springer Science and Business Media B.V.
SN  - 1574020X (ISSN)
LA  - English
J2  - Lang. Resour. Eval.
M3  - Article
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 1; Correspondence Address: R. Wilkens; Université catholique de Louvain, Leuven-la-Neuve, Belgium; email: rodrigo.wilkens@uclouvain.be
ER  -

TY  - CONF
AU  - Bitton, Y.
AU  - Bitton-Guetta, N.
AU  - Yosef, R.
AU  - Elovici, Y.
AU  - Bansal, M.
AU  - Stanovsky, G.
AU  - Schwartz, R.
TI  - WinoGAViL: Gamified Association Benchmark to Challenge Vision-and-Language Models
PY  - 2022
T2  - Advances in Neural Information Processing Systems
VL  - 35
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85160318913&partnerID=40&md5=da0e9170cdcec5a8cf10c6d68cb24ea1
AD  - The Hebrew University of Jerusalem, Israel
AD  - Ben Gurion University, Israel
AD  - University of North, Carolina at Chapel Hill, United States
AB  - While vision-and-language models perform well on tasks such as visual question answering, they struggle when it comes to basic human commonsense reasoning skills. In this work, we introduce WinoGAViL: an online game of vision-and-language associations (e.g., between werewolves and a full moon), used as a dynamic evaluation benchmark. Inspired by the popular card game Codenames, a “spymaster” gives a textual cue related to several visual candidates, and another player tries to identify them. Human players are rewarded for creating associations that are challenging for a rival AI model but still solvable by other human players. We use the game to collect 3.5K instances, finding that they are intuitive for humans (>90% Jaccard index) but challenging for state-of-the-art AI models, where the best model (ViLT) achieves a score of 52%, succeeding mostly where the cue is visually salient. Our analysis as well as the feedback we collect from players indicate that the collected associations require diverse reasoning skills, including general knowledge, common sense, abstraction, and more. We release the dataset, the code and the interactive game, allowing future data collection that can be used to develop models with better association abilities. © 2022 Neural information processing systems foundation. All rights reserved.
KW  - Visual languages
KW  - Best model
KW  - Card games
KW  - Commonsense reasoning
KW  - Dynamic evaluation
KW  - Human players
KW  - Jaccard index
KW  - Language model
KW  - On-line games
KW  - Question Answering
KW  - State of the art
KW  - Computational linguistics
A2  - Koyejo S.
A2  - Mohamed S.
A2  - Agarwal A.
A2  - Belgrave D.
A2  - Cho K.
A2  - Oh A.
PB  - Neural information processing systems foundation
SN  - 10495258 (ISSN); 978-171387108-8 (ISBN)
LA  - English
J2  - Adv. neural inf. proces. syst.
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 1; Correspondence Address: Y. Bitton; The Hebrew University of Jerusalem, Israel; email: yonatan.bitton@mail.huji.ac.il; N. Bitton-Guetta; Ben Gurion University, Israel; email: nitzangu@bgu.ac.il; Conference name: 36th Conference on Neural Information Processing Systems, NeurIPS 2022; Conference date: 28 November 2022 through 9 December 2022; Conference code: 189185
ER  -

TY  - CONF
AU  - Sawicki, P.
AU  - Grzes, M.
AU  - Jordanous, A.
AU  - Brown, D.
AU  - Peeperkorn, M.
TI  - Training GPT-2 to represent two Romantic-era authors: challenges, evaluations and pitfalls
PY  - 2022
T2  - Proceedings of the 13th International Conference on Computational Creativity, ICCC 2022
SP  - 34
EP  - 43
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85162047499&partnerID=40&md5=d17caf86445c51ad6178ae45f799e624
AD  - School of Computing, University of Kent, Canterbury, United Kingdom
AD  - Cheriton School of Computer Science, University of Waterloo, Canada
AB  - Poetry generation within style constraints has many creative challenges, despite the recent advances in Transformer models for text generation. We study 1) how overfitting of various versions of GPT-2 models affects the quality of the generated text, and 2) which model is better at generating text in a specific style. For that purpose, we propose a novel setup for text evaluation with neural networks. Our GPT-2 models are trained on datasets of collected works of the two Romantic-era poets: Byron and Shelley. With some models, overfitting manifests by producing malformed samples, with others, the samples are always well-formed, but contain increasingly higher levels of n-grams duplicated from the original corpus. This behaviour can lead to incorrect evaluations of generated text because the plagiarised output can deceive neural network classifiers and even human judges. To determine which model is better at preserving style before it becomes overfitted, we conduct two series of experiments with BERT-based classifiers. Overall, our results provide a novel way of selecting the right models for fine-tuning on a specific dataset, while highlighting the pitfalls that come with overfitting, like reordering and replicating text, towards more credible creative text generation. © 2022 Proceedings of the 13th International Conference on Computational Creativity, ICCC 2022. All rights reserved.
KW  - Creatives
KW  - Fine tuning
KW  - N-grams
KW  - Neural networks classifiers
KW  - Neural-networks
KW  - Overfitting
KW  - Text evaluation
KW  - Text generations
KW  - Transformer modeling
KW  - Artificial intelligence
A2  - Hedblom M.M.
A2  - Kantosalo A.A.
A2  - Confalonieri R.
A2  - Kutz O.
A2  - Veale T.
PB  - Association for Computational Creativity (ACC)
SN  - 978-989541604-2 (ISBN)
LA  - English
J2  - Proc. Int. Conf. Comput. Creat., ICCC
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 0; Conference name: 13th International Conference on Computational Creativity, ICCC 2022; Conference date: 27 June 2022 through 1 July 2022; Conference code: 194875
ER  -

TY  - CONF
AU  - Dong, X.
AU  - Shen, S.
AU  - Jia, J.
AU  - Yu, L.
AU  - Wang, Y.
AU  - Zhang, P.
TI  - Behavior Sequence Transformer Applied on SERP Evaluation and Model Interpretation
PY  - 2022
T2  - Proceedings - 21st IEEE International Conference on Machine Learning and Applications, ICMLA 2022
SP  - 653
EP  - 658
DO  - 10.1109/ICMLA55696.2022.00108
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85152214647&doi=10.1109%2fICMLA55696.2022.00108&partnerID=40&md5=26fa11807603074b06e81d894719e540
AD  - Baidu Inc, Beijing, China
AB  - SERP (Search Engine Result Page) quality evaluation plays a vital role in industrial practice. With the rapid iterations of search engine, traditional page-level metrics like click ratio, dwell time are no longer suitable to evaluate user experience on various templates of results. To promote evaluation accuracy, we implement Transformer to capture the sequential patterns from behavior sequence data. In recent studies, approaches focusing on modeling behavior sequences have emerged. Some studies concentrate on feature engineering by extracting subsequence patterns, others focus on end-to-end deep learning models. While widely used, these two methods both have drawbacks, either a risk of distortion of true subsequence patterns or difficulty for interpretation. Here we implement Transformer to give considerations to both completeness of sequential patterns and model interpretation. To find the best way of modeling behavior sequence data with continuous features, we adopt two embedding methods to predict SERP quality evaluation, and the second one achieves good promotion. What's more, we develop a novel interpretation method for transformer models and demonstrate its ability to make interpretations for subsequence patterns.  © 2022 IEEE.
KW  - Behavior sequence
KW  - Model Interpretation
KW  - Transformer
KW  - Deep learning
KW  - Quality control
KW  - Behavior sequences
KW  - Industrial practices
KW  - Model interpretations
KW  - Modeling behaviour
KW  - Page quality
KW  - Quality evaluation
KW  - Search engine results pages
KW  - Sequence data
KW  - Sequential patterns
KW  - Transformer
KW  - Search engines
A2  - Wani M.A.
A2  - Kantardzic M.
A2  - Palade V.
A2  - Neagu D.
A2  - Yang L.
A2  - Chan K.-Y.
PB  - Institute of Electrical and Electronics Engineers Inc.
SN  - 978-166546283-9 (ISBN)
LA  - English
J2  - Proc. - IEEE Int. Conf. Mach. Learn. Appl., ICMLA
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 0; Correspondence Address: X. Dong; Baidu Inc, Beijing, China; email: dongxiaoyu01@baidu.com; Conference name: 21st IEEE International Conference on Machine Learning and Applications, ICMLA 2022; Conference date: 12 December 2022 through 14 December 2022; Conference code: 187486
ER  -

TY  - CONF
AU  - Pan, R.
AU  - García-Díaz, J.A.
AU  - Valencia-García, R.
TI  - Evaluation of Transformer-Based Models for Punctuation and Capitalization Restoration in Spanish and Portuguese
PY  - 2023
T2  - Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)
VL  - 13913 LNCS
SP  - 243
EP  - 256
DO  - 10.1007/978-3-031-35320-8_17
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85164681079&doi=10.1007%2f978-3-031-35320-8_17&partnerID=40&md5=7c94570cd5ffbe266c1c771080f5cfe5
AD  - Departamento de Informática y Sistemas, Facultad de Informática, Universidad de Murcia, Espinardo, Murcia, 30100, Spain
AB  - Punctuation restoration plays a key role as a post-processing task in various text generation methods, such as Automatic Speech Recognition (ASR), and Machine Translation (MT). Despite its importance, the results of ASR systems and other generation models used in these tasks often produce texts that lack punctuation, which is difficult for human readers and might limit the performance of many downstream text processing tasks for web analytics, such as sentiment analysis, sarcasm detection or hate-speech identification including stereotypes, sexism, and misogyny. Thus, there are many techniques for restoring text punctuation, but most solutions like Condition Random Field (CRF) and pre-trained models such as the BERT, have been widely applied. In addition, they focus only on English and on restoring punctuation, without considering the restoration of capitalization. Recently, there has been a growing interest in an alternative method of addressing the problem of punctuation restoration, which is to transform it into a sequence labeling task. In this sense, we propose a capitalization and punctuation restoration system based on Transformers models and a sequence labeling approach for Spanish and Portuguese. Both models obtained good results: a macro-averaged F1-score of 59.90% and overall performance of 93.87% for Spanish and macro-averaged F1-score of 76.94% and 93.66% overall performance for Portuguese. In addition, they are also able to restore capitalization, identifying proper names, names of countries and organizations. © 2023, The Author(s), under exclusive license to Springer Nature Switzerland AG.
KW  - Capitalization restoration
KW  - Natural Language Processing
KW  - Portuguese
KW  - Punctuation restoration
KW  - Spanish
KW  - Computational linguistics
KW  - Random processes
KW  - Semantics
KW  - Sentiment analysis
KW  - Speech recognition
KW  - Capitalization restoration
KW  - F1 scores
KW  - Language processing
KW  - Natural language processing
KW  - Natural languages
KW  - Performance
KW  - Portuguese
KW  - Punctuation restoration
KW  - Sequence Labeling
KW  - Spanish
KW  - Restoration
A2  - Métais E.
A2  - Meziane F.
A2  - Manning W.
A2  - Reiff-Marganiec S.
A2  - Sugumaran V.
PB  - Springer Science and Business Media Deutschland GmbH
SN  - 03029743 (ISSN); 978-303135319-2 (ISBN)
LA  - English
J2  - Lect. Notes Comput. Sci.
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 0; Correspondence Address: J.A. García-Díaz; Departamento de Informática y Sistemas, Facultad de Informática, Universidad de Murcia, Murcia, Espinardo, 30100, Spain; email: joseantonio.garcia8@um.es; Conference name: 28th International Conference on Applications of Natural Language to Information Systems, NLDB 2023; Conference date: 21 June 2023 through 23 June 2023; Conference code: 296599
ER  -

TY  - JOUR
AU  - Gamallo, P.
AU  - Garcia, M.
AU  - de-Dios-Flores, I.
TI  - Evaluating Contextualized Vectors from both Large Language Models and Compositional Strategies
ST  - Evaluando vectores contextualizados generados a partir de grandes modelos de lenguaje y de estrategias composicionales
PY  - 2022
T2  - Procesamiento del Lenguaje Natural
VL  - 69
SP  - 153
EP  - 164
DO  - 10.26342/2022-69-13
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85139830596&doi=10.26342%2f2022-69-13&partnerID=40&md5=67e27900a316c0c57a5a75c95973fa1b
AD  - Centro de Investigación en Tecnoloxías Intelixentes (CITIUS), Universidade de Santiago de Compostela, Galiza, Spain
AB  - In this article, we compare contextualized vectors derived from large language models with those generated by means of dependency-based compositional techniques. For this purpose, we make use of a word-in-context similarity task. As all experiments are conducted for the Galician language, we created a new Galician evaluation dataset for this specific semantic task. The results show that compositional vectors derived from syntactic approaches based on selectional preferences are competitive with the contextual embeddings derived from neural-based large language models. © 2022 Sociedad Española para el Procesamiento del Lenguaje Natural.
KW  - Comositionality
KW  - Contextualized Vectors
KW  - Large Language Models
KW  - Selection Preferences
KW  - Semantic Similarity
KW  - Syntactic Dependencies
PB  - Sociedad Espanola para el Procesamiento del Lenguaje Natural
SN  - 11355948 (ISSN)
LA  - English
J2  - Proces. Lenguaje Nat.
M3  - Article
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 2
ER  -

TY  - CONF
AU  - Shrestha, R.
TI  - A transformer-based deep learning model for evaluation of accessibility of image descriptions
PY  - 2022
T2  - ACM International Conference Proceeding Series
SP  - 28
EP  - 33
DO  - 10.1145/3529836.3529856
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85133475762&doi=10.1145%2f3529836.3529856&partnerID=40&md5=c62a808be7317ed60538ef2cb6a8c4e7
AD  - Department of Computer Science, Oslo Metropolitan University (OsloMet), Norway
AB  - Images have become an integral part of digital and online media and they are used for creative expression and dissemination of knowledge. To address image accessibility challenges to the visually impaired community, adequate textual image descriptions or captions are provided, which can be read through screen readers. These descriptions could be either human-authored or software-generated. It is found that most of the image descriptions provided tend to be generic, inadequate, and often unreliable making them inaccessible. There are tools, methods, and metrics used to evaluate the quality of the generated text, but almost all of them are word-similarity-based and generic. There are standard guidelines such as NCAM image accessibility guidelines to help write accessible image descriptions. However, web content developers and authors do not seem to use them much, possibly due to the lack of knowledge, undermining the importance of accessibility coupled with complexity and difficulty understanding the guidelines. To our knowledge, none of the quality evaluation techniques take into account accessibility aspects. To address this, a deep learning model based on the transformer, a most recent and most effective architecture used in natural language processing, which measures compliance of the given image description to ten NCAM guidelines, is proposed. The experimental results confirm the effectiveness of the proposed model. This work could contribute to the growing research towards accessible images not only on the web but also on all digital devices.  © 2022 ACM.
KW  - Deep learning
KW  - Evaluation
KW  - Image accessibility
KW  - Image description
KW  - NCAM guidelines
KW  - Neural networks
KW  - Transformer
KW  - Deep learning
KW  - Image analysis
KW  - Learning systems
KW  - Natural language processing systems
KW  - Quality control
KW  - Deep learning
KW  - Evaluation
KW  - Image accessibility
KW  - Image descriptions
KW  - Integral part
KW  - Learning models
KW  - NCAM guideline
KW  - Neural-networks
KW  - Online medium
KW  - Transformer
KW  - Digital devices
PB  - Association for Computing Machinery
SN  - 978-145039570-0 (ISBN)
LA  - English
J2  - ACM Int. Conf. Proc. Ser.
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 0; Correspondence Address: R. Shrestha; Department of Computer Science, Oslo Metropolitan University (OsloMet), Norway; email: raju.shrestha@oslomet.no; Conference name: 14th International Conference on Machine Learning and Computing, ICMLC 2022; Conference date: 18 February 2022 through 21 February 2022; Conference code: 180295
ER  -

TY  - CONF
AU  - Wolfe, R.
AU  - Caliskan, A.
TI  - VAST: The Valence-Assessing Semantics Test for Contextualizing Language Models
PY  - 2022
T2  - Proceedings of the 36th AAAI Conference on Artificial Intelligence, AAAI 2022
VL  - 36
SP  - 11477
EP  - 11485
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85133025019&partnerID=40&md5=f3530cce47775f55b95c6f94a210c204
AD  - University of Washington, United States
AB  - We introduce VAST, the Valence-Assessing Semantics Test, a novel intrinsic evaluation task for contextualized word embeddings (CWEs). Despite the widespread use of contextualizing language models (LMs), researchers have no intrinsic evaluation task for understanding the semantic quality of CWEs and their unique properties as related to contextualization, the change in the vector representation of a word based on surrounding words; tokenization, the breaking of uncommon words into subcomponents; and LM-specific geometry learned during training. VAST uses valence, the association of a word with pleasantness, to measure the correspondence of word-level LM semantics with widely used human judgments, and examines the effects of contextualization, tokenization, and LM-specific geometry. Because prior research has found that CWEs from OpenAI's 2019 English-language causal LM GPT-2 perform poorly on other intrinsic evaluations, we select GPT-2 as our primary subject, and include results showing that VAST is useful for 7 other LMs, and can be used in 7 languages. GPT-2 results show that the semantics of a word incorporate the semantics of context in layers closer to model output, such that VAST scores diverge between our contextual settings, ranging from Pearson's ρ of .55 to .77 in layer 11. We also show that multiply tokenized words are not semantically encoded until layer 8, where they achieve Pearson's ρ of .46, indicating the presence of an encoding process for multiply tokenized words which differs from that of singly tokenized words, for which ρ is highest in layer 0. We find that a few neurons with values having greater magnitude than the rest mask word-level semantics in GPT-2's top layer, but that word-level semantics can be recovered by nullifying non-semantic principal components: Pearson's ρ in the top layer improves from .32 to .76. Downstream POS tagging and sentence classification experiments indicate that the GPT-2 uses these principal components for non-semantic purposes, such as to represent sentence-level syntax relevant to next-word prediction. After isolating semantics, we show the utility of VAST for understanding LM semantics via improvements over related work on four word similarity tasks, with a score of .50 on SimLex-999, better than the previous best of .45 for GPT-2. Finally, we show that 8 of 10 WEAT bias tests, which compare differences in word embedding associations between groups of words, exhibit more stereotype-congruent biases after isolating semantics, indicating that non-semantic structures in LMs also mask social biases. Copyright © 2022, Association for the Advancement of Artificial Intelligence (www.aaai.org). All rights reserved.
KW  - Artificial intelligence
KW  - Computational linguistics
KW  - Embeddings
KW  - Forecasting
KW  - Quality control
KW  - Contextualization
KW  - Embeddings
KW  - Language model
KW  - Model semantics
KW  - Principal Components
KW  - Property
KW  - Semantic qualities
KW  - Tokenization
KW  - Top layers
KW  - Word level
KW  - Semantics
PB  - Association for the Advancement of Artificial Intelligence
SN  - 1577358767 (ISBN); 978-157735876-3 (ISBN)
LA  - English
J2  - Proc. AAAI Conf. Artif. Intell., AAAI
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 7; Conference name: 36th AAAI Conference on Artificial Intelligence, AAAI 2022; Conference date: 22 February 2022 through 1 March 2022; Conference code: 185285
ER  -

TY  - JOUR
AU  - Walker, H.L.
AU  - Ghani, S.
AU  - Kuemmerli, C.
AU  - Nebiker, C.A.
AU  - Müller, B.P.
AU  - Raptis, D.A.
AU  - Staubli, S.M.
TI  - Reliability of Medical Information Provided by ChatGPT: Assessment Against Clinical Guidelines and Patient Information Quality Instrument
PY  - 2023
T2  - Journal of Medical Internet Research
VL  - 25
C7  - e47479
DO  - 10.2196/47479
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85164229850&doi=10.2196%2f47479&partnerID=40&md5=fa6e66c642c2e473436b2c99858ae7da
AD  - Royal Free London NHS Foundation Trust, London, United Kingdom
AD  - Clarunis – University Center for Gastrointestinal and Liver Diseases, Basel, Switzerland
AD  - Departement Chirurgie, Kantonsspital Aarau, Aarau, Switzerland
AD  - Organ Transplant Center of Excellence, King Faisal Specialist Hospital & Research Centre, Riyadh, Saudi Arabia
AB  - Background: ChatGPT-4 is the latest release of a novel artificial intelligence (AI) chatbot able to answer freely formulated and complex questions. In the near future, ChatGPT could become the new standard for health care professionals and patients to access medical information. However, little is known about the quality of medical information provided by the AI. Objective: We aimed to assess the reliability of medical information provided by ChatGPT. Methods: Medical information provided by ChatGPT-4 on the 5 hepato-pancreatico-biliary (HPB) conditions with the highest global disease burden was measured with the Ensuring Quality Information for Patients (EQIP) tool. The EQIP tool is used to measure the quality of internet-available information and consists of 36 items that are divided into 3 subsections. In addition, 5 guideline recommendations per analyzed condition were rephrased as questions and input to ChatGPT, and agreement between the guidelines and the AI answer was measured by 2 authors independently. All queries were repeated 3 times to measure the internal consistency of ChatGPT. Results: Five conditions were identified (gallstone disease, pancreatitis, liver cirrhosis, pancreatic cancer, and hepatocellular carcinoma). The median EQIP score across all conditions was 16 (IQR 14.5-18) for the total of 36 items. Divided by subsection, median scores for content, identification, and structure data were 10 (IQR 9.5-12.5), 1 (IQR 1-1), and 4 (IQR 4-5), respectively. Agreement between guideline recommendations and answers provided by ChatGPT was 60% (15/25). Interrater agreement as measured by the Fleiss κ was 0.78 (P<.001), indicating substantial agreement. Internal consistency of the answers provided by ChatGPT was 100%. Conclusions: ChatGPT provides medical information of comparable quality to available static internet information. Although currently of limited quality, large language models could become the future standard for patients and health care professionals to gather medical information. © 2023 Journal of Medical Internet Research. All rights reserved.
KW  - artificial intelligence
KW  - bile
KW  - biliary
KW  - chatbot
KW  - chatbots
KW  - ChatGPT
KW  - conversational agent
KW  - conversational agents
KW  - EQIP tool
KW  - gall
KW  - gallstone
KW  - hepatic
KW  - internal medicine
KW  - internet information
KW  - liver
KW  - medical information
KW  - pancreas
KW  - pancreatic
KW  - pancreatitis
KW  - patient information
KW  - Artificial Intelligence
KW  - Health Personnel
KW  - Humans
KW  - Internet
KW  - Language
KW  - Reproducibility of Results
KW  - Article
KW  - artificial intelligence
KW  - cholelithiasis
KW  - Ensuring Quality Information for Patient
KW  - global disease burden
KW  - human
KW  - internal consistency
KW  - interrater reliability
KW  - liver cell carcinoma
KW  - liver cirrhosis
KW  - medical information
KW  - pancreas cancer
KW  - pancreatitis
KW  - practice guideline
KW  - quality assessment tool
KW  - reliability
KW  - artificial intelligence
KW  - health care personnel
KW  - Internet
KW  - language
KW  - reproducibility
PB  - JMIR Publications Inc.
SN  - 14388871 (ISSN)
C2  - 37389908
LA  - English
J2  - J. Med. Internet Res.
M3  - Article
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 16; Correspondence Address: S.M. Staubli; Royal Free London NHS Foundation Trust, London, Pond Street, NW3 2QG, United Kingdom; email: s.staubli@nhs.net
ER  -

TY  - CONF
AU  - Kaneko, M.
AU  - Bollegala, D.
TI  - Unmasking the Mask - Evaluating Social Biases in Masked Language Models
PY  - 2022
T2  - Proceedings of the 36th AAAI Conference on Artificial Intelligence, AAAI 2022
VL  - 36
SP  - 11954
EP  - 11962
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85137071027&partnerID=40&md5=90a78e8ced9256cac40a8bb6a2eb6399
AD  - Tokyo Institute of Technology, Japan
AD  - University of Liverpool, United Kingdom
AD  - Amazon
AB  - Masked Language Models (MLMs) have shown superior performances in numerous downstream Natural Language Processing (NLP) tasks. Unfortunately, MLMs also demonstrate significantly worrying levels of social biases. We show that the previously proposed evaluation metrics for quantifying the social biases in MLMs are problematic due to the following reasons: (1) prediction accuracy of the masked tokens itself tend to be low in some MLMs, which leads to unreliable evaluation metrics, and (2) in most downstream NLP tasks, masks are not used; therefore prediction of the mask is not directly related to them, and (3) high-frequency words in the training data are masked more often, introducing noise due to this selection bias in the test cases. Therefore, we propose All Unmasked Likelihood (AUL), a bias evaluation measure that predicts all tokens in a test case given the MLM embedding of the unmasked input and AUL with Attention weights (AULA) to evaluate tokens based on their importance in a sentence. Our experimental results show that the proposed bias evaluation measures accurately detect different types of biases in MLMs, and unlike AUL and AULA, previously proposed measures for MLMs systematically overestimate the measured biases and are heavily influenced by the unmasked tokens in the context. Copyright © 2022, Association for the Advancement of Artificial Intelligence (www.aaai.org). All rights reserved.
KW  - Artificial intelligence
KW  - Natural language processing systems
KW  - Down-stream
KW  - Evaluation measures
KW  - Evaluation metrics
KW  - High-frequency words
KW  - Language model
KW  - Language processing
KW  - Natural languages
KW  - Performance
KW  - Prediction accuracy
KW  - Test case
KW  - Computational linguistics
PB  - Association for the Advancement of Artificial Intelligence
SN  - 1577358767 (ISBN); 978-157735876-3 (ISBN)
LA  - English
J2  - Proc. AAAI Conf. Artif. Intell., AAAI
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 10; Conference name: 36th AAAI Conference on Artificial Intelligence, AAAI 2022; Conference date: 22 February 2022 through 1 March 2022; Conference code: 185285
ER  -

TY  - JOUR
AU  - Alnaqbi, N.M.
AU  - Fouda, W.
TI  - Exploring the Role of ChatGPT and social media in Enhancing Student Evaluation of Teaching Styles in Higher Education Using Neutrosophic Sets
PY  - 2023
T2  - International Journal of Neutrosophic Science
VL  - 20
IS  - 4
SP  - 181
EP  - 190
DO  - 10.54216/IJNS.200414
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85158040339&doi=10.54216%2fIJNS.200414&partnerID=40&md5=0e27a45e9b4f63f41d77cf5c9a12d04c
AD  - Mohamed bin Zayed University for Humanities, United Arab Emirates
AD  - American University in the Emirates, United Arab Emirates
AB  - This paper provides an in-depth analysis of how Chat GPT and social media can be used as tools for capturing real-time student feedback on teaching styles in higher education. The study employs neutrosophic sets to deal with the uncertainties and ambiguities that arise in student evaluation data. Traditional methods of evaluating teaching styles in higher education, such as paper-based surveys, may not fully capture the nuanced experiences of students in the classroom. Recent advancements in chatbots, such as ChatGPT, and the growing use of social media platforms offer new opportunities for more efficient and effective methods of evaluating teaching styles. However, there are significant challenges in using these technologies, including the handling of indeterminate and uncertain data. Neutrosophic sets provide a mathematical framework for handling ambiguity and uncertainty in data and can be used to better capture the complex and multifaceted aspects of student experiences in the classroom. Additionally, the use of chatbots and social media platforms raises practical and ethical concerns that must be addressed in the evaluation process. This study aims to explore the role of ChatGPT and social media in enhancing student evaluation of teaching styles in higher education using neutrosophic sets, while also addressing the practical and ethical challenges that arise from their use. © 2023, American Scientific Publishing Group (ASPG). All rights reserved.
KW  - AHP
KW  - Chat GPT
KW  - Education
KW  - Neutrosophic Sets
KW  - Uncertainty
PB  - American Scientific Publishing Group (ASPG)
SN  - 26926148 (ISSN)
LA  - English
J2  - Int. J. Neutrosophic. Sci.
M3  - Article
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 5; Correspondence Address: N.M. Alnaqbi; Mohamed bin Zayed University for Humanities, United Arab Emirates; email: Najla.alnaqbi@mbzuh.ac.ae
ER  -

TY  - CONF
AU  - Ge, H.
AU  - Zhao, X.
AU  - Liu, C.
AU  - Zeng, Y.
AU  - Liu, Q.
AU  - Xiong, D.
TI  - TGEA 2.0: A Large-Scale Diagnostically Annotated Dataset with Benchmark Tasks for Text Generation of Pretrained Language Models
PY  - 2022
T2  - Advances in Neural Information Processing Systems
VL  - 35
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85163146095&partnerID=40&md5=5ebb80a7717fc63f8616a3994e2d6e40
AD  - College of Intelligence and Computing, Tianjin University, Tianjin, China
AD  - Huawei Noah's Ark Lab, Hong Kong
AB  - In order to diagnostically analyze and improve the capability of pretrained language models (PLMs) in text generation, we propose TGEA 2.0, to date the largest dataset built on machine-authored texts by PLMs with fine-grained semantic annotations on a wide variety of pathological generation errors. We collect 170K nominal, phrasal and sentential prompts from 6M natural sentences in 3 domains. These prompts are fed into 4 generative PLMs with their best decoding strategy to generate paragraphs. 195,629 sentences are extracted from these generated paragraphs for manual annotation, where 36K erroneous sentences are detected, 42K erroneous spans are located and categorized into an error type defined in a two-level error taxonomy. We define a Minimal Set of Error-related Words (MiSEW) for each erroneous span, which not only provides error-associated words but also rationalizes the reasoning behind the error. Quality control with a pre-annotation and feedback loop is performed before and during the entire annotation process. With the diagnostically annotated dataset, we propose 5 diagnosis benchmark tasks (i.e., erroneous text detection, MiSEW extraction, erroneous span location and correction together with error type classification) and 2 pathology mitigation benchmark tasks (pairwise comparison and word prediction). Experiment results on these benchmark tasks demonstrate that TGEA 2.0 is a challenging dataset that could facilitate further research on automatic diagnosis and pathology mitigation over machine texts. The dataset is publicly available at https://github.com/tjunlp-lab/TGEA/. © 2022 Neural information processing systems foundation. All rights reserved.
KW  - Classification (of information)
KW  - Computational linguistics
KW  - Computer aided diagnosis
KW  - Large dataset
KW  - Pathology
KW  - Semantics
KW  - Text processing
KW  - Annotated datasets
KW  - Decoding strategy
KW  - Fine grained
KW  - Language model
KW  - Large datasets
KW  - Large-scales
KW  - On-machines
KW  - Related word
KW  - Semantic annotations
KW  - Text generations
KW  - Errors
A2  - Koyejo S.
A2  - Mohamed S.
A2  - Agarwal A.
A2  - Belgrave D.
A2  - Cho K.
A2  - Oh A.
PB  - Neural information processing systems foundation
SN  - 10495258 (ISSN); 978-171387108-8 (ISBN)
LA  - English
J2  - Adv. neural inf. proces. syst.
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 0; Correspondence Address: D. Xiong; College of Intelligence and Computing, Tianjin University, Tianjin, China; email: dyxiong@tju.edu.cn; Conference name: 36th Conference on Neural Information Processing Systems, NeurIPS 2022; Conference date: 28 November 2022 through 9 December 2022; Conference code: 189185
ER  -

TY  - CONF
AU  - Verma, K.
AU  - Milosevic, T.
AU  - Cortis, K.
AU  - Davis, B.
TI  - Benchmarking Language Models for Cyberbullying Identification and Classification from Social-media texts
PY  - 2022
T2  - Proceedings of the Language Resources and Evaluation Conference, LREC 2022 Workshop on Language Technology and Resources for a Fair, Inclusive, and Safe Society, LATERAISSE 2022
SP  - 26
EP  - 31
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85145873802&partnerID=40&md5=b1f088dee2533cdecf9e55b4d4269a50
AD  - ADAPT SFI Research Centre, Dublin City University, Dublin, Ireland
AD  - DCU Anti Bullying Centre, Dublin, Ireland
AB  - Cyberbullying is bullying perpetrated via the medium of modern communication technologies like social media networks and gaming platforms. Unfortunately, most existing datasets focusing on cyberbullying detection or classification are i) limited in number ii) usually targeted to one specific online social networking (OSN) platform, or iii) often contain low-quality annotations. In this study, we fine-tune and benchmark state of the art neural transformers for the binary classification of cyberbullying in social media texts, which is of high value to Natural Language Processing (NLP) researchers and computational social scientists. Furthermore, this work represents the first step toward building neural language models for cross OSN platform cyberbullying classification to make them as OSN platform agnostic as possible. © European Language Resources Association (ELRA).
KW  - Benchmarking
KW  - Classification
KW  - Cross-platform
KW  - Cyberbullying
KW  - Transformers
KW  - Classification (of information)
KW  - Computational linguistics
KW  - Computer crime
KW  - Natural language processing systems
KW  - Social networking (online)
KW  - Cross-platform
KW  - Cyber bullying
KW  - Language model
KW  - Low qualities
KW  - Modern Communication Technologies
KW  - Online social networkings
KW  - Social media
KW  - Social media networks
KW  - State of the art
KW  - Transformer
KW  - Benchmarking
A2  - Adebayo K.
A2  - Nanda R.
A2  - Verma K.
A2  - Davis B.
PB  - European Language Resources Association (ELRA)
SN  - 978-249381409-8 (ISBN)
LA  - English
J2  - Proc. Lang. Resour. Eval. Conf., LREC Workshop Lang. Technol. Resour. Fair, Incl., Safe Soc., LATERAISSE
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 6; Conference name: 1st Workshop on Language Technology and Resources for a Fair, Inclusive, and Safe Society, LATERAISSE 2022; Conference code: 184372
ER  -

TY  - CONF
AU  - Zhu, F.
AU  - Laosen, N.
AU  - Laosen, K.
AU  - Paripremkul, K.
AU  - Nanthaamornphong, A.
AU  - Ng, S.-K.
AU  - Bressan, S.
TI  - A Comparative Empirical Evaluation of Neural Language Models for Thai Question-Answering
PY  - 2022
T2  - ITC-CSCC 2022 - 37th International Technical Conference on Circuits/Systems, Computers and Communications
SP  - 120
EP  - 123
DO  - 10.1109/ITC-CSCC55581.2022.9894948
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85140652517&doi=10.1109%2fITC-CSCC55581.2022.9894948&partnerID=40&md5=f8d427c57440ddb1d710b2c5891aab8c
AD  - Institute of Data Science National University of Singapore, Singapore
AD  - Phuket Rajabhat University, Faculty of Science and Technology, Thailand
AD  - College of Computing Prince of Songkla University, Phuket Campus, Thailand
AD  - College of Computing Prince of Songkla University, Thailand
AD  - School of Computing National University of Singapore, Singapore
AB  - Despite engineers and researchers' significant and continuing efforts in developing natural language processing tools for the Thai language, the Thai language is, alongside many others, a de facto low-resource language. Can unsupervisedly trained neural language models come to the rescue? The remarkable success of transformer-based language models in most natural language processing tasks promises the advent of a much needed polyglot panacea. It seems, unfortunately, that powerful enough models are not yet available for most other-than-English languages. To assess the situation, we propose to empirically and comparatively evaluate the performance of existing neural language models for the task of extractive question-answering for the Thai language.  © 2022 IEEE.
KW  - Question-Answering
KW  - Thai NLP
KW  - Transformer
KW  - Computational linguistics
KW  - Empirical evaluations
KW  - Language model
KW  - Language processing
KW  - Low resource languages
KW  - Natural Language Processing Tools
KW  - Natural languages
KW  - Question Answering
KW  - Thai language
KW  - Thai NLP
KW  - Transformer
KW  - Natural language processing systems
PB  - Institute of Electrical and Electronics Engineers Inc.
SN  - 978-166548559-3 (ISBN)
LA  - English
J2  - ITC-CSCC - Int. Tech. Conf. Circuits/Syst., Comput. Commun.
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 1; Conference name: 37th International Technical Conference on Circuits/Systems, Computers and Communications, ITC-CSCC 2022; Conference date: 5 July 2022 through 8 July 2022; Conference code: 183374
ER  -

TY  - CONF
AU  - Weigang, L.
AU  - Rocha, C.A.A.
AU  - Li, D.L.
AU  - Dib, M.V.P.
TI  - Evaluation of Typing Efficiency Using Language Model for the Chinese Typewriter
PY  - 2022
T2  - Proceedings - 2022 4th International Conference on Natural Language Processing, ICNLP 2022
SP  - 331
EP  - 335
DO  - 10.1109/ICNLP55136.2022.00060
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85139386974&doi=10.1109%2fICNLP55136.2022.00060&partnerID=40&md5=cfc02637b368eafd43905027e1721d36
AD  - University of Brasilia, Dept. of Computer Science, Brasilia, Brazil
AD  - University of Brasilia, Dept. of Mechanical Engineering, Brasilia, Brazil
AD  - University of Sao Paulo, Fea, Sao Paulo, Brazil
AB  - The predictive text with 'Radiating style' refers to the personalized distribution of Chinese characters in the tray bed of the Chinese typewriter. With this arrangement, the typing speed reached 60- 80 words per minute (WPM). In the field of natural language processing (NLP), there is little research on this topic. To fill this gap in the literature, we identified some 'Radiating style' patterns from the predicted text, and proposed a language model to evaluate the input efficiency of three different versions of the tray beds: Traditional Chinese tray bed (TCTB), Simplified Chinese tray bed (SCTB), and personalized setting panel. The research demonstrates that the tray bed setting and query of the Chinese typewriter inherit some Chinese language properties, and should be considered as one important step of Chinese natural language processing (CNLP). It is also valuable as a reference to improve the inputting panel of the future for the smart Chinese Language Information Processing Systems (CLIPS).  © 2022 IEEE.
KW  - Chinese typewriter
KW  - language model
KW  - predictive text
KW  - radiating style
KW  - Computational linguistics
KW  - Efficiency
KW  - Natural language processing systems
KW  - Chinese characters
KW  - Chinese language
KW  - Chinese typewriter
KW  - Input efficiencies
KW  - Language model
KW  - Language processing
KW  - Natural languages
KW  - Predictive text
KW  - Radiating style
KW  - Typing speed
KW  - Typewriters
PB  - Institute of Electrical and Electronics Engineers Inc.
SN  - 978-166549544-8 (ISBN)
LA  - English
J2  - Proc. - Int. Conf. Nat. Lang. Process., ICNLP
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 0; Conference name: 4th International Conference on Natural Language Processing, ICNLP 2022; Conference date: 25 March 2022 through 27 March 2022; Conference code: 182901
ER  -

TY  - CONF
AU  - Ibañez, M.
AU  - Reyes, L.L.A.
AU  - Sapinit, R.
AU  - Hussien, M.A.
AU  - Imperial, J.M.
TI  - On Applicability of Neural Language Models for Readability Assessment in Filipino
PY  - 2022
T2  - Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)
VL  - 13356 LNCS
SP  - 573
EP  - 576
DO  - 10.1007/978-3-031-11647-6_118
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85135895276&doi=10.1007%2f978-3-031-11647-6_118&partnerID=40&md5=350e7898aa688cc930f23f2fef1a43e1
AD  - National University, Manila, Philippines
AB  - In the field of automatic readability assessment (ARA), the current trend in the research community focuses on the use of large neural language models such as BERT as evidenced from its high performance in other downstream NLP tasks. In this study, we dissect the BERT model and applied it to readability assessment in a low-resource setting using a dataset in the Filipino language. Results show that extracting embeddings separately from various layers of BERT obtain relatively similar performance with models trained using a diverse set of handcrafted features and substantially better than using conventional transfer learning approach. © 2022, Springer Nature Switzerland AG.
KW  - BERT
KW  - Neural language models
KW  - Readability assessment
KW  - 'current
KW  - BERT
KW  - Down-stream
KW  - Embeddings
KW  - Language model
KW  - Low-resource settings
KW  - Neural language model
KW  - Performance
KW  - Readability assessment
KW  - Research communities
KW  - Computational linguistics
A2  - Rodrigo M.M.
A2  - Matsuda N.
A2  - Cristea A.I.
A2  - Dimitrova V.
PB  - Springer Science and Business Media Deutschland GmbH
SN  - 03029743 (ISSN); 978-303111646-9 (ISBN)
LA  - English
J2  - Lect. Notes Comput. Sci.
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 3; Correspondence Address: J.M. Imperial; National University, Manila, Philippines; email: jrimperial@national-u.edu.ph; Conference name: 23rd International Conference on Artificial Intelligence in Education, AIED 2022; Conference date: 27 July 2022 through 31 July 2022; Conference code: 281319
ER  -

TY  - CONF
AU  - Markchom, T.
AU  - Liang, H.
AU  - Chen, J.
TI  - UoR-NCL at SemEval-2022 Task 3: Fine-Tuning the BERT-Based Models for Validating Taxonomic Relations
PY  - 2022
T2  - SemEval 2022 - 16th International Workshop on Semantic Evaluation, Proceedings of the Workshop
SP  - 260
EP  - 265
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85137543951&partnerID=40&md5=7b2a5d6c0e1725986bdb4186f900bccd
AD  - University of Reading, United Kingdom
AD  - Newcastle University, United Kingdom
AD  - University of Oxford, United Kingdom
AB  - In human languages, there are many presuppositional constructions that impose a constrain on the taxonomic relations between two nouns depending on their order. These constructions create a challenge in validating taxonomic relations in real-world contexts. In SemEval2022-Task3 Presupposed Taxonomies: Evaluating Neural Network Semantics (PreTENS), the organizers introduced a task regarding validating the taxonomic relations within a variety of presuppositional constructions. This task is divided into two subtasks: classification and regression. Each subtask contains three datasets in multiple languages, i.e., English, Italian and French. To tackle this task, this work proposes to fine-tune different BERT-based models pre-trained on different languages. According to the experimental results, the fine-tuned BERT-based models are effective compared to the baselines for classification. For regression, the fine-tuned models show promising performances with the possibility of improvement. © 2022 Association for Computational Linguistics.
KW  - Classification (of information)
KW  - Fine tuning
KW  - Human language
KW  - Multiple languages
KW  - Neural-networks
KW  - Performance
KW  - Real-world
KW  - Subtask
KW  - Semantics
A2  - Emerson G.
A2  - Schluter N.
A2  - Stanovsky G.
A2  - Kumar R.
A2  - Palmer A.
A2  - Schneider N.
A2  - Singh S.
A2  - Ratan S.
PB  - Association for Computational Linguistics (ACL)
SN  - 978-195591780-3 (ISBN)
LA  - English
J2  - SemEval - Int. Workshop Semant. Eval., Proc. Workshop
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 1; Conference name: 16th International Workshop on Semantic Evaluation, SemEval 2022; Conference date: 14 July 2022 through 15 July 2022; Conference code: 181952
ER  -

TY  - CONF
AU  - Hammoudeh, A.
AU  - Vanderplaetse, B.
AU  - Dupont, S.
TI  - Soccer captioning: Dataset, transformer-based model, and triple-level evaluation
PY  - 2022
T2  - Procedia Computer Science
VL  - 210
IS  - C
SP  - 104
EP  - 111
DO  - 10.1016/j.procs.2022.10.125
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85144823052&doi=10.1016%2fj.procs.2022.10.125&partnerID=40&md5=d14305f435b2c390f10c09ca25038433
AD  - ISIA Lab, University of Mons, Belgium
AD  - MAIA Lab, University of Mons, Belgium
AD  - MARO Lab, University of Mons, Belgium
AB  - This work aims at generating captions for soccer videos using deep learning. The paper introduces a novel dataset, model, and triple-level evaluation. The dataset consists of 22k caption-clip pairs and three visual features (images, optical flow, inpainting) for 500 hours of SoccerNet videos. The model is divided into three parts: a transformer learns language, ConvNets learn vision, and a fusion of linguistic and visual features generates captions. The suggested evaluation criterion of captioning models covers three levels: syntax (the commonly used evaluation metrics such as BLEU-score and CIDEr), semantics (the quality of descriptions for a domain expert), and corpus (the diversity of generated captions). The paper shows that the diversity of generated captions has improved (from 0.07 reaching 0.18) with semantics-related losses that prioritize selected words. Semantics-related losses and the utilization of more visual features (optical flow, inpainting) improved the normalized captioning score by 27%. © 2022 Elsevier B.V.. All rights reserved.
KW  - deep learning
KW  - multimodality
KW  - soccer
KW  - transformer
KW  - video captioning
KW  - Deep learning
KW  - Optical flows
KW  - Quality control
KW  - Sports
KW  - Visual languages
KW  - Convnet
KW  - Deep learning
KW  - Feature images
KW  - Inpainting
KW  - Learn+
KW  - Multi-modality
KW  - Soccer video
KW  - Transformer
KW  - Video captioning
KW  - Visual feature
KW  - Semantics
A2  - Shakshuki E.
PB  - Elsevier B.V.
SN  - 18770509 (ISSN)
LA  - English
J2  - Procedia Comput. Sci.
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 1; Correspondence Address: A. Hammoudeh; ISIA Lab, University of Mons, Belgium; email: at.hammoudeh@gmail.com; Conference name: 13th International Conference on Emerging Ubiquitous Systems and Pervasive Networks, EUSPN / The 12th International Conference on Current and Future Trends of Information and Communication Technologies in Healthcare, ICTH 2022 / Affiliated Workshops; Conference date: 26 October 2022 through 28 October 2022; Conference code: 148658
ER  -

TY  - CONF
AU  - Cong, Y.
TI  - Pre-trained Language Models’ Interpretation of Evaluativity Implicature: Evidence from Gradable Adjectives Usage in Context
PY  - 2022
T2  - UnImplicit 2022 - 2nd Workshop on Understanding Implicit and Underspecified Language, Proceedings of the Workshop
SP  - 1
EP  - 7
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85139129520&partnerID=40&md5=96398ce9f8dc869ee39a87aee1b84ef3
AB  - By saying Maria is tall, a human speaker typically implies that Maria is evaluatively tall from the speaker’s perspective. However, by using a different construction Maria is taller than Sophie, we cannot infer from Maria and Sophie’s relative heights that Maria is evaluatively tall because it is possible for Maria to be taller than Sophie in a context in which they both count as short. Can pre-trained language models (LMs) “understand” evaulativity (EVAL) inference? To what extent can they discern the EVAL salience of different constructions in a conversation? Will it help LMs’ implicitness performance if we give LMs a persona such as chill, social, and pragmatically skilled? Our study provides an approach to probing LMs’ interpretation of EVAL inference by incorporating insights from experimental pragmatics and sociolinguistics. We find that with the appropriate prompt, LMs can succeed in some pragmatic level language understanding tasks. Our study suggests that socio-pragmatics methodology can shed light on the challenging questions in NLP. © 2022 Association for Computational Linguistics.
KW  - Counts-as
KW  - Experimental pragmatics
KW  - In contexts
KW  - Language model
KW  - Language understanding
KW  - Model interpretations
KW  - Performance
KW  - Relative heights
KW  - Computational linguistics
A2  - Pyatkin V.
A2  - Fried D.
A2  - Anthonio T.
PB  - Association for Computational Linguistics (ACL)
SN  - 978-195591792-6 (ISBN)
LA  - English
J2  - UnImplicit - Workshop Underst. Implicit Underspecified Lang., Proc. Workshop
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 0; Correspondence Address: Y. Cong; email: yancong222@gmail.com; Conference name: 2nd Workshop on Understanding Implicit and Underspecified Language, UnImplicit 2022; Conference code: 182711
ER  -

TY  - CONF
AU  - Collins, K.M.
AU  - Wong, C.
AU  - Feng, J.
AU  - Wei, M.
AU  - Tenenbaum, J.B.
TI  - Structured, flexible, and robust: benchmarking and improving large language models towards more human-like behavior in out-of-distribution reasoning tasks
PY  - 2022
T2  - Proceedings of the 44th Annual Meeting of the Cognitive Science Society: Cognitive Diversity, CogSci 2022
SP  - 869
EP  - 875
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85146438821&partnerID=40&md5=4f41608e5589fa8c01893240d6120160
AD  - University of Cambridge, United Kingdom
AD  - MIT
AB  - Human language offers a powerful window into our thoughts - we tell stories, give explanations, and express our beliefs and goals through words. Abundant evidence also suggests that language plays a developmental role in structuring our learning. Here, we ask: how much of human-like thinking can be captured by learning statistical patterns in language alone? We first contribute a new challenge benchmark for comparing humans and distributional large language models (LLMs). Our benchmark contains two problem-solving domains (planning and explanation generation) and is designed to require generalization to new, out-of-distribution problems expressed in language. We find that humans are far more robust than LLMs on this benchmark. Next, we propose a hybrid Parse-and-Solve model, which augments distributional LLMs with a structured symbolic reasoning module. We find that this model shows more robust adaptation to out-of-distribution planning problems, demonstrating the promise of hybrid AI models for more human-like reasoning. © 2022 The Author(s). This work is licensed under a Creative Commons Attribution 4.0 International License (CC BY)
KW  - language
KW  - language of thought
KW  - neuro-symbolic models
KW  - problem-solving
KW  - programs
KW  - Computational linguistics
KW  - Problem solving
KW  - Creative Commons
KW  - Human like
KW  - Language
KW  - Language model
KW  - Language of thought
KW  - Neuro-symbolic model
KW  - Problem-solving
KW  - Program
KW  - Reasoning tasks
KW  - Symbolic modeling
KW  - Behavioral research
PB  - The Cognitive Science Society
LA  - English
J2  - Proc. Annu. Meet. Cogn. Sci. Soc.: Cogn. Diversity, CogSci
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 1; Conference name: 44th Annual Meeting of the Cognitive Science Society: Cognitive Diversity, CogSci 2022; Conference date: 27 July 2022 through 30 July 2022; Conference code: 185866
ER  -

TY  - JOUR
AU  - Loureiro, D.
AU  - Rezaee, K.
AU  - Pilehvar, M.T.
AU  - Camacho-Collados, J.
TI  - Analysis and evaluation of language models for word sense disambiguation
PY  - 2021
T2  - Computational Linguistics
VL  - 47
IS  - 2
SP  - 387
EP  - 443
DO  - 10.1162/COLI_a_00405
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85108204419&doi=10.1162%2fCOLI_a_00405&partnerID=40&md5=bd2dae00751c224f5acb92d10aa52ae3
AD  - LIAAD-INESC TEC, Department of Computer Science, FCUP University of Porto, Portugal
AD  - Department of Computer Engineering, Iran University of Science and Technology, Iran
AD  - Tehran Institute for Advanced Studies, Iran
AD  - School of Computer Science and Informatics, Cardiff University, United Kingdom
AB  - Transformer-based language models have taken many fields in NLP by storm. BERT and its derivatives dominate most of the existing evaluation benchmarks, including those for Word Sense Disambiguation (WSD), thanks to their ability in capturing context-sensitive semantic nuances. However, there is still little knowledge about their capabilities and potential limitations in encoding and recovering word senses. In this article, we provide an in-depth quantitative and qualitative analysis of the celebrated BERT model with respect to lexical ambiguity. One of the main conclusions of our analysis is that BERT can accurately capture high-level sense distinctions, even when a limited number of examples is available for each word sense. Our analysis also reveals that in some cases language models come close to solving coarse-grained noun disambiguation under ideal conditions in terms of availability of training data and computing resources. However, this scenario rarely occurs in real-world settings and, hence, many practical challenges remain even in the coarse-grained setting. We also perform an in-depth comparison of the two main language model-based WSD strategies, namely, fine-tuning and feature extraction, finding that the latter approach is more robust with respect to sense bias and it can better exploit limited available training data. In fact, the simple feature extraction strategy of averaging contextualized embeddings proves robust even using only three training sentences per word sense, with minimal improvements obtained by increasing the size of this training data. © 2021 Association for Computational Linguistics.
KW  - Computational linguistics
KW  - Data mining
KW  - Extraction
KW  - Feature extraction
KW  - Semantics
KW  - Analysis and evaluation
KW  - Coarse-grained
KW  - Computing resource
KW  - Context sensitive
KW  - Lexical ambiguity
KW  - Quantitative and qualitative analysis
KW  - Real world setting
KW  - Word Sense Disambiguation
KW  - Natural language processing systems
PB  - MIT Press Journals
SN  - 08912017 (ISSN)
LA  - English
J2  - Comput. Linguist.
M3  - Article
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 29
ER  -

TY  - CONF
AU  - Patricoski, J.
AU  - Kreimeyer, K.
AU  - Balan, A.
AU  - Hardart, K.
AU  - Tao, J.
AU  - Anagnostou, V.
AU  - Botsis, T.
TI  - An Evaluation of Pretrained BERT Models for Comparing Semantic Similarity Across Unstructured Clinical Trial Texts
PY  - 2022
T2  - Studies in Health Technology and Informatics
VL  - 289
SP  - 18
EP  - 21
DO  - 10.3233/SHTI210848
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85123185234&doi=10.3233%2fSHTI210848&partnerID=40&md5=78bc9b1aeecd2a5e9c4fa92d5f4beddf
AD  - Biomedical Informatics and Data Science Section, Johns Hopkins University School of Medicine, Baltimore, MD, United States
AB  - Processing unstructured clinical texts is often necessary to support certain tasks in biomedicine, such as matching patients to clinical trials. Among other methods, domain-specific language models have been built to utilize free-text information. This study evaluated the performance of Bidirectional Encoder Representations from Transformers (BERT) models in assessing the similarity between clinical trial texts. We compared an unstructured aggregated summary of clinical trials reviewed at the Johns Hopkins Molecular Tumor Board with the ClinicalTrials.gov records, focusing on the titles and eligibility criteria. Seven pretrained BERT-Based models were used in our analysis. Of the six biomedical-domain-specific models, only SciBERT outperformed the original BERT model by accurately assigning higher similarity scores to matched than mismatched trials. This finding is promising and shows that BERT and, likely, other language models may support patient-trial matching.  © 2022 The authors and IOS Press.
KW  - bidirectional coder representations
KW  - Clinical trial
KW  - word embeddings
KW  - Humans
KW  - Language
KW  - Natural Language Processing
KW  - Semantics
KW  - Computational linguistics
KW  - Medical applications
KW  - Natural language processing systems
KW  - Problem oriented languages
KW  - Bidirectional coder representation
KW  - Clinical trial
KW  - Embeddings
KW  - Free texts
KW  - Matchings
KW  - Performance
KW  - Semantic similarity
KW  - Text information
KW  - Transformer modeling
KW  - Word embedding
KW  - human
KW  - language
KW  - natural language processing
KW  - semantics
KW  - Semantics
A2  - Mantas J.
A2  - Hasman A.
A2  - Househ M.S.
A2  - Gallos P.
A2  - Zoulias E.
A2  - Liasko J.
PB  - IOS Press BV
SN  - 09269630 (ISSN); 978-164368250-1 (ISBN)
C2  - 35062081
LA  - English
J2  - Stud. Health Technol. Informatics
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 4
ER  -

TY  - JOUR
AU  - Dong, S.
AU  - Wang, S.
TI  - Assembled graph neural network using graph transformer with edges for protein model quality assessment
PY  - 2022
T2  - Journal of Molecular Graphics and Modelling
VL  - 110
C7  - 108053
DO  - 10.1016/j.jmgm.2021.108053
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85118878925&doi=10.1016%2fj.jmgm.2021.108053&partnerID=40&md5=5f6d692870f42f5f604497f978584f16
AD  - Department of Computer Science and Engineering, School of Information Science and Engineering, Yunnan University, Kunming, 650504, China
AB  - Acquainting protein's structure is of vital importance to accurately understanding its function. Computational method of deep learning has made great progress in protein structure prediction from sequence, and has the potential to help structural biology research. The computational methods usually require independent protein structure model quality assessment to select the best from the model pool or guide protein structure refinement. We construct a graph neural network finely assembled with Graph Transformer Feature Extractor and message-passing layers for protein model quality assessment. The graph based method can more naturally embody the protein structure than a sequence or voxelized representation method. Although the widely used graph convolutional network has a strong ability to learn spatial patterns, it does not weigh the dependencies of different nodes on other nodes. So we introduce Graph Transformer to excavate the different degrees of neighboring residue nodes contributing to their local environments and extract local features. This is subsequently followed by message-passing layers to transmit-receive local information. Our network makes better use of edge information and is lightweight since relatively few input features and number of network layers, and experimental results demonstrate that our model outperforms various existing methods. Core code is made freely available at: https://github.com/Crystal-Dsq/proteinqa. © 2021
KW  - Graph transformer
KW  - Message-passing
KW  - Protein graph
KW  - Protein model quality assessment
KW  - Neural Networks, Computer
KW  - Proteins
KW  - Computational methods
KW  - Deep learning
KW  - Graph neural networks
KW  - Graph theory
KW  - Graphic methods
KW  - Message passing
KW  - Multilayer neural networks
KW  - Network layers
KW  - protein
KW  - Graph neural networks
KW  - Graph transformer
KW  - Message-passing
KW  - Model quality assessments
KW  - Protein graph
KW  - Protein model quality assessment
KW  - Protein models
KW  - Protein structure prediction
KW  - Proteins structures
KW  - Structural biology
KW  - article
KW  - crystal
KW  - deep learning
KW  - Excavata
KW  - nonhuman
KW  - prediction
KW  - protein structure
KW  - quality control
KW  - structural model
KW  - Proteins
PB  - Elsevier Inc.
SN  - 10933263 (ISSN)
C2  - 34773871
LA  - English
J2  - J. Mol. Graph. Model.
M3  - Article
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 0; Correspondence Address: S. Wang; Department of Computer Science and Engineering, School of Information Science and Engineering, Yunnan University, Kunming, 650504, China; email: sfwang_66@ynu.edu.cn; CODEN: JMGMF
ER  -

TY  - CONF
AU  - Kaddari, Z.
AU  - Mellah, Y.
AU  - Berrich, J.
AU  - Belkasmi, M.G.
AU  - Bouchentouf, T.
TI  - OctaNLP: A Benchmark for Evaluating Multitask Generalization of Transformer-Based Pre-trained Language Models
PY  - 2022
T2  - Lecture Notes in Electrical Engineering
VL  - 745
SP  - 223
EP  - 232
DO  - 10.1007/978-981-33-6893-4_21
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85113311616&doi=10.1007%2f978-981-33-6893-4_21&partnerID=40&md5=e704d04e1da7beb07d8c329a1b61b89b
AD  - LaRSA Laboratory, AIRES Team, National School of Applied Sciences, Université Mohammed Premier, Oujda, Morocco
AD  - SmartICT Laboratory, National School of Applied Sciences, Université Mohammed Premier, Oujda, Morocco
AB  - In the last decade, deep learning based Natural Language Processing (NLP) models achieved remarkable performance on the majority of NLP tasks, especially, in machine translation, question answering and dialogue. NLP language models shifted from uncontextualized vector space models like word2vec and Glove in 2013, and 2014, to contextualized LSTM-based model like ELMO and ULMFit in 2018, to contextualized transformer-based models like BERT. Transformer-based language models are already trained to perform very well on individual NLP tasks. However, when applied to many tasks simultaneously, their performance drops considerably. In this paper, we overview NLP evaluation metrics, multitask benchmarks, and the recent transformer-based language models. We discuss the limitations of the current multitask benchmarks, and we propose our octaNLP benchmark for comparing the generalization capabilities of the transformer-based pre-trained language models on multiple downstream NLP tasks simultaneously. © 2022, Springer Nature Singapore Pte Ltd.
KW  - Benchmark
KW  - Metrics
KW  - Multitask
KW  - NLP
KW  - octaNLP
KW  - Transformer
KW  - Computational linguistics
KW  - Computer aided language translation
KW  - Deep learning
KW  - Embedded systems
KW  - Intelligent systems
KW  - Natural language processing systems
KW  - Vector spaces
KW  - Evaluation metrics
KW  - Generalization capability
KW  - Language model
KW  - Machine translations
KW  - NAtural language processing
KW  - Question Answering
KW  - Vector space models
KW  - Long short-term memory
A2  - Bennani S.
A2  - Lakhrissi Y.
A2  - Khaissidi G.
A2  - Mansouri A.
A2  - Khamlichi Y.
PB  - Springer Science and Business Media Deutschland GmbH
SN  - 18761100 (ISSN); 978-981336892-7 (ISBN)
LA  - English
J2  - Lect. Notes Electr. Eng.
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 0; Correspondence Address: Z. Kaddari; LaRSA Laboratory, AIRES Team, National School of Applied Sciences, Université Mohammed Premier, Oujda, Morocco; email: z.kaddari@ump.ac.ma; Conference name: 6th International Conference on Wireless Technologies, Embedded and Intelligent Systems, WITS 2020; Conference date: 14 October 2020 through 16 October 2020; Conference code: 262999
ER  -

TY  - CONF
AU  - Zhou, L.
AU  - Martínez-Plumed, F.
AU  - Hernández-Orallo, J.
AU  - Ferri, C.
AU  - Schellaert, W.
TI  - Reject Before You Run: Small Assessors Anticipate Big Language Models
PY  - 2022
T2  - CEUR Workshop Proceedings
VL  - 3169
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85134885815&partnerID=40&md5=d180d646eac00d1a9fe1d8a202a621c5
AD  - Valencian Research Institute for Artificial Intelligence (VRAIN), Universitat Politècnica de València, Spain
AD  - Leverhulme Centre for the Future of Intelligence, University of Cambridge, United Kingdom
AB  - Large Language Models (LMs) are expensive to operate. It would be more frugal to avoid querying them when results are predictably bad. In this paper we therefore investigate whether it is possible to granularly predict the performance of these large LMs with a much smaller external model, the assessor, which is trained on evaluation results. For instance, given an input prompt, can an assessor estimate the probability of correct completion by a giant like GPT-3 Davinci (175B parameters)? Using a data-wrangling task included in the BIG-bench repository as a case study, we find it is indeed possible, and we report results that are comparable in accuracy and calibration to the LM itself. This suggests that, at least for some tasks, a lot of compute, money, and emissions could be spared through the assessor's anticipative reject option. It also suggests that assessors can capture meaningful extra information from the evaluation procedure, and as such, could be a useful complement to simple aggregate metrics. © 2022 Copyright for this paper by its authors. Use permitted under Creative Commons License Attribution 4.0 International (CC BY 4.0).
KW  - AI Evaluation
KW  - Anticipative Reject Option
KW  - Assessor
KW  - Data Wrangling
KW  - Instance Granularity
KW  - Language Model
KW  - Artificial intelligence
KW  - AI evaluation
KW  - Anticipative reject option
KW  - Assessor
KW  - Case-studies
KW  - Data wrangling
KW  - Davinci
KW  - Evaluation results
KW  - Instance granularity
KW  - Language model
KW  - Performance
KW  - Computational linguistics
A2  - Hernandez-Orallo J.
A2  - Hernandez-Orallo J.
A2  - Hernandez-Orallo J.
A2  - Cheke L.
A2  - Tenebaum J.
A2  - Ullman T.
A2  - Martinez-Plumed F.
A2  - Rutar D.
A2  - Burden J.
A2  - Burden J.
A2  - Burnell R.
A2  - Schellaert W.
PB  - CEUR-WS
SN  - 16130073 (ISSN)
LA  - English
J2  - CEUR Workshop Proc.
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 0; Correspondence Address: L. Zhou; Valencian Research Institute for Artificial Intelligence (VRAIN), Universitat Politècnica de València, Spain; email: lzhou@inf.upv.es; Conference name: 2022 Workshop on AI Evaluation Beyond Metrics, EBeM 2022; Conference code: 180920
ER  -

TY  - JOUR
AU  - Nicula, B.
AU  - Dascalu, M.
AU  - Newton, N.N.
AU  - Orcutt, E.
AU  - McNamara, D.S.
TI  - Automated paraphrase quality assessment using language models and transfer learning
PY  - 2021
T2  - Computers
VL  - 10
IS  - 12
C7  - 166
DO  - 10.3390/computers10120166
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85121844841&doi=10.3390%2fcomputers10120166&partnerID=40&md5=13be2e7c356205a347027391885ec857
AD  - Department of Computer Science, University Politehnica of Bucharest, 313 Splaiul Independentei, Bucharest, 060042, Romania
AD  - Academy of Romanian Scientists, Str. Ilfov, Nr. 3, Bucharest, 050044, Romania
AD  - Department of Psychology, Arizona State University, P.O. Box 871104, Tempe, 85287, AZ, United States
AD  - Department of Educational Psychology, University of Minnesota, 56 East River Road, Minneapolis, 55455, MN, United States
AB  - Learning to paraphrase supports both writing ability and reading comprehension, particularly for less skilled learners. As such, educational tools that integrate automated evaluations of paraphrases can be used to provide timely feedback to enhance learner paraphrasing skills more efficiently and effectively. Paraphrase identification is a popular NLP classification task that involves establishing whether two sentences share a similar meaning. Paraphrase quality assessment is a slightly more complex task, in which pairs of sentences are evaluated in-depth across multiple dimensions. In this study, we focus on four dimensions: lexical, syntactical, semantic, and overall quality. Our study introduces and evaluates various machine learning models using handcrafted features combined with Extra Trees, Siamese neural networks using BiLSTM RNNs, and pretrained BERT-based models, together with transfer learning from a larger general paraphrase corpus, to estimate the quality of paraphrases across the four dimensions. Two datasets are considered for the tasks involving paraphrase quality: ULPC (User Language Paraphrase Corpus) containing 1998 paraphrases and a smaller dataset with 115 paraphrases based on children’s inputs. The paraphrase identification dataset used for the transfer learning task is the MSRP dataset (Microsoft Research Paraphrase Corpus) containing 5801 paraphrases. On the ULPC dataset, our BERT model improves upon the previous baseline by at least 0.1 in F1-score across the four dimensions. When using fine-tuning from ULPC for the children dataset, both the BERT and Siamese neural network models improve upon their original scores by at least 0.11 F1-score. The results of these experiments suggest that transfer learning using generic paraphrase identification datasets can be successful, while at the same time obtaining comparable results in fewer epochs. © 2021 by the authors. Licensee MDPI, Basel, Switzerland.
KW  - Language models
KW  - Natural language processing
KW  - Paraphrase quality assessment
KW  - Recurrent neural networks
KW  - Transfer learning
PB  - MDPI
SN  - 2073431X (ISSN)
LA  - English
J2  - Comput.
M3  - Article
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 3; Correspondence Address: B. Nicula; Department of Computer Science, University Politehnica of Bucharest, Bucharest, 313 Splaiul Independentei, 060042, Romania; email: bogdan.nicula@upb.ro
ER  -

TY  - CONF
AU  - Wang, H.
AU  - Wang, H.
AU  - Wang, Z.
AU  - Wong, K.-F.
TI  - INTEGRATING PRETRAINED LANGUAGE MODEL FOR DIALOGUE POLICY EVALUATION
PY  - 2022
T2  - ICASSP, IEEE International Conference on Acoustics, Speech and Signal Processing - Proceedings
VL  - 2022-May
SP  - 6692
EP  - 6696
DO  - 10.1109/ICASSP43922.2022.9747593
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85131251604&doi=10.1109%2fICASSP43922.2022.9747593&partnerID=40&md5=102685ddd3cc0389583e19455abe5439
AD  - Department of Systems Engineering and Engineering Management, The Chinese University of Hong Kong, Hong Kong
AB  - Reinforcement Learning (RL) has been witnessed its potential for training a dialogue policy agent towards maximizing the accumulated rewards given from users. However, the reward can be very sparse for it is usually only provided at the end of a dialog session, which causes unaffordable interaction requirements for an acceptable dialog agent. Distinguished from many efforts dedicated to optimizing the policy and recovering the reward alternatively which suffers from easily getting stuck in local optima and model collapse, we decompose the adversarial training into two steps: 1) we integrate a pre-trained language model as a discriminator to judge whether the current system action is good enough for the last user action (i.e., next action prediction); 2) the discriminator gives and extra local dense reward to guide the agent's exploration. The experimental result demonstrates that our method significantly improves the complete rate (4.4%) and success rate (8.0%) of the dialogue system. © 2022 IEEE
KW  - Dialogue Policy Learning
KW  - Pre-trained Language Model
KW  - Reward Shaping
KW  - Computational linguistics
KW  - Learning systems
KW  - Speech processing
KW  - Dialog policy learning
KW  - Language model
KW  - Local model
KW  - Local optima
KW  - Policy agents
KW  - Policy evaluation
KW  - Policy learning
KW  - Pre-trained language model
KW  - Reinforcement learnings
KW  - Reward shaping
KW  - Reinforcement learning
PB  - Institute of Electrical and Electronics Engineers Inc.
SN  - 15206149 (ISSN); 978-166540540-9 (ISBN)
LA  - English
J2  - ICASSP IEEE Int Conf Acoust Speech Signal Process Proc
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 1; Conference name: 47th IEEE International Conference on Acoustics, Speech, and Signal Processing, ICASSP 2022; Conference date: 23 May 2022 through 27 May 2022; Conference code: 179417; CODEN: IPROD
ER  -

TY  - CONF
AU  - Hanslo, R.
TI  - Evaluation of Neural Network Transformer Models for Named-Entity Recognition on Low-Resourced Languages
PY  - 2021
T2  - Proceedings of the 16th Conference on Computer Science and Intelligence Systems, FedCSIS 2021
SP  - 115
EP  - 119
DO  - 10.15439/2021F7
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85117810088&doi=10.15439%2f2021F7&partnerID=40&md5=c3eb81c6fa5f4fb0991f253a374943f1
AD  - University of Pretoria, Gauteng, South Africa
AB  - Neural Network (NN) models produce state-of-the-art results for natural language processing tasks. Further, NN models are used for sequence tagging tasks on low-resourced languages with good results. However, the findings are not consistent for all low-resourced languages, and many of these languages have not been sufficiently evaluated. Therefore, in this paper, transformer NN models are used to evaluate named-entity recognition for ten low-resourced South African languages. Further, these transformer models are compared to other NN models and a Conditional Random Fields (CRF) Machine Learning (ML) model. The findings show that the transformer models have the highest F-scores with more than a 5% performance difference from the other models. However, the CRF ML model has the highest average F-score. The transformer model's greater parallelization allows low-resourced languages to be trained and tested with less effort and resource costs. This makes transformer models viable for low-resourced languages. Future research could improve upon these findings by implementing a linear-complexity recurrent transformer variant.  © 2021 Polish Information Processing Society.
KW  - Information systems
KW  - Information use
KW  - Learning algorithms
KW  - Natural language processing systems
KW  - African languages
KW  - F-score
KW  - Field machines
KW  - Machine learning models
KW  - Named entity recognition
KW  - Neural network model
KW  - Neural-networks
KW  - Performance
KW  - State of the art
KW  - Transformer modeling
KW  - Random processes
A2  - Ganzha M.
A2  - Maciaszek L.
A2  - Maciaszek L.
A2  - Paprzycki M.
A2  - Slezak D.
PB  - Institute of Electrical and Electronics Engineers Inc.
SN  - 978-839591838-4 (ISBN)
LA  - English
J2  - Proc. Conf. Comput. Sci. Intell. Syst., FedCSIS
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 4; Correspondence Address: R. Hanslo; University of Pretoria, Gauteng, South Africa; email: ridewaan.hanslo@up.ac.za; Conference name: 16th Conference on Computer Science and Intelligence Systems, FedCSIS 2021; Conference date: 2 September 2021 through 5 September 2021; Conference code: 172454
ER  -

TY  - CONF
AU  - Ramli, I.
AU  - Krisnadhi, A.A.
AU  - Prasojo, R.E.
TI  - IndoKEPLER, IndoWiki, and IndoLAMA: A Knowledge-enhanced Language Model, Dataset, and Benchmark for the Indonesian Language
PY  - 2022
T2  - IWBIS 2022 - 7th International Workshop on Big Data and Information Security, Proceedings
SP  - 19
EP  - 26
DO  - 10.1109/IWBIS56557.2022.9924844
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85141842381&doi=10.1109%2fIWBIS56557.2022.9924844&partnerID=40&md5=82b99fe57f26c7a770c8c463093bf607
AD  - Universitas Indonesia, Faculty of Computer Science, Tokopedia-UI Ai Center of Excellence, Depok, Indonesia
AD  - Pitik Digital Indonesia, Data & Ai Team, Jakarta, Indonesia
AB  - Pretrained language models posses an ability to learn the structural representation of a natural language by processing unstructured textual data. However, the current language model design lacks the ability to learn factual knowledge from knowledge graphs. Several attempts have been made to address this issue, such as the development of KEPLER. KEPLER combines the BERT language model and TransE knowledge embedding method to achieve a language model that can incorporate knowledge graphs as training data. Unfortunately, such knowledge enhanced language model is not yet available for the Indonesian language. In this experiment, we propose IndoKEPLER: a language model trained usingWikipedia Bahasa Indonesia andWikidata. We also create a new knowledge probing benchmark named IndoLAMA to test the ability of a language model to recall factual knowledge. The benchmark is based on LAMA, which is designed to test the suitability of our language model to be used as a knowledge base. IndoLAMA tests a language model by giving cloze style question and compare the prediction of the model to the factually correct answer. This experiment shows that IndoKEPLER increases the ability of a normal DistilBERT model to recall factual knowledge by 0.8%. Moreover, the most significant increase happens when dealing with many-to-one relationships, where IndoKEPLER outperforms it's original text encoder model by 3%.  © 2022 IEEE.
KW  - Indonesian language
KW  - knowledge embedding
KW  - knowledge graph
KW  - Language model
KW  - natural language processing
KW  - Computational linguistics
KW  - Data handling
KW  - Graph embeddings
KW  - Natural language processing systems
KW  - Factual knowledge
KW  - Indonesian languages
KW  - Knowledge embedding
KW  - Knowledge graphs
KW  - Language model
KW  - Language processing
KW  - Learn+
KW  - Natural language processing
KW  - Natural languages
KW  - Structural representation
KW  - Knowledge graph
PB  - Institute of Electrical and Electronics Engineers Inc.
SN  - 978-166548950-8 (ISBN)
LA  - English
J2  - IWBIS - Int. Workshop Big Data Inf. Secur., Proc.
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 0; Correspondence Address: A.A. Krisnadhi; Universitas Indonesia, Faculty of Computer Science, Tokopedia-UI Ai Center of Excellence, Depok, Indonesia; email: adila@cs.ui.ac.id; Conference name: 7th International Workshop on Big Data and Information Security, IWBIS 2022; Conference date: 1 October 2022 through 3 October 2022; Conference code: 183826
ER  -

TY  - CONF
AU  - Zhao, T.
AU  - Zhang, T.
AU  - Zhu, M.
AU  - Shen, H.
AU  - Lee, K.
AU  - Lu, X.
AU  - Yin, J.
TI  - An Explainable Toolbox for Evaluating Pre-trained Vision-Language Models
PY  - 2022
T2  - EMNLP 2022 - 2022 Conference on Empirical Methods in Natural Language Processing, Proceedings of the Demonstrations Session
SP  - 30
EP  - 37
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85149668359&partnerID=40&md5=8d1cd9c2180ea7ac6bb4fd14c4e9e60d
AD  - Om Research Lab, Binjiang Institute of Zhejiang University, China
AD  - Linker Technology Research Co. Ltd, China
AD  - College of Computer Science and Technology, Zhejiang University, China
AB  - We introduce VL-CheckList, a toolbox for evaluating Vision-Language Pretraining (VLP) models, along with a benchmark dataset for fine-grained VLP model analysis. Most existing VLP models evaluate their performance by comparing the fine-tuned downstream task performance. However, only average downstream task accuracy provides little information about the pros and cons of each VLP method. In this paper, we demonstrate how minor input changes in language and vision will affect the prediction outputs. We also provide a guideline for the research community to utilizes and contributes to this toolbox. Lastly, a case study based on VL-CheckList is conducted to analyze one of the representative VLP models. Data and code are available at https://github.com/om-ai-lab/VL-CheckList. © 2022 Association for Computational Linguistics.
KW  - Benchmark datasets
KW  - Case-studies
KW  - Down-stream
KW  - Fine grained
KW  - Language model
KW  - Modeling analyzes
KW  - Performance
KW  - Pre-training
KW  - Research communities
KW  - Task performance
A2  - Che W.
A2  - Shutova E.
PB  - Association for Computational Linguistics (ACL)
SN  - 978-195942941-8 (ISBN)
LA  - English
J2  - EMNLP - Conf. Empir. Methods Nat. Lang. Process., Proc. Demonstr. Sess.
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 2; Conference name: 2022 Conference on Empirical Methods in Natural Language Processing, EMNLP 2022; Conference date: 7 December 2022 through 11 December 2022; Conference code: 186897
ER  -

TY  - CONF
AU  - Chen, Y.
AU  - Belouadi, J.
AU  - Eger, S.
TI  - Reproducibility Issues for BERT-based Evaluation Metrics
PY  - 2022
T2  - Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing, EMNLP 2022
SP  - 2965
EP  - 2989
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85149441148&partnerID=40&md5=8c9af9fedfca84d5da444a6d17a31673
AD  - Computer Science Department, Technical University of Darmstadt, Germany
AD  - NLLG, Faculty of Technology, Bielefeld University, Germany
AB  - Reproducibility is of utmost concern in machine learning and natural language processing (NLP). In the field of natural language generation (especially machine translation), the seminal paper of Post (2018) has pointed out problems of reproducibility of the dominant metric, BLEU, at the time of publication. Nowadays, BERT-based evaluation metrics considerably outperform BLEU. In this paper, we ask whether results and claims from four recent BERT-based metrics can be reproduced. We find that reproduction of claims and results often fails because of (i) heavy undocumented preprocessing involved in the metrics, (ii) missing code and (iii) reporting weaker results for the baseline metrics. (iv) In one case, the problem stems from correlating not to human scores but to a wrong column in the csv file, inflating scores by 5 points. Motivated by the impact of preprocessing, we then conduct a second study where we examine its effects more closely (for one of the metrics). We find that preprocessing can have large effects, especially for highly inflectional languages. In this case, the effect of preprocessing may be larger than the effect of the aggregation mechanism (e.g., greedy alignment vs. Word Mover Distance). © 2022 Association for Computational Linguistics.
KW  - Computational linguistics
KW  - Learning algorithms
KW  - Natural language processing systems
KW  - Aggregation mechanism
KW  - Evaluation metrics
KW  - Language processing
KW  - Learning languages
KW  - Machine translations
KW  - Machine-learning
KW  - Missing codes
KW  - Natural language generation
KW  - Natural languages
KW  - Reproducibilities
KW  - Cell proliferation
A2  - Goldberg Y.
A2  - Kozareva Z.
A2  - Zhang Y.
PB  - Association for Computational Linguistics (ACL)
LA  - English
J2  - Proc. Conf. Empir. Methods Nat. Lang. Process., EMNLP
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 3; Conference name: 2022 Conference on Empirical Methods in Natural Language Processing, EMNLP 2022; Conference date: 7 December 2022 through 11 December 2022; Conference code: 186895
ER  -

TY  - CONF
AU  - Yahya, A.A.
AU  - Levin, V.M.
TI  - Digital Model for Predictive Assessment of a Power Transformer Technical Condition
PY  - 2022
T2  - Smart Innovation, Systems and Technologies
VL  - 272
SP  - 515
EP  - 526
DO  - 10.1007/978-981-16-8759-4_53
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85126201095&doi=10.1007%2f978-981-16-8759-4_53&partnerID=40&md5=562befd2be8252e7ec3ace8f5f94be0b
AD  - Department of Energy, Novosibirsk State Technical University, Novosibirsk, Russian Federation
AB  - The reliability and safety of the electrical power system are ensured by monitoring and diagnosing the technical state of the equipment that comprises the power system. Power transformers are one of the most important, responsible, and most expensive parts of the distribution network and electrical power system. In this paper, the authors propose to design a predictive program to diagnose the technical state of the power transformer oil filled and predict faults using LabVIEW 2018, fuzzy logic, and dissolved gas analysis (DGA) based on the Duval triangle method. The front interface of the program was designed using LabVIEW, which acts as a control panel through which the data are entered, to then process this data through an expert system designed using a fuzzy logic toolbox in order to determine the defect type and location, and the results are displayed on the front interface of the program as well. The results showed the program’s effectiveness in predicting the technical state of the power transformer and identifying defects with high reliability. The designed program was also compared with other studies and showed great agreement with the results of these studies. This gives support to the program in its applicability on the power transformers oil filled. © 2022, The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd.
KW  - Diagnostics
KW  - Dissolved gas analysis
KW  - Duval triangle
KW  - Fuzzy logic
KW  - Identify defects
KW  - LabVIEW
KW  - Power transformer
KW  - Predict the technical state
KW  - Computer circuits
KW  - Defects
KW  - Expert systems
KW  - Forecasting
KW  - Fuzzy logic
KW  - Oil filled transformers
KW  - Diagnostic
KW  - Dissolved gases analysis
KW  - Duval triangle
KW  - Electrical power system
KW  - Fuzzy-Logic
KW  - Identify defect
KW  - LabVIEW
KW  - Power transformer oil
KW  - Predict the technical state
KW  - Power transformers
A2  - Lin K.
A2  - Liu R.
A2  - Yang B.
PB  - Springer Science and Business Media Deutschland GmbH
SN  - 21903018 (ISSN); 978-981168758-7 (ISBN)
LA  - English
J2  - Smart Innov. Syst. Technol.
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 0; Correspondence Address: A.A. Yahya; Department of Energy, Novosibirsk State Technical University, Novosibirsk, Russian Federation; email: ammarazez384@gmail.com; Conference name: International Conference on SMART Automatics and Energy, SMART-ICAE 2021; Conference date: 7 October 2021 through 8 October 2021; Conference code: 274059
ER  -

TY  - CONF
AU  - Ng, S.H.
AU  - Huang, Y.-C.
AU  - Lin, S.-J.
AU  - Chang, Y.-C.
TI  - Context-dependent Features Fusion with BERT for Evaluating Multi-Turn Customer-Helpdesk Dialogues
PY  - 2021
T2  - ACM International Conference Proceeding Series
SP  - 512
EP  - 517
DO  - 10.1145/3486622.3493988
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85128611928&doi=10.1145%2f3486622.3493988&partnerID=40&md5=0a2c8d5e67075b1a72b0d34b2e41e498
AD  - Snhcc, Tigp, Academia Sinica, National Cheng Chi University, Taiwan
AD  - Graduate Institute of Data Science, Taipei Medical University, Taiwan
AB  - With the growth of online text data in recent years, the research on automated dialogue systems has made more progress than before. In this paper, we propose a new model DepBERT. This model uses BERT pre-training model and integrates Syntactic Dependency Feature to extract the key features of customer and helpdesk data in the dialogue content to enhance the prediction of evaluating multiple turns of dialogue. The contribution of this research is to optimize the method of automated evaluation dialogue system. The F1-score of DepBERT has a 4% increase in customer dataset and has a 10% increase in helpdesk dataset compared to BERT, indicating that it can effectively predict the task behavior in the dialogue between the customer and the helpdesk.  © 2021 ACM.
KW  - BERT
KW  - Context-dependency Parsing
KW  - Dialogue Evaluation
KW  - Multi-feature Fusion
KW  - Natural Language Processing
KW  - Computational linguistics
KW  - Natural language processing systems
KW  - Online systems
KW  - Speech processing
KW  - Syntactics
KW  - BERT
KW  - Context dependency
KW  - Context dependent
KW  - Context-dependency parsing
KW  - Dependency parsing
KW  - Dialogue evaluation
KW  - Dialogue systems
KW  - Features fusions
KW  - Help Desk
KW  - Multi-feature fusion
KW  - Sales
PB  - Association for Computing Machinery
SN  - 978-145039115-3 (ISBN)
LA  - English
J2  - ACM Int. Conf. Proc. Ser.
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 0; Conference name: 2021 IEEE/WIC/ACM International Conference on Web Intelligence and Intelligent Agent Technology, WI-IAT 2021; Conference date: 14 December 2021 through 17 December 2021; Conference code: 178753
ER  -

TY  - CONF
AU  - Li, Y.
AU  - Yin, L.
AU  - Heng, P.
TI  - Research on Comprehensive Evaluation Method of Transformer Noise Based on AHP Matter Element Model
PY  - 2021
T2  - Journal of Physics: Conference Series
VL  - 2137
IS  - 1
C7  - 012057
DO  - 10.1088/1742-6596/2137/1/012057
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85123344399&doi=10.1088%2f1742-6596%2f2137%2f1%2f012057&partnerID=40&md5=8d81cca603f3011643932fd46254ec5f
AD  - Nanjing Power Supply Company, Jiangsu Electic Power Co. Ltd., State Grid, Jiangsu, Nanjing, 210013, China
AB  - Aiming at the problem of transformer condition evaluation, a comprehensive evaluation system for transformer noise is constructed according to the mechanism of transformer noise generation and propagation. Using matter-element theory and AHP, a state analysis method for transformer noise evaluation based on AHP matter-element model is proposed. The case analysis proves that the method is feasible for non-contact evaluation of transformer faults, and can accurately evaluate the state of the transformer, providing guidance for the operation and maintenance of the transformer. © 2021 Institute of Physics Publishing. All rights reserved.
KW  - Comprehensive evaluation
KW  - Comprehensive evaluation system
KW  - Condition evaluation
KW  - Evaluation methods
KW  - Matter elements model
KW  - Matter-element
KW  - Noise generation
KW  - Noise propagation
KW  - State analysis
KW  - Transformer noise
KW  - Hierarchical systems
PB  - Institute of Physics
SN  - 17426588 (ISSN)
LA  - English
J2  - J. Phys. Conf. Ser.
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 0; Correspondence Address: Y. Li; Nanjing Power Supply Company, Jiangsu Electic Power Co. Ltd., State Grid, Nanjing, Jiangsu, 210013, China; email: liyong@js.sgcc.com.cn; Conference name: 2021 5th International Conference on Electrical, Mechanical and Computer Engineering, ICEMCE 2021; Conference date: 29 October 2021 through 31 October 2021; Conference code: 176003
ER  -

TY  - CONF
AU  - Muffo, M.
AU  - Cocco, A.
AU  - Bertino, E.
TI  - Evaluating Transformer Language Models on Arithmetic Operations Using Number Decomposition
PY  - 2022
T2  - 2022 Language Resources and Evaluation Conference, LREC 2022
SP  - 291
EP  - 297
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85144371625&partnerID=40&md5=4a5e7646591af39c5a7727879ca0bc57
AD  - Indigo.ai, Via Torino 61, Milan, Italy
AB  - In recent years, Large Language Models such as GPT-3 showed remarkable capabilities in performing NLP tasks in the zero and few shot settings. On the other hand, the experiments highlighted the difficulty of GPT-3 in carrying out tasks that require a certain degree of reasoning, such as arithmetic operations. In this paper we evaluate the ability of Transformer Language Models to perform arithmetic operations following a pipeline that, before performing computations, decomposes numbers in units, tens, and so on. We denote the models fine-tuned with this pipeline with the name Calculon and we test them in the task of performing additions, subtractions and multiplications on the same test sets of GPT-3. Results show an increase of accuracy of 63% in the five-digit addition task. Moreover, we demonstrate the importance of the decomposition pipeline introduced, since fine-tuning the same Language Model without decomposing numbers results in 0% accuracy in the five-digit addition task. © European Language Resources Association (ELRA), licensed under CC-BY-NC-4.0.
KW  - arithmetic operations
KW  - number decomposition
KW  - Transformer Language Models
KW  - Computational linguistics
KW  - Decomposition
KW  - Arithmetic operations
KW  - Fine tuning
KW  - Language model
KW  - Number decomposition
KW  - Test sets
KW  - Transformer language model
KW  - Pipelines
A2  - Calzolari N.
A2  - Bechet F.
A2  - Blache P.
A2  - Choukri K.
A2  - Cieri C.
A2  - Declerck T.
A2  - Goggi S.
A2  - Isahara H.
A2  - Maegaard B.
A2  - Mariani J.
A2  - Mazo H.
A2  - Odijk J.
A2  - Piperidis S.
PB  - European Language Resources Association (ELRA)
SN  - 979-109554672-6 (ISBN)
LA  - English
J2  - Lang. Resour. Eval. Conf., LREC
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 4; Conference name: 13th International Conference on Language Resources and Evaluation Conference, LREC 2022; Conference date: 20 June 2022 through 25 June 2022; Conference code: 184830
ER  -

TY  - CONF
AU  - Greco, C.M.
AU  - Tagarelli, A.
AU  - Zumpano, E.
TI  - A Comparison of Transformer-Based Language Models on NLP Benchmarks
PY  - 2022
T2  - Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)
VL  - 13286 LNCS
SP  - 490
EP  - 501
DO  - 10.1007/978-3-031-08473-7_45
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85133006899&doi=10.1007%2f978-3-031-08473-7_45&partnerID=40&md5=cccc707c6f3a45ef647af8340b123a07
AD  - DIMES, University of Calabria, Rende (CS), Italy
AB  - Since the advent of BERT, Transformer-based language models (TLMs) have shown outstanding effectiveness in several NLP tasks. In this paper, we aim at bringing order to the landscape of TLMs and their performance on important benchmarks for NLP. Our analysis sheds light on the advantages that some TLMs take over the others, but also unveils issues in making a complete and fair comparison in some situations. © 2022, The Author(s), under exclusive license to Springer Nature Switzerland AG.
KW  - Benchmarks
KW  - BERTology
KW  - Deep learning
KW  - Benchmarking
KW  - Computational linguistics
KW  - Deep learning
KW  - Benchmark
KW  - Bertology
KW  - Deep learning
KW  - Language model
KW  - Performance
KW  - Natural language processing systems
A2  - Rosso P.
A2  - Basile V.
A2  - Martínez R.
A2  - Métais E.
A2  - Meziane F.
PB  - Springer Science and Business Media Deutschland GmbH
SN  - 03029743 (ISSN); 978-303108472-0 (ISBN)
LA  - English
J2  - Lect. Notes Comput. Sci.
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 2; Correspondence Address: A. Tagarelli; DIMES, University of Calabria, Rende (CS), Italy; email: tagarelli@dimes.unical.it; Conference name: 27th International Conference on Applications of Natural Language to Information Systems, NLDB 2022; Conference date: 15 June 2022 through 17 June 2022; Conference code: 279519
ER  -

TY  - CONF
AU  - Favreau, C.-O.
AU  - Zouaq, A.
AU  - Bhatnagar, S.
TI  - Learning to Rank with BERT for Argument Quality Evaluation
PY  - 2022
T2  - Proceedings of the International Florida Artificial Intelligence Research Society Conference, FLAIRS
VL  - 35
DO  - 10.32473/flairs.v35i.130643
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85131140133&doi=10.32473%2fflairs.v35i.130643&partnerID=40&md5=69c02c44852e7f73fc95b386f0f47a74
AD  - Polytechnique Montreal, 2500 Chem. de Polytechnique, Montreal, Canada
AB  - The task of argument quality ranking, which identifies the quality of free text arguments, remains, to this day, a challenge. While most state-of-the-art initiatives use point-wise ranking methods and predict an absolute quality score for each argument, we instead focus on learning how to order them by their relative convincingness, experimenting with several learning-to-rank methods for argument quality. We leverage BERT’s powerful ability in building a representation of an argument, paired with learning-to-rank approaches (point-wise, pairwise, list-wise) to rank arguments according to their measure of convincingness. We also demonstrate how an ensemble of models trained with different ranking losses often improves the performance at identifying the most convincing arguments of a list. Finally, we compare BERT coupled with learning-to-rank methods to state-of-the-art approaches on all major argument quality datasets available for the ranking task, demonstrating how a learning-to-rank approach generally performs better at outlining the topmost convincing arguments. © 2021 by the authors. All rights reserved.
KW  - Argument qualities
KW  - Ensemble of models
KW  - Free texts
KW  - In-buildings
KW  - Performance
KW  - Point wise
KW  - Quality evaluation
KW  - Quality ranking
KW  - Ranking methods
KW  - State of the art
KW  - Machine learning
A2  - Bartak R.
A2  - Franklin M.
A2  - Keshtkar F.
PB  - Florida Online Journals, University of Florida
SN  - 23340754 (ISSN)
LA  - English
J2  - Proc. Int. Fla. Artif. Intell. Res. Soc. Conf., FLAIRS
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 0; Conference name: 35th International Florida Artificial Intelligence Research Society Conference, FLAIRS-35 2022; Conference date: 15 May 2022 through 18 May 2022; Conference code: 277889
ER  -

TY  - CONF
AU  - Zhang, W.
AU  - Li, B.
AU  - Lu, Y.
AU  - Li, J.
AU  - Jiang, J.
AU  - Zhang, C.
TI  - Residual Lifetime Evaluation of Power Transformer Insulation Based on PSO-Wiener Model
PY  - 2022
T2  - 2022 IEEE International Conference on High Voltage Engineering and Applications, ICHVE 2022
DO  - 10.1109/ICHVE53725.2022.9961633
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85143965629&doi=10.1109%2fICHVE53725.2022.9961633&partnerID=40&md5=71c45d1b88ea8d246fefbd75901b14ee
AD  - Jiangsu Key Laboratory of New Energy Generation and Power Conversion, Nanjing University of Aeronautics and Astronautics, Nanjing, 211106, China
AD  - State Grid Jiangsu Electric Power Co. Ltd. Research Institute, Nanjing, 211103, China
AB  - Power transformers play an important role in the operation of power system. Prediction of transformer insulation lifetime reasonably can improve the reliability of power grid and bring in economic benefits. In this paper, the transformer life correlation index (LCI) is constructed as its degradation data by fusing the multi-dimensional data including dissolved gas and polymerization degree (DP) in oil instead of existing single parameter. Then Bayesian updating and Maximum Expectation (EM) algorithm are used to update the parameters of Wiener model. To solve the problem that uncertain initial parameters of Wiener model bring stochastic error to life prediction, Particle Swarm Optimization (PSO) algorithm is proposed. The combined model is efficient to get the optimal solution of initial parameters to improve the prediction accuracy of remaining useful life of power transformers. A 500 kV power transformer in the field is taken as the case. The minimum loss between actual degradation path and predicted trajectory are compared and evaluated. Finally, its predicted total life is 37.96 years, which is in close to the general service life of transformers. Therefore, the PSO-Wiener model is effective for the practical application in the field.  © 2022 IEEE.
KW  - Electric power system economics
KW  - Forecasting
KW  - Parameter estimation
KW  - Particle swarm optimization (PSO)
KW  - Polymerization
KW  - Stochastic models
KW  - Stochastic systems
KW  - Uncertainty analysis
KW  - Initial parameter
KW  - Lifetime evaluation
KW  - Operation of power system
KW  - Particle swarm
KW  - Power grids
KW  - Power transformer insulation
KW  - Residual lifetime
KW  - Swarm optimization
KW  - Transformer insulation
KW  - Wiener models
KW  - Power transformers
PB  - Institute of Electrical and Electronics Engineers Inc.
SN  - 978-166540750-2 (ISBN)
LA  - English
J2  - IEEE Int. Conf. High Volt. Eng. Appl., ICHVE
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 0; Correspondence Address: J. Jiang; Jiangsu Key Laboratory of New Energy Generation and Power Conversion, Nanjing University of Aeronautics and Astronautics, Nanjing, 211106, China; email: jiangjun0628@nuaa.edu.cn; Conference name: 2022 IEEE International Conference on High Voltage Engineering and Applications, ICHVE 2022; Conference date: 25 September 2022 through 29 September 2022; Conference code: 184810
ER  -

TY  - CONF
AU  - Ghaddar, A.
AU  - Wu, Y.
AU  - Bagga, S.
AU  - Rashid, A.
AU  - Bibi, K.
AU  - Rezagholizadeh, M.
AU  - Xing, C.
AU  - Wang, Y.
AU  - Xinyu, D.
AU  - Wang, Z.
AU  - Huai, B.
AU  - Jiang, X.
AU  - Liu, Q.
AU  - Langlais, P.
TI  - Revisiting Pre-trained Language Models and their Evaluation for Arabic Natural Language Processing
PY  - 2022
T2  - Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing, EMNLP 2022
SP  - 3135
EP  - 3151
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85149443032&partnerID=40&md5=b4e423c54d8019fbb5ac8f6f23f59763
AD  - Huawei Technologies Co., Ltd.
AD  - Huawei Cloud Computing Technologies Co., Ltd
AD  - RALI/DIRO, Université de Montréal, Canada
AB  - There is a growing body of work in recent years to develop pre-trained language models (PLMs) for the Arabic language. This work addresses two major problems in existing Arabic PLMs that limit the progress of the Arabic NLU and NLG fields. First, existing Arabic PLMs are not well-explored and their pre-training can be improved significantly using a more methodical approach. Second, there is a lack of systematic and reproducible evaluation of these models in the literature. We revisit both the pre-training and evaluation of Arabic PLMs. In terms of pre-training, we explore the impact of the quality of the pretraining data, the size of the model and the incorporation of character-level information to Arabic PLMs. As a result, we release three new Arabic BERT-style models (JABER, Char-JABER, and SABER), and two T5-style models (AT5S and AT5B). In terms of evaluation, we conduct a comprehensive empirical study to systematically evaluate the performance of existing state-of-the-art models on ALUE, a leaderboard-powered benchmark for Arabic NLU tasks, and on a subset of Arabic generative tasks. We show that our models significantly outperform existing Arabic PLMs and achieve a new state-of-the-art performance on both discriminative and generative tasks. © 2022 Association for Computational Linguistics.
KW  - Computational linguistics
KW  - Natural language processing systems
KW  - Arabic languages
KW  - Arabic natural language processing
KW  - Character level
KW  - Empirical studies
KW  - Language model
KW  - Methodical approach
KW  - Performance
KW  - Pre-evaluation
KW  - Pre-training
KW  - State of the art
KW  - Benchmarking
A2  - Goldberg Y.
A2  - Kozareva Z.
A2  - Zhang Y.
PB  - Association for Computational Linguistics (ACL)
LA  - English
J2  - Proc. Conf. Empir. Methods Nat. Lang. Process., EMNLP
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 1; Conference name: 2022 Conference on Empirical Methods in Natural Language Processing, EMNLP 2022; Conference date: 7 December 2022 through 11 December 2022; Conference code: 186895
ER  -

TY  - CONF
AU  - Daðason, J.F.
AU  - Loftsson, H.
TI  - Pre-training and Evaluating Transformer-based Language Models for Icelandic
PY  - 2022
T2  - 2022 Language Resources and Evaluation Conference, LREC 2022
SP  - 7386
EP  - 7391
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85144359038&partnerID=40&md5=ad71ec0d0a806dc8b0352528d47d7f8c
AD  - Department of Computer Science, Reykjavik University, Iceland
AB  - In this paper, we evaluate several Transformer-based language models for Icelandic on four downstream tasks: Part-of-Speech tagging, Named Entity Recognition. Dependency Parsing, and Automatic Text Summarization. We pre-train four types of monolingual ELECTRA and ConvBERT models and compare our results to a previously trained monolingual RoBERTa model and the multilingual mBERT model. We find that the Transformer models obtain better results, often by a large margin, compared to previous state-of-the-art models. Furthermore, our results indicate that pre-training larger language models results in a significant reduction in error rates in comparison to smaller models. Finally, our results show that the monolingual models for Icelandic outperform a comparably sized multilingual model. © European Language Resources Association (ELRA), licensed under CC-BY-NC-4.0.
KW  - Evaluation
KW  - Icelandic
KW  - Language Models
KW  - Transformer
KW  - Natural language processing systems
KW  - Speech recognition
KW  - Dependency parsing
KW  - Down-stream
KW  - Evaluation
KW  - Icelandics
KW  - Language model
KW  - Named entity recognition
KW  - Part of speech tagging
KW  - Parts-of-speech tagging
KW  - Pre-training
KW  - Transformer
KW  - Computational linguistics
A2  - Calzolari N.
A2  - Bechet F.
A2  - Blache P.
A2  - Choukri K.
A2  - Cieri C.
A2  - Declerck T.
A2  - Goggi S.
A2  - Isahara H.
A2  - Maegaard B.
A2  - Mariani J.
A2  - Mazo H.
A2  - Odijk J.
A2  - Piperidis S.
PB  - European Language Resources Association (ELRA)
SN  - 979-109554672-6 (ISBN)
LA  - English
J2  - Lang. Resour. Eval. Conf., LREC
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 3; Conference name: 13th International Conference on Language Resources and Evaluation Conference, LREC 2022; Conference date: 20 June 2022 through 25 June 2022; Conference code: 184830
ER  -

TY  - JOUR
AU  - Xia, Y.
AU  - Lei, Y.
AU  - Liu, G.
AU  - Liu, X.
AU  - Wang, X.
TI  - Research and Validation of Saturation Model for Single-phase Four-column Converter Transformer Based on No-load Experiment Data and UMEC Model
ST  - 基于空载试验数据和UMEC的单相四柱换流变压器饱和模型研究和有效性验证
PY  - 2021
T2  - Gaodianya Jishu/High Voltage Engineering
VL  - 47
IS  - 10
SP  - 3733
EP  - 3743
DO  - 10.13336/j.1003-6520.hve.20210052
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85120865786&doi=10.13336%2fj.1003-6520.hve.20210052&partnerID=40&md5=1b1c540c7686c2a9538e5a69364299ba
AD  - Hebei Provincial Key Laboratory of Power Transmission Equipment Security Defense, North China Electric Power University, Baoding, 071003, China
AD  - Electric Power Research Institute, China Southern Power Grid, Guangzhou, 510663, China
AB  - In order to accurately and quickly perform electromagnetic transient simulation of single-phase four-leg converter transformers, this paper proposes a single-phase four-limb converter transformer saturation model based on no-load test data and UMEC(unified magnetic equivalent circuit) model. Based on the UMEC magnetic circuit model, the method of solving the incidence matrix, inductance matrix and core permeance of the single-phase four-limb converter transformer is derived. When considering the saturation of the core, the excitation branch is simulated by the parallel connection of a nonlinear resistance and a nonlinear inductance. Through the no-load test data, the piecewise linearization curves of u-iR and u-iL in the excitation branch are obtained to simulate the core loss and the nonlinearity of the magnetic permeability. The method in this paper is based on the UMEC model, meanwhile, the nonlinearity of the core main column, iron yoke, side column and side yoke magnetic guide as a whole is taken into account, thus the method has the advantages of fast calculation speed, high efficiency and high precision. Finally, the method in this paper is used to simulate and calculate the scaled model and the product-level single-phase four-limb converter transformer under normal operating conditions and DC bias conditions. The comparison with experimental measurements proves that the model has high accuracy. © 2021, High Voltage Engineering Editorial Department of CEPRI. All right reserved.
KW  - Electromagnetic transient simulation
KW  - Piecewise linearization
KW  - Saturation characteristics
KW  - Single-phase four-limb transformer
KW  - UMEC
KW  - Electric connectors
KW  - Electric transformer testing
KW  - Electromagnetic simulation
KW  - Equivalent circuits
KW  - Inductance
KW  - Load testing
KW  - Magnetic cores
KW  - Magnetic permeability
KW  - Mechanical permeability
KW  - Transient analysis
KW  - Converter transformers
KW  - Electromagnetic transient simulation
KW  - Equivalent circuit model
KW  - Magnetic equivalent circuits
KW  - No load
KW  - Piecewise linearization
KW  - Saturation characteristic
KW  - Single phasis
KW  - Single-phase four-limb transformer
KW  - Unified magnetic equivalent circuit
KW  - Deflection yokes
PB  - Science Press
SN  - 10036520 (ISSN)
LA  - Chinese
J2  - Gaodianya Jishu
M3  - Article
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 1; Correspondence Address: G. Liu; Hebei Provincial Key Laboratory of Power Transmission Equipment Security Defense, North China Electric Power University, Baoding, 071003, China; email: liugang_em@163.com; CODEN: GAJIE
ER  -

TY  - CONF
AU  - Banar, B.
AU  - Colton, S.
TI  - A Systematic Evaluation of GPT-2-Based Music Generation
PY  - 2022
T2  - Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)
VL  - 13221 LNCS
SP  - 19
EP  - 35
DO  - 10.1007/978-3-031-03789-4_2
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85128884114&doi=10.1007%2f978-3-031-03789-4_2&partnerID=40&md5=af3ea6d7dc93ac27c30880c3fe5bbff8
AD  - School of EECS, Queen Mary University of London, London, E1 4NS, United Kingdom
AB  - There have been various generative music applications recently which employ a pre-trained transformer neural model. The way in which these models are trained greatly effects the nature of the music they produce, but there has been little exploration of the extent of this phenomenon. We provide here a systematic evaluation of the output from GPT-2-based transformer models by analysing, comparing and contrasting the output from multiple models trained under various conditions, with reference to numerous musical metrics. As a further element of our methodology, we describe a web application for exploring the output of such models. We conclude with a summary of our findings on how training effects output, a discussion around how our methodology could be used in generative music practice, and future avenues for research. © 2022, The Author(s), under exclusive license to Springer Nature Switzerland AG.
KW  - Deep learning
KW  - Generative music
KW  - Music generation evaluation
KW  - Transfer learning
KW  - Transformers
KW  - Computer music
KW  - Deep learning
KW  - Deep learning
KW  - Generative musics
KW  - Multiple-modeling
KW  - Music applications
KW  - Music generation evaluation
KW  - Neural modelling
KW  - Systematic evaluation
KW  - Transfer learning
KW  - Transformer
KW  - Transformer modeling
KW  - Music
A2  - Martins T.
A2  - Rodríguez-Fernández N.
A2  - Rebelo S.M.
PB  - Springer Science and Business Media Deutschland GmbH
SN  - 03029743 (ISSN); 978-303103788-7 (ISBN)
LA  - English
J2  - Lect. Notes Comput. Sci.
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 5; Correspondence Address: B. Banar; School of EECS, Queen Mary University of London, London, E1 4NS, United Kingdom; email: b.banar@qmul.ac.uk; Conference name: 11th International Conference on Artificial Intelligence in Music, Sound, Art and Design, EvoMUSART 2022, held as Part of EvoStar 2022; Conference date: 20 April 2022 through 22 April 2022; Conference code: 276819
ER  -

TY  - CONF
AU  - Yu, H.
AU  - Yu, Y.
AU  - Wang, M.
AU  - Xiong, W.
AU  - Yuan, X.
AU  - Zou, X.
TI  - A Power Transformer Condition Assessment Method Based on Fuzzy Nearness Degree and Improved Cloud Matter-element Model
PY  - 2021
T2  - Proceedings of 2021 IEEE 4th International Electrical and Energy Conference, CIEEC 2021
C7  - 9510875
DO  - 10.1109/CIEEC50170.2021.9510875
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85114204114&doi=10.1109%2fCIEEC50170.2021.9510875&partnerID=40&md5=cf63728c12d8e6a59a455f6eb2844228
AD  - Guizhou University, School of Electrical Engineering, Guiyang, China
AB  - In order to solve the problems of subjectivity, limitation of decision method and only considering the defect of single fuzziness in transformer condition assessment, a condition assessment method of power transformer based on fuzzy nearness degree and improved cloud matter-element model is proposed. Considering the randomness and fuzziness of transformer at the condition level boundary, the cloud matterelement model is used to construct the basic framework of condition assessment. Then, in order to take into account the clarity and fuzziness of the "3En"rule and the "50% association degree"rule, and to avoid conflicts of condition conclusions, cloud matter-element model is improved by cloud entropy optimization algorithm to calculate the membership degree of corresponding level of evaluation index. In addition, based on the multi-objective classification algorithm of fuzzy nearness degree, the evaluation index and asymmetric nearness degree vector of each condition level are calculated, the positive and negative ideal levels are determined by Technique for Order Preference by Similarity to Ideal Solution (TOPSIS), and the condition of the transformer is determined according to each asymmetric nearness degree vector and symmetric nearness degree of the positive and negative ideal levels. Taking two 220kV oil-immersed power transformers as examples, the validity and accuracy of the method are proved. © 2021 IEEE.
KW  - condition assessment
KW  - fuzzy nearness degree
KW  - ideal solution method
KW  - improved cloud matter-element model
KW  - power transformer
KW  - Fuzzy set theory
KW  - Fuzzy systems
KW  - Oil filled transformers
KW  - Condition assessments
KW  - Entropy optimization
KW  - Fuzzy nearness degree
KW  - Matter-element model
KW  - Multi-objective classification
KW  - Oil immersed power transformer
KW  - Technique for order preference by similarity to ideal solutions
KW  - Transformer condition assessment
KW  - Power transformers
PB  - Institute of Electrical and Electronics Engineers Inc.
SN  - 978-172817149-4 (ISBN)
LA  - English
J2  - Proc. IEEE Int. Electr. Energy Conf., CIEEC
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 2; Conference name: 4th IEEE China International Electrical and Energy Conference, CIEEC 2021; Conference date: 28 May 2021 through 30 May 2021; Conference code: 171287
ER  -

TY  - CONF
AU  - Mandhasiya, D.G.
AU  - Murfi, H.
AU  - Bustamam, A.
AU  - Anki, P.
TI  - Evaluation of Machine Learning Performance Based on BERT Data Representation with LSTM Model to Conduct Sentiment Analysis in Indonesian for Predicting Voices of Social Media Users in the 2024 Indonesia Presidential Election
PY  - 2022
T2  - ICOIACT 2022 - 5th International Conference on Information and Communications Technology: A New Way to Make AI Useful for Everyone in the New Normal Era, Proceeding
SP  - 441
EP  - 446
DO  - 10.1109/ICOIACT55506.2022.9972206
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85145350119&doi=10.1109%2fICOIACT55506.2022.9972206&partnerID=40&md5=dde2ecaeca8506ab1ec4ece6dcadc231
AD  - Universitas Indonesia, Department of Mathematics, Depok, Indonesia
AB  - In this era, the innovation of science and technology has changed rapidly, such as Artificial Intelligence (A.I.) which has helped a lot in human life. Deep learning (DL) as part of A.I. is the development of one of the machine learning models, namely the neural network. With many neural network layers, deep learning models can perform feature extraction and classification processes in a single architecture. This model has proven to perform state-of-the-art machine learning techniques in text classification, pattern recognition, speech, and imagery. Various text classification tasks, including sentiment analysis, have gone beyond AI-based approaches in Deep Learning models. Text data can come from multiple sources, including social media, such as comments on videos on YouTube. Sentiment analysis, one of the opinion mining, is a computational study that analyzes people's opinions from texts. In this research, machine learning performance analysis is carried out on a deep learning method based on BERT data representation with the LSTM method. The implementation of the model uses youtube commentary data on political videos related to the 2024 presidential election in Indonesia; performance analysis is carried out using accuracy, precision, and recall metrics. In this study, the accuracy of the BERT-LSTM model outperformed the BERT model with an accuracy of 0.8783.  © 2022 IEEE.
KW  - BERT
KW  - LSTM
KW  - Machine Learning
KW  - NLP
KW  - Sentiment Analysis
KW  - Classification (of information)
KW  - Learning systems
KW  - Long short-term memory
KW  - Multilayer neural networks
KW  - Network layers
KW  - Social networking (online)
KW  - Speech recognition
KW  - BERT
KW  - Data representations
KW  - Indonesia
KW  - Learning performance
KW  - LSTM
KW  - Machine-learning
KW  - Neural-networks
KW  - Presidential election
KW  - Sentiment analysis
KW  - Social media
KW  - Sentiment analysis
PB  - Institute of Electrical and Electronics Engineers Inc.
SN  - 978-166545140-6 (ISBN)
LA  - English
J2  - ICOIACT - Int. Conf. Inf. Commun. Technol.: A New Way Make AI Useful Everyone New Norm. Era, Proceeding
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 0; Conference name: 5th International Conference on Information and Communications Technology, ICOIACT 2022; Conference date: 24 August 2022 through 25 August 2022; Conference code: 185076
ER  -

TY  - CONF
AU  - Zhu, P.
AU  - Hauff, C.
TI  - Evaluating BERT-based Rewards for Question Generation with Reinforcement Learning
PY  - 2021
T2  - ICTIR 2021 - Proceedings of the 2021 ACM SIGIR International Conference on Theory of Information Retrieval
SP  - 261
EP  - 270
DO  - 10.1145/3471158.3472240
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85114464513&doi=10.1145%2f3471158.3472240&partnerID=40&md5=01c363f874fd2d1f928aac9e5bd1eea1
AD  - Delft University of Technology, Delft, Netherlands
AB  - Question generation systems aim to generate natural language questions that are relevant to a given piece of text, and can usually be answered by just considering this text. Prior works have identified a range of shortcomings (including semantic drift and exposure bias) and thus have turned to the reinforcement learning paradigm to improve the effectiveness of question generation. As part of it, different reward functions have been proposed. As typically these reward functions have been empirically investigated in different experimental settings (different datasets, models and parameters) we lack a common framework to fairly compare them. In this paper, we first categorize existing rewards systematically. We then provide such a fair empirical evaluation of different reward functions (including three we propose here for QG) in a common framework. We find rewards that model answerability to be the most effective.  © 2021 ACM.
KW  - question generation
KW  - reinforcement learning
KW  - reward functions
KW  - Function evaluation
KW  - Information retrieval
KW  - Semantics
KW  - Empirical evaluations
KW  - Generation systems
KW  - Natural language questions
KW  - Reward function
KW  - Semantic drifts
KW  - Reinforcement learning
PB  - Association for Computing Machinery, Inc
SN  - 978-145038611-1 (ISBN)
LA  - English
J2  - ICTIR - Proc. ACM SIGIR Int. Conf. Theory Inf. Retr.
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 2; Conference name: 11th ACM SIGIR International Conference on Theory of Information Retrieval, ICTIR 2021; Conference code: 171505
ER  -

TY  - JOUR
AU  - Zou, Y.
AU  - He, J.
AU  - Jin, T.
TI  - Evaluation model of transformer oil-paper insulation based on neighborhood rough set and dempster-shafer evidence theory
ST  - 基于NRS和D-S证据理论的变压器油纸绝缘状态评估模型
PY  - 2021
T2  - Dianji yu Kongzhi Xuebao/Electric Machines and Control
VL  - 25
IS  - 10
SP  - 89
EP  - 96
DO  - 10.15938/j.emc.2021.10.010
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85118734242&doi=10.15938%2fj.emc.2021.10.010&partnerID=40&md5=f8663210f23801adc2c4837e3ec91873
AD  - College of Electrical Engineering and Automation, Fuzhou University, Fuzhou, 350108, China
AB  - An effective assessment method of transformer oil-paper insulation is of guiding significance for making a reasonable maintenance plan. In order to accurately diagnose the oil-paper insulation state, this paper proposes an evaluation model based on neighborhood rough set (NRS) and D-S evidence theory. The construction of the model is based on the multi-characteristics evaluation database of the recovery voltage method, and the evidence fusion theory is used to calculate the confidence of the insulation state proposition, which overcomes the one-sidedness of the evaluation method using single characteristic. At the same time, according to the definition of upper and lower approximation in NRS, a basic reliability allocation method based on database is proposed to reduce the influence of subjective factors. In view of the different sensitivities of the feature quantity in reflecting the insulation state, the objective weight based on attribute importance and the subjective weight based on expert experience are synthesized through the combination weighting method, which strengthens the rationality of weight distribution. Finally, the measured data of multiple transformers with different furfural content which are not in the database are calculated by examples. The results show that the distribution of confidence in the insulation state proposition accurately reflects the actual insulation state of the transformer, and its deterioration trend, and provides a reference for the formulation of maintenance strategies. © 2021, Harbin University of Science and Technology Publication. All right reserved.
KW  - Evidence theory
KW  - Extended Debye model
KW  - Neighborhood rough set
KW  - Oil paper insulation
KW  - Recovery voltage method
KW  - State evaluation
KW  - Approximation algorithms
KW  - Database systems
KW  - Deterioration
KW  - Oil filled transformers
KW  - Rough set theory
KW  - Debye models
KW  - Dempster Shafer evidence theory
KW  - Evaluation models
KW  - Evidence theories
KW  - Extended debye model
KW  - Guiding significances
KW  - Neighborhood rough sets
KW  - Oil/paper insulation
KW  - Recovery voltage methods
KW  - State evaluation
KW  - Insulation
PB  - Editorial Department of Electric Machines and Control
SN  - 1007449X (ISSN)
LA  - Chinese
J2  - Dianji yu Kongzhi Xuebao
M3  - Article
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 3
ER  -

TY  - CHAP
AU  - Tran, L.
AU  - Velazquez, E.
AU  - Sips, R.-J.
AU  - De Boer, V.
TI  - Evaluating medical lexical simplification: Rule-based vs. BERT
PY  - 2021
T2  - Public Health and Informatics: Proceedings of MIE 2021
SP  - 1023
EP  - 1024
DO  - 10.3233/SHTI210337
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85107238009&doi=10.3233%2fSHTI210337&partnerID=40&md5=5a979245b441159719b3bc1ac4c7be27
AD  - Vrije Universiteit, Amsterdam, Netherlands
AD  - myTomorrows, Amsterdam, Netherlands
AB  - Lexical simplification (LS) can decrease the communication gap between medical experts and laypeople by replacing medical terms with layperson counterparts. In this paper, we present: 1) a rule-based approach to LS using a consumer health vocabulary, and 2) an unsupervised approach using BERT to generate word candidates. Human evaluation shows that the unsupervised model performed better for simplicity and grammaticality, while the rule-based method was better at meaning preservation. © 2021 European Federation for Medical Informatics (EFMI) and IOS Press. © 2021 European Federation for Medical Informatics (EFMI) and IOS Press. All rights reserved.
KW  - Health Vocabulary
KW  - Lexical Simplification
KW  - Machine Learning
KW  - Communication
KW  - Humans
KW  - Research Design
KW  - Vocabulary
KW  - Vocabulary, Controlled
KW  - controlled vocabulary
KW  - human
KW  - interpersonal communication
KW  - methodology
KW  - vocabulary
PB  - IOS Press
SN  - 978-164368185-6 (ISBN); 978-164368184-9 (ISBN)
C2  - 34042832
LA  - English
J2  - Public Health and Inform.: Proc. of MIE 2021
M3  - Book chapter
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 2; Correspondence Address: L. Tran; Vrije Universiteit, Amsterdam, Netherlands; email: trplinh@gmail.com
ER  -

TY  - CONF
AU  - Hung, J.-W.
AU  - Lin, J.-R.
AU  - Zhuang, L.-Y.
TI  - The Evaluation Study of the Deep Learning Model Transformer in Speech Translation
PY  - 2021
T2  - 2021 7th International Conference on Applied System Innovation, ICASI 2021
SP  - 30
EP  - 33
DO  - 10.1109/ICASI52993.2021.9568450
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85118572660&doi=10.1109%2fICASI52993.2021.9568450&partnerID=40&md5=81d4bd5f2a739ee81102108e76c364fb
AD  - National Chi Nan University, Nantou, Taiwan
AB  - Neural machine translation (NMT) employs the prevailing deep learning techniques to build a single deep neural network (DNN) that directly maps the input speech utterances of one language to the corresponding texts of the other language. Compared with the conventional statistical machine translation, which separately optimizes each component model (such as acoustic models and language models) in series, NMT can learn the used DNN to directly maximize the overall translation performance. In particular, a novel encoder-decoder DNN structure termed transformer, which Google develops, has been applied in NMT and revealed outstanding translation performance. In this study, we investigate and evaluate the Transformer-based speech translation algorithm by varying the model settings in the training process of the used Transformer. The experiments follow a tutorial script provided in the Tensorflow forum, which are conducted on the TED talk dataset to translate Portuguese to English, which consists of 50,000 utterances for training, 1,100 utterances for validation, and 2,000 utterances for testing. The baseline system, which sets the encoding dimension as 128, the number of encoder/decoder layers as 4, the dropout rate as 0.1 and the negative exponent as -1.5, gives rise to 68.01% in translation accuracy. While the encoding dimension is increased to be 512, the translation accuracy can be promoted to be 76.02%. Also, changing the number of layers to be 2, the dropout rate to be 0.01 and the negative exponent to be 1 can achieve 70.98%, 80.97% and 75.40% in translation accuracy, respectively. The experimental results indicate that we can further improve the translation performance of the transformer by properly arranging the underlying hyper-parameters.  © 2021 IEEE.
KW  - neural machine translation
KW  - speech translation
KW  - transformer
KW  - translation accuracy
KW  - Computational linguistics
KW  - Computer aided language translation
KW  - Deep neural networks
KW  - Encoding (symbols)
KW  - Signal encoding
KW  - Speech recognition
KW  - Speech transmission
KW  - Statistical tests
KW  - Encoder-decoder
KW  - Evaluation study
KW  - Learning models
KW  - Learning techniques
KW  - Model transformers
KW  - Negative exponents
KW  - Performance
KW  - Speech translation
KW  - Transformer
KW  - Translation accuracy
KW  - Neural machine translation
A2  - Chang S.-J.
A2  - Young S.-J.
A2  - Kin-Tak Lam A.D.
A2  - Ji L.-W.
A2  - Prior S.D.
PB  - Institute of Electrical and Electronics Engineers Inc.
SN  - 978-166544143-8 (ISBN)
LA  - English
J2  - Int. Conf. Appl. Syst. Innov., ICASI
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 4; Conference name: 7th International Conference on Applied System Innovation, ICASI 2021; Conference date: 24 September 2021 through 25 September 2021; Conference code: 173107
ER  -

TY  - CONF
AU  - Walker, C.
AU  - Walker, D.
TI  - Creation & Validation of Transformer Residual Life Models
PY  - 2022
T2  - Proceedings - IEEE International Conference on Dielectric Liquids
VL  - 2022-May
DO  - 10.1109/ICDL49583.2022.9830925
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85135791040&doi=10.1109%2fICDL49583.2022.9830925&partnerID=40&md5=1204a315a7db422cfd10c3ab2eff5e27
AD  - Sp Energy Networks, United Kingdom
AB  - The ageing process of power transformers is a complex mechanism, which means condition and health assessment of these critical assets is a challenging task. While transformers are in-service, obtaining paper samples for direct analysis cannot easily be achieved, meaning the only practical way of assessing the state of degradation of the paper insulation is through prediction models. In recent years SP Energy Networks have made a significant investment in their ageing transformer fleet by systematically carrying out post-mortems on all power transformers as they are removed and retired from service. These post-mortems allow comparison between the estimated degree of polymerisation (DP), that was calculated from oil sample results and the real DP measured during the Post-mortem. Predicted DP and residual life is one of the main criteria for condition assessment, and ultimately the decision to retire a transformer. However, analysis of the retired transformer paper samples typically indicated that the actual DP results vary and are inconsistent with the estimated DP values, and that in the majority of cases transformers were being retired from service with significant residual life left in the solid insulation. The purpose of this research is to determine the best prediction model for estimating DP and from this to create a new more precise model for SPEN fleet condition assessment. The potential additional benefits that come with the creation of a new more accurate model to predicted DP include the deference of capital expenditure on new transformers, ability to maximize asset life and provide better value to customers and shareholders. For the purposes of this research, 38 transformers and 14 different models were used in total, each tested against the actual DP values and 2-FAL history found within the post-mortem reports provided by SPEN.  © 2022 IEEE.
KW  - charge generation
KW  - Charge injection
KW  - Field-dependent conductivity
KW  - Pre-inception currents
KW  - Streamers
KW  - Investments
KW  - Oil filled transformers
KW  - Paper
KW  - 'current
KW  - Charge generation
KW  - Condition assessments
KW  - Degrees of polymerizations
KW  - Field dependent conductivity
KW  - Paper samples
KW  - Post mortem
KW  - Pre-inception current
KW  - Residual life
KW  - Streamer
KW  - Power transformers
PB  - IEEE Computer Society
SN  - 21533725 (ISSN); 978-166548491-6 (ISBN)
LA  - English
J2  - Proc. IEEE Int. Conf. Dielectr. Liq.
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 2; Conference name: 21st IEEE International Conference on Dielectric Liquids, ICDL 2022; Conference date: 29 May 2022 through 2 June 2022; Conference code: 181351
ER  -

TY  - JOUR
AU  - Pota, M.
AU  - Ventura, M.
AU  - Fujita, H.
AU  - Esposito, M.
TI  - Multilingual evaluation of pre-processing for BERT-based sentiment analysis of tweets
PY  - 2021
T2  - Expert Systems with Applications
VL  - 181
C7  - 115119
DO  - 10.1016/j.eswa.2021.115119
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85106937552&doi=10.1016%2fj.eswa.2021.115119&partnerID=40&md5=09c5cc2b621ff6c9e8e90038e5ab5803
AD  - Institute for High Performance Computing and Networking (ICAR), National Research Council, Naples, Italy
AD  - Faculty of Information Technology, Ho Chi Minh City University of Technology (HUTECH), Ho Chi Minh City, Viet Nam
AD  - National Taipei University of Technology, Taipei, Taiwan
AD  - i-somet Incorporation association, Morioka, Japan
AB  - Social media offer a big amount of information, to exploit in many fields of research. However, while methods for Natural Language Processing are being developed with good results when applied to well-formed datasets made of written text with a clear syntax, these sources present text written in informal language, unstructured syntax, and with peculiar symbols; therefore, particular approaches are required for text processing in this case. In this paper, the task of sentiment analysis of tweets is regarded. In particular, in order to avoid noise constituted by some web constructs like URLs and mentions and by other text fragments, and to exploit information hidden in symbols like emoticons, emojis and hashtags, the pre-processing of tweets is analyzed. More in detail, a number of experiments, performed by a state-of-the-art classification model (BERT), are designed, to evaluate many currently available operations for pre-processing tweets, in terms of the statistical significance of their influence on sentiment analysis performances. Moreover, available data in two languages are considered, i.e., English and Italian, in order to also evaluate dependence on the language. Results allow to individuate the most convenient strategy to pre-process tweets, and thus to improve the state of the art in both languages for the considered task of sentiment analysis. © 2021 Elsevier Ltd
KW  - English
KW  - Italian
KW  - Pre-processing
KW  - Sentiment analysis
KW  - Twitter
KW  - Social networking (online)
KW  - Syntactics
KW  - Amount of information
KW  - English
KW  - Italian
KW  - Language processing
KW  - Natural languages
KW  - Pre-processing
KW  - Sentiment analysis
KW  - Social media
KW  - State of the art
KW  - Written texts
KW  - Sentiment analysis
PB  - Elsevier Ltd
SN  - 09574174 (ISSN)
LA  - English
J2  - Expert Sys Appl
M3  - Article
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 51; Correspondence Address: M. Pota; Institute for High Performance Computing and Networking (ICAR), National Research Council, Naples, Italy; email: marco.pota@icar.cnr.it; CODEN: ESAPE
ER  -

TY  - CONF
AU  - Lebron, L.
AU  - Graham, Y.
AU  - O'Connor, N.E.
AU  - McGuinness, K.
TI  - EVALUATION OF AUTOMATICALLY GENERATED VIDEO CAPTIONS USING VISION AND LANGUAGE MODELS
PY  - 2022
T2  - Proceedings - International Conference on Image Processing, ICIP
SP  - 2416
EP  - 2420
DO  - 10.1109/ICIP46576.2022.9897559
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85146641863&doi=10.1109%2fICIP46576.2022.9897559&partnerID=40&md5=50aeb12e92dd51912f01341271260a08
AD  - Insight SFI Research Centre for Data Analytics, Dublin City University (DCU), Ireland
AD  - School of Computer Science and Statistics, Trinity College Dublin, Ireland
AB  - Vision and language models are easily transferred to other tasks. In particular, they have been demonstrated to work well in the evaluation of automatic image captioning. This has made it possible to evaluate systems without the need for references or additional information apart from the image and the caption. However, these models do not provide a straightforward way of evaluating videos. In this paper, we propose using these models for video captioning evaluation. We explore the use of both single image-based evaluation and different methods to include data from multiple frames. Experiments demonstrate that using clustering methods to select a few frames to compute the final score gives an excellent correlation with human judgment. The bias in the human annotations can also influence the metric, so we propose filtering the human assessments to discard outliers and improve the evaluation process. © 2022 IEEE.
KW  - Clustering
KW  - Transformers
KW  - Video Captioning
KW  - Video Captioning Evaluation
KW  - Vision and Language Models
KW  - Computer vision
KW  - Petroleum reservoir evaluation
KW  - Automatic image captioning
KW  - Automatically generated
KW  - Clusterings
KW  - Language model
KW  - Single images
KW  - Transformer
KW  - Video captioning
KW  - Video captioning evaluation
KW  - Video captions
KW  - Vision model
KW  - Computational linguistics
PB  - IEEE Computer Society
SN  - 15224880 (ISSN); 978-166549620-9 (ISBN)
LA  - English
J2  - Proc. Int. Conf. Image Process. ICIP
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 0; Correspondence Address: L. Lebron; Insight SFI Research Centre for Data Analytics, Dublin City University (DCU), Ireland; email: luis.lebroncasas@insight-centre.org; ; ; Conference name: 29th IEEE International Conference on Image Processing, ICIP 2022; Conference date: 16 October 2022 through 19 October 2022; Conference code: 185922
ER  -

TY  - CONF
AU  - Jang, J.
AU  - Ye, S.
AU  - Lee, C.
AU  - Yang, S.
AU  - Shin, J.
AU  - Han, J.
AU  - Kim, G.
AU  - Seo, M.
TI  - TemporalWiki: A Lifelong Benchmark for Training and Evaluating Ever-Evolving Language Models
PY  - 2022
T2  - Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing, EMNLP 2022
SP  - 6237
EP  - 6250
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85144265982&partnerID=40&md5=60bb25d8b866f2d9f80cfcc3408197c1
AD  - KAIST, South Korea
AD  - LG AI Research
AD  - Korea University, South Korea
AB  - Language Models (LMs) become outdated as the world changes; they often fail to perform tasks requiring recent factual information which was absent or different during training, a phenomenon called temporal misalignment. This is especially a challenging problem because the research community still lacks a coherent dataset for assessing the adaptability of LMs to frequently-updated knowledge corpus such as Wikipedia. To this end, we introduce TEMPORALWIKI, a lifelong benchmark for ever-evolving LMs that utilizes the difference between consecutive snapshots of English Wikipedia and English Wikidata for training and evaluation, respectively. The benchmark hence allows researchers to periodically track an LM's ability to retain previous knowledge and acquire updated/new knowledge at each point in time. We also find that training an LM on the diff data through continual learning methods achieves similar or better perplexity than on the entire snapshot in our benchmark with 12 times less computational cost, which verifies that factual knowledge in LMs can be safely updated with minimal training data via continual learning. The dataset and the code is made available at this link. © 2022 Association for Computational Linguistics.
KW  - Learning systems
KW  - Computational costs
KW  - Continual learning
KW  - Factual information
KW  - Factual knowledge
KW  - Language model
KW  - Learning methods
KW  - Minimal training
KW  - Research communities
KW  - Training data
KW  - Wikipedia
KW  - Computational linguistics
A2  - Goldberg Y.
A2  - Kozareva Z.
A2  - Zhang Y.
PB  - Association for Computational Linguistics (ACL)
LA  - English
J2  - Proc. Conf. Empir. Methods Nat. Lang. Process., EMNLP
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 7; Conference name: 2022 Conference on Empirical Methods in Natural Language Processing, EMNLP 2022; Conference date: 7 December 2022 through 11 December 2022; Conference code: 186895
ER  -

TY  - CONF
AU  - Zhang, S.
AU  - Li, P.
TI  - Unmasking the Stereotypes: Evaluating Social Biases in Chinese BERT
PY  - 2022
T2  - Proceedings - 2022 4th International Conference on Natural Language Processing, ICNLP 2022
SP  - 324
EP  - 330
DO  - 10.1109/ICNLP55136.2022.00059
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85139430508&doi=10.1109%2fICNLP55136.2022.00059&partnerID=40&md5=06e7b27665a9332369911ef05eed112a
AD  - Tsinghua University, Shenzhen International Gratuate School, Shenzhen, China
AD  - Institute of Science, Technology & Society Tsinghua University, Beijing, China
AB  - Pretrained language models like BERT have great performances in various NLP tasks. However, recent researches have shown that language model can learn social biases from corpus. We designed a new bias evaluation experiment, and made the first attempt to evaluate social bias in Chinese BERT. Instead of pursuing absolute fairness in numbers, we compared BERT's bias performances after fine-tuning on different contexts to study whether the model encode social biases. After adopting Predicted Likelihood Probability (PLP) and All Unmasked Likelihood (AUL) for bias measurement, we found original Chinese BERT reflects the real-world stereotypes of gender, like IT jobs are more suitable for male. We found Chinese BERT demonstrate significant biases, as with the increase of proportion of male-dominated sentences in the training set, BERT is more favorable to males after fine-tuning. Our result suggests that social biases are also encoded in Chinese language models, and one of the effective ways to mitigate bias is fine-tuning model on a gender-balanced corpus, although this method may not be robust enough.  © 2022 IEEE.
KW  - BERT
KW  - bias measurement
KW  - fine-tune
KW  - occupational gender bias
KW  - social bias
KW  - BERT
KW  - Bias measurement
KW  - Fine tuning
KW  - Fine-tune
KW  - Gender bias
KW  - Language model
KW  - Occupational gender bias
KW  - Performance
KW  - Recent researches
KW  - Social bias
KW  - Computational linguistics
PB  - Institute of Electrical and Electronics Engineers Inc.
SN  - 978-166549544-8 (ISBN)
LA  - English
J2  - Proc. - Int. Conf. Nat. Lang. Process., ICNLP
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 0; Conference name: 4th International Conference on Natural Language Processing, ICNLP 2022; Conference date: 25 March 2022 through 27 March 2022; Conference code: 182901
ER  -

TY  - CONF
AU  - Wu, X.
AU  - Wang, P.
AU  - Wang, L.
AU  - Xu, Y.
AU  - Zhao, Z.
TI  - Transformer Combination Weighting Evaluation Model Based on BP Neural Network
PY  - 2022
T2  - Lecture Notes in Electrical Engineering
VL  - 833 LNEE
SP  - 341
EP  - 349
DO  - 10.1007/978-981-16-8430-2_31
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85123311170&doi=10.1007%2f978-981-16-8430-2_31&partnerID=40&md5=f94ef8229f77ee8ab04584c0002f32c8
AD  - State Grid Hangzhou Power Supply Company, Zhejiang, Hangzhou, 310000, China
AD  - Hangzhou Power Equipment Manufacturing Co., Ltd., Zhejiang, Hangzhou, 310000, China
AD  - School of Information Technology, Zhejiang Gongshang University, Zhejiang, Hangzhou, 310000, China
AB  - The structure of the power transformer is complex, and there are many indicators that characterize the state. It is necessary to integrate multi-dimensional information indicators to get a comprehensive and scientific evaluation conclusion. The analytic hierarchy process is one of the main methods to solve multi-factor decision-making. It uses a hierarchical way to describe more complex problems, which can effectively mine the information between the transformer's multi-dimensional indicators, and combine quantitative and qualitative analysis to ensure The integrity of the data. The importance of power transformer indexes is quite different. In order to obtain more accurate index weights, the influence of expert experience and data distribution must be considered. This paper establishes an analytic hierarchy model that integrates transformer multi-dimensional information, uses fuzzy analytic hierarchy process to obtain subjective weights, uses improved entropy weight method to calculate objective weights, combines subjective and objective weights, and uses BP neural network to learn the nonlinear mapping of state evaluation Relationship, established a transformer state evaluation model based on the combination weighting method. © 2022, The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd.
KW  - BP neural network
KW  - Condition assessment
KW  - Transformer
KW  - Complex networks
KW  - Decision making
KW  - Neural networks
KW  - Power transformers
KW  - BP neural networks
KW  - Combination weighting
KW  - Condition assessments
KW  - Evaluation models
KW  - Model-based OPC
KW  - Multi dimensional
KW  - Objective weight
KW  - State evaluation
KW  - Subjective weights
KW  - Transformer
KW  - Analytic hierarchy process
A2  - Chu S.
A2  - Lin J.C.
A2  - Li J.
A2  - Pan J.
PB  - Springer Science and Business Media Deutschland GmbH
SN  - 18761100 (ISSN); 978-981168429-6 (ISBN)
LA  - English
J2  - Lect. Notes Electr. Eng.
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 1; Correspondence Address: X. Wu; Hangzhou Power Equipment Manufacturing Co., Ltd., Hangzhou, Zhejiang, 310000, China; email: 1084610669@qq.com; Conference name: 14th International Conference on Genetic and Evolutionary Computing, ICGEC 2021; Conference date: 21 October 2021 through 23 October 2021; Conference code: 270849
ER  -

TY  - CONF
AU  - Córdova Sáenz, C.A.
AU  - Becker, K.
TI  - Assessing the use of attention weights to interpret BERT-based stance classification
PY  - 2021
T2  - ACM International Conference Proceeding Series
SP  - 194
EP  - 201
DO  - 10.1145/3486622.3493966
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85128665151&doi=10.1145%2f3486622.3493966&partnerID=40&md5=fbf9beb48f6c7a79608b321294ed351b
AD  - Informatics Institute, Universidade Federal Do Rio Grande Do sul (UFRGS), Rio Grande do Sul, Porto Alegre, Brazil
AB  - BERT models are currently state-of-the-art solutions for various tasks, including stance classification. However, these models are a black box for their users. Some proposals have leveraged the weights assigned by the internal attention mechanisms of these models for interpretability purposes. However, whether the attention weights help the interpretability of the model is still a matter of debate, with positions in favor and against. This work proposes an attention-based interpretability mechanism to identify the most influential words for stances predicted using BERT-based models. We target stances expressed in Twitter using the Portuguese language and assess the proposed mechanism using a case study regarding stances on COVID-19 vaccination in the Brazilian context. The interpretation mechanism traces tokens' attentions back to words, assigning a newly proposed metric referred to as absolute word attention. Through this metric, we assess several aspects to determine if we can find important words for the classification and with meaning for the domain. We developed a broad experimental setting that involved three datasets with tweets in Brazilian Portuguese and three BERT models with support for this language. Our results are encouraging, as we were able to identify 52-82% of words with high absolute attention contributing positively to stance classification. The interpretability mechanism proved to be helpful to understand the influence of words in the classification, and they revealed intrinsic properties of the domain and representative arguments of the stances.  © 2021 ACM.
KW  - BERT
KW  - BERT attention weights
KW  - interpretability
KW  - stance classification
KW  - Attention mechanisms
KW  - BERT
KW  - BERT attention weight
KW  - Black boxes
KW  - Case-studies
KW  - Interpretability
KW  - Intrinsic property
KW  - Portuguese languages
KW  - Stance classification
KW  - State of the art
PB  - Association for Computing Machinery
SN  - 978-145039115-3 (ISBN)
LA  - English
J2  - ACM Int. Conf. Proc. Ser.
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 2; Conference name: 2021 IEEE/WIC/ACM International Conference on Web Intelligence and Intelligent Agent Technology, WI-IAT 2021; Conference date: 14 December 2021 through 17 December 2021; Conference code: 178753
ER  -

TY  - JOUR
AU  - Silva-Ortega, J.I.
AU  - Holguin-Torres, Y.
AU  - Fernández-Flórez, A.F.
AU  - Candelo-Becerra, J.E.
AU  - Villacob-Pineda, K.J.
TI  - Follow-Up Model to Evaluate Failure Factors of Single-Phase Distribution Transformers in High Environmental Pollution Zones
PY  - 2022
T2  - International Review of Electrical Engineering
VL  - 17
IS  - 4
SP  - 360
EP  - 370
DO  - 10.15866/iree.v17i4.20084
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85141862434&doi=10.15866%2firee.v17i4.20084&partnerID=40&md5=bcd50edb7c86716c0103ea7f8493fad3
AD  - Universidad de la Costa, Barranquilla, Colombia
AD  - Universidad Nacional de Colombia, Sede Medellín, Facultad de Minas, Departamento de Energía Eléctrica y Automática., Colombia
AB  - – Single-phase distribution transformers are commonly installed in outdoor distribution networks to supply electricity to final users. Utilities are used to receive abnormal operating reports related to typical failures that negatively affect the reliability and security indicators. Therefore, a follow-up model is proposed in this paper to evaluate the failure factors of distribution transformers installed in high environmental pollution zones. The results show that the main factors that cause failures are overload, overvoltage, overcurrent, moisture, hot spots, manufacturing process, and lack of technical knowledge. Furthermore, all those factors are presented in a typical case using time-lines diagrams to characterize the main failures. Finally, hot spots, overloads, and unauthorized connections are the most critical failure factors identified in the research. According to the statistical analysis, those failures could occur 16 days after installing the transformer. The follow-up model presented in this research can characterize the main failures presented in outdoor distribution transformers. © 2022 Praise Worthy Prize S.r.l.-All rights reserved.
KW  - Distribution Network
KW  - Distribution Transformers
KW  - Environmental Pollution
KW  - Failure Factors
KW  - Reliability
PB  - Praise Worthy Prize S.r.l
SN  - 18276660 (ISSN)
LA  - English
J2  - Int. Rev. Elec. Eng.
M3  - Article
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 0; Correspondence Address: J.I. Silva-Ortega; Universidad de la Costa, Barranquilla, Colombia; email: jsilva6@cuc.edu.co
ER  -

TY  - CONF
AU  - Lakim, I.
AU  - Almazrouei, E.
AU  - Alhaol, I.A.
AU  - Debbah, M.
AU  - Launay, J.
TI  - A Holistic Assessment of the Carbon Footprint of Noor, a Very Large Arabic Language Model
PY  - 2022
T2  - 2022 Challenges and Perspectives in Creating Large Language Models, Proceedings of the Workshop
SP  - 84
EP  - 94
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85134844660&partnerID=40&md5=2f74a2ec7681263a56ee520e2a99edc6
AD  - TII, Abu Dhabi, United Arab Emirates
AD  - LightOn, Paris, France
AB  - As ever larger language models grow more ubiquitous, it is crucial to consider their environmental impact. Characterised by extreme size and resource use, recent generations of models have been criticised for their voracious appetite for compute, and thus significant carbon footprint. Although reporting of carbon impact has grown more common in machine learning papers, this reporting is usually limited to compute resources used strictly for training. In this work, we propose a holistic assessment of the footprint of an extreme-scale language model, Noor. Noor is an ongoing project aiming to develop the largest multi-task Arabic language models-with up to 13B parameters-leveraging zero-shot generalisation to enable a wide range of downstream tasks via natural language instructions. We assess the total carbon bill of the entire project: starting with data collection and storage costs, including research and development budgets, pretraining costs, future serving estimates, and other exogenous costs necessary for this international cooperation. Notably, we find that inference costs and exogenous factors can have a significant impact on total budget. Finally, we discuss pathways to reduce the carbon footprint of extreme-scale models. © 2022 Association for Computational Linguistics.
KW  - Budget control
KW  - Carbon footprint
KW  - Computational linguistics
KW  - Cost benefit analysis
KW  - Environmental impact
KW  - International cooperation
KW  - Arabic languages
KW  - Compute resources
KW  - Down-stream
KW  - Extreme scale
KW  - Generalisation
KW  - Language model
KW  - Machine-learning
KW  - Multi tasks
KW  - Natural languages
KW  - Resource use
KW  - Digital storage
A2  - Fan A.
A2  - Ilic S.
A2  - Wolf T.
A2  - Galle M.
PB  - Association for Computational Linguistics (ACL)
SN  - 978-195591726-1 (ISBN)
LA  - English
J2  - Challenges Perspect. Creat. Large Lang. Model., Proc. Workshop
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 6; Conference name: 2022 Challenges and Perspectives in Creating Large Language Models; Conference code: 181973
ER  -

TY  - CONF
AU  - Lamproudis, A.
AU  - Henriksson, A.
AU  - Dalianis, H.
TI  - Evaluating Pretraining Strategies for Clinical BERT Models
PY  - 2022
T2  - 2022 Language Resources and Evaluation Conference, LREC 2022
SP  - 410
EP  - 416
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85137943977&partnerID=40&md5=e2534f81008a062856d7bee2b73ddd3b
AD  - Department of Computer and Systems Sciences (DSV), Stockholm University, Kista, Sweden
AB  - Research suggests that using generic language models in specialized domains may be sub-optimal due to significant domain differences. As a result, various strategies for developing domain-specific language models have been proposed, including techniques for adapting an existing generic language model to the target domain, e.g. through various forms of vocabulary modifications and continued domain-adaptive pretraining with in-domain data. Here, an empirical investigation is carried out in which various strategies for adapting a generic language model to the clinical domain are compared to pretraining a pure clinical language model. Three clinical language models for Swedish, pretrained for up to ten epochs, are fine-tuned and evaluated on several downstream tasks in the clinical domain. A comparison of the language models' downstream performance over the training epochs is conducted. The results show that the domain-specific language models outperform a general-domain language model, although there is little difference in performance between the various clinical language models. However, compared to pretraining a pure clinical language model with only in-domain data, leveraging and adapting an existing general-domain language model requires fewer epochs of pretraining with in-domain data. © European Language Resources Association (ELRA), licensed under CC-BY-NC-4.0.
KW  - domain-adaptive pretraining
KW  - language models
KW  - Swedish clinical text
KW  - Problem oriented languages
KW  - Domain differences
KW  - Domain language
KW  - Domain-adaptive pretraining
KW  - Domains specific languages
KW  - Down-stream
KW  - Language model
KW  - Performance
KW  - Pre-training
KW  - Swedish clinical text
KW  - Swedishs
KW  - Computational linguistics
A2  - Calzolari N.
A2  - Bechet F.
A2  - Blache P.
A2  - Choukri K.
A2  - Cieri C.
A2  - Declerck T.
A2  - Goggi S.
A2  - Isahara H.
A2  - Maegaard B.
A2  - Mariani J.
A2  - Mazo H.
A2  - Odijk J.
A2  - Piperidis S.
PB  - European Language Resources Association (ELRA)
SN  - 979-109554672-6 (ISBN)
LA  - English
J2  - Lang. Resour. Eval. Conf., LREC
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 6; Conference name: 13th International Conference on Language Resources and Evaluation Conference, LREC 2022; Conference date: 20 June 2022 through 25 June 2022; Conference code: 184830
ER  -

TY  - CONF
AU  - Frohberg, J.
AU  - Binder, F.
TI  - CRASS: A Novel Data Set and Benchmark to Test Counterfactual Reasoning of Large Language Models
PY  - 2022
T2  - 2022 Language Resources and Evaluation Conference, LREC 2022
SP  - 2126
EP  - 2140
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85143772115&partnerID=40&md5=d075a4b33e5ec7414c1b51a8db2e28f4
AD  - apergo UG
AD  - Institute for Applied Informatics, Leipzig University (InfAI), Germany
AB  - We introduce the CRASS (counterfactual reasoning assessment) data set and benchmark utilizing questionized counterfactual conditionals as a novel and powerful tool to evaluate large language models. We present the data set design and benchmark. We test six state-of-the-art models against our benchmark. Our results show that it poses a valid challenge for these models and opens up considerable room for their improvement. © European Language Resources Association (ELRA), licensed under CC-BY-NC-4.0.
KW  - common-sense reasoning
KW  - counterfactual conditionals
KW  - large language models
KW  - NLP
KW  - Computational linguistics
KW  - Natural language processing systems
KW  - ART model
KW  - Commonsense reasoning
KW  - Counterfactual conditional
KW  - Counterfactuals
KW  - Data set
KW  - Language model
KW  - Large language model
KW  - Set design
KW  - State of the art
KW  - Statistical tests
A2  - Calzolari N.
A2  - Bechet F.
A2  - Blache P.
A2  - Choukri K.
A2  - Cieri C.
A2  - Declerck T.
A2  - Goggi S.
A2  - Isahara H.
A2  - Maegaard B.
A2  - Mariani J.
A2  - Mazo H.
A2  - Odijk J.
A2  - Piperidis S.
PB  - European Language Resources Association (ELRA)
SN  - 979-109554672-6 (ISBN)
LA  - English
J2  - Lang. Resour. Eval. Conf., LREC
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 3; Conference name: 13th International Conference on Language Resources and Evaluation Conference, LREC 2022; Conference date: 20 June 2022 through 25 June 2022; Conference code: 184830
ER  -

TY  - JOUR
AU  - Soleimani, M.
AU  - Kezunovic, M.
AU  - Butenko, S.
TI  - Linear Arrhenius-Weibull Model for Power Transformer Thermal Stress Assessment
PY  - 2022
T2  - IEEE Access
VL  - 10
SP  - 19013
EP  - 19021
DO  - 10.1109/ACCESS.2022.3150039
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85124755275&doi=10.1109%2fACCESS.2022.3150039&partnerID=40&md5=7a113e89c836350ea86e7b8636893e68
AD  - Electrical and Computer Engineering Department, Texas AxM University, College Station, TX, United States
AD  - Industrial and Systems Engineering Department, Texas Am University, College Station, TX, United States
AB  - Arrhenius equations with Weibull distribution have been broadly deployed to quantify the loss of life and probability of failure of power transformers. This model is highly nonlinear, and this non-linearity makes it challenging to use this model for grid management and optimization. In this study, equations are linearized using Taylor series expansion to provide a linear formulation for transformer loss of life and probability of failure as a function of ambient temperature and transformer loading. The proposed formulation allows transformer constraints to be incorporated in grid management applications within conventional optimization approaches, such as linear programming, and decreases the calculation burden caused by nonlinearity. © 2013 IEEE.
KW  - Arrhenius model
KW  - electric transformers
KW  - linearization
KW  - Weibull distribution
KW  - Linear programming
KW  - Outages
KW  - Power transformers
KW  - Weibull distribution
KW  - Arrhenius
KW  - Arrhenius models
KW  - Grid management
KW  - Linearisation
KW  - Load modeling
KW  - Oil
KW  - Oil insulations
KW  - Power transformer insulation
KW  - Probability of failure
KW  - Weibull models
KW  - Linearization
PB  - Institute of Electrical and Electronics Engineers Inc.
SN  - 21693536 (ISSN)
LA  - English
J2  - IEEE Access
M3  - Article
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 6; Correspondence Address: M. Soleimani; Electrical and Computer Engineering Department, Texas AxM University, College Station, United States; email: msoleimani@ieee.org
ER  -

TY  - CONF
AU  - Li, J.
AU  - Tang, T.
AU  - Gong, Z.
AU  - Yang, L.
AU  - Yu, Z.
AU  - Chen, Z.
AU  - Wang, J.
AU  - Zhao, W.X.
AU  - Wen, J.-R.
TI  - ElitePLM: An Empirical Study on General Language Ability Evaluation of Pretrained Language Models
PY  - 2022
T2  - NAACL 2022 - 2022 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Proceedings of the Conference
SP  - 3519
EP  - 3539
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85138372709&partnerID=40&md5=9309408a1b88f0c1d46b9d38051464e7
AD  - Gaoling School of Artificial Intelligence, Renmin University of China, China
AD  - Renmin University of China, China
AD  - Peng Cheng Laboratory, China
AD  - School of Computer Science and Engineering, Beihang University, China
AD  - Beijing Key Laboratory of Big Data Management and Analysis Methods, China
AB  - Nowadays, pretrained language models (PLMs) have dominated the majority of NLP tasks. While, little research has been conducted on systematically evaluating the language abilities of PLMs. In this paper, we present a large-scale empirical study on genEral language ability evaluation of PLMs (ElitePLM). In our study, we design four evaluation dimensions, i.e., memory, comprehension, reasoning, and composition, to measure ten widely-used PLMs within five categories. Our empirical results demonstrate that: (1) PLMs with varying training objectives and strategies are good at different ability tests; (2) fine-tuning PLMs in downstream tasks is usually sensitive to the data size and distribution; (3) PLMs have excellent transferability between similar tasks. Moreover, the prediction results of PLMs in our experiments are released as an open resource for more deep and detailed analysis on the language abilities of PLMs. This paper can guide the future work to select, apply, and design PLMs for specific tasks. We have made all the details of experiments publicly available at https://github.com/RUCAIBox/ElitePLM. © 2022 Association for Computational Linguistics.
KW  - Ability evaluation
KW  - Data distribution
KW  - Data size
KW  - Down-stream
KW  - Empirical studies
KW  - Fine tuning
KW  - Language model
KW  - Large-scales
KW  - Specific tasks
KW  - Computational linguistics
PB  - Association for Computational Linguistics (ACL)
SN  - 978-195591771-1 (ISBN)
LA  - English
J2  - NAACL - Conf. N. Am. Chapter Assoc. Comput. Linguist.: Hum. Lang. Technol., Proc. Conf.
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 3; Correspondence Address: W.X. Zhao; Gaoling School of Artificial Intelligence, Renmin University of China, China; email: batmanfly@gmail.com; Conference name: 2022 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, NAACL 2022; Conference date: 10 July 2022 through 15 July 2022; Conference code: 182070
ER  -

TY  - CONF
AU  - Bhattacharjee, A.
AU  - Hasan, T.
AU  - Uddin Ahmad, W.
AU  - Samin, K.
AU  - Islam, M.S.
AU  - Iqbal, A.
AU  - Rahman, M.S.
AU  - Shahriyar, R.
TI  - BanglaBERT: Language Model Pretraining and Benchmarks for Low-Resource Language Understanding Evaluation in Bangla
PY  - 2022
T2  - Findings of the Association for Computational Linguistics: NAACL 2022 - Findings
SP  - 1318
EP  - 1327
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85131633143&partnerID=40&md5=6cb5e431176b563860b9b8e5d6c588ce
AD  - Bangladesh University of Engineering and Technology (BUET), Bangladesh
AD  - AWS AI Labs, United States
AD  - University of Rochester, United States
AB  - In this work, we introduce BanglaBERT, a BERT-based Natural Language Understanding (NLU) model pretrained in Bangla, a widely spoken yet low-resource language in the NLP literature. To pretrain BanglaBERT, we collect 27.5 GB of Bangla pretraining data (dubbed 'Bangla2B+') by crawling 110 popular Bangla sites. We introduce two downstream task datasets on natural language inference and question answering and benchmark on four diverse NLU tasks covering text classification, sequence labeling, and span prediction. In the process, we bring them under the first-ever Bangla Language Understanding Benchmark (BLUB). BanglaBERT achieves state-of-the-art results outperforming multilingual and monolingual models. We are making the models, datasets, and a leaderboard publicly available at https://github. com/csebuetnlp/banglabert to advance Bangla NLP. © Findings of the Association for Computational Linguistics: NAACL 2022 - Findings.
KW  - Classification (of information)
KW  - Computational linguistics
KW  - Text processing
KW  - Down-stream
KW  - Language inference
KW  - Language model
KW  - Language understanding
KW  - Low resource languages
KW  - Natural language understanding
KW  - Natural languages
KW  - Pre-training
KW  - Question Answering
KW  - Text classification
KW  - Natural language processing systems
PB  - Association for Computational Linguistics (ACL)
SN  - 978-195591776-6 (ISBN)
LA  - English
J2  - Find. Assoc. Comput. Linguist.: NAACL
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 23; Conference name: 2022 Findings of the Association for Computational Linguistics: NAACL 2022; Conference date: 10 July 2022 through 15 July 2022; Conference code: 182081
ER  -

TY  - CONF
AU  - Kwako, A.
AU  - Wan, E.
AU  - Zhao, J.
AU  - Chang, K.-W.
AU  - Cai, L.
AU  - Hansen, M.
TI  - Using Item Response Theory to Measure Gender and Racial Bias of a BERT-based Automated English Speech Assessment System
PY  - 2022
T2  - BEA 2022 - 17th Workshop on Innovative Use of NLP for Building Educational Applications, Proceedings
SP  - 1
EP  - 7
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85138403284&partnerID=40&md5=858d1e9d5368942692ff386083e0f332
AD  - University of California, Los Angeles, United States
AD  - University of Maryland, College Park, United States
AB  - Recent advances in natural language processing and transformer-based models have made it easier to implement accurate, automated English speech assessments. Yet, without careful examination, applications of these models may exacerbate social prejudices based on gender and race. This study addresses the need to examine potential biases of transformer-based models in the context of automated English speech assessment. For this purpose, we developed a BERT-based automated speech assessment system and investigated gender and racial bias of examinees’ automated scores. Gender and racial bias was measured by examining differential item functioning (DIF) using an item response theory framework. Preliminary results, which focused on a single verbal-response item, showed no statistically significant DIF based on gender or race for automated scores. © 2022 Association for Computational Linguistics.
KW  - Automation
KW  - Speech
KW  - Assessment system
KW  - Differential items
KW  - Gender bias
KW  - Item response theory
KW  - Language processing
KW  - Natural languages
KW  - Racial bias
KW  - Verbal response
KW  - Natural language processing systems
A2  - Kochmar E.
A2  - Burstein J.
A2  - Horbach A.
A2  - Laarmann-Quante R.
A2  - Madnani N.
A2  - Tack A.
A2  - Yaneva V.
A2  - Yuan Z.
A2  - Zesch T.
PB  - Association for Computational Linguistics (ACL)
SN  - 978-195591783-4 (ISBN)
LA  - English
J2  - BEA - Workshop Innov. Use NLP Build. Educ. Appl., Proc.
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 3; Conference name: 17th Workshop on Innovative Use of NLP for Building Educational Applications, BEA 2022; Conference code: 182102
ER  -

TY  - CONF
AU  - Koch, P.
AU  - Aßenmacher, M.
AU  - Heumann, C.
TI  - Pre-trained language models evaluating themselves - A comparative study
PY  - 2022
T2  - Insights 2022 - 3rd Workshop on Insights from Negative Results in NLP, Proceedings of the Workshop
SP  - 180
EP  - 187
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85137519288&partnerID=40&md5=82550358bada16df96e7f3568c483a22
AD  - Department of Statistics, Ludwig-Maximilians-Universität, Ludwigstr. 33, Munich, D-80539, Germany
AB  - Evaluating generated text received new attention with the introduction of model-based metrics in recent years. These new metrics have a higher correlation with human judgments and seemingly overcome many issues of previous n-gram based metrics from the symbolic age. In this work, we examine the recently introduced metrics BERTScore, BLEURT, NUBIA, MoverScore, and Mark-Evaluate (Petersen). We investigate their sensitivity to different types of semantic deterioration (part of speech drop and negation), word order perturbations, word drop, and the common problem of repetition. No metric showed appropriate behaviour for negation, and further none of them was overall sensitive to the other issues mentioned above. © 2022 Association for Computational Linguistics.
KW  - Computational linguistics
KW  - Deterioration
KW  - Semantics
KW  - Comparatives studies
KW  - Human judgments
KW  - Language model
KW  - Model-based OPC
KW  - N-grams
KW  - Part Of Speech
KW  - Petersen
KW  - Word orders
KW  - Drops
A2  - Tafreshi S.
A2  - Sedoc J.
A2  - Rogers A.
A2  - Drozd A.
A2  - Rumshisky A.
A2  - Akula A.R.
PB  - Association for Computational Linguistics (ACL)
SN  - 978-195591740-7 (ISBN)
LA  - English
J2  - Insights - Workshop Insights Negat. Results NLP, Proc. Workshop
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 0; Conference name: 3rd Workshop on Insights from Negative Results in NLP, Insights 2022; Conference code: 181935
ER  -

TY  - CONF
AU  - Tan, X.
AU  - Yuan, C.
AU  - Wu, H.
AU  - Zhao, X.
TI  - Comprehensive Evaluation of BERT Model for DNA-Language for Prediction of DNA Sequence Binding Specificities in Fine-Tuning Phase
PY  - 2022
T2  - Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)
VL  - 13394 LNCS
SP  - 92
EP  - 102
DO  - 10.1007/978-3-031-13829-4_8
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85139826783&doi=10.1007%2f978-3-031-13829-4_8&partnerID=40&md5=74179086a84f0ed16692342b5e589f54
AD  - Institute of Machine Learning and Systems Biology, School of Electronics and Information Engineering, Tongji University, Shanghai, 201804, China
AD  - Guangxi Academy of Science, Nanning, 530007, China
AD  - Guangxi Key Lab of Human-Machine Interaction and Intelligent Decision, Guangxi Academy Sciences, Nanning, China
AD  - School of Electronic and Information Engineering, Suzhou University of Science and Technology, Suzhou, 215009, China
AD  - Institute of Science and Technology for Brain Inspired Intelligence (ISTBI), Fudan University, Shanghai, 200433, China
AB  - Deciphering the language of DNA has always been one of the difficult problems that informatics methods need to deal with. In order to meet this challenge, many deep learning models have been proposed. Among them, DNA-language models based on pre-trained Bidirectional Encoder Representations from Transformers (BERT) is one of the methods with excellent performance in recognition accuracy. At the same time, most studies focus on the design of the model structure, while for pre-trained DNA-language models such as BERT, there are relatively few studies on the influence of the fine-tuning stage on model performance. To this end, we select DNABERT, the first pre-trained BERT model for DNA-language, to analysis its fine-tuning performances with different parameters settings in motif mining tasks, which are one of the most classic missions for prediction of DNA sequence binding specificities. Furthermore, we compare the fine-tuning results to the performances of previously existing models by dividing different types of datasets. The results show that in fine-tuning phase, different hyper-parameters combinations and types of dataset do have significant impact on model performance. © 2022, The Author(s), under exclusive license to Springer Nature Switzerland AG.
KW  - BERT
KW  - DNA-language model
KW  - Fine-tuning analysis
KW  - Motif mining
KW  - Sequence binding specificities
KW  - Computational linguistics
KW  - Deep learning
KW  - DNA
KW  - Bidirectional encoder representation from transformer
KW  - Binding specificities
KW  - DNA languages
KW  - DNA-language model
KW  - Fine tuning
KW  - Fine-tuning analyse
KW  - Language model
KW  - Motif mining
KW  - Sequence binding specificity
KW  - Tuning analysis
KW  - DNA sequences
A2  - Huang D.-S.
A2  - Jo K.-H.
A2  - Jing J.
A2  - Premaratne P.
A2  - Bevilacqua V.
A2  - Hussain A.
PB  - Springer Science and Business Media Deutschland GmbH
SN  - 03029743 (ISSN); 978-303113828-7 (ISBN)
LA  - English
J2  - Lect. Notes Comput. Sci.
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 0; Correspondence Address: X. Tan; Institute of Machine Learning and Systems Biology, School of Electronics and Information Engineering, Tongji University, Shanghai, 201804, China; email: 2032986@tongji.edu.cn; Conference name: 18th International Conference on Intelligent Computing, ICIC 2022; Conference date: 7 August 2022 through 11 August 2022; Conference code: 281979
ER  -

TY  - JOUR
AU  - Yu, H.
AU  - Yuan, W.
AU  - Wang, M.
AU  - Zhang, H.
AU  - Xiong, W.
AU  - Yuan, X.
AU  - Zou, X.
TI  - Comprehensive Condition Assessment of Power Transformer Based on Asymmetric Nearness Degree Evidence Cloud Matter-element Model
ST  - 基于非对称贴近度证据云物元模型的电力变压器综合状态评估方法
PY  - 2021
T2  - Dianwang Jishu/Power System Technology
VL  - 45
IS  - 9
SP  - 3706
EP  - 3713
DO  - 10.13335/j.1000-3673.pst.2020.1938
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85114634139&doi=10.13335%2fj.1000-3673.pst.2020.1938&partnerID=40&md5=3f919d0e7b05dbf95726de758b2d386a
AD  - College of Electrical Engineering, Guizhou University, Guiyang, 550025, China
AB  - At present, in the process of condition assessment of the power transformer, the condition grades of evaluation indexes are divided into intervals, results deviation caused by selecting different reliability values by reliability criterion judgement, and the maximum membership principle judged only by using the maximum component. A comprehensive condition assessment method of the power transformer based on the asymmetric nearness degree evidence cloud matter-element model is proposed. Firstly, due to the randomness and fuzziness of the transformer at the condition grade boundary, the cloud matter-element model is used to construct the basic framework of the condition assessment. Then, in order to obtain the clarity and fuzziness of the "3En " criterion and the "50% association degree" criterion, and to avoid the conflicts between the condition conclusions, the cloud matter-element model is improved by the cloud entropy optimization algorithm to calculate the grade association degree of the evaluation indexes. Finally, based on the D-S evidence theory, the grade association degree of each test item is fused, and the final evaluation result is obtained by using the asymmetric nearness degree decision judgment, which effectively avoids the problems of result deviation caused by selecting different reliability values and the inconsistency between the condition conclusions and the actual situation caused easily by using the maximum component to make decision and judgment. Taking two 220kV oil-immersed power transformers as an example, it is proved that this method can not only improve the accuracy of the power transformer condition assessment, but also further expand its applicability. © 2021, Power System Technology Press. All right reserved.
KW  - Asymmetric nearness degree
KW  - Comprehensive condition assessment
KW  - D-S evidence theory
KW  - Improved cloud matter-element model
KW  - Power transformer
KW  - Decision theory
KW  - Fuzzy set theory
KW  - Fuzzy systems
KW  - Power transformers
KW  - Reliability theory
KW  - Condition assessments
KW  - D S evidence theory
KW  - Entropy optimization
KW  - Matter-element model
KW  - Maximum membership principle
KW  - Oil immersed power transformer
KW  - Reliability criterion
KW  - Transformer condition assessment
KW  - Oil filled transformers
PB  - Power System Technology Press
SN  - 10003673 (ISSN)
LA  - Chinese
J2  - Dianwang Jishu
M3  - Article
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 9; Correspondence Address: W. Xiong; College of Electrical Engineering, Guizhou University, Guiyang, 550025, China; email: wxiong@gzu.edu.cn; CODEN: DIJIE
ER  -

TY  - JOUR
AU  - Mrinalini, K.
AU  - Vijayalakshmi, P.
AU  - Thangavelu, N.
TI  - SBSim: A Sentence-BERT Similarity-Based Evaluation Metric for Indian Language Neural Machine Translation Systems
PY  - 2022
T2  - IEEE/ACM Transactions on Audio Speech and Language Processing
VL  - 30
SP  - 1396
EP  - 1406
DO  - 10.1109/TASLP.2022.3161160
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85127028560&doi=10.1109%2fTASLP.2022.3161160&partnerID=40&md5=18f5cac76859b88bb8c7f49b780f2c93
AD  - Sri Sivasubramaniya Nadar College of Engineering, Tamil Nadu, Chennai, 603110, India
AD  - Shiv Nadar University, Tamil Nadu, Chennai, 603110, India
AB  - Machine translation (MT) outputs are widely scored using automatic evaluation metrics and human evaluation scores. The automatic evaluation metrics are expected to be easily computable and a reflection of human evaluation. Traditional string-based metrics such as BLEU, ChrF++ scores, are widely used to evaluate MT systems, but fail to account for synonyms that appear in the state-of-the-art neural machine translation (NMT) systems, owing to their inability to evaluate paraphrases. While similarity-based metrics such as Yisi, BERTScore address this issue, these metrics need to be modified to better evaluate morphologically rich Indian languages such as, Tamil and Hindi. The current work proposes a novel and individual sentence-BERT based similarity (SBSim) metric, that makes use of a paraphrase-BERT model and sentence-level embedding to evaluate NMT outputs. The effectiveness of the BLEU, ChrF++, Yisi, BERTScore, and the proposed SBSim are evaluated on English-to-Tamil and English-to-Hindi NMT outputs. The sentence-level metric correlation of the proposed SBSim metric with respect to human scores is observed to outperform the existing metrics with a correlation of 0.9123 and 0.9052 for English-to-Tamil and English-to-Hindi NMT systems, respectively. Further, the average metric correlation of the SBSim metric is also observed to be the highest with a value of 0.9801 and 0.9836 for these NMT systems, respectively. The proposed metric is also evaluated on WMT2020 dataset and reports the highest correlation of 0.7129 with the human scores.  © 2014 IEEE.
KW  - Automatic evaluation
KW  - human correlation
KW  - individual metric
KW  - paraphrase-BERT
KW  - sentence-BERT
KW  - Computational linguistics
KW  - Neural machine translation
KW  - Speech processing
KW  - Automatic evaluation
KW  - Computational modelling
KW  - Correlation
KW  - Evaluation metrics
KW  - Human correlation
KW  - Individual metric
KW  - Machine translation systems
KW  - Paraphrasebert
KW  - Sentencebert
KW  - Similarity metrics
KW  - Computer aided language translation
PB  - Institute of Electrical and Electronics Engineers Inc.
SN  - 23299290 (ISSN)
LA  - English
J2  - IEEE ACM Trans. Audio Speech Lang. Process.
M3  - Article
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 7; Correspondence Address: K. Mrinalini; Sri Sivasubramaniya Nadar College of Engineering, Chennai, Tamil Nadu, 603110, India; email: mrinalinik@ssn.edu.in
ER  -

TY  - CONF
AU  - Kiio, M.N.
AU  - Wekesa, C.W.
AU  - Kamau, S.I.
TI  - Formulation and performance evaluation of a linear hybrid state estimator model incorporating transmission lines, transformers and phase shifters
PY  - 2021
T2  - International Conference on Electrical, Computer, Communications and Mechatronics Engineering, ICECCME 2021
DO  - 10.1109/ICECCME52200.2021.9590843
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85119426352&doi=10.1109%2fICECCME52200.2021.9590843&partnerID=40&md5=edacf47aa0e627b00b2ec4ca5f2c9a79
AD  - Pan African University Institute for Basic Sciences Technology and Innovation (PAUSTI), Department of Electrical Engineering, Nairobi, Kenya
AD  - University of Eldoret (UoE), School of Engineering, Nairobi, Kenya
AD  - Jomo Kenyatta University of Agriculture Technology (JKUAT), Department of Electrical and Electronic Engineering, Nairobi, Kenya
AB  - State estimation involves computation of power system variables, voltage magnitudes and phase angles at all system buses and is one of the important functions of energy management systems. The advent of phasor measurement units has made it necessary to develop methods for state estimation combining measurements from these units as well as from older remote terminal units. Conventionally, state estimation is performed using nonlinear models challenged by initialization and slow convergence problems. This paper proposes a novel linear model that also incorporates transformer and phase shifter models. The state variables are modeled in rectangular form, with principles of circuit theory used to model the measurements. To evaluate the performance of the proposed linear state estimator relative to the conventional nonlinear estimator, simulations are performed on IEEE-14 bus, IEEE-30 Bus and IEEE-57 bus systems using MATPOWER. The proposed linear estimator provides more accurate results based on normalized cumulative error. For example, for the IEEE-57 bus system, the proposed linear state estimator gives a normalized cumulative error of 0.0043 while the conventional nonlinear state estimator gives a normalized cumulative error of 0.2202. © 2021 IEEE.
KW  - Hybrid state estimator
KW  - Linear model
KW  - Phase shifter
KW  - Phasor measurement unit
KW  - Remote terminal unit
KW  - Transformer tap setting
KW  - Circuit theory
KW  - Computation theory
KW  - Electric power transmission
KW  - Energy management systems
KW  - Errors
KW  - Nonlinear analysis
KW  - Phase measurement
KW  - Phase shifters
KW  - State estimation
KW  - Bus systems
KW  - Cumulative errors
KW  - Hybrid state
KW  - Hybrid state estimator
KW  - Linear modeling
KW  - Phase-shifters
KW  - Remote terminal units
KW  - State Estimators
KW  - Transformer tap setting
KW  - Transformer taps
KW  - Phasor measurement units
PB  - Institute of Electrical and Electronics Engineers Inc.
SN  - 978-166541262-9 (ISBN)
LA  - English
J2  - Int. Conf. Electr., Comput., Commun. Mechatronics Eng., ICECCME
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 1; Conference name: 2021 IEEE International Conference on Electrical, Computer, Communications and Mechatronics Engineering, ICECCME 2021; Conference date: 7 October 2021 through 8 October 2021; Conference code: 173922
ER  -

TY  - CONF
AU  - Jerdhaf, O.
AU  - Santini, M.
AU  - Lundberg, P.
AU  - Bjerner, T.
AU  - Al-Abasse, Y.
AU  - Jönsson, A.
AU  - Vakili, T.
TI  - Evaluating Pre-Trained Language Models for Focused Terminology Extraction from Swedish Medical Records
PY  - 2022
T2  - Terminology in the 21st Century: Many Faces, Many Places, Term 2022 - held in conjunction with the International Conference on Language Resources and Evaluation, LREC 2022 - Proceedings
SP  - 30
EP  - 32
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85146268302&partnerID=40&md5=056571223fd5324d7c84bd234a9e0e0a
AD  - Linköping University Hospital, Sweden
AD  - RISE Research Institutes of Sweden, Sweden
AD  - Linköping University, Sweden
AD  - Stockholm University, Sweden
AB  - In the experiments briefly presented in this abstract, we compare the performance of a generalist Swedish pre-trained language model with a domain-specific Swedish pre-trained model on the downstream task of focused terminology extraction of implant terms, which are terms that indicate the presence of implants in the body of patients. The fine-tuning is identical for both models. For the search strategy we rely on KD-Tree that we feed with two different lists of term seeds, one with noise and one without noise. Results shows that the use of a domain-specific pre-trained language model has a positive impact on focused terminology extraction only when using term seeds without noise. © European Language Resources Association (ELRA), licensed under CC-BY-NC-4.0.
KW  - domain-specific BERT
KW  - generalist BERT
KW  - implant terms
KW  - terminology extraction
KW  - Computational linguistics
KW  - Extraction
KW  - Natural language processing systems
KW  - Domain specific
KW  - Domain-specific BERT
KW  - Down-stream
KW  - Generalist BERT
KW  - Implant term
KW  - Language model
KW  - Medical record
KW  - Performance
KW  - Swedishs
KW  - Terminology extraction
KW  - Terminology
A2  - Costa R.
A2  - Carvalho S.
A2  - Anic A.O.
A2  - Khan A.F.
PB  - European Language Resources Association (ELRA)
SN  - 979-109554695-5 (ISBN)
LA  - English
J2  - Terminol. Century: Many Faces, Many Places, Term - held conjunction Int. Conf. Lang. Resour. Eval., LREC - Proc.
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 0; Conference name: Terminology in the 21st Century: Many Faces, Many Places, Term 2022; Conference code: 185495
ER  -

TY  - CONF
AU  - Mokrii, I.
AU  - Boytsov, L.
AU  - Braslavski, P.
TI  - A Systematic Evaluation of Transfer Learning and Pseudo-labeling with BERT-based Ranking Models
PY  - 2021
T2  - SIGIR 2021 - Proceedings of the 44th International ACM SIGIR Conference on Research and Development in Information Retrieval
C7  - 3463093
SP  - 2081
EP  - 2085
DO  - 10.1145/3404835.3463093
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85111638459&doi=10.1145%2f3404835.3463093&partnerID=40&md5=74cc6ebcb0c8a5b174dde65a068614b6
AD  - Hse University, Moscow, Russian Federation
AD  - Bosch Center for Artificial Intelligence, Pittsburgh, PA, United States
AD  - Ural Federal University and Hse University, Yekaterinburg, Russian Federation
AB  - Due to high annotation costs making the best use of existing human-created training data is an important research direction. We, therefore, carry out a systematic evaluation of transferability of BERT-based neural ranking models across five English datasets. Previous studies focused primarily on zero-shot and few-shot transfer from a large dataset to a dataset with a small number of queries. In contrast, each of our collections has a substantial number of queries, which enables a full-shot evaluation mode and improves reliability of our results. Furthermore, since source datasets licences often prohibit commercial use, we compare transfer learning to training on pseudo-labels generated by a BM25 scorer. We find that training on pseudo-labels - -possibly with subsequent fine-tuning using a modest number of annotated queries - -can produce a competitive or better model compared to transfer learning. Yet, it is necessary to improve the stability and/or effectiveness of the few-shot training, which, sometimes, can degrade performance of a pretrained model. © 2021 ACM.
KW  - neural information retrieval
KW  - pseudo-labeling
KW  - transfer learning
KW  - Information retrieval
KW  - Large dataset
KW  - Learning systems
KW  - Transfer learning
KW  - Evaluation modes
KW  - Fine tuning
KW  - Ranking model
KW  - Systematic evaluation
KW  - Training data
KW  - Learning to rank
PB  - Association for Computing Machinery, Inc
SN  - 978-145038037-9 (ISBN)
LA  - English
J2  - SIGIR - Proc. Int. ACM SIGIR Conf. Res. Dev. Inf. Retr.
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 11; Conference name: 44th International ACM SIGIR Conference on Research and Development in Information Retrieval, SIGIR 2021; Conference date: 11 July 2021 through 15 July 2021; Conference code: 170067
ER  -

TY  - JOUR
AU  - Gutierrez-Choque, A.-C.
AU  - Medina-Mamani, V.
AU  - Castro-Gutierrez, E.
AU  - Nú˜nez-Pacheco, R.
AU  - Aguaded, I.
TI  - Transformer based Model for Coherence Evaluation of Scientific Abstracts: Second Fine-tuned BERT
PY  - 2022
T2  - International Journal of Advanced Computer Science and Applications
VL  - 13
IS  - 5
SP  - 929
EP  - 937
DO  - 10.14569/IJACSA.2022.01305105
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85131413431&doi=10.14569%2fIJACSA.2022.01305105&partnerID=40&md5=f2860773b00e96b1fa96a51148451361
AD  - Universidad Nacional de San Agustın de Arequipa, Peru
AD  - Universidad de Huelva, Spain
AB  - Coherence evaluation is a problem related to the area of natural language processing whose complexity lies mainly in the analysis of the semantics and context of the words in the text. Fortunately, the Bidirectional Encoder Representation from Transformers (BERT) architecture can capture the aforementioned variables and represent them as embeddings to perform Fine-tunings. The present study proposes a Second Fine-Tuned model based on BERT to detect inconsistent sentences (coherence evaluation) in scientific abstracts written in English/Spanish. For this purpose, 2 formal methods for the generation of inconsistent abstracts have been proposed: Random Manipulation (RM) and K-means Random Manipulation (KRM). Six experiments were performed; showing that performing Second Fine-Tuned improves the detection of inconsistent sentences with an accuracy of 71%. This happens even if the new retraining data are of different language or different domain. It was also shown that using several methods for generating inconsistent abstracts and mixing them when performing Second Fine-Tuned does not provide better results than using a single technique. © 2022. International Journal of Advanced Computer Science and Applications. All Rights Reserved.
KW  - Bert
KW  - Coherence evaluation
KW  - Inconsistent sentences detection
KW  - Second fine-tuned
KW  - Formal methods
KW  - K-means clustering
KW  - Natural language processing systems
KW  - Semantics
KW  - Bert
KW  - Coherence evaluation
KW  - Different domains
KW  - Embeddings
KW  - Fine tuning
KW  - Inconsistent sentence detection
KW  - K-means
KW  - Model-based OPC
KW  - Second fine-tuned
KW  - Abstracting
PB  - Science and Information Organization
SN  - 2158107X (ISSN)
LA  - English
J2  - Intl. J. Adv.  Comput. Sci. Appl.
M3  - Article
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 0
ER  -

TY  - CONF
AU  - Song, Y.
AU  - Krishna, K.
AU  - Bhatt, R.
AU  - Iyyer, M.
TI  - SLING: Sino LINGuistic Evaluation of Large Language Models
PY  - 2022
T2  - Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing, EMNLP 2022
SP  - 4606
EP  - 4634
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85149440789&partnerID=40&md5=e9e883fe6f8e146e89a1e1fbeec0e513
AD  - Department of Linguistics, UMass Amherst, United States
AD  - Manning College of Information and Computer Sciences, UMass Amherst, United States
AB  - To understand what kinds of linguistic knowledge are encoded by pretrained Chinese language models (LMs), we introduce the benchmark of Sino LINGuistics (SLING), which consists of 38K minimal sentence pairs in Mandarin Chinese grouped into 9 high-level linguistic phenomena. Each pair demonstrates the acceptability contrast of a specific syntactic or semantic phenomenon (e.g., The keys are lost vs. The keys is lost), and an LM should assign lower perplexity to the acceptable sentence. In contrast to the CLiMP dataset (Xiang et al., 2021), which also contains Chinese minimal pairs and was created by translating the vocabulary of the English BLiMP dataset, the minimal pairs in SLING are derived primarily by applying syntactic and lexical transformations to naturally-occurring, linguist-annotated sentences from the Chinese Treebank 9.0, thus addressing severe issues in CLiMP's data generation process. We test 18 publicly available pretrained monolingual (e.g., BERT-base-zh, CPM) and multi-lingual (e.g., mT5, XLM) language models on SLING. Our experiments show that the average accuracy for LMs is far below human performance (69.7% vs. 97.1%), while BERT-base-zh achieves the highest accuracy (84.8%) of all tested LMs, even much larger ones. Additionally, we find that most LMs have a strong gender and number (singular/plural) bias, and they perform better on local phenomena than hierarchical ones. © 2022 Association for Computational Linguistics.
KW  - Computational linguistics
KW  - High level languages
KW  - Semantics
KW  - Chinese language models
KW  - Data generation
KW  - Generation process
KW  - Human performance
KW  - Language model
KW  - Linguistic knowledge
KW  - Linguistic phenomena
KW  - Mandarin Chinese
KW  - Naturally occurring
KW  - Treebanks
KW  - Syntactics
A2  - Goldberg Y.
A2  - Kozareva Z.
A2  - Zhang Y.
PB  - Association for Computational Linguistics (ACL)
LA  - English
J2  - Proc. Conf. Empir. Methods Nat. Lang. Process., EMNLP
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 0; Conference name: 2022 Conference on Empirical Methods in Natural Language Processing, EMNLP 2022; Conference date: 7 December 2022 through 11 December 2022; Conference code: 186895
ER  -

TY  - CONF
AU  - Xu, Z.
AU  - Lin, T.
AU  - Tang, H.
AU  - Li, F.
AU  - He, D.
AU  - Sebe, N.
AU  - Timofte, R.
AU  - Van Gool, L.
AU  - Ding, E.
TI  - Predict, Prevent, and Evaluate: Disentangled Text-Driven Image Manipulation Empowered by Pre-Trained Vision-Language Model
PY  - 2022
T2  - Proceedings of the IEEE Computer Society Conference on Computer Vision and Pattern Recognition
VL  - 2022-June
SP  - 18208
EP  - 18217
DO  - 10.1109/CVPR52688.2022.01769
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85137433390&doi=10.1109%2fCVPR52688.2022.01769&partnerID=40&md5=bbc43475930873f40ad7e59021d94629
AD  - University of Trento, Mhug, Italy
AD  - Vis, Baidu Inc.
AD  - Cvl, Eth Zürich, Switzerland
AB  - To achieve disentangled image manipulation, previous works depend heavily on manual annotation. Meanwhile, the available manipulations are limited to a pre-defined set the models were trainedfor. We propose a novelframework, i.e., Predict, Prevent, and Evaluate (PPE), for disentangled text-driven image manipulation that requires little manual annotation while being applicable to a wide variety of ma-nipulations. Our method approaches the targets by deeply exploiting the power of the large-scale pre-trained vision-language model CLIP [32]. Concretely, we firstly Predict the possibly entangled attributes for a given text command. Then, based on the predicted attributes, we introduce an entanglement loss to Prevent entanglements during training. Finally, we propose a new evaluation metric to Evaluate the disentangled image manipulation. We verify the effectiveness of our method on the challenging face editing task. Extensive experiments show that the proposed PPE frame-work achieves much better quantitative and qualitative re-sults than the up-to-date StyleCLIP [31] baseline. Code is available at https://github.com/zipengxuc/PPE. © 2022 IEEE.
KW  - Face and gestures
KW  - Image and video synthesis and generation
KW  - Computational linguistics
KW  - Forecasting
KW  - Face and gesture
KW  - Image and video synthesis and generation
KW  - Image manipulation
KW  - Images synthesis
KW  - Language model
KW  - Large-scales
KW  - Manual annotation
KW  - Power
KW  - Video generation
KW  - Video synthesis
KW  - Computer vision
PB  - IEEE Computer Society
SN  - 10636919 (ISSN); 978-166546946-3 (ISBN)
LA  - English
J2  - Proc IEEE Comput Soc Conf Comput Vision Pattern Recognit
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 13; Conference name: 2022 IEEE/CVF Conference on Computer Vision and Pattern Recognition, CVPR 2022; Conference date: 19 June 2022 through 24 June 2022; Conference code: 183275; CODEN: PIVRE
ER  -

TY  - JOUR
AU  - Stojanov, R.
AU  - Popovski, G.
AU  - Cenikj, G.
AU  - Seljak, B.K.
AU  - Eftimov, T.
TI  - A fine-tuned bidirectional encoder representations from transformers model for food named-entity recognition: Algorithm development and validation
PY  - 2021
T2  - Journal of Medical Internet Research
VL  - 23
IS  - 8
C7  - e28229
DO  - 10.2196/28229
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85112506427&doi=10.2196%2f28229&partnerID=40&md5=b3ed120d79a4788246600d0694e9ca40
AD  - Faculty of Computer Science and Engineering, Ss Cyril and Methodius, University- Skopje, Skopje, North Macedonia
AD  - Computer Systems Department, Jožef Stefan Institute, Ljubljana, Slovenia
AD  - Jožef Stefan International Postgraduate School, Ljubljana, Slovenia
AB  - Background: Recently, food science has been garnering a lot of attention. There are many open research questions on food interactions, as one of the main environmental factors, with other health-related entities such as diseases, treatments, and drugs. In the last 2 decades, a large amount of work has been done in natural language processing and machine learning to enable biomedical information extraction. However, machine learning in food science domains remains inadequately resourced, which brings to attention the problem of developing methods for food information extraction. There are only few food semantic resources and few rule-based methods for food information extraction, which often depend on some external resources. However, an annotated corpus with food entities along with their normalization was published in 2019 by using several food semantic resources. Objective: In this study, we investigated how the recently published bidirectional encoder representations from transformers (BERT) model, which provides state-of-the-art results in information extraction, can be fine-tuned for food information extraction. Methods: We introduce FoodNER, which is a collection of corpus-based food named-entity recognition methods. It consists of 15 different models obtained by fine-tuning 3 pretrained BERT models on 5 groups of semantic resources: food versus nonfood entity, 2 subsets of Hansard food semantic tags, FoodOn semantic tags, and Systematized Nomenclature of Medicine Clinical Terms food semantic tags. Results: All BERT models provided very promising results with 93.30% to 94.31% macro F1 scores in the task of distinguishing food versus nonfood entity, which represents the new state-of-the-art technology in food information extraction. Considering the tasks where semantic tags are predicted, all BERT models obtained very promising results once again, with their macro F1 scores ranging from 73.39% to 78.96%. Conclusions: FoodNER can be used to extract and annotate food entities in 5 different tasks: food versus nonfood entities and distinguishing food entities on the level of food groups by using the closest Hansard semantic tags, the parent Hansard semantic tags, the FoodOn semantic tags, or the Systematized Nomenclature of Medicine Clinical Terms semantic tags. ©Riste Stojanov, Gorjan Popovski, Gjorgjina Cenikj, Barbara Koroušić Seljak, Tome Eftimov.
KW  - BERT
KW  - Bidirectional encoder representations from transformers
KW  - Fine-tuning BERT
KW  - Food information extraction
KW  - Information extraction
KW  - Machine learning
KW  - Named-entity recognition
KW  - Natural language processing
KW  - Semantic annotation
KW  - Algorithms
KW  - Humans
KW  - Information Storage and Retrieval
KW  - Machine Learning
KW  - Natural Language Processing
KW  - Semantics
KW  - algorithm
KW  - Article
KW  - comparative study
KW  - controlled study
KW  - deep neural network
KW  - food drug interaction
KW  - food industry
KW  - human
KW  - machine learning
KW  - medical information
KW  - natural language processing
KW  - nutritional science
KW  - ontology
KW  - semantics
KW  - Systematized Nomenclature of Medicine
KW  - word processing
KW  - information retrieval
KW  - natural language processing
PB  - JMIR Publications Inc.
SN  - 14388871 (ISSN)
C2  - 34383671
LA  - English
J2  - J. Med. Internet Res.
M3  - Article
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 14; Correspondence Address: T. Eftimov; Computer Systems Department, Jožef Stefan Institute, Ljubljana, Jamova Cesta 39, 1000, Slovenia; email: tome.eftimov@ijs.si
ER  -

TY  - CONF
AU  - Naseem, U.
AU  - Lee, B.C.
AU  - Khushi, M.
AU  - Kim, J.
AU  - Dunn, A.G.
TI  - Benchmarking for Public Health Surveillance tasks on Social Media with a Domain-Specific Pretrained Language Model
PY  - 2022
T2  - NLP-Power 2022 - 1st Workshop on Efficient Benchmarking in NLP, Proceedings of the Workshop
SP  - 22
EP  - 31
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85137689996&partnerID=40&md5=abb20c34751f9e3ecb5e95cc1f61a8d7
AD  - School of Computer Science, University of Sydney, Australia
AD  - School of Medicine, University of Sydney, Australia
AD  - School of Medical Sciences, University of Sydney, Australia
AB  - A user-generated text on social media enables health workers to keep track of information, identify possible outbreaks, forecast disease trends, monitor emergency cases, and ascertain disease awareness and response to official health correspondence. This exchange of health information on social media has been regarded as an attempt to enhance public health surveillance (PHS). Despite its potential, the technology is still in its early stages and is not ready for widespread application. Advancements in pretrained language models (PLMs) have facilitated the development of several domain-specific PLMs and a variety of downstream applications. However, there are no PLMs for social media tasks involving PHS. We present and release PHS-BERT, a transformer-based PLM, to identify tasks related to public health surveillance on social media. We compared and benchmarked the performance of PHS-BERT on 25 datasets from different social medial platforms related to 7 different PHS tasks. Compared with existing PLMs that are mainly evaluated on limited tasks, PHS-BERT achieved state-of-the-art performance on all 25 tested datasets, showing that our PLM is robust and generalizable in the common PHS tasks. By making PHS-BERT available, we aim to facilitate the community to reduce the computational cost and introduce new baselines for future works across various PHS-related tasks. © 2022 Association for Computational Linguistics.
KW  - Monitoring
KW  - Public health
KW  - Social networking (online)
KW  - Domain specific
KW  - Downstream applications
KW  - Health informations
KW  - Keep track of
KW  - Language model
KW  - Public health surveillances
KW  - Social media
KW  - Surveillance task
KW  - User-generated
KW  - Workers'
KW  - Computational linguistics
A2  - Shavrina T.
A2  - Mikhailov V.
A2  - Malykh V.
A2  - Artemova E.
A2  - Serikov O.
A2  - Protasov V.
PB  - Association for Computational Linguistics (ACL)
SN  - 978-195591747-6 (ISBN)
LA  - English
J2  - NLP-Power - Workshop Effic. Benchmarking NLP, Proc. Workshop
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 6; Conference name: 1st Workshop on Efficient Benchmarking in NLP, NLP-Power 2022; Conference code: 181951
ER  -

TY  - JOUR
AU  - Latteur, A.
AU  - Larøi, F.
AU  - Bortolon, C.
TI  - Translation and Validation of the French Version of the Revised Green et al., Paranoid Thoughts Scale (R-GPTS) in Two Samples: Non-Clinical and Clinical Adults
PY  - 2022
T2  - Psychologica Belgica
VL  - 62
IS  - 1
SP  - 208
EP  - 217
DO  - 10.5334/pb.1134
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85132517971&doi=10.5334%2fpb.1134&partnerID=40&md5=68d6079914b39ae6f2bab53fa88e1bd9
AD  - Psychology and Neuroscience of Cognition Research Unit, University of Liège, Belgium
AD  - Department of Psychology, University of Oslo, Norway
AD  - Norwegian Center of Excellence for Mental Disorders Research, University of Oslo, Norway
AD  - Université Grenoble-Alpes, Laboratoire Interuniversitaire de Psychologie (LIP/PC2S), France
AD  - C3R Centre Référent Réhabilitation Psychosociale et Remédiation, Centre Hospitalier Alpes-Isère, Grenoble, France
AB  - Paranoia consists of unfounded beliefs that harm will be caused with intent to hurt the subject. Paranoid thoughts exist on a continuum of severity from severe forms in several psychological pathologies to milder forms in a significant minority of individuals of the general population (Freeman, 2007). It can be measured using several types of questionnaires. One recent questionnaire that measures paranoia in both clinical and non-clinical populations is the revised Green et al., Paranoid Thoughts Scale (R-GPTS) (Freeman et al., 2019). This questionnaire is an improved version of the Green et al., Paranoid Thoughts Scale (GPTS) (Green et al., 2008) and has excellent psychometric properties. In the present study, the R-GPTS was translated into French and the psychometric properties of the new French version were evaluated in a sample of the general population (N = 600) and in a clinical sample (N = 22). Confirmatory factor analysis supported the original two-factor structure (social reference and persecution subscales) of the R-GPTS. Evidence of excellent internal consistency of the R-GPTS was found. Furthermore, good convergent and discriminant validity was also found. Test-retest reliability showed significant positive correlations over a 1-month period. The findings discussed above were found in the non-clinical sample. Lastly, the R-GPTS revealed good preliminary criterion validity established from the comparison between the clinical and the non-clinical groups. In conclusion, the French version of the R-GPTS is a valid and reliable tool to measure paranoia in the general population. Due to the small sample size of the clinical sample, further studies are needed in order to confirm good psychometric properties in clinical populations, even though our preliminary findings are promising. © 2022 Ubiquity Press. All rights reserved.
KW  - Paranoia
KW  - psychometric properties
KW  - translation
PB  - Ubiquity Press
SN  - 00332879 (ISSN)
LA  - English
J2  - Psychol. Belg.
M3  - Article
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 2; Correspondence Address: A. Latteur; Université de Liège Psychologie et Neuroscience Cognitives, Bât. B33 - Quartier Agora, Liège, Place des Orateurs 1, 4000, Belgium; email: alatteur@uliege.be
ER  -

TY  - CONF
AU  - Benamar, A.
AU  - Grouin, C.
AU  - Bothua, M.
AU  - Vilnat, A.
TI  - Evaluating Tokenizers Impact on OOVs Representation with Transformers Models
PY  - 2022
T2  - 2022 Language Resources and Evaluation Conference, LREC 2022
SP  - 4193
EP  - 4204
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85144417976&partnerID=40&md5=00e5296c8c8297944d02e5721d62fcbc
AD  - Université Paris-Saclay, CNRS, LISN, Orsay, France
AD  - EDF Lab R&D, Palaiseau, France
AB  - Transformer models have achieved significant improvements in multiple downstream tasks in recent years. One of the main contributions of Transformers is their ability to create new representations for out-of-vocabulary (OOV) words. In this paper, we have evaluated three categories of OOVs: (A) new domain-specific terms (e.g., “eucaryote” in microbiology), (B) misspelled words containing typos, and (C) cross-domain homographs (e.g., “arm” has different meanings in a clinical trial and anatomy). We use three French domain-specific datasets on the legal, medical, and energetical domains to robustly analyze these categories. Our experiments have led to exciting findings that showed: (1) It is easier to improve the representation of new words (A and B) than it is for words that already exist in the vocabulary of the Transformer models (C), (2) To ameliorate the representation of OOVs, the most effective method relies on adding external morpho-syntactic context rather than improving the semantic understanding of the words directly (fine-tuning) and (3) We cannot foresee the impact of minor misspellings in words because similar misspellings have different impacts on their representation. We believe that tackling the challenges of processing OOVs regarding their specificities will significantly help the domain adaptation aspect of BERT. © European Language Resources Association (ELRA), licensed under CC-BY-NC-4.0.
KW  - Language models
KW  - Out-of-vocabulary
KW  - Sub-units tokenization
KW  - Transformer models
KW  - Domain specific
KW  - Down-stream
KW  - Language model
KW  - Out-of-vocabulary
KW  - Outof-vocabulary words (OOV)
KW  - Sub-unit tokenization
KW  - Sub-units
KW  - Tokenization
KW  - Tokenizer
KW  - Transformer modeling
KW  - Semantics
A2  - Calzolari N.
A2  - Bechet F.
A2  - Blache P.
A2  - Choukri K.
A2  - Cieri C.
A2  - Declerck T.
A2  - Goggi S.
A2  - Isahara H.
A2  - Maegaard B.
A2  - Mariani J.
A2  - Mazo H.
A2  - Odijk J.
A2  - Piperidis S.
PB  - European Language Resources Association (ELRA)
SN  - 979-109554672-6 (ISBN)
LA  - English
J2  - Lang. Resour. Eval. Conf., LREC
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 1; Conference name: 13th International Conference on Language Resources and Evaluation Conference, LREC 2022; Conference date: 20 June 2022 through 25 June 2022; Conference code: 184830
ER  -

TY  - CONF
AU  - Mao, Z.
AU  - Jaiswal, A.
AU  - Wang, Z.
AU  - Chan, S.H.
TI  - Single Frame Atmospheric Turbulence Mitigation: A Benchmark Study and a New Physics-Inspired Transformer Model
PY  - 2022
T2  - Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)
VL  - 13679 LNCS
SP  - 430
EP  - 446
DO  - 10.1007/978-3-031-19800-7_25
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85142741283&doi=10.1007%2f978-3-031-19800-7_25&partnerID=40&md5=5f9314347cf0d746c4b372a1ae71adaf
AD  - Purdue University, West Lafayette, 47907, IN, United States
AD  - University of Texas at Austin, Austin, 78712, TX, United States
AB  - Image restoration algorithms for atmospheric turbulence are known to be much more challenging to design than traditional ones such as blur or noise because the distortion caused by the turbulence is an entanglement of spatially varying blur, geometric distortion, and sensor noise. Existing CNN-based restoration methods built upon convolutional kernels with static weights are insufficient to handle the spatially dynamical atmospheric turbulence effect. To address this problem, in this paper, we propose a physics-inspired transformer model for imaging through atmospheric turbulence. The proposed network utilizes the power of transformer blocks to jointly extract a dynamical turbulence distortion map and restore a turbulence-free image. In addition, recognizing the lack of a comprehensive dataset, we collect and present two new real-world turbulence datasets that allow for evaluation with both classical objective metrics (e.g., PSNR and SSIM) and a new task-driven metric using text recognition accuracy. The code and datasets are available at github.com/VITA-Group/TurbNet. © 2022, The Author(s), under exclusive license to Springer Nature Switzerland AG.
KW  - Atmospheric turbulence mitigation
KW  - Image restoration
KW  - Atmospheric thermodynamics
KW  - Atmospheric turbulence
KW  - Character recognition
KW  - Restoration
KW  - Atmospheric turbulence mitigation
KW  - Benchmark study
KW  - Geometric distortion
KW  - Geometric sensors
KW  - Image restoration algorithms
KW  - New physics
KW  - Restoration methods
KW  - Sensors noise
KW  - Single frames
KW  - Transformer modeling
KW  - Image reconstruction
A2  - Avidan S.
A2  - Brostow G.
A2  - Cissé M.
A2  - Farinella G.M.
A2  - Hassner T.
PB  - Springer Science and Business Media Deutschland GmbH
SN  - 03029743 (ISSN); 978-303119799-4 (ISBN)
LA  - English
J2  - Lect. Notes Comput. Sci.
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 6; Correspondence Address: Z. Mao; Purdue University, West Lafayette, 47907, United States; email: mao114@purdue.edu; Conference name: 17th European Conference on Computer Vision, ECCV 2022; Conference date: 23 October 2022 through 27 October 2022; Conference code: 285469
ER  -

TY  - CONF
AU  - Ehara, Y.
TI  - Neural Language Model-based Readability Assessment of Computer Science Introductory Texts for English-as-a-Second Language Learners
PY  - 2022
T2  - Proceedings of the 44th Annual Meeting of the Cognitive Science Society: Cognitive Diversity, CogSci 2022
SP  - 1698
EP  - 1704
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85146416600&partnerID=40&md5=c0f5a761b74aee4f598d1ce33d91c77b
AD  - Tokyo Gakugei University, 4-1-1 Nukuikita-machi, Koganei, Tokyo, 1848501, Japan
AB  - English is the dominant language in computer science. In addition to English-based academic papers, English is frequently the only language provided in introduction sections and manuals of command and software libraries, which are essential aspects of computer programming. Hence, English-as-a-second-language (ESL) learners may have difficulty studying computer science because they must learn this field while also learning English. Despite this problem, few studies have assessed the difficulty level of computer science texts for ESL learners. Ideally, the difficulty levels of texts are assessed by having groups of ESL learners read them. However, owing to the excessive time and financial costs involved, such practices can be impractical. Hence, using two highly accurate automatic readability assessors based on natural language processing (NLP) techniques, we assessed the readability of various computer-science-related texts for ESL learners. The first assessor is based on state-of-the-art deep transfer learning, and the second is based on classical machine learning and applied linguistics. For training the assessors, we used a standard corpus employed in NLP, which was annotated by professional English teachers to evaluate the readability of the texts for ESL learners. To conduct the experiments, we built a collection of computer science texts ranging from academic papers to software manuals (READMEs) crawled from a source-code hosting website, namely GitHub. The experimental results showed that intermediate ESL learners were able to read most of the computer science related texts. © 2022 The Author(s). This work is licensed under a Creative Commons Attribution 4.0 International License (CC BY)
KW  - Assessment
KW  - Neural Language Model
KW  - Readability
KW  - Computational linguistics
KW  - Computer programming
KW  - Learning algorithms
KW  - Learning systems
KW  - Natural language processing systems
KW  - Personnel training
KW  - Transfer learning
KW  - Academic paper
KW  - Assessment
KW  - Creative Commons
KW  - English as a second language
KW  - Language model
KW  - Model-based OPC
KW  - Natural languages
KW  - Neural language model
KW  - Readability
KW  - Second language learners
KW  - Deep learning
PB  - The Cognitive Science Society
LA  - English
J2  - Proc. Annu. Meet. Cogn. Sci. Soc.: Cogn. Diversity, CogSci
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 1; Correspondence Address: Y. Ehara; Tokyo Gakugei University, Tokyo, 4-1-1 Nukuikita-machi, Koganei, 1848501, Japan; email: ehara@u-gakugei.ac.jp; Conference name: 44th Annual Meeting of the Cognitive Science Society: Cognitive Diversity, CogSci 2022; Conference date: 27 July 2022 through 30 July 2022; Conference code: 185866
ER  -

TY  - CONF
AU  - Rauh, M.
AU  - Mellor, J.
AU  - Uesato, J.
AU  - Huang, P.-S.
AU  - Welbl, J.
AU  - Weidinger, L.
AU  - Dathathri, S.
AU  - Glaese, A.
AU  - Irving, G.
AU  - Gabriel, I.
AU  - Isaac, W.
AU  - Hendricks, L.A.
TI  - Characteristics of Harmful Text: Towards Rigorous Benchmarking of Language Models
PY  - 2022
T2  - Advances in Neural Information Processing Systems
VL  - 35
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85140426523&partnerID=40&md5=97e0a22d17d6060168a661063e8587ed
AD  - DeepMind, United Kingdom
AB  - Large language models produce human-like text that drives a growing number of applications. However, recent literature and, increasingly, real world observations, have demonstrated that these models can generate language that is toxic, biased, untruthful or otherwise harmful. Though work to evaluate language model harms is under way, translating foresight about which harms may arise into rigorous benchmarks is not straightforward. To facilitate this translation, we outline six ways of characterizing harmful text which merit explicit consideration when designing new benchmarks. We then use these characteristics as a lens to identify trends and gaps in existing benchmarks. Finally, we apply them in a case study of the Perspective API, a toxicity classifier that is widely used in harm benchmarks. Our characteristics provide one piece of the bridge that translates between foresight and effective evaluation. © 2022 Neural information processing systems foundation. All rights reserved.
KW  - Computational linguistics
KW  - Case-studies
KW  - Human like
KW  - Language model
KW  - Real-world
KW  - Translation (languages)
A2  - Koyejo S.
A2  - Mohamed S.
A2  - Agarwal A.
A2  - Belgrave D.
A2  - Cho K.
A2  - Oh A.
PB  - Neural information processing systems foundation
SN  - 10495258 (ISSN); 978-171387108-8 (ISBN)
LA  - English
J2  - Adv. neural inf. proces. syst.
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 2; Correspondence Address: M. Rauh; DeepMind, United Kingdom; email: mbrauh@deepmind.com; Conference name: 36th Conference on Neural Information Processing Systems, NeurIPS 2022; Conference date: 28 November 2022 through 9 December 2022; Conference code: 189185
ER  -

TY  - CONF
AU  - Roux, T.B.
AU  - Rouvier, M.
AU  - Wottawa, J.
AU  - Dufour, R.
TI  - Qualitative Evaluation of Language Model Rescoring in Automatic Speech Recognition
PY  - 2022
T2  - Proceedings of the Annual Conference of the International Speech Communication Association, INTERSPEECH
VL  - 2022-September
SP  - 3968
EP  - 3972
DO  - 10.21437/Interspeech.2022-10931
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85140092544&doi=10.21437%2fInterspeech.2022-10931&partnerID=40&md5=6627cb2b01745ae90b691375c69967d4
AD  - LS2N - Nantes University, France
AD  - LIA - Avignon University, France
AD  - LIUM - Le Mans University, France
AB  - Evaluating automatic speech recognition (ASR) systems is a classical but difficult and still open problem, which often boils down to focusing only on the word error rate (WER). However, this metric suffers from many limitations and does not allow an in-depth analysis of automatic transcription errors. In this paper, we propose to study and understand the impact of rescoring using language models in ASR systems by means of several metrics often used in other natural language processing (NLP) tasks in addition to the WER. In particular, we introduce two measures related to morpho-syntactic and semantic aspects of transcribed words: 1) the POSER (Part-of-speech Error Rate), which should highlight the grammatical aspects, and 2) the EmbER (Embedding Error Rate), a measurement that modifies the WER by providing a weighting according to the semantic distance of the wrongly transcribed words. These metrics illustrate the linguistic contributions of the language models that are applied during a posterior rescoring step on transcription hypotheses. Copyright © 2022 ISCA.
KW  - Automatic speech recognition
KW  - evaluation metrics
KW  - Language modeling
KW  - Semantic analysis
KW  - Computational linguistics
KW  - Modeling languages
KW  - Natural language processing systems
KW  - Semantics
KW  - Speech communication
KW  - Speech recognition
KW  - Automatic speech recognition
KW  - Automatic speech recognition system
KW  - Automatic transcription
KW  - Error rate
KW  - Evaluation metrics
KW  - In-depth analysis
KW  - Language model
KW  - Qualitative evaluations
KW  - Semantic analysis
KW  - Word error rate
KW  - Errors
PB  - International Speech Communication Association
SN  - 2308457X (ISSN)
LA  - English
J2  - Proc. Annu. Conf. Int. Speech. Commun. Assoc., INTERSPEECH
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 2; Conference name: 23rd Annual Conference of the International Speech Communication Association, INTERSPEECH 2022; Conference date: 18 September 2022 through 22 September 2022; Conference code: 183121
ER  -

TY  - CONF
AU  - Ogul, I.U.
AU  - Tekir, S.
TI  - Performance evaluation of BERT vectors on natural language inference models
ST  - Doǧal dil çikarimi modellerinde BERT vektörlerinin başarim deǧerlendirmesi
PY  - 2021
T2  - SIU 2021 - 29th IEEE Conference on Signal Processing and Communications Applications, Proceedings
C7  - 9478044
DO  - 10.1109/SIU53274.2021.9478044
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85111422010&doi=10.1109%2fSIU53274.2021.9478044&partnerID=40&md5=a032fa503646a66a05ba97a6abee6ef6
AD  - Bilgisayar Mühendisliǧi, Izmir Yüksek Teknoloji Enstitüsü, Izmir, Turkey
AB  - Natural language inference aims to classify the binary relation between opinionated sentences as a contradiction, entailment, or neutral. To accomplish the task, classifiers transform textual data into numerical representations called vectors or embeddings. In this study, both static (Glove, OntoNotes5) and contextual (BERT) word embedding methods are used. Classifying the logical relationships between opinionated sentences is difficult. These sentences have complex grammatical structures to convert them into logical representations, and traditional natural language processing solutions are insufficient to meet the requirement. This study uses Decomposable Attention and Advanced LSTM for Natural Language Inference (ESIM) deep learning methods to perform this classification. The best accuracy score is achieved with 88% using ESIM - BERT on the SNLI corpus. © 2021 IEEE.
KW  - BERT
KW  - Decomposable Attention
KW  - ESIM
KW  - Natural Language Inference
KW  - SNLI
KW  - Deep learning
KW  - Embeddings
KW  - Learning systems
KW  - Natural language processing systems
KW  - Signal processing
KW  - Embedding method
KW  - Grammatical structure
KW  - Learning methods
KW  - Logical relationships
KW  - Logical representations
KW  - NAtural language processing
KW  - Natural languages
KW  - Numerical representation
KW  - Long short-term memory
PB  - Institute of Electrical and Electronics Engineers Inc.
SN  - 978-166543649-6 (ISBN)
LA  - Turkish
J2  - SIU - IEEE Conf. Signal Process. Commun. Appl., Proc.
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 0; Conference name: 29th IEEE Conference on Signal Processing and Communications Applications, SIU 2021; Conference date: 9 June 2021 through 11 June 2021; Conference code: 170536
ER  -

TY  - CONF
AU  - Wang, C.
AU  - Liu, X.
AU  - Song, D.
TI  - IELM: An Open Information Extraction Benchmark for Pre-Trained Language Models
PY  - 2022
T2  - Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing, EMNLP 2022
SP  - 8417
EP  - 8437
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85149440891&partnerID=40&md5=b0a7a5af208d6a33288037fffc84286c
AD  - Washington University, St. Louis, United States
AD  - Tsinghua University, China
AD  - UC Berkeley, United States
AB  - We introduce a new open information extraction (OIE) benchmark for pre-trained language models (LM). Recent studies have demonstrated that pre-trained LMs, such as BERT and GPT, may store linguistic and relational knowledge. In particular, LMs are able to answer “fill-in-the-blank” questions when given a pre-defined relation category. Instead of focusing on pre-defined relations, we create an OIE benchmark aiming to fully examine the open relational information present in the pre-trained LMs. We accomplish this by turning pre-trained LMs into zero-shot OIE systems. Surprisingly, pre-trained LMs are able to obtain competitive performance on both standard OIE datasets (CaRB and Re-OIE2016) and two new large-scale factual OIE datasets (TAC KBP-OIE and Wikidata-OIE) that we establish via distant supervision. For instance, the zero-shot pre-trained LMs outperform the F1 score of the state-of-the-art supervised OIE methods on our factual OIE datasets without needing to use any training sets. © 2022 Association for Computational Linguistics.
KW  - Information retrieval
KW  - Large dataset
KW  - Zero-shot learning
KW  - Competitive performance
KW  - F1 scores
KW  - Information extraction methods
KW  - Information extraction systems
KW  - Language model
KW  - Large-scales
KW  - State of the art
KW  - Training sets
KW  - Computational linguistics
A2  - Goldberg Y.
A2  - Kozareva Z.
A2  - Zhang Y.
PB  - Association for Computational Linguistics (ACL)
LA  - English
J2  - Proc. Conf. Empir. Methods Nat. Lang. Process., EMNLP
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 1; Conference name: 2022 Conference on Empirical Methods in Natural Language Processing, EMNLP 2022; Conference date: 7 December 2022 through 11 December 2022; Conference code: 186895
ER  -

TY  - JOUR
AU  - Roshanzamir, A.
AU  - Aghajan, H.
AU  - Soleymani Baghshah, M.
TI  - Transformer-based deep neural network language models for Alzheimer’s disease risk assessment from targeted speech
PY  - 2021
T2  - BMC Medical Informatics and Decision Making
VL  - 21
IS  - 1
C7  - 92
DO  - 10.1186/s12911-021-01456-3
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85102362746&doi=10.1186%2fs12911-021-01456-3&partnerID=40&md5=95521a68019b47b578ee41d2eb335b00
AD  - Department of Computer Engineering, Sharif University of Technology, Azadi Avenue, Tehran, Iran
AD  - Department of Electrical Engineering, Sharif University of Technology, Azadi Avenue, Tehran, Iran
AB  - Background: We developed transformer-based deep learning models based on natural language processing for early risk assessment of Alzheimer’s disease from the picture description test. Methods: The lack of large datasets poses the most important limitation for using complex models that do not require feature engineering. Transformer-based pre-trained deep language models have recently made a large leap in NLP research and application. These models are pre-trained on available large datasets to understand natural language texts appropriately, and are shown to subsequently perform well on classification tasks with small training sets. The overall classification model is a simple classifier on top of the pre-trained deep language model. Results: The models are evaluated on picture description test transcripts of the Pitt corpus, which contains data of 170 AD patients with 257 interviews and 99 healthy controls with 243 interviews. The large bidirectional encoder representations from transformers (BERTLarge) embedding with logistic regression classifier achieves classification accuracy of 88.08%, which improves the state-of-the-art by 2.48%. Conclusions: Using pre-trained language models can improve AD prediction. This not only solves the problem of lack of sufficiently large datasets, but also reduces the need for expert-defined features. © 2021, The Author(s).
KW  - Alzheimer’s disease
KW  - Deep learning
KW  - Early risk assessment
KW  - Language model
KW  - Natural language processing
KW  - Picture description test
KW  - Transfer learning
KW  - Transformer
KW  - Alzheimer Disease
KW  - Humans
KW  - Natural Language Processing
KW  - Neural Networks, Computer
KW  - Risk Assessment
KW  - Speech
KW  - Alzheimer disease
KW  - human
KW  - natural language processing
KW  - risk assessment
KW  - speech
PB  - BioMed Central Ltd
SN  - 14726947 (ISSN)
C2  - 33750385
LA  - English
J2  - BMC Med. Informatics Decis. Mak.
M3  - Article
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 44; Correspondence Address: M. Soleymani Baghshah; Department of Computer Engineering, Sharif University of Technology, Tehran, Azadi Avenue, Iran; email: soleymani@sharif.edu
ER  -

TY  - CONF
AU  - Zhang, M.
AU  - Qiao, X.
AU  - Yang, H.
AU  - Tao, S.
AU  - Zhao, Y.
AU  - Li, Y.
AU  - Su, C.
AU  - Wang, M.
AU  - Guo, J.
AU  - Liu, Y.
AU  - Qin, Y.
TI  - Target-Side Language Model for Reference-Free Machine Translation Evaluation
PY  - 2022
T2  - Communications in Computer and Information Science
VL  - 1671 CCIS
SP  - 45
EP  - 53
DO  - 10.1007/978-981-19-7960-6_5
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85145255126&doi=10.1007%2f978-981-19-7960-6_5&partnerID=40&md5=252705084627bee5335620d10a6af17a
AD  - Huawei Translation Services Center, Beijing, China
AB  - With the rapid progress of deep learning in multilingual language processing, there has been a growing interest in reference-free machine translation evaluation, where source texts are directly compared with system translations. In this paper, we design a reference-free metric that is based only on a target-side language model for segment-level and system-level machine translation evaluations respectively, and it is found out that promising results could be achieved when only the target-side language model is used in such evaluations. From the experimental results on all the 18 language pairs of the WMT19 news translation shared task, it is interesting to see that the designed metrics with the multilingual model XLM-R get very promising results (best segment-level mean score on the from-English language pairs, and best system-level mean scores on the from-English and none-English language pairs) when the current SOTA metrics that we know are chosen for comparison. © 2022, The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd.
KW  - Machine translation evaluation
KW  - Reference-free metric
KW  - Target-side language model
KW  - Computer aided language translation
KW  - Deep learning
KW  - Neural machine translation
KW  - English languages
KW  - Language model
KW  - Language pairs
KW  - Language processing
KW  - Machine translation evaluations
KW  - Reference-free
KW  - Reference-free metric
KW  - Source text
KW  - System levels
KW  - Target-side language model
KW  - Computational linguistics
A2  - Xiao T.
A2  - Pino J.
PB  - Springer Science and Business Media Deutschland GmbH
SN  - 18650929 (ISSN); 978-981197959-0 (ISBN)
LA  - English
J2  - Commun. Comput. Info. Sci.
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 1; Correspondence Address: M. Zhang; Huawei Translation Services Center, Beijing, China; email: zhangmin186@huawei.com; Conference name: 18th China Conference on Machine Translation, CCMT 2022; Conference date: 6 August 2022 through 10 August 2022; Conference code: 287699
ER  -

TY  - CONF
AU  - Zhou, W.
AU  - Zeng, Y.
AU  - Diao, S.
AU  - Zhang, X.
TI  - VLUE: A Multi-Task Benchmark for Evaluating Vision-Language Models
PY  - 2022
T2  - Proceedings of Machine Learning Research
VL  - 162
SP  - 27395
EP  - 27411
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85139903037&partnerID=40&md5=a293e685c49763974ce2b5a93ad9803c
AD  - ByteDance AI Lab, China
AD  - The Hong Kong University of Science and Technology, Hong Kong
AB  - Recent advances in vision-language pre-training (VLP) have demonstrated impressive performance in a range of vision-language (VL) tasks. However, there exist several challenges for measuring the community's progress in building general multi-modal intelligence. First, most of the downstream VL datasets are annotated using raw images that are already seen during pre-training, which may result in an overestimation of current VLP models' generalization ability. Second, recent VLP work mainly focuses on absolute performance but overlooks the efficiency-performance trade-off, which is also an important indicator for measuring progress. To this end, we introduce the Vision-Language Understanding Evaluation (VLUE) benchmark, a multi-task multi-dimension benchmark for evaluating the generalization capabilities and the efficiency-performance trade-off (“Pareto SOTA”) of VLP models. We demonstrate that there is a sizable generalization gap for all VLP models when testing on out-of-distribution test sets annotated on images from a more diverse distribution that spreads across cultures. Moreover, we find that measuring the efficiency-performance trade-off of VLP models leads to complementary insights for several design choices of VLP. We release the VLUE benchmark to promote research on building vision-language models that generalize well to more diverse images and concepts unseen during pre-training, and are practical in terms of efficiency-performance trade-off. Copyright © 2022 by the author(s)
KW  - Benchmarking
KW  - Computational linguistics
KW  - Economic and social effects
KW  - Down-stream
KW  - In-buildings
KW  - Language model
KW  - Language understanding
KW  - Multi tasks
KW  - Multi-modal
KW  - Performance
KW  - Performance tradeoff
KW  - Pre-training
KW  - Training model
KW  - Efficiency
A2  - Chaudhuri K.
A2  - Jegelka S.
A2  - Song L.
A2  - Szepesvari C.
A2  - Niu G.
A2  - Sabato S.
PB  - ML Research Press
SN  - 26403498 (ISSN)
LA  - English
J2  - Proc. Mach. Learn. Res.
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 2; Correspondence Address: W. Zhou; email: wcszhou@outlook.com; Conference name: 39th International Conference on Machine Learning, ICML 2022; Conference date: 17 July 2022 through 23 July 2022; Conference code: 189002
ER  -

TY  - CONF
AU  - Mahor, K.
AU  - Manjhvar, A.K.
TI  - Public Sentiment Assessment of Coronavirus-Specific Tweets using a Transformer-based BERT Classifier
PY  - 2022
T2  - International Conference on Edge Computing and Applications, ICECAA 2022 - Proceedings
SP  - 1559
EP  - 1564
DO  - 10.1109/ICECAA55415.2022.9936448
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85142681724&doi=10.1109%2fICECAA55415.2022.9936448&partnerID=40&md5=9136a8475e044b2b14bcdbb2828f4984
AD  - Dept. of Computer Science & Engineering, Madhav Institute of Technology and Science, Gwalior, India
AB  - Worldwide, the (COVID-19) pandemic had also affected people's daily routines. In general also during lockdown periods, people around the world use social media to express their thoughts and feelings about the epidemic which has interrupted their daily lives. There has been a huge spike in tweets about coronavirus on Twitter in a short period of time, including both positive and negative messages. As a result of the wide range of content in the tweets, the researchers have turned to sentiment analysis in order to gauge how the general public feels about COVID-19. According to the findings of this study, the best way to examine COVID-19 is to look athow people use Twitter to share theirthoughts and opinions. Sentiment categorization can be accomplished by utilising a variety of feature sets as well as classifiers in combination with the suggested approach. Tweets collected from people with COVID-19 perceptions can be used to better understand and manage the epidemic. Positive, negative, as well as neutral emotion classifications are being usedto classify tweets. In this study, Tweets containing specific information about the Coronavirus epidemic are used as sentiment analysis packages. Bidirectional Encoder Representations from Transformers (BERT) are used to identify sentiment categories, whereas the TF-IDF (term frequency-inverse document frequency) prototype is used to summarise the topics of postings. Trend analysis and qualitative methods are being used to identify negative sentiment traits. In general, when it comes to sentiment classification, the fine-tuned BERT is very accurate. In addition, the COVID-19related post features of TF-IDF themes are accurately conveyed. Coronavirus tweet sentiments are analysedusing a BERT and TF-IDF hybrid classifier. Single-sentence classification is transformedinto pair-sentence classification, which solves BERT's performance issue in text classification problems. Our evaluation measures (accuracy= 0.70; precision= 0.67; recall= 0.64; and F1-score= 0.65) are used to evaluate the effectiveness of the classifier. © 2022 IEEE.
KW  - BERT classifier
KW  - COVID-19
KW  - Machine Learning
KW  - Sentiment Analysis (SA)
KW  - Twitter data
KW  - Classification (of information)
KW  - Coronavirus
KW  - Epidemiology
KW  - Inverse problems
KW  - Machine learning
KW  - Sentiment analysis
KW  - Social networking (online)
KW  - Bidirectional encoder representation from transformer classifier
KW  - Coronaviruses
KW  - Daily routines
KW  - Machine-learning
KW  - Public sentiments
KW  - Sentence classifications
KW  - Sentiment analyse
KW  - Sentiment analysis
KW  - Term frequencyinverse document frequency (TF-IDF)
KW  - Twitter data
KW  - COVID-19
PB  - Institute of Electrical and Electronics Engineers Inc.
SN  - 978-166548232-5 (ISBN)
LA  - English
J2  - Int. Conf. Edge Comput. Appl., ICECAA - Proc.
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 0; Conference name: 2022 International Conference on Edge Computing and Applications, ICECAA 2022; Conference date: 13 October 2022 through 15 October 2022; Conference code: 184201
ER  -

TY  - CONF
AU  - Seker, A.
AU  - Bandel, E.
AU  - Bareket, D.
AU  - Brusilovsky, I.
AU  - Greenfeld, R.S.
AU  - Tsarfaty, R.
TI  - AlephBERT: Language Model Pre-training and Evaluation from Sub-Word to Sentence Level
PY  - 2022
T2  - Proceedings of the Annual Meeting of the Association for Computational Linguistics
VL  - 1
SP  - 46
EP  - 56
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85141234976&partnerID=40&md5=3cb71719f2cb68f14ad0749327a353fb
AD  - Department of Computer Science, Bar Ilan University, Ramat-Gan, Israel
AB  - Large Pre-trained Language Models (PLMs) have become ubiquitous in the development of language understanding technology and lie at the heart of many artificial intelligence advances. While advances reported for English using PLMs are unprecedented, reported advances using PLMs for Hebrew are few and far between. The problem is twofold. First, so far, Hebrew resources for training large language models are not of the same magnitude as their English counterparts. Second, most benchmarks available to evaluate progress in Hebrew NLP require morphological boundaries which are not available in the output of PLMs. In this work we remedy both aspects. We present AlephBERT, a large PLM for Modern Hebrew, trained on larger vocabulary and a larger dataset than any Hebrew PLM before. Moreover, we introduce a novel neural architecture that recovers the morphological segments encoded in contextualized embedding vectors. Based on this new morphological component we offer an evaluation suite consisting of multiple tasks and benchmarks that cover sentence-level, word-level and sub-word level analyses. On all tasks, AlephBERT obtains state-of-the-art results beyond contemporary Hebrew state-of-the-art models. We make our AlephBERT model, the morphological extraction component, and the Hebrew evaluation suite publicly available, for future investigations and evaluations of Hebrew PLMs. © 2022 Association for Computational Linguistics.
KW  - Computational linguistics
KW  - Language model
KW  - Language understanding
KW  - Large datasets
KW  - Large vocabulary
KW  - Pre-evaluation
KW  - Pre-training
KW  - Sentence level
KW  - State of the art
KW  - Sub words
KW  - Word level
KW  - Large dataset
A2  - Muresan S.
A2  - Nakov P.
A2  - Villavicencio A.
PB  - Association for Computational Linguistics (ACL)
SN  - 0736587X (ISSN); 978-195591721-6 (ISBN)
LA  - English
J2  - Proc. Annu. Meet. Assoc. Comput Linguist.
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 11; Conference name: 60th Annual Meeting of the Association for Computational Linguistics, ACL 2022; Conference date: 22 May 2022 through 27 May 2022; Conference code: 181737
ER  -

TY  - CONF
AU  - Palma Preciado, V.M.
AU  - Sidorov, G.
AU  - Preciado, C.P.
TI  - Assessing Wordplay-Pun classification from JOKER dataset with pretrained BERT humorous models
PY  - 2022
T2  - CEUR Workshop Proceedings
VL  - 3180
SP  - 1828
EP  - 1833
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85136920312&partnerID=40&md5=c4b002f33dc8769f61b9d08d165a60a2
AD  - Instituto Politécnico Nacional (IPN), Centro de Investigación en Computación (CIC), Av. Juan de Dios Batiz, s/n, Mexico City, 07320, Mexico
AB  - Humor is one of the most subjective matters of human behavior since it includes a wide range of variables: sentiments, wordplay, double meanings structurally or phonetic, all of this within the construction of written humor. It is important to assess the humor from a different point of view since this variability tends to provide insight into the true structure or the main core of the humoristic dilemma, as we know the range of humor is so diverse that it presents a high skilled problem even on the simplest tasks. Pre-trained base Bert and DistilBert models trained with a humorous one-liners dataset were used, these trained models were tested with a merged dataset from JOKER from data of tasks 1 and task 3, the collected data was trimmed from duplicated records and special characters to create a final dataset with 3,601 humorous sentences. Under this experiment we try to see if our models were able to detect a different humor from the initial type with which they were trained, it was noted that both methods are able to successfully classify another type of humor. On the one hand, it was expected that the pre-trained models would be able to classify at least a portion of the humor in the data set, the results obtained were much better than anticipated, obtaining 95.64% for BERT and 92.58% for DistilBERT, the models were really able to identify humor, an analysis of the worst and best cases were taken into account. © 2022 Copyright for this paper by its authors.
KW  - Classifiers
KW  - Humor identification
KW  - Humourism
KW  - Transformers
KW  - Behavioral research
KW  - Machine learning
KW  - Data set
KW  - Human behaviors
KW  - Humor identification
KW  - Humourism
KW  - Simple++
KW  - Special characters
KW  - Transformer
KW  - Classification (of information)
A2  - Faggioli G.
A2  - University of Padova, Department of Information Engineering, Via Gradenigo 6/b, Padova
A2  - Ferro N.
A2  - University of Padova, Department of Information Engineering, Via Gradenigo 6/b, Padova
A2  - Hanbury A.
A2  - Vienna University of Technology, Favoritenstrasse 9, Vienna
A2  - Potthast M.
A2  - University of Leipzig, Augustusplatz 10, Leipzig
PB  - CEUR-WS
SN  - 16130073 (ISSN)
LA  - English
J2  - CEUR Workshop Proc.
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 1; Conference name: 2022 Conference and Labs of the Evaluation Forum, CLEF 2022; Conference date: 5 September 2022 through 8 September 2022; Conference code: 181762
ER  -

TY  - JOUR
AU  - Ormerod, M.
AU  - del Rincón, J.M.
AU  - Devereux, B.
TI  - Predicting semantic similarity between clinical sentence pairs using transformer models: Evaluation and representational analysis
PY  - 2021
T2  - JMIR Medical Informatics
VL  - 9
IS  - 5
C7  - e23099
DO  - 10.2196/23099
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85106949779&doi=10.2196%2f23099&partnerID=40&md5=65365efa2acbb29429798bd919851ea0
AD  - Institute of Electronics, Communications & Information Technology, School of Electronics, Electrical Engineering and Computer Science, Queen's University Belfast, Belfast, United Kingdom
AB  - Background: Semantic textual similarity (STS) is a natural language processing (NLP) task that involves assigning a similarity score to 2 snippets of text based on their meaning. This task is particularly difficult in the domain of clinical text, which often features specialized language and the frequent use of abbreviations. Objective: We created an NLP system to predict similarity scores for sentence pairs as part of the Clinical Semantic Textual Similarity track in the 2019 n2c2/OHNLP Shared Task on Challenges in Natural Language Processing for Clinical Data. We subsequently sought to analyze the intermediary token vectors extracted from our models while processing a pair of clinical sentences to identify where and how representations of semantic similarity are built in transformer models. Methods: Given a clinical sentence pair, we take the average predicted similarity score across several independently fine-tuned transformers. In our model analysis we investigated the relationship between the final model’s loss and surface features of the sentence pairs and assessed the decodability and representational similarity of the token vectors generated by each model. Results: Our model achieved a correlation of 0.87 with the ground-truth similarity score, reaching 6th place out of 33 teams (with a first-place score of 0.90). In detailed qualitative and quantitative analyses of the model’s loss, we identified the system’s failure to correctly model semantic similarity when both sentence pairs contain details of medical prescriptions, as well as its general tendency to overpredict semantic similarity given significant token overlap. The token vector analysis revealed divergent representational strategies for predicting textual similarity between bidirectional encoder representations from transformers (BERT)–style models and XLNet. We also found that a large amount information relevant to predicting STS can be captured using a combination of a classification token and the cosine distance between sentence-pair representations in the first layer of a transformer model that did not produce the best predictions on the test set. Conclusions: We designed and trained a system that uses state-of-the-art NLP models to achieve very competitive results on a new clinical STS data set. As our approach uses no hand-crafted rules, it serves as a strong deep learning baseline for this task. Our key contribution is a detailed analysis of the model’s outputs and an investigation of the heuristic biases learned by transformer models. We suggest future improvements based on these findings. In our representational analysis we explore how different transformer models converge or diverge in their representation of semantic signals as the tokens of the sentences are augmented by successive layers. This analysis sheds light on how these “black box” models integrate semantic similarity information in intermediate layers, and points to new research directions in model distillation and sentence embedding extraction for applications in clinical NLP. ©Mark Ormerod, Jesús Martínez del Rincón, Barry Devereux.
KW  - Biomedical NLP
KW  - Clinical text
KW  - Natural language processing
KW  - Representation learning
KW  - Transformer models
PB  - JMIR Publications Inc.
SN  - 22919694 (ISSN)
LA  - English
J2  - JMIR Med. Inform.
M3  - Article
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 16; Correspondence Address: M. Ormerod; BEng Institute of Electronics, Communications & Information Technology School of Electronics, Electrical Engineering and Computer Science, Queen's University Belfast, Queen's Island Belfast, Queen's Road, BT3 9DT, United Kingdom; email: mormerod01@qub.ac.uk
ER  -

TY  - CONF
AU  - Levy, S.
AU  - Allaway, E.
AU  - Subbiah, M.
AU  - Chilton, L.
AU  - Patton, D.
AU  - McKeown, K.
AU  - Wang, W.Y.
TI  - SAFETEXT: A Benchmark for Exploring Physical Safety in Language Models
PY  - 2022
T2  - Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing, EMNLP 2022
SP  - 2407
EP  - 2421
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85149166176&partnerID=40&md5=097367d2ff743f966d4c02e2220acce0
AD  - University of California, Santa Barbara, United States
AD  - Columbia University, United States
AD  - University of Pennsylvania, United States
AB  - Understanding what constitutes safe text is an important issue in natural language processing and can often prevent the deployment of models deemed harmful and unsafe. One such type of safety that has been scarcely studied is commonsense physical safety, i.e. text that is not explicitly violent and requires additional commonsense knowledge to comprehend that it leads to physical harm. We create the first benchmark dataset, SAFETEXT, comprising real-life scenarios with paired safe and physically unsafe pieces of advice. We utilize SAFETEXT to empirically study commonsense physical safety across various models designed for text generation and commonsense reasoning tasks. We find that state-of-the-art large language models are susceptible to the generation of unsafe text and have difficulty rejecting unsafe advice. As a result, we argue for further studies of safety and the assessment of commonsense physical safety in models before release. © 2022 Association for Computational Linguistics.
KW  - Natural language processing systems
KW  - Benchmark datasets
KW  - Commonsense knowledge
KW  - Commonsense reasoning
KW  - Language model
KW  - Language processing
KW  - Natural languages
KW  - Reasoning tasks
KW  - State of the art
KW  - Text generations
KW  - Computational linguistics
A2  - Goldberg Y.
A2  - Kozareva Z.
A2  - Zhang Y.
PB  - Association for Computational Linguistics (ACL)
LA  - English
J2  - Proc. Conf. Empir. Methods Nat. Lang. Process., EMNLP
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 4; Conference name: 2022 Conference on Empirical Methods in Natural Language Processing, EMNLP 2022; Conference date: 7 December 2022 through 11 December 2022; Conference code: 186895
ER  -

TY  - CONF
AU  - Yuan, H.
AU  - Yuan, Z.
AU  - Gan, R.
AU  - Zhang, J.
AU  - Xie, Y.
AU  - Yu, S.
TI  - BioBART: Pretraining and Evaluation of A Biomedical Generative Language Model
PY  - 2022
T2  - Proceedings of the Annual Meeting of the Association for Computational Linguistics
SP  - 97
EP  - 109
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85138171193&partnerID=40&md5=b07cd56273985e81def296b5513a22ee
AD  - Tsinghua University, China
AD  - International Digital Economy Academy, China
AB  - Pretrained language models have served as important backbones for natural language processing. Recently, in-domain pretraining has been shown to benefit various domain-specific downstream tasks. In the biomedical domain, natural language generation (NLG) tasks are of critical importance, while understudied. Approaching natural language understanding (NLU) tasks as NLG achieves satisfying performance in the general domain through constrained language generation or language prompting.We emphasize the lack of in-domain generative language models and the unsystematic generative downstream benchmarks in the biomedical domain, hindering the development of the research community. In this work, we introduce the generative language model BioBART that adapts BART to the biomedical domain. We collate various biomedical language generation tasks including dialogue, summarization, entity linking, and named entity recognition. BioBART pretrained on PubMed abstracts has enhanced performance compared to BART and set strong baselines on several tasks. Furthermore, we conduct ablation studies on the pretraining tasks for BioBART and find that sentence permutation has negative effects on downstream tasks. © 2022 Association for Computational Linguistics.
KW  - Natural language processing systems
KW  - Biomedical domain
KW  - Domain specific
KW  - Down-stream
KW  - Language generation
KW  - Language model
KW  - Language processing
KW  - Natural language generation
KW  - Natural languages
KW  - Performance
KW  - Pre-training
KW  - Computational linguistics
PB  - Association for Computational Linguistics (ACL)
SN  - 0736587X (ISSN); 978-195591727-8 (ISBN)
LA  - English
J2  - Proc. Annu. Meet. Assoc. Comput Linguist.
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 24; Correspondence Address: S. Yu; Tsinghua University, China; email: syu@tsinghua.edu.cn; Conference name: 21st Workshop on Biomedical Language Processing, BioNLP 2022 at the Association for Computational Linguistics Conference, ACL 2022; Conference code: 182391
ER  -

TY  - CONF
AU  - Moore, S.
AU  - Nguyen, H.A.
AU  - Bier, N.
AU  - Domadia, T.
AU  - Stamper, J.
TI  - Assessing the Quality of Student-Generated Short Answer Questions Using GPT-3
PY  - 2022
T2  - Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)
VL  - 13450 LNCS
SP  - 243
EP  - 257
DO  - 10.1007/978-3-031-16290-9_18
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85137976967&doi=10.1007%2f978-3-031-16290-9_18&partnerID=40&md5=853018256df7b46487458ae0c4f13a13
AD  - Carnegie Mellon University, Pittsburgh, 15213, PA, United States
AB  - Generating short answer questions is a popular form of learnersourcing with benefits for both the students’ higher-order thinking and the instructors’ collection of assessment items. However, assessing the quality of the student-generated questions can involve significant efforts from instructors and domain experts. In this work, we investigate the feasibility of leveraging students to generate short answer questions with minimal scaffolding and machine learning models to evaluate the student-generated questions. We had 143 students across 7 online college-level chemistry courses participate in an activity where they were prompted to generate a short answer question regarding the content they were presently learning. Using both human and automatic evaluation methods, we investigated the linguistic and pedagogical quality of these student-generated questions. Our results showed that 32% of the student-generated questions were evaluated by experts as high quality, indicating that they could be added and used in the course in their present condition. Additional expert evaluation identified that 23% of the student-generated questions assessed higher cognitive processes according to Bloom’s Taxonomy. We also identified the strengths and weaknesses of using a state-of-the-art language model, GPT-3, to automatically evaluate the student-generated questions. Our findings suggest that students are relatively capable of generating short answer questions that can be leveraged in their online courses. Based on the evaluation methods, recommendations for leveraging experts and automatic methods are discussed. © 2022, The Author(s), under exclusive license to Springer Nature Switzerland AG.
KW  - Question evaluation
KW  - Question generation
KW  - Question quality
KW  - Curricula
KW  - E-learning
KW  - Education computing
KW  - Learning systems
KW  - Quality control
KW  - Scaffolds
KW  - Automatic evaluation
KW  - Domain experts
KW  - Evaluation methods
KW  - Higher-order thinkings
KW  - Human evaluation
KW  - Machine learning models
KW  - Question evaluation
KW  - Question generation
KW  - Question quality
KW  - Student-Generated Questions
KW  - Students
A2  - Hilliger I.
A2  - Muñoz-Merino P.J.
A2  - De Laet T.
A2  - Ortega-Arranz A.
A2  - Farrell T.
PB  - Springer Science and Business Media Deutschland GmbH
SN  - 03029743 (ISSN); 978-303116289-3 (ISBN)
LA  - English
J2  - Lect. Notes Comput. Sci.
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 24; Correspondence Address: S. Moore; Carnegie Mellon University, Pittsburgh, 15213, United States; email: StevenJamesMoore@gmail.com; Conference name: 17th European Conference on Technology Enhanced Learning, EC-TEL 2022; Conference date: 12 September 2022 through 16 September 2022; Conference code: 282849
ER  -

TY  - JOUR
AU  - Khatun, M.C.S.
AU  - Muhit, M.A.
AU  - Hossain, M.J.
AU  - Al-Mansur, M.A.
AU  - Rahman, S.M.A.
TI  - Isolation of phytochemical constituents from Stevia rebaudiana (Bert.) and evaluation of their anticancer, antimicrobial and antioxidant properties via in vitro and in silico approaches
PY  - 2021
T2  - Heliyon
VL  - 7
IS  - 12
C7  - e08475
DO  - 10.1016/j.heliyon.2021.e08475
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85120330847&doi=10.1016%2fj.heliyon.2021.e08475&partnerID=40&md5=400d300fac91fba0440d6e373dbd701a
AD  - Department of Clinical Pharmacy and Pharmacology, Faculty of Pharmacy, University of Dhaka, Dhaka, 1000, Bangladesh
AD  - Department of Pharmaceutical Chemistry, Faculty of Pharmacy, University of Dhaka, Dhaka, 1000, Bangladesh
AD  - Institute of National Analytical Research and Service (INARS), Bangladesh Council of Scientific and Industrial Research (BCSIR), Dhanmondi, Dhaka, 1205, Bangladesh
AB  - The current study was designed to isolate and characterize some bioactive secondary metabolites by using repeated chromatographic and spectroscopic techniques, targeting their anticancer, antimicrobial, and antioxidant properties through in vitro and in silico approaches. Six compounds were isolated and analyzed by thin layer chromatographic technique and the compounds were identified as 5-O-caffeoyl quinic acid (1), syringin (2), luteolin (3), apigenin (4), jhanol (5), and jhanidiol (6) based on spectroscopic methods. The cytotoxic effect of each compound was dose-dependent, and compound 1 showed a higher anti-proliferative effect (IC50 = 181.3 μg/ml) than other compounds (compound 2, 4, 5, and 6). Besides, compound 1 showed the most promising antibacterial activity with a zone of inhibition ranges from 12–15 mm against different strains compared to ciprofloxacin (14–22 mm). In contrast, compound 3 exerted the highest scavenging property against DPPH free radical. Finally, the in vitro bioactivities were also supported by molecular docking studies. The computational study demonstrated that the isolated compounds exerted stronger affinity compared to the standard drugs towards the binding sites of dihydrofolate reductase (DHFR), glutathione reductase, and urase oxidase. © 2021 The Author(s)
KW  - Antimicrobial
KW  - Antioxidant
KW  - Cytotoxicity
KW  - Molecular docking
KW  - Phenolic constituents
KW  - Stevia rebaudiana
PB  - Elsevier Ltd
SN  - 24058440 (ISSN)
LA  - English
J2  - Heliyon
M3  - Article
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 15; Correspondence Address: S.M.A. Rahman; Department of Clinical Pharmacy and Pharmacology, Faculty of Pharmacy, University of Dhaka, Dhaka, 1000, Bangladesh; email: smarahman@du.ac.bd
ER  -

TY  - CONF
AU  - Zhang, C.
AU  - D’Haro, L.F.
AU  - Chen, Y.
AU  - Friedrichs, T.
AU  - Li, H.
TI  - Investigating the Impact of Pre-trained Language Models on Dialog Evaluation
PY  - 2022
T2  - Lecture Notes in Electrical Engineering
VL  - 943
SP  - 291
EP  - 306
DO  - 10.1007/978-981-19-5538-9_21
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85142724573&doi=10.1007%2f978-981-19-5538-9_21&partnerID=40&md5=59caffcde126231d52c74eb1456280e3
AD  - National University of Singapore (NUS), Singapore, Singapore
AD  - Universidad Politécnica de Madrid (UPM), Madrid, Spain
AD  - Robert Bosch (SEA) Pte Ltd, Singapore, Singapore
AD  - Guangdong Provincial Key Laboratory of Big Data Computing, The Chinese University of Hong Kong, Shenzhen, China
AB  - Recently, there is a surge of interest in applying pre-trained language models (Pr-LM) in automatic open-domain dialog evaluation. Pr-LMs offer a promising direction for addressing the multi-domain evaluation challenge. Yet, the impact of different Pr-LMs on the performance of automatic metrics is not well-understood. This paper examines eight different Pr-LMs and studies their impact on three typical automatic dialog evaluation metrics across three different dialog evaluation benchmarks. Specifically, we analyze how the choice of Pr-LMs affects the performance of automatic metrics. Extensive correlation analyses on each of the metrics are performed to assess the effects of different Pr-LMs along various axes, including pre-training objectives, dialog evaluation criteria, model size, and cross-dataset robustness. This study serves as the first comprehensive assessment of the effects of different Pr-LMs on automatic dialog evaluation. © 2022, The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd.
KW  - Automatic metrics
KW  - Correlation analysis
KW  - Dialogue evaluation
KW  - Evaluation criteria
KW  - Evaluation metrics
KW  - Language model
KW  - Model size
KW  - Multi-domains
KW  - Performance
KW  - Pre-training
KW  - Computational linguistics
A2  - Stoyanchev S.
A2  - Ultes S.
A2  - Li H.
PB  - Springer Science and Business Media Deutschland GmbH
SN  - 18761100 (ISSN); 978-981195537-2 (ISBN)
LA  - English
J2  - Lect. Notes Electr. Eng.
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 1; Correspondence Address: C. Zhang; National University of Singapore (NUS), Singapore, Singapore; email: chen_zhang@u.nus.edu; Conference name: 12th International Workshop on Spoken Dialogue System Technology, IWSDS 2021; Conference date: 15 November 2021 through 17 November 2021; Conference code: 285769
ER  -

TY  - CONF
AU  - Dascalu, M.-D.
AU  - Ruseti, S.
AU  - Dascalu, M.
AU  - McNamara, D.S.
AU  - Trausan-Matu, S.
TI  - Dialogism Meets Language Models for Evaluating Involvement in CSCL Conversations
PY  - 2022
T2  - Smart Innovation, Systems and Technologies
VL  - 249
SP  - 67
EP  - 78
DO  - 10.1007/978-981-16-3930-2_6
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85115255751&doi=10.1007%2f978-981-16-3930-2_6&partnerID=40&md5=edac669d52bdf4de6091289bd5e40ee2
AD  - University Politehnica of Bucharest, 313 Splaiul Independentei, Bucharest, 060042, Romania
AD  - Academy of Romanian Scientists, Str. Ilfov, Nr. 3, Bucharest, 050044, Romania
AD  - Department of Psychology, Arizona State University, PO Box 871104, Tempe, AZ, United States
AB  - The use of technology as a facilitator in learning environments has become increasingly prevalent with the global pandemic caused by COVID-19. As such, computer-supported collaborative learning (CSCL) gains a wider adoption in contrast to traditional learning methods. At the same time, the need for automated tools capable of assessing and stimulating collaboration between participants has become more stringent, as human monitoring of the increasing volume of conversations becomes overwhelming. This paper introduces a method grounded in dialogism for evaluating students’ involvement in chat conversations based on semantic chains computed using language models. These semantic chains reflect emergent voices from dialogism that span and interact throughout the conversation. Our integrated method uses contextual information captured by BERT transformer models to identify links in a chain that connects semantically related concepts from a voice uttered by one or more participants. Two types of visualizations were generated to depict the longitudinal propagation and the transversal inter-animation of voices within the conversation. In addition, a list of handcrafted features derived from the constructed chains and computed for each participant is introduced. Several machine learning algorithms were tested using these features to evaluate the extent to which semantic chains are predictive of student involvement in chat conversations. © 2022, The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd.
KW  - Computer-supported collaborative learning
KW  - Dialogism
KW  - Language models
KW  - Semantic chains
KW  - Computational linguistics
KW  - Computer aided instruction
KW  - Ecosystems
KW  - Education computing
KW  - Machine learning
KW  - Regional planning
KW  - Semantics
KW  - Computer Supported Collaborative Learning
KW  - Contextual information
KW  - Integrated method
KW  - Learning environments
KW  - Longitudinal propagation
KW  - Student involvements
KW  - Traditional learning
KW  - Transformer models
KW  - Learning algorithms
A2  - Mealha O.
A2  - Dascalu M.
A2  - Di Mascio T.
PB  - Springer Science and Business Media Deutschland GmbH
SN  - 21903018 (ISSN); 978-981163929-6 (ISBN)
LA  - English
J2  - Smart Innov. Syst. Technol.
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 0; Correspondence Address: M. Dascalu; University Politehnica of Bucharest, Bucharest, 313 Splaiul Independentei, 060042, Romania; email: mihai.dascalu@upb.ro; Conference name: 6th International Conference on Smart Learning Ecosystems and Regional Development, SLERD 2021; Conference date: 24 June 2021 through 25 June 2021; Conference code: 264739
ER  -

TY  - CONF
AU  - Garcia, M.
AU  - Crespo-Otero, A.
TI  - A Targeted Assessment of the Syntactic Abilities of Transformer Models for Galician-Portuguese
PY  - 2022
T2  - Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)
VL  - 13208 LNAI
SP  - 46
EP  - 56
DO  - 10.1007/978-3-030-98305-5_5
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85127215645&doi=10.1007%2f978-3-030-98305-5_5&partnerID=40&md5=ae6d77d7f0f9db4cc109a9cff687d996
AD  - CiTIUS - Centro Singular de Investigación en Tecnoloxías Intelixentes, Universidade de Santiago de Compostela, Galiza, Santiago de Compostela, Spain
AB  - This paper presents a targeted syntactic evaluation of Transformer models for Galician-Portuguese. We defined three experiments that allow to explore how these models, trained with a masked language modeling objective, encode syntactic knowledge. To do so, we created a new dataset including test instances of number (subject-verb), gender (subject-predicative adjective), and person (subject-inflected infinitive) agreement. This dataset was used to evaluate monolingual and multilingual BERT models, controlling for various aspects such as the presence of attractors or the distance between the dependent elements. The results show that Transformer models perform competently in many cases, but they are generally confounded by the presence of attractors in long-distance dependencies. Moreover, the different behavior of monolingual models trained with the same corpora reinforces the need for a deep exploration of the network architectures and their learning process. © 2022, Springer Nature Switzerland AG.
KW  - Language models
KW  - Syntax
KW  - Targeted syntactic evaluation
KW  - Computational linguistics
KW  - Dynamical systems
KW  - Modeling languages
KW  - Network architecture
KW  - Statistical tests
KW  - Language model
KW  - Learning process
KW  - Long-distance dependencies
KW  - Modeling objectives
KW  - Targeted syntactic evaluation
KW  - Test instances
KW  - Transformer modeling
KW  - Syntactics
A2  - Pinheiro V.
A2  - Gamallo P.
A2  - Amaro R.
A2  - Scarton C.
A2  - Batista F.
A2  - Silva D.
A2  - Magro C.
A2  - Pinto H.
PB  - Springer Science and Business Media Deutschland GmbH
SN  - 03029743 (ISSN); 978-303098304-8 (ISBN)
LA  - English
J2  - Lect. Notes Comput. Sci.
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 2; Correspondence Address: M. Garcia; CiTIUS - Centro Singular de Investigación en Tecnoloxías Intelixentes, Universidade de Santiago de Compostela, Santiago de Compostela, Galiza, Spain; email: marcos.garcia.gonzalez@usc.gal; Conference name: 15th International Conference on the Computational Processing of Portuguese, PROPOR 2022; Conference date: 21 March 2022 through 23 March 2022; Conference code: 275209
ER  -

TY  - CONF
AU  - Shah, R.S.
AU  - Chawla, K.
AU  - Eidnani, D.
AU  - Shah, A.
AU  - Du, W.
AU  - Chava, S.
AU  - Raman, N.
AU  - Smiley, C.
AU  - Chen, J.
AU  - Yang, D.
TI  - WHEN FLUE MEETS FLANG: Benchmarks and Large Pre-trained Language Model for Financial Domain
PY  - 2022
T2  - Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing, EMNLP 2022
SP  - 2322
EP  - 2335
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85149441059&partnerID=40&md5=8ceeafd5c40161aca3be006a7ac14d52
AD  - Georgia Institute of Technology, United States
AD  - JPMorgan AI Research
AD  - Stanford University, United States
AB  - Pre-trained language models have shown impressive performance on a variety of tasks and domains. Previous research on financial language models usually employs a generic training scheme to train standard model architectures, without completely leveraging the richness of the financial data. We propose a novel domain specific Financial LANGuage model (FLANG) which uses financial keywords and phrases for better masking, together with span boundary objective and in-filing objective. Additionally, the evaluation benchmarks in the field have been limited. To this end, we contribute the Financial Language Understanding Evaluation (FLUE), an open-source comprehensive suite of benchmarks for the financial domain. These include new benchmarks across 5 NLP tasks in financial domain as well as common benchmarks used in the previous research. Experiments on these benchmarks suggest that our model outperforms those in prior literature on a variety of NLP tasks. Our models, code and benchmark data are publicly available on Github and Huggingface. © 2022 Association for Computational Linguistics.
KW  - Computational linguistics
KW  - Finance
KW  - Domain specific
KW  - Financial data
KW  - Financial domains
KW  - Language model
KW  - Language understanding
KW  - Modeling architecture
KW  - Novel domain
KW  - Performance
KW  - Standard model
KW  - Training schemes
KW  - Natural language processing systems
A2  - Goldberg Y.
A2  - Kozareva Z.
A2  - Zhang Y.
PB  - Association for Computational Linguistics (ACL)
LA  - English
J2  - Proc. Conf. Empir. Methods Nat. Lang. Process., EMNLP
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 9; Conference name: 2022 Conference on Empirical Methods in Natural Language Processing, EMNLP 2022; Conference date: 7 December 2022 through 11 December 2022; Conference code: 186895
ER  -

TY  - JOUR
AU  - Pan, Y.
AU  - Wang, C.
AU  - Hu, B.
AU  - Xiang, Y.
AU  - Wang, X.
AU  - Chen, Q.
AU  - Chen, J.
AU  - Du, J.
TI  - A BERT-Based Generation Model to Transform Medical Texts to SQL Queries for Electronic Medical Records: Model Development and Validation
PY  - 2021
T2  - JMIR Medical Informatics
VL  - 9
IS  - 12
C7  - e32698
DO  - 10.2196/32698
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85122020760&doi=10.2196%2f32698&partnerID=40&md5=7840840be7fb7168f36e5c90f4ee02b2
AD  - Intelligent Computing Research Center, Harbin Institute of Technology, Shenzhen, China
AD  - Peng Cheng Laboratory, Shenzhen, China
AD  - University of Texas Health Science Center at Houston, Houston, TX, United States
AB  - Background: Electronic medical records (EMRs) are usually stored in relational databases that require SQL queries to retrieve information of interest. Effectively completing such queries can be a challenging task for medical experts due to the barriers in expertise. Existing text-to-SQL generation studies have not been fully embraced in the medical domain. Objective: The objective of this study was to propose a neural generation model that can jointly consider the characteristics of medical text and the SQL structure to automatically transform medical texts to SQL queries for EMRs. Methods: We proposed a medical text–to-SQL model (MedTS), which employed a pretrained Bidirectional Encoder Representations From Transformers model as the encoder and leveraged a grammar-based long short-term memory network as the decoder to predict the intermediate representation that can easily be transformed into the final SQL query. We adopted the syntax tree as the intermediate representation rather than directly regarding the SQL query as an ordinary word sequence, which is more in line with the tree-structure nature of SQL and can also effectively reduce the search space during generation. Experiments were conducted on the MIMICSQL dataset, and 5 competitor methods were compared. Results: Experimental results demonstrated that MedTS achieved the accuracy of 0.784 and 0.899 on the test set in terms of logic form and execution, respectively, which significantly outperformed the existing state-of-the-art methods. Further analyses proved that the performance on each component of the generated SQL was relatively balanced and offered substantial improvements. Conclusions: The proposed MedTS was effective and robust for improving the performance of medical text–to-SQL generation, indicating strong potential to be applied in the real medical scenario. © Youcheng Pan, Chenghao Wang, Baotian Hu, Yang Xiang, Xiaolong Wang, Qingcai Chen, Junjie Chen, Jingcheng Du.
KW  - BERT
KW  - Electronic medical record
KW  - Grammar-based decoding
KW  - Text-to-SQL generation
KW  - Tree-structured intermediate representation
PB  - JMIR Publications Inc.
SN  - 22919694 (ISSN)
LA  - English
J2  - JMIR Med. Inform.
M3  - Article
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 2; Correspondence Address: B. Hu; Intelligent Computing Research Center, Harbin Institute of Technology, Shenzhen, No. 6, Pingshan 1st Road, 518055, China; email: hubaotian@hit.edu.cn
ER  -

TY  - JOUR
AU  - Pan, X.
AU  - Zhang, M.
AU  - Yan, Y.
AU  - Lu, Y.
AU  - Yang, M.
TI  - Evaluating Privacy Risks of Deep Learning Based General-Purpose Language Models
ST  - 通用深度学习语言模型的隐私风险评估
PY  - 2021
T2  - Jisuanji Yanjiu yu Fazhan/Computer Research and Development
VL  - 58
IS  - 5
SP  - 1092
EP  - 1105
DO  - 10.7544/issn1000-1239.2021.20200908
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85106377167&doi=10.7544%2fissn1000-1239.2021.20200908&partnerID=40&md5=456d036ea0b0195fcfb381165573cd02
AD  - School of Computer Science, Fudan University, Shanghai, 200438, China
AB  - Recently, a variety of Transformer-based GPLMs (general-purpose language models), including Google's BERT (bidirectional encoder representation from transformers), are proposed in NLP (natural language processing). GPLMs help achieve state-of-the-art performance on a wide range of NLP tasks, and are applied in industrial applications. Despite their generality and promising performance, a recent research work first shows that an attacker, who has access to the textual embeddings produced by GPLMs, can infer whether the original text contains a specific keyword with high accuracy. However, the previous work has the following limitations. First, they only consider the occurrence of one sensitive word as the sensitive information to steal, which is still far from a threatening privacy violation. Besides, their attack requires several rather strict security assumptions on the attacker's capability, e.g., the attacker knows which GPLM produces the victim's textual embeddings. Moreover, they only consider the GPLMs designed for English texts. To address the aforementioned limitations and serve as a complement to their work, this paper proposes a more comprehensive privacy theft chain which is designed to explore whether there are even more privacy risks in general-purpose language models. Via experiments on 13 commercial GPLMs, we empirically show that an attacker can step by step infer the GPLM type behind the textual embedding with near 100% accuracy, then infer the textual length with over 70% on average and finally probe sensitive words that possibly occur in the original text, which brings useful information for the attacker to finally reconstruct the sensitive semantics. Besides, this paper also evaluates the privacy risks of three typical general-purpose language models in Chinese. The results confirm that privacy risks also exist in Chinese general-purpose language models, which calls for mitigation studies in the future. © 2021, Science Press. All right reserved.
KW  - Artificial intelligence
KW  - Deep learning
KW  - Deep learning privacy
KW  - General-purpose language model (GPLMs)
KW  - Information security
KW  - Natural language processing
KW  - Computational linguistics
KW  - Embeddings
KW  - Natural language processing systems
KW  - Privacy by design
KW  - Semantics
KW  - General purpose languages
KW  - High-accuracy
KW  - Nlp (natural language processing)
KW  - Privacy violation
KW  - Recent researches
KW  - Sensitive informations
KW  - Sensitive semantics
KW  - State-of-the-art performance
KW  - Deep learning
PB  - Science Press
SN  - 10001239 (ISSN)
LA  - Chinese
J2  - Jisuanji Yanjiu yu Fazhan
M3  - Article
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 2; Correspondence Address: M. Yang; School of Computer Science, Fudan University, Shanghai, 200438, China; email: m_yang@fudan.edu.cn; CODEN: JYYFE
ER  -

TY  - CONF
AU  - Cattan, O.
AU  - Ghannay, S.
AU  - Servan, C.
AU  - Rosset, S.
TI  - Benchmarking Transformers-based models on French Spoken Language Understanding tasks
PY  - 2022
T2  - Proceedings of the Annual Conference of the International Speech Communication Association, INTERSPEECH
VL  - 2022-September
SP  - 1238
EP  - 1242
DO  - 10.21437/Interspeech.2022-385
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85140085453&doi=10.21437%2fInterspeech.2022-385&partnerID=40&md5=6eef21c2ff586ff79ce2628a91bfdb1e
AD  - Université Paris-Saclay, CNRS, LISN, Orsay, 91405, France
AD  - QWANT, 10 boulevard Haussmann, Paris, 75009, France
AB  - In the last five years, the rise of the self-attentional Transformer-based architectures led to state-of-the-art performances over many natural language tasks. Although these approaches are increasingly popular, they require large amounts of data and computational resources. There is still a substantial need for benchmarking methodologies ever upwards on under-resourced languages in data-scarce application conditions. Most pre-trained language models were massively studied using the English language and only a few of them were evaluated on French. In this paper, we propose a unified benchmark, focused on evaluating models quality and their ecological impact on two well-known French spoken language understanding tasks. Especially we benchmark thirteen well-established Transformer-based models on the two available spoken language understanding tasks for French: MEDIA and ATIS-FR. Within this framework, we show that compact models can reach comparable results to bigger ones while their ecological impact is considerably lower. However, this assumption is nuanced and depends on the considered compression method. Copyright © 2022 ISCA.
KW  - Benchmarking
KW  - French Language
KW  - Language Models
KW  - Model costs
KW  - Spoken Language Understanding
KW  - Computational linguistics
KW  - Ecology
KW  - Speech communication
KW  - Speech recognition
KW  - Computational resources
KW  - Data resources
KW  - Ecological impacts
KW  - French language
KW  - Language model
KW  - Large amounts of data
KW  - Model cost
KW  - Natural languages
KW  - Spoken language understanding
KW  - State-of-the-art performance
KW  - Benchmarking
PB  - International Speech Communication Association
SN  - 2308457X (ISSN)
LA  - English
J2  - Proc. Annu. Conf. Int. Speech. Commun. Assoc., INTERSPEECH
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 0; Conference name: 23rd Annual Conference of the International Speech Communication Association, INTERSPEECH 2022; Conference date: 18 September 2022 through 22 September 2022; Conference code: 183121
ER  -

TY  - CONF
AU  - Parcalabescu, L.
AU  - Cafagna, M.
AU  - Muradjan, L.
AU  - Frank, A.
AU  - Calixto, I.
AU  - Gatt, A.
TI  - VALSE: A Task-Independent Benchmark for Vision and Language Models Centered on Linguistic Phenomena
PY  - 2022
T2  - Proceedings of the Annual Meeting of the Association for Computational Linguistics
VL  - 1
SP  - 8253
EP  - 8280
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85138525239&partnerID=40&md5=839c234bbc2eaaa72ccf0ad09b82c572
AD  - Heidelberg University, Department of Computational Linguistics, Germany
AD  - University of Malta, Institute of Linguistics and Language Technology, Malta
AD  - New York University, United States
AD  - ILLC, University of Amsterdam, Netherlands
AD  - Utrecht University, Department of Information and Computing Sciences, Netherlands
AB  - We propose VALSE (Vision And Language Structured Evaluation), a novel benchmark designed for testing general-purpose pretrained vision and language (V&L) models for their visio-linguistic grounding capabilities on specific linguistic phenomena. VALSE offers a suite of six tests covering various linguistic constructs. Solving these requires models to ground linguistic phenomena in the visual modality, allowing more fine-grained evaluations than hitherto possible. We build VALSE using methods that support the construction of valid foils, and report results from evaluating five widely-used V&L models. Our experiments suggest that current models have considerable difficulty addressing most phenomena. Hence, we expect VALSE to serve as an important benchmark to measure future progress of pretrained V&L models from a linguistic perspective, complementing the canonical taskcentred V&L evaluations. © 2022 Association for Computational Linguistics.
KW  - Current modeling
KW  - Fine grained
KW  - Language evaluations
KW  - Language model
KW  - Linguistic phenomena
KW  - Structured evaluation
KW  - Vision model
KW  - Visual modalities
A2  - Muresan S.
A2  - Nakov P.
A2  - Villavicencio A.
PB  - Association for Computational Linguistics (ACL)
SN  - 0736587X (ISSN); 978-195591721-6 (ISBN)
LA  - English
J2  - Proc. Annu. Meet. Assoc. Comput Linguist.
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 10; Correspondence Address: L. Parcalabescu; Heidelberg University, Department of Computational Linguistics, Germany; email: parcalabescu@cl.uni-heidelberg.de; Conference name: 60th Annual Meeting of the Association for Computational Linguistics, ACL 2022; Conference date: 22 May 2022 through 27 May 2022; Conference code: 181737
ER  -

TY  - CONF
AU  - Mumtaz, D.
AU  - Jena, A.
AU  - Jakhetiya, V.
AU  - Nathwani, K.
AU  - Guntuku, S.C.
TI  - TRANSFORMER-BASED QUALITY ASSESSMENT MODEL FOR GENERALIZED USER-GENERATED MULTIMEDIA AUDIO CONTENT
PY  - 2022
T2  - Proceedings of the Annual Conference of the International Speech Communication Association, INTERSPEECH
VL  - 2022-September
SP  - 674
EP  - 678
DO  - 10.21437/Interspeech.2022-10386
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85140099031&doi=10.21437%2fInterspeech.2022-10386&partnerID=40&md5=e1fcdc5cc2eb51b01568ef92617f55a0
AD  - IIT JAMMU, India
AD  - University of Pennsylvania, United States
AB  - In this paper, we propose a computational measure for the quality of audio in user-generated multimedia (UGM) in accordance with the human perceptual system. To this end, we first extend the previously proposed IIT-JMU-UGM Audio dataset by including samples with more diverse context, content, distortion types, and intensities, along with implicitly distorted audio that reflect realistic scenarios. We conduct subjective testing on the extended database containing 2075 audio clips to obtain the mean opinion scores for each sample. We then introduce transformer-based learning to the domain of audio quality assessment, which is trained on three vital audio features: Mel-frequency cepstral coefficients, chroma, and Mel-scaled spectrogram. The proposed non-intrusive transformer-based model is compared against state-of-the-art methods and found to outperform Simple RNN, LSTM, and GRU models by over 4%. The database and the source code will be made public upon acceptance. Copyright © 2022 ISCA.
KW  - Non-intrusive Audio Quality Assessment
KW  - Transformer-based Learning
KW  - User-generated Multimedia
KW  - Audio signal processing
KW  - Long short-term memory
KW  - Speech communication
KW  - Audio content
KW  - Audio quality assessments
KW  - Human perceptual system
KW  - Non-intrusive
KW  - Non-intrusive audio quality assessment
KW  - Quality assessment model
KW  - Realistic scenario
KW  - Transformer-based learning
KW  - User-generated
KW  - User-generated multimedium
KW  - Subjective testing
PB  - International Speech Communication Association
SN  - 2308457X (ISSN)
LA  - English
J2  - Proc. Annu. Conf. Int. Speech. Commun. Assoc., INTERSPEECH
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 0; Conference name: 23rd Annual Conference of the International Speech Communication Association, INTERSPEECH 2022; Conference date: 18 September 2022 through 22 September 2022; Conference code: 183121
ER  -

TY  - CONF
AU  - Alhamed, M.
AU  - Storer, T.
TI  - Evaluation of Context-Aware Language Models and Experts for Effort Estimation of Software Maintenance Issues
PY  - 2022
T2  - Proceedings - 2022 IEEE International Conference on Software Maintenance and Evolution, ICSME 2022
SP  - 129
EP  - 138
DO  - 10.1109/ICSME55016.2022.00020
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85146217263&doi=10.1109%2fICSME55016.2022.00020&partnerID=40&md5=85cc33d4f8463b990d64566f077cdc7a
AD  - University of Glasgow, School of Computing Science, Glasgow, United Kingdom
AB  - Reflecting upon recent advances in Natural Language Processing (NLP), this paper evaluates the effectiveness of context-aware NLP models for predicting software task effort estimates. Term Frequency-Inverse Document Frequency (TF-IDF) and Bidirectional Encoder Representations from Transformers (BERT) were used as feature extraction methods; Random forest and BERT feed-forward linear neural networks were used as classifiers. Using three datasets drawn from open-source projects and one from a commercial project, the paper evaluates the models and compares the best performing model with expert estimates from both kinds of datasets. The results suggest that BERT as feature extraction and classifier shows slightly better performance than other combinations, but that there is no significant difference between the presented methods. On the other hand, the results show that expert and Machine Learning (ML) estimate performances are similar, with the experts' performance being slightly better. Both findings confirmed existing literature, but using substantially different experimental settings. © 2022 IEEE.
KW  - BERT
KW  - datasets
KW  - empirical software engineering
KW  - machine learning
KW  - NLP
KW  - Planing Poker
KW  - software effort estimation
KW  - software maintenance issues
KW  - TF-IDF
KW  - Classification (of information)
KW  - Computer software maintenance
KW  - Extraction
KW  - Feedforward neural networks
KW  - Inverse problems
KW  - Learning algorithms
KW  - Natural language processing systems
KW  - Open source software
KW  - Text processing
KW  - Bidirectional encoder representation from transformer
KW  - Dataset
KW  - Empirical Software Engineering
KW  - Language processing
KW  - Machine-learning
KW  - Natural language processing
KW  - Natural languages
KW  - Planing poker
KW  - Software effort estimation
KW  - Software maintenance issue
KW  - Term frequencyinverse document frequency (TF-IDF)
KW  - Feature extraction
PB  - Institute of Electrical and Electronics Engineers Inc.
SN  - 978-166547956-1 (ISBN)
LA  - English
J2  - Proc. - IEEE Int. Conf. Softw. Maint. Evol., ICSME
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 1; Conference name: 39th IEEE International Conference on Software Maintenance and Evolution, ICSME 2022; Conference date: 2 October 2022 through 7 October 2022; Conference code: 185336
ER  -

TY  - CONF
AU  - Feng, F.
AU  - Rui, X.
AU  - Wang, W.
AU  - Cao, Y.
AU  - Chua, T.-S.
TI  - Pre-training and evaluation of numeracy-oriented language model
PY  - 2021
T2  - ICAIF 2021 - 2nd ACM International Conference on AI in Finance
C7  - 47
DO  - 10.1145/3490354.3494412
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85130537065&doi=10.1145%2f3490354.3494412&partnerID=40&md5=d41695613ce219d171262ada0e365fc6
AD  - Sea-NExT Joint Lab, Singapore
AD  - National University of Singapore, Singapore
AD  - Tsinghua University, China
AD  - Nanyang Technological University, Singapore
AB  - Pre-trained language model (LM) has led to significant performance gains in various natural language processing (NLP) applications due to its strong literacy, e.g., the ability to capture word dependencies. However, the existing pre-trained LMs largely ignore numeracy, i.e., treating numbers within text as plain words and without understanding the basic numerical concepts. The weak numeracy has become a barrier to the use of pre-trained LMs in NLP applications over financial documents such as annual filings and analyst reports that are number intensive. However, the understanding and analysis of financial documents are becoming gradationally important. To bridge this gap, this work explores the central theme of numerical pre-training to empower LM with numeracy. In particular, we propose two numerical pre-training methods with objectives that encourage the LM to understand the magnitude and value of numbers and encode the dependency between a number and its context. By applying the proposed methods on BERT, we pre-train two LMs, named BERT-M and BERT-V. Moreover, we construct four datasets of financial documents for evaluating the numeracy of pre-trained LM, which focus on three fundamental perspectives of numeracy: a) number embedding; b) number-text composition; and c) number-number composition. Extensive experiments on the datasets validate the effectiveness of the pre-trained BERT-M and BERT-V, which outperform the state-of-the-art LM for financial documents (FinBERT) by 4.83% and 4.34% on average. Furthermore, their aggregation named BERT-MV increases the gain to 10.88%.  © 2021 ACM.
KW  - language model
KW  - numeracy
KW  - representation learning
KW  - Computational linguistics
KW  - Finance
KW  - Natural language processing systems
KW  - Numerical methods
KW  - B-number
KW  - Embeddings
KW  - Language model
KW  - Natural language processing applications
KW  - Numerical concepts
KW  - Performance Gain
KW  - Pre-evaluation
KW  - Pre-training
KW  - Representation learning
KW  - Training methods
KW  - Statistics
PB  - Association for Computing Machinery, Inc
SN  - 978-145039148-1 (ISBN)
LA  - English
J2  - ICAIF - ACM Int. Conf. AI Financ.
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 0; Conference name: 2nd ACM International Conference on AI in Finance, ICAIF 2021; Conference date: 3 November 2021 through 5 November 2021; Conference code: 179136
ER  -

TY  - JOUR
AU  - Chang, D.
AU  - Lin, E.
AU  - Brandt, C.
AU  - Taylor, R.A.
TI  - Incorporating domain knowledge into language models by using graph convolutional networks for assessing semantic textual similarity: Model development and performance comparison
PY  - 2021
T2  - JMIR Medical Informatics
VL  - 9
IS  - 11
C7  - e23101
DO  - 10.2196/23101
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85120171749&doi=10.2196%2f23101&partnerID=40&md5=75cd7707fc3f80c27955fa4d85f4c2a5
AD  - Yale Center for Medical Informatics, Yale University, New Haven, CT, United States
AD  - Department of Psychiatry, Yale University, School of Medicine, New Haven, CT, United States
AD  - Department of Emergency Medicine, Yale University, School of Medicine, New Haven, CT, United States
AD  - West Haven Campus, Veterans Affairs Connecticut Healthcare System, West Haven, CT, United States
AB  - Background: Although electronic health record systems have facilitated clinical documentation in health care, they have also introduced new challenges, such as the proliferation of redundant information through the use of copy and paste commands or templates. One approach to trimming down bloated clinical documentation and improving clinical summarization is to identify highly similar text snippets with the goal of removing such text. Objective: We developed a natural language processing system for the task of assessing clinical semantic textual similarity. The system assigns scores to pairs of clinical text snippets based on their clinical semantic similarity. Methods: We leveraged recent advances in natural language processing and graph representation learning to create a model that combines linguistic and domain knowledge information from the MedSTS data set to assess clinical semantic textual similarity. We used bidirectional encoder representation from transformers (BERT)-based models as text encoders for the sentence pairs in the data set and graph convolutional networks (GCNs) as graph encoders for corresponding concept graphs that were constructed based on the sentences. We also explored techniques, including data augmentation, ensembling, and knowledge distillation, to improve the model's performance, as measured by the Pearson correlation coefficient (r). Results: Fine-tuning the BERT_base and ClinicalBERT models on the MedSTS data set provided a strong baseline (Pearson correlation coefficients: 0.842 and 0.848, respectively) compared to those of the previous year's submissions. Our data augmentation techniques yielded moderate gains in performance, and adding a GCN-based graph encoder to incorporate the concept graphs also boosted performance, especially when the node features were initialized with pretrained knowledge graph embeddings of the concepts (r=0.868). As expected, ensembling improved performance, and performing multisource ensembling by using different language model variants, conducting knowledge distillation with the multisource ensemble model, and taking a final ensemble of the distilled models further improved the system's performance (Pearson correlation coefficients: 0.875, 0.878, and 0.882, respectively). Conclusions: This study presents a system for the MedSTS clinical semantic textual similarity benchmark task, which was created by combining BERT-based text encoders and GCN-based graph encoders in order to incorporate domain knowledge into the natural language processing pipeline. We also experimented with other techniques involving data augmentation, pretrained concept embeddings, ensembling, and knowledge distillation to further increase our system's performance. Although the task and its benchmark data set are in the early stages of development, this study, as well as the results of the competition, demonstrates the potential of modern language model-based systems to detect redundant information in clinical notes. © 2021 JMIR Publications Inc.. All rights reserved.
KW  - Bidirectional encoder representation from transformers
KW  - Graph neural networks
KW  - National NLP Clinical Challenges
KW  - Natural language processing
PB  - JMIR Publications Inc.
SN  - 22919694 (ISSN)
LA  - English
J2  - JMIR Med. Inform.
M3  - Article
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 5; Correspondence Address: R.A. Taylor; Yale Center for Medical Informatics, Yale University, New Haven, 300 George St, United States; email: richard.taylor@yale.edu
ER  -

TY  - CONF
AU  - Prabhu, S.
AU  - Akhila, K.
AU  - Sanriya, S.
TI  - A Hybrid Approach Towards Automated Essay Evaluation based on Bert and Feature Engineering
PY  - 2022
T2  - 2022 IEEE 7th International conference for Convergence in Technology, I2CT 2022
DO  - 10.1109/I2CT54291.2022.9824999
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85135631461&doi=10.1109%2fI2CT54291.2022.9824999&partnerID=40&md5=42e7b4cd53c8871cd5f018dc4fc813b9
AD  - Computer Science, Pes University, Banglore, India
AB  - Educational institutions often assess a student's critical thinking and communication skills based on essay responses. Manual Evaluation is time-consuming, and there may be wide variations when multiple evaluators rate batches of essays. In the last few years, the automated grading of essay scripts has emerged as a new area of research. Most studies essentially focus on visible attributes such as length, vocabulary, sentiment or spelling. The use of neural networks requires the conversion of text into some vector representations. However solely using handcrafted attributes or text encodings implies primarily operating on word granularity. On the other hand, Transformers can handle dependencies between words of the text. In this paper, we propose a hybrid model that can capture the interaction of words in the essay using the BERT self-attention transformer, along with handcrafted syntactical features. While previous studies have built individual models for every essay topic, our model has been incrementally trained on multiple essay topics to test its generalizability. The validation of the model uses quadratic weighted kappa to compare human-rated scores and model scores. © 2022 IEEE.
KW  - automated grading
KW  - BERT
KW  - essay
KW  - kappa
KW  - self-attention
KW  - Automation
KW  - Grading
KW  - Automated grading
KW  - BERT
KW  - Communication skills
KW  - Critical thinking skills
KW  - Educational institutions
KW  - Essay
KW  - Feature engineerings
KW  - Hybrid approach
KW  - Kappa
KW  - Self-attention
KW  - Students
PB  - Institute of Electrical and Electronics Engineers Inc.
SN  - 978-166542168-3 (ISBN)
LA  - English
J2  - IEEE Int. Conf. Converg. Technol., I2CT
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 5; Conference name: 7th IEEE International conference for Convergence in Technology, I2CT 2022; Conference date: 7 April 2022 through 9 April 2022; Conference code: 181071
ER  -

TY  - CONF
AU  - Chuang, C.Y.
AU  - Yang, Y.
TI  - Buy Tesla, Sell Ford: Assessing Implicit Stock Market Preference in Pre-trained Language Models
PY  - 2022
T2  - Proceedings of the Annual Meeting of the Association for Computational Linguistics
VL  - 2
SP  - 100
EP  - 105
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85142848224&partnerID=40&md5=1efbd87fa4cf2b6c62a740585c22d184
AD  - Department of Mathematics and Economics, Hong Kong University of Science and Technology, Hong Kong
AD  - Department of Information Systems and Operations Management, Hong Kong University of Science and Technology, Hong Kong
AB  - Pretrained language models such as BERT have achieved remarkable success in several NLP tasks. With the wide adoption of BERT in real-world applications, researchers begin to investigate the implicit biases encoded in the BERT. In this paper, we assess the implicit stock market preferences in BERT and its finance domain-specific model FinBERT. We find some interesting patterns. For example, the language models are overall more positive towards the stock market, but there are significant differences in preferences between a pair of industry sectors, or even within a sector. Given the prevalence of NLP models in financial decision making systems, this work raises the awareness of their potential implicit preferences in the stock markets. Awareness of such problems can help practitioners improve robustness and accountability of their financial NLP pipelines. © 2022 Association for Computational Linguistics.
KW  - Commerce
KW  - Computational linguistics
KW  - Decision making
KW  - Natural language processing systems
KW  - Decision-making systems
KW  - Domain-specific modelling
KW  - Financial decisions
KW  - Industry sectors
KW  - Language model
KW  - Real-world
KW  - Financial markets
A2  - Muresan S.
A2  - Nakov P.
A2  - Villavicencio A.
PB  - Association for Computational Linguistics (ACL)
SN  - 0736587X (ISSN); 978-195591722-3 (ISBN)
LA  - English
J2  - Proc. Annu. Meet. Assoc. Comput Linguist.
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 3; Conference name: 60th Annual Meeting of the Association for Computational Linguistics, ACL 2022; Conference date: 22 May 2022 through 27 May 2022; Conference code: 181737
ER  -

TY  - CONF
AU  - Sharma, A.
AU  - Kimball, J.W.
TI  - New Hybrid Model for Evaluating the Frequency-Dependent Leakage Inductance of a Variable Inductance Transformer (VIT)
PY  - 2022
T2  - 2022 IEEE Energy Conversion Congress and Exposition, ECCE 2022
DO  - 10.1109/ECCE50734.2022.9947451
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85144052179&doi=10.1109%2fECCE50734.2022.9947451&partnerID=40&md5=a4aa54a8efb630de5ae111e56494abef
AD  - Department of Electrical and Computer Engineering, Missouri University of Science and Technology, Rolla, MO, United States
AB  - Skin and proximity effects can cause a significant drop in the effective leakage inductance of a transformer when the operating frequency is increased. Although the magnetic image method-based double-2-D model can calculate the low-frequency leakage inductance with sufficient accuracy, it is inherently a frequency-independent model. While Dowell's 1-D model uses frequency-dependent relations to account for both skin and proximity effects, its accuracy is severely affected by the assumed winding geometry. In this paper, a hybrid model is proposed that uses superposition to combine a modified Dowell's model with the double-2-D model. The proposed model is investigated on a variable inductance transformer (VIT)-a partially-filled transformer whose leakage inductance can be varied by moving one of the windings mechanically. The frequency-dependent leakage inductances of the VIT evaluated using the hybrid model are in excellent agreement with the corresponding finite element method (FEM) simulated and experimentally measured values, thereby validating the proposed hybrid model. © 2022 IEEE.
KW  - Double-2-D model
KW  - Dowell's 1-D model
KW  - hybrid model
KW  - leakage inductance
KW  - variable inductance transformer
KW  - Inductance
KW  - Magnetic leakage
KW  - Transformer windings
KW  - 1-D models
KW  - 2-D model
KW  - Double-2-D model
KW  - Dowell 1-D model
KW  - Frequency-dependent
KW  - Hybrid model
KW  - Leakage inductance
KW  - Proximity effects
KW  - Variable inductance
KW  - Variable inductance transformer
KW  - Winding
PB  - Institute of Electrical and Electronics Engineers Inc.
SN  - 978-172819387-8 (ISBN)
LA  - English
J2  - IEEE Energy Convers. Congr. Expo., ECCE
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 0; Conference name: 2022 IEEE Energy Conversion Congress and Exposition, ECCE 2022; Conference date: 9 October 2022 through 13 October 2022; Conference code: 184711
ER  -

TY  - CONF
AU  - Liu, D.
AU  - Liu, Z.
AU  - Yang, Q.
AU  - Huang, Y.
AU  - Prud’hommeaux, E.
TI  - Evaluating the Performance of Transformer-based Language Models for Neuroatypical Language
PY  - 2022
T2  - Proceedings - International Conference on Computational Linguistics, COLING
VL  - 29
IS  - 1
SP  - 3412
EP  - 3419
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85147524288&partnerID=40&md5=fbf3e054abfb2fcab19510ca5c418b2a
AD  - Department of Computer Science, Boston College, Chestnut Hill, MA, United States
AD  - MIT, Cambridge, MA, United States
AD  - Cornell Tech, New York, NY, United States
AB  - Difficulties with social aspects of language are among the hallmarks of autism spectrum disorder (ASD). These communication differences are thought to contribute to the challenges that adults with ASD experience when seeking employment, underscoring the need for interventions that focus on improving areas of weakness in pragmatic and social language. In this paper, we describe a transformer-based framework for identifying linguistic features associated with social aspects of communication using a corpus of conversations between adults with and without ASD and neurotypical conversational partners produced while engaging in collaborative tasks. While our framework yields strong accuracy overall, performance is significantly worse for the language of participants with ASD, suggesting that they use a more diverse set of strategies for some social linguistic functions. These results, while showing promise for the development of automated language analysis tools to support targeted language interventions for ASD, also reveal weaknesses in the ability of large contextualized language models to model neuroatypical language. © 2022 Proceedings - International Conference on Computational Linguistics, COLING. All rights reserved.
KW  - Computational linguistics
KW  - Analysis tools
KW  - Autism spectrum disorders
KW  - Collaborative tasks
KW  - Language analysis
KW  - Language model
KW  - Linguistic features
KW  - Linguistic functions
KW  - Performance
KW  - Social aspects
A2  - Calzolari N.
A2  - Huang C.-R.
A2  - Kim H.
A2  - Pustejovsky J.
A2  - Wanner L.
A2  - Choi K.-S.
A2  - Ryu P.-M.
A2  - Chen H.-H.
A2  - Donatelli L.
A2  - Ji H.
A2  - Kurohashi S.
A2  - Paggio P.
A2  - Paggio P.
A2  - Xue N.
A2  - Kim S.
A2  - Hahm Y.
A2  - He Z.
A2  - Lee T.K.
A2  - Santus E.
A2  - Bond F.
A2  - Na S.-H.
PB  - Association for Computational Linguistics (ACL)
SN  - 29512093 (ISSN)
LA  - English
J2  - Proc. Main Conf. Int. Conf. Comput. Linguist., COLING
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 2; Conference name: 29th International Conference on Computational Linguistics, COLING 2022; Conference date: 12 October 2022 through 17 October 2022; Conference code: 186893
ER  -

TY  - JOUR
AU  - Shadab, S.
AU  - Hozefa, J.
AU  - Sonam, K.
AU  - Wagh, S.
AU  - Singh, N.M.
TI  - Gaussian process surrogate model for an effective life assessment of transformer considering model and measurement uncertainties
PY  - 2022
T2  - International Journal of Electrical Power and Energy Systems
VL  - 134
C7  - 107401
DO  - 10.1016/j.ijepes.2021.107401
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85112024261&doi=10.1016%2fj.ijepes.2021.107401&partnerID=40&md5=72ecc947f26978485c3f060f11ad9f0a
AD  - Control and Decision Research Centre (CDRC), Electrical Engineering Department (EED), Veermata Jijabai Technological Institute (VJTI), Mumbai, India
AB  - The challenges encountered because of simplifications, assumptions, and limited information in the transformer thermal modeling affect the entire life assessment process of the transformer. The classical techniques such as the gradient estimator and the Levenberg-Marquardt (LM) method for parameter estimation of the existing thermal models result in incorrect gradient and Hessian calculation due to measurement noise. Such limitations lead to model and measurement uncertainties that fail to achieve effective online monitoring for system diagnosis, determination of overload capability, and ageing rate. A systematic approach relying on the black-box model and Design of experiment (DoE) is proposed to build a surrogate model for Top-oil Temperature (TOT) prediction and parameter estimation. The Hot spot Temperature (HST) and Loss-of-Life (LoL) are evaluated under uncertainties with sequential use of the Gaussian Process (GP) surrogate model and an existing thermal-electrical-based thermal model (white-box model) of a transformer. An in-service transformer data and the virtual data generated in MATLAB are used to authenticate the proposed method's accuracy and effectiveness in the presence of uncertainties. © 2021 Elsevier Ltd
KW  - Design of Experiment (DoE)
KW  - Gaussian Process Regression (GPR)
KW  - Hot spot Temperature (HST)
KW  - Loss of Life (LoL)
KW  - Top-oil Temperature (TOT)
KW  - Gaussian distribution
KW  - Gaussian noise (electronic)
KW  - Parameter estimation
KW  - Thermography (temperature measurement)
KW  - Uncertainty analysis
KW  - Design of experiment
KW  - Gaussian process regression
KW  - Gaussian Processes
KW  - Hot spot temperature
KW  - Life assessment
KW  - Loss of life
KW  - Model uncertainties
KW  - Modeling and measurement
KW  - Surrogate model
KW  - Top-oil temperature
KW  - Design of experiments
PB  - Elsevier Ltd
SN  - 01420615 (ISSN)
LA  - English
J2  - Int J Electr Power Energy Syst
M3  - Article
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 32; Correspondence Address: S. Shadab; Control and Decision Research Centre (CDRC), Electrical Engineering Department (EED), Veermata Jijabai Technological Institute (VJTI), Mumbai, India; email: sisyed_p19@ee.vjti.ac.in; CODEN: IEPSD
ER  -

TY  - CONF
AU  - Devi, P.S.
AU  - Sarkar, S.
AU  - Singh, T.S.
AU  - Sharma, L.D.
AU  - Pankaj, C.
AU  - Singh, K.R.
TI  - An Approach to Evaluating Subjective Answers using BERT model
PY  - 2022
T2  - 2022 IEEE International Conference on Electronics, Computing and Communication Technologies, CONECCT 2022
DO  - 10.1109/CONECCT55679.2022.9865706
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85138246703&doi=10.1109%2fCONECCT55679.2022.9865706&partnerID=40&md5=e19bde7daf81d2d41324d44e0e308f7b
AD  - Manipur Univerity, Manipur Institute of Technology, Dept. of Computer Science and Engg., India
AD  - Assam University, Dept. of Computer Science and Engg., Silchar, India
AD  - Manipur Univerity, Manipur Institute of Technology, Dept. of Electronics and Communication, India
AD  - M S Ramaiah Institute of Technology, Dept. of Information Science and Engg., Bangalore, India
AB  - The state of art model for language translation, conversion from hand written to digital text, transcription are succeeded in wide range of fields using Natural Language Processing, Artificial Intelligence and Machine Learning (AIML) applications. In present, evaluation of subjective answers are not exercised systematically and graded using computer system. In this work, a mathematical method is proposed for evaluating subjective answers using Bidirectional Encoder Representation Transformers for word embedding and convert the sentence into vector space using pooling method for representing similar sentences. The proposed method evaluates the subjective answers having semantic meaning of answers based on topic Engineering and Medical related questions and answers dataset. It achieves to understand the similarity of different answers which are same semantically. The BERT model is used with machine learning methods to transform the sentence into vector space. The vector space is used to calculate percentage of similarity. The similarity of the sentences with percentage is observed and evaluated.  © 2022 IEEE.
KW  - BERT
KW  - Cosine Similarity
KW  - Machine Learning
KW  - Natural Language Processing
KW  - Neural Network
KW  - subjective answer correction
KW  - Learning algorithms
KW  - Learning systems
KW  - Machine learning
KW  - Natural language processing systems
KW  - Neural networks
KW  - Semantics
KW  - ART model
KW  - BERT
KW  - Cosine similarity
KW  - Language processing
KW  - Language translation
KW  - Machine-learning
KW  - Natural language processing
KW  - Natural languages
KW  - Neural-networks
KW  - Subjective answer correction
KW  - Vector spaces
PB  - Institute of Electrical and Electronics Engineers Inc.
SN  - 978-166549781-7 (ISBN)
LA  - English
J2  - IEEE Int. Conf. Electron., Comput. Commun. Technol., CONECCT
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 0; Conference name: 2022 IEEE International Conference on Electronics, Computing and Communication Technologies, CONECCT 2022; Conference date: 8 July 2022 through 10 July 2022; Conference code: 182416
ER  -

TY  - CONF
AU  - Zhao, J.
AU  - Du, B.
AU  - Zhu, S.
AU  - Liu, P.
TI  - Construction of Chinese Sentence-Level Gender-Unbiased Data Set and Evaluation of Gender Bias in Pre-Training Language Model
ST  - 中文句子级性别无偏数据集构建及预训练语言模型的性别偏度评估
PY  - 2021
T2  - CCL 2021 - Proceedings of the 20th Chinese National Conference on Computational Linguistics
SP  - 564
EP  - 575
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85123451800&partnerID=40&md5=a75dfdf849c4443896093cee271400ba
AD  - Beijing Language and Culture University, School of Information Science Language Resources Monitoring, Reserch Center Print Media Language Branch, 15 Xueyuan Road, Haidian District, Beijing, 100083, China
AB  - In various tasks in the field of natural language processing, models are widely gender-biased. However, there is no relevant data set for Chinese gender bias assessment and debiasing, so it is impossible to evaluate gender bias in Chinese natural language processing models. First, according to 16 pairs of gender appellations, this paper screened out gender-unbiased sentences from a print media corpus, and constructed a Chinese sentence-level gender-unbiased data set SlguSet containing 20,000 sentences. Subsequently, this paper proposes an index that can measure the degree of gender bias in pre-trained language models, and evaluates the gender bias in five popular pretrained language models. The results show that there are different degrees of gender bias in the Chinese pre-training language model, and the data set constructed in this article can effectively evaluate the gender bias in the Chinese pre-training language model. At the same time, this data set can also be used as a data set for evaluating the debiasing methods of pre-trained language models. © 2021 China National Conference on Computational Linguistics Published under Creative Commons Attribution 4.0 International License
KW  - Dataset
KW  - Gender bias
KW  - Pre-training language model
KW  - Natural language processing systems
KW  - Chinese sentence
KW  - Data set
KW  - Dataset
KW  - De-biasing
KW  - Gender bias
KW  - Language model
KW  - Pre-training
KW  - Pre-training language model
KW  - Processing model
KW  - Sentence level
KW  - Computational linguistics
A2  - Li S.
A2  - Sun M.
A2  - Liu Y.
A2  - Wu H.
A2  - Liu K.
A2  - Che W.
A2  - He S.
A2  - Rao G.
PB  - Chinese National Conference on Computational Linguistic (CCL)
LA  - Chinese
J2  - CCL - Proc. Chin. Natl. Conf. Comput. Linguist.
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 0; Correspondence Address: P. Liu; Beijing Language and Culture University, School of Information Science Language Resources Monitoring, Reserch Center Print Media Language Branch, Beijing, 15 Xueyuan Road, Haidian District, 100083, China; email: liupengyuan@blcu.edu.cn; Conference name: 20th Chinese National Conference on Computational Linguistics, CCL 2021; Conference date: 13 August 2021 through 15 August 2021; Conference code: 175250
ER  -

TY  - CONF
AU  - Espinosa-Anke, L.
AU  - Codina-Filbà, J.
AU  - Wanner, L.
TI  - Evaluating language models for the retrieval and categorization of lexical collocations
PY  - 2021
T2  - EACL 2021 - 16th Conference of the European Chapter of the Association for Computational Linguistics, Proceedings of the Conference
SP  - 1406
EP  - 1417
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85107270238&partnerID=40&md5=f85d6b0e130efb08dd97154ac66aa04d
AD  - School of Computer Science and Informatics, Cardiff University, United Kingdom
AD  - TALN Research Group, Pompeu Fabra University, Barcelona, Spain
AD  - Catalan Institute for Research and Advanced Studies (ICREA), Barcelona, Spain
AB  - Lexical collocations are idiosyncratic combinations of two syntactically bound lexical items (e.g., “heavy rain”, “take a step” or “undergo surgery”). Understanding their degree of compositionality and idiosyncrasy, as well their underlying semantics, is crucial for language learners, lexicographers and downstream NLP applications alike. In this paper we analyse a suite of language models for collocation understanding. We first construct a dataset of apparitions of lexical collocations in context, categorized into 16 representative semantic categories. Then, we perform two experiments: (1) unsupervised collocate retrieval, and (2) supervised collocation classification in context. We find that most models perform well in distinguishing light verb constructions, especially if the collocation's first argument acts as a subject, but often fail to distinguish, first, different syntactic structures within the same semantic category, and second, finer-grained categories which restrict the set of correct collocates. © 2021 Association for Computational Linguistics
KW  - Classification (of information)
KW  - Semantics
KW  - Syntactics
KW  - Compositionality
KW  - Heavy rains
KW  - In contexts
KW  - Language model
KW  - Lexical collocations
KW  - Lexical items
KW  - Semantic category
KW  - Syntactic structure
KW  - Computational linguistics
PB  - Association for Computational Linguistics (ACL)
SN  - 978-195408502-2 (ISBN)
LA  - English
J2  - EACL - Conf. Eur. Chapter Assoc. Comput. Linguist., Proc. Conf.
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 5; Conference name: 16th Conference of the European Chapter of the Associationfor Computational Linguistics, EACL 2021; Conference date: 19 April 2021 through 23 April 2021; Conference code: 169023
ER  -

TY  - CONF
AU  - Barikeri, S.
AU  - Lauscher, A.
AU  - Vulic, I.
AU  - Glavaš, G.
TI  - REDDITBIAS: A real-world resource for bias evaluation and debiasing of conversational language models
PY  - 2021
T2  - ACL-IJCNLP 2021 - 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing, Proceedings of the Conference
SP  - 1941
EP  - 1955
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85114189131&partnerID=40&md5=01182520a6bf655ea43c9ed98f316cbe
AD  - Data and Web Science Research Group, University of Mannheim, Germany
AD  - Language Technology Lab, University of Cambridge, United Kingdom
AB  - Text representation models are prone to exhibit a range of societal biases, reflecting the non-controlled and biased nature of the underlying pretraining data, which consequently leads to severe ethical issues and even bias amplification. Recent work has predominantly focused on measuring and mitigating bias in pretrained language models. Surprisingly, the landscape of bias measurements and mitigation resources and methods for conversational language models is still very scarce: it is limited to only a few types of bias, artificially constructed resources, and completely ignores the impact that debiasing methods may have on the final performance in dialog tasks, e.g., conversational response generation. In this work, we present REDDITBIAS, the first conversational data set grounded in the actual human conversations from Reddit, allowing for bias measurement and mitigation across four important bias dimensions: gender, race, religion, and queerness. Further, we develop an evaluation framework which simultaneously 1) measures bias on the developed REDDITBIAS resource, and 2) evaluates model capability in dialog tasks after model debiasing. We use the evaluation framework to benchmark the widely used conversational DialoGPT model along with the adaptations of four debiasing methods. Our results indicate that DialoGPT is biased with respect to religious groups and that some debiasing techniques can remove this bias while preserving downstream task performance. © 2021 Association for Computational Linguistics
KW  - Data set
KW  - De-biasing
KW  - Ethical issues
KW  - Evaluation framework
KW  - Language model
KW  - Performance
KW  - Pre-training
KW  - Real-world
KW  - Response generation
KW  - Text representation models
KW  - Computational linguistics
PB  - Association for Computational Linguistics (ACL)
SN  - 978-195408552-7 (ISBN)
LA  - English
J2  - ACL-IJCNLP - Annu. Meet. Assoc. Comput. Linguist. Int. Jt. Conf. Nat. Lang. Process., Proc. Conf.
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 43; Conference name: Joint Conference of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing, ACL-IJCNLP 2021; Conference date: 1 August 2021 through 6 August 2021; Conference code: 173030
ER  -

TY  - CONF
AU  - Lo, C.-K.
TI  - Extended Study on Using Pretrained Language Models and YiSi-1 for Machine Translation Evaluation
PY  - 2021
T2  - 5th Conference on Machine Translation, WMT 2020 - Proceedings
SP  - 895
EP  - 902
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85116742788&partnerID=40&md5=f5406d58415c7cffa6ff0b6f483b8b64
AD  - Multilingual Text Processing Digital Technologies Research Centre, National Research Council Canada (NRC-CNRC), 1200 Montreal Road, Ottawa, K1A 0R6, ON, Canada
AB  - We present an extended study on using pretrained language models and YiSi-1 for machine translation evaluation. Although the recently proposed contextual embedding based metrics, YiSi-1, significantly outperform BLEU and other metrics in correlating with human judgment on translation quality, we have yet to understand the full strength of using pretrained language models for machine translation evaluation. In this paper, we study YiSi-1's correlation with human translation quality judgment by varying three major attributes (which architecture; which intermediate layer; whether it is monolingual or multilingual) of the pretrained language models. Results of the study show further improvements over YiSi-1 on the WMT 2019 Metrics shared task. We also describe the pretrained language model we trained for evaluating Inuktitut machine translation output. © 2020 Association for Computational Linguistics
KW  - Computer aided language translation
KW  - Machine translation
KW  - Natural language processing systems
KW  - Quality control
KW  - Embeddings
KW  - Human judgments
KW  - Intermediate layers
KW  - Language model
KW  - Machine translation evaluations
KW  - Machine translations
KW  - Translation quality
KW  - Computational linguistics
A2  - Barrault L.
A2  - Bojar O.
A2  - Bougares F.
A2  - Chatterjee R.
A2  - Costa-Jussa M.R.
A2  - Federmann C.
A2  - Fishel M.
A2  - Fraser A.
A2  - Graham Y.
A2  - Guzman P.
A2  - Haddow B.
A2  - Huck M.
A2  - Yepes A.J.
A2  - Koehn P.
A2  - Martins A.
A2  - Morishita M.
A2  - Monz C.
A2  - Nagata M.
A2  - Nakazawa T.
A2  - Negri M.
PB  - Association for Computational Linguistics (ACL)
SN  - 978-194808781-0 (ISBN)
LA  - English
J2  - Conf. Machine Translation, WMT - Proc.
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 9; Correspondence Address: C.-K. Lo; Multilingual Text Processing Digital Technologies Research Centre, National Research Council Canada (NRC-CNRC), Ottawa, 1200 Montreal Road, K1A 0R6, Canada; email: chikiu.lo@nrc-cnrc.gc.ca; Conference name: 5th Conference on Machine Translation, WMT 2020; Conference date: 19 November 2020 through 20 November 2020; Conference code: 174267
ER  -

TY  - CONF
AU  - Kaster, M.
AU  - Zhao, W.
AU  - Eger, S.
TI  - Global Explainability of BERT-Based Evaluation Metrics by Disentangling along Linguistic Factors
PY  - 2021
T2  - EMNLP 2021 - 2021 Conference on Empirical Methods in Natural Language Processing, Proceedings
SP  - 8912
EP  - 8925
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85124065158&partnerID=40&md5=5947adf38f5a361c136b9db026140219
AD  - Natural Language Learning Group (NLLG), Technische Universität, Darmstadt, Germany
AB  - Evaluation metrics are a key ingredient for progress of text generation systems. In recent years, several BERT-based evaluation metrics have been proposed (including BERTScore, MoverScore, BLEURT, etc.) which correlate much better with human assessment of text generation quality than BLEU or ROUGE, invented two decades ago. However, little is known what these metrics, which are based on black-box language model representations, actually capture (it is typically assumed they model semantic similarity). In this work, we use a simple regression based global explainability technique to disentangle metric scores along linguistic factors, including semantics, syntax, morphology, and lexical overlap. We show that the different metrics capture all aspects to some degree, but that they are all substantially sensitive to lexical overlap, just like BLEU and ROUGE. This exposes limitations of these novelly proposed metrics, which we also highlight in an adversarial test scenario. © 2021 Association for Computational Linguistics
KW  - Computational linguistics
KW  - Quality control
KW  - Black boxes
KW  - Evaluation metrics
KW  - Generation systems
KW  - Human assessment
KW  - Language model
KW  - Model representation
KW  - Model semantics
KW  - Semantic similarity
KW  - Simple++
KW  - Text generations
KW  - Semantics
PB  - Association for Computational Linguistics (ACL)
SN  - 978-195591709-4 (ISBN)
LA  - English
J2  - EMNLP - Conf. Empir. Methods Nat. Lang. Process., Proc.
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 13; Conference name: 2021 Conference on Empirical Methods in Natural Language Processing, EMNLP 2021; Conference date: 7 November 2021 through 11 November 2021; Conference code: 177530
ER  -

TY  - JOUR
AU  - Liu, J.
AU  - Fan, X.
AU  - Zhang, Y.
AU  - Zhang, C.
AU  - Wang, Z.
TI  - Aging evaluation and moisture prediction of oil-immersed cellulose insulation in field transformer using frequency domain spectroscopy and aging kinetics model
PY  - 2020
T2  - Cellulose
VL  - 27
IS  - 12
SP  - 7175
EP  - 7189
DO  - 10.1007/s10570-020-03242-2
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85085579550&doi=10.1007%2fs10570-020-03242-2&partnerID=40&md5=d5e2e17c53daaa650ea4badfb8eadbd9
AD  - School of Electrical Engineering, Guangxi University, Nanning, China
AB  - Abstract: This work aims to propose an improved model for aging evaluation and moisture prediction of transformer cellulose insulation, which is based on the combination of the advantages of both frequency domain spectroscopy (FDS) and cellulose aging kinetics model. In the present work, the FDS was firstly employed to achieve the prediction of the inside moisture according to its moisture-sensitive property. Then, the predicted moisture is applied to construct the improved aging kinetics model, so that the aging condition of the transformer cellulose insulation can be predicted as well. The presented lab tests, as well as the field tests, have demonstrated the accuracy and feasibility of the proposed model. In that respect, the present contributions attempt to present a novel idea for the aging evaluation and moisture prediction for transformer cellulose insulation. Graphic abstract: [Figure not available: see fulltext.]. © 2020, Springer Nature B.V.
KW  - Aging kinetics model
KW  - Cellulose insulation
KW  - Frequency domain spectroscopy (FDS)
KW  - Transformer
KW  - Aging
KW  - Cellulose
KW  - Evaluation
KW  - Forecasts
KW  - Frequency
KW  - Insulation
KW  - Kinetics
KW  - Moisture
KW  - Cellulose
KW  - Forecasting
KW  - Frequency domain analysis
KW  - Insulating materials
KW  - Insulation
KW  - Kinetics
KW  - Moisture
KW  - Aging conditions
KW  - Aging kinetics
KW  - Cellulose insulation
KW  - Field test
KW  - Frequency domain spectroscopy
KW  - In-field
KW  - Sensitive properties
KW  - Oil filled transformers
PB  - Springer
SN  - 09690239 (ISSN)
LA  - English
J2  - Cellulose
M3  - Article
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 30; Correspondence Address: Y. Zhang; School of Electrical Engineering, Guangxi University, Nanning, China; email: yiyizhang@gxu.edu.cn; CODEN: CELLE
ER  -

TY  - CONF
AU  - Newman, B.
AU  - Ang, K.-S.
AU  - Gong, J.
AU  - Hewitt, J.
TI  - Refining Targeted Syntactic Evaluation of Language Models
PY  - 2021
T2  - NAACL-HLT 2021 - 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Proceedings of the Conference
SP  - 3710
EP  - 3723
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85127101338&partnerID=40&md5=0680b8a1419d66861356510a20e3531a
AD  - Department of Computer Science, Stanford University, United States
AB  - Targeted syntactic evaluation of subject-verb number agreement in English (TSE) evaluates language models’ syntactic knowledge using hand-crafted minimal pairs of sentences that differ only in the main verb’s conjugation. The method evaluates whether language models rate each grammatical sentence as more likely than its ungrammatical counterpart. We identify two distinct goals for TSE. First, evaluating the systematicity of a language model’s syntactic knowledge: given a sentence, can it conjugate arbitrary verbs correctly? Second, evaluating a model’s likely behavior: given a sentence, does the model concentrate its probability mass on correctly conjugated verbs, even if only on a subset of the possible verbs? We argue that current implementations of TSE do not directly capture either of these goals, and propose new metrics to capture each goal separately. Under our metrics, we find that TSE overestimates systematicity of language models, but that models score up to 40% better on verbs that they predict are likely in context. © 2021 Association for Computational Linguistics.
KW  - Computational linguistics
KW  - 'current
KW  - In contexts
KW  - Language model
KW  - Likely behavior
KW  - Systematicity
KW  - Syntactics
PB  - Association for Computational Linguistics (ACL)
SN  - 978-195408546-6 (ISBN)
LA  - English
J2  - NAACL-HLT - Conf. N. Am. Chapter Assoc. Comput. Linguist.: Hum. Lang. Technol., Proc. Conf.
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 19; Conference name: 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, NAACL-HLT 2021; Conference date: 6 June 2021 through 11 June 2021; Conference code: 182055
ER  -

TY  - CONF
AU  - Hofstätter, S.
AU  - Hanbury, A.
TI  - Evaluating Transformer-Kernel Models at TREC Deep Learning 2020
PY  - 2020
T2  - 29th Text REtrieval Conference, TREC 2020 - Proceedings
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85135072343&partnerID=40&md5=0f0705e81631af0f33cff249e86c4f4b
AD  - TU Wien, Austria
AB  - We tested multiple hypotheses using the Transformer-Kernel neural ranking pattern. The TK model family sits between BERT and previous ranking model in terms of the efficiency-effectiveness trade-off, faster than BERT albeit less effective. In the passage re-ranking task we tested the effectiveness of contextualized stopwords, introduced with TK-Sparse and find that removing 19% of terms after contextualization even slightly increases the model's effectiveness. In the document re-ranking task we tested if a long-text TKL model is better with 2,000 or 4,000 document tokens and find that our 2,000 token instance outperforms the other. Our results confirm the path for new storage saving methods for interpretable ranking models, and give an interesting insight into the questions of how many tokens of a document we need to read for a relevance assessment. © 2020 29th Text REtrieval Conference, TREC 2020 - Proceedings. All Rights Reserved.
KW  - Deep learning
KW  - Economic and social effects
KW  - Contextualization
KW  - Kernel models
KW  - Multiple hypothesis
KW  - Ranking model
KW  - Re-ranking
KW  - Relevance assessments
KW  - Trade off
KW  - Information retrieval
A2  - Voorhees E.M.
A2  - Ellis A.
PB  - National Institute of Standards and Technology (NIST)
LA  - English
J2  - Text Retr. Conf., TREC - Proc.
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 2; Conference name: 29th Text REtrieval Conference, TREC 2020; Conference date: 16 November 2020 through 20 November 2020; Conference code: 194936
ER  -

TY  - CONF
AU  - Paris, M.
AU  - Jäschke, R.
TI  - Evaluating Dataset Creation Heuristics for Concept Detection in Web Pages Using BERT
PY  - 2021
T2  - Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)
VL  - 12816 LNAI
SP  - 163
EP  - 175
DO  - 10.1007/978-3-030-82147-0_14
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85113788546&doi=10.1007%2f978-3-030-82147-0_14&partnerID=40&md5=d74b281a05b1764bcdd3c5681b60310b
AD  - Berlin School for Library and Information Science, Humboldt-Universität zu Berlin, Berlin, Germany
AD  - L3S Research Center Hannover, Hanover, Germany
AB  - Dataset creation for the purpose of training natural language processing (NLP) algorithms is often accompanied by an uncertainty about how the target concept is represented in the data. Extracting such data from web pages and verifying its quality is a non-trivial task, due to the Web’s unstructured and heterogeneous nature and the cost of annotation. In that situation, annotation heuristics can be employed to create a dataset that captures the target concept, but in turn may lead to an unstable downstream performance. On the one hand, a trade-off exists between cost, quality, and magnitude for annotation heuristics in tasks such as classification, leading to fluctuations in trained models’ performance. On the other hand, general-purpose NLP tools like BERT are now commonly used to benchmark new models on a range of tasks on static datasets. We utilize this standardization as a means to assess dataset quality, as most applications are dataset specific. In this study, we investigate and evaluate the performance of three annotation heuristics for a classification task on extracted web data using BERT. We present multiple datasets, from which the classifier shall learn to identify web pages that are centered around an individual in the academic domain. In addition, we assess the relationship between the performance of the trained classifier and the training data size. The models are further tested on out-of-domain web pages, to asses the influence of the individuals’ occupation and web page domain. © 2021, Springer Nature Switzerland AG.
KW  - Bias
KW  - Classification
KW  - Dataset
KW  - Generation
KW  - Heuristic
KW  - Quality
KW  - Web archive
KW  - Data mining
KW  - Economic and social effects
KW  - Natural language processing systems
KW  - Websites
KW  - Classification tasks
KW  - Concept detection
KW  - Multiple data sets
KW  - NAtural language processing
KW  - NLP tools
KW  - Non-trivial tasks
KW  - Target concept
KW  - Training data
KW  - Classification (of information)
A2  - Qiu H.
A2  - Zhang C.
A2  - Fei Z.
A2  - Qiu M.
A2  - Kung S.
PB  - Springer Science and Business Media Deutschland GmbH
SN  - 03029743 (ISSN); 978-303082146-3 (ISBN)
LA  - English
J2  - Lect. Notes Comput. Sci.
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 0; Correspondence Address: M. Paris; Berlin School for Library and Information Science, Humboldt-Universität zu Berlin, Berlin, Germany; email: michael.paris@hu-berlin.de; Conference name: 14th International Conference on Knowledge Science, Engineering and Management, KSEM 2021; Conference date: 14 August 2021 through 16 August 2021; Conference code: 263589
ER  -

TY  - CONF
AU  - Bhatia, N.K.
AU  - El-Hag, A.H.
AU  - Shaban, K.B.
TI  - Machine Learning-based Regression and Classification Models for Oil Assessment of Power Transformers
PY  - 2020
T2  - 2020 IEEE International Conference on Informatics, IoT, and Enabling Technologies, ICIoT 2020
C7  - 9089647
SP  - 400
EP  - 403
DO  - 10.1109/ICIoT48696.2020.9089647
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85083640074&doi=10.1109%2fICIoT48696.2020.9089647&partnerID=40&md5=0fe9b86a42d3afc73b0a6e5c404b1a87
AD  - University of Waterloo, Department of Electrical and Computer Engineering, ON, Canada
AD  - Qatar University, Computer Science and Engineering Department, Doha, Qatar
AB  - Expensive and widely used power and distribution transformers need to be monitored to ensure the reliability of the power grid. Evaluating the transformer oil different parameters is vital to determine the transformer insulation health conditions. In this paper, both regression and classification models based on machine learning are used to test the correlation between the interfacial tension values (IFT) of the transformer oil with other oil test results, namely, breakdown voltage, acidity, color, dissipation factor and water content. Experimental results with oil samples obtained for 730 units indicate that both acidity and color have the highest correlation with IFT. Nevertheless, other parameters like breakdown voltage and dielectric dissipation factor contributes marginally in increasing the classifier output accuracy when added to the acidity and color. © 2020 IEEE.
KW  - Machine learning
KW  - power transformer
KW  - transformer oil quality tests
KW  - Color
KW  - Electric breakdown
KW  - Electric power transmission networks
KW  - Electric transformer testing
KW  - Internet of things
KW  - Machine learning
KW  - Power transformers
KW  - Dielectric dissipation factors
KW  - Dissipation factors
KW  - Distribution transformer
KW  - Health condition
KW  - Interfacial tension values
KW  - Output accuracy
KW  - Regression and classification models
KW  - Transformer insulation
KW  - Oil filled transformers
PB  - Institute of Electrical and Electronics Engineers Inc.
SN  - 978-172814821-2 (ISBN)
LA  - English
J2  - IEEE Int. Conf. Inf., IoT, Enabling Technol., ICIoT
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 9; Conference name: 2020 IEEE International Conference on Informatics, IoT, and Enabling Technologies, ICIoT 2020; Conference date: 2 February 2020 through 5 February 2020; Conference code: 115124
ER  -

TY  - CONF
AU  - Beyer, A.
AU  - Loáiciga, S.
AU  - Schlangen, D.
TI  - Is Incoherence Surprising? Targeted Evaluation of Coherence Prediction from Language Models
PY  - 2021
T2  - NAACL-HLT 2021 - 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Proceedings of the Conference
SP  - 4164
EP  - 4173
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85115861415&partnerID=40&md5=e5f6ca39801fa804250d7cd1524a7c63
AD  - Computational Linguistics, Department of Linguistics, University of Potsdam, Germany
AB  - Coherent discourse is distinguished from a mere collection of utterances by the satisfaction of a diverse set of constraints, for example choice of expression, logical relation between denoted events, and implicit compatibility with world-knowledge. Do neural language models encode such constraints? We design an extendable set of test suites addressing different aspects of discourse and dialogue coherence. Unlike most previous coherence evaluation studies, we address specific linguistic devices beyond sentence order perturbations, allowing for a more fine-grained analysis of what constitutes coherence and what neural models trained on a language modelling objective do encode. Extending the targeted evaluation paradigm for neural language models (Marvin and Linzen, 2018) to phenomena beyond syntax, we show that this paradigm is equally suited to evaluate linguistic qualities that contribute to the notion of coherence. © 2021 Association for Computational Linguistics.
KW  - Computational linguistics
KW  - Encoding (symbols)
KW  - Natural language processing systems
KW  - Quality control
KW  - Evaluation study
KW  - Fine-grained analysis
KW  - Language model
KW  - Linguistic devices
KW  - Logical relations
KW  - Modeling objectives
KW  - Neural modelling
KW  - Notions of coherence
KW  - Sentence ordering
KW  - World knowledge
KW  - Modeling languages
PB  - Association for Computational Linguistics (ACL)
SN  - 978-195408546-6 (ISBN)
LA  - English
J2  - NAACL-HLT - Conf. N. Am. Chapter Assoc. Comput. Linguist.: Hum. Lang. Technol., Proc. Conf.
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 7; Conference name: 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, NAACL-HLT 2021; Conference date: 6 June 2021 through 11 June 2021; Conference code: 182055
ER  -

TY  - CONF
AU  - Del Carmenrodriguez-Hernandez, M.
AU  - Del-Hoyo-Alonso, R.
AU  - Ilarri, S.
AU  - Montanes-Salas, R.M.
AU  - Sabroso-Lasa, S.
TI  - An Experimental Evaluation of Content-based Recommendation Systems: Can Linked Data and BERT Help?
PY  - 2020
T2  - Proceedings of IEEE/ACS International Conference on Computer Systems and Applications, AICCSA
VL  - 2020-November
C7  - 9316466
DO  - 10.1109/AICCSA50499.2020.9316466
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85099775206&doi=10.1109%2fAICCSA50499.2020.9316466&partnerID=40&md5=2b6d6bc4ba670fbd57fe0ed0899df6cd
AD  - Tech. Institute of Aragon (ITAINNOVA), Zaragoza, Spain
AD  - I3A, University of Zaragoza, Zaragoza, Spain
AB  - Content-Based Recommendation Systems suggest items (e.g., articles, products, objects, services, or places) that are relevant to the user based on the features describing the items. In many content-based recommendation systems we can find, along with discrete attributes, textual features (e.g., text summaries or comments) obtained from web pages, news articles, etc. Traditionally, to enable its exploitation, the textual information of items is represented by using basic information retrieval models (such as the vector space model), which do not take into account natural language challenges involving the semantics of the words (synonymy, polysemy and hiperonymy, etc.) or language understanding. Other solutions try to exploit those semantics. In this paper, we present an experimental evaluation where we compare several recommendation approaches, including a content-based recommender based on vector space models, a deep learning and content-based recommendation approach, and a semantic-aware content-based recommendation model. This last approach exploits textual features of items obtained from the Linked Open Data (LOD) and BERT (Bidirectional Encoder Representations from Transformers) for language modelling. Deep Learning transformers are achieving good results in different NLP (Natural Language Processing) problems, but using them to build content-based recommendation systems has not been explored in depth so far. Our experimental results, focused on the domain of movie recommendations, show that a approach based on the use of BERT can provide good results if enough training data are available.  © 2020 IEEE.
KW  - BERT
KW  - Content-Based Recommendation Systems
KW  - Deep Learning
KW  - Linked Open Data
KW  - Deep learning
KW  - Learning systems
KW  - Linked data
KW  - Modeling languages
KW  - Open Data
KW  - Recommender systems
KW  - Search engines
KW  - Semantics
KW  - Vector spaces
KW  - Websites
KW  - Content-based recommendation
KW  - Experimental evaluation
KW  - Information retrieval models
KW  - Language understanding
KW  - Linked open data (LOD)
KW  - Movie recommendations
KW  - Nlp (natural language processing)
KW  - Vector space models
KW  - Natural language processing systems
PB  - IEEE Computer Society
SN  - 21615322 (ISSN); 978-172818577-4 (ISBN)
LA  - English
J2  - Proc. IEEE/ACS Int. Conf. Comput. Syst. Appl., AICCSA
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 4; Conference name: 17th IEEE/ACS International Conference on Computer Systems and Applications, AICCSA 2020; Conference date: 2 November 2020 through 5 November 2020; Conference code: 166537
ER  -

TY  - JOUR
AU  - Park, H.
AU  - Park, J.
TI  - Assessment of word-level neural language models for sentence completion
PY  - 2020
T2  - Applied Sciences (Switzerland)
VL  - 10
IS  - 4
C7  - 1340
DO  - 10.3390/app10041340
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85081270069&doi=10.3390%2fapp10041340&partnerID=40&md5=91af1aedbc7c291b630237cf716d4faa
AD  - Department of Industrial Engineering and Center for Superintelligence, Seoul National University, Seoul, 08826, South Korea
AB  - The task of sentence completion, which aims to infer the missing text of a given sentence, was carried out to assess the reading comprehension level of machines as well as humans. In this work, we conducted a comprehensive study of various approaches for the sentence completion based on neural language models, which have been advanced in recent years. First, we revisited the recurrent neural network language model (RNN LM), achieving highly competitive results with an appropriate network structure and hyper-parameters. This paper presents a bidirectional version of RNN LM, which surpassed the previous best results on Microsoft Research (MSR) Sentence Completion Challenge and the Scholastic Aptitude Test (SAT) sentence completion questions. In parallel with directly applying RNN LM to sentence completion, we also employed a supervised learning framework that fine-tunes a large pre-trained transformer-based LM with a few sentence-completion examples. By fine-tuning a pre-trained BERT model, this work established state-of-the-art results on the MSR and SAT sets. Furthermore, we performed similar experimentation on newly collected cloze-style questions in the Korean language. The experimental results reveal that simply applying the multilingual BERT models for the Korean dataset was not satisfactory, which leaves room for further research. © 2020 by the authors.
KW  - BERT
KW  - Bidirectional RNN
KW  - Cloze test
KW  - Korean dataset
KW  - Machine comprehension
KW  - Neural language model
KW  - Sentence completion
PB  - MDPI AG
SN  - 20763417 (ISSN)
LA  - English
J2  - Appl. Sci.
M3  - Article
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 3; Correspondence Address: J. Park; Department of Industrial Engineering and Center for Superintelligence, Seoul National University, Seoul, 08826, South Korea; email: jonghun@snu.ac.kr
ER  -

TY  - CONF
AU  - Liu, Y.
AU  - Maier, W.
AU  - Minker, W.
AU  - Ultes, S.
TI  - Naturalness Evaluation of Natural Language Generation in Task-oriented Dialogues using BERT
PY  - 2021
T2  - International Conference Recent Advances in Natural Language Processing, RANLP
SP  - 839
EP  - 845
DO  - 10.26615/978-954-452-072-4_096
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85123570045&doi=10.26615%2f978-954-452-072-4_096&partnerID=40&md5=672289fc3b21c021819580501ae178e2
AD  - Mercedes-Benz AG, Sindelfingen, Germany
AD  - Ulm University, Ulm, Germany
AB  - This paper presents an automatic method to evaluate the naturalness of natural language generation in dialogue systems. While this task was previously rendered through expensive and time-consuming human labor, we present this novel task of automatic naturalness evaluation of generated language. By fine-tuning the BERT model, our proposed naturalness evaluation method shows robust results and outperforms the baselines: support vector machines, bi-directional LSTMs, and BLEURT. In addition, the training speed and evaluation performance of naturalness model are improved by transfer learning from quality and informativeness linguistic knowledge. © 2021 Incoma Ltd. All rights reserved.
KW  - Natural language processing systems
KW  - Quality control
KW  - Support vector machines
KW  - Automatic method
KW  - Bi-directional
KW  - Dialogue systems
KW  - Evaluation methods
KW  - Fine tuning
KW  - Human labor
KW  - Natural language generation
KW  - Novel task
KW  - Support vectors machine
KW  - Task-oriented
KW  - Speech processing
A2  - Angelova G.
A2  - Kunilovskaya M.
A2  - Mitkov R.
A2  - Nikolova-Koleva I.
PB  - Incoma Ltd
SN  - 13138502 (ISSN); 978-954452072-4 (ISBN)
LA  - English
J2  - Int. Conf. Recent Adv. Nat. Lang. Proces., RANLP
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 0; Conference name: International Conference on Recent Advances in Natural Language Processing: Deep Learning for Natural Language Processing Methods and Applications, RANLP 2021; Conference date: 1 September 2021 through 3 September 2021; Conference code: 176177
ER  -

TY  - CONF
AU  - Wilcox, E.G.
AU  - Vani, P.
AU  - Levy, R.P.
TI  - A targeted assessment of incremental processing in neural language models and humans
PY  - 2021
T2  - ACL-IJCNLP 2021 - 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing, Proceedings of the Conference
SP  - 939
EP  - 952
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85118954728&partnerID=40&md5=714a406d9b4f6bea24492a3c4b8a5500
AD  - Harvard University, Department of Linguistics, United States
AD  - MIT, Brain and Cognitive Science
AB  - We present a targeted, scaled-up comparison of incremental processing in humans and neural language models by collecting by-word reaction time data for sixteen different syntactic test suites across a range of structural phenomena. Human reaction time data comes from a novel online experimental paradigm called the Interpolated Maze task. We compare human reaction times to by-word probabilities for four contemporary language models, with different architectures and trained on a range of data set sizes. We find that across many phenomena, both humans and language models show increased processing difficulty in ungrammatical sentence regions with human and model 'accuracy' scores (à la Marvin and Linzen (2018)) about equal. However, although language model outputs match humans in direction, we show that models systematically under-predict the difference in magnitude of incremental processing difficulty between grammatical and ungrammatical sentences. Specifically, when models encounter syntactic violations they fail to accurately predict the longer reaction times observed in the human data. These results call into question whether contemporary language models are approaching human-like performance for sensitivity to syntactic violations. © 2021 Association for Computational Linguistics
KW  - Computational linguistics
KW  - Data set size
KW  - Human data
KW  - Human like
KW  - Human modelling
KW  - Incremental processing
KW  - Language model
KW  - Model outputs
KW  - Modeling accuracy
KW  - Performance
KW  - Scaled-up
KW  - Syntactics
PB  - Association for Computational Linguistics (ACL)
SN  - 978-195408552-7 (ISBN)
LA  - English
J2  - ACL-IJCNLP - Annu. Meet. Assoc. Comput. Linguist. Int. Jt. Conf. Nat. Lang. Process., Proc. Conf.
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 9; Conference name: Joint Conference of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing, ACL-IJCNLP 2021; Conference date: 1 August 2021 through 6 August 2021; Conference code: 173030
ER  -

TY  - JOUR
AU  - Wang, H.
AU  - Deng, L.
AU  - He, Q.
AU  - Xiang, C.
AU  - Wang, Q.
AU  - Fu, H.
TI  - Grey Fuzzy Comprehensive Evaluation Model of Transformer State Based on Intuitionistic Fuzzy Analytic Hierarchy Process
ST  - 直觉模糊层次分析法下变压器状态的灰色模糊综合评判模型
PY  - 2020
T2  - Gaoya Dianqi/High Voltage Apparatus
VL  - 56
IS  - 9
SP  - 216
EP  - 222
DO  - 10.13296/j.1001-1609.hva.2020.09.032
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85092532991&doi=10.13296%2fj.1001-1609.hva.2020.09.032&partnerID=40&md5=1974c33ca93ef343d1bdaf59483e3af0
AD  - Yichang Electric Company of State Grid Hubei Electric Power Co. Ltd, Yichang, 443001, Hubei, China
AD  - College of Electrical Engineering & New Energy, China Three Gorges University, Yichang, 443002, Hubei, China
AB  - The condition evaluation of electric power equipment is the foundation to carry out the condition maintenance work.In view of the characteristics of grey fuzzy and randomness of index information in transformer state evaluation, a grey fuzzy comprehensive model is proposed by combining intuitionistic fuzzy sets and cloud theory. This model firstly uses intuitionistic fuzzy analytic hierarchy process and the concepts of fuzzy entropy to determine accurately the weight set of evaluation indexes. Next, the correlation degree of the state level obtained by cloud theory is used as the module of the evaluation factor set. Then the grey part of factor set is determined by combining expert experiences and information adequacy to represent the uncertainty of the information, and this model builds grey fuzzy evaluation matrix to deal with the result. Lastly, the feasibility and validity of the proposed model are verified by example analysis and comparison with other methods. © 2020, Xi'an High Voltage Apparatus Research Institute Co., Ltd. All right reserved.
KW  - Cloud theory
KW  - Grey fuzzy comprehensive evaluation
KW  - Intuitionistic fuzzy analytic hierarchy process
KW  - Power transformer
KW  - State evaluation
PB  - Xi'an High Voltage Apparatus Research Institute
SN  - 10011609 (ISSN)
LA  - Chinese
J2  - Gaoya Dianqi
M3  - Article
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 5; Correspondence Address: Q. Wang; College of Electrical Engineering & New Energy, China Three Gorges University, Yichang, 443002, China; email: 572451353@qq.com; CODEN: GADIE
ER  -

TY  - CONF
AU  - Lo, C.-K.
AU  - Larkin, S.
TI  - Machine Translation Reference-less Evaluation using YiSi-2 with Bilingual Mappings of Massive Multilingual Language Model
PY  - 2021
T2  - 5th Conference on Machine Translation, WMT 2020 - Proceedings
SP  - 903
EP  - 910
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85123852891&partnerID=40&md5=966ba16d1a43274bd952db61b049b495
AD  - Multilingual Text Processing Digital Technologies Research Centre, National Research Council Canada (NRC-CNRC), 1200 Montreal Road, Ottawa, K1A 0R6, ON, Canada
AB  - We present a study on using YiSi-2 with massive multilingual pretrained language models for machine translation (MT) reference-less evaluation. Aiming at finding better semantic representation for semantic MT evaluation, we first test YiSi-2 with contextual embeddings extracted from different layers of two different pretrained models, multilingual BERT and XLM-RoBERTa. We also experiment with learning bilingual mappings that transform the vector subspace of the source language to be closer to that of the target language in the pretrained model to obtain more accurate cross-lingual semantic similarity representations. Our results show that YiSi-2's correlation with human direct assessment on translation quality is greatly improved by replacing multilingual BERT with XLM-RoBERTa and projecting the source embeddings into the target embedding space using a cross-lingual linear projection (CLP) matrix learnt from a small development set. © 2020 Association for Computational Linguistics
KW  - Computational linguistics
KW  - Computer aided language translation
KW  - Machine translation
KW  - Mapping
KW  - Semantics
KW  - Bilinguals
KW  - Cross-lingual
KW  - Different layers
KW  - Embeddings
KW  - Language model
KW  - Machine translation evaluations
KW  - Machine translations
KW  - Semantic representation
KW  - Source language
KW  - Vector subspace
KW  - Embeddings
A2  - Barrault L.
A2  - Bojar O.
A2  - Bougares F.
A2  - Chatterjee R.
A2  - Costa-Jussa M.R.
A2  - Federmann C.
A2  - Fishel M.
A2  - Fraser A.
A2  - Graham Y.
A2  - Guzman P.
A2  - Haddow B.
A2  - Huck M.
A2  - Yepes A.J.
A2  - Koehn P.
A2  - Martins A.
A2  - Morishita M.
A2  - Monz C.
A2  - Nagata M.
A2  - Nakazawa T.
A2  - Negri M.
PB  - Association for Computational Linguistics (ACL)
SN  - 978-194808781-0 (ISBN)
LA  - English
J2  - Conf. Machine Translation, WMT - Proc.
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 6; Conference name: 5th Conference on Machine Translation, WMT 2020; Conference date: 19 November 2020 through 20 November 2020; Conference code: 174267
ER  -

TY  - JOUR
AU  - Ruiz-Dolz, R.
AU  - Alemany, J.
AU  - Barbera, S.M.H.
AU  - Garcia-Fornes, A.
TI  - Transformer-Based Models for Automatic Identification of Argument Relations: A Cross-Domain Evaluation
PY  - 2021
T2  - IEEE Intelligent Systems
VL  - 36
IS  - 6
SP  - 62
EP  - 70
DO  - 10.1109/MIS.2021.3073993
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85104598146&doi=10.1109%2fMIS.2021.3073993&partnerID=40&md5=58175d56b84cef46d9e4335951ce4e78
AD  - Valencian Research Institute for Artificial Intelligence (VRAIN), Universitat Politècnica de València, Valencia, 46022, Spain
AB  - Argument mining is defined as the task of automatically identifying and extracting argumentative components (e.g., premises, claims, etc.) and detecting the existing relations among them (i.e., support, attack, rephrase, no relation). One of the main issues when approaching this problem is the lack of data, and the size of the publicly available corpora. In this work, we use the recently annotated US2016 debate corpus. US2016 is the largest existing argument annotated corpus, which allows exploring the benefits of the most recent advances in natural language processing in a complex domain like argument (relation) mining. We present an exhaustive analysis of the behavior of transformer-based models (i.e., BERT, XLNET, RoBERTa, DistilBERT, and ALBERT) when predicting argument relations. Finally, we evaluate the models in five different domains, with the objective of finding the less domain-dependent model. We obtain a macro F1-score of 0.70 with the US2016 evaluation corpus, and a macro F1-score of 0.61 with the Moral Maze cross-domain corpus.  © 2001-2011 IEEE.
KW  - Automation
KW  - Natural language processing systems
KW  - Complex domains
KW  - Cross-domain
KW  - Cross-domain evaluations
KW  - Different domains
KW  - F1 scores
KW  - NAtural language processing
KW  - Linguistics
PB  - Institute of Electrical and Electronics Engineers Inc.
SN  - 15411672 (ISSN)
LA  - English
J2  - IEEE Intell. Syst.
M3  - Article
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 13
ER  -

TY  - CONF
AU  - Kougia, V.
AU  - Pavlopoulos, J.
TI  - Multimodal or Text? Retrieval or BERT? Benchmarking Classifiers for the Shared Task on Hateful Memes
PY  - 2021
T2  - WOAH 2021 - 5th Workshop on Online Abuse and Harms, Proceedings of the Workshop
SP  - 220
EP  - 225
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85138752789&partnerID=40&md5=c9ea5603b07c17777fdcda36ad1fe55c
AD  - Stockholm University, Sweden
AB  - The Shared Task on Hateful Memes is a challenge that aims at the detection of hateful content in memes by inviting the implementation of systems that understand memes, potentially by combining image and textual information. The challenge consists of three detection tasks: hate, protected category and attack type. The first is a binary classification task, while the other two are multi-label classification tasks. Our participation included a text-based BERT baseline (TxtBERT), the same but adding information from the image (ImgBERT), and neural retrieval approaches. We also experimented with retrieval augmented classification models. We found that an ensemble of TxtBERT and ImgBERT achieves the best performance in terms of ROC AUC score in two out of the three tasks on our development set.  © 2021 Association for Computational Linguistics.
KW  - Computational linguistics
KW  - Binary classification
KW  - Classification models
KW  - Classification tasks
KW  - Detection tasks
KW  - Image information
KW  - Multi-label classifications
KW  - Multi-modal
KW  - Performance
KW  - Textual information
KW  - Classification (of information)
A2  - Davani A.M.
A2  - Kiela D.
A2  - Lambert M.
A2  - Vidgen B.
A2  - Prabhakaran V.
A2  - Waseem Z.
PB  - Association for Computational Linguistics (ACL)
SN  - 978-195408559-6 (ISBN)
LA  - English
J2  - WOAH - Workshop Online Abuse Harms, Proc. Workshop
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 2; Conference name: 5th Workshop on Online Abuse and Harms, WOAH 2021; Conference code: 182536
ER  -

TY  - JOUR
AU  - Zhou, Z.
AU  - Xu, H.
AU  - Ye, H.
TI  - A new model of transformer operation state evaluation based on analytic hierarchy process and association rule mining
PY  - 2021
T2  - International Journal of Computer Applications in Technology
VL  - 65
IS  - 3
SP  - 253
EP  - 260
DO  - 10.1504/IJCAT.2021.116001
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85109752595&doi=10.1504%2fIJCAT.2021.116001&partnerID=40&md5=ce97d58eed671492859d88eba6b77df1
AD  - School of Information and Control Engineering, China University of Mining and Technology, Jiangsu, Xuzhou, 221116, China
AD  - Changshu Institute of Technology, College of Electrical and Automation Engineering, Jiangsu, Changshu, 215500, China
AD  - Changshu Institute of Technology, College of Electrical and Automation Engineering, Jiangsu, Changshu, 215500, China
AB  - In order to establish a transformer state evaluation model for power grid operation and maintenance management, based on the aging mechanism of transformer, a state risk evaluation method based on the Analytic Hierarchy Process (AHP) and the association rule mining is proposed. Based on the big data analysis of the actual state quantity of the transformer, the subjective weight coefficient of different state quantity is determined by the analytic hierarchy process. The objective weight coefficient of the comprehensive state quantity is determined by the association rules mining. And the fusion of the subjective weight coefficient and the objective weight coefficient is completed according to the weight coefficient fusion technology of the mean square deviation method. The practical results show that the model in this paper can evaluate the operation state of transformer comprehensively and accurately  Copyright 2021 Inderscience Enterprises Ltd.
KW  - Aging mechanism
KW  - Ahp
KW  - Association rules mining
KW  - State evaluation model
KW  - Transformer
KW  - Association rules
KW  - Data mining
KW  - Electric power transmission networks
KW  - Analytic hierarchy process (ahp)
KW  - Association rules mining
KW  - Fusion technology
KW  - Mean square deviation methods
KW  - Power grid operations
KW  - State evaluation
KW  - Subjective weights
KW  - Weight coefficients
KW  - Analytic hierarchy process
PB  - Inderscience Publishers
SN  - 09528091 (ISSN)
LA  - English
J2  - Int J Comput Appl Technol
M3  - Article
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 3; Correspondence Address: H. Ye; School of Information and Control Engineering, China University of Mining and Technology, Xuzhou, Jiangsu, 221116, China; email: yhf2007@126.com; CODEN: IJCTE
ER  -

TY  - JOUR
AU  - Wen, A.
AU  - Elwazir, M.Y.
AU  - Moon, S.
AU  - Fan, J.
TI  - Adapting and evaluating a deep learning language model for clinical why-question answering
PY  - 2021
T2  - JAMIA Open
VL  - 3
IS  - 1
SP  - 16
EP  - 20
DO  - 10.1093/JAMIAOPEN/OOZ072
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85100647550&doi=10.1093%2fJAMIAOPEN%2fOOZ072&partnerID=40&md5=7e8f5b6d8a1fad7471e01a714af6ea05
AD  - Division of Digital Health Sciences, Department of Health Sciences Research, Mayo Clinic, Rochester, MN, United States
AD  - Department of Cardiovascular Medicine, Mayo Clinic, Rochester, MN, United States
AD  - Department of Cardiology, Faculty of Medicine, Suez Canal University, Ismailia, Egypt
AD  - Robert D. and Patricia E. Kern Center for the Science of Health Care Delivery, Mayo Clinic, Rochester, MN, United States
AB  - Objectives: To adapt and evaluate a deep learning language model for answering why-questions based on patient-specific clinical text. Materials and Methods: Bidirectional encoder representations from transformers (BERT) models were trained with varying data sources to perform SQuAD 2.0 style why-question answering (why-QA) on clinical notes. The evaluation focused on: (1) comparing the merits from different training data and (2) error analysis. Results: The best model achieved an accuracy of 0.707 (or 0.760 by partial match). Training toward customization for the clinical language helped increase 6% in accuracy. Discussion: The error analysis suggested that the model did not really perform deep reasoning and that clinical why-QA might warrant more sophisticated solutions. Conclusion: The BERT model achieved moderate accuracy in clinical why-QA and should benefit from the rapidly evolving technology. Despite the identified limitations, it could serve as a competent proxy for questiondriven clinical information extraction.  © The Author(s) 2020.
KW  - Artificial intelligence
KW  - Clinical decision-making
KW  - Evaluation studies
KW  - Natural language processing
KW  - Question answering
KW  - article
KW  - artificial intelligence
KW  - clinical decision making
KW  - deep learning
KW  - evaluation study
KW  - extraction
KW  - human
KW  - human experiment
KW  - natural language processing
KW  - reasoning
PB  - Oxford University Press
SN  - 25742531 (ISSN)
LA  - English
J2  - JAMIA Open
M3  - Article
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 15; Correspondence Address: J. Fan; Division of Digital Health Sciences, Department of Health Sciences Research, Mayo Clinic, Rochester, 200 1st Street SW, RO-HA-2-CSHCD, 55905, United States; email: fan.jung-wei@mayo.edu
ER  -

TY  - CONF
AU  - Hoory, S.
AU  - Feder, A.
AU  - Tendler, A.
AU  - Cohen, A.
AU  - Erell, S.
AU  - Laish, I.
AU  - Nakhost, H.
AU  - Stemmer, U.
AU  - Benjamini, A.
AU  - Hassidim, A.
AU  - Matias, Y.
TI  - Learning and Evaluating a Differentially Private Pre-trained Language Model
PY  - 2021
T2  - Findings of the Association for Computational Linguistics, Findings of ACL: EMNLP 2021
SP  - 1178
EP  - 1189
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85128307387&partnerID=40&md5=66e15dbd23bfa1a6c8a4d9dfb5da0656
AD  - Google, Tel Aviv, Israel
AB  - Contextual language models have led to significantly better results, especially when pretrained on the same data as the downstream task. While this additional pre-training usually improves performance, it can lead to information leakage and therefore risks the privacy of individuals mentioned in the training data. One method to guarantee the privacy of such individuals is to train a differentially-private language model, but this usually comes at the expense of model performance. Also, in the absence of a differentially private vocabulary training, it is not possible to modify the vocabulary to fit the new data, which might further degrade results. In this work we bridge these gaps, and provide guidance to future researchers and practitioners on how to improve privacy while maintaining good model performance. We introduce a novel differentially private word-piece algorithm, which allows training a tailored domain-specific vocabulary while maintaining privacy. We then experiment with entity extraction tasks from clinical notes, and demonstrate how to train a differentially private pre-trained language model (i.e., BERT) with a privacy guarantee of ? = 1.1 and with only a small degradation in performance. Finally, as it is hard to tell given a privacy parameter ? what was the effect on the trained representation, we present experiments showing that the trained model does not memorize private information.  © 2021 Association for Computational Linguistics.
KW  - Clinical notes
KW  - Down-stream
KW  - Entity extractions
KW  - Improve performance
KW  - Information leakage
KW  - Language model
KW  - Modeling performance
KW  - Pre-training
KW  - Provide guidances
KW  - Training data
KW  - Computational linguistics
A2  - Moens M.-F.
A2  - Huang X.
A2  - Specia L.
A2  - Yih S.W.-T.
PB  - Association for Computational Linguistics (ACL)
SN  - 978-195591710-0 (ISBN)
LA  - English
J2  - Find. Assoc. Comput. Linguist., Findings ACL: EMNLP
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 13; Conference name: 2021 Findings of the Association for Computational Linguistics, Findings of ACL: EMNLP 2021; Conference date: 7 November 2021 through 11 November 2021; Conference code: 178705
ER  -

TY  - JOUR
AU  - La Ganga, A.
AU  - Re, R.
AU  - Guglielmi, P.
TI  - Input parallel output series structure of planar medium frequency transformers for 200 kw power converter: Model and parameters evaluation
PY  - 2021
T2  - Energies
VL  - 14
IS  - 5
C7  - 1450
DO  - 10.3390/en14051450
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85106320454&doi=10.3390%2fen14051450&partnerID=40&md5=fa03d2bb143151eb9b3a06dc0f2112c9
AD  - Politecnico di Torino, Department of Energy, Corso Duca degli Abruzzi 24, Torino, 10129, Italy
AB  - Nowadays, the demand for high power converters for DC applications, such as renewable sources or ultra-fast chargers for electric vehicles, is constantly growing. Galvanic isolation is mandatory in most of these applications. In this context, the Solid State Transformer (SST) converter plays a fundamental role. The adoption of the Medium Frequency Transformers (MFT) guarantees galvanic isolation in addition to high performance in reduced size. In the present paper, a multi MFT structure is proposed as a solution to improve the power density and the modularity of the system. Starting from 20 kW planar transformer model, experimentally validated, a multi-transformer structure is analyzed. After an analytical treatment of the Input Parallel Output Series (IPOS) structure, an equivalent electrical model of a 200 kW IPOS (made by 10 MFTs) is introduced. The model is validated by experimental measurements and tests. © 2021 by the authors. Licensee MDPI, Basel, Switzerland.
KW  - IPOS
KW  - Model
KW  - Power transformers
KW  - Solid State Transformer
KW  - Computer science
KW  - Energy management
KW  - Analytical treatment
KW  - Equivalent electrical models
KW  - Galvanic isolation
KW  - High power converters
KW  - Medium frequency transformer
KW  - Planar transformer
KW  - Solid state transformer (SST)
KW  - Transformer structure
KW  - Power converters
PB  - MDPI AG
SN  - 19961073 (ISSN)
LA  - English
J2  - Energies
M3  - Article
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 1; Correspondence Address: A. La Ganga; Politecnico di Torino, Department of Energy, Torino, Corso Duca degli Abruzzi 24, 10129, Italy; email: alessandro.laganga@polito.it
ER  -

TY  - JOUR
AU  - Chen, Y.-P.
AU  - Chen, Y.-Y.
AU  - Lin, J.-J.
AU  - Huang, C.-H.
AU  - Lai, F.
TI  - Modified bidirectional encoder representations from transformers extractive summarization model for hospital information systems based on character-level tokens (AlphaBERT): Development and performance evaluation
PY  - 2020
T2  - JMIR Medical Informatics
VL  - 8
IS  - 4
C7  - e17787
DO  - 10.2196/17787
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85096304469&doi=10.2196%2f17787&partnerID=40&md5=9c03af82cd611903869c0f04030bdeb9
AD  - Graduate Institute of Biomedical Electronics and Bioinformatics, National Taiwan University, Taipei City, Taiwan
AD  - Department of Emergency Medicine, National Taiwan University Hospital Chu-Tung Branch, Hsinchu County, Taiwan
AD  - Department of Emergency Medicine, National Taiwan University Hospital, Taipei City, Taiwan
AD  - Department of Emergency Medicine, College of Medicine, National Taiwan University, Taipei City, Taiwan
AD  - Department of Computer Science & Information Engineering, National Taiwan University, Taipei City, Taiwan
AD  - Department of Electrical Engineering, National Taiwan University, Taipei City, Taiwan
AB  - Background: Doctors must care for many patients simultaneously, and it is time-consuming to find and examine all patients' medical histories. Discharge diagnoses provide hospital staff with sufficient information to enable handling multiple patients; however, the excessive amount of words in the diagnostic sentences poses problems. Deep learning may be an effective solution to overcome this problem, but the use of such a heavy model may also add another obstacle to systems with limited computing resources. Objective: We aimed to build a diagnoses-extractive summarization model for hospital information systems and provide a service that can be operated even with limited computing resources. Methods: We used a Bidirectional Encoder Representations from Transformers (BERT)-based structure with a two-stage training method based on 258,050 discharge diagnoses obtained from the National Taiwan University Hospital Integrated Medical Database, and the highlighted extractive summaries written by experienced doctors were labeled. The model size was reduced using a character-level token, the number of parameters was decreased from 108,523,714 to 963,496, and the model was pretrained using random mask characters in the discharge diagnoses and International Statistical Classification of Diseases and Related Health Problems sets. We then fine-tuned the model using summary labels and cleaned up the prediction results by averaging all probabilities for entire words to prevent character level-induced fragment words. Model performance was evaluated against existing models BERT, BioBERT, and Long Short-Term Memory (LSTM) using the Recall-Oriented Understudy for Gisting Evaluation (ROUGE) L score, and a questionnaire website was built to collect feedback from more doctors for each summary proposal. Results: The area under the receiver operating characteristic curve values of the summary proposals were 0.928, 0.941, 0.899, and 0.947 for BERT, BioBERT, LSTM, and the proposed model (AlphaBERT), respectively. The ROUGE-L scores were 0.697, 0.711, 0.648, and 0.693 for BERT, BioBERT, LSTM, and AlphaBERT, respectively. The mean (SD) critique scores from doctors were 2.232 (0.832), 2.134 (0.877), 2.207 (0.844), 1.927 (0.910), and 2.126 (0.874) for reference-by-doctor labels, BERT, BioBERT, LSTM, and AlphaBERT, respectively. Based on the paired t test, there was a statistically significant difference in LSTM compared to the reference (P<.001), BERT (P=.001), BioBERT (P<.001), and AlphaBERT (P=.002), but not in the other models. Conclusions: Use of character-level tokens in a BERT model can greatly decrease the model size without significantly reducing performance for diagnoses summarization. A well-developed deep-learning model will enhance doctors' abilities to manage patients and promote medical studies by providing the capability to use extensive unstructured free-text notes. © 2020 Yen-Pin Chen, Yi-Ying Chen, Jr-Jiun Lin, Chien-Hua Huang, Feipei Lai.
KW  - Automatic summarization
KW  - BERT
KW  - Deep learning
KW  - Emergency medicine
KW  - Transformer
PB  - JMIR Publications Inc.
SN  - 22919694 (ISSN)
LA  - English
J2  - JMIR Med. Inform.
M3  - Article
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 12; Correspondence Address: Y.-P. Chen; Graduate Institute of Biomedical Electronics and Bioinformatics, National Taiwan University, Barry Lam Hall, Taipei City, No 1, Sec 4, Roosevelt Road, Taiwan; email: f06945029@g.ntu.edu.tw
ER  -

TY  - JOUR
AU  - Eke, C.I.
AU  - Norman, A.A.
AU  - Shuib, L.
TI  - Context-Based Feature Technique for Sarcasm Identification in Benchmark Datasets Using Deep Learning and BERT Model
PY  - 2021
T2  - IEEE Access
VL  - 9
C7  - 9383219
SP  - 48501
EP  - 48518
DO  - 10.1109/ACCESS.2021.3068323
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85103244303&doi=10.1109%2fACCESS.2021.3068323&partnerID=40&md5=eb8f236945206cb1eff34c979706a29d
AD  - Department of Information Systems, Faculty of Computer Science and Information Technology, University of Malaya, Kuala Lumpur, Malaysia
AD  - Department of Computer Science, Faculty of Computing, Federal University, P.M.B 046, Lafia, Nigeria
AB  - Sarcasm is a complicated linguistic term commonly found in e-commerce and social media sites. Failure to identify sarcastic utterances in Natural Language Processing applications such as sentiment analysis and opinion mining will confuse classification algorithms and generate false results. Several studies on sarcasm detection have utilised different learning algorithms. However, most of these learning models have always focused on the contents of expression only, leaving the contextual information in isolation. As a result, they failed to capture the contextual information in the sarcastic expression. Secondly, many deep learning methods in NLP uses a word embedding learning algorithm as a standard approach for feature vector representation, which ignores the sentiment polarity of the words in the sarcastic expression. This study proposes a context-based feature technique for sarcasm Identification using the deep learning model, BERT model, and conventional machine learning to address the issues mentioned above. Two Twitter and Internet Argument Corpus, version two (IAC-v2) benchmark datasets were utilised for the classification using the three learning models. The first model uses embedding-based representation via deep learning model with bidirectional long short term memory (Bi-LSTM), a variant of Recurrent Neural Network (RNN), by applying Global Vector representation (GloVe) for the construction of word embedding and context learning. The second model is based on Transformer using a pre-trained Bidirectional Encoder representation and Transformer (BERT). In contrast, the third model is based on feature fusion that comprised BERT feature, sentiment related, syntactic, and GloVe embedding feature with conventional machine learning. The effectiveness of this technique is tested with various evaluation experiments. However, the technique's evaluation on two Twitter benchmark datasets attained 98.5% and 98.0% highest precision, respectively. The IAC-v2 dataset, on the other hand, achieved the highest precision of 81.2%, which shows the significance of the proposed technique over the baseline approaches for sarcasm analysis.  © 2013 IEEE.
KW  - BERT
KW  - Bi-LSTM
KW  - GloVe embedding
KW  - Natural language processing
KW  - sarcasm identification
KW  - Classification (of information)
KW  - Deep learning
KW  - Embeddings
KW  - Learning systems
KW  - Long short-term memory
KW  - Semantics
KW  - Sentiment analysis
KW  - Social networking (online)
KW  - Benchmark datasets
KW  - Classification algorithm
KW  - Contextual information
KW  - Conventional machines
KW  - Evaluation experiments
KW  - Natural language processing applications
KW  - Recurrent neural network (RNN)
KW  - Vector representations
KW  - Learning algorithms
PB  - Institute of Electrical and Electronics Engineers Inc.
SN  - 21693536 (ISSN)
LA  - English
J2  - IEEE Access
M3  - Article
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 41; Correspondence Address: A.A. Norman; Department of Information Systems, Faculty of Computer Science and Information Technology, University of Malaya, Kuala Lumpur, Malaysia; email: azahnorman@um.edu.my; L. Shuib; Department of Information Systems, Faculty of Computer Science and Information Technology, University of Malaya, Kuala Lumpur, Malaysia; email: liyanashuib@um.edu.my
ER  -

TY  - JOUR
AU  - Segura-Bedmar, I.
AU  - Ruz, L.
AU  - Guerrero-Aspizua, S.
TI  - Evaluation of a transformer model applied to the task of text summarization in different domains
ST  - Evaluación de un modelo transformador aplicado a la tarea de generación de resúmenes en distintos dominios
PY  - 2021
T2  - Procesamiento del Lenguaje Natural
VL  - 66
SP  - 27
EP  - 39
DO  - 10.26342/2021-66-2
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85104227577&doi=10.26342%2f2021-66-2&partnerID=40&md5=5a8f45f5dd920b7ea74aa65138242684
AD  - Universidad Carlos III de Madrid, Leganés, Spain
AB  - In recent years, deep learning techniques have provided a significant technological advance in many Natural Language Processing (NLP) tasks. Text summarization has also benefited from these techniques. Recently, several deep learning approaches have been implemented, surpassing the previous state of the art performances. Most of these works have been evaluated on collections of journalistic texts. This article presents a preliminary work where we apply a transforming model, BART, for text summarization. The model is evaluated on several datasets, one of them consisting of texts from the biomedical domain. © 2021 Sociedad Española para el Procesamiento del Lenguaje Natural
KW  - Text summarization, Transformers
PB  - Sociedad Espanola para el Procesamiento del Lenguaje Natural
SN  - 11355948 (ISSN)
LA  - Spanish
J2  - Proces. Lenguaje Nat.
M3  - Article
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 0
ER  -

TY  - JOUR
AU  - Rahman, M.M.
AU  - Watanobe, Y.
AU  - Nakamura, K.
TI  - A bidirectional lstm language model for code evaluation and repair
PY  - 2021
T2  - Symmetry
VL  - 13
IS  - 2
C7  - 247
SP  - 1
EP  - 15
DO  - 10.3390/sym13020247
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85100333393&doi=10.3390%2fsym13020247&partnerID=40&md5=267d06d1b409c1cb3842dd6ec27cee3e
AD  - Graduate Department of Computer and Information Systems, School of Computer Science and Engineering, The University of Aizu, Aizu-Wakamatsu, Fukushima, 965-8580, Japan
AB  - Programming is a vital skill in computer science and engineering-related disciplines. However, developing source code is an error-prone task. Logical errors in code are particularly hard to identify for both students and professionals, and a single error is unexpected to end-users. At present, conventional compilers have difficulty identifying many of the errors (especially logical errors) that can occur in code. To mitigate this problem, we propose a language model for evaluating source codes using a bidirectional long short-term memory (BiLSTM) neural network. We trained the BiLSTM model with a large number of source codes with tuning various hyperparameters. We then used the model to evaluate incorrect code and assessed the model’s performance in three prin-cipal areas: source code error detection, suggestions for incorrect code repair, and erroneous code classification. Experimental results showed that the proposed BiLSTM model achieved 50.88% cor-rectness in identifying errors and providing suggestions. Moreover, the model achieved an F-score of approximately 97%, outperforming other state-of-the-art models (recurrent neural networks (RNNs) and long short-term memory (LSTM)). © 2021 by the authors. Licensee MDPI, Basel, Switzerland.
KW  - Bidirectional LSTM
KW  - Code repair
KW  - Error detection
KW  - Neural network
KW  - Online judge
KW  - Programming education
KW  - Software engineering
KW  - Source code assessment
PB  - MDPI AG
SN  - 20738994 (ISSN)
LA  - English
J2  - Symmetry
M3  - Article
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 51; Correspondence Address: M.M. Rahman; Graduate Department of Computer and Information Systems, School of Computer Science and Engineering, The University of Aizu, Fukushima, Aizu-Wakamatsu, 965-8580, Japan; email: mostafiz26@gmail.com; Y. Watanobe; Graduate Department of Computer and Information Systems, School of Computer Science and Engineering, The University of Aizu, Fukushima, Aizu-Wakamatsu, 965-8580, Japan; email: yutaka@u-aizu.ac.jp
ER  -

TY  - CONF
AU  - Aßenmacher, M.
AU  - Schulze, P.
AU  - Heumann, C.
TI  - Benchmarking down-scaled (not so large) pre-trained language models
PY  - 2021
T2  - KONVENS 2021 - Proceedings of the 17th Conference on Natural Language Processing
SP  - 14
EP  - 27
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85119448084&partnerID=40&md5=8b733df3bbdcd94a86cfddbac5e6e591
AD  - Department of Statistics, Ludwig-Maximilians-Universität, Ludwigstr. 33, Munich, D-80539, Germany
AB  - Large Transformer-based language models are pre-trained on corpora of varying sizes, for a different number of steps and with different batch sizes. At the same time fundamental components, such as the pre-training objective or architectural hyperparameters, are modified. In total, it is therefore difficult to ascribe changes in performance to specific factors. Since searching the hyperparameter space over the full systems is too costly, we pre-train down-scaled versions of several popular Transformer-based architectures on a common pre-training corpus and benchmark them on a subset of the GLUE tasks (Wang et al., 2018). Specifically, we systematically compare three pre-training objectives for different shape parameters and model sizes, while also varying the number of pre-training steps and the batch size. In our experiments MLM + NSP (BERT-style) consistently outperforms MLM (RoBERTa-style) as well as the standard LM objective. Furthermore, we find that additional compute should be mainly allocated to an increased model size, while training for more steps is inefficient. Based on these observations, as a final step we attempt to scale up several systems using compound scaling (Tan and Le, 2019) adapted to Transformer-based language models. © 2021 KONVENS 2021 - Proceedings of the 17th Conference on Natural Language Processing. All Rights Reserved.
KW  - Computational linguistics
KW  - Batch sizes
KW  - Different shapes
KW  - Fundamental component
KW  - Hyper-parameter
KW  - Hyper-parameter space
KW  - Language model
KW  - Model size
KW  - Performance
KW  - Pre-training
KW  - Training corpus
KW  - Natural language processing systems
PB  - KONVENS
SN  - 978-195408583-1 (ISBN)
LA  - English
J2  - KONVENS - Proc. Conf. Nat. Lang. Process.
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 0; Conference name: 17th Conference on Natural Language Processing, KONVENS 2021; Conference date: 6 September 2021 through 9 September 2021; Conference code: 173594
ER  -

TY  - JOUR
AU  - Zhang, P.
AU  - Jin, N.
AU  - Lin, X.
AU  - Li, Z.
AU  - Xing, J.
AU  - Rong, Z.
AU  - Ma, S.
AU  - Guo, Q.
AU  - Mo, W.
TI  - High-voltage Built-in Transformer No-load Closing Model and Its Application for the Mal-operation Risk Assessment of Line Zero-sequence Over-current Protection
ST  - 面向零序过流保护误动风险评估的高压内置型高阻抗变压器空载合闸模型及应用
PY  - 2020
T2  - Zhongguo Dianji Gongcheng Xuebao/Proceedings of the Chinese Society of Electrical Engineering
VL  - 40
IS  - 20
SP  - 6593
EP  - 6602
DO  - 10.13334/j.0258-8013.pcsee.190801
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85095681528&doi=10.13334%2fj.0258-8013.pcsee.190801&partnerID=40&md5=8811a2a0c679954f9541e09c674b862f
AD  - State Key Laboratory of Advanced Electromagnetic Engineering and Technology, Huazhong University of Science and Technology, Wuhan, 430074, China
AD  - Tests and Research Instiute of Guangzhou Power Supply Bureau, Guangzhou, 510410, China
AB  - Aiming at the mal-operation of the line zero-sequence over-current protection, when the high-voltage built-in transformer is energized, a new transformer mathematical model was proposed in this paper based on dual-time-constant. And the calculation results of the model were compared with the recorded data and simulation data, which showed that the model was able to simulate the law of zero-sequence inrush. The model was able to take place of the PSCAD/EMTDC. Besides, it can calculate and analyze massive data automatically. Based on the proposed model, the problem of zero-sequence over-current protection mal- operation caused by zero-sequence inrush was studied in depth, and the seriousness of zero-sequence inrush current generated by high-voltage built-in transformer no-load-closing was quantitatively described. At last, the risk of the over-current protection mal-operation was evaluated, which provided a reference for the operational department. © 2020 Chin. Soc. for Elec. Eng.
KW  - Dual-time-constant
KW  - High-voltage built-in transformer (HVBT)
KW  - Mathematical model
KW  - Risk assessment
KW  - Zero-sequence inrush
KW  - Zero-sequence over-current protection (ZOCP)
KW  - Risk assessment
KW  - Surge protection
KW  - Calculation results
KW  - Dual time
KW  - High voltage
KW  - In-rush current
KW  - ITS applications
KW  - Massive data
KW  - Simulation data
KW  - Zero sequences
KW  - Transformer protection
PB  - Chinese Society for Electrical Engineering
SN  - 02588013 (ISSN)
LA  - Chinese
J2  - Zhongguo Dianji Gongcheng Xuebao
M3  - Article
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 0; Correspondence Address: N. Jin; State Key Laboratory of Advanced Electromagnetic Engineering and Technology, Huazhong University of Science and Technology, Wuhan, 430074, China; email: jinnengjn@126.com; CODEN: ZDGXE
ER  -

TY  - CONF
AU  - Jiang, M.
AU  - Hu, Y.
AU  - Worthey, G.
AU  - Dubnicek, R.C.
AU  - Underwood, T.
AU  - Downie, J.S.
TI  - Evaluating BERT's Encoding of Intrinsic Semantic Features of OCR'd Digital Library Collections
PY  - 2021
T2  - Proceedings of the ACM/IEEE Joint Conference on Digital Libraries
VL  - 2021-September
SP  - 308
EP  - 309
DO  - 10.1109/JCDL52503.2021.00045
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85124198418&doi=10.1109%2fJCDL52503.2021.00045&partnerID=40&md5=6fa30a3d716e2c058ff332a19353065b
AD  - School of Information Sciences, University of Illinois, Urbana-Champaign, IL, United States
AD  - HathiTrust Research Center iSchool, University of Illinois, Urbana-Champaign, IL, United States
AB  - The uncertainty caused by optical character recognition (OCR) noise has been a primary barrier for digital libraries (DL) to promote their curated datasets for research purposes, particularly when the datasets are fed into advanced language models with less transparency. To shed some light on this issue, this study evaluates the impacts of OCR noise on BERT models for encoding the intrinsic semantic features of OCR'd texts. Specifically, we encoded chapterwise paired OCR'd texts and their cleaned counterparts extracted from books in six domains using BERT pre-trained and fine-tune models respectively. Given the encoded text features, we further calculated the cosine similarity between any two chapters and used normalized discounted cumulative gain (NDCG) [1] to measure BERT variants' capabilities to preserve narrative coherence and semantic relevance among texts. Our empirical results show that (1) BERT embeddings can encode and preserve texts' intrinsic semantic features (i.e., relevance and coherence); and (2) such capabilities are comparatively robust against OCR noise. This should help alleviate some DL users' concerns regarding applying contextualized word embeddings to encode chapter-level or even document-level OCR'd text information, which benefits promoting scholarly use of DL collections. Our research also demonstrates how texts' intrinsic semantic features can be used for evaluating the impacts of OCR noise on advanced language models, which is an underdeveloped and promising direction for future work. © 2021 IEEE.
KW  - BERT Evaluation
KW  - Data Curation
KW  - Digital Humanities
KW  - Digital Libraries
KW  - HathiTrust
KW  - Intrinsic Semantic Features
KW  - Optical Character Recognition
KW  - Parallel Corpus
KW  - Word Embeddings
KW  - Computational linguistics
KW  - Digital libraries
KW  - Encoding (symbols)
KW  - Optical character recognition
KW  - Semantics
KW  - Signal encoding
KW  - BERT evaluation
KW  - Data curation
KW  - Digital humanities
KW  - Digital library collections
KW  - Embeddings
KW  - Hathitrust
KW  - Intrinsic semantic feature
KW  - Parallel corpora
KW  - Semantic features
KW  - Word embedding
KW  - Embeddings
A2  - Downie J.S.
A2  - McKay D.
A2  - Suleman H.
A2  - Nichols D.M.
A2  - Poursardar F.
PB  - Institute of Electrical and Electronics Engineers Inc.
SN  - 15525996 (ISSN); 978-166541770-9 (ISBN)
LA  - English
J2  - Proc. ACM IEEE Joint Conf. Digit. Libr.
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 4; Conference name: 21st ACM/IEEE Joint Conference on Digital Libraries, JCDL 2021; Conference date: 27 September 2021 through 30 September 2021; Conference code: 175953
ER  -

TY  - CONF
AU  - Azis Prasojo, R.
AU  - Ulfa Maulidevi, N.
AU  - Anggoro Soedjarno, B.
TI  - A Multiple Expert Consensus Model for Transformer Assessment Index Weighting Factor Determination
PY  - 2020
T2  - Proceeding - 8th International Conference on Condition Monitoring and Diagnosis, CMD 2020
C7  - 9287198
SP  - 234
EP  - 237
DO  - 10.1109/CMD48350.2020.9287198
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85107080889&doi=10.1109%2fCMD48350.2020.9287198&partnerID=40&md5=da5b035145c622adb25124c30b376442
AD  - Institut Teknologi Bandung, School of Electrical Engineering and Informatics, Bandung, Indonesia
AB  - In composing a Transformer Assessment Index (TAI), weighting factor is a critical consideration. Expert judgment is a common practice in adjusting weighting factor of a TAI. Years of experience from experts is a valuable information to be considered. Several previous researches develop AHP to determine parameter prioritization based on expert judgment. The use of multi-expert can benefit the system developed, but this may lead to another complexity in aggregating the results. As much as five experts with in-depth experience in transformer condition monitoring and diagnostics were taking parts in this study. A row geometric mean method was used to obtain the consensus matrix. This paper proposed an approach to implement the consensus model for multiple experts in power transformer assessment index weighting factor determination using AHP.  © 2020 IEEE.
KW  - analytic hierarchy process
KW  - consensus analysis
KW  - health index
KW  - transformer assessment index
KW  - weighting factor
KW  - Hierarchical systems
KW  - Lead compounds
KW  - Power transformers
KW  - Assessment index
KW  - Consensus models
KW  - Expert judgment
KW  - Geometric mean method
KW  - Multi-expert
KW  - Prioritization
KW  - Transformer condition monitoring
KW  - Weighting factors
KW  - Condition monitoring
PB  - Institute of Electrical and Electronics Engineers Inc.
SN  - 978-172815931-7 (ISBN)
LA  - English
J2  - Proceeding - Int. Conf. Cond. Monit. Diagn., CMD
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 17; Conference name: 8th International Conference on Condition Monitoring and Diagnosis, CMD 2020; Conference date: 25 October 2020 through 28 October 2020; Conference code: 165867
ER  -

TY  - JOUR
AU  - Du, J.
AU  - Sun, M.
TI  - Hierarchical Assessment Method of Transformer Condition Based on Weight-Varying Grey Cloud Model
ST  - 基于变权灰云模型的变压器状态层次评估方法
PY  - 2020
T2  - Diangong Jishu Xuebao/Transactions of China Electrotechnical Society
VL  - 35
IS  - 20
SP  - 4306
EP  - 4316
DO  - 10.19595/j.cnki.1000-6753.tces.190827
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85094657858&doi=10.19595%2fj.cnki.1000-6753.tces.190827&partnerID=40&md5=c95b947e962e0208267efcac7989831a
AD  - State Key Laboratory of Reliability and Intelligence of Electrical Equipment, Hebei University of Technology, Tianjin, 300130, China
AD  - Key Laboratory of Electromagnetic Field and Electrical Apparatus Reliability of Hebei Province, Hebei University of Technology, Tianjin, 300130, China
AB  - In order to objectively and scientifically evaluate the transformer condition, a hierarchical index system for transformer condition evaluation was established, and a hierarchical assessment method for transformer condition based on weight-varying grey cloud model was proposed. Firstly, the cloud model was used to improve traditional whitening weight function to build grey cloud model. Compared with the traditional grey clustering whitening weight function, the grey cloud model could effectively reflect fuzziness, greyness and randomness for information of evaluation level. To better reflect the uncertainty of the transformer status information, the cloud correlation was calculated using index cloud model instead of index value. Then, the condition of transformer fault layer was obtained by association rules and grey cloud clustering. The overall condition of transformer was obtained by weight-varying fusion. To acquire the final evaluation result, the condition of transformer fault layer and the overall condition were considered comprehensively. Finally, the case studies verified that the proposed method is effective and superior. © 2020, Electrical Technology Press Co. Ltd. All right reserved.
KW  - Cloud correlation
KW  - Cloud model
KW  - Condition assessment
KW  - Gray cloud clustering
KW  - Transformer
KW  - Weight-varying theory
KW  - Function evaluation
KW  - Cloud modeling
KW  - Condition evaluation
KW  - Evaluation results
KW  - Grey clustering
KW  - Index systems
KW  - Status informations
KW  - Transformer faults
KW  - Weight functions
KW  - Cloud computing
PB  - China Machine Press
SN  - 10006753 (ISSN)
LA  - Chinese
J2  - Diangong Jishu Xuebao
M3  - Article
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 19; Correspondence Address: J. Du; State Key Laboratory of Reliability and Intelligence of Electrical Equipment, Hebei University of Technology, Tianjin, 300130, China; email: dj@hebut.edu.cn; CODEN: DIJXE
ER  -

TY  - CONF
AU  - Schmalz, V.J.
AU  - Brutti, A.
TI  - Automatic assessment of English CEFR levels using BERT embeddings
PY  - 2021
T2  - CEUR Workshop Proceedings
VL  - 3033
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85121251509&partnerID=40&md5=b05011a56cc1ae5e2c7ed56dc7dbe242
AD  - Free University of Bozen-Bolzano, Bolzano, Italy
AD  - Fondazione Bruno Kessler, Trento, Italy
AD  - KU Leuven, Imec Research Group Itec, Kortrijk, Belgium
AB  - The automatic assessment of language learners' competences represents an increasingly promising task thanks to recent developments in NLP and deep learning technologies. In this paper, we propose the use of neural models for classifying English written exams into one of the Common European Framework of Reference for Languages (CEFR) competence levels. We employ pre-trained Bidirectional Encoder Representations from Transformers (BERT) models which provide efficient and rapid language processing on account of attention-based mechanisms and the capacity of capturing long-range sequence features. In particular, we investigate on augmenting the original learner's text with corrections provided by an automatic tool or by human evaluators. We consider different architectures where the texts and corrections are combined at an early stage, via concatenation before the BERT network, or as late fusion of the BERT embeddings. The proposed approach is evaluated on two open-source datasets: The English First Cambridge open language Database (EFCAMDAT) and the Cambridge Learner Corpus for the First Certificate in English (CLC-FCE). The experimental results show that the proposed approach can predict the learner's competence level with remarkably high accuracy, in particular when large labelled corpora are available. In addition, we observed that augmenting the input text with corrections provides further improvement in the automatic language assessment task. © 2021 for this paper by its author. Use permitted under Creative Commons License Attribution 4.0 International (CC BY 4.0).
KW  - Embeddings
KW  - Natural language processing systems
KW  - Automatic assessment
KW  - Automatic tools
KW  - Cambridge
KW  - Embeddings
KW  - Language levels
KW  - Language processing
KW  - Learning technology
KW  - Neural modelling
KW  - Sequence features
KW  - Transformer modeling
KW  - Deep learning
A2  - Fersini E.
A2  - Passarotti M.
A2  - Patti V.
PB  - CEUR-WS
SN  - 16130073 (ISSN)
LA  - English
J2  - CEUR Workshop Proc.
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 1; Conference name: 8th Italian Conference on Computational Linguistics, CLiC-it 2021; Conference date: 26 January 2022 through 28 January 2022; Conference code: 175403
ER  -

TY  - JOUR
AU  - Suzuki, T.
AU  - Miura, N.
AU  - Hojo, R.
AU  - Yanagiba, Y.
AU  - Suda, M.
AU  - Hasegawa, T.
AU  - Miyagawa, M.
AU  - Wang, R.-S.
TI  - Erratum: Genotoxicity assessment of titanium dioxide nanoparticle accumulation of 90 days in the liver of gpt delta transgenic mice (Genes and Environment (2020) 42 (7) DOI: 10.1186/s41021-020-0146-3)
PY  - 2020
T2  - Genes and Environment
VL  - 42
IS  - 1
C7  - 10
DO  - 10.1186/s41021-020-00151-5
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85082673957&doi=10.1186%2fs41021-020-00151-5&partnerID=40&md5=318b47ad65f8209854e674e7f62b70d8
AD  - Division of Industrial Toxicology and Health Effects Research, National Institute of Occupational Safety and Health, 6-21-1 Nagao, Tama-ku, Kawasaki, Kanagawa, 214-8585, Japan
AD  - Graduate School of Biomedical and Health Sciences, Hiroshima University, Hiroshima, 734-8553, Japan
AD  - Department of Health Science, Yokohama University of Pharmacy, Yokohama, 245-0066, Japan
AD  - Division of Human Environmental Science, Mount Fuji Research Institute, Yamanashi Prefectural Government, 5597-1 Kenmarubi, Kamiyoshida, Fujiyoshida, Yamanashi, 403-0005, Japan
AD  - Department of Sport and Medical Science, Faculty of Medical Technology, Teikyo University, Tokyo, Hachioji, 192-0835, Japan
AB  - Correction to: Genes Environ (2020) 42:7 https://doi.org/10.1186/s41021-020-0146-3 In the original publication of this article [1], the author made a correction but wasnt carried out. The (Fig. 1b) in sentence Large clusters containing the TiO NPs were found in the parenchymal hepatocytes (Fig. 1c) and Kupffer cells (Fig. 1b), although the clusters were much more should be (Fig. 1d). The original publication has been corrected. © 2020 The Author(s). Reference:.
KW  - erratum
PB  - BioMed Central Ltd.
SN  - 18807046 (ISSN)
LA  - English
J2  - Genes Environ.
M3  - Erratum
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 3; Correspondence Address: R.-S. Wang; Division of Industrial Toxicology and Health Effects Research, National Institute of Occupational Safety and Health, Kawasaki, Kanagawa, 6-21-1 Nagao, Tama-ku, 214-8585, Japan; email: wang@h.jniosh.johas.go.jp
ER  -

TY  - CONF
AU  - Zhang, E.
AU  - Liu, J.
AU  - Zhang, H.
AU  - Geng, C.
AU  - Zhang, Y.
TI  - Evaluation Model of Ternary Chemical Indicators for Aging Status of Paper Insulation at Transformer Winding Hot Spots
PY  - 2021
T2  - Annual Report - Conference on Electrical Insulation and Dielectric Phenomena, CEIDP
VL  - 2021-December
SP  - 555
EP  - 558
DO  - 10.1109/CEIDP50766.2021.9705415
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85126005538&doi=10.1109%2fCEIDP50766.2021.9705415&partnerID=40&md5=b03e251de212233128c18cbe904252c3
AD  - Guangxi University, School of Electrical Engineering, Nanning, 530004, China
AB  - Existing studies have only analyzed the evaluation mechanism of chemical indicators on the 'uniform' aging status of paper insulation. In view of this, this work explores the use of chemical indicators to characterize the degree of aging of paper insulation hot spots. Furthermore, the ternary chemical indicators are employed as assessment factors in order to eliminate the limitations of single indicators. Determine the influence model of temperature and moisture on methanol, ethanol and furfural. Then, based on the entropy weight method, the contribution of ternary chemical indicators in the assessment of paper insulation aging is obtained. Finally, according to the distribution law of the degree of polymerization along different heights in the uneven aging state, the relationship between the degree of polymerization of the insulating paper in the hot spots area (Tmax, DPmin) and the ternary indicators in the oil could be derived. © 2021 IEEE.
KW  - Chemical analysis
KW  - Insulation
KW  - Oil filled transformers
KW  - Polymerization
KW  - %moisture
KW  - Aging status
KW  - Degrees of polymerizations
KW  - Entropy weight method
KW  - Evaluation models
KW  - Hotspots
KW  - Influence model
KW  - Insulation aging
KW  - Paper insulation
KW  - Transformers winding
KW  - Indicators (chemical)
PB  - Institute of Electrical and Electronics Engineers Inc.
SN  - 00849162 (ISSN); 978-166541907-9 (ISBN)
LA  - English
J2  - Annu. Rep. Conf. Electr. Insul. Dielectr. Phenom. CEIDP
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 0; Conference name: 96th IEEE Conference on Electrical Insulation and Dielectric Phenomena, CEIDP 2021; Conference date: 12 December 2021 through 15 December 2021; Conference code: 177310; CODEN: CEIPA
ER  -

TY  - JOUR
AU  - Chen, R.
AU  - You, X.
AU  - Cao, Y.
AU  - Masumura, K.
AU  - Ando, T.
AU  - Hamada, S.
AU  - Horibata, K.
AU  - Wan, J.
AU  - Xi, J.
AU  - Zhang, X.
AU  - Honma, M.
AU  - Luan, Y.
TI  - Benchmark dose analysis of multiple genotoxicity endpoints in gpt delta mice exposed to aristolochic acid i
PY  - 2021
T2  - Mutagenesis
VL  - 36
IS  - 1
SP  - 87
EP  - 94
DO  - 10.1093/mutage/geaa034
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85105834213&doi=10.1093%2fmutage%2fgeaa034&partnerID=40&md5=0a05f7bfc8c28b9f1d111019dd42f06d
AD  - School of Public Health, Hongqiao International Institute of Medicine, Shanghai Jiao Tong University School of Medicine, 227 South Chongqing Road, Shanghai, 200025, China
AD  - Division of Genetics and Mutagenesis, National Institute of Health Sciences, Tonomachi, Kawasaki-ku, 3-25-26 Tonomachi, Kanagawa, Kawasaki, 210-9501, Japan
AD  - Tokyo Laboratory BoZo Research Center Inc., 1-3-11 Hanegi, Setagaya, Tokyo, 156-0042, Japan
AB  - As the carcinogenic risk of herbs containing aristolochic acids (AAs) is a global health issue, quantitative evaluation of toxicity is needed for the regulatory decision-making and risk assessment of AAs. In this study, we selected AA I (AAI), the most abundant and representative compound in AAs, to treat transgenic gpt delta mice at six gradient doses ranging from 0.125 to 4 mg/kg/day for 28 days. AAI-DNA adduct frequencies and gpt gene mutation frequencies (MFs) in the kidney, as well as Pig-a gene MFs and micronucleated reticulocytes (MN-RETs) frequencies in peripheral blood, were monitored. The dose-response (DR) relationship data for these in vivo genotoxicity endpoints were quantitatively evaluated using an advanced benchmark dose (BMD) approach with different critical effect sizes (CESs; i.e., BMD5, BMD10, BMD50 and BMD100). The results showed that the AAI-DNA adduct frequencies, gpt MFs and the MN-RETs presented good DR relationship to the administrated doses, and the corresponding BMDL100 (the lower 90% confidence interval of the BMD100) values were 0.017, 0.509 and 3.9 mg/kg/day, respectively. No positive responses were observed in the Pig-a MFs due to bone marrow suppression caused by AAI. Overall, we quantitatively evaluated the genotoxicity of AAI at low doses for multiple endpoints for the first time. Comparisons of BMD100 values across different endpoints provide a basis for the risk assessment and regulatory decision-making of AAs and are also valuable for understanding the genotoxicity mechanism of AAs. © 2020 The Author(s) 2020. Published by Oxford University Press on behalf of the UK Environmental Mutagen Society.All rights reserved. For permissions, please e-mail: journals.permissions@oup.com.
KW  - Animals
KW  - Aristolochic Acids
KW  - Benchmarking
KW  - DNA Adducts
KW  - DNA Damage
KW  - Escherichia coli Proteins
KW  - Humans
KW  - Male
KW  - Mice
KW  - Mice, Inbred C57BL
KW  - Mice, Transgenic
KW  - Micronucleus Tests
KW  - Mutagenicity Tests
KW  - Mutagens
KW  - Mutation Rate
KW  - Pentosyltransferases
KW  - alanine aminotransferase
KW  - aristolochic acid
KW  - genomic DNA
KW  - aristolochic acid
KW  - aristolochic acid I
KW  - Escherichia coli protein
KW  - glycosyltransferase
KW  - Gpt protein, E coli
KW  - mutagenic agent
KW  - animal cell
KW  - animal experiment
KW  - animal model
KW  - animal tissue
KW  - Article
KW  - blood
KW  - bone marrow suppression
KW  - chromosome aberration
KW  - controlled study
KW  - DNA adduct
KW  - DNA damage
KW  - electrospray mass spectrometry
KW  - erythrocyte
KW  - gene frequency
KW  - gene mutation
KW  - genotoxicity
KW  - gpt delta mouse
KW  - in vivo study
KW  - kidney
KW  - limit of detection
KW  - liquid chromatography-mass spectrometry
KW  - liver
KW  - micronucleus test
KW  - mouse
KW  - multiple reaction monitoring
KW  - nonhuman
KW  - reticulocyte
KW  - risk assessment
KW  - animal
KW  - benchmarking
KW  - C57BL mouse
KW  - DNA adduct
KW  - DNA damage
KW  - genetics
KW  - human
KW  - male
KW  - metabolism
KW  - mutagen testing
KW  - mutation rate
KW  - transgenic mouse
PB  - Oxford University Press
SN  - 02678357 (ISSN)
C2  - 33367723
LA  - English
J2  - Mutagenesis
M3  - Article
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 4; Correspondence Address: Y. Luan; School of Public Health, Hongqiao International Institute of Medicine, Shanghai Jiao Tong University School of Medicine, Shanghai, 227 South Chongqing Road, 200025, China; email: yluan@sjtu.edu.cn; CODEN: MUTAE
ER  -

TY  - CONF
AU  - Lin, B.Y.
AU  - Lee, S.
AU  - Qiao, X.
AU  - Ren, X.
TI  - Common sense beyond english: Evaluating and improving multilingual language models for commonsense reasoning
PY  - 2021
T2  - ACL-IJCNLP 2021 - 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing, Proceedings of the Conference
SP  - 1274
EP  - 1287
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85117978347&partnerID=40&md5=7605ef3f17ee23636bf1efe39d4a4f0f
AD  - Department of Computer Science, Information Sciences Institute, University of Southern California, United States
AB  - Commonsense reasoning research has so far been limited to English. We aim to evaluate and improve popular multilingual language models (ML-LMs) to help advance commonsense reasoning (CSR) beyond English. We collect the Mickey corpus, consisting of 561k sentences in 11 different languages, which can be used for analyzing and improving ML-LMs. We propose Mickey Probe, a language-agnostic probing task for fairly evaluating the common sense of popular ML-LMs across different languages. In addition, we also create two new datasets, X-CSQA and X-CODAH, by translating their English versions to 15 other languages, so that we can evaluate popular ML-LMs for cross-lingual commonsense reasoning. To improve the performance beyond English, we propose a simple yet effective method - multilingual contrastive pretraining (MCP). It significantly enhances sentence representations, yielding a large performance gain on both benchmarks (e.g., +2.7% accuracy for X-CSQA over XLM-RL). © 2021 Association for Computational Linguistics
KW  - Computational linguistics
KW  - Common sense
KW  - Commonsense reasoning
KW  - Cross-lingual
KW  - Language model
KW  - Performance
KW  - Performance Gain
KW  - Pre-training
KW  - Simple++
KW  - Benchmarking
PB  - Association for Computational Linguistics (ACL)
SN  - 978-195408552-7 (ISBN)
LA  - English
J2  - ACL-IJCNLP - Annu. Meet. Assoc. Comput. Linguist. Int. Jt. Conf. Nat. Lang. Process., Proc. Conf.
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 14; Conference name: Joint Conference of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing, ACL-IJCNLP 2021; Conference date: 1 August 2021 through 6 August 2021; Conference code: 173030
ER  -

TY  - CONF
AU  - Koto, F.
AU  - Rahimi, A.
AU  - Lau, J.H.
AU  - Baldwin, T.
TI  - IndoLEM and IndoBERT: A Benchmark Dataset and Pre-trained Language Model for Indonesian NLP
PY  - 2020
T2  - COLING 2020 - 28th International Conference on Computational Linguistics, Proceedings of the Conference
SP  - 757
EP  - 770
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85149645196&partnerID=40&md5=136d3eac74aea4a049cbe65a40bb5092
AD  - The University of Melbourne, Australia
AD  - The University of Queensland, Australia
AB  - Although the Indonesian language is spoken by almost 200 million people and the 10th most-spoken language in the world,1 it is under-represented in NLP research. Previous work on Indonesian has been hampered by a lack of annotated datasets, a sparsity of language resources, and a lack of resource standardization. In this work, we release the INDOLEM dataset comprising seven tasks for the Indonesian language, spanning morpho-syntax, semantics, and discourse. We additionally release INDOBERT, a new pre-trained language model for Indonesian, and evaluate it over INDOLEM, in addition to benchmarking it against existing resources. Our experiments show that INDOBERT achieves state-of-the-art performance over most of the tasks in INDOLEM. © 2020 COLING 2020 - 28th International Conference on Computational Linguistics, Proceedings of the Conference. All rights reserved.
KW  - Computational linguistics
KW  - Semantics
KW  - Annotated datasets
KW  - Benchmark datasets
KW  - Indonesian languages
KW  - Language model
KW  - Language resources
KW  - Spoken languages
KW  - State-of-the-art performance
KW  - Under-represented
KW  - Natural language processing systems
A2  - Scott D.
A2  - Bel N.
A2  - Zong C.
PB  - Association for Computational Linguistics (ACL)
SN  - 978-195214827-9 (ISBN)
LA  - English
J2  - COLING - Int. Conf. Comput. Linguist., Proc. Conf.
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 69; Conference name: 28th International Conference on Computational Linguistics, COLING 2020; Conference date: 8 December 2020 through 13 December 2020; Conference code: 186886
ER  -

TY  - JOUR
AU  - Li, J.
AU  - Li, J.
TI  - Core form transformer topological duality based transient model validation for exciting current calculation within DC bias
PY  - 2020
T2  - IET Generation, Transmission and Distribution
VL  - 14
IS  - 15
SP  - 3099
EP  - 3107
DO  - 10.1049/iet-gtd.2019.1174
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85089948305&doi=10.1049%2fiet-gtd.2019.1174&partnerID=40&md5=29316c557b804b4370ab29e8511b6e5e
AD  - China Electric Power Research Institute, Beijing, 100192, China
AD  - State Grid Corporation of China, Beijing, 100031, China
AB  - Transformer topological duality-based transient model (TDuM) has been widely used in the electromagnetic transient (EMT) simulation to consider the impact of core non-linear features and windings arrangement on exciting current. In this study, the transformer TDuMs that specialized for geomagnetically induced current events studying were validated. After a summary of the transformer TDuMs' derivation and their parameters estimation methodologies, the numerical experiments were carried out to investigate the transformer TDuMs and their related key issues such as core's material types, loss factor of hysteresis model, linear leakage inductance, tank wall with EMT analysis software. The numerical results show a good agreement with the measured data in the field experiments with DC bias applied, which mean that using the transformer TDuM to calculate the exciting current under DC bias condition is feasible. Besides, some practical tips were proposed based on the parameters sensitivity analysis for estimating the transformer TDuMs' parameters to study the transformers' dynamics under DC bias condition. © 2019 The Institution of Engineering and Technology.
KW  - Hysteresis
KW  - Parameter estimation
KW  - Power quality
KW  - Sensitivity analysis
KW  - Topology
KW  - Transformer windings
KW  - Electromagnetic transients
KW  - Geomagnetically induced currents
KW  - Hysteresis modeling
KW  - Leakage inductance
KW  - Nonlinear features
KW  - Numerical experiments
KW  - Parameters estimation
KW  - Topological dualities
KW  - DC transformers
PB  - Institution of Engineering and Technology
SN  - 17518687 (ISSN)
LA  - English
J2  - IET Gener. Transm. Distrib.
M3  - Article
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 3; Correspondence Address: J. Li; China Electric Power Research Institute, Beijing, 100192, China; email: Jinlong.Li.CN@ieee.org
ER  -

TY  - CONF
AU  - Ou, X.
AU  - Li, H.
TI  - YNU-oxz at SemEval-2020 Task 4: Commonsense Validation using BERT with Bidirectional GRU
PY  - 2020
T2  - 14th International Workshops on Semantic Evaluation, SemEval 2020 - co-located 28th International Conference on Computational Linguistics, COLING 2020, Proceedings
SP  - 626
EP  - 632
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85123951654&partnerID=40&md5=36de95b6ba1d3ac9db44e55bb086f00a
AD  - School of Information Science and Engineering, Yunnan University, Yunnan, China
AB  - This paper describes the system and results of our team participated in SemEval-2020 Task4: Commonsense Validation and Explanation (ComVE), which aim to distinguish meaningful natural language statements from unreasonable natural language statements. This task contains three subtasks: Subtask A-Validation, Subtask B-Explanation (Multi-Choice), and Subtask C-Explanation (Generation). In these three subtasks, we only participated in Subtask A, which aims to distinguish whether a given two natural language statements with similar wording are meaningful. To solve this problem, we proposed a method using a combination of BERT with the Bidirectional Gated Recurrent Unit (Bi-GRU). Our model achieved an accuracy of 0.836 in Subtask A (ranked 27/45). © 2020 14th International Workshops on Semantic Evaluation, SemEval 2020 - co-located 28th International Conference on Computational Linguistics, COLING 2020, Proceedings. All rights reserved.
KW  - Computational linguistics
KW  - Language statements
KW  - Multi choices
KW  - Natural languages
KW  - Subtask
KW  - Semantics
A2  - Herbelot A.
A2  - Zhu X.
A2  - Palmer A.
A2  - Schneider N.
A2  - May J.
A2  - Shutova E.
PB  - International Committee for Computational Linguistics
SN  - 978-195214831-6 (ISBN)
LA  - English
J2  - Int. Workshops Semant. Eval., SemEval - co-located Int. Conf. Comput. Linguist., COLING , Proc.
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 0; Correspondence Address: H. Li; School of Information Science and Engineering, Yunnan University, Yunnan, China; email: honglingli66@126.com; Conference name: 14th International Workshops on Semantic Evaluation, SemEval 2020; Conference date: 12 December 2020 through 13 December 2020; Conference code: 174265
ER  -

TY  - CONF
AU  - Koay, H.V.
AU  - Chuah, J.H.
AU  - Chow, C.-O.
TI  - Convolutional Neural Network or Vision Transformer? Benchmarking Various Machine Learning Models for Distracted Driver Detection
PY  - 2021
T2  - IEEE Region 10 Annual International Conference, Proceedings/TENCON
VL  - 2021-December
SP  - 417
EP  - 422
DO  - 10.1109/TENCON54134.2021.9707341
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85125967028&doi=10.1109%2fTENCON54134.2021.9707341&partnerID=40&md5=c4e95818800551ae6fb56e3610b1fbdd
AD  - Faculty of Engineering University of Malaya, Department of Electrical Engineering, Kuala Lumpur, 50603, Malaysia
AB  - Driver distraction is the main factor of severe traffic accidents and has become an essential issue in the traffic safety field. Hence, driver inattention systems are crucial in ensuring the safety of road users. With the introduction of Vision Transformer for computer vision tasks, there is a lack of comprehensive evaluation of various models for distracted driver detection. Hence, we raise the question - does vision transformers outperform convolutional neural networks (CNNs) in the field of detecting driving distraction? In this work, we evaluate and perform in-depth evaluations of various state-of-the-art CNN and Vision Transformer models to detect the distracted driver. We believe this will aid future researchers in this field in benchmarking their novel models with state-of-the-art models. We select ResNet, VGGNet, DenseNet, and EfficientNet as the candidates for CNN, while ViT, Swin Transformer, DeiT, and CaiT for Vision Transformer. We perform our benchmark on the American University of Cairo Distracted Driving Dataset (AUC-DDD) which consists of ten distracted classes. It is observed that CNN should be considered first if the downstream task is specific and the available dataset is small. An in-depth discussion and analysis are included in this work.  © 2021 IEEE.
KW  - Computer vision
KW  - Convolution
KW  - Convolutional neural networks
KW  - Intelligent systems
KW  - Machine learning
KW  - Safety factor
KW  - Comprehensive evaluation
KW  - Convolutional neural network
KW  - Depth evaluations
KW  - Driver distractions
KW  - Driving distractions
KW  - Machine learning models
KW  - Road users
KW  - State of the art
KW  - Traffic safety
KW  - Transformer modeling
KW  - Benchmarking
PB  - Institute of Electrical and Electronics Engineers Inc.
SN  - 21593442 (ISSN); 978-166549532-5 (ISBN)
LA  - English
J2  - IEEE Reg 10 Annu Int Conf Proc TENCON
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 5; Conference name: 2021 IEEE Region 10 Conference, TENCON 2021; Conference date: 7 December 2021 through 10 December 2021; Conference code: 177312; CODEN: 85QXA
ER  -

TY  - CONF
AU  - Riedmann, C.
AU  - Schichler, U.
TI  - A physical model for the improvement of dga-based condition assessment of power transformers
PY  - 2020
T2  - Proceeding - 8th International Conference on Condition Monitoring and Diagnosis, CMD 2020
C7  - 9287292
SP  - 106
EP  - 109
DO  - 10.1109/CMD48350.2020.9287292
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85108546134&doi=10.1109%2fCMD48350.2020.9287292&partnerID=40&md5=9388b7efcd6433136cf22627e1b1ddb9
AD  - Graz University of Technology, Institute of High Voltage Engineering and System Performance, Graz, Austria
AB  - At the phase interface in the conservator tank of power transformers, gas losses into the gas phase can occur. Among other approaches, film theory offers a method to quantify such gas losses. The model based on film theory is described in this paper and an analogy to Ohm's law of electrical engineering is shown. In addition, measurements are presented, which prove that the determination of the necessary parameters for the model is adequate but requires further development of the methods. An example of degassing at a phase interface in a transformer model was established and analysed.  © 2020 IEEE.
KW  - Degassing
KW  - Dga
KW  - Diffusion
KW  - Dissolved gas analysis
KW  - Film theory
KW  - Mass transfer
KW  - Monitoring
KW  - Transformers
KW  - Condition monitoring
KW  - Power transformers
KW  - Condition assessments
KW  - Film theory
KW  - Gas loss
KW  - Gasphase
KW  - Model-based OPC
KW  - Ohm's law
KW  - Physical model
KW  - Transformer modeling
KW  - Phase interfaces
PB  - Institute of Electrical and Electronics Engineers Inc.
SN  - 978-172815931-7 (ISBN)
LA  - English
J2  - Proceeding - Int. Conf. Cond. Monit. Diagn., CMD
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 2; Conference name: 8th International Conference on Condition Monitoring and Diagnosis, CMD 2020; Conference date: 25 October 2020 through 28 October 2020; Conference code: 165867
ER  -

TY  - CONF
AU  - Liu, P.
TI  - QiaoNing at SemEval-2020 Task 4: Commonsense Validation and Explanation system based on ensemble of language model
PY  - 2020
T2  - 14th International Workshops on Semantic Evaluation, SemEval 2020 - co-located 28th International Conference on Computational Linguistics, COLING 2020, Proceedings
SP  - 415
EP  - 421
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85123928561&partnerID=40&md5=7ee1d892b8b90e1c4b98dedfc0b91d2b
AD  - Northeastern University, Shenyang, China
AB  - In this paper, we present language model system submitted to SemEval-2020 Task 4 competition:”Commonsense Validation and Explanation”. We participate in two subtasks for subtask A: validation and subtask B: Explanation. We implemented with transfer learning using pretrained language models (BERT, XLNet, RoBERTa, and ALBERT) and fine-tune them on this task. Then we compared their characteristics in this task to help future researchers understand and use these models more properly. The ensembled model better solves this problem, making the model's accuracy reached 95.9% on subtask A, which just worse than human's by only 3% accuracy. © 2020 14th International Workshops on Semantic Evaluation, SemEval 2020 - co-located 28th International Conference on Computational Linguistics, COLING 2020, Proceedings. All rights reserved.
KW  - Computational linguistics
KW  - Explanation systems
KW  - Language model
KW  - Modeling accuracy
KW  - Modelling systems
KW  - Subtask
KW  - Transfer learning
KW  - Semantics
A2  - Herbelot A.
A2  - Zhu X.
A2  - Palmer A.
A2  - Schneider N.
A2  - May J.
A2  - Shutova E.
PB  - International Committee for Computational Linguistics
SN  - 978-195214831-6 (ISBN)
LA  - English
J2  - Int. Workshops Semant. Eval., SemEval - co-located Int. Conf. Comput. Linguist., COLING , Proc.
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 0; Correspondence Address: P. Liu; Northeastern University, Shenyang, China; email: pai.liu.1998@gmail.com; Conference name: 14th International Workshops on Semantic Evaluation, SemEval 2020; Conference date: 12 December 2020 through 13 December 2020; Conference code: 174265
ER  -

TY  - CONF
AU  - Farha, I.A.
AU  - Magdy, W.
TI  - Benchmarking Transformer-based Language Models for Arabic Sentiment and Sarcasm Detection
PY  - 2021
T2  - WANLP 2021 - 6th Arabic Natural Language Processing Workshop, Proceedings of the Workshop
SP  - 21
EP  - 31
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85134393142&partnerID=40&md5=fdac0e628c13a70d83f4469476ea53a4
AD  - School of Informatics, University of Edinburgh, Edinburgh, United Kingdom
AD  - Alan Turing Institute, London, United Kingdom
AB  - The introduction of transformer-based language models has been a revolutionary step for natural language processing (NLP) research. These models, such as BERT, GPT and ELECTRA, led to state-of-the-art performance in many NLP tasks. Most of these models were initially developed for English and other languages followed later. Recently, several Arabic-specific models started emerging. However, there are limited direct comparisons between these models. In this paper, we evaluate the performance of 24 of these models on Arabic sentiment and sarcasm detection. Our results show that the models achieving the best performance are those that are trained on only Arabic data, including dialectal Arabic, and use a larger number of parameters, such as the recently released MARBERT. However, we noticed that AraELECTRA is one of the top performing models while being much more efficient in its computational cost. Finally, the experiments on AraGPT2 variants showed low performance compared to BERT models, which indicates that it might not be suitable for classification tasks. © WANLP 2021 - 6th Arabic Natural Language Processing Workshop
KW  - Natural language processing systems
KW  - Classification tasks
KW  - Computational costs
KW  - Dialectal arabics
KW  - Language model
KW  - Language processing
KW  - Natural languages
KW  - State-of-the-art performance
KW  - Computational linguistics
A2  - Habash N.
A2  - Bouamor H.
A2  - Hajj H.
A2  - Magdy W.
A2  - Zaghouani W.
A2  - Bougares F.
A2  - Tomeh N.
A2  - Farha I.A.
A2  - Touileb S.
PB  - Association for Computational Linguistics (ACL)
SN  - 978-195408509-1 (ISBN)
LA  - English
J2  - WANLP - Arabic Nat. Lang. Process. Workshop, Proc. Workshop
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 45; Conference name: 6th Arabic Natural Language Processing Workshop, WANLP 2021; Conference code: 182533
ER  -

TY  - CONF
AU  - Ács, J.
AU  - Lévai, D.
AU  - Kornai, A.
TI  - Evaluating Transferability of BERT Models on Uralic Languages
PY  - 2021
T2  - IWCLUL 2021 - 7th International Workshop on Computational Linguistics of Uralic Languages, Proceedings
SP  - 27
EP  - 36
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85127464741&partnerID=40&md5=022f98eb4740baf735b5ffc6e7101e2f
AD  - SZTAKI Institute for Computer Science and Control, Hungary
AD  - Department of Digital Humanities, Eötvös Loránd University, Hungary
AB  - Transformer-based language models such as BERT have outperformed previous models on a large number of English benchmarks, but their evaluation is often limited to English or a small number of well-resourced languages. In this work, we evaluate monolingual, multilingual, and randomly initialized language models from the BERT family on a variety of Uralic languages including Estonian, Finnish, Hungarian, Erzya, Moksha, Karelian, Livvi, Komi Permyak, Komi Zyrian, Northern Sámi, and Skolt Sámi. When monolingual models are available (currently only et, fi, hu), these perform better on their native language, but in general they transfer worse than multilingual models or models of genetically unrelated languages that share the same character set. Remarkably, straightforward transfer of high-resource models, even without special efforts toward hyperparameter optimization, yields what appear to be state of the art POS and NER tools for the minority Uralic languages where there is sufficient data for finetuning. © 2021 IWCLUL 2021 - 7th International Workshop on Computational Linguistics of Uralic Languages, Proceedings. All rights reserved.
KW  - Character sets
KW  - Petroleum reservoir evaluation
KW  - Finnish
KW  - Hungarians
KW  - Hyper-parameter optimizations
KW  - Language model
KW  - Native language
KW  - Resource modelling
KW  - State of the art
KW  - Computational linguistics
PB  - Association for Computational Linguistics (ACL)
SN  - 978-195408582-4 (ISBN)
LA  - English
J2  - IWCLUL - Int. Workshop Comput. Linguist. Uralic Lang., Proc.
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 3; Conference name: 7th International Workshop on Computational Linguistics of Uralic Languages, IWCLUL 2021; Conference date: 23 September 2021 through 24 September 2021; Conference code: 177533
ER  -

TY  - CONF
AU  - He, J.
AU  - Peng, B.
AU  - Liao, Y.
AU  - Liu, Q.
AU  - Xiong, D.
TI  - TGEA: An error-annotated dataset and benchmark tasks for text generation from pretrained language models
PY  - 2021
T2  - ACL-IJCNLP 2021 - 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing, Proceedings of the Conference
SP  - 6012
EP  - 6025
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85118946993&partnerID=40&md5=63ace8d23fde80852900d60dc6679879
AD  - College of Intelligence and Computing, Tianjin University, Tianjin, China
AD  - Huawei Noah's Ark Lab, Hong Kong
AB  - In order to deeply understand the capability of pretrained language models in text generation and conduct a diagnostic evaluation, we propose TGEA, an error-annotated dataset with multiple benchmark tasks for text generation from pretrained language models (PLMs). We use carefully selected prompt words to guide GPT-2 to generate candidate sentences, from which we select 47K for error annotation. Crowdsourced workers manually check each of these sentences and detect 12k erroneous sentences. We create an error taxonomy to cover 24 types of errors occurring in these erroneous sentences according to the nature of errors with respect to linguistics and knowledge (e.g., common sense). For each erroneous span in PLM-generated sentences, we also detect another span that is closely associated with it. Each error is hence manually labeled with comprehensive annotations, including the span of the error, the associated span, minimal correction to the error, the type of the error, and rationale behind the error. Apart from the fully annotated dataset, we also present a detailed description of the data collection procedure, statistics and analysis of the dataset. This is the first dataset with comprehensive annotations for PLM-generated texts, which facilitates the diagnostic evaluation of PLM-based text generation. Furthermore, we use TGEA as a benchmark dataset and propose a series of automatic diagnosis tasks, including error detection, error type classification, associated span detection, error rationale generation, to further promote future study on the automatic error detection and correction on texts generated by pretrained language models. © 2021 Association for Computational Linguistics
KW  - Classification (of information)
KW  - Computational linguistics
KW  - Computer aided diagnosis
KW  - Annotated datasets
KW  - Common sense
KW  - Data collection
KW  - Detection error
KW  - Error taxonomy
KW  - Language model
KW  - Model-based OPC
KW  - Statistics and analysis
KW  - Text generations
KW  - Workers'
KW  - Error detection
PB  - Association for Computational Linguistics (ACL)
SN  - 978-195408552-7 (ISBN)
LA  - English
J2  - ACL-IJCNLP - Annu. Meet. Assoc. Comput. Linguist. Int. Jt. Conf. Nat. Lang. Process., Proc. Conf.
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 5; Correspondence Address: D. Xiong; College of Intelligence and Computing, Tianjin University, Tianjin, China; email: dyxiong@tju.edu.cn; Conference name: Joint Conference of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing, ACL-IJCNLP 2021; Conference date: 1 August 2021 through 6 August 2021; Conference code: 173030
ER  -

TY  - CONF
AU  - Pérez-Mayos, L.
AU  - García, A.T.
AU  - Mille, S.
AU  - Wanner, L.
TI  - Assessing the Syntactic Capabilities of Transformer-based Multilingual Language Models
PY  - 2021
T2  - Findings of the Association for Computational Linguistics: ACL-IJCNLP 2021
SP  - 3799
EP  - 3812
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85123960405&partnerID=40&md5=be014753b96bf18e3b0f772f5a2c3afb
AD  - TALN Research Group, Pompeu Fabra University, Barcelona, Spain
AD  - Catalan Institute for Research and Advanced Studies (ICREA), Barcelona, Spain
AB  - Multilingual Transformer-based language models, usually pretrained on more than 100 languages, have been shown to achieve outstanding results in a wide range of cross-lingual transfer tasks. However, it remains unknown whether the optimization for different languages conditions the capacity of the models to generalize over syntactic structures, and how languages with syntactic phenomena of different complexity are affected. In this work, we explore the syntactic generalization capabilities of the monolingual and multilingual versions of BERT and RoBERTa. More specifically, we evaluate the syntactic generalization potential of the models on English and Spanish tests, comparing the syntactic abilities of monolingual and multilingual models on the same language (English), and of multilingual models on two different languages (English and Spanish). For English, we use the available SyntaxGym test suite; for Spanish, we introduce SyntaxGymES, a novel ensemble of targeted syntactic tests in Spanish, designed to evaluate the syntactic generalization capabilities of language models through the SyntaxGym online platform. © 2021 Association for Computational Linguistics
KW  - Computational linguistics
KW  - Condition
KW  - Cross-lingual
KW  - Generalisation
KW  - Generalization capability
KW  - Language model
KW  - Multilingual version
KW  - Online platforms
KW  - Optimisations
KW  - Syntactic structure
KW  - Syntactics
A2  - Zong C.
A2  - Xia F.
A2  - Li W.
A2  - Navigli R.
PB  - Association for Computational Linguistics (ACL)
SN  - 978-195408554-1 (ISBN)
LA  - English
J2  - Find. Assoc. Comput. Linguist.: ACL-IJCNLP
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 3; Conference name: Findings of the Association for Computational Linguistics: ACL-IJCNLP 2021; Conference date: 1 August 2021 through 6 August 2021; Conference code: 174271
ER  -

TY  - CONF
AU  - Aßenmacher, M.
AU  - Corvonato, A.
AU  - Heumann, C.
TI  - Re-evaluating GermEval17 using German pre-trained language models
PY  - 2021
T2  - CEUR Workshop Proceedings
VL  - 2957
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85116449344&partnerID=40&md5=008bb40151176cd6bac5b7b493922b80
AD  - Department of Statistics, Ludwig-Maximilians-Universität, Munich, Germany
AB  - The lack of a commonly used benchmark data set (collection) such as (Super) GLUE (Wang et al., 2018, 2019) for the evaluation of non-English pre-trained language models is a severe shortcoming of current English-centric NLP-research. It concentrates a large part of the research on English, neglecting the uncertainty when transferring conclusions found for the English language to other languages. We evaluate the performance of German and multilingual BERT models currently available via the huggingface transformers library on four subtasks of Aspect-based Sentiment Analysis (ABSA) from the GermEval17 workshop. We compare them to pre-BERT architectures (Wojatzki et al., 2017; Schmitt et al., 2018; Attia et al., 2018) as well as to an ELMo-based architecture (Biesialska et al., 2020) and a BERT-based approach (Guhr et al., 2020). The observed improvements are put in relation to those for a similar ABSA task (Pontiki et al., 2014) and similar models (pre-BERT vs. BERT-based) for the English language and we check whether the reported improvements correspond to those we observe for German. © 2021 for this paper by its authors.
KW  - Computational linguistics
KW  - 'current
KW  - Benchmark data
KW  - Data set
KW  - English languages
KW  - Language model
KW  - Large parts
KW  - Performance
KW  - Sentiment analysis
KW  - Subtask
KW  - Uncertainty
KW  - Sentiment analysis
A2  - Benites F.
A2  - Tuggener D.
A2  - Hurlimann M.
A2  - Cieliebak M.
A2  - Vogel M.
PB  - CEUR-WS
SN  - 16130073 (ISSN)
LA  - English
J2  - CEUR Workshop Proc.
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 0; Conference name: 2021 Swiss Text Analytics Conference, SwissText 2021; Conference date: 14 June 2021 through 16 June 2021; Conference code: 171953
ER  -

TY  - JOUR
AU  - Suzuki, T.
AU  - Miura, N.
AU  - Hojo, R.
AU  - Yanagiba, Y.
AU  - Suda, M.
AU  - Hasegawa, T.
AU  - Miyagawa, M.
AU  - Wang, R.-S.
TI  - Genotoxicity assessment of titanium dioxide nanoparticle accumulation of 90 days in the liver of gpt delta transgenic mice
PY  - 2020
T2  - Genes and Environment
VL  - 42
IS  - 1
C7  - 7
DO  - 10.1186/s41021-020-0146-3
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85079291635&doi=10.1186%2fs41021-020-0146-3&partnerID=40&md5=33061fa6176d5b951552695573a73414
AD  - Division of Industrial Toxicology and Health Effects Research, National Institute of Occupational Safety and Health, 6-21-1 Nagao, Tama-ku, Kawasaki, Kanagawa, 214-8585, Japan
AD  - Graduate School of Biomedical and Health Sciences, Hiroshima University, Hiroshima, 734-8553, Japan
AD  - Department of Health Science, Yokohama University of Pharmacy, Yokohama, 245-0066, Japan
AD  - Division of Human Environmental Science, Mount Fuji Research Institute, Yamanashi Prefectural Government, 5597-1 Kenmarubi, Kamiyoshida, Fujiyoshida, Yamanashi, 403-0005, Japan
AD  - Department of Sport and Medical Science, Faculty of Medical Technology, Teikyo University, Tokyo, Hachioji, 192-0835, Japan
AB  - Backgound: A variety of in vivo and in vitro studies to assess the genotoxicity of titanium dioxide nanoparticles (TiO2 NPs) have been reported, but the results are inconsistent. Recently, we reported that TiO2 NPs exhibit no genotoxic effects in the liver and erythrocytes during a relatively brief period following intravenous injection into mice. However, there is no information about long-term genotoxicity due to TiO2 NP accumulation in tissues. In this study, we investigated the long-term mutagenic effects of TiO2 NPs and the localization of residual TiO2 NPs in mouse liver after multiple intravenous injections. Results: Male gpt delta C57BL/6 J mice were administered with various doses of TiO2 NPs weekly for 4 consecutive weeks. The long-term mutagenic effects on the liver were analyzed using gpt and Spi- mutation assays 90 days after the final injection. We also quantified the amount of titanium in the liver using inductively coupled plasma mass spectrometry and observed the localization of TiO2 NPs in the liver using transmission electron microscopy. Although TiO2 NPs were found in the liver cells, the gpt and Spi- mutation frequencies in the liver were not significantly increased by the TiO2 NP administration. Conclusions: These results clearly show that TiO2 NPs have no mutagenic effects on the liver, even though the particles remain in the liver long-term. © 2020 The Author(s).
KW  - gpt delta mice
KW  - Mutation frequency
KW  - Nanoparticles
KW  - Titanium dioxide
KW  - titanium dioxide nanoparticle
KW  - animal cell
KW  - animal experiment
KW  - Article
KW  - controlled study
KW  - erythrocyte
KW  - genotoxicity
KW  - inductively coupled plasma mass spectrometry
KW  - liver
KW  - liver cell
KW  - male
KW  - mouse
KW  - mutagenic activity
KW  - mutagenicity
KW  - mutation rate
KW  - nonhuman
KW  - transmission electron microscopy
KW  - ultrastructure
PB  - BioMed Central
SN  - 18807046 (ISSN)
LA  - English
J2  - Genes Environ.
M3  - Article
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 9; Correspondence Address: R.-S. Wang; Division of Industrial Toxicology and Health Effects Research, National Institute of Occupational Safety and Health, Kawasaki, Kanagawa, 6-21-1 Nagao, Tama-ku, 214-8585, Japan; email: wang@h.jniosh.johas.go.jp
ER  -

TY  - CONF
AU  - Yingyu, C.
AU  - Yubo, Z.
AU  - Youyuan, W.
AU  - Jian, F.
TI  - State evaluation model of distribution transformer considering environmental factors and operation data
PY  - 2020
T2  - 2020 IEEE Electrical Insulation Conference, EIC 2020
C7  - 9158769
SP  - 98
EP  - 102
DO  - 10.1109/EIC47619.2020.9158769
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85092149331&doi=10.1109%2fEIC47619.2020.9158769&partnerID=40&md5=2535da7e5ea1635340a8e91bae37abc4
AD  - School of Electrical Engineering, Chongqing University, Chongqing, China
AD  - Guangzhou Power Supply Bureau Co., Ltd., Guangzhou, China
AB  - In the fault diagnosis of distribution transformer, in order to fully consider the influence of environmental factors and operation data on distribution transformer, a method of fault diagnosis model of distribution transformer considering environmental factors and operation data is established. First of all, according to the fault data of distribution transformer provided by Guangzhou Power Supply Bureau in recent five years, the environmental factors causing the fault of distribution transformer are calculated. The association rule mining algorithm is used to mine the external environmental factors of distribution transformer fault, and find out the external environmental factors that have a high impact on distribution transformer; secondly, according to the operation data of distribution transformer fault, select the important operation data of distribution transformer fault, and calculate the deviation between the data and the standard value, and take the final result as one of the evaluation indicators; then, in the use of Based on the evaluation of internal test data, the external factors and operation data are fully integrated into the model to establish a complete evaluation model. Finally, the health level of a 10kV distribution transformer in Guangzhou is evaluated in real time in one day. The research of this paper can provide reference for the fault diagnosis and operation maintenance of 10kV distribution transformer  © 2020 IEEE.
KW  - Distribution transformer
KW  - Fault diagnosis
KW  - Real time evaluation
KW  - State evaluation
KW  - Data mining
KW  - Electric power systems
KW  - Electric transformers
KW  - Failure analysis
KW  - Fault detection
KW  - Distribution transformer
KW  - Environmental factors
KW  - Evaluation indicators
KW  - Evaluation modeling
KW  - Fault diagnosis model
KW  - Operation maintenance
KW  - Power supply bureaux
KW  - Rule mining algorithms
KW  - Electric transformer testing
PB  - Institute of Electrical and Electronics Engineers Inc.
SN  - 978-172815485-5 (ISBN)
LA  - English
J2  - IEEE Electr. Insul. Conf., EIC
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 2; Conference name: 2020 IEEE Electrical Insulation Conference, EIC 2020; Conference date: 22 June 2020 through 3 July 2020; Conference code: 162491
ER  -

TY  - CONF
AU  - Imperial, J.M.
TI  - BERT Embeddings for Automatic Readability Assessment
PY  - 2021
T2  - International Conference Recent Advances in Natural Language Processing, RANLP
SP  - 611
EP  - 618
DO  - 10.26615/978-954-452-072-4_069
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85123596287&doi=10.26615%2f978-954-452-072-4_069&partnerID=40&md5=92d6e4f7ca9d3201cd60f9ae14d1ce7a
AD  - National University, Manila, Philippines
AB  - Automatic readability assessment (ARA) is the task of evaluating the level of ease or difficulty of text documents for a target audience. For researchers, one of the many open problems in the field is to make such models trained for the task show efficacy even for low-resource languages. In this study, we propose an alternative way of utilizing the information-rich embeddings of BERT models with handcrafted linguistic features through a combined method for readability assessment. Results show that the proposed method outperforms classical approaches in readability assessment using English and Filipino datasets-obtaining as high as 12.4% increase in F1 performance. We also show that the general information encoded in BERT embeddings can be used as a substitute feature set for low-resource languages like Filipino with limited semantic and syntactic NLP tools to explicitly extract feature values for the task. © 2021 Incoma Ltd. All rights reserved.
KW  - Semantics
KW  - Classical approach
KW  - Combined method
KW  - Embeddings
KW  - Features sets
KW  - General information
KW  - Linguistic features
KW  - Low resource languages
KW  - Performance
KW  - Target audience
KW  - Text document
KW  - Embeddings
A2  - Angelova G.
A2  - Kunilovskaya M.
A2  - Mitkov R.
A2  - Nikolova-Koleva I.
PB  - Incoma Ltd
SN  - 13138502 (ISSN); 978-954452072-4 (ISBN)
LA  - English
J2  - Int. Conf. Recent Adv. Nat. Lang. Proces., RANLP
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 10; Correspondence Address: J.M. Imperial; National University, Manila, Philippines; email: jrimperial@national-u.edu.ph; Conference name: International Conference on Recent Advances in Natural Language Processing: Deep Learning for Natural Language Processing Methods and Applications, RANLP 2021; Conference date: 1 September 2021 through 3 September 2021; Conference code: 176177
ER  -

TY  - CONF
AU  - Yanaka, H.
AU  - Mineshima, K.
TI  - Assessing the Generalization Capacity of Pre-trained Language Models through Japanese Adversarial Natural Language Inference
PY  - 2021
T2  - BlackboxNLP 2021 - Proceedings of the 4th BlackboxNLP Workshop on Analyzing and Interpreting Neural Networks for NLP
SP  - 337
EP  - 349
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85127261712&partnerID=40&md5=568011d7c11edeccd34996f02f4fed2e
AD  - The University of Tokyo, Japan
AD  - Keio University, Japan
AB  - Despite the success of multilingual pre-trained language models, it remains unclear to what extent these models have human-like generalization capacity across languages. The aim of this study is to investigate the out-of-distribution generalization of pre-trained language models through Natural Language Inference (NLI) in Japanese, the typological properties of which are different from those of English. We introduce a synthetically generated Japanese NLI dataset, called the Japanese Adversarial NLI (JaNLI) dataset, which is inspired by the English HANS dataset and is designed to require understanding of Japanese linguistic phenomena and illuminate the vulnerabilities of models. Through a series of experiments to evaluate the generalization performance of both Japanese and multilingual BERT models, we demonstrate that there is much room to improve current models trained on Japanese NLI tasks. Furthermore, a comparison of human performance and model performance on the different types of garden-path sentences in the JaNLI dataset shows that structural phenomena that ease interpretation of garden-path sentences for human readers do not help models in the same way, highlighting a difference between human readers and the models. © 2021 Association for Computational Linguistics.
KW  - Garden path
KW  - Generalisation
KW  - Generalization capacity
KW  - Human like
KW  - Human readers
KW  - Language inference
KW  - Language model
KW  - Linguistic phenomena
KW  - Natural languages
KW  - Property
KW  - Computational linguistics
PB  - Association for Computational Linguistics (ACL)
SN  - 978-195591706-3 (ISBN)
LA  - English
J2  - BlackboxNLP - Proc. BlackboxNLP Workshop Anal. Interpret. Neural Networks NLP
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 4; Conference name: 4th BlackboxNLP Workshop on Analyzing and Interpreting Neural Networks for NLP, BlackboxNLP 2021; Conference code: 177526
ER  -

TY  - CONF
AU  - Tutubalina, E.
AU  - Kadurin, A.
AU  - Miftahutdinov, Z.
TI  - Fair Evaluation in Concept Normalization: a Large-scale Comparative Analysis for BERT-based Models
PY  - 2020
T2  - COLING 2020 - 28th International Conference on Computational Linguistics, Proceedings of the Conference
SP  - 6710
EP  - 6716
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85143411978&partnerID=40&md5=39c4d2f361c4d49247615b9e3ad7531f
AD  - Insilico Medicine Hong Kong, Pak Shek Kok, Hong Kong
AD  - Kazan Federal University, Kazan, Russian Federation
AB  - Linking of biomedical entity mentions to various terminologies of chemicals, diseases, genes, adverse drug reactions is a challenging task, often requiring non-syntactic interpretation. A large number of biomedical corpora and state-of-the-art models have been introduced in the past five years. However, there are no general guidelines regarding the evaluation of models on these corpora in single- and cross-terminology settings. In this work, we perform a comparative evaluation of various benchmarks and study the efficiency of state-of-the-art neural architectures based on Bidirectional Encoder Representations from Transformers (BERT) for linking of three entity types across three domains: research abstracts, drug labels, and user-generated texts on drug therapy in English. We have made the source code and results available at https://github.com/insilicomedicine/Fair-Evaluation-BERT. © 2020 COLING 2020 - 28th International Conference on Computational Linguistics, Proceedings of the Conference. All rights reserved.
KW  - Computational linguistics
KW  - Drug therapy
KW  - Adverse drug reactions
KW  - ART model
KW  - Comparative analyzes
KW  - Comparative evaluations
KW  - Disease genes
KW  - Large-scales
KW  - Neural architectures
KW  - Normalisation
KW  - State of the art
KW  - Syntactic interpretation
KW  - Terminology
A2  - Scott D.
A2  - Bel N.
A2  - Zong C.
PB  - Association for Computational Linguistics (ACL)
SN  - 978-195214827-9 (ISBN)
LA  - English
J2  - COLING - Int. Conf. Comput. Linguist., Proc. Conf.
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 21; Conference name: 28th International Conference on Computational Linguistics, COLING 2020; Conference date: 8 December 2020 through 13 December 2020; Conference code: 186886
ER  -

TY  - CONF
AU  - Meister, C.
AU  - Cotterell, R.
TI  - Language model evaluation beyond perplexity
PY  - 2021
T2  - ACL-IJCNLP 2021 - 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing, Proceedings of the Conference
SP  - 5328
EP  - 5339
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85117998651&partnerID=40&md5=8dae615e93922dc04f1908058a0fbd54
AD  - ETH Zürich, Switzerland
AD  - University of Cambridge, United Kingdom
AB  - We propose an alternate approach to quantifying how well language models learn natural language: we ask how well they match the statistical tendencies of natural language. To answer this question, we analyze whether text generated from language models exhibits the statistical tendencies present in the human-generated text on which they were trained. We provide a framework-paired with significance tests-for evaluating the fit of language models to these trends. We find that neural language models appear to learn only a subset of the tendencies considered, but align much more closely with empirical trends than proposed theoretical distributions (when present). Further, the fit to different distributions is highly-dependent on both model architecture and generation strategy. As concrete examples, text generated under the nucleus sampling scheme adheres more closely to the type-token relationship of natural language than text produced using standard ancestral sampling; text from LSTMs reflects the natural language distributions over length, stopwords, and symbols surprisingly well. © 2021 Association for Computational Linguistics
KW  - Alternate approaches
KW  - Different distributions
KW  - Language model
KW  - Learn+
KW  - Model evaluation
KW  - Model generation
KW  - Modeling architecture
KW  - Natural languages
KW  - Sampling schemes
KW  - Significance test
KW  - Computational linguistics
PB  - Association for Computational Linguistics (ACL)
SN  - 978-195408552-7 (ISBN)
LA  - English
J2  - ACL-IJCNLP - Annu. Meet. Assoc. Comput. Linguist. Int. Jt. Conf. Nat. Lang. Process., Proc. Conf.
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 17; Conference name: Joint Conference of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing, ACL-IJCNLP 2021; Conference date: 1 August 2021 through 6 August 2021; Conference code: 173030
ER  -

TY  - JOUR
AU  - Zeinoddini-Meymand, H.
AU  - Kamel, S.
AU  - Khan, B.
TI  - An Efficient Approach with Application of Linear and Nonlinear Models for Evaluation of Power Transformer Health Index
PY  - 2021
T2  - IEEE Access
VL  - 9
SP  - 150172
EP  - 150186
DO  - 10.1109/ACCESS.2021.3124845
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85118680599&doi=10.1109%2fACCESS.2021.3124845&partnerID=40&md5=794a8800ed6177a04376dfd71b517a8a
AD  - Department of Electrical and Computer Engineering, Graduate University of Advanced Technology, Kerman, 76318-85356, Iran
AD  - Department of Electrical Engineering, Faculty of Engineering, Aswan University, Aswan, 81542, Egypt
AD  - Department of Electrical and Computer Engineering, Hawassa University, Hawassa, 05, Ethiopia
AB  - In this paper, efficient and accurate linear and nonlinear models are proposed for indicating comprehensive health requirements of the transformer using health index (HI) concept. The models are established with 336 experimental datasets including oil characteristics and dissolved gas analysis (DGA) of various types of transformers placed in different areas. The significance of DGA parameters in transformer health condition is considered with the inclusive DGA factor (DGAF) parameter, which considers the weighting importance of seven dissolved gases. Nonlinear models used in this paper are artificial neural network (ANN) and adaptive neuro-fuzzy inference system (ANFIS), which represent the behavior of transformer insulation parameters. The nonlinear models are compared with multiple linear regression (MLR) which is a linear statistical model. The models are established with 80 percent of the experimental dataset. The other 20 percent of data are utilized for the efficiency assessment of the models. The results demonstrate that the models provide an assessment of the health condition of the transformers comparable to existing models with high accuracy. The contributions of this paper are: 1) Evaluating the overall HI of the transformer employing a complete set of 15 input parameters of transformer oil-paper insulation system. 2) Adding DGAF, %WaterPaper, IFT parameters and showing the importance of these parameters. 3) Regarding the condition of solid insulation of the transformer particularly. 4) Applying a diverse and large practical dataset composed of 336 different transformers located in different country areas. 5) Using the MLR method for three purposes. 6) Providing linear (MLR) and nonlinear (ANN, ANFIS) models for HI calculation of the dataset, simultaneously. 7) Verifying the applicability and efficiency of the ANFIS model for simulating HI value.  © 2013 IEEE.
KW  - ANFIS
KW  - ANN
KW  - condition assessment
KW  - health index
KW  - lifetime management
KW  - MLR
KW  - oil-paper insulation system
KW  - power transformer
KW  - Efficiency
KW  - Fuzzy inference
KW  - Fuzzy neural networks
KW  - Fuzzy systems
KW  - Health
KW  - Insulation
KW  - Linear regression
KW  - Nonlinear systems
KW  - Oil filled transformers
KW  - Support vector machines
KW  - Adaptive neuro-fuzzy inference
KW  - Adaptive neuro-fuzzy inference system
KW  - Condition assessments
KW  - Health indices
KW  - Index
KW  - Lifetime management
KW  - Neuro-fuzzy inference systems
KW  - Oil
KW  - Oil insulations
KW  - Oil-paper insulation system
KW  - Power transformer insulation
KW  - Support vectors machine
KW  - Power transformers
PB  - Institute of Electrical and Electronics Engineers Inc.
SN  - 21693536 (ISSN)
LA  - English
J2  - IEEE Access
M3  - Article
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 8; Correspondence Address: H. Zeinoddini-Meymand; Department of Electrical and Computer Engineering, Graduate University of Advanced Technology, Kerman, 76318-85356, Iran; email: h.zeinoddini@kgut.ac.ir
ER  -

TY  - CONF
AU  - Simin, L.
AU  - Shuo, X.
AU  - Le, L.
AU  - Qianwen, G.
AU  - Yiping, C.
AU  - Tian, L.
TI  - Risk assessment model of 10kV distribution line special transformer trip based on improved TOPSIS algorithm
PY  - 2021
T2  - Proceedings - 2021 International Conference on Intelligent Computing, Automation and Systems, ICICAS 2021
SP  - 335
EP  - 338
DO  - 10.1109/ICICAS53977.2021.00076
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85127302353&doi=10.1109%2fICICAS53977.2021.00076&partnerID=40&md5=9aab63a2a14bd416e59e7c00b924929b
AD  - Guangzhou Power Supply Bureau of Guangdong Power Grid Corporation, Guangzhou, China
AB  - As the final link of the power system, the distribution network can distribute electric energy to power users through distribution equipment. Therefore, it is urgent to evaluate the trip risk of feeder transformer users. Based on the improved TOPSIS algorithm, this paper proposes a user trip risk assessment method for special substations of 10kV distribution lines. First, six risk assessment indicators are extracted from the two dimensions of the environment and the transformer body, the quantitative indicators and the association rules of the user tripping of special transformers, and the feeders are used as the evaluation unit to fill in the indicators to form an evaluation sample. Secondly, combining the entropy method and the analytic hierarchy process to comprehensively weight the indicators, and use the weighted Mahalanobis distance to replace the traditional Euclidean distance to improve the TOPSIS algorithm, and build a 10kV distribution line dedicated substation user trip risk assessment model. Based on the above model, the sample risk assessment coefficient is calculated, and the risk level is divided according to the data distribution characteristics, and the sample risk assessment is completed. Finally, the user data of a 10kV distribution line dedicated to a certain urban power grid in southern China was used to verify the effectiveness of the risk assessment method.  © 2021 IEEE.
KW  - analytic hierarchy process
KW  - dedicated variable user trip risk
KW  - entropy method
KW  - Improved TOPSIS algorithm
KW  - Electric power distribution
KW  - Electric power transmission networks
KW  - Risk assessment
KW  - 10kv distribution lines
KW  - Dedicated variable user trip risk
KW  - Electric energies
KW  - Entropy methods
KW  - Improved TOPSIS algorithm
KW  - Power
KW  - Power users
KW  - Risk assessment - modelling
KW  - Risk assessment methods
KW  - Risks assessments
KW  - Analytic hierarchy process
A2  - Pu Z.
A2  - Bai Y.
A2  - Cabrera D.
PB  - Institute of Electrical and Electronics Engineers Inc.
SN  - 978-166542810-1 (ISBN)
LA  - English
J2  - Proc. - Int. Conf. Intell. Comput., Autom. Syst., ICICAS
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 3; Correspondence Address: L. Simin; Guangzhou Power Supply Bureau of Guangdong Power Grid Corporation, Guangzhou, China; email: 81157183@qq.com; Conference name: 2021 International Conference on Intelligent Computing, Automation and Systems, ICICAS 2021; Conference date: 29 December 2021 through 31 December 2021; Conference code: 177603
ER  -

TY  - CONF
AU  - Jumelet, J.
AU  - Denic, M.
AU  - Szymanik, J.
AU  - Hupkes, D.
AU  - Steinert-Threlkeld, S.
TI  - Language Models Use Monotonicity to Assess NPI Licensing
PY  - 2021
T2  - Findings of the Association for Computational Linguistics: ACL-IJCNLP 2021
SP  - 4958
EP  - 4969
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85117033075&partnerID=40&md5=824172ecfad46e8388c33d61ed262678
AD  - Institute for Logic, Language and Computation, University of Amsterdam, Netherlands
AD  - Facebook AI Research, United States
AD  - Department of Linguistics, University of Washington, United States
AB  - We investigate the semantic knowledge of language models (LMs), focusing on (1) whether these LMs create categories of linguistic environments based on their semantic monotonicity properties, and (2) whether these categories play a similar role in LMs as in human language understanding, using negative polarity item licensing as a case study. We introduce a series of experiments consisting of probing with diagnostic classifiers (DCs), linguistic acceptability tasks, as well as a novel DC ranking method that tightly connects the probing results to the inner workings of the LM. By applying our experimental pipeline to LMs trained on various filtered corpora, we are able to gain stronger insights into the semantic generalizations that are acquired by these models. © 2021 Association for Computational Linguistics
KW  - Computational linguistics
KW  - Case-studies
KW  - Human language
KW  - Language model
KW  - Language understanding
KW  - Linguistic environment
KW  - Model use
KW  - Monotonicity
KW  - Monotonicity property
KW  - Negative polarity items
KW  - Semantics knowledge
KW  - Semantics
A2  - Zong C.
A2  - Xia F.
A2  - Li W.
A2  - Navigli R.
PB  - Association for Computational Linguistics (ACL)
SN  - 978-195408554-1 (ISBN)
LA  - English
J2  - Find. Assoc. Comput. Linguist.: ACL-IJCNLP
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 11; Conference name: Findings of the Association for Computational Linguistics: ACL-IJCNLP 2021; Conference date: 1 August 2021 through 6 August 2021; Conference code: 174271
ER  -

TY  - CONF
AU  - Moradi, M.
AU  - Samwald, M.
TI  - Evaluating the Robustness of Neural Language Models to Input Perturbations
PY  - 2021
T2  - EMNLP 2021 - 2021 Conference on Empirical Methods in Natural Language Processing, Proceedings
SP  - 1558
EP  - 1570
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85122605997&partnerID=40&md5=92cb7068cc77284fd41c861fc4fb9f12
AD  - Institute for Artificial Intelligence, Medical University of Vienna, Austria
AB  - High-performance neural language models have obtained state-of-the-art results on a wide range of Natural Language Processing (NLP) tasks. However, results for common benchmark datasets often do not reflect model reliability and robustness when applied to noisy, real-world data. In this study, we design and implement various types of character-level and word-level perturbation methods to simulate realistic scenarios in which input texts may be slightly noisy or different from the data distribution on which NLP systems were trained. Conducting comprehensive experiments on different NLP tasks, we investigate the ability of high-performance language models such as BERT, XLNet, RoBERTa, and ELMo in handling different types of input perturbations. The results suggest that language models are sensitive to input perturbations and their performance can decrease even when small changes are introduced. We highlight that models need to be further improved and that current benchmarks are not reflecting model robustness well. We argue that evaluations on perturbed inputs should routinely complement widely-used benchmarks in order to yield a more realistic understanding of NLP systems' robustness. © 2021 Association for Computational Linguistics
KW  - Computational linguistics
KW  - Perturbation techniques
KW  - Benchmark datasets
KW  - Design and implements
KW  - Input perturbation
KW  - Language model
KW  - Model reliability
KW  - Model robustness
KW  - Performance
KW  - Real-world
KW  - Reliability and robustness
KW  - State of the art
KW  - Natural language processing systems
PB  - Association for Computational Linguistics (ACL)
SN  - 978-195591709-4 (ISBN)
LA  - English
J2  - EMNLP - Conf. Empir. Methods Nat. Lang. Process., Proc.
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 15; Conference name: 2021 Conference on Empirical Methods in Natural Language Processing, EMNLP 2021; Conference date: 7 November 2021 through 11 November 2021; Conference code: 177530
ER  -

TY  - JOUR
AU  - Liu, Q.
AU  - Zhang, X.
AU  - Cai, J.
TI  - Aging State Evaluation of Oil-paper Insulation Transformer Based on Multivariate Fuzzy Relation Degree Model
ST  - 基于多元模糊联系度模型的变压器油纸绝缘老化评价
PY  - 2020
T2  - Gaoya Dianqi/High Voltage Apparatus
VL  - 56
IS  - 5
SP  - 47
EP  - 54and61
DO  - 10.13296/j.1001-1609.hva.2020.05.008
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85085642623&doi=10.13296%2fj.1001-1609.hva.2020.05.008&partnerID=40&md5=aa218463114f7823a230055982ae93b8
AD  - College of Electrical Engineering and Automation, Fuzhou University, Fuzhou, 350108, China
AB  - In view of the uncertainties existing in the transformer oil-paper insulation evaluation index and the ambiguity of the evaluation criteria, a combination of set-pair analysis and fuzzy set combination method is proposed to apply the multivariate fuzzy connection degree model to the evaluation of transformer oil-paper insulation status. Firstly, three new features of insulation aging quantities are extracted based on the analysis of depolarization current spectrum, and combined the transformer’s measured data for statistical analysis to establish the nine aging evaluation indexes system for transformers, and determine the three levels of evaluation criteria based on fuzzy C-means clustering(FCM)algorithm. Then, the same-and-backward analysis is used to construct the connection degree expressions of each evaluation index and the evaluation grade standard, a combination weighting method with subjective weight and objective weight is also introduced and the data mining method is used for difference degree information to determine the combination contact degree. Finally, according to the level of the maximum combination degree of connection as a set pair analysis results, the example results verify that the multivariate fuzzy connection degree model can effectively and accurately evaluate the transformer oil-paper insulation state and has promotion and application value. © 2020, Xi'an High Voltage Apparatus Research Institute Co., Ltd. All right reserved.
KW  - Combination weight
KW  - Fuzzy C-means clustering
KW  - Fuzzy connection degree
KW  - insulation state
KW  - Oil-paper
KW  - Set pair analysis
PB  - Xi'an High Voltage Apparatus Research Institute
SN  - 10011609 (ISSN)
LA  - Chinese
J2  - Gaoya Dianqi
M3  - Article
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 6; CODEN: GADIE
ER  -

TY  - CONF
AU  - Afonso, J.I.
AU  - Toscano, P.
AU  - Briozzo, I.
TI  - Current Transformer model validation on EMTP-ATP software
PY  - 2020
T2  - 2020 IEEE PES Transmission and Distribution Conference and Exhibition - Latin America, T and D LA 2020
C7  - 9326157
DO  - 10.1109/TDLA47668.2020.9326157
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85100851361&doi=10.1109%2fTDLA47668.2020.9326157&partnerID=40&md5=ad9e9e3a1269e76738d8fcd30524f2f6
AD  - Universidad de la República, Department of Electrical Engineering, School of Engineering, Montevideo, Uruguay
AB  - The present work is the continuation of a revision previously made by the authors about the different ways of modeling a current transformer (CT) and the importance of the parameters involved. This paper presents the description of several models elaborated for electromagnetic transient studies and the tests and simulations carried out for their validation. Special focus is made on the modeling of the magnetizing branch which proves to be a critical parameter in the performance of the CT model. © 2020 IEEE.
KW  - ATP-EMTP
KW  - Current Transformer
KW  - Electromagnetic Transients
KW  - Modeling
KW  - Protection Systems
KW  - Saturation
KW  - Electric instrument transformers
KW  - Transmissions
KW  - Electromagnetic transient studies
KW  - Emtp-atp
KW  - Magnetizing branches
KW  - Transformer modeling
KW  - Electric currents
PB  - Institute of Electrical and Electronics Engineers Inc.
SN  - 978-172814155-8 (ISBN)
LA  - English
J2  - IEEE PES Transm. Distrib. Conf. Exhib. - Lat. America, T D LA
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 2; Conference name: 2020 IEEE PES Transmission and Distribution Conference and Exhibition - Latin America, T and D LA 2020; Conference date: 28 September 2020 through 2 October 2020; Conference code: 166716
ER  -

TY  - JOUR
AU  - Kuczmann, M.
AU  - Szöcs, A.
AU  - Kovács, G.
TI  - Transformer model identification by artap: A benchmark problem
PY  - 2021
T2  - Periodica polytechnica Electrical engineering and computer science
VL  - 65
IS  - 2
SP  - 123
EP  - 130
DO  - 10.3311/PPee.17606
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85105846338&doi=10.3311%2fPPee.17606&partnerID=40&md5=981437b9b15ba4df714e2025cf636e70
AD  - Department of Automation, Faculty of Mechanical Engineering, Széchenyi István University, H9026-Gyor, 1, Egyetem tér, Hungary
AB  - The paper presents how Artap can be used for determining the equivalent circuit parameters of a one phase transformer as a benchmark problem. The following unknown parameters of the equivalent circuit are identified: primary resistance and primary leakage reactance, secondary resistance and secondary leakage reactance, finally magnetizing resistance, and magnetizing reactance. The known quantities from measurement are the primary voltage, primary current, power factor, secondary voltage, and the load resistance. Algorithms implemented in Artap are used for determining the transformer parameters and the results are compared with the analytical solution. © 2021 Budapest University of Technology and Economics. All rights reserved.
KW  - Artap
KW  - parameter identification
KW  - transformer equivalent circuit model
KW  - transformer measurement
KW  - Benchmarking
KW  - Bench-mark problems
KW  - Equivalent circuit parameter
KW  - Leakage reactance
KW  - Magnetizing reactance
KW  - Phase transformers
KW  - Secondary voltage
KW  - Transformer modeling
KW  - Transformer parameters
KW  - Equivalent circuits
PB  - Budapest University of Technology and Economics
SN  - 20645260 (ISSN)
LA  - English
J2  - Period. polytech., Electr. eng. comput. sci.
M3  - Article
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 3; Correspondence Address: M. Kuczmann; Department of Automation, Faculty of Mechanical Engineering, Széchenyi István University, Egyetem tér, H9026-Gyor, 1, Hungary; email: kuczmann@maxwell.sze.hu
ER  -

TY  - CONF
AU  - Puccinelli, D.
AU  - Demartini, S.
AU  - Ferrari, P.L.
TI  - Tackling Italian university assessment tests with transformer-based language models
PY  - 2021
T2  - CEUR Workshop Proceedings
VL  - 3033
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85121252857&partnerID=40&md5=a2db4583d0e78f8a681aabedc3962089
AD  - University of Applied Sciences and Arts of Southern Switzerland, Switzerland
AD  - University of Eastern Piedmont, Italy
AB  - Cloze tests are a great tool to asses reading proficiency as well as analytical thinking, and are therefore employed in admission and assessment tests at various levels of the education system in multiple countries. In Italy, cloze tests are administered to incoming university students to ascertain their starting level. The goal of a cloze test is to determine several tokens that have been pre-deleted from a text; this is largely equivalent to the well-known NLP task of missing token prediction. In this paper, we show that cloze tests can be solved reasonably well with various Transformer-based pre-trained language models, whose performance often compares favorably to the one of incoming Italian university students. © 2021 for this paper by its author. Use permitted under Creative Commons License Attribution 4.0 International (CC BY 4.0).
KW  - Education computing
KW  - Electric transformer testing
KW  - Analytical thinking
KW  - Education systems
KW  - Language model
KW  - Performance
KW  - Reading proficiency
KW  - University assessments
KW  - University students
KW  - Computational linguistics
A2  - Fersini E.
A2  - Passarotti M.
A2  - Patti V.
PB  - CEUR-WS
SN  - 16130073 (ISSN)
LA  - English
J2  - CEUR Workshop Proc.
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 0; Conference name: 8th Italian Conference on Computational Linguistics, CLiC-it 2021; Conference date: 26 January 2022 through 28 January 2022; Conference code: 175403
ER  -

TY  - CONF
AU  - Šuppa, M.
AU  - Jariabka, O.
TI  - Benchmarking pre-trained language models for multilingual NER: TraSpaS at the BSNLP2021 shared task
PY  - 2021
T2  - Proceedings of the 8th BSNLP Workshop on Balto-Slavic Natural Language Processing, BSNLP 2021 - Co-located with the 16th European Chapter of the Association for Computational Linguistics, EACL 2021
SP  - 105
EP  - 114
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85119600657&partnerID=40&md5=561c1eb4d7786a10c7b41b0a2b24a1b8
AD  - Comenius University, Bratislava, Slovakia
AB  - In this paper we describe TraSpaS, a submission to the third shared task on named entity recognition hosted as part of the Balto-Slavic Natural Language Processing (BSNLP) Workshop. In it we evaluate various pre-trained language models on the NER task using three open-source NLP toolkits: character level language model with Stanza, language-specific BERT-style models with SpaCy and Adapter-enabled XLM-R with Trankit. Our results show that the Trankit-based models outperformed those based on the other two toolkits, even when trained on smaller amounts of data. Our code is available at https://github.com/NaiveNeuron/slavner-2021. © 2021 Association for Computational Linguistics.
KW  - Computational linguistics
KW  - Character level
KW  - Language model
KW  - Named entity recognition
KW  - Open-source
KW  - Natural language processing systems
A2  - Babych B.
A2  - Kanishcheva O.
A2  - Nakov P.
A2  - Piskorski J.
A2  - Pivovarova L.
A2  - Starko V.
A2  - Steinberger J.
A2  - Yangarber R.
A2  - Marcinczuk M.
A2  - Pollak S.
A2  - Priban P.
A2  - Robnik-Sikonja M.
PB  - Association for Computational Linguistics (ACL)
SN  - 978-195408514-5 (ISBN)
LA  - English
J2  - Proc. BSNLP Workshop Balto-Slavic Nat. Lang. Process., BSNLP - Co-located Eur. Chapter Assoc. Comput. Linguist., EACL
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 4; Correspondence Address: M. Šuppa; Comenius University, Bratislava, Slovakia; email: marek@suppa.sk; O. Jariabka; Comenius University, Bratislava, Slovakia; email: o.jariabka@gmail.com; Conference name: 8th Workshop on Balto-Slavic Natural Language Processing, BSNLP 2021; Conference code: 172926
ER  -

TY  - CONF
AU  - Mendbayar, K.
AU  - Aono, M.
TI  - KDE SenseForce at SemEval-2020 Task 4: Exploiting BERT for Commonsense Validation and Explanation
PY  - 2020
T2  - 14th International Workshops on Semantic Evaluation, SemEval 2020 - co-located 28th International Conference on Computational Linguistics, COLING 2020, Proceedings
SP  - 551
EP  - 555
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85123936639&partnerID=40&md5=834f9efdeb4fd469880afc0d89aed683
AD  - Department of Computer Science, Toyohashi University of Technology, Aichi, Toyohashi, Japan
AB  - Using a natural language understanding system for commonsense comprehension is getting increasing attention from researchers. Current multi-purpose state-of-the-art models suffer on commonsense validation and explanation tasks. We have adopted one of the state-of-the-art models and proposing a method to boost the performance of the model in commonsense related tasks. © 2020 14th International Workshops on Semantic Evaluation, SemEval 2020 - co-located 28th International Conference on Computational Linguistics, COLING 2020, Proceedings. All rights reserved.
KW  - Computational linguistics
KW  - 'current
KW  - ART model
KW  - Multi-purpose
KW  - Natural language understanding
KW  - Performance
KW  - State of the art
KW  - Semantics
A2  - Herbelot A.
A2  - Zhu X.
A2  - Palmer A.
A2  - Schneider N.
A2  - May J.
A2  - Shutova E.
PB  - International Committee for Computational Linguistics
SN  - 978-195214831-6 (ISBN)
LA  - English
J2  - Int. Workshops Semant. Eval., SemEval - co-located Int. Conf. Comput. Linguist., COLING , Proc.
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 0; Conference name: 14th International Workshops on Semantic Evaluation, SemEval 2020; Conference date: 12 December 2020 through 13 December 2020; Conference code: 174265
ER  -

TY  - CONF
AU  - Sharma, M.
AU  - Jain, M.
AU  - Garg, M.
AU  - Tripathi, M.M.
TI  - Evaluation of transformer model performance on a set of language pairs by varying standard parameters
PY  - 2021
T2  - Proceedings of International Conference on Innovative Practices in Technology and Management, ICIPTM 2021
C7  - 9388359
SP  - 194
EP  - 199
DO  - 10.1109/ICIPTM52218.2021.9388359
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85104401943&doi=10.1109%2fICIPTM52218.2021.9388359&partnerID=40&md5=28640181a278aec1f027d7f2807446ca
AD  - Delhi Technological University, Department of Electrical Engineering, Delhi, India
AB  - In this paper, we have performed machine translation using modified Transformer model on TED Talk Dataset and from this we have selected four language pairs (English-Portuguese, Russian-English, French-Portuguese, Turkish-English) for testing. We have evaluated and analyzed the machine translation model on critical criteria's such as dataset size, batch size and training time over all four language pairs and have used BLEU scoring to generalize the results. We have searched for general trends and have analyzed the impacts of these variations on the scoring of the translation upon variation of different parameters, this analysis has been performed on each language pairs as well as have been compared with the results of other language pairs. From the results we found that with increase in dataset size, batch size and training time the BLEU score increases. The English - Portuguese pair achieves highest BLEU score of 23.2 from all language pairs and we get lowest BLEU score of 19.1 from the French - Portuguese pair. © 2021 IEEE.
KW  - BLEU score
KW  - Neural Machine Translation
KW  - TED talk Dataset
KW  - Transformer Model
KW  - Computational linguistics
KW  - Computer aided language translation
KW  - Statistical tests
KW  - Batch sizes
KW  - Data set size
KW  - General trends
KW  - Language pairs
KW  - Machine translation models
KW  - Machine translations
KW  - Training time
KW  - Transformer modeling
KW  - Electric transformer testing
PB  - Institute of Electrical and Electronics Engineers Inc.
SN  - 978-073813289-1 (ISBN)
LA  - English
J2  - Proc. Int. Conf. Innov. Pract. Technol. Manag., ICIPTM
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 0; Conference name: 2021 International Conference on Innovative Practices in Technology and Management, ICIPTM 2021; Conference date: 17 February 2021 through 19 February 2021; Conference code: 168293
ER  -

TY  - CONF
AU  - Cheong, S.F.
AU  - Chieu, H.L.
AU  - Lim, J.
TI  - Intrinsic evaluation of language models for code-switching
PY  - 2021
T2  - W-NUT 2021 - 7th Workshop on Noisy User-Generated Text, Proceedings of the Conference
SP  - 81
EP  - 86
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85138804255&partnerID=40&md5=6495a697b960ea5ce0d022b1ed8ad41a
AD  - NUS High School of Mathematics and Science, 20 Clementi Avenue 1, Singapore, 129957, Singapore
AD  - DSO National Laboratories, 12 Science Park Drive, Singapore, 118225, Singapore
AB  - Language models used in speech recognition are often either evaluated intrinsically using perplexity on test data, or extrinsically with an automatic speech recognition (ASR) system. The former evaluation does not always correlate well with ASR performance, while the latter could be specific to particular ASR systems. Recent work proposed to evaluate language models by using them to classify ground truth sentences among alternative phonetically similar sentences generated by a fine state transducer. Underlying such an evaluation is the assumption that the generated sentences are linguistically incorrect. In this paper, we first put this assumption into question, and observe that alternatively generated sentences could often be linguistically correct when they differ from the ground truth by only one edit. Secondly, we showed that by using multi-lingual BERT, we can achieve better performance than previous work on two code-switching data sets. Our implementation is publicly available on Github. © 2021 Association for Computational Linguistics.
KW  - Codes (symbols)
KW  - Computational linguistics
KW  - Automatic speech recognition
KW  - Automatic speech recognition system
KW  - Code-switching
KW  - Data set
KW  - Ground truth
KW  - Language model
KW  - Performance
KW  - Speech recognition performance
KW  - Test data
KW  - Speech recognition
A2  - Xu W.
A2  - Ritter A.
A2  - Baldwin T.
A2  - Rahimi A.
PB  - Association for Computational Linguistics (ACL)
SN  - 978-195408590-9 (ISBN)
LA  - English
J2  - W-NUT - Workshop Noisy User-Gener. Text, Proc. Conf.
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 1; Conference name: 7th Workshop on Noisy User-Generated Text, W-NUT 2021; Conference code: 182532
ER  -

TY  - CONF
AU  - Wahle, J.P.
AU  - Ruas, T.
AU  - Meuschke, N.
AU  - Gipp, B.
TI  - Are Neural Language Models Good Plagiarists? A Benchmark for Neural Paraphrase Detection
PY  - 2021
T2  - Proceedings of the ACM/IEEE Joint Conference on Digital Libraries
VL  - 2021-September
SP  - 226
EP  - 229
DO  - 10.1109/JCDL52503.2021.00065
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85123436562&doi=10.1109%2fJCDL52503.2021.00065&partnerID=40&md5=ba037dd427dd9dff73f0a07794bbd48c
AD  - University of Wuppertal, Wuppertal, Germany
AB  - Neural language models such as BERT allow for human-like text paraphrasing. This ability threatens academic integrity, as it aggravates identifying machine-obfuscated plagiarism. We make two contributions to foster the research on detecting these novel machine-paraphrases. First, we provide the first large-scale dataset of documents paraphrased using the Transformer-based models BERT, RoBERTa, and Longformer. The dataset includes paragraphs from scientific papers on arXiv, theses, and Wikipedia articles and their paraphrased counterparts (1.5M paragraphs in total). We show the paraphrased text maintains the semantics of the original source. Second, we benchmark how well neural classification models can distinguish the original and paraphrased text. The dataset and source code of our study are publicly available. © 2021 IEEE.
KW  - BERT
KW  - Paraphrase detection
KW  - transformers
KW  - Computational linguistics
KW  - Large dataset
KW  - Text processing
KW  - Academic integrity
KW  - BERT
KW  - Human like
KW  - Language model
KW  - Large-scale datasets
KW  - Neural classification
KW  - Paraphrase detection
KW  - Scientific papers
KW  - Transformer
KW  - Wikipedia articles
KW  - Semantics
A2  - Downie J.S.
A2  - McKay D.
A2  - Suleman H.
A2  - Nichols D.M.
A2  - Poursardar F.
PB  - Institute of Electrical and Electronics Engineers Inc.
SN  - 15525996 (ISSN); 978-166541770-9 (ISBN)
LA  - English
J2  - Proc. ACM IEEE Joint Conf. Digit. Libr.
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 16; Conference name: 21st ACM/IEEE Joint Conference on Digital Libraries, JCDL 2021; Conference date: 27 September 2021 through 30 September 2021; Conference code: 175953
ER  -

TY  - CONF
AU  - Chen, G.
AU  - Liu, X.
AU  - Xu, M.
AU  - Lu, Z.
AU  - Guo, J.
TI  - Reliability Probability Evaluation Method of Electronic transformer based on Xgboost model
PY  - 2020
T2  - Asia-Pacific Power and Energy Engineering Conference, APPEEC
VL  - 2020-September
C7  - 9220552
DO  - 10.1109/APPEEC48164.2020.9220552
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85094313905&doi=10.1109%2fAPPEEC48164.2020.9220552&partnerID=40&md5=a3f960b78286859c7608ac8fcaebc5b1
AD  - Elec. Ener. Msrmt. Lab. of State Grid Corp. of China State Grid Jiangsu Electric Power Co. Ltd., Marketing Service Center, China
AD  - Southeast University, College of Electrical Engineering, Nanjing, China
AB  - The development of electronic transformers is becoming faster with the development of intelligent substation technology. Although it has better improvement in stability, safety and other performance than traditional transformers, there are still some difficulties in the aspects of measurement situation monitoring, status and error evaluation. In order for electronic transformers to be better put into engineering use, their operational reliability must be well evaluated. In this paper, Xgboost is used to model the operation error of the electronic transformer, and the result of the model is processed to obtain the operational reliability probability of the electronic transformer. First, the collected data is clustered by the DBSCAN density clustering algorithm. Then the reliability probability is calculated for each cluster, and then the reliability probability is used as a label, and the collected data is used as an input to establish an Xgboost model. The trained model can make a probabilistic assessment of the operational reliability of an electronic transformer without the measurement results of traditional electronic transformers as standard.  © 2020 IEEE.
KW  - DBSCAN
KW  - electronic transformers
KW  - operational reliability
KW  - probabilistic assessment
KW  - Xgboost
KW  - Clustering algorithms
KW  - Electric transformers
KW  - Probability
KW  - Reliability
KW  - Density clustering
KW  - Electronic transformer
KW  - Error evaluation
KW  - Operation errors
KW  - Operational reliability
KW  - Probabilistic assessments
KW  - Reliability probability
KW  - Electronic assessment
PB  - IEEE Computer Society
SN  - 21574839 (ISSN); 978-172815748-1 (ISBN)
LA  - English
J2  - Asia-Pacific Pow. Energy Eng. Conf., APPEEC
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 1; Conference name: 12th IEEE PES Asia-Pacific Power and Energy Engineering Conference, APPEEC 2020; Conference date: 20 September 2020 through 23 September 2020; Conference code: 164025
ER  -

TY  - CONF
AU  - Zhou, Y.
AU  - Li, M.
TI  - Online Course Quality Evaluation Based on BERT
PY  - 2020
T2  - Proceedings - 2020 International Conference on Communications, Information System and Computer Engineering, CISCE 2020
C7  - 9258801
SP  - 255
EP  - 258
DO  - 10.1109/CISCE50729.2020.00057
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85097931496&doi=10.1109%2fCISCE50729.2020.00057&partnerID=40&md5=796e2e5ed084308d12c00a0582919303
AD  - Guilin University of Electronic Technology, Guangxi Key Laboratory, Guilin, China
AB  - In order to evaluate the quality of online courses, this paper proposes a framework based on online course feature extraction and sentiment analysis, and applies this framework to the online courses of MOOC. Extract the <feature word, opinion word> word pair of the review data through the word frequency syntactic dependency, and merge the word pair into the sentiment classification of the BERT model to realize the fine-grained feature analysis of the online course review data, so as to obtain online courses in each Use this aspect to evaluate the quality of the course. Experiments conducted on MOOC online course reviews show that the BERT model incorporating binary features has improved accuracy, recall, and F1 values compared to traditional machine learning methods. © 2020 IEEE.
KW  - BERT
KW  - course quality assessment
KW  - feature word extraction
KW  - online course reviews
KW  - sentiment analysis
KW  - Data communication systems
KW  - Information systems
KW  - Information use
KW  - Learning systems
KW  - Quality control
KW  - Sentiment analysis
KW  - Binary features
KW  - Feature analysis
KW  - Feature words
KW  - Machine learning methods
KW  - Online course
KW  - Sentiment classification
KW  - Syntactic dependencies
KW  - Word frequencies
KW  - E-learning
PB  - Institute of Electrical and Electronics Engineers Inc.
SN  - 978-172819761-6 (ISBN)
LA  - English
J2  - Proc. - Int. Conf. Commun., Inf. Syst. Comput. Eng., CISCE
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 2; Correspondence Address: M. Li; Guilin University of Electronic Technology, Guangxi Key Laboratory, Guilin, China; email: 1050779162@qq.com; Conference name: 2020 International Conference on Communications, Information System and Computer Engineering, CISCE 2020; Conference date: 3 July 2020 through 5 July 2020; Conference code: 165125
ER  -

TY  - JOUR
AU  - El Hage, F.S.
AU  - Vieira, F.P.B.
AU  - Carareto, R.
TI  - Deriving and validating an electrodynamic model of a voltage transformer from scratch
PY  - 2021
T2  - European Journal of Physics
VL  - 42
IS  - 3
C7  - 035207
DO  - 10.1088/1361-6404/abed9f
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85104927348&doi=10.1088%2f1361-6404%2fabed9f&partnerID=40&md5=64e5aa80d569964db54508b8cfb38ef5
AD  - Engineering Department, Insper, Sao Paulo, Brazil
AB  - Comprehending the in-depth functioning of a voltage transformer beyond the trivial voltage ratio, generally deducted from the application of Faraday's law to an open secondary circuit, can be quite challenging for both students and teachers. In this paper, the authors propose an approach that uses Faraday's and Ohm's laws alone to derive an electric equivalent circuit for a transformer, with which is possible to accurately explain and predict currents and voltages in its primary and secondary coils under different load resistors connected to the secondary. The authors intend to use a common real-world application as motivation for students to learn Faraday's law in the context of a modelling and simulation framework, which consists of deriving a model from fundamental physical laws that, after experimental validation, is capable of accurately predicting and explaining a complex phenomenon. © 2021 European Physical Society.
KW  - equivalent circuit
KW  - Faraday s law
KW  - modelling and simulation
KW  - transformer
KW  - Power transformers
KW  - Timing circuits
KW  - Electrodynamic models
KW  - Faraday Law
KW  - Faraday s law
KW  - Model and simulation
KW  - Ohm's law
KW  - Secondary circuit
KW  - Teachers'
KW  - Transformer
KW  - Voltage ratios
KW  - Voltage transformer
KW  - Equivalent circuits
PB  - Institute of Physics
SN  - 01430807 (ISSN)
LA  - English
J2  - Eur. J. Phys.
M3  - Article
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 4; Correspondence Address: F.S. El Hage; Engineering Department, Insper, Sao Paulo, Brazil; email: fhage@insper.edu.br; CODEN: EJPHD
ER  -

TY  - CONF
AU  - Xu, C.
AU  - Zhou, W.
AU  - Ge, T.
AU  - Xu, K.
AU  - McAuley, J.
AU  - Wei, F.
TI  - Beyond Preserved Accuracy: Evaluating Loyalty and Robustness of BERT Compression
PY  - 2021
T2  - EMNLP 2021 - 2021 Conference on Empirical Methods in Natural Language Processing, Proceedings
SP  - 10653
EP  - 10659
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85117988954&partnerID=40&md5=57ad7c961d3ef01c6807568be9a2767e
AD  - University of California, San Diego, United States
AD  - Stanford University, United States
AD  - Microsoft Research Asia
AD  - Beihang University, China
AB  - Recent studies on compression of pretrained language models (e.g., BERT) usually use preserved accuracy as the metric for evaluation. In this paper, we propose two new metrics, label loyalty and probability loyalty that measure how closely a compressed model (i.e., student) mimics the original model (i.e., teacher). We also explore the effect of compression with regard to robustness under adversarial attacks. We benchmark quantization, pruning, knowledge distillation and progressive module replacing with loyalty and robustness. By combining multiple compression techniques, we provide a practical strategy to achieve better accuracy, loyalty and robustness. © 2021 Association for Computational Linguistics
KW  - Computational linguistics
KW  - Compression techniques
KW  - Language model
KW  - Original model
KW  - Quantisation
KW  - Teachers'
KW  - Distillation
PB  - Association for Computational Linguistics (ACL)
SN  - 978-195591709-4 (ISBN)
LA  - English
J2  - EMNLP - Conf. Empir. Methods Nat. Lang. Process., Proc.
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 20; Conference name: 2021 Conference on Empirical Methods in Natural Language Processing, EMNLP 2021; Conference date: 7 November 2021 through 11 November 2021; Conference code: 177530
ER  -

TY  - CONF
AU  - Hande, A.
AU  - Puranik, K.
AU  - Priyadharshini, R.
AU  - Thavareesan, S.
AU  - Chakravarthi, B.R.
TI  - Evaluating Pretrained Transformer-based Models for COVID-19 Fake News Detection
PY  - 2021
T2  - Proceedings - 5th International Conference on Computing Methodologies and Communication, ICCMC 2021
C7  - 9418446
SP  - 766
EP  - 772
DO  - 10.1109/ICCMC51019.2021.9418446
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85105978729&doi=10.1109%2fICCMC51019.2021.9418446&partnerID=40&md5=0442bb49eca796b3819a5010f8de12bf
AD  - Indian Institute of Information Technology Tiruchirappalli
AD  - Ultra Arts and Science College, Madurai, India
AD  - Eastern University, Sri Lanka
AD  - National University of Ireland Galway
AB  - The expeditious growth of technology with social media as a platform for communication has led to a proliferous increase in the spread of misinformation and fake news. The ongoing COVID-19 widespread has pushed us to review posts on various social media platforms to stop people from being subjected to false and perilous posts. Detecting fake news in social media has been the need of an hour. The proposed research work has approached it with various Transformer and recurrent models with several contextual word embedding models. Furthermore, the effectiveness of the proposed model is evaluated by using a different loss function instead of the conventional loss function, Binary cross Entropy. The fake news detection is considered as a sequence classification task, one of the downstream tasks of natural language processing. It has been observed that using domain-specific language models along with custom loss function has achieved the highest weighted average F1-score. © 2021 IEEE.
KW  - COVID-19
KW  - Sequence Classification
KW  - Transfer Learning
KW  - Problem oriented languages
KW  - Social networking (online)
KW  - Contextual words
KW  - Domain specific languages
KW  - Loss functions
KW  - NAtural language processing
KW  - Recurrent models
KW  - Sequence classification
KW  - Social media platforms
KW  - Weighted averages
KW  - Natural language processing systems
PB  - Institute of Electrical and Electronics Engineers Inc.
SN  - 978-166540360-3 (ISBN)
LA  - English
J2  - Proc. - Int. Conf. Comput. Methodol. Commun., ICCMC
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 21; Conference name: 5th International Conference on Computing Methodologies and Communication, ICCMC 2021; Conference date: 8 April 2021 through 10 April 2021; Conference code: 168766
ER  -

TY  - CONF
AU  - Hua, L.
AU  - Di, Z.
TI  - A general evaluation method of university curriculum summative text based on optimized BERT model
PY  - 2020
T2  - Proceedings - 2020 International Conference on Information Science and Education, ICISE-IE 2020
C7  - 9418821
SP  - 64
EP  - 69
DO  - 10.1109/ICISE51755.2020.00021
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85105994955&doi=10.1109%2fICISE51755.2020.00021&partnerID=40&md5=a33adb9f8a5d44a8d453adf38e0f7246
AD  - Chongqing University of Technology, Chongqing, China
AB  - At present, many curriculum evaluations in universities are based on students' summative texts of courses. However, because the evaluation methods are based on Teachers' subjective judgment and time-consuming, they are unstable and inefficient. In order to solve this problem, this paper proposes a text classification model based on optimized BERT (bidirectional encoder representations from transformers) for summative text evaluation of university courses. In this model, the deep dynamic representation of word vector is extracted by using the BERT pre-trained language model, and then the summative text analysis is carried out by using the Mean-Max-pooling method. Finally, the text classification is completed by using the sigmoid function and threshold fine-tuned. The experimental result shows that the AUC (Area Under Curve) of this model is 12.5% higher than that of the RNN(Recurrent Neural Network) and CNN(Convolutional Neural Network) model, and the model is effective.  © 2020 IEEE.
KW  - BERT model
KW  - neural network
KW  - summative text
KW  - text classification
KW  - Classification (of information)
KW  - Convolutional neural networks
KW  - Curricula
KW  - Education computing
KW  - Text processing
KW  - Curriculum evaluation
KW  - Dynamic representation
KW  - Evaluation methods
KW  - Sigmoid function
KW  - Text classification
KW  - Text classification models
KW  - University course
KW  - University curricula
KW  - Recurrent neural networks
PB  - Institute of Electrical and Electronics Engineers Inc.
SN  - 978-166542261-1 (ISBN)
LA  - English
J2  - Proc. - Int. Conf. Inf. Sci. Educ., ICISE-IE
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 0; Correspondence Address: Z. Di; Chongqing University of Technology, Chongqing, China; email: zhangdi@2019.cqut.edu.cn; Conference name: 2020 International Conference on Information Science and Education, ICISE-IE 2020; Conference date: 4 December 2020 through 6 December 2020; Conference code: 168767
ER  -

TY  - JOUR
AU  - Xia, Y.
AU  - Liu, D.
AU  - Zhang, J.
AU  - Li, K.
TI  - BERT-based automated risk of bias assessment
ST  - 基于 BERT 的自动化偏倚风险评价方法的研究
PY  - 2021
T2  - Chinese Journal of Evidence-Based Medicine
VL  - 21
IS  - 2
SP  - 204
EP  - 209
DO  - 10.7507/1672-2531.202006177
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85115748891&doi=10.7507%2f1672-2531.202006177&partnerID=40&md5=70664f7fc2fe2568f4e79ac627648d52
AD  - School of Life Science and Technology, University of Electronic Science and Technology of China, Chengdu, 610051, China
AB  - Objective To realize automatic risk bias assessment for the randomized controlled trial (RCT) literature using BERT (Bidirectional Encoder Representations from Transformers) as an approach for feature representation and text classification. Methods We first searched The Cochrane Library to obtain risk bias assessment data and detailed information on RCTs, and constructed data sets for text classification. We assigned 80% of the data set as the training set, 10% as the test set, and 10% as the validation set. Then, we used BERT to extract features, construct text classification model, and evaluate the seven types of risk bias values (high and low). The results were compared with those from traditional machine learning methods using a combination of n-gram and TF-IDF as well as the Linear SVM classifier. The accuracy rate (P value), recall rate (R value) and F1 value were used to evaluate the performance of the models. Results Our BERT-based model achieved F1 values of 78.5% to 95.2% for the seven types of risk bias assessment tasks, which was 14.7% higher than the traditional machine learning method. F1 values of 85.7% to 92.8% were obtained in the extraction task of the other six types of biased descriptors except "other sources of bias", which was 18.2% higher than the traditional machine learning method. Conclusions The BERT-based automatic risk bias assessment model can realize higher accuracy in risk of bias assessment for RCT literature, and improve the efficiency of assessment. © 2021 West China University of Medical Science. All rights reserved.
KW  - Automated
KW  - BERT
KW  - Evidence-based medicine
KW  - Risk bias assessment
KW  - Systematic review
KW  - article
KW  - classifier
KW  - Cochrane Library
KW  - evidence based medicine
KW  - extraction
KW  - human
KW  - linear support vector machine
KW  - randomized controlled trial (topic)
KW  - recall
KW  - risk assessment
KW  - systematic review
PB  - West China University of Medical Science
SN  - 16722531 (ISSN)
LA  - Chinese
J2  - Chin. J. Evid.-Based Med.
M3  - Article
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 0; Correspondence Address: K. Li; School of Life Science and Technology, University of Electronic Science and Technology of China, Chengdu, 610051, China; email: colinlike@163.com
ER  -

TY  - CONF
AU  - Cao, K.
AU  - Rimell, L.
TI  - You should evaluate your language model on marginal likelihood over tokenisations
PY  - 2021
T2  - EMNLP 2021 - 2021 Conference on Empirical Methods in Natural Language Processing, Proceedings
SP  - 2104
EP  - 2114
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85121736104&partnerID=40&md5=c0aab27a46fb3664dba2452f496ab777
AD  - DeepMind, London, United Kingdom
AB  - Neural language models typically tokenise input text into sub-word units to achieve an open vocabulary. The standard approach is to use a single canonical tokenisation at both train and test time. We suggest that this approach is unsatisfactory and may bottleneck our evaluation of language model performance. Using only the one-best tokenisation ignores tokeniser uncertainty over alternative tokenisations, which may hurt model out-of-domain performance. In this paper, we argue that instead, language models should be evaluated on their marginal likelihood over tokenisations. We compare different estimators for the marginal likelihood based on sampling, and show that it is feasible to estimate the marginal likelihood with a manageable number of samples. We then evaluate pretrained English and German language models on both the one-best-tokenisation and marginal perplexities, and show that the marginal perplexity can be significantly better than the one best, especially on out-of-domain data. We link this difference in perplexity to the tokeniser uncertainty as measured by tokeniser entropy. We discuss some implications of our results for language model training and evaluation, particularly with regard to tokenisation robustness. © 2021 Association for Computational Linguistics
KW  - English languages
KW  - Language model
KW  - Marginal likelihood
KW  - Modeling performance
KW  - Number of samples
KW  - Performance
KW  - Subword units
KW  - Test time
KW  - Tokenization
KW  - Uncertainty
KW  - Computational linguistics
PB  - Association for Computational Linguistics (ACL)
SN  - 978-195591709-4 (ISBN)
LA  - English
J2  - EMNLP - Conf. Empir. Methods Nat. Lang. Process., Proc.
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 4; Conference name: 2021 Conference on Empirical Methods in Natural Language Processing, EMNLP 2021; Conference date: 7 November 2021 through 11 November 2021; Conference code: 177530
ER  -

TY  - CONF
AU  - Shih, C.-F.
AU  - Tseng, Y.-H.
AU  - Yang, C.-W.
AU  - Chen, P.-E.
AU  - Chou, H.-Y.
AU  - Tan, L.-H.
AU  - Lin, T.-J.
AU  - Wang, C.-W.
AU  - Hsieh, S.-K.
TI  - What confuses BERT? Linguistic Evaluation of Sentiment Analysis on Telecom Customer Opinion
PY  - 2021
T2  - ROCLING 2021 - Proceedings of the 33rd Conference on Computational Linguistics and Speech Processing
SP  - 271
EP  - 279
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85127390169&partnerID=40&md5=a58a7bde22cb4d5a678b8320b7ab835d
AD  - National Taiwan University, Taiwan
AD  - Chunghwa Telecom Laboratories, Taiwan
AB  - Ever-expanding evaluative texts on online forums have become an important source of sentiment analysis. This paper proposes an aspect-based annotated dataset consisting of Chinese telecom reviews on social media. We introduce a data category called implicit evaluative texts, impevals for short, to investigate how the deep learning model works on these implicit reviews. We first compare two models, BertSimple and BertImpvl, and find that while both models are competent to learn simple evaluative texts, they are confused when classifying impevals. To investigate the factors underlying the correctness of the model's predictions, we conduct a series of analyses, including qualitative error analysis and quantitative analysis of linguistic features with logistic regressions. The results show that local features that affect the overall sentential sentiment confuse the model: multiple target entities, transitional words, sarcasm, and rhetorical questions. Crucially, these linguistic features are independent of the model's confidence measured by the classifier's softmax probabilities. Interestingly, the sentence complexity indicated by syntax-tree depth is not correlated with the model's correctness. In sum, this paper sheds light on the characteristics of the modern deep learning model and when it might need more supervision through linguistic evaluations. © 2021 ROCLING 2021 - Proceedings of the 33rd Conference on Computational Linguistics and Speech Processing. All rights reserved.
KW  - Deep Learning
KW  - Implicit Evaluative Text
KW  - Linguistic Evaluation
KW  - Sentiment Analysis
KW  - Deep learning
KW  - Regression analysis
KW  - Social networking (online)
KW  - Trees (mathematics)
KW  - Annotated datasets
KW  - Deep learning
KW  - Implicit evaluative text
KW  - Learning models
KW  - Linguistic evaluation
KW  - Linguistic features
KW  - Online forums
KW  - Sentiment analysis
KW  - Telecom
KW  - Telecom customers
KW  - Sentiment analysis
A2  - Lee L.-H.
A2  - Chang C.-H.
A2  - Chen K.-Y.
PB  - The Association for Computational Linguistics and Chinese Language Processing (ACLCLP)
SN  - 978-986957694-9 (ISBN)
LA  - English
J2  - ROCLING - Proc. Conf. Comput. Linguist. Speech Process.
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 0; Conference name: 33rd Conference on Computational Linguistics and Speech Processing, ROCLING 2021; Conference date: 15 October 2021 through 16 October 2021; Conference code: 177553
ER  -

TY  - CONF
AU  - Wang, Y.
AU  - Hu, J.
AU  - Levy, R.
AU  - Qian, P.
TI  - Controlled Evaluation of Grammatical Knowledge in Mandarin Chinese Language Models
PY  - 2021
T2  - EMNLP 2021 - 2021 Conference on Empirical Methods in Natural Language Processing, Proceedings
SP  - 5604
EP  - 5620
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85122605361&partnerID=40&md5=58dba87eb338601377408a8ccddf212e
AD  - John A. Paulson School of Engineering and Applied Sciences, Harvard University, United States
AD  - Department of Brain and Cognitive Sciences, MIT
AB  - Prior work has shown that structural supervision helps English language models learn generalizations about syntactic phenomena such as subject-verb agreement. However, it remains unclear if such an inductive bias would also improve language models' ability to learn grammatical dependencies in typologically different languages. Here we investigate this question in Mandarin Chinese, which has a logographic, largely syllable-based writing system; different word order; and sparser morphology than English. We train LSTMs, Recurrent Neural Network Grammars, Transformer language models, and Transformer-parameterized generative parsing models on two Mandarin Chinese datasets of different sizes. We evaluate the models' ability to learn different aspects of Mandarin grammar that assess syntactic and semantic relationships. We find suggestive evidence that structural supervision helps with representing syntactic state across intervening content and improves performance in low-data settings, suggesting that the benefits of hierarchical inductive biases in acquiring dependency relationships may extend beyond English. © 2021 Association for Computational Linguistics
KW  - Computational linguistics
KW  - Recurrent neural networks
KW  - Semantics
KW  - Chinese language models
KW  - English languages
KW  - Generalisation
KW  - Inductive bias
KW  - Language model
KW  - Learn+
KW  - Mandarin Chinese
KW  - Modeling abilities
KW  - Word orders
KW  - Writing systems
KW  - Syntactics
PB  - Association for Computational Linguistics (ACL)
SN  - 978-195591709-4 (ISBN)
LA  - English
J2  - EMNLP - Conf. Empir. Methods Nat. Lang. Process., Proc.
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 1; Conference name: 2021 Conference on Empirical Methods in Natural Language Processing, EMNLP 2021; Conference date: 7 November 2021 through 11 November 2021; Conference code: 177530
ER  -

TY  - CONF
AU  - Miaschi, A.
AU  - Ravelli, A.A.
AU  - Dell'Orletta, F.
TI  - Evaluating Transformer Models for Punctuation Restoration in Italian
PY  - 2021
T2  - CEUR Workshop Proceedings
VL  - 3015
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85121647978&partnerID=40&md5=b6d8c2b8c01e4c78f674f020377cc649
AD  - Department of Computer Science, Università di Pisa, Italy
AD  - Istituto di Linguistica Computazionale Antonio Zampolli (ILC-CNR), ItaliaNLP Lab, Italy
AB  - In this paper, we propose an evaluation of a Transformerbased punctuation restoration model for the Italian language. Experimenting with a BERT-base model, we perform several fine-tuning with different training data and sizes and tested them in an in- and crossdomain scenario. Moreover, we offer a comparison in a multilingual setting with the same model fine-tuned on English transcriptions. Finally, we conclude with an error analysis of the main weaknesses of the model related to specific punctuation marks.  Copyright © 2021 Copyright for this paper by its authors.
KW  - Punctuation restoration
KW  - Speech transcription
KW  - Transformers
KW  - Speech transmission
KW  - Base models
KW  - Cross-domain
KW  - Fine tuning
KW  - Punctuation restoration
KW  - Restoration model
KW  - Speech transcriptions
KW  - Training data
KW  - Training size
KW  - Transformer
KW  - Transformer modeling
KW  - Restoration
A2  - Cabrio E.
A2  - Croce D.
A2  - Passaro L.C.
A2  - Sprugnoli R.
PB  - CEUR-WS
SN  - 16130073 (ISSN)
LA  - English
J2  - CEUR Workshop Proc.
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 0; Conference name: 5th Workshop on Natural Language for Artificial Intelligence, NL4AI 2021; Conference code: 174256
ER  -

TY  - CONF
AU  - Mendbayar, K.
AU  - Aono, M.
TI  - Token Level Evaluation and Feature Enhancer for Transformer-based Models
PY  - 2021
T2  - Proceedings - 2021 8th International Conference on Advanced Informatics: Concepts, Theory, and Application, ICAICTA 2021
DO  - 10.1109/ICAICTA53211.2021.9640269
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85123761533&doi=10.1109%2fICAICTA53211.2021.9640269&partnerID=40&md5=e5b30f5f7e551cf6c1064aa1735887d2
AD  - Toyohashi University of Technology, Department of Computer Science, Aichi, Toyohashi, Japan
AB  - Most recent state-of-the-art models in the natural language processing (NLP) field such as BERT, ALBERT and XLNet share a common architecture of including an embedding and Transformer encoder and/or decoder layers (aka. Transformer blocks). Here we propose Token Level Evaluation and Feature Enhancer (TLEFE) to be added on any of the Transformer-based models. The TLEFE is supposed to upscale token features for every token in the sentence passed into the system. Through experiments using datasets provided by SemEval-2020 Commonsense Validation and Explanation, we have demonstrated that TLEFE applied model performs better than plain model with negligible additional number of parameters.  © 2021 IEEE.
KW  - Commonsense
KW  - Natural Language Processing
KW  - Word embedding
KW  - Embeddings
KW  - ART model
KW  - Common architecture
KW  - Commonsense
KW  - Embeddings
KW  - Encoder-decoder
KW  - Recent state
KW  - State of the art
KW  - Word embedding
KW  - Natural language processing systems
PB  - Institute of Electrical and Electronics Engineers Inc.
SN  - 978-166541743-3 (ISBN)
LA  - English
J2  - Proc. - Int. Conf. Adv. Informatics: Concepts, Theory, Appl., ICAICTA
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 0; Conference name: 8th International Conference on Advanced Informatics: Concepts, Theory, and Application, ICAICTA 2021; Conference date: 29 September 2021 through 30 September 2021; Conference code: 175630
ER  -

TY  - CONF
AU  - Liu, S.
AU  - Hu, Y.
AU  - Zhang, Z.
AU  - Li, J.
AU  - Zhao, Y.
AU  - Li, X.
AU  - Xiong, L.
AU  - Zhai, C.
TI  - EVALUATION MODEL OF TRANSFORMER STATE BASED ON IMPROVED FUZZY COMPREHENSIVE DIAGNOSIS THEORY
PY  - 2021
T2  - IET Conference Proceedings
VL  - 2021
IS  - 15
SP  - 648
EP  - 653
DO  - 10.1049/icp.2022.0066
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85174653236&doi=10.1049%2ficp.2022.0066&partnerID=40&md5=47c8ae4b27de2aacc19a7ade0d85b697
AD  - China Nuclear Power Design Co. Ltd (Shenzhen), Shenzhen, China
AD  - State Key Laboratory of Electrical Insulation and Power Equipment, Xi'an Jiaotong University, No. 28 West Xianning Road, Xi'an, China
AB  - The state evaluation of transformer includes analysing many kinds of operating signals, but the relationship between those signals and transformer states is fuzzy. To clearly describe the relationship, a multi-level comprehensive fuzzy mathematics algorithm is used. The algorithm is based on the intelligent fuzzy diagnosis theory. Taking the power transformer as the research object, the factor set and comment set are selected through appropriate methods, and the membership function relationship between them is established. The selected factors come from the electrical test, the amount of gas in the oil, and the insulating oil. And the comment set is the division of the transformer status, which is uniformly divided into four evaluations. Considering the multi-level nature of factors, fuzzy inferences are carried out to determinate the membership function, and a weight set of the factor set is established through an improved analytic hierarchy process (IAHP). In addition, a two-level fuzzy evaluation example for evaluating the state of a transformer in operation is given, which verifies the effectiveness and feasibility of the evaluation model. © 2021 The Institution of Engineering and Technology.
KW  - ANALYTIC HIERARCHY PROCESS
KW  - FUZZY MATHEMATICS
KW  - POWER TRANSFORMER
KW  - STATE ASSESSMENT
KW  - Analytic hierarchy process
KW  - Electric transformer testing
KW  - Function evaluation
KW  - Oil filled transformers
KW  - Power transformers
KW  - Comments sets
KW  - Evaluation models
KW  - Fuzzy mathematics
KW  - Mathematic algorithms
KW  - Memberships function
KW  - Multilevels
KW  - Operating signal
KW  - State assessment
KW  - State based
KW  - State evaluation
KW  - Membership functions
PB  - Institution of Engineering and Technology
SN  - 27324494 (ISSN); 978-183953430-0 (ISBN); 978-183953504-8 (ISBN); 978-183953574-1 (ISBN); 978-183953591-8 (ISBN); 978-183953604-5 (ISBN); 978-183953605-2 (ISBN); 978-183953606-9 (ISBN); 978-183953619-9 (ISBN); 978-183953636-6 (ISBN); 978-183953658-8 (ISBN); 978-183953679-3 (ISBN); 978-183953680-9 (ISBN); 978-183953681-6 (ISBN); 978-183953684-7 (ISBN); 978-183953703-5 (ISBN)
LA  - English
J2  - IET. Conf. Proc.
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 0; Correspondence Address: J. Li; State Key Laboratory of Electrical Insulation and Power Equipment, Xi'an Jiaotong University, Xi'an, No. 28 West Xianning Road, China; email: junhaoli@mail.xjtu.edu.cn; Conference name: 22nd International Symposium on High Voltage Engineering, ISH 2021; Conference date: 21 November 2021 through 26 November 2021; Conference code: 181322
ER  -

TY  - CONF
AU  - Xiang, B.
AU  - Yang, C.
AU  - Li, Y.
AU  - Warstadt, A.
AU  - Kann, K.
TI  - CLiMP: A benchmark for Chinese language model evaluation
PY  - 2021
T2  - EACL 2021 - 16th Conference of the European Chapter of the Association for Computational Linguistics, Proceedings of the Conference
SP  - 2784
EP  - 2790
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85101479375&partnerID=40&md5=5f733cd6d66f579ccd3b7766ce78e337
AD  - University of Colorado Boulder, United States
AD  - New York University, United States
AB  - Linguistically informed analyses of language models (LMs) contribute to the understanding and improvement of these models. Here, we introduce the corpus of Chinese linguistic minimal pairs (CLiMP), which can be used to investigate what knowledge Chinese LMs acquire. CLiMP consists of sets of 1,000 minimal pairs (MPs) for 16 syntactic contrasts in Mandarin, covering 9 major Mandarin linguistic phenomena. The MPs are semi-automatically generated, and human agreement with the labels in CLiMP is 95.8%. We evaluate 11 different LMs on CLiMP, covering n-grams, LSTMs, and Chinese BERT. We find that classifier-noun agreement and verb complement selection are the phenomena that models generally perform best at. However, models struggle the most with the bǎ construction, binding, and filler-gap dependencies. Overall, Chinese BERT achieves an 81.8% average accuracy, while the performances of LSTMs and 5-grams are only moderately above chance level. © 2021 Association for Computational Linguistics
KW  - Automatically generated
KW  - Chinese language modeling
KW  - Chinese linguistics
KW  - Language model
KW  - Linguistic phenomena
KW  - N-grams
KW  - Computational linguistics
PB  - Association for Computational Linguistics (ACL)
SN  - 978-195408502-2 (ISBN)
LA  - English
J2  - EACL - Conf. Eur. Chapter Assoc. Comput. Linguist., Proc. Conf.
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 12; Conference name: 16th Conference of the European Chapter of the Associationfor Computational Linguistics, EACL 2021; Conference date: 19 April 2021 through 23 April 2021; Conference code: 169023
ER  -

TY  - CONF
AU  - Kittask, C.
AU  - Milintsevich, K.
AU  - Sirts, K.
TI  - Evaluating multilingual BERT for estonian
PY  - 2020
T2  - Frontiers in Artificial Intelligence and Applications
VL  - 328
SP  - 19
EP  - 26
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85093360718&partnerID=40&md5=e683f6e49a9c440c515ddc22e2e3d96a
AD  - Institute of Computer Science, University of Tartu, Estonia
AB  - Recently, large pre-trained language models, such as BERT, have reached state-of-the-art performance in many natural language processing tasks, but for many languages, including Estonian, BERT models are not yet available. However, there exist several multilingual BERT models that can handle multiple languages simultaneously and that have been trained also on Estonian data. In this paper, we evaluate four multilingual models - multilingual BERT, multilingual distilled BERT, XLM and XLM-RoBERTa - on several NLP tasks including POS and morphological tagging, NER and text classification. Our aim is to establish a comparison between these multilingual BERT models and the existing baseline neural models for these tasks. Our results show that multilingual BERT models can generalise well on different Estonian NLP tasks outperforming all baselines models for POS and morphological tagging and text classification, and reaching the comparable level with the best baseline for NER, with XLM-RoBERTa achieving the highest results compared with other multilingual models.  © 2020 The authors and IOS Press.
KW  - Estonian
KW  - Multilingual BERT
KW  - NER
KW  - POS tagging
KW  - Text classification
KW  - Classification (of information)
KW  - Computational linguistics
KW  - Text processing
KW  - Estonian
KW  - Language model
KW  - Language processing
KW  - Morphological tagging
KW  - Multilingual BERT
KW  - Natural languages
KW  - NER
KW  - POS tagging
KW  - State-of-the-art performance
KW  - Text classification
KW  - Natural language processing systems
A2  - Utka A.
A2  - Vaicenoniene J.
A2  - Kovalevskaite J.
A2  - Kalinauskaite D.
PB  - IOS Press BV
SN  - 09226389 (ISSN); 978-164368116-0 (ISBN)
LA  - English
J2  - Front. Artif. Intell. Appl.
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 4; Correspondence Address: C. Kittask; Institute of Computer Science, University of Tartu, Estonia; email: claudiakittask@gmail.com; Conference name: 9th International Conference on Human Language Technologies - The Baltic Perspective, Baltic HLT 2020; Conference date: 22 September 2020 through 23 September 2020; Conference code: 163632
ER  -

TY  - CONF
AU  - Huggins, M.
AU  - Alghowinem, S.
AU  - Jeong, S.
AU  - Colon-Hernandez, P.
AU  - Breazeal, C.
AU  - Park, H.W.
TI  - Practical guidelines for intent recognition: BERT with minimal training data evaluated in real-world HRI application
PY  - 2021
T2  - ACM/IEEE International Conference on Human-Robot Interaction
C7  - 3444671
SP  - 341
EP  - 350
DO  - 10.1145/3434073.3444671
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85102728534&doi=10.1145%2f3434073.3444671&partnerID=40&md5=7202c2918d2e4c21636335b794db5c31
AD  - MIT Media Lab, Cambridge, MA, United States
AB  - Intent recognition models, which match a written or spoken input's class in order to guide an interaction, are an essential part of modern voice user interfaces, chatbots, and social robots. However, getting enough data to train these models can be very expensive and challenging, especially when designing novel applications such as real-world human-robot interactions. In this work, wefi rst investigate how much training data is needed for high performance in an intent classification task. We train and evaluate BiLSTM and BERT models on various subsets of the ATIS and Snips datasets. Wefi nd that only 25 training examples per intent are required for our BERT model to achieve 94% intent accuracy compared to 98% with the entire datasets, challenging the belief that large amounts of labeled data are required for high performance in intent recognition. We apply this knowledge to train models for a real-world HRI application, character strength recognition during a positive psychology interaction with a social robot, and evaluate against the Character Strength dataset collected in our previous HRI study. Our real-world HRI application results also confirm that our model can produce 76% intent accuracy with 25 examples per intent compared to 80% with 100 examples. In a real-world scenario, the difference is only one additional error per 25 classifications. Finally, we investigate the limitations of our minimal data models and offer suggestions on developing high quality datasets. We conclude with practical guidelines for training BERT intent recognition models with minimal training data and make our code and evaluation framework available for others to replicate our results and easily develop models for their own applications. © 2021 IEEE Computer Society. All rights reserved.
KW  - BERT
KW  - Intent recognition
KW  - Natural language processing
KW  - Real-world HRI application
KW  - Agricultural robots
KW  - Large dataset
KW  - Man machine systems
KW  - Social robots
KW  - User interfaces
KW  - Classification tasks
KW  - Evaluation framework
KW  - Intent recognition
KW  - Novel applications
KW  - Positive psychology
KW  - Practical guidelines
KW  - Real-world scenario
KW  - Voice user interface
KW  - Classification (of information)
PB  - IEEE Computer Society
SN  - 21672148 (ISSN); 978-145038289-2 (ISBN)
LA  - English
J2  - ACM/IEEE Int. Conf. Hum.-Rob. Interact.
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 8; Conference name: 2021 ACM/IEEE International Conference on Human-Robot Interaction, HRI 2021; Conference date: 8 March 2021 through 11 March 2021; Conference code: 167644
ER  -

TY  - CONF
AU  - Ding, S.
AU  - Koehn, P.
TI  - Evaluating Saliency Methods for Neural Language Models
PY  - 2021
T2  - NAACL-HLT 2021 - 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Proceedings of the Conference
SP  - 5034
EP  - 5052
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85114697491&partnerID=40&md5=9e414c031d4ce7ef79471cd37fa14bb2
AD  - Center for Language and Speech Processing, Johns Hopkins University, United States
AB  - Saliency methods are widely used to interpret neural network predictions, but different variants of saliency methods often disagree even on the interpretations of the same prediction made by the same model. In these cases, how do we identify when are these interpretations trustworthy enough to be used in analyses? To address this question, we conduct a comprehensive and quantitative evaluation of saliency methods on a fundamental category of NLP models: neural language models. We evaluate the quality of prediction interpretations from two perspectives that each represents a desirable property of these interpretations: plausibility and faithfulness. Our evaluation is conducted on four different datasets constructed from the existing human annotation of syntactic and semantic agreements, on both sentence-level and document-level. Through our evaluation, we identified various ways saliency methods could yield interpretations of low quality. We recommend that future work deploying such methods to neural language models should carefully validate their interpretations before drawing insights. © 2021 Association for Computational Linguistics.
KW  - Computational linguistics
KW  - Forecasting
KW  - Quality control
KW  - Comprehensive evaluation
KW  - Human annotations
KW  - Language model
KW  - Low qualities
KW  - Neural network predictions
KW  - Property
KW  - Quality of predictions
KW  - Quantitative evaluation
KW  - Sentence level
KW  - Semantics
PB  - Association for Computational Linguistics (ACL)
SN  - 978-195408546-6 (ISBN)
LA  - English
J2  - NAACL-HLT - Conf. N. Am. Chapter Assoc. Comput. Linguist.: Hum. Lang. Technol., Proc. Conf.
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 20; Conference name: 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, NAACL-HLT 2021; Conference date: 6 June 2021 through 11 June 2021; Conference code: 182055
ER  -

TY  - JOUR
AU  - Kades, K.
AU  - Sellner, J.
AU  - Koehler, G.
AU  - Full, P.M.
AU  - Emmy Lai, T.Y.
AU  - Kleesiek, J.
AU  - Maier-Hein, K.H.
TI  - Adapting Bidirectional Encoder Representations from Transformers (BERT) to assess clinical semantic textual similarity: Algorithm development and validation study
PY  - 2021
T2  - JMIR Medical Informatics
VL  - 9
IS  - 2
C7  - e22795
DO  - 10.2196/22795
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85101218161&doi=10.2196%2f22795&partnerID=40&md5=4f7b398b5c45fdcaf77467802a2a0760
AD  - German Cancer Research Center (DKFZ), Im Neuenheimer Feld 280, Heidelberg, 69120, Germany
AD  - Partner Site Heidelberg, German Cancer Consortium (DKTK), Heidelberg, Germany
AD  - Helmholtz Information and Data Science School for Health, Karlsruhe/Heidelberg, Germany
AD  - Heidelberg University, Heidelberg, Germany
AD  - Hochschule Mannheim, University of Applied Sciences, Mannheim, Germany
AD  - Institute for Artificial Intelligence in Medicine (IKIM), University Medicine Essen, Essen, Germany
AB  - Background: Natural Language Understanding enables automatic extraction of relevant information from clinical text data, which are acquired every day in hospitals. In 2018, the language model Bidirectional Encoder Representations from Transformers (BERT) was introduced, generating new state-of-the-art results on several downstream tasks. The National NLP Clinical Challenges (n2c2) is an initiative that strives to tackle such downstream tasks on domain-specific clinical data. In this paper, we present the results of our participation in the 2019 n2c2 and related work completed thereafter. Objective: The objective of this study was to optimally leverage BERT for the task of assessing the semantic textual similarity of clinical text data. Methods: We used BERT as an initial baseline and analyzed the results, which we used as a starting point to develop 3 different approaches where we (1) added additional, handcrafted sentence similarity features to the classifier token of BERT and combined the results with more features in multiple regression estimators, (2) incorporated a built-in ensembling method, M-Heads, into BERT by duplicating the regression head and applying an adapted training strategy to facilitate the focus of the heads on different input patterns of the medical sentences, and (3) developed a graph-based similarity approach for medications, which allows extrapolating similarities across known entities from the training set. The approaches were evaluated with the Pearson correlation coefficient between the predicted scores and ground truth of the official training and test dataset. Results: We improved the performance of BERT on the test dataset from a Pearson correlation coefficient of 0.859 to 0.883 using a combination of the M-Heads method and the graph-based similarity approach. We also show differences between the test and training dataset and how the two datasets influenced the results. Conclusions: We found that using a graph-based similarity approach has the potential to extrapolate domain specific knowledge to unseen sentences. We observed that it is easily possible to obtain deceptive results from the test dataset, especially when the distribution of the data samples is different between training and test datasets. © Klaus Kades, Jan Sellner, Gregor Koehler, Peter M Full, T Y Emmy Lai, Jens Kleesiek, Klaus H Maier-Hein.
KW  - Clinical text mining
KW  - National NLP Clinical Challenges
KW  - Natural Language Processing
KW  - Semantic textual similarity
PB  - JMIR Publications Inc.
SN  - 22919694 (ISSN)
LA  - English
J2  - JMIR Med. Inform.
M3  - Article
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 12; Correspondence Address: K. Kades; German Cancer Research Center (DKFZ), Heidelberg, Im Neuenheimer Feld 280, 69120, Germany; email: k.kades@dkfz.de
ER  -

TY  - CONF
AU  - Senel, L.K.
AU  - Schütze, H.
TI  - Does he wink or does he nod? A challenging benchmark for evaluating word understanding of language models
PY  - 2021
T2  - EACL 2021 - 16th Conference of the European Chapter of the Association for Computational Linguistics, Proceedings of the Conference
SP  - 532
EP  - 538
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85107290821&partnerID=40&md5=7fe7b20a437354d6e1e9c7f1a4b5c1d8
AD  - Center for Information and Language Processing (CIS), LMU Munich, Germany
AB  - Recent progress in pretraining language models on large corpora has resulted in large performance gains on many NLP tasks. These large models acquire linguistic knowledge during pretraining, which helps to improve performance on downstream tasks via fine-tuning. To assess what kind of knowledge is acquired, language models are commonly probed by querying them with 'fill in the blank' style cloze questions. Existing probing datasets mainly focus on knowledge about relations between words and entities. We introduce WDLMPro (Word Definition Language Model Probing) to evaluate word understanding directly using dictionary definitions of words. In our experiments, three popular pretrained language models struggle to match words and their definitions. This indicates that they understand many words poorly and that our new probing task is a difficult challenge that could help guide research on LMs in the future. © 2021 Association for Computational Linguistics
KW  - Dictionary definitions
KW  - Improve performance
KW  - Language model
KW  - Large corpora
KW  - Large models
KW  - Linguistic knowledge
KW  - Performance Gain
KW  - Recent progress
KW  - Computational linguistics
PB  - Association for Computational Linguistics (ACL)
SN  - 978-195408502-2 (ISBN)
LA  - English
J2  - EACL - Conf. Eur. Chapter Assoc. Comput. Linguist., Proc. Conf.
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 1; Conference name: 16th Conference of the European Chapter of the Associationfor Computational Linguistics, EACL 2021; Conference date: 19 April 2021 through 23 April 2021; Conference code: 169023
ER  -

TY  - CONF
AU  - Zhou, D.
AU  - Zhang, X.
AU  - Zou, Y.
AU  - Ni, Y.
AU  - Wang, D.
TI  - State Evaluation Model of Distribution Transformer Based on Analytic Hierarchy Process
PY  - 2021
T2  - ICSMD 2021 - 2nd International Conference on Sensing, Measurement and Data Analytics in the Era of Artificial Intelligence
DO  - 10.1109/ICSMD53520.2021.9670797
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85124977936&doi=10.1109%2fICSMD53520.2021.9670797&partnerID=40&md5=90d6826459ef2fe2377c9867a74816f0
AD  - Marketing Service Center State Grid Jiangsu Electric Power Co. Ltd, Nanjing, China
AB  - The status evaluation of distribution transformers is a systematic process, and selecting appropriate methods can quickly and accurately evaluate its operating status. In this paper, the characteristics of the transformer are integrated and a method for evaluating the state of the transformer before delivery based on the analytic hierarchy process (AHP) is proposed. This method calculates the weight through the analytic hierarchy process, collects the field state quantity data, and adds the weighted sum of the state scores at each level, and finally determines the overall health state of the transformer. The calculation result of this method is accurate and the process is clear. After substituting actual data, the calculation results show that the method can accurately assess the health status of the transformer. The proposed method has broad application prospects in the evaluation of the transformer status.  © 2021 IEEE.
KW  - analytic hierarchy process
KW  - condition assessment
KW  - distribution transformer
KW  - Electric transformers
KW  - Calculation results
KW  - Condition assessments
KW  - Distribution transformer
KW  - Evaluation models
KW  - Field state
KW  - Health state
KW  - State evaluation
KW  - Status evaluations
KW  - Systematic process
KW  - Weighted Sum
KW  - Analytic hierarchy process
PB  - Institute of Electrical and Electronics Engineers Inc.
SN  - 978-166542747-0 (ISBN)
LA  - English
J2  - ICSMD - Int. Conf. Sens., Meas. Data Anal. Era Artif. Intell.
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 1; Correspondence Address: D. Zhou; Marketing Service Center State Grid Jiangsu Electric Power Co. Ltd, Nanjing, China; email: 80967629@qq.com; Conference name: 2nd International Conference on Sensing, Measurement and Data Analytics in the Era of Artificial Intelligence, ICSMD 2021; Conference date: 21 October 2021 through 23 October 2021; Conference code: 176353
ER  -

TY  - CONF
AU  - Shibayama, N.
AU  - Shinnou, H.
TI  - Construction and Evaluation of Japanese Sentence-BERT Models
PY  - 2021
T2  - Proceedings of the 35th Pacific Asia Conference on Language, Information and Computation, PACLIC 2021
SP  - 529
EP  - 536
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85127505453&partnerID=40&md5=75406630a06ac355bf4e3c9e9233af4e
AD  - Ibaraki University, Ibaraki, Japan
AB  - Sentence-BERT is model which based on “Bidirectional Encoder Representations from Transformers” (BERT) for building sentence embedding. This model has abilities for semantic analysis similar to BERT; however, the processing need not be online like in BERT. Therefore, it is also effective for similar sentence searches. No Japanese sentence-BERT model has been released in the right format. Here, we built six Japanese sentence-BERT models with Japanese Stanford natural language inference (JSNLI) released at Kyoto University and six public Japanese BERT models. Furthermore, we proposed two evaluation methods for the sentence-BERT models and evaluated the six Japanese sentence-BERT models using the ratio of the in-class dispersion to out-of-class dispersions and accuracy of classification tasks using k-nearest neighbor (k-NN) classifier. As a result, two sentence-BERT models recorded higher performance: the model which was built from Tohoku BERT and the National Institute of Information and Communications Technology (NICT) BERT. © Proceedings of the 35th Pacific Asia Conference on Language, Information and Computation, PACLIC 2021.
KW  - Dispersions
KW  - Nearest neighbor search
KW  - Accuracy of classifications
KW  - Classification tasks
KW  - Embeddings
KW  - Evaluation methods
KW  - Language inference
KW  - Natural languages
KW  - Processing needs
KW  - Semantic analysis
KW  - Stanford
KW  - Transformer modeling
KW  - Semantics
A2  - Hu K.
A2  - Kim J.-B.
A2  - Zong C.
A2  - Chersoni E.
PB  - Association for Computational Linguistics (ACL)
LA  - English
J2  - Proc. Pac. Asia Conf. Lang., Inf. Comput., PACLIC
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 3; Conference name: 35th Pacific Asia Conference on Language, Information and Computation, PACLIC 2021; Conference date: 5 November 2021 through 7 November 2021; Conference code: 177552
ER  -

TY  - CONF
AU  - Nicula, B.
AU  - Dascalu, M.
AU  - Newton, N.
AU  - Orcutt, E.
AU  - McNamara, D.S.
TI  - Automated Paraphrase Quality Assessment Using Recurrent Neural Networks and Language Models
PY  - 2021
T2  - Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)
VL  - 12677 LNCS
SP  - 333
EP  - 340
DO  - 10.1007/978-3-030-80421-3_36
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85112250426&doi=10.1007%2f978-3-030-80421-3_36&partnerID=40&md5=a785d580153a54d3979ea10d6fc34784
AD  - University Politehnica of Bucharest, 313 Splaiul Independentei, Bucharest, 060042, Romania
AD  - Academy of Romanian Scientists, Str. Ilfov, Nr. 3, Bucharest, 050044, Romania
AD  - Department of Psychology, Arizona State University, P.O. Box 871104, Tempe, 85287, AZ, United States
AD  - Department of Educational Psychology, University of Minnesota, 56 East River Road, Minneapolis, 55455, MN, United States
AB  - The ability to automatically assess the quality of paraphrases can be very useful for facilitating literacy skills and providing timely feedback to learners. Our aim is twofold: a) to automatically evaluate the quality of paraphrases across four dimensions: lexical similarity, syntactic similarity, semantic similarity and paraphrase quality, and b) to assess how well models trained for this task generalize. The task is modeled as a classification problem and three different methods are explored: a) manual feature extraction combined with an Extra Trees model, b) GloVe embeddings and a Siamese neural network, and c) using a pretrained BERT model fine-tuned on our task. Starting from a dataset of 1998 paraphrases from the User Language Paraphrase Corpus (ULPC), we explore how the three models trained on the ULPC dataset generalize when applied on a separate, small paraphrase corpus based on children inputs. The best out-of-the-box generalization performance is obtained by the Extra Trees model with at least 75% average F1-scores for the three similarity dimensions. We also show that the Siamese neural network and BERT models can obtain an improvement of at least 5% after fine-tuning across all dimensions. © 2021, Springer Nature Switzerland AG.
KW  - Language models
KW  - Natural language processing
KW  - Paraphrase quality assessment
KW  - Recurrent neural networks
KW  - Computer aided instruction
KW  - Forestry
KW  - Intelligent vehicle highway systems
KW  - Natural language processing systems
KW  - Semantics
KW  - Four dimensions
KW  - Generalization performance
KW  - Lexical similarity
KW  - Paraphrase corpus
KW  - Quality assessment
KW  - Semantic similarity
KW  - Syntactic similarities
KW  - Timely feedback
KW  - Recurrent neural networks
A2  - Cristea A.I.
A2  - Troussas C.
PB  - Springer Science and Business Media Deutschland GmbH
SN  - 03029743 (ISSN); 978-303080420-6 (ISBN)
LA  - English
J2  - Lect. Notes Comput. Sci.
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 6; Correspondence Address: M. Dascalu; University Politehnica of Bucharest, Bucharest, 313 Splaiul Independentei, 060042, Romania; email: mihai.dascalu@upb.ro; Conference name: 17th International Conference on Intelligent Tutoring Systems, ITS 2021; Conference date: 7 June 2021 through 11 June 2021; Conference code: 262619
ER  -

TY  - CONF
AU  - Almeida, T.
AU  - Matos, S.
TI  - Benchmarking a transformer-FREE model for ad-hoc retrieval
PY  - 2021
T2  - EACL 2021 - 16th Conference of the European Chapter of the Association for Computational Linguistics, Proceedings of the Conference
SP  - 3343
EP  - 3353
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85107311005&partnerID=40&md5=7334281fe15ee1e27a052d9bc987be77
AD  - IEETA, Universidade de Aveiro, Aveiro, Portugal
AD  - DETI, IEETA, Universidade de Aveiro, Aveiro, Portugal
AB  - Transformer-based “behemoths” have grown in popularity, as well as structurally, shattering multiple NLP benchmarks along the way. However, their real-world usability remains a question. In this work, we empirically assess the feasibility of applying transformer-based models in real-world ad-hoc retrieval applications by comparison to a “greener and more sustainable” alternative, comprising only 620 trainable parameters. We present an analysis of their efficacy and efficiency and show that considering limited computational resources, the lighter model running on the CPU achieves a 3 to 20 times speedup in training and 7 to 47 times in inference while maintaining a comparable retrieval performance. Code to reproduce the efficiency experiments is available on https://github.com/bioinformatics-ua/ EACL2021-reproducibility/. © 2021 Association for Computational Linguistics
KW  - Efficiency
KW  - Ad Hoc retrieval
KW  - Computational resources
KW  - Free model
KW  - Real-world
KW  - Reproducibilities
KW  - Retrieval performance
KW  - Computational linguistics
PB  - Association for Computational Linguistics (ACL)
SN  - 978-195408502-2 (ISBN)
LA  - English
J2  - EACL - Conf. Eur. Chapter Assoc. Comput. Linguist., Proc. Conf.
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 1; Conference name: 16th Conference of the European Chapter of the Associationfor Computational Linguistics, EACL 2021; Conference date: 19 April 2021 through 23 April 2021; Conference code: 169023
ER  -

TY  - CONF
AU  - Wei, Q.
AU  - Tang, W.
AU  - Qian, T.
AU  - Liu, G.
AU  - Zhang, H.
AU  - Zhou, Z.
AU  - Li, Y.
TI  - An Improved Thermal-electric Analogy Model for Evaluating Loading Capability of Oil-immersed Transformers
PY  - 2021
T2  - Proceedings - 2021 6th Asia Conference on Power and Electrical Engineering, ACPEE 2021
C7  - 9437048
SP  - 1261
EP  - 1266
DO  - 10.1109/ACPEE51499.2021.9437048
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85107465794&doi=10.1109%2fACPEE51499.2021.9437048&partnerID=40&md5=8369015c7f6964622fc1d4a5568d3e4c
AD  - South China University of Technology, School of Electric Power Engineering, Guangzhou, China
AD  - Guangdong Power Grid Corporation, Dongguan Power Supply Bureau, Dongguan, China
AB  - The load capacity of oil-immersed transformers affects the safety of power system operation. In order to fully exploit and utilize the load capacity of transformer, a novel improved model is proposed based on the principle of thermal- electric analogy. Firstly, solar radiation is introduced as a new heat source, and the thermal conductance is modified by considering the effect of temperature on oil viscosity. Then, a transformer load capacity evaluation model based on the thermal-electric analogy principle is proposed under the constraint conditions of top-oil temperature, hot-spot temperature, relative life loss, and auxiliary equipment capacity level. Finally, a 50 MVA transformer is carried out for oil temperature and load capacity. The results demonstrate that compared with Tang-model and the transformer guidelines, the error of the top-oil temperature and the hot-spot temperature of the new model is smaller. In addition, for periodic loads, transformer load capacity also represents different characteristics, which provides a guide for exploiting the load potential of power transformers. © 2021 IEEE.
KW  - hot-spot temperature
KW  - load capacity
KW  - relative life loss
KW  - thermal-electric analogy
KW  - Auxiliary equipment
KW  - Electric losses
KW  - Oil filled transformers
KW  - Power transformers
KW  - Constraint conditions
KW  - Effect of temperature
KW  - Hotspot temperature
KW  - Oil immersed transformers
KW  - Power system operations
KW  - Thermal conductance
KW  - Top oil temperature
KW  - Transformer-load
KW  - Electric transformer loads
A2  - Lie T.-T.
A2  - Liu Y.
PB  - Institute of Electrical and Electronics Engineers Inc.
SN  - 978-172819159-1 (ISBN)
LA  - English
J2  - Proc. - Asia Conf. Power Electr. Eng., ACPEE
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 0; Conference name: 6th Asia Conference on Power and Electrical Engineering, ACPEE 2021; Conference date: 8 April 2021 through 11 April 2021; Conference code: 169194
ER  -

TY  - CONF
AU  - Jia, Q.
AU  - Cui, J.
AU  - Xiao, Y.
AU  - Liu, C.
AU  - Rashid, P.
AU  - Gehringer, E.
TI  - ALL-IN-ONE: Multi-Task Learning BERT models for Evaluating Peer Assessments
PY  - 2021
T2  - Proceedings of the 14th International Conference on Educational Data Mining, EDM 2021
SP  - 525
EP  - 532
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85145998800&partnerID=40&md5=22b4f7b3a9006bdac983498eca4113a5
AD  - Department of Computer Science, North Carolina State University, Raleigh, NC, United States
AB  - Peer assessment has been widely applied across diverse academic fields over the last few decades, and has demonstrated its effectiveness. However, the advantages of peer assessment can only be achieved with high-quality peer reviews. Previous studies have found that high-quality review comments usually comprise several features (e.g., contain suggestions, mention problems, use a positive tone). Thus, researchers have attempted to evaluate peer-review comments by detecting different features using various machine learning and deep learning models. However, there is no single study that investigates using a multi-task learning (MTL) model to detect multiple features simultaneously. This paper presents two MTL models for evaluating peer-review comments by leveraging the state-of-the-art pre-trained language representation models BERT and DistilBERT. Our results demonstrate that BERT-based models significantly outperform previous GloVe-based methods by around 6% in F1-score on tasks of detecting a single feature, and MTL further improves performance while reducing model size. © EDM 2021.All rights reserved.
KW  - automated peer-assessment evaluation
KW  - educational data mining
KW  - Peer assessment
KW  - peer feedback
KW  - text analytics
KW  - Deep learning
KW  - Feature extraction
KW  - Learning systems
KW  - Linearization
KW  - Automated peer-assessment evaluation
KW  - Educational data mining
KW  - High quality
KW  - Learning models
KW  - Multitask learning
KW  - Peer assessment
KW  - Peer feedback
KW  - Peer review
KW  - Text analytics
KW  - Data mining
A2  - Hsiao I.-H.
A2  - Sahebi S.
A2  - Bouchet F.
A2  - Vie J.-J.
PB  - International Educational Data Mining Society
SN  - 978-173367362-4 (ISBN)
LA  - English
J2  - Proc. Int. Conf. Educ. Data Min., EDM
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 5; Conference name: 14th International Conference on Educational Data Mining, EDM 2023; Conference date: 29 June 2021 through 2 July 2021; Conference code: 192951
ER  -

TY  - CONF
AU  - Lazaridou, A.
AU  - Kuncoro, A.
AU  - Gribovskaya, E.
AU  - Agrawal, D.
AU  - Liška, A.
AU  - Terzi, T.
AU  - Gimenez, M.
AU  - de Masson d’Autume, C.
AU  - Kocisky, T.
AU  - Ruder, S.
AU  - Yogatama, D.
AU  - Cao, K.
AU  - Young, S.
AU  - Blunsom, P.
TI  - Mind the Gap: Assessing Temporal Generalization in Neural Language Models
PY  - 2021
T2  - Advances in Neural Information Processing Systems
VL  - 35
SP  - 29348
EP  - 29363
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85131316064&partnerID=40&md5=e46f05692dd7fb931194f37ef48033ca
AD  - DeepMind, London, United Kingdom
AB  - Our world is open-ended, non-stationary, and constantly evolving; thus what we talk about and how we talk about it change over time. This inherent dynamic nature of language contrasts with the current static language modelling paradigm, which trains and evaluates models on utterances from overlapping time periods. Despite impressive recent progress, we demonstrate that Transformer-XL language models perform worse in the realistic setup of predicting future utterances from beyond their training period, and that model performance becomes increasingly worse with time. We find that, while increasing model size alone—a key driver behind recent progress—does not solve this problem, having models that continually update their knowledge with new information can indeed mitigate this performance degradation over time. Hence, given the compilation of ever-larger language modelling datasets, combined with the growing list of language-model-based NLP applications that require up-to-date factual knowledge about the world, we argue that now is the right time to rethink the static way in which we currently train and evaluate our language models, and develop adaptive language models that can remain up-to-date with respect to our ever-changing and non-stationary world. We publicly release our dynamic, streaming language modelling benchmarks for WMT and ARXIV to facilitate language model evaluation that takes temporal dynamics into account.1 © 2021 Neural information processing systems foundation. All rights reserved.
KW  - Computational linguistics
KW  - 'current
KW  - Change-over time
KW  - Dynamic nature
KW  - Generalisation
KW  - Language model
KW  - Modeling paradigms
KW  - Modeling performance
KW  - Nonstationary
KW  - Recent progress
KW  - Time-periods
KW  - Modeling languages
A2  - Ranzato M.
A2  - Beygelzimer A.
A2  - Dauphin Y.
A2  - Liang P.S.
A2  - Wortman Vaughan J.
PB  - Neural information processing systems foundation
SN  - 10495258 (ISSN); 978-171384539-3 (ISBN)
LA  - English
J2  - Adv. neural inf. proces. syst.
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 55; Correspondence Address: A. Lazaridou; DeepMind, London, United Kingdom; email: angeliki@deepmind.com; A. Kuncoro; DeepMind, London, United Kingdom; email: akuncoro@deepmind.com; E. Gribovskaya; DeepMind, London, United Kingdom; email: egribovskaya@deepmind.com; Conference name: 35th Conference on Neural Information Processing Systems, NeurIPS 2021; Conference date: 6 December 2021 through 14 December 2021; Conference code: 179642
ER  -

TY  - CONF
AU  - Oniani, D.
AU  - Wang, Y.
TI  - A Qualitative Evaluation of Language Models on Automatic Question-Answering for COVID-19
PY  - 2020
T2  - Proceedings of the 11th ACM International Conference on Bioinformatics, Computational Biology and Health Informatics, BCB 2020
DO  - 10.1145/3388440.3412413
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85097002603&doi=10.1145%2f3388440.3412413&partnerID=40&md5=ce1629d2ae2f7ada1b1bfea5a8161ce4
AD  - Mayo Clinic, Kern Center for the Science of Health Care Delivery, Rochester, MN, United States
AD  - Mayo Clinic, Division of Digital Health Sciences, Rochester, MN, United States
AB  - COVID-19 (2019 Novel Coronavirus) has resulted in an ongoing pandemic and as of 26 July 2020, has caused more than 15.7 million cases and over 640,000 deaths. The highly dynamic and rapidly evolving situation with COVID-19 has made it difficult to access accurate, on-demand information regarding the disease. Online communities, forums, and social media provide potential venues to search for relevant questions and answers, or post questions and seek answers from other members. However, due to the nature of such sites, there are always a limited number of relevant questions and responses to search from, and posted questions are rarely answered immediately. With the advancements in the field of natural language processing, particularly in the domain of language models, it has become possible to design chatbots that can automatically answer consumer questions. However, such models are rarely applied and evaluated in the healthcare domain, to meet the information needs with accurate and up-To-date healthcare data. In this paper, we propose to apply a language model for automatically answering questions related to COVID-19 and qualitatively evaluate the generated responses. We utilized the GPT-2 language model and applied transfer learning to retrain it on the COVID-19 Open Research Dataset (CORD-19) corpus. In order to improve the quality of the generated responses, we applied 4 different approaches, namely tf-idf (Term Frequency-Inverse Document Frequency), Bidirectional Encoder Representations from Transformers (BERT), Bidirectional Encoder Representations from Transformers for Biomedical Text Mining (BioBERT), and Universal Sentence Encoder (USE) to filter and retain relevant sentences in the responses. In the performance evaluation step, we asked two medical experts to rate the responses. We found that BERT and BioBERT, on average, outperform both tf-idf and USE in relevance-based sentence filtering tasks. Additionally, based on the chatbot, we created a user-friendly interactive web application to be hosted online and made its source code available free of charge to anyone interested in running it locally, online, or just for experimental purposes. Overall, our work has yielded significant results in both designing a chatbot that produces high-quality responses to COVID-19-related questions and comparing several embedding generation techniques. © 2020 ACM.
KW  - ai
KW  - bert
KW  - biobert
KW  - cord-19
KW  - covid-19
KW  - dataset
KW  - gpt-2
KW  - nlp
KW  - semantic similarity
KW  - tf-idf
KW  - use
KW  - Bioinformatics
KW  - Computational linguistics
KW  - Filtration
KW  - Health care
KW  - Natural language processing systems
KW  - Signal encoding
KW  - Social networking (online)
KW  - Text mining
KW  - Transfer learning
KW  - Automatic question answering
KW  - Biomedical text minings
KW  - Generation techniques
KW  - Interactive web applications
KW  - NAtural language processing
KW  - On-demand informations
KW  - Qualitative evaluations
KW  - Term frequency-inverse document frequencies
KW  - Medical informatics
PB  - Association for Computing Machinery, Inc
SN  - 978-145037964-9 (ISBN)
LA  - English
J2  - Proc. ACM Int. Conf. Bioinformatics, Computational Biology Health Informatics, BCB
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 22; Conference name: 11th ACM International Conference on Bioinformatics, Computational Biology and Health Informatics, BCB 2020; Conference date: 21 September 2020 through 24 September 2020; Conference code: 164833
ER  -

TY  - CONF
AU  - Szarkowska, K.
AU  - Moore, V.
AU  - Vandenbussche, P.-Y.
AU  - Groth, P.
TI  - Quality assessment of knowledge graph hierarchies using KG-BERT
PY  - 2021
T2  - CEUR Workshop Proceedings
VL  - 3034
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85121324969&partnerID=40&md5=8a05478fef867b5259ab6e604af64498
AD  - University of Amsterdam, Science Park 904, Amsterdam, 1098 XH, Netherlands
AD  - Elsevier Amsterdam, Radarweg 29a, Amsterdam, 1043 NX, Netherlands
AB  - Knowledge graphs in both public and corporate settings need to keep pace with the constantly growing amount of data being generated. It is, therefore, crucial to have automated solutions for assessing the quality of Knowledge Graphs, as manual curation quickly reaches its limits. This research proposes the use of KG-BERT for a triple (binary) classification task that assesses the quality of a Knowledge Graphs’s hierarchical structure. The use of KG-BERT allows the textual as well structural aspects of a Knowledge Graph to be leverage for this quality assessment (QA) task. The performance of our proposed approach is measured using four different Knowledge Graphs: two branches (Physics and Mathematics) of a corporate Knowledge Graph - OmniScience, a WordNet subset, and the UMLS Semantic Network. Our method yields high-performance scores on all four KGs (88-92% accuracy) making it a relevant tool for quality assessment and knowledge graph maintenance. © 2021 Copyright for this paper by its authors.
KW  - BERT
KW  - Contextual word embeddings
KW  - Hierarchical knowledge graphs
KW  - Hierarchy evaluation
KW  - KG-BERT
KW  - Knowledge graphs
KW  - Ontology maintenance
KW  - Triple classification
KW  - Embeddings
KW  - Graphic methods
KW  - Knowledge management
KW  - Ontology
KW  - Quality control
KW  - Semantics
KW  - BERT
KW  - Contextual word embedding
KW  - Contextual words
KW  - Embeddings
KW  - Hierarchical knowledge
KW  - Hierarchical knowledge graph
KW  - Hierarchy evaluation
KW  - KG-BERT
KW  - Knowledge graphs
KW  - Ontology maintenance
KW  - Ontology's
KW  - Triple classification
KW  - Knowledge graph
A2  - Alam M.
A2  - Buscaldi D.
A2  - Cochez M.
A2  - Osborne F.
A2  - Recupero D.R.
A2  - Sack H.
PB  - CEUR-WS
SN  - 16130073 (ISSN)
LA  - English
J2  - CEUR Workshop Proc.
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 0; Conference name: 4th  Workshop on Deep Learning for Knowledge Graphs, DL4KG 2021; Conference code: 175404
ER  -

TY  - CONF
AU  - Meidinger, M.
AU  - Aßenmacher, M.
TI  - A new benchmark for NLP in social sciences: Evaluating the usefulness of pre-trained language models for classifying open-ended survey responses
PY  - 2021
T2  - ICAART 2021 - Proceedings of the 13th International Conference on Agents and Artificial Intelligence
VL  - 2
SP  - 866
EP  - 873
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85103847004&partnerID=40&md5=e34c74d6dd6a8e7975dbec37b43e150d
AD  - Department of Statistics, Ludwig-Maximilians-Universität, Munich, Germany
AB  - In order to evaluate transfer learning models for Natural Language Processing on a common ground, numerous general domain (sets of) benchmark data sets have been established throughout the last couple of years. Primarily, the proposed tasks are classification (binary, multi-class), regression or language generation. However, no benchmark data set for (extreme) multi-label classification relying on full-text inputs has been proposed in the area of social science survey research to this date. This constitutes an important gap, as a common data set for algorithm development in this field could lead to more reproducible, sustainable research. Thus, we provide a transparent and fully reproducible preparation of the 2008 American National Election Study (ANES) data set, which can be used for benchmark comparisons of different NLP models on the task of multi-label classification. In contrast to other data sets, our data set comprises full-text inputs instead of bag-of-words representations or similar. Furthermore, we provide baseline performances of simple logistic regression models as well as performance values for recently established transfer learning architectures, namely BERT (Devlin et al., 2018), RoBERTa (Liu et al., 2019) and XLNet (Yang et al., 2019). © 2021 by SCITEPRESS - Science and Technology Publications, Lda.
KW  - Benchmark
KW  - Multi-label classification
KW  - Open-ended responses
KW  - Pre-trained language models
KW  - Transfer learning
KW  - Behavioral research
KW  - Learning systems
KW  - Logistic regression
KW  - Natural language processing systems
KW  - Surveys
KW  - Text processing
KW  - Transfer learning
KW  - Algorithm development
KW  - Base-line performance
KW  - Benchmark comparison
KW  - Language generation
KW  - Learning architectures
KW  - Multi label classification
KW  - NAtural language processing
KW  - Simple logistic regressions
KW  - Classification (of information)
A2  - Rocha A.P.
A2  - Steels L.
A2  - van den Herik J.
PB  - SciTePress
SN  - 978-989758484-8 (ISBN)
LA  - English
J2  - ICAART - Proc. Int. Conf. Agents Artif. Intell.
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 1; Conference name: 13th International Conference on Agents and Artificial Intelligence, ICAART 2021; Conference date: 4 February 2021 through 6 February 2021; Conference code: 167493
ER  -

TY  - JOUR
AU  - Rahman, M.M.
AU  - Watanobe, Y.
AU  - Nakamura, K.
TI  - Source Code assessment and classification based on estimated error probability using attentive lstm language model and its application in programming education
PY  - 2020
T2  - Applied Sciences (Switzerland)
VL  - 10
IS  - 8
C7  - 2973
DO  - 10.3390/APP10082973
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85084635480&doi=10.3390%2fAPP10082973&partnerID=40&md5=5babc6b872752bfac0343ca679160b56
AD  - School of Computer Science and Engineering, Graduate Department of Computer and Information Systems, The University of Aizu, Aizu-Wakamatsu, Fukushima, 965-8580, Japan
AB  - The rate of software development has increased dramatically. Conventional compilers cannot assess and detect all source code errors. Software may thus contain errors, negatively affecting end-users. It is also difficult to assess and detect source code logic errors using traditional compilers, resulting in software that contains errors. Amethod that utilizes artificial intelligence for assessing and detecting errors and classifying source code as correct (error-free) or incorrect is thus required. Here, we propose a sequential language model that uses an attention-mechanism-based long short-term memory (LSTM) neural network to assess and classify source code based on the estimated error probability. The attentive mechanism enhances the accuracy of the proposed language model for error assessment and classification. We trained the proposed model using correct source code and then evaluated its performance. The experimental results show that the proposed model has logic and syntax error detection accuracies of 92.2% and 94.8%, respectively, outperforming state-of-the-art models. We also applied the proposed model to the classification of source code with logic and syntax errors. The average precision, recall, and F-measure values for such classification are much better than those of benchmark models. To strengthen the proposed model, we combined the attention mechanism with LSTM to enhance the results of error assessment and detection as well as source code classification. Finally, our proposed model can be effective in programming education and software engineering by improving code writing, debugging, error-correction, and reasoning. © 2020 by the authors.
KW  - Attention mechanism
KW  - Classification
KW  - Error assessment
KW  - Error probability
KW  - Language modeling
KW  - Logic error
KW  - LSTM
KW  - Neural network
KW  - Programming education
PB  - MDPI AG
SN  - 20763417 (ISSN)
LA  - English
J2  - Appl. Sci.
M3  - Article
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 36; Correspondence Address: M.M. Rahman; School of Computer Science and Engineering, Graduate Department of Computer and Information Systems, The University of Aizu, Aizu-Wakamatsu, Fukushima, 965-8580, Japan; email: mostafiz26@gmail.com
ER  -

TY  - CONF
AU  - Bouscarrat, L.
AU  - Bonnefoy, A.
AU  - Capponi, C.
AU  - Ramisch, C.
TI  - AMU-EURANOVA at CASE 2021 Task 1: Assessing the stability of multilingual BERT
PY  - 2021
T2  - 4th Workshop on Challenges and Applications of Automated Extraction of Socio-Political Events from Text, CASE 2021 - Proceedings
SP  - 161
EP  - 170
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85123165034&partnerID=40&md5=c92edc13bd9c15915e0d8221b4c3e8d4
AD  - Eura Nova, Marseille, France
AD  - Aix Marseille Univ, Universit e De Toulon, CNRS, Lis, Marseille, France
AB  - This paper explains our participation in task 1 of the CASE 2021 shared task. This task is about multilingual event extraction from news. We focused on sub-task 4, event information extraction. This sub-task has a small training dataset and we fine-tuned a multilingual BERT to solve this sub-task. We studied the instability problem on the dataset and tried to mitigate it.  ©2021 Association for Computational Linguistics.
KW  - Events extractions
KW  - Instability problems
KW  - Small training
KW  - Subtask
KW  - Training dataset
A2  - Hurriyetoglu A.
PB  - Association for Computational Linguistics (ACL)
SN  - 978-195408579-4 (ISBN)
LA  - English
J2  - Workshop Challenges Appl. Autom. Extr. Socio-Political Events Text, CASE - Proc.
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 2; Conference name: 4th Workshop on Challenges and Applications of Automated Extraction of Socio-Political Events from Text, CASE 2021; Conference date: 5 August 2021 through 6 August 2021; Conference code: 175247
ER  -

TY  - CONF
AU  - Ge, H.
AU  - Sun, C.
AU  - Xiong, D.
AU  - Liu, Q.
TI  - Chinese WPLC: A Chinese Dataset for Evaluating Pretrained Language Models on Word Prediction Given Long-Range Context
PY  - 2021
T2  - EMNLP 2021 - 2021 Conference on Empirical Methods in Natural Language Processing, Proceedings
SP  - 3770
EP  - 3778
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85122052684&partnerID=40&md5=224ea892cdc8ccfb5d18907ac8cecfec
AD  - College of Intelligence and Computing, Tianjin University, Tianjin, China
AD  - Huawei Noah's Ark Lab, Hong Kong, Hong Kong
AB  - This paper presents a Chinese dataset for evaluating pretrained language models on Word Prediction given Long-term Context (Chinese WPLC). We propose both automatic and manual selection strategies tailored to Chinese to guarantee that target words in passages collected from over 69K novels can only be predicted with long-term context beyond the scope of sentences containing the target words. Dataset analysis reveals that the types of target words range from common nouns to Chinese 4-character idioms. We also observe that linguistic relations between target words and long-range context exhibit diversity, including lexical match, synonym, summary and reasoning. Experiment results show that the Chinese pretrained language model PanGu-α (Zeng et al., 2021) is 45 points behind human in terms of top-1 word prediction accuracy, indicating that Chinese WPLC is a challenging dataset. The dataset is publicly available at https://git.openi.org.cn/PCLPlatform.Intelligence/Chinese_WPLC. © 2021 Association for Computational Linguistics
KW  - Computational linguistics
KW  - Data-set analysis
KW  - Language model
KW  - Prediction accuracy
KW  - Target words
KW  - Word prediction
KW  - Forecasting
PB  - Association for Computational Linguistics (ACL)
SN  - 978-195591709-4 (ISBN)
LA  - English
J2  - EMNLP - Conf. Empir. Methods Nat. Lang. Process., Proc.
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 1; Correspondence Address: D. Xiong; College of Intelligence and Computing, Tianjin University, Tianjin, China; email: dyxiong@tju.edu.cn; Conference name: 2021 Conference on Empirical Methods in Natural Language Processing, EMNLP 2021; Conference date: 7 November 2021 through 11 November 2021; Conference code: 177530
ER  -

TY  - CONF
AU  - Zhang, T.
AU  - Kishore, V.
AU  - Wu, F.
AU  - Weinberger, K.Q.
AU  - Artzi, Y.
TI  - BERTSCORE: EVALUATING TEXT GENERATION WITH BERT
PY  - 2020
T2  - 8th International Conference on Learning Representations, ICLR 2020
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85150641448&partnerID=40&md5=4314be8186e3fa6bb6bed9e94d985bab
AD  - Department of Computer Science, Cornell University, United States
AD  - Cornell Tech, Cornell University, United States
AD  - ASAPP Inc.
AB  - We propose BERTSCORE, an automatic evaluation metric for text generation. Analogously to common metrics, BERTSCORE computes a similarity score for each token in the candidate sentence with each token in the reference sentence. However, instead of exact matches, we compute token similarity using contextual embeddings. We evaluate using the outputs of 363 machine translation and image captioning systems. BERTSCORE correlates better with human judgments and provides stronger model selection performance than existing metrics. Finally, we use an adversarial paraphrase detection task to show that BERTSCORE is more robust to challenging examples when compared to existing metrics. © 2020 8th International Conference on Learning Representations, ICLR 2020. All rights reserved.
KW  - Automatic evaluation
KW  - Embeddings
KW  - Evaluation metrics
KW  - Human judgments
KW  - Image captioning
KW  - Machine translations
KW  - Model Selection
KW  - Performance
KW  - Similarity scores
KW  - Text generations
PB  - International Conference on Learning Representations, ICLR
LA  - English
J2  - Int. Conf. Learn. Represent., ICLR
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 1080; Conference name: 8th International Conference on Learning Representations, ICLR 2020; Conference code: 186995
ER  -

TY  - CONF
AU  - Choi, H.
AU  - Kim, J.
AU  - Joe, S.
AU  - Gwon, Y.
TI  - Evaluation of BERT and Albert sentence embedding performance on downstream NLP tasks
PY  - 2020
T2  - Proceedings - International Conference on Pattern Recognition
C7  - 9412102
SP  - 5482
EP  - 5487
DO  - 10.1109/ICPR48806.2021.9412102
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85110507539&doi=10.1109%2fICPR48806.2021.9412102&partnerID=40&md5=43628353e05a9d7ab4251fbbc10e1f87
AD  - Samsung SDS, Seoul, South Korea
AB  - Contextualized representations from a pre-trained language model are central to achieve a high performance on downstream NLP task. The pre-trained BERT and A Lite BERT (ALBERT) models can be fine-tuned to give state-of-the-art results in sentence-pair regressions such as semantic textual similarity (STS) and natural language inference (NLI). Although BERT-based models yield the [CLS] token vector as a reasonable sentence embedding, the search for an optimal sentence embedding scheme remains an active research area in computational linguistics. This paper explores on sentence embedding models for BERT and ALBERT. In particular, we take a modified BERT network with siamese and triplet network structures called Sentence-BERT (SBERT) and replace BERT with ALBERT to create Sentence-ALBERT (SALBERT). We also experiment with an outer CNN sentence-embedding network for SBERT and SALBERT. We evaluate performances of all sentence-embedding models considered using the STS and NLI datasets. The empirical results indicate that our CNN architecture improves ALBERT models substantially more than BERT models for STS benchmark. Despite significantly fewer model parameters, ALBERT sentence embedding is highly competitive to BERT in downstream NLP evaluations. © 2020 IEEE
KW  - Computational linguistics
KW  - Natural language processing systems
KW  - Pattern recognition
KW  - Semantics
KW  - Embedding network
KW  - Language model
KW  - Model parameters
KW  - Natural languages
KW  - Network structures
KW  - Pair regression
KW  - State of the art
KW  - Textual similarities
KW  - Embeddings
PB  - Institute of Electrical and Electronics Engineers Inc.
SN  - 10514651 (ISSN); 978-172818808-9 (ISBN)
LA  - English
J2  - Proc. Int. Conf. Pattern Recognit.
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 43; Conference name: 25th International Conference on Pattern Recognition, ICPR 2020; Conference date: 10 January 2021 through 15 January 2021; Conference code: 169954; CODEN: PICRE
ER  -

TY  - JOUR
AU  - Yang, F.
AU  - Li, H.
AU  - Sheng, C.
AU  - Huang, H.
AU  - Xiong, T.
AU  - Zhang, X.
TI  - Reliability evaluation model of cascaded multiport power electronic transformer and its application
ST  - 多端口级联式电力电子变压器可靠性评估模型及其应用
PY  - 2019
T2  - Dianli Xitong Baohu yu Kongzhi/Power System Protection and Control
VL  - 47
IS  - 20
SP  - 41
EP  - 49
DO  - 10.19783/j.cnki.pspc.181417
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85075649342&doi=10.19783%2fj.cnki.pspc.181417&partnerID=40&md5=ca274eba0698864dc490d2f3f750d7f2
AD  - Electric Power Research Institute of Guangdong Power Grid Co., Ltd., Guangzhou, 510080, China
AD  - Sichuan Energy Internet Research Institute, Tsinghua University, Chengdu, 610042, China
AB  - The cascaded multiport Power Electronic Transformer (PET) is a key equipment for future distribution grid with multi-voltage level and AC/DC hybrid feature, whose reliability has significant effect on the distribution grid reliability level. First, the typical topological structure and working principle of cascaded multiport PET are analyzed. Secondly, the reliability evaluation model for PET considering the device redundancy is established based on the engineering reliability theory. Then the effect of cascaded multiport PET on the AC/DC hybrid distribution network reliability is analyzed. Finally, the case studies are provided with a ‘hand in hand’ AC/DC hybrid power distribution network structure. The PET reliability levels under different design patterns and the redundancy levels are calculated. The influence of PET on reliability of AC/DC hybrid distribution system and its sensitivity analysis are carried out, which verifies the correctness and validity of the proposed algorithm. © 2019, Power System Protection and Control Press. All right reserved.
KW  - AC/DC hybrid distribution network
KW  - Cascaded multiport
KW  - Device redundancy
KW  - Power electronic transformer
KW  - Reliability evaluation
KW  - Electric power system protection
KW  - Power electronics
KW  - Reliability analysis
KW  - Reliability theory
KW  - Sensitivity analysis
KW  - Transformer protection
KW  - AC/DC hybrid distribution network
KW  - Cascaded multiport
KW  - Device redundancy
KW  - Distribution grid
KW  - Evaluation models
KW  - Multi-port
KW  - Power Electronics Transformer
KW  - Reliability Evaluation
KW  - Reliability level
KW  - Transformer applications
KW  - Redundancy
PB  - Power System Protection and Control Press
SN  - 16743415 (ISSN)
LA  - Chinese
J2  - Dianli Xitong Baohu yu Kongzhi
M3  - Article
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 16
ER  -

TY  - CONF
AU  - Zaczynska, K.
AU  - Feldhus, N.
AU  - Schwarzenberg, R.
AU  - Gabryszak, A.
AU  - Möller, S.
TI  - Evaluating German transformer language models with syntactic agreement tests
PY  - 2020
T2  - CEUR Workshop Proceedings
VL  - 2624
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85088408587&partnerID=40&md5=62c73990d1c108519dcbd748697e2591
AD  - German Research Center for Artificial Intelligence, DFKI, Germany
AB  - Pre-trained transformer language models (TLMs) have recently refashioned natural language processing (NLP): Most state-of-the-art NLP models now operate on top of TLMs to benefit from contextualization and knowledge induction. To explain their success, the scientific community conducted numerous analyses. Besides other methods, syntactic agreement tests were utilized to analyse TLMs. Most of the studies were conducted for the English language, however. In this work, we analyse German TLMs. To this end, we design numerous agreement tasks, some of which consider peculiarities of the German language. Our experimental results show that state-of-the-art German TLMs generally perform well on agreement tasks, but we also identify and discuss syntactic structures that push them to their limits. Copyright © 2020 for this paper by its authors.
KW  - Computational linguistics
KW  - Electric transformer testing
KW  - Syntactics
KW  - Text mining
KW  - Contextualization
KW  - English languages
KW  - German language
KW  - Language model
KW  - NAtural language processing
KW  - Scientific community
KW  - State of the art
KW  - Syntactic structure
KW  - Natural language processing systems
A2  - Ebling S.
A2  - Tuggener D.
A2  - Hurlimann M.
A2  - Cieliebak M.
A2  - Volk M.
PB  - CEUR-WS
SN  - 16130073 (ISSN)
LA  - English
J2  - CEUR Workshop Proc.
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 0; Conference name: 5th Swiss Text Analytics Conference and 16th Conference on Natural Language Processing, SWISSTEXT and KONVENS 2020; Conference date: 23 June 2020 through 25 June 2020; Conference code: 161235
ER  -

TY  - CONF
AU  - Lin, Z.
AU  - Tang, S.
AU  - Peng, G.
AU  - Zhang, Y.
AU  - Zhong, Z.
TI  - An artificial neural network model with Yager composition theory for transformer state assessment
PY  - 2017
T2  - Proceedings of 2017 IEEE 2nd Advanced Information Technology, Electronic and Automation Control Conference, IAEAC 2017
C7  - 8054097
SP  - 652
EP  - 655
DO  - 10.1109/IAEAC.2017.8054097
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85034601864&doi=10.1109%2fIAEAC.2017.8054097&partnerID=40&md5=af1dfaa19bc81e7ec6e4113b9f503d1c
AD  - Guangdong Power Grid Corporation Huizhou Power Supply Bureau, Huizhou, Guangdong, 516000, China
AB  - Oil-immersed transformer is one of the key equipment in power system. The state assessment is an important mean to ensure the normal operation of power transformer. Traditional transformer state assessment uses a single standard, which cannot get the ideal effect. In addition, different types of status information in power transformer gives different evaluation results, which makes equipment management personnel difficult to make decision. Taking into account the these defects, this paper proposes an artificial neural network model with Yager composition theory for transformer state assessment, which chooses the raw data of state variables as the input of artificial neural network, and the output vectors of artificial neural network are used as the preliminary evaluation results. As for the conflicting evaluation results from different kinds of evidence, this paper uses the Yager evidence synthesis theory to fuse the various evaluation results of the transformer status. Related experiments based on the established model are performed on multiple sets of samples. The results show that this artificial neural network model with Yager composition theory has a better effect than traditional models. © 2017 IEEE.
KW  - Artificial neural network
KW  - Data fusion
KW  - Power transformer
KW  - State assessment
KW  - Yager composition theory
KW  - Data fusion
KW  - Human resource management
KW  - Neural networks
KW  - Power transformers
KW  - Artificial neural network modeling
KW  - Equipment management
KW  - Evaluation results
KW  - Oil immersed transformers
KW  - State assessment
KW  - Status informations
KW  - Traditional models
KW  - Yager composition theory
KW  - Oil filled transformers
A2  - Xu B.
PB  - Institute of Electrical and Electronics Engineers Inc.
SN  - 978-146738977-8 (ISBN)
LA  - English
J2  - Proc. IEEE Adv. Inf. Technol., Electron. Autom. Control Conf., IAEAC
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 8; Conference name: 2nd IEEE Advanced Information Technology, Electronic and Automation Control Conference, IAEAC 2017; Conference date: 25 March 2017 through 26 March 2017; Conference code: 130957
ER  -

TY  - CONF
AU  - Kakwani, D.
AU  - Kunchukuttan, A.
AU  - Golla, S.
AU  - Gokul, N.C.
AU  - Bhattacharyya, A.
AU  - Khapra, M.M.
AU  - Kumar, P.
TI  - IndicNLPSuite: Monolingual corpora, evaluation benchmarks and pre-trained multilingual language models for Indian languages
PY  - 2020
T2  - Findings of the Association for Computational Linguistics Findings of ACL: EMNLP 2020
SP  - 4948
EP  - 4961
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85098840778&partnerID=40&md5=1613730f407d41c55093cc0ac9aeb142
AD  - Robert Bosch Centre for Data Science and AI, IIT Madras, India
AD  - Microsoft India, India
AD  - AI4Bharat
AB  - In this paper, we introduce NLP resources for 11 major Indian languages from two major language families. These resources include: (a) large-scale sentence-level monolingual corpora, (b) pre-trained word embeddings, (c) pre-trained language models, and (d) multiple NLU evaluation datasets (IndicGLUE benchmark). The monolingual corpora contains a total of 8.8 billion tokens across all 11 languages and Indian English, primarily sourced from news crawls. The word embeddings are based on FastText, hence suitable for handling morphological complexity of Indian languages. The pre-trained language models are based on the compact ALBERT model. Lastly, we compile the IndicGLUE benchmark for Indian language NLU. To this end, we create datasets for the following tasks: Article Genre Classification, Headline Prediction, Wikipedia Section-Title Prediction, Cloze-style Multiple choice QA, Winograd NLI and COPA. We also include publicly available datasets for some Indic languages for tasks like Named Entity Recognition, Cross-lingual Sentence Retrieval, Paraphrase detection, etc. Our embeddings are competitive or better than existing pre-trained embeddings on multiple tasks. We hope that the availability of the dataset will accelerate Indic NLP research which has the potential to impact more than a billion people. It can also help the community in evaluating advances in NLP over a more diverse pool of languages. The data and models are available at https://indicnlp.ai4bharat.org. © 2020 Association for Computational Linguistics
KW  - C (programming language)
KW  - Classification (of information)
KW  - Computational linguistics
KW  - HTTP
KW  - Large dataset
KW  - Natural language processing systems
KW  - Article genres
KW  - Embeddings
KW  - Genre classification
KW  - Indian languages
KW  - Language model
KW  - Large-scales
KW  - Morphological complexity
KW  - Multiple choice
KW  - Sentence level
KW  - Wikipedia
KW  - Embeddings
PB  - Association for Computational Linguistics (ACL)
SN  - 978-195214890-3 (ISBN)
LA  - English
J2  - Findings Assoc. Comp. Linguist. Findings ACL: EMNLP
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 235; Conference name: Findings of the Association for Computational Linguistics, ACL 2020: EMNLP 2020; Conference date: 16 November 2020 through 20 November 2020; Conference code: 172733
ER  -

TY  - CONF
AU  - O’Neill, J.
AU  - Bollegala, D.
TI  - Learning to Evaluate Neural Language Models
PY  - 2020
T2  - Communications in Computer and Information Science
VL  - 1215 CCIS
SP  - 123
EP  - 133
DO  - 10.1007/978-981-15-6168-9_11
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85088540478&doi=10.1007%2f978-981-15-6168-9_11&partnerID=40&md5=cc65c06bf4cda3a1a79a465185d0a9b6
AD  - Department of Computer Science, University of Liverpool, Liverpool, L69 3BX, United Kingdom
AB  - Evaluating the performance of neural network-based text generators and density estimators is challenging since no one measure perfectly evaluates language quality. Perplexity has been a mainstay metric for neural language models trained by maximizing the conditional log-likelihood. We argue perplexity alone is a naive measure since it does not explicitly take into account the semantic similarity between generated and target sentences. Instead, it relies on measuring the cross-entropy between the targets and predictions on the word-level, while ignoring alternative incorrect predictions that may be semantically similar and globally coherent, thus ignoring quality of neighbouring tokens that may be good candidates. This is particularly important when learning from smaller corpora where co-occurrences are even more sparse. Thus, this paper proposes the use of a pretrained model-based evaluation that assesses semantic and syntactic similarity between predicted sequences and target sequences. We argue that this is an improvement over perplexity which does not distinguish between incorrect predictions that vary in semantic distance to the target words. We find that models that outperform other models using perplexity as an evaluation metric on Penn-Treebank and WikiText-2, do not necessarily perform better on measures that evaluate using semantic similarity. © 2020, Springer Nature Singapore Pte Ltd.
KW  - Language models
KW  - Neural networks
KW  - Semantic evaluation
KW  - Computational linguistics
KW  - Forecasting
KW  - Natural language processing systems
KW  - Semantics
KW  - Density estimator
KW  - Evaluation metrics
KW  - Model-based evaluation
KW  - Semantic distance
KW  - Semantic similarity
KW  - Syntactic similarities
KW  - Target sequences
KW  - Text generators
KW  - Quality control
A2  - Nguyen L.-M.
A2  - Tojo S.
A2  - Phan X.-H.
A2  - Hasida K.
PB  - Springer
SN  - 18650929 (ISSN); 978-981156167-2 (ISBN)
LA  - English
J2  - Commun. Comput. Info. Sci.
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 0; Correspondence Address: J. O’Neill; Department of Computer Science, University of Liverpool, Liverpool, L69 3BX, United Kingdom; email: james.o-neill@liverpool.ac.uk; Conference name: 16th International Conference of the Pacific Association for Computational Linguistics, PACLING 2019; Conference date: 11 October 2019 through 13 October 2019; Conference code: 241929
ER  -

TY  - CONF
AU  - Sun, C.
AU  - Yang, Z.
TI  - Transfer Learning in Biomedical Named Entity Recognition: An Evaluation of BERT in the PharmaCoNER task
PY  - 2019
T2  - BioNLP-OST@EMNLP-IJNCLP 2019 - Proceedings of the 5th Workshop on BioNLP Open Shared Tasks
SP  - 100
EP  - 104
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85095278956&partnerID=40&md5=9b8d44aa88358f19dab02bda8280c38a
AD  - Dalian University of Technology, China
AB  - To date, a large amount of biomedical content has been published in non-English texts, especially for clinical documents. Therefore, it is of considerable significance to conduct Natural Language Processing (NLP) research in non-English literature. PharmaCoNER is the first Named Entity Recognition (NER) task to recognize chemical and protein entities from Spanish biomedical texts. Since there have been abundant resources in the NLP field, how to exploit these existing resources to a new task to obtain competitive performance is a meaningful study. Inspired by the success of transfer learning with language models, we introduce the BERT benchmark to facilitate the research of PharmaCoNER task. In this paper, we evaluate two baselines based on Multilingual BERT and BioBERT on the Pharma- CoNER corpus. Experimental results show that transferring the knowledge learned from source large-scale datasets to the target domain offers an effective solution for the PharmaCoNER task. c 2019 Association for Computational Linguistics. © 2019 BioNLP-OST@EMNLP-IJNCLP 2019 - Proceedings of the 5th Workshop on BioNLP Open Shared Tasks. All rights reserved.
KW  - Computational linguistics
KW  - Large dataset
KW  - Learning systems
KW  - Abundant resources
KW  - Biomedical named entity recognition
KW  - Biomedical text
KW  - Competitive performance
KW  - English literature
KW  - Language model
KW  - Large amounts
KW  - Large-scale datasets
KW  - Target domain
KW  - Natural language processing systems
PB  - Association for Computational Linguistics (ACL)
SN  - 978-195073782-6 (ISBN)
LA  - English
J2  - BioNLP-OST@EMNLP-IJNCLP - Proc. Workshop BioNLP Open Shar. Tasks
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 25; Correspondence Address: Z. Yang; Dalian University of Technology, China; email: yangzh@dlut.edu.cn; Conference name: 5th Workshop on BioNLP Open Shared Tasks, BioNLP-OST@EMNLP-IJNCLP 2019; Conference code: 172773
ER  -

TY  - CONF
AU  - Ji, Y.
AU  - Hu, L.
AU  - Liu, S.
AU  - Xu, Z.
AU  - Liu, Y.
AU  - Liu, K.
AU  - Tang, S.
AU  - Liu, Q.
AU  - Xiao, W.
TI  - MEFE: A Multi-fEature Knowledge Fusion and Evaluation Method Based on BERT
PY  - 2020
T2  - Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)
VL  - 12453 LNCS
SP  - 449
EP  - 462
DO  - 10.1007/978-3-030-60239-0_30
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85092725832&doi=10.1007%2f978-3-030-60239-0_30&partnerID=40&md5=a91121a39ccd5494af9346c5012e7c43
AD  - School of Computer Science, Nanjing University of Posts and Telecommunications, Nanjing, 210023, China
AD  - Jiangsu High Technology Research Key Laboratory for Wireless Sensor Networks, Nanjing, 210003, Jiangsu, China
AD  - Institue of High Performance Computing and Bigdata, Nanjing University of Posts and Telecommunications, Nanjing, 210003, Jiangsu, China
AD  - Nanjing Center of HPC China, Nanjing, 210003, Jiangsu, China
AD  - Jiangsu HPC and Intelligent Processing Engineer Research Center, Nanjing, 210003, Jiangsu, China
AD  - College of Educational Science and Technology, Nanjing University of Posts and Telecommunications, Nanjing, 210023, China
AB  - Knowledge fusion is an important part of constructing a knowledge graph. In recent years, with the development of major knowledge bases, the integration of multi-source knowledge bases is the focus and difficulty in the field of knowledge fusion. Due to the large differences in knowledge base structure, the efficiency and accuracy of fusion are not high. In response to this problem, this paper proposes MEFE (Multi-fEature Knowledge Fusion and Evaluation Method) based on BERT. MEFE comprehensively considers the attributes, descriptions and category characteristics of entities to perform knowledge fusion on multi-source knowledge bases. Firstly, MEFE uses entity category tags to build a category dictionary. Then, it vectorizes the category tags based on the dictionary and clusters the entities according to the category tags. Finally it uses BERT (Bidirectional Encoder Representation from Transformers) to calculate the entity similarity for the entity pairs in the same group. We calculate entity redundancy rate and information loss rate of knowledge base according to the fusion result, so as to evaluate the quality of the knowledge base. Experiments show that MEFE effectively improves the efficiency of knowledge fusion through clustering, and the use of BERT promotes the accuracy of fusion. © 2020, Springer Nature Switzerland AG.
KW  - BERT
KW  - Knowledge fusion
KW  - Multi-source knowledge base
KW  - Quality evaluation
KW  - Vectorization of category labels
KW  - Efficiency
KW  - Knowledge acquisition
KW  - Knowledge based systems
KW  - Knowledge representation
KW  - Parallel architectures
KW  - Entity similarities
KW  - Information loss
KW  - Knowledge base
KW  - Knowledge basis
KW  - Knowledge fusion
KW  - Knowledge graphs
KW  - Multi features
KW  - Multi-Sources
KW  - Quality control
A2  - Qiu M.
PB  - Springer Science and Business Media Deutschland GmbH
SN  - 03029743 (ISSN); 978-303060238-3 (ISBN)
LA  - English
J2  - Lect. Notes Comput. Sci.
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 2; Conference name: 20th International Conference on Algorithms and Architectures for Parallel Processing, ICA3PP 2020; Conference date: 2 October 2020 through 4 October 2020; Conference code: 249549
ER  -

TY  - CONF
AU  - Wilhelm, H.M.
AU  - Fernandes, P.O.
AU  - Pereira, T.K.
AU  - Santos, G.C.
AU  - Filho, D.A.
AU  - Mar, A.
AU  - Ribeiro, M.
TI  - Laboratory Model for Evaluation of Incipient Transformer Thermal Fault Involving Insulating
PY  - 2019
T2  - 2019 IEEE Electrical Insulation Conference, EIC 2019
C7  - 9046540
SP  - 120
EP  - 123
DO  - 10.1109/EIC43217.2019.9046540
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85083485994&doi=10.1109%2fEIC43217.2019.9046540&partnerID=40&md5=0324a8d5e49bbe2d13e34566a17c68ba
AD  - VEGOOR, Dept. Research and Innovation, Curitiba, Paraná, Brazil
AD  - GERA MARANHAO, Dept. Planning and Control, Miranda do Norte, Maranhão, Brazil
AB  - In order to age thermally upgraded kraft paper immersed in insulating oil without aging the oil, an 'aging device' was built in which a copper electric resistance was covered with insulating paper and the setup was immersed in insulating oil contained in a vessel. The oil was water cooled to keep its temperature below 60° C, while paper's temperature was raised up to 500 °C. The experiment allowed the determination of the CO2/CO rate variation against aging time and temperature. The generation of other decomposition products, namely furan compounds, methanol and ethanol was also determined against aging time and temperature. Paper aging status was also determined through degree of polymerization (DP). The aging of oil was also monitored. © 2019 IEEE.
KW  - 2-FAL
KW  - 2-furaldehyde
KW  - DGA
KW  - dissolving gases analyses
KW  - ethanol
KW  - furan compounds
KW  - insulating paper thermal degradation
KW  - methanol
KW  - thermal failure
KW  - Kraft paper
KW  - Oil filled transformers
KW  - Aging time and temperatures
KW  - Decomposition products
KW  - Degree of polymerization
KW  - Insulating paper
KW  - Laboratory models
KW  - Paper aging
KW  - Rate variation
KW  - Thermal faults
KW  - Insulation
PB  - Institute of Electrical and Electronics Engineers Inc.
SN  - 978-153867624-0 (ISBN)
LA  - English
J2  - IEEE Electr. Insul. Conf., EIC
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 0; Conference name: 2019 IEEE Electrical Insulation Conference, EIC 2019; Conference date: 16 June 2019 through 19 June 2019; Conference code: 158871
ER  -

TY  - CONF
AU  - Tevet, G.
AU  - Habib, G.
AU  - Shwartz, V.
AU  - Berant, J.
TI  - Evaluating text gans as language models
PY  - 2019
T2  - NAACL HLT 2019 - 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies - Proceedings of the Conference
VL  - 1
SP  - 2241
EP  - 2247
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85085547602&partnerID=40&md5=3e80e82770ecd3dfba920da96d4dac0b
AD  - School of Computer Science, Tel-Aviv University, Israel
AD  - Department of Electrical Engineering, Tel-Aviv University
AD  - Computer Science Department, Bar-Ilan University, Israel
AD  - Allen Institute for Artificial Intelligence, United States
AB  - Generative Adversarial Networks (GANs) are a promising approach for text generation that, unlike traditional language models (LM), does not suffer from the problem of “exposure bias”. However, A major hurdle for understanding the potential of GANs for text generation is the lack of a clear evaluation metric. In this work, we propose to approximate the distribution of text generated by a GAN, which permits evaluating them with traditional probability-based LM metrics. We apply our approximation procedure on several GAN-based models and show that they currently perform substantially worse than state-of-the-art LMs. Our evaluation procedure promotes better understanding of the relation between GANs and LMs, and can accelerate progress in GAN-based text generation. © 2019 Association for Computational Linguistics
KW  - Probability distributions
KW  - Adversarial networks
KW  - Approximation procedure
KW  - Evaluation metrics
KW  - GaN based
KW  - Language model
KW  - State of the art
KW  - Text generations
KW  - Computational linguistics
PB  - Association for Computational Linguistics (ACL)
SN  - 978-195073713-0 (ISBN)
LA  - English
J2  - NAACL HLT - Conf. N. Am. Chapter Assoc. Comput. Linguistics: Hum. Lang. Technol. - Proc. Conf.
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 6; Conference name: 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, NAACL HLT 2019; Conference date: 2 June 2019 through 7 June 2019; Conference code: 159851
ER  -

TY  - CONF
AU  - Jiang, M.
AU  - D’Souza, J.
AU  - Auer, S.
AU  - Downie, J.S.
TI  - Improving Scholarly Knowledge Representation: Evaluating BERT-Based Models for Scientific Relation Classification
PY  - 2020
T2  - Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)
VL  - 12504 LNCS
SP  - 3
EP  - 19
DO  - 10.1007/978-3-030-64452-9_1
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85097538751&doi=10.1007%2f978-3-030-64452-9_1&partnerID=40&md5=4ca0ab57eedd977fe7423802223a5547
AD  - University of Illinois at Urbana-Champaign, Champaign, United States
AD  - TIB Leibniz Information Centre for Science and Technology and L3S Research Center at Leibniz University of Hannover, Hanover, Germany
AB  - With the rapid growth of research publications, there is a vast amount of scholarly knowledge that needs to be organized in digital libraries. To deal with this challenge, techniques relying on knowledge-graph structures are being advocated. Within such graph-based pipelines, inferring relation types between related scientific concepts is a crucial step. Recently, advanced techniques relying on language models pre-trained on large corpora have been popularly explored for automatic relation classification. Despite the remarkable contributions that have been made, many of these methods were evaluated under different scenarios, which limits their comparability. To address this shortcoming, we present a thorough empirical evaluation of eight Bert-based classification models by focusing on two key factors: 1) Bert model variants, and 2) classification strategies. Experiments on three corpora show that domain-specific pre-training corpus benefits the Bert-based classification model to identify the type of scientific relations. Although the strategy of predicting a single relation each time achieves a higher classification accuracy than the strategy of identifying multiple relation types simultaneously in general, the latter strategy demonstrates a more consistent performance in the corpus with either a large or small number of annotations. Our study aims to offer recommendations to the stakeholders of digital libraries for selecting the appropriate technique to build knowledge-graph-based systems for enhanced scholarly information organization. © 2020, Springer Nature Switzerland AG.
KW  - Digital library
KW  - Information extraction
KW  - Knowledge graphs
KW  - Neural machine learning
KW  - Scholarly text mining
KW  - Semantic relation classification
KW  - Graph structures
KW  - Graphic methods
KW  - Knowledge representation
KW  - Appropriate techniques
KW  - Classification accuracy
KW  - Classification models
KW  - Consistent performance
KW  - Empirical evaluations
KW  - Information organization
KW  - Knowledge graphs
KW  - Relation classifications
KW  - Digital libraries
A2  - Ishita E.
A2  - Pang N.L.
A2  - Zhou L.
PB  - Springer Science and Business Media Deutschland GmbH
SN  - 03029743 (ISSN); 978-303064451-2 (ISBN)
LA  - English
J2  - Lect. Notes Comput. Sci.
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 6; Correspondence Address: M. Jiang; University of Illinois at Urbana-Champaign, Champaign, United States; email: mjiang17@illinois.edu; Conference name: 22nd International Conference on Asia-Pacific Digital Libraries, ICADL 2020; Conference date: 30 November 2020 through 1 December 2020; Conference code: 252499
ER  -

TY  - JOUR
AU  - Corea-Araujo, J.A.
AU  - Martinez-Velasco, J.A.
AU  - González-Molina, F.
AU  - Barrado-Rodrigo, J.A.
AU  - Guasch-Pesquer, L.
AU  - Castro-Aranda, F.
TI  - Validation of single-phase transformer model for ferroresonance analysis
PY  - 2018
T2  - Electrical Engineering
VL  - 100
IS  - 3
SP  - 1339
EP  - 1349
DO  - 10.1007/s00202-017-0594-3
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85021730197&doi=10.1007%2fs00202-017-0594-3&partnerID=40&md5=ba29787a7c4c24b5bf226481576611b9
AD  - Universitat Politecnica de Catalunya, Barcelona, Spain
AD  - Universitat Rovira i Virgili, Tarragona, Spain
AD  - Universidad del Valle, Cali, Colombia
AB  - The validation of power system component models for transient analysis implies the use of data recorded from either field measurements or laboratory tests. This task can be particularly difficult when the transient process is quite nonlinear, as it occurs in ferroresonance phenomena. Up-to-date research has proved that the π model can be more accurate than the classical T model for representing the transient response of transformers with a high level of saturation. This paper proposes a new technique for representing and implementing hysteresis in low-frequency transformer models using the π approach. The ultimate goal is to validate the addition of hysteresis effects in the π model for single-phase transformer representation in ferroresonance studies. © 2017, Springer-Verlag GmbH Germany.
KW  - EMTP
KW  - Experimental measurements
KW  - Ferroresonance
KW  - Hysteresis
KW  - Transformer modeling
KW  - Electric surges
KW  - Hysteresis
KW  - Magnetic resonance
KW  - EMTP
KW  - Ferroresonance
KW  - Hysteresis effect
KW  - Low-frequency transformers
KW  - Power system components
KW  - Single-phase transformers
KW  - Transformer modeling
KW  - Transient process
KW  - Transient analysis
PB  - Springer Verlag
SN  - 09487921 (ISSN)
LA  - English
J2  - Electr Eng
M3  - Article
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 5; Correspondence Address: J.A. Corea-Araujo; Universitat Politecnica de Catalunya, Barcelona, Spain; email: javier.arturo.corea@upc.edu; CODEN: EENGF
ER  -

TY  - CONF
AU  - Paraschiv, A.
AU  - Cercel, D.-C.
TI  - UPB at germeval-2020 task 3: Assessing summaries for German texts using BERTScore and Sentence-BERT
PY  - 2020
T2  - CEUR Workshop Proceedings
VL  - 2624
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85088411080&partnerID=40&md5=eeeeefc02b79419cf35b0cfa3d7885d2
AD  - University Politehnica of Bucharest, Computer Science and Engineering Department, Romania
AB  - The overwhelming amount of online text information available today has increased the need for more research on its automatic summarization. In this work, we describe our participation in GermEval-2020, Task 3: German Text Summarization. We compare two BERT-based metrics, Sentence-BERT and BERTScore, to automatically evaluate the quality of summaries in the German language. Our lowest error rate achieved was 31.9925, ranking us in 4th place out of 6 participating teams. Copyright © 2020 for this paper by its authors.
KW  - Text mining
KW  - Automatic summarization
KW  - Error rate
KW  - German language
KW  - Participating teams
KW  - Text information
KW  - Text summarization
KW  - Natural language processing systems
A2  - Ebling S.
A2  - Tuggener D.
A2  - Hurlimann M.
A2  - Cieliebak M.
A2  - Volk M.
PB  - CEUR-WS
SN  - 16130073 (ISSN)
LA  - English
J2  - CEUR Workshop Proc.
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 1; Conference name: 5th Swiss Text Analytics Conference and 16th Conference on Natural Language Processing, SWISSTEXT and KONVENS 2020; Conference date: 23 June 2020 through 25 June 2020; Conference code: 161235
ER  -

TY  - JOUR
AU  - Li, J.
AU  - Li, J.
AU  - Zhang, S.
TI  - Topology-correct Duality-based Transformer Transient Model and Its Application in DC Bias Assessment
ST  - 变压器拓扑修正暂态模型及其在直流偏磁耐受评估中的应用
PY  - 2019
T2  - Dianwang Jishu/Power System Technology
VL  - 43
IS  - 9
SP  - 3439
EP  - 3446
DO  - 10.13335/j.1000-3673.pst.2019.0190
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85072963567&doi=10.13335%2fj.1000-3673.pst.2019.0190&partnerID=40&md5=7d155182304e23537e139ac36848e7d4
AD  - China Electric Power Research Institute, Haidian District, Beijing, 100192, China
AD  - State Grid Corporation of China, Xicheng District, Beijing, 100031, China
AB  - Recently, transformer DC bias was on increasing rise with construction and operation of UHV transmission systems in China. It is essentially important to assess the tolerance level of transformer under DC bias. It was a key issue to calculate the exciting current of transformer under DC bias condition. In this paper, a topology-correct transformer transient model taking into account the structural characteristics and nonlinear features of iron core was proposed within duality principle of magnetic and electric circuits to calculate the exciting current of transformer under DC bias. Numerical results demonstrated a good consistency between computed current and measured data. The impact of major parameters, e.g. material type, air gap between core and yoke, zero sequence impedance, and etc. on transformer exciting current under DC bias were verified. It was concluded that the influence of core material type could be neglected, while the air-gap distance and leakage inductance should be carefully chosen and adjusted during computing. The proposed model and conclusions of this paper can provide reference for transformer DC bias assessment in engineering application. © 2019, Power System Technology Press. All right reserved.
KW  - DC bias
KW  - EMTP
KW  - Hysteresis modelling
KW  - Topology-correct duality-based transformer transient model
KW  - Coremaking
KW  - Topology
KW  - UHV power transmission
KW  - DC bias
KW  - EMTP
KW  - Engineering applications
KW  - Hysteresis modelling
KW  - Structural characteristics
KW  - Transformer transients
KW  - Uhv transmission systems
KW  - Zero sequence impedance
KW  - DC transformers
PB  - Power System Technology Press
SN  - 10003673 (ISSN)
LA  - Chinese
J2  - Dianwang Jishu
M3  - Article
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 8; Correspondence Address: J. Li; China Electric Power Research Institute, Beijing, Haidian District, 100192, China; email: lljjzh@163.com; CODEN: DIJIE
ER  -

TY  - CONF
AU  - Condra, L.
AU  - Alagappan, A.
AU  - Hillman, C.
TI  - SAE ARP6338: Process for assessment and mitigation of aging and potential early wearout of Life-Limited microcircuits (LLM)
PY  - 2019
T2  - SAE Technical Papers
VL  - 2019-April
IS  - April
DO  - 10.4271/2019-01-1254
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85064630183&doi=10.4271%2f2019-01-1254&partnerID=40&md5=4678e81b7220151becff5d1b6b7016d7
AD  - DfR Solutions, United States
AB  - This paper describes a Reliability Physics Analysis process to assess aging and the potential for early wearout of microcircuits, as documented in SAE ARP6338. As microcircuit feature sizes (gate length, line width, etc.) continue to shrink to near atomic levels, they become increasingly susceptible to aging mechanisms such as Electromigration, Time-Dependent Dielectric Breakdown, Hot Carrier Injection and Bias Temperature Instability effects. These mechanisms are driven by voltage, current and thermal operating stresses resulting in shorter times for aging to progress to the point where wearout can occur. If the times to wearout are shorter than the required lifetimes of the microcircuits in their applications, the microcircuits are called Life-Limited Microcircuits. A brief overview of these aging mechanisms and their impact on the long-life electronics systems used in Aerospace, Automotive, Defense, and other High Performance industries is provided. A summary of the SAE ARP6338 approach and implementation recommendations is also provided along with its importance to automotive Advanced Driver-Assistance Systems and autonomous electronic systems. © 2019 SAE International. All Rights Reserved.
KW  - Automobile drivers
KW  - Automobile electronic equipment
KW  - Dielectric materials
KW  - Field effect transistors
KW  - Hot carriers
KW  - Reliability analysis
KW  - Aging mechanism
KW  - Autonomous electronics
KW  - Bias temperature instability
KW  - Electronics system
KW  - Hot carrier injection
KW  - Operating stress
KW  - Physics analysis
KW  - Time dependent dielectric breakdown
KW  - Advanced driver assistance systems
PB  - SAE International
SN  - 01487191 (ISSN)
LA  - English
J2  - SAE Techni. Paper.
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 0; Conference name: SAE World Congress Experience, WCX 2019; Conference date: 9 April 2019 through 11 April 2019; Conference code: 146987
ER  -

TY  - CONF
AU  - Teo, D.
TI  - TR at SemEval-2020 Task 4: Exploring the Limits of Language-model-based Common Sense Validation
PY  - 2020
T2  - 14th International Workshops on Semantic Evaluation, SemEval 2020 - co-located 28th International Conference on Computational Linguistics, COLING 2020, Proceedings
SP  - 601
EP  - 608
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85095372454&partnerID=40&md5=8d46de3e580634ddb3eb99610be6e196
AD  - Center for AI and Cognitive Computing Thomson Reuters, Toronto, Canada
AB  - In this paper, we present our submission for subtask A of the Common Sense Validation and Explanation (ComVE) shared task. We examine the ability of large-scale pre-trained language models to distinguish commonsense from non-commonsense statements. We also explore the utility of external resources that aim to supplement the world knowledge inherent in such language models, including commonsense knowledge graph embedding models, word concreteness ratings, and text-to-image generation models. We find that such resources provide insignificant gains to the performance of fine-tuned language models. We also provide a qualitative analysis of the limitations of the language model fine-tuned to this task. © 2020 14th International Workshops on Semantic Evaluation, SemEval 2020 - co-located 28th International Conference on Computational Linguistics, COLING 2020, Proceedings. All rights reserved.
KW  - Computational linguistics
KW  - Semantics
KW  - Common sense
KW  - Commonsense knowledge
KW  - External resources
KW  - Graph embeddings
KW  - Knowledge graphs
KW  - Language model
KW  - Large-scales
KW  - Model-based OPC
KW  - Subtask
KW  - World knowledge
KW  - Knowledge graph
A2  - Herbelot A.
A2  - Zhu X.
A2  - Palmer A.
A2  - Schneider N.
A2  - May J.
A2  - Shutova E.
PB  - International Committee for Computational Linguistics
SN  - 978-195214831-6 (ISBN)
LA  - English
J2  - Int. Workshops Semant. Eval., SemEval - co-located Int. Conf. Comput. Linguist., COLING , Proc.
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 1; Correspondence Address: D. Teo; Center for AI and Cognitive Computing Thomson Reuters, Toronto, Canada; email: don.teo@tr.com; Conference name: 14th International Workshops on Semantic Evaluation, SemEval 2020; Conference date: 12 December 2020 through 13 December 2020; Conference code: 174265
ER  -

TY  - CONF
AU  - Wang, H.
AU  - Yang, Q.
AU  - Li, Y.
AU  - Wang, J.
AU  - Zhao, Y.
TI  - Model design and calculation validation for leakage magnetic field and temperature rise of transformer core tie-plate
PY  - 2018
T2  - Proceedings of 2018 IEEE International Conference on Applied Superconductivity and Electromagnetic Devices, ASEMD 2018
C7  - 8558939
DO  - 10.1109/ASEMD.2018.8558939
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85060143417&doi=10.1109%2fASEMD.2018.8558939&partnerID=40&md5=122a4f6ec708723c900dc0a61fdf5fef
AD  - State Key Laboratory of Reliability and Intelligence of Electrical Equipment, Hebei University of Technology, Tianjin, 300130, China
AD  - Institute of power transformation technology, Baoding Tianwei baobian electric Co.Ltd., Baoding, 071056, China
AB  - According to the actual structure and operation of the transformer, the core tie-plate test model is designed. In order to save memory and computation time, the stray losses in core tie-plate, tank and other structural parts are calculated by using surface impedance method, and core tie-plate temperature rise in different schemes are accurately calculated by magneto-thermal-fluid coupling method. The error of simulation values obtained by this method and experimental values can meet project needs, and it shows that the actual distribution of the surface temperature rise can be reflected more accurately by the calculation method used in this paper, which provides a more efficient and reliable analysis method to prevent overheating of transformer core tie-plate. © 2018 IEEE.
KW  - Magneto-thermal-fluid coupling
KW  - Surface impedance method
KW  - Temperature rise
KW  - Transformer core tie-plate
KW  - Electric transformer testing
KW  - Electromagnets
KW  - Magnetic leakage
KW  - Experimental values
KW  - Leakage magnetic field
KW  - Plate temperature
KW  - Surface impedance methods
KW  - Surface temperatures
KW  - Temperature rise
KW  - Thermal fluids
KW  - Transformer core
KW  - Plates (structural components)
PB  - Institute of Electrical and Electronics Engineers Inc.
SN  - 978-153862494-4 (ISBN)
LA  - English
J2  - Proc. IEEE Int. Conf. Appl. Supercond. Electromagn. Devices, ASEMD
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 1; Conference name: 2018 IEEE International Conference on Applied Superconductivity and Electromagnetic Devices, ASEMD 2018; Conference date: 15 April 2018 through 18 April 2018; Conference code: 143416
ER  -

TY  - JOUR
AU  - Guan, Y.
AU  - Xu, L.
AU  - You, X.
AU  - Gao, Q.
AU  - Tang, W.
AU  - Mi, Q.
AU  - Cao, Y.
AU  - Zhu, Z.
AU  - Xi, J.
AU  - Liu, W.
AU  - Luan, Y.
AU  - Yao, J.
TI  - Evaluation of genotoxicity of e-cigarette aerosol using gpt delta transgenic mouse model
ST  - 应用gpt delta转基因小鼠模型评价电子烟气溶胶的遗传毒性
PY  - 2019
T2  - Tobacco Science and Technology
VL  - 52
IS  - 4
SP  - 51
EP  - 56
DO  - 10.16135/j.issn1002-0861.2017.0498
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85068686999&doi=10.16135%2fj.issn1002-0861.2017.0498&partnerID=40&md5=ed1bd5ac33c7a3abcb3101d8f1d6d112
AD  - Key Laboratory of Tobacco Chemistry of Yunnan, Technology Center of China Tobacco Yunnan Industrial Co., Ltd., Kunming, 650231, China
AD  - Hongqiao International Institute of Medicine, School of Public Health, Shanghai Jiao Tong University, Shanghai, 200025, China
AD  - Shanghai Integrated Biotech Solutions Co., Ltd., Shanghai, 201203, China
AD  - Institute of Environmental Pollution and Health, School of Environmental and Chemical Engineering, Shanghai University, Shanghai, 200444, China
AB  - In this study, gpt transgenic mouse model was used to evaluate the genotoxicity of e-cigarette aerosol. Taking peripheral blood reticulocytes as experimental assay, the effects of e-cigarette aerosol on chromosome damage were detected by micronucleus test, and the mutagenic effect of e-cigarette aerosol was detected by Pig-a gene mutation test. Using lung tissue as experimental assay, the effects of e-cigarette aerosol on the gene expression of mmu-miR-34a, mmu-let-7a, Akt1, Il-6 and Tnf-a were detected by real-time fluorescent quantitative PCR. The results showed that comparing with the control group, micronucleus frequency, Pig-a mutation frequency and RET% were not significantly different in the low- and high-dose e-cigarette aerosol group and the low- and high-dose group of 3R4F reference cigarette smoke (P>0.05). The mmu-miR-34a, Il-6 and Tnf-a in the low- and high-dose groups of e-cigarette aerosol significantly decreased (P< 0.05), and the expression of mmu-let-7a increased (P<0.05) in the high-dose group. The mmu-miR-34a, mmu-let-7a and Tnf-a in the high-dose group of 3R4F reference cigarette smoke significantly reduced (P< 0.05).In conclusion, the genotoxicity of e-cigarette aerosol could not be detected in gpt delta transgenic mice model, however e-cigarette aerosol significantly affected the mRNA expression of DNA damage and inflammation- related genes. © 2019, Editorial Office of Tobacco Science and Technology. All right reserved.
KW  - Aerosol
KW  - E-cigarette
KW  - Genotoxicity
KW  - Gpt delta transgenic mice
KW  - Mutation
KW  - Pig-a gene
PB  - Editorial Office of Tobacco Science and Technology
SN  - 10020861 (ISSN)
LA  - Chinese
J2  - Tob. Sci. Technol.
M3  - Article
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 0; Correspondence Address: J. Yao; Key Laboratory of Tobacco Chemistry of Yunnan, Technology Center of China Tobacco Yunnan Industrial Co., Ltd., Kunming, 650231, China; email: jhyao_2007@126.com
ER  -

TY  - CONF
AU  - Gârbacea, C.
AU  - Carton, S.
AU  - Yan, S.
AU  - Mei, Q.
TI  - Judge the Judges: A large-scale evaluation study of neural language models for online review generation
PY  - 2019
T2  - EMNLP-IJCNLP 2019 - 2019 Conference on Empirical Methods in Natural Language Processing and 9th International Joint Conference on Natural Language Processing, Proceedings of the Conference
SP  - 3968
EP  - 3981
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85084320934&partnerID=40&md5=e16ab2e1e38e2284a644be3ef0312c6d
AD  - Department of EECS, University of Michigan, Ann Arbor, MI, United States
AD  - School of Information, University of Michigan, Ann Arbor, MI, United States
AB  - We conduct a large-scale, systematic study to evaluate the existing evaluation methods for natural language generation in the context of generating online product reviews. We compare human-based evaluators with a variety of automated evaluation procedures, including discriminative evaluators that measure how well machine-generated text can be distinguished from human-written text, as well as word overlap metrics that assess how similar the generated text compares to human-written references. We determine to what extent these different evaluators agree on the ranking of a dozen of state-of-the-art generators for online product reviews. We find that human evaluators do not correlate well with discriminative evaluators, leaving a bigger question of whether adversarial accuracy is the correct objective for natural language generation. In general, distinguishing machine-generated text is challenging even for human evaluators, and human decisions correlate better with lexical overlaps. We find lexical diversity an intriguing metric that is indicative of the assessments of different evaluators. A post-experiment survey of participants provides insights into how to evaluate and improve the quality of natural language generation systems. © 2019 Association for Computational Linguistics
KW  - Large scale systems
KW  - Natural language processing systems
KW  - Petroleum reservoir evaluation
KW  - Surveys
KW  - Automated evaluation
KW  - Evaluation methods
KW  - Evaluation study
KW  - Machine-generated texts
KW  - Natural language generation
KW  - Natural language generation systems
KW  - Online product reviews
KW  - Systematic study
KW  - Quality control
PB  - Association for Computational Linguistics
SN  - 978-195073790-1 (ISBN)
LA  - English
J2  - EMNLP-IJCNLP - Conf. Empir. Methods Nat. Lang. Process. Int. Jt. Conf. Nat. Lang. Process., Proc. Conf.
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 11; Conference name: 2019 Conference on Empirical Methods in Natural Language Processing and 9th International Joint Conference on Natural Language Processing, EMNLP-IJCNLP 2019; Conference date: 3 November 2019 through 7 November 2019; Conference code: 159367
ER  -

TY  - CONF
AU  - Spithourakis, G.P.
AU  - Riedel, S.
TI  - Numeracy for language models: Evaluating and improving their ability to predict numbers
PY  - 2018
T2  - ACL 2018 - 56th Annual Meeting of the Association for Computational Linguistics, Proceedings of the Conference (Long Papers)
VL  - 1
SP  - 2104
EP  - 2115
DO  - 10.18653/v1/p18-1196
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85063092010&doi=10.18653%2fv1%2fp18-1196&partnerID=40&md5=fb2561d0e1ecf9dd921bc6425226231d
AD  - Department of Computer Science, University College London, United Kingdom
AB  - Numeracy is the ability to understand and work with numbers. It is a necessary skill for composing and understanding documents in clinical, scientific, and other technical domains. In this paper, we explore different strategies for modelling numerals with language models, such as memorisation and digit-by-digit composition, and propose a novel neural architecture that uses a continuous probability density function to model numerals from an open vocabulary. Our evaluation on clinical and scientific datasets shows that using hierarchical models to distinguish numerals from words improves a perplexity metric on the subset of numerals by 2 and 4 orders of magnitude, respectively, over non-hierarchical models. A combination of strategies can further improve perplexity. Our continuous probability density function model reduces mean absolute percentage errors by 18% and 54% in comparison to the second best strategy for each dataset, respectively. © 2018 Association for Computational Linguistics
KW  - Computational linguistics
KW  - Function evaluation
KW  - Hierarchical systems
KW  - Modeling languages
KW  - Statistics
KW  - Hierarchical model
KW  - Language model
KW  - Mean absolute percentage error
KW  - Neural architectures
KW  - Orders of magnitude
KW  - Probability density function
PB  - Association for Computational Linguistics (ACL)
SN  - 978-194808732-2 (ISBN)
LA  - English
J2  - ACL - Annu. Meet. Assoc. Comput. Linguist., Proc. Conf. (Long Pap.)
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 38; Conference name: 56th Annual Meeting of the Association for Computational Linguistics, ACL 2018; Conference date: 15 July 2018 through 20 July 2018; Conference code: 145927
ER  -

TY  - JOUR
AU  - Tang, W.-H.
AU  - Qian, T.
AU  - Huang, J.-J.
AU  - Lu, G.-J.
AU  - Wang, Y.
AU  - Luan, L.
TI  - Improved Thermal-Electrical Analogy Model for Evaluating Loading Capability of Transformer
PY  - 2017
T2  - Huanan Ligong Daxue Xuebao/Journal of South China University of Technology (Natural Science)
VL  - 45
IS  - 10
SP  - 71
EP  - 77and86
DO  - 10.3969/j.issn.1000-565X.2017.10.010
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85045289178&doi=10.3969%2fj.issn.1000-565X.2017.10.010&partnerID=40&md5=1937a26f45357d67fb1c8c7f88be18d6
AD  - School of Electric Power, South China University of Technology, Guangzhou, 510640, Guangdong, China
AD  - Guangzhou Power Supply Bureau Co., Ltd., Guangzhou, 510620, Guangdong, China
AB  - The loading capability of an oil-immersed power transformer is closely related to oil temperatures and hot-spot temperatures (HST). In order to accurately calculate top-oil temperatures (TOT) and HSTs and thus help evaluate the loading capability of the oil-immersed transformer, a thermal-electrical analogy model for the transformer is improved based on the principle of heat transfer and the circuit laws. In the improved model, first, the oil viscosity is introduced to redefine the nonlinear thermal conductance of the relative parts of the transformer, and the heat transfer between the transformer and the ambient environment is taken into account. Then, a hot-spot temperature node is introduced into the improved model, so that this model can really reflect the general process of the heat transfer in the transformer. Finally, a genetic algorithm(GA)is employed to globally optimize thermal parameters. By taking a 180000kVA oil-immersed power transformer as an example, the calculated results of the HSTs, TOTs and bottom-oil temperatures of the original and improved models are compared with the on-line data and the results calculated by the recommended empirical formulas in the transformer loading guide. It is found that the improved model is more accurate. Then, the improved model is used to calculate the relative daily loss of life, the maximum TOT and the maximum HST of a large oil-immersed power transformer in given working conditions, so as to evaluate the loading capability of the tested transformer and thus provide a reference for the load rating increase of the tested transformer. © 2017, Editorial Department, Journal of South China University of Technology. All right reserved.
KW  - Hot-spot temperature
KW  - Loading capability
KW  - Relative loss of life
KW  - Thermal-electrical analogy
KW  - Transformer thermal model
KW  - Genetic algorithms
KW  - Heat transfer
KW  - Power transformers
KW  - Hotspot temperature
KW  - Loss of life
KW  - Oil immersed power transformer
KW  - Oil immersed transformers
KW  - Thermal conductance
KW  - Thermal-electrical analogy
KW  - Transformer loadings
KW  - Transformer thermal models
KW  - Oil filled transformers
PB  - South China University of Technology
SN  - 1000565X (ISSN)
LA  - Chinese
J2  - Huanan Ligong Daxue Xuebao
M3  - Article
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 9; CODEN: HLDKE
ER  -

TY  - JOUR
AU  - Vessely, M.J.
AU  - Leopold, A.L.
AU  - Walters, B.E.
AU  - Collins, M.P.
TI  - Discussion of "Comparison of three retaining wall condition assessment rating systems" by Mohammed A. Gabr, William Rasdorf, Daniel J. Findley, Cedrick J. Butler, and Steven A. Bert
PY  - 2018
T2  - Journal of Infrastructure Systems
VL  - 24
IS  - 4
C7  - 07018001
DO  - 10.1061/(ASCE)IS.1943-555X.0000403
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85053670306&doi=10.1061%2f%28ASCE%29IS.1943-555X.0000403&partnerID=40&md5=0f5d5c4fdbb76aca7a83ff07fe25c780
AD  - BGC Engineering Inc., 701 12th St., Golden, 80401, CO, United States
AD  - Shannon and Wilson Inc., 1321 Bannock St., Denver, 80204, CO, United States
AD  - Collins Engineers Inc., 455 Sherman St., Suite 160, Denver, 80203, CO, United States
AD  - Colorado Dept. of Transportation, 4201 E. Arkansas Ave., Denver, 80222, CO, United States
PB  - American Society of Civil Engineers (ASCE)
SN  - 10760342 (ISSN)
LA  - English
J2  - J. Infrastruct. Syst.
M3  - Note
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 0; Correspondence Address: A.L. Leopold; Shannon and Wilson Inc., Denver, 1321 Bannock St., 80204, United States; email: all@shanwil.com
ER  -

TY  - JOUR
AU  - Banerjee, C.M.
AU  - Baral, A.
AU  - Chakravorti, S.
TI  - Effective analysis of time-domain dielectric response for reliable diagnosis of power transformer insulation using statistical parameter evaluated from time-varying model
PY  - 2020
T2  - IET Science, Measurement and Technology
VL  - 14
IS  - 1
SP  - 48
EP  - 55
DO  - 10.1049/iet-smt.2018.5673
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85078050491&doi=10.1049%2fiet-smt.2018.5673&partnerID=40&md5=e6911cfa9c705565f126c6dc17151716
AD  - Department of Electrical Engineering, Indian Institute of Technology, Indian School of Mines, Dhanbad, India
AD  - Department of Electrical Engineering, Jadavpur University, Kolkata, India
AB  - Various types of insulation models with time-invariant parameters are available in the literature. Depending on the aging sensitive performance parameters to be evaluated, different models need to be employed (e.g. XY model for oil and paper-conductivity, conventional Debye model (CDM) for paper-moisture and tand). While the XY model cannot be used for estimating paper-moisture directly, analysis based on CDM parameter becomes dependent on its branch parameters, which are non-unique. These factors lead to either incomplete or ambiguous insulation diagnosis. These problems are resolved using the proposed new insulation model containing unique time-varying branch parameters. Another major advantage of the proposed model is that it can be used to evaluate a host of performance parameters (like paper-conductivity, oil and paper-moisture, dielectric loss) thus giving a complete picture of the insulation concerned. The application of the proposed model is also tested on data collected from several real-life power transformers. © The Institution of Engineering and Technology 2019.
KW  - Dielectric losses
KW  - Insulation
KW  - Moisture
KW  - Power transformers
KW  - Time domain analysis
KW  - Dielectric response
KW  - Insulation diagnosis
KW  - Insulation modeling
KW  - Paper conductivities
KW  - Performance parameters
KW  - Power transformer insulation
KW  - Statistical parameters
KW  - Time-varying models
KW  - Paper
PB  - Institution of Engineering and Technology
SN  - 17518822 (ISSN)
LA  - English
J2  - IET Sci. Meas. Technol.
M3  - Article
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 5; Correspondence Address: C.M. Banerjee; Department of Electrical Engineering, Indian Institute of Technology, Indian School of Mines, Dhanbad, India; email: cmbanerjee90@gmail.com
ER  -

TY  - CONF
AU  - Huang, P.-S.
AU  - Zhang, H.
AU  - Jiang, R.
AU  - Stanforth, R.
AU  - Welbl, J.
AU  - Rae, J.W.
AU  - Maini, V.
AU  - Yogatama, D.
AU  - Kohli, P.
TI  - Reducing sentiment bias in language models via counterfactual evaluation
PY  - 2020
T2  - Findings of the Association for Computational Linguistics Findings of ACL: EMNLP 2020
SP  - 65
EP  - 83
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85118456933&partnerID=40&md5=57190c77a90b052d045885a46df40c5f
AD  - DeepMind
AD  - University of California, Los Angeles, United States
AD  - University College London, United Kingdom
AB  - Advances in language modeling architectures and the availability of large text corpora have driven progress in automatic text generation. While this results in models capable of generating coherent texts, it also prompts models to internalize social biases present in the training corpus. This paper aims to quantify and reduce a particular type of bias exhibited by language models: bias in the sentiment of generated text. Given a conditioning context (e.g., a writing prompt) and a language model, we analyze if (and how) the sentiment of the generated text is affected by changes in values of sensitive attributes (e.g., country names, occupations, genders) in the conditioning context using a form of counterfactual evaluation. We quantify sentiment bias by adopting individual and group fairness metrics from the fair machine learning literature, and demonstrate that large-scale models trained on two different corpora (news articles, and Wikipedia) exhibit considerable levels of bias. We then propose embedding and sentiment prediction-derived regularization on the language model’s latent representations. The regularizations improve fairness metrics while retaining comparable levels of perplexity and semantic similarity. © 2020 Association for Computational Linguistics
KW  - Modeling languages
KW  - Natural language processing systems
KW  - Semantics
KW  - Automatic text generation
KW  - Counterfactuals
KW  - Language model
KW  - Machine learning literature
KW  - Model bias
KW  - Modeling architecture
KW  - Regularisation
KW  - Sensitive attribute
KW  - Text corpora
KW  - Training corpus
KW  - Computational linguistics
PB  - Association for Computational Linguistics (ACL)
SN  - 978-195214890-3 (ISBN)
LA  - English
J2  - Findings Assoc. Comp. Linguist. Findings ACL: EMNLP
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 52; Correspondence Address: P.-S. Huang; DeepMind; email: posenhuang@google.com; Conference name: Findings of the Association for Computational Linguistics, ACL 2020: EMNLP 2020; Conference date: 16 November 2020 through 20 November 2020; Conference code: 172733
ER  -

TY  - CONF
AU  - Aspillaga, C.
AU  - Carvallo, A.
AU  - Araujo, V.
TI  - Stress test evaluation of transformer-based models in natural language understanding tasks
PY  - 2020
T2  - LREC 2020 - 12th International Conference on Language Resources and Evaluation, Conference Proceedings
SP  - 1882
EP  - 1894
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85096546857&partnerID=40&md5=5e15b6cb5e32cda48c93b92e156a3ed5
AD  - Pontificia Universidad Católica de Chile, Santiago, Chile
AD  - IMFD, Santiago, Chile
AB  - There has been significant progress in recent years in the field of Natural Language Processing thanks to the introduction of the Transformer architecture. Current state-of-the-art models, via a large number of parameters and pre-training on massive text corpus, have shown impressive results on several downstream tasks. Many researchers have studied previous (non-Transformer) models to understand their actual behavior under different scenarios, showing that these models are taking advantage of clues or failures of datasets and that slight perturbations on the input data can severely reduce their performance. In contrast, recent models have not been systematically tested with adversarial-examples in order to show their robustness under severe stress conditions. For that reason, this work evaluates three Transformer-based models (RoBERTa, XLNet, and BERT) in Natural Language Inference (NLI) and Question Answering (QA) tasks to know if they are more robust or if they have the same flaws as their predecessors. As a result, our experiments reveal that RoBERTa, XLNet and BERT are more robust than recurrent neural network models to stress tests for both NLI and QA tasks. Nevertheless, they are still very fragile and demonstrate various unexpected behaviors, thus revealing that there is still room for future improvement in this field. © European Language Resources Association (ELRA), licensed under CC-BY-NC
KW  - Adversarial evaluation
KW  - Natural language inference
KW  - Natural language understanding
KW  - Question answering
KW  - Stress tests
KW  - Natural language processing systems
KW  - Recurrent neural networks
KW  - Future improvements
KW  - NAtural language processing
KW  - Natural language understanding
KW  - Natural languages
KW  - Question Answering
KW  - Recurrent neural network model
KW  - State of the art
KW  - Stress condition
KW  - Electric transformer testing
A2  - Calzolari N.
A2  - Bechet F.
A2  - Blache P.
A2  - Choukri K.
A2  - Cieri C.
A2  - Declerck T.
A2  - Goggi S.
A2  - Isahara H.
A2  - Maegaard B.
A2  - Mariani J.
A2  - Mazo H.
A2  - Moreno A.
A2  - Odijk J.
A2  - Piperidis S.
PB  - European Language Resources Association (ELRA)
SN  - 979-109554634-4 (ISBN)
LA  - English
J2  - LREC - Int. Conf. Lang. Resour. Eval., Conf. Proc.
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 11; Conference name: 12th International Conference on Language Resources and Evaluation, LREC 2020; Conference date: 11 May 2020 through 16 May 2020; Conference code: 164155
ER  -

TY  - CONF
AU  - Mrabet, Y.
AU  - Demner-Fushman, D.
TI  - HOLMS: Alternative Summary Evaluation with Large Language Models
PY  - 2020
T2  - COLING 2020 - 28th International Conference on Computational Linguistics, Proceedings of the Conference
SP  - 5679
EP  - 5688
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85123921646&partnerID=40&md5=34e12763b5ca9b6b26fdfd980bcd15ad
AD  - U.S. National Library of Medicine, National Institutes of Health, 8600 Rockville Pike, Bethesda, 20894, MD, United States
AB  - Efficient document summarization requires evaluation measures that can not only rank a set of systems based on an average score, but also highlight which individual summary is better than another. However, despite the very active research on summarization approaches, few works have proposed new evaluation measures in the recent years. The standard measures relied upon for the development of summarization systems are most often ROUGE and BLEU which, despite being efficient in overall system ranking, remain lexical in nature and have a limited potential when it comes to training neural networks. In this paper, we present a new hybrid evaluation measure for summarization, called HOLMS, that combines both language models pre-trained on large corpora and lexical similarity measures. Through several experiments, we show that HOLMS outperforms ROUGE and BLEU substantially in its correlation with human judgments on several extractive summarization datasets for both linguistic quality and pyramid scores. © 2020 COLING 2020 - 28th International Conference on Computational Linguistics, Proceedings of the Conference. All rights reserved.
KW  - Document summarization
KW  - Evaluation measures
KW  - Human judgments
KW  - Language model
KW  - Large corpora
KW  - Lexical similarity
KW  - Neural-networks
KW  - Similarity measure
KW  - Summarization systems
KW  - System rankings
KW  - Computational linguistics
A2  - Scott D.
A2  - Bel N.
A2  - Zong C.
PB  - Association for Computational Linguistics (ACL)
SN  - 978-195214827-9 (ISBN)
LA  - English
J2  - COLING - Int. Conf. Comput. Linguist., Proc. Conf.
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 12; Conference name: 28th International Conference on Computational Linguistics, COLING 2020; Conference date: 8 December 2020 through 13 December 2020; Conference code: 186886
ER  -

TY  - CONF
AU  - Jiang, N.
AU  - de Marneffe, M.-C.
TI  - Evaluating BERT for natural language inference: A case study on the CommitmentBank
PY  - 2019
T2  - EMNLP-IJCNLP 2019 - 2019 Conference on Empirical Methods in Natural Language Processing and 9th International Joint Conference on Natural Language Processing, Proceedings of the Conference
SP  - 6086
EP  - 6091
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85084290810&partnerID=40&md5=601c3aee2fc8465c70c7b1fe3544f40c
AD  - Department of Linguistics, Ohio State University, United States
AB  - Natural language inference (NLI) datasets (e.g., MultiNLI) were collected by soliciting hypotheses for a given premise from annotators. Such data collection led to annotation artifacts: systems can identify the premise-hypothesis relationship without observing the premise (e.g., negation in hypothesis being indicative of contradiction). We address this problem by recasting the CommitmentBank for NLI, which contains items involving reasoning over the extent to which a speaker is committed to complements of clause-embedding verbs under entailment-canceling environments (conditional, negation, modal and question). Instead of being constructed to stand in certain relationships with the premise, hypotheses in the recast CommitmentBank are the complements of the clause-embedding verb in each premise, leading to no annotation artifacts in the hypothesis. A state-of-the-art BERT-based model performs well on the CommitmentBank with 85% F1. However analysis of model behavior shows that the BERT models still do not capture the full complexity of pragmatic reasoning, nor encode some of the linguistic generalizations, highlighting room for improvement. © 2019 Association for Computational Linguistics
KW  - Embeddings
KW  - Data collection
KW  - Modeling behavior
KW  - Natural languages
KW  - State of the art
KW  - Natural language processing systems
PB  - Association for Computational Linguistics
SN  - 978-195073790-1 (ISBN)
LA  - English
J2  - EMNLP-IJCNLP - Conf. Empir. Methods Nat. Lang. Process. Int. Jt. Conf. Nat. Lang. Process., Proc. Conf.
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 41; Conference name: 2019 Conference on Empirical Methods in Natural Language Processing and 9th International Joint Conference on Natural Language Processing, EMNLP-IJCNLP 2019; Conference date: 3 November 2019 through 7 November 2019; Conference code: 159367
ER  -

TY  - CONF
AU  - Takahashi, K.
AU  - Sudoh, K.
AU  - Nakamura, S.
TI  - Automatic machine translation evaluation using source language inputs and cross-lingual language model
PY  - 2020
T2  - Proceedings of the Annual Meeting of the Association for Computational Linguistics
SP  - 3553
EP  - 3558
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85116830661&partnerID=40&md5=923c22943413c60ab5b1925f6d54ff8d
AD  - Nara Institute of Science and Technology
AD  - PRESTO, Japan Science and Technology Agency
AB  - We propose an automatic evaluation method of machine translation that uses source language sentences regarded as additional pseudo references. The proposed method evaluates a translation hypothesis in a regression model. The model takes the paired source, reference, and hypothesis sentence all together as an input. A pretrained large scale cross-lingual language model encodes the input to sentence-pair vectors, and the model predicts a human evaluation score with those vectors. Our experiments show that our proposed method using Cross-lingual Language Model (XLM) trained with a translation language modeling (TLM) objective achieves a higher correlation with human judgments than a baseline method that uses only hypothesis and reference sentences. Additionally, using source sentences in our proposed method is confirmed to improve the evaluation performance. © 2020 Association for Computational Linguistics
KW  - Computer aided language translation
KW  - Modeling languages
KW  - Natural language processing systems
KW  - Neural machine translation
KW  - Regression analysis
KW  - Automatic evaluation
KW  - Automatic machines
KW  - Cross-lingual
KW  - Evaluation methods
KW  - Language model
KW  - Large-scales
KW  - Machine translation evaluations
KW  - Machine translations
KW  - Regression modelling
KW  - Source language
KW  - Computational linguistics
PB  - Association for Computational Linguistics (ACL)
SN  - 0736587X (ISSN); 978-195214825-5 (ISBN)
LA  - English
J2  - Proc. Annu. Meet. Assoc. Comput Linguist.
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 13; Conference name: 58th Annual Meeting of the Association for Computational Linguistics, ACL 2020; Conference date: 5 July 2020 through 10 July 2020; Conference code: 172533
ER  -

TY  - CONF
AU  - Liu, C.
AU  - Zhang, Y.
AU  - Zhang, P.
AU  - Wang, Y.
TI  - Evaluating modeling units and sub-word features in language models for Turkish ASR
PY  - 2018
T2  - 2018 11th International Symposium on Chinese Spoken Language Processing, ISCSLP 2018 - Proceedings
C7  - 8706685
SP  - 414
EP  - 418
DO  - 10.1109/ISCSLP.2018.8706685
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85065871270&doi=10.1109%2fISCSLP.2018.8706685&partnerID=40&md5=e0f500bda8819f149aab57e488040a9f
AD  - Institute of Acoustics, Chinese Academy of Sciences, China
AD  - University of Chinese Academy of Sciences, China
AD  - School of Computer Science and Software Engineering, East China Normal University, China
AB  - Turkish is a morphologically rich language, which leads to serious data sparsity problems in language modeling for automatic speech recognition (ASR) tasks. Using sub-words as language modeling units and incorporating sub-word features into word-level models are two strategies to alleviate the problem. In this paper, we propose a novel model architecture which can incorporate sub-word features directly. And we use a CNN to learn (sub)word embeddings as sub-word features from character or sub-word level input. We evaluate the proposed model on Turkish ASR task. We choose word and morph (sub-word) as language modeling unit respectively. Results show that the consistency between language modeling units and ASR system units is important for the effectiveness of rescoring. And the proposed method reduces the word error rate (WER) of word and statistical sub-word level system by absolute 1.56% and 1.87%. � 2018 IEEE
KW  - Convolutional neural network
KW  - Sub-word language modeling
KW  - Turkish speech recogniton
KW  - Computational linguistics
KW  - Neural networks
KW  - Speech recognition
KW  - Automatic speech recognition
KW  - Convolutional neural network
KW  - Data sparsity problems
KW  - Evaluating models
KW  - Model architecture
KW  - Sub words
KW  - Turkishs
KW  - Word error rate
KW  - Modeling languages
PB  - Institute of Electrical and Electronics Engineers Inc.
SN  - 978-153865627-3 (ISBN)
LA  - English
J2  - Int. Symp. Chin. Spok. Lang. Process., ISCSLP - Proc.
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 2; Conference name: 11th International Symposium on Chinese Spoken Language Processing, ISCSLP 2018; Conference date: 26 November 2018 through 29 November 2018; Conference code: 147824
ER  -

TY  - JOUR
AU  - Duan, J.
AU  - Li, H.
AU  - Lei, Y.
TI  - Modeling and experimental validation of a dynamic regional saturation J-A model for protective current transformer
PY  - 2019
T2  - International Journal of Electrical Power and Energy Systems
VL  - 105
SP  - 315
EP  - 322
DO  - 10.1016/j.ijepes.2018.08.029
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85052476380&doi=10.1016%2fj.ijepes.2018.08.029&partnerID=40&md5=53af5450c0a39d595697c391630a8b34
AD  - Department of Electrical Engineering, Xi'an University of Technology, Xi'an, 710048, Shaanxi, China
AD  - Xi'an Thermal Power Research Institute Co., Ltd., Xi'an, 710054, China
AB  - The analysis and accuracy of modeling the protective current transformer are yet not suitable for a wide range of current levels, especially under weak transient saturation. It is necessary to develop a mathematical tool allowing to create field models of current transformers allow modeling not only steady modes, but also transients ones. With the support of the large current transient test conducted on the real protective current transformers, multiple test levels from 6 to 48 kA transients were obtained. This paper devoted to the study of modeling protective current transformers more accurately proposes an improved dynamic regional saturation J-A model. It emphasizes the excess loss of the core under transient conditions, and designs a numerical solution for the proposed dynamic regional saturation J-A current transformer model without iteration, so that it can simulate the secondary output of the current transformer online. By numerous data which are actually saturated in the transient flow test, the proposed dynamic partitioned saturation J-A model, the static J-A model and the dynamic J-A model are compared and verified, respectively. Extensive results prove the effectiveness of the proposed method, which is capable to modeling protective current transformer transient of the actual situation. And the average error under a wide range test is relatively stable. © 2018
KW  - Dynamic regional saturation
KW  - Improved J-A model
KW  - Protective current transformer
KW  - Transient test
KW  - Electric currents
KW  - Electric instrument transformers
KW  - Electric transformer testing
KW  - Iterative methods
KW  - Transient analysis
KW  - Experimental validations
KW  - J-a models
KW  - Mathematical tools
KW  - Numerical solution
KW  - Protective current transformers
KW  - Transient conditions
KW  - Transient saturation
KW  - Transient tests
KW  - Power quality
PB  - Elsevier Ltd
SN  - 01420615 (ISSN)
LA  - English
J2  - Int J Electr Power Energy Syst
M3  - Article
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 10; Correspondence Address: H. Li; Department of Electrical Engineering, Xi'an University of Technology, Xi'an, 710048, China; email: li_hao_xaut@163.com; CODEN: IEPSD
ER  -

TY  - CHAP
AU  - Wu, W.
AU  - Liu, G.
TI  - Modeling and validation of thermal-fluid field of transformer winding based on a product-level heating and cooling model
PY  - 2019
T2  - Modeling and Application of Electromagnetic and Thermal Field in Electrical Engineering
SP  - 665
EP  - 685
DO  - 10.1007/978-981-15-0173-9_16
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85087687738&doi=10.1007%2f978-981-15-0173-9_16&partnerID=40&md5=020418b063cf6936f1f4befa8425dbf8
AD  - Institute of Power Transmission and Transformation Technology, Baobian Electric, Baoding, China
AD  - Department of Electrical Engineering, North China Electric Power University, Baoding, China
AB  - The temperature rise and hotspot of transformer winding is an important index to judge the reliability of transformer and is one of the key issues concerned by the transformer manufacturers and researchers. At present, there are many simulation studies on the temperature rise and hotspots of transformer windings, but they are often limited to the algorithm study or software application and lack of experimental validation, especially the tests on a product-level platform. To this end, our laboratory has built a product-level platform for testing the winding temperature rise and hotspot in Baobian Electric. The heating and cooling model of the transformer winding's platform is mainly composed of the air core non-inductive coil, active-part insulation, heat-insulating tank, panel-type radiator, oil pump, fan, oil conduit and thermoelectric couple. Based on this model, the temperature rise and hotspot experiments under various operating conditions are carried out, and the experimental data are compared with the results of the ANSYS FLUENT. The simulation results show that the accuracy of the simulation results can be further improved by considering the influence of spacers, strips and other factors when modeling so as to better meet the engineering application requirements. © Science Press, Beijing and Springer Nature Singapore Pte Ltd. 2020.
KW  - Heating and cooling model
KW  - Modeling and simulation
KW  - Thermal-fluid field
KW  - Transformer winding
PB  - Springer Singapore
SN  - 978-981150173-9 (ISBN); 978-981150172-2 (ISBN)
LA  - English
J2  - Model. and Appl. of Electromagn. and Therm. Field in Electr. Eng.
M3  - Book chapter
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 0; Correspondence Address: W. Wu; Institute of Power Transmission and Transformation Technology, Baobian Electric, Baoding, China; email: wuweige@btw.cn
ER  -

TY  - CONF
AU  - Lee, J.-H.
AU  - Na, S.-H.
TI  - JBNU at SemEval-2020 Task 4: BERT and UniLM for Commonsense Validation and Explanation
PY  - 2020
T2  - 14th International Workshops on Semantic Evaluation, SemEval 2020 - co-located 28th International Conference on Computational Linguistics, COLING 2020, Proceedings
SP  - 527
EP  - 534
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85095302662&partnerID=40&md5=b692d3bad26b80903aa2ee9543b21d6d
AD  - Computer Science and Engineering, Jeonbuk National University, South Korea
AB  - This paper presents our contributions to the SemEval-2020 Task 4 Commonsense Validation and Explanation (ComVE) and includes the experimental results of the two Subtasks B and C of the SemEval-2020 Task 4. Our systems rely on pre-trained language models, i.e., BERT (including its variants) and UniLM, and rank 10th and 7th among 27 and 17 systems on Subtasks B and C, respectively. We analyze the commonsense ability of the existing pretrained language models by testing them on the SemEval-2020 Task 4 ComVE dataset, specifically for Subtasks B and C, the explanation subtasks with multi-choice and sentence generation, respectively. © 2020 14th International Workshops on Semantic Evaluation, SemEval 2020 - co-located 28th International Conference on Computational Linguistics, COLING 2020, Proceedings. All rights reserved.
KW  - C (programming language)
KW  - Computational linguistics
KW  - Statistical tests
KW  - Language model
KW  - Multi choices
KW  - Subtask
KW  - Semantics
A2  - Herbelot A.
A2  - Zhu X.
A2  - Palmer A.
A2  - Schneider N.
A2  - May J.
A2  - Shutova E.
PB  - International Committee for Computational Linguistics
SN  - 978-195214831-6 (ISBN)
LA  - English
J2  - Int. Workshops Semant. Eval., SemEval - co-located Int. Conf. Comput. Linguist., COLING , Proc.
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 2; Conference name: 14th International Workshops on Semantic Evaluation, SemEval 2020; Conference date: 12 December 2020 through 13 December 2020; Conference code: 174265
ER  -

TY  - JOUR
AU  - Sajini, G.
AU  - Kallimani, J.S.
TI  - Computational evaluation of language models by considering various scaling properties for processing natural languages
PY  - 2020
T2  - Journal of Advanced Research in Dynamical and Control Systems
VL  - 12
IS  - 7 Special Issue
SP  - 691
EP  - 700
DO  - 10.5373/JARDCS/V12SP7/20202159
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85090659870&doi=10.5373%2fJARDCS%2fV12SP7%2f20202159&partnerID=40&md5=147c1d6f98ece3ef791d6ccd4db727ec
AD  - Department of Computer Science and Engineering, M.S. Ramaiah Institute of Technology, Bangalore, India
AB  - The natural language outlines the equity of scaling, which appraises the overall format in the community of vocabulary and the mind of a text. This was acknowledged by the statistical mechanical investigation. This paper focuses on the estimated models of natural languages considering the extensive analytical nature of natural language. The author tries to understand whether the five scaling properties can handle the appraisal of the estimated models. Explicitly, a unique n-gram model of language is approved, a probabilistic CFG, dialect copy based on Simon/Pitman-Yor approaches, a model of the neural language, and unusual adversarial networks for the text creation. The language model that is designed from a recurrent neural network with the mechanism of gating is reasoned to be the only estimated model that was able to regenerate the natural language from the understanding of the behavior of the long memory. Additionally, comparing the results of the newly approved model-based appraisals, they found out that a good signal of the model aspect is the interpreter of Taylor’s law. © 2020, Institute of Advanced Scientific Research, Inc.. All rights reserved.
KW  - BLEU
KW  - GAN
KW  - Prababilistic Context-Free Grammar (PCFG)
KW  - ROUGE
PB  - Institute of Advanced Scientific Research, Inc.
SN  - 1943023X (ISSN)
LA  - English
J2  - J. Adv. Res. Dyn. Control. Syst.
M3  - Article
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 0
ER  -

TY  - CONF
AU  - Maharjan, M.
AU  - Banerjee, A.
AU  - Kavasseri, R.G.
TI  - Application of a Simplified model of Solid State Transformer in Hybrid Residential Energy System - A Benchmark model
PY  - 2018
T2  - 2018 North American Power Symposium, NAPS 2018
C7  - 8600669
DO  - 10.1109/NAPS.2018.8600669
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85061770072&doi=10.1109%2fNAPS.2018.8600669&partnerID=40&md5=67e5ca0ebdd2060f49ea1122d8e0d525
AD  - Electrical and Computer Engg., North Dakota State University, Fargo, ND, United States
AB  - This paper presents a benchmark model for a hybrid residential energy system comprised of AC as well as DC loads, DG and, a storage unit. The benchmark is connected to the grid through a simplified model of a Solid State Transformer (SST), developed in MAT-LAB/Simulink. Distributed generation (DG) is established by modeling the PV using the solar irradiance information obtained by the SAM software. A battery is modeled to be present in the grid with State-of-Charge (SOC) battery controls governing its switching on and off times. Solar irradiance for various times of the year were collected from the SAM software and were used as in-feed for various simulation schemes to test the fidelity of the model, subject to the hybrid nature of loads. The results demonstrate the bi-directional power flow capability of the the simplified SST in the context of hybrid generation and uneven load demand, over a range of scenarios incorporating the variability in PV penetration and its effects on the distribution system. © 2018 IEEE.
KW  - Irradiance
KW  - Photovoltaics (PV)
KW  - Residential System
KW  - Solid State Transformer (SST)
KW  - State-of-charge (SOC)
KW  - Battery management systems
KW  - Benchmarking
KW  - Charging (batteries)
KW  - Housing
KW  - Secondary batteries
KW  - Simulink
KW  - Software testing
KW  - Benchmark models
KW  - Irradiance
KW  - Photovoltaic
KW  - Photovoltaics
KW  - Residential energy systems
KW  - Residential systems
KW  - Solid state transformer
KW  - State-of-charge
KW  - State-transformers
KW  - States of charges
KW  - Electric load flow
PB  - Institute of Electrical and Electronics Engineers Inc.
SN  - 978-153867138-2 (ISBN)
LA  - English
J2  - North Am. Power Symp., NAPS
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 1; Conference name: 2018 North American Power Symposium, NAPS 2018; Conference date: 9 September 2018 through 11 September 2018; Conference code: 144296
ER  -

TY  - JOUR
AU  - Gabr, M.A.
AU  - Rasdorf, W.
AU  - Findley, D.J.
AU  - Butler, C.J.
AU  - Bert, S.A.
TI  - Closure to "Comparison of three retaining wall condition assessment rating systems" by Mohammed A. Gabr, William Rasdorf, Daniel J. Findley, Cedrick J. Butler, and Steven A. Bert
PY  - 2018
T2  - Journal of Infrastructure Systems
VL  - 24
IS  - 4
C7  - 07018002
DO  - 10.1061/(ASCE)IS.1943-555X.0000403
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85053679021&doi=10.1061%2f%28ASCE%29IS.1943-555X.0000403&partnerID=40&md5=8dd11f51f2e042a011e7ad1467b9268c
AD  - Dept. of Civil, Construction and Environmental Engineering, North Carolina State Univ., Raleigh, 27606-7908, NC, United States
AD  - Institute for Transportation Research and Education, North Carolina State Univ., Centennial Campus Box 8601, Raleigh, 27695-8601, NC, United States
PB  - American Society of Civil Engineers (ASCE)
SN  - 10760342 (ISSN)
LA  - English
J2  - J. Infrastruct. Syst.
M3  - Note
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 1; Correspondence Address: W. Rasdorf; Dept. of Civil, Construction and Environmental Engineering, North Carolina State Univ., Raleigh, 27606-7908, United States; email: rasdorf@ncsu.edu
ER  -

TY  - CONF
AU  - Ryadi, M.
AU  - Tanguy, A.
TI  - Field Validated Dynamic Thermal Model for Power Transformer Insulation System Assessment
PY  - 2018
T2  - 2018 IEEE Electrical Insulation Conference, EIC 2018
C7  - 8481065
SP  - 101
EP  - 105
DO  - 10.1109/EIC.2018.8481065
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85056264950&doi=10.1109%2fEIC.2018.8481065&partnerID=40&md5=f1cc8e412c5b6f8979ae9adc41f7591b
AD  - EDF LAB Paris-Saclay, Palaiseau, France
AB  - Mastering the thermal performances of power transformers is an aspect of first importance for the utilities. Because it's the knowledge of the life expectancy or the condition of the transformer. Oil temperature and winding hot spot are the main parameters which have an impact on the transformer condition. Therefore a reliable thermal model represents a tool of a great support to the transformer user. The use of the thermal models is a subject which always raises discussions on their validity. Our experiment is based on an investigation program regarding the thermal model validation using the data recorded over several months in the condition of industrial operation of two GSU transformers. A set of sensors was installed in the transformers having undergoes FAT. These two units of EDF transformers flotilla were in operation in experiencing various stages of the cooling system impacting consequently the oil temperatures and winding hot spot variations. The application of the data recorded on line during the two GSU operation with consideration of the number of operating heat exchanger, pumps and fans, allows to evaluate the models suggested in the IEC and IEEE standards as well as other models. To assess the oil temperature and hot spot of the transformers, a thermal model has been adapted in order to be used as a tool for the transformer monitoring. In this paper we will expose a methodology used for the improvement of the thermal model. In this paper, we will demonstrate how such validated thermal model will be used in the monitoring of other transformer in operation. © 2018 IEEE.
KW  - cooling system
KW  - model fitting
KW  - monitoring
KW  - Power transformer
KW  - PSO algorithm
KW  - thermal model
KW  - winding hot spot
KW  - Cooling systems
KW  - Electric windings
KW  - IEEE Standards
KW  - Monitoring
KW  - Oil filled transformers
KW  - Power transformers
KW  - Thermoelectric equipment
KW  - Thermography (temperature measurement)
KW  - Winding
KW  - Dynamic thermal modeling
KW  - Hot spot
KW  - Industrial operations
KW  - Model fitting
KW  - Power transformer insulation
KW  - PSO algorithms
KW  - Thermal model
KW  - Transformer monitoring
KW  - Thermal insulation
PB  - Institute of Electrical and Electronics Engineers Inc.
SN  - 978-153864178-1 (ISBN)
LA  - English
J2  - IEEE Electr. Insul. Conf., EIC
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 2; Conference name: 2018 IEEE Electrical Insulation Conference, EIC 2018; Conference date: 17 June 2018 through 20 June 2018; Conference code: 140527
ER  -

TY  - CONF
AU  - Enderle, T.P.
AU  - Campos, M.
AU  - Sausen, P.S.
AU  - Sausen, A.T.Z.R.
AU  - Oliveira, A.C.
AU  - Emmel, R.R.
TI  - Evaluation of the thermal behavior models of underground transformers based on real data
PY  - 2019
T2  - 2019 IEEE PES Conference on Innovative Smart Grid Technologies, ISGT Latin America 2019
C7  - 8895293
DO  - 10.1109/ISGT-LA.2019.8895293
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85075723809&doi=10.1109%2fISGT-LA.2019.8895293&partnerID=40&md5=cbe1007f5b24fd2819e1d5e9b3bd7a2e
AD  - Regional University of the Northwest of the State of Rio Grande Do sul - UNIJUI, Department of Exact Sciences and Engineering, Ijuí, Brazil
AD  - Federal University of Campina Grande - UFCG, Department of Electro-Electronics, Campina Grande, Brazil
AD  - State Electric Power Distribution Company - CEEE/D, Department of Underground Networks, Porto Alegre, Brazil
AB  - Transformers are fundamental components in energy distribution systems, especially with the evolution of smart grids, the instrumentation of this equipment should be more and more present. In this sense, mathematical models that can correctly represent their behavior are necessary, since they can compose, together with techniques of artificial intelligence, innumerable propositions and analyzes of their operation. This paper objectives to perform a bibliographic review of the mathematical models available in the technical literature on the effects of temperature variations on transformers installed in underground chambers. From this study, one of the models is adapted to the problem, transforming into a reduced model, and its validation is performed using real operation data obtained through a remote monitoring system of an underground power distribution network. The results presented considered two seasons of the year, winter and summer, for a period of 72 hours. © 2019 IEEE.
KW  - Mathematical Modeling
KW  - Temperature
KW  - Transformers
KW  - Underground Networks
KW  - Electric power transmission networks
KW  - Electric transformers
KW  - Mathematical models
KW  - Metadata
KW  - Temperature
KW  - Bibliographic reviews
KW  - Effects of temperature
KW  - Fundamental component
KW  - Remote monitoring system
KW  - Technical literature
KW  - Thermal behavior model
KW  - Underground networks
KW  - Underground power distribution
KW  - Smart power grids
PB  - Institute of Electrical and Electronics Engineers Inc.
SN  - 978-153869567-8 (ISBN)
LA  - English
J2  - IEEE PES Conf. Innov. Smart Grid Technol., ISGT Lat. America
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 0; Conference name: 2019 IEEE PES Conference on Innovative Smart Grid Technologies, ISGT Latin America 2019; Conference date: 15 September 2019 through 18 September 2019; Conference code: 154372
ER  -

TY  - CONF
AU  - Kuribayashi, T.
AU  - Ito, T.
AU  - Suzuki, J.
AU  - Inui, K.
TI  - Language models as an alternative evaluator of word order hypotheses: A case study in Japanese
PY  - 2020
T2  - Proceedings of the Annual Meeting of the Association for Computational Linguistics
SP  - 488
EP  - 504
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85117929922&partnerID=40&md5=dbdf3ab0d55617de5aafe09afa5364a2
AD  - Tohoku University
AD  - RIKEN
AD  - Langsmith Inc.
AB  - We examine a methodology using neural language models (LMs) for analyzing the word order of language. This LM-based method has the potential to overcome the difficulties existing methods face, such as the propagation of preprocessor errors in count-based methods. In this study, we explore whether the LM-based method is valid for analyzing the word order. As a case study, this study focuses on Japanese due to its complex and flexible word order. To validate the LM-based method, we test (i) parallels between LMs and human word order preference, and (ii) consistency of the results obtained using the LM-based method with previous linguistic studies. Through our experiments, we tentatively conclude that LMs display sufficient word order knowledge for usage as an analysis tool. Finally, using the LM-based method, we demonstrate the relationship between the canonical word order and topicalization, which had yet to be analyzed by large-scale experiments. © 2020 Association for Computational Linguistics
KW  - Backpropagation
KW  - Analysis tools
KW  - Case-studies
KW  - Language model
KW  - Large scale experiments
KW  - Model-based method
KW  - Word orders
KW  - Computational linguistics
PB  - Association for Computational Linguistics (ACL)
SN  - 0736587X (ISSN); 978-195214825-5 (ISBN)
LA  - English
J2  - Proc. Annu. Meet. Assoc. Comput Linguist.
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 0; Conference name: 58th Annual Meeting of the Association for Computational Linguistics, ACL 2020; Conference date: 5 July 2020 through 10 July 2020; Conference code: 172533
ER  -

TY  - CONF
AU  - Naidoo, J.
AU  - Swanson, A.G.
TI  - Validation of model for medium voltage distribution transformer under inrush current conditions
PY  - 2017
T2  - 2017 IEEE International Magnetics Conference, INTERMAG 2017
C7  - 8007696
DO  - 10.1109/INTMAG.2017.8007696
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85034660394&doi=10.1109%2fINTMAG.2017.8007696&partnerID=40&md5=70e9bc22847dceb77c6f855ee4c5f19f
AD  - Standards Implementation, Eskom, Durban, South Africa
AD  - College of Agriculture, Engineering and Science, University of KwaZulu-Natal, Durban, South Africa
AB  - Pole mounted transformers are subject to inrush currents, that occur during start-up of the transformer. The inrush currents may cause unwanted forces on the windings. Testing was done at a Transformer Testing Facility to develop a model to understand the inrush currents. The model matched measured results closely. © 2017 IEEE.
KW  - ATP/EMTP
KW  - Inrush current
KW  - Electric transformers
KW  - ATP/EMTP
KW  - In-rush current
KW  - Measured results
KW  - Medium voltage
KW  - Testing facility
KW  - Electric transformer testing
PB  - Institute of Electrical and Electronics Engineers Inc.
SN  - 978-153861086-2 (ISBN)
LA  - English
J2  - IEEE Int. Magn. Conf., INTERMAG
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 0; Conference name: 2017 IEEE International Magnetics Conference, INTERMAG 2017; Conference date: 24 April 2017 through 28 April 2017; Conference code: 129920
ER  -

TY  - CONF
AU  - Mahurkar, S.
AU  - Patil, R.
TI  - LRG at SemEval-2020 Task 7: Assessing the Ability of BERT and Derivative Models to Perform Short-Edits based Humor Grading
PY  - 2020
T2  - 14th International Workshops on Semantic Evaluation, SemEval 2020 - co-located 28th International Conference on Computational Linguistics, COLING 2020, Proceedings
SP  - 858
EP  - 864
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85098808412&partnerID=40&md5=7de412af8a62f75a547e29cdb150e847
AD  - Department of Computer Science and Engineering, Vellore Institute of Technology, Vellore, India
AD  - Department of Electrical and Electronics Engineering, BITS Pilani K. K. Birla Goa Campus, India
AB  - In this paper, we assess the ability of BERT and its derivative models (RoBERTa, DistilBERT, and ALBERT) for short-edits based humor grading. We test these models for humor grading and classification tasks on the Humicroedit and the FunLines dataset. We perform extensive experiments with these models to test their language modeling and generalization abilities via zero-shot inference and cross-dataset inference based approaches. Further, we also inspect the role of self-attention layers in humor-grading by performing a qualitative analysis over the self-attention weights from the final layer of the trained BERT model. Our experiments show that all the pre-trained BERT derivative models show significant generalization capabilities for humor-grading related tasks. © 2020 14th International Workshops on Semantic Evaluation, SemEval 2020 - co-located 28th International Conference on Computational Linguistics, COLING 2020, Proceedings. All rights reserved.
KW  - Classification (of information)
KW  - Computational linguistics
KW  - Modeling languages
KW  - Semantics
KW  - Statistical tests
KW  - Classification tasks
KW  - Derivative models
KW  - Generalization ability
KW  - Generalization capability
KW  - Grading and classifications
KW  - Language model
KW  - Modeling abilities
KW  - Qualitative analysis
KW  - Grading
A2  - Herbelot A.
A2  - Zhu X.
A2  - Palmer A.
A2  - Schneider N.
A2  - May J.
A2  - Shutova E.
PB  - International Committee for Computational Linguistics
SN  - 978-195214831-6 (ISBN)
LA  - English
J2  - Int. Workshops Semant. Eval., SemEval - co-located Int. Conf. Comput. Linguist., COLING , Proc.
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 2; Conference name: 14th International Workshops on Semantic Evaluation, SemEval 2020; Conference date: 12 December 2020 through 13 December 2020; Conference code: 174265
ER  -

TY  - JOUR
AU  - Zhang, X.
AU  - Wang, Z.
TI  - Assessment of Hydraulic Network Models in Predicting Reverse Flows in OD Cooled Disc Type Transformer Windings
PY  - 2019
T2  - IEEE Access
VL  - 7
C7  - 8847609
SP  - 139249
EP  - 139257
DO  - 10.1109/ACCESS.2019.2943566
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85075362293&doi=10.1109%2fACCESS.2019.2943566&partnerID=40&md5=94dcf29e08c48a40918489194f7f3ed1
AD  - School of Electrical and Electronic Engineering, University of Manchester, Manchester, M13 9PL, United Kingdom
AB  - Predicting liquid flow distribution in the winding is crucial for transformer thermal design and hydraulic network models are usually used to guarantee reasonable liquid flow distribution. This paper is a continuation of the research effort in using computational fluid dynamics (CFD) to calibrate and improve the network modelling approach. The possibility is assessed of hydraulic network models in predicting the occurrence of reverse flows in pump-driven oil directed (OD) cooling modes. CFD modelling shows that the occurrence of reverse flows requires both high Reynolds number at the winding pass inlet and the 'real' pass inlet velocity profile. To reflect the effect of pass inlet velocity profile on flow distribution, a winding pass is added beneath dividing and merging junctions in deriving minor pressure loss correlations. In addition, hybrid minor loss correlations are used to incorporate the effect of pass inlet velocity profile and to mitigate the inaccuracy of minor pressure loss segregation introduced by the inclusion of a winding pass beneath the junctions. Even with the above mentioned improvements, a conventional network model with one node for each junction still cannot predict reverse flows because of its architecture limit, hence a 3-node junction network model is then proposed. It is demonstrated that the newly developed 3-node junction hydraulic network model can predict the occurrence of reverse flows in OD cooled disc-type transformer windings. © 2013 IEEE.
KW  - hybrid correlation
KW  - Hydraulic network model
KW  - junction 3-node
KW  - reverse flow
KW  - transformer
KW  - Computational fluid dynamics
KW  - Forecasting
KW  - Inlet flow
KW  - Pressure effects
KW  - Reynolds number
KW  - Winding
KW  - High Reynolds number
KW  - Hydraulic networks
KW  - Inlet velocity profile
KW  - junction 3-node
KW  - Network modeling
KW  - Network modelling
KW  - Reverse flow
KW  - transformer
KW  - Transformer windings
PB  - Institute of Electrical and Electronics Engineers Inc.
SN  - 21693536 (ISSN)
LA  - English
J2  - IEEE Access
M3  - Article
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 10; Correspondence Address: Z. Wang; School of Electrical and Electronic Engineering, University of Manchester, Manchester, M13 9PL, United Kingdom; email: zhongdong.wang@manchester.ac.uk
ER  -

TY  - CONF
AU  - Ko, W.-J.
AU  - Li, J.J.
TI  - Assessing Discourse Relations in Language Generation from GPT-2
PY  - 2020
T2  - INLG 2020 - 13th International Conference on Natural Language Generation, Proceedings
SP  - 52
EP  - 59
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85104240479&partnerID=40&md5=8c925da06c356fab7e9fcde6348a62e2
AD  - Department of Computer Science, The University of Texas, Austin, United States
AD  - Department of Linguistics, The University of Texas, Austin, United States
AB  - Recent advances in NLP have been attributed to the emergence of large-scale pre-trained language models. GPT-2 (Radford et al., 2019), in particular, is suited for generation tasks given its left-to-right language modeling objective, yet the linguistic quality of its generated text has largely remain unexplored. Our work takes a step in understanding GPT-2's outputs in terms of discourse coherence. We perform a comprehensive study on the validity of explicit discourse relations in GPT-2's outputs under both organic generation and fine-tuned scenarios. Results show GPT-2 does not always generate text containing valid discourse relations; nevertheless, its text is more aligned with human expectation in the fine-tuned scenario. We propose a decoupled strategy to mitigate these problems and highlight the importance of explicitly modeling discourse information. © 2020 Association for Computational Linguistics
KW  - Computational linguistics
KW  - Modeling languages
KW  - Language generation
KW  - Language model
KW  - Large-scales
KW  - Modeling objectives
KW  - Organics
KW  - Natural language processing systems
A2  - Davis B.
A2  - Graham Y.
A2  - Kelleher J.
A2  - Sripada Y.
PB  - Association for Computational Linguistics (ACL)
SN  - 978-195214854-5 (ISBN)
LA  - English
J2  - INLG - Int. Conf. Nat. Lang. Gener., Proc.
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 11; Conference name: 13th International Conference on Natural Language Generation, INLG 2020; Conference date: 15 December 2020 through 18 December 2020; Conference code: 174264
ER  -

TY  - CONF
AU  - Liu, S.
AU  - Guo, Y.
AU  - Li, B.
AU  - Ren, F.
TI  - LMVE at SemEval-2020 Task 4: Commonsense Validation and Explanation using Pretraining Language Model
PY  - 2020
T2  - 14th International Workshops on Semantic Evaluation, SemEval 2020 - co-located 28th International Conference on Computational Linguistics, COLING 2020, Proceedings
SP  - 562
EP  - 568
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85095340753&partnerID=40&md5=6c1e3ad32b06290d6920bf9069093d05
AD  - School of Computer Science and Engineering, Northeastern University
AD  - Key Laboratory of Data Analytics and Optimization for Smart Industry, Northeastern University, Ministry of Education
AB  - This paper describes our submission to subtask a and b of SemEval-2020 Task 4. For subtask a, we use a ALBERT based model with improved input form to pick out the common sense statement from two statement candidates. For subtask b, we use a multiple choice model enhanced by hint sentence mechanism to select the reason from given options about why a statement is against common sense. Besides, we propose a novel transfer learning strategy between subtasks which help improve the performance. The accuracy scores of our system are 95.6/94.9 on official test set2 and rank 7th/2nd on Post-Evaluation leaderboard. © 2020 14th International Workshops on Semantic Evaluation, SemEval 2020 - co-located 28th International Conference on Computational Linguistics, COLING 2020, Proceedings. All rights reserved.
KW  - Computational linguistics
KW  - Learning systems
KW  - Choice model
KW  - Common sense
KW  - Language model
KW  - Learning strategy
KW  - Multiple choice
KW  - Performance
KW  - Pre-training
KW  - Subtask
KW  - Test sets
KW  - Transfer learning
KW  - Semantics
A2  - Herbelot A.
A2  - Zhu X.
A2  - Palmer A.
A2  - Schneider N.
A2  - May J.
A2  - Shutova E.
PB  - International Committee for Computational Linguistics
SN  - 978-195214831-6 (ISBN)
LA  - English
J2  - Int. Workshops Semant. Eval., SemEval - co-located Int. Conf. Comput. Linguist., COLING , Proc.
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 2; Correspondence Address: F. Ren; School of Computer Science and Engineering, Northeastern University; email: renfeiliang@ise.neu.edu.cn; Conference name: 14th International Workshops on Semantic Evaluation, SemEval 2020; Conference date: 12 December 2020 through 13 December 2020; Conference code: 174265
ER  -

TY  - CONF
AU  - Markchom, T.
AU  - Dhruva, B.
AU  - Pravin, C.
AU  - Liang, H.
TI  - UoR at SemEval-2020 Task 4: Pre-trained Sentence Transformer Models for Commonsense Validation and Explanation
PY  - 2020
T2  - 14th International Workshops on Semantic Evaluation, SemEval 2020 - co-located 28th International Conference on Computational Linguistics, COLING 2020, Proceedings
SP  - 430
EP  - 436
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85095264571&partnerID=40&md5=9eeb1f7bfadb75b971afa8a5f65f57ae
AD  - University of Reading White Knights, Berkshire, RG6 6AH, United Kingdom
AB  - SemEval Task 4 Commonsense Validation and Explanation Challenge is to validate whether a system can differentiate natural language statements that make sense from those that do not make sense. Two subtasks, A and B, are focused in this work, i.e., detecting against-common-sense statements and selecting explanations of why they are false from the given options. Intuitively, commonsense validation requires additional knowledge beyond the given statements. Therefore, we propose a system utilising pre-trained sentence transformer models based on BERT, RoBERTa and DistillBERT architectures to embed the statements before classification. According to the results, these embeddings can improve the performance of the typical MLP and LSTM classifiers as downstream models of both subtasks compared to regular tokenised statements. These embedded statements are shown to comprise additional information from external resources which help validate common sense in natural language. © 2020 14th International Workshops on Semantic Evaluation, SemEval 2020 - co-located 28th International Conference on Computational Linguistics, COLING 2020, Proceedings. All rights reserved.
KW  - Classification (of information)
KW  - Computational linguistics
KW  - Semantics
KW  - Additional knowledge
KW  - Common sense
KW  - Down-stream
KW  - Embeddings
KW  - Language statements
KW  - Model-based OPC
KW  - Natural languages
KW  - Performance
KW  - Subtask
KW  - Transformer modeling
KW  - Long short-term memory
A2  - Herbelot A.
A2  - Zhu X.
A2  - Palmer A.
A2  - Schneider N.
A2  - May J.
A2  - Shutova E.
PB  - International Committee for Computational Linguistics
SN  - 978-195214831-6 (ISBN)
LA  - English
J2  - Int. Workshops Semant. Eval., SemEval - co-located Int. Conf. Comput. Linguist., COLING , Proc.
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 2; Conference name: 14th International Workshops on Semantic Evaluation, SemEval 2020; Conference date: 12 December 2020 through 13 December 2020; Conference code: 174265
ER  -

TY  - CONF
AU  - Fulda, N.
TI  - Rethinking Our Assumptions About Language Model Evaluation
PY  - 2020
T2  - Advances in Intelligent Systems and Computing
VL  - 1229 AISC
SP  - 599
EP  - 609
DO  - 10.1007/978-3-030-52246-9_44
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85088499748&doi=10.1007%2f978-3-030-52246-9_44&partnerID=40&md5=9722a7833a0425391af95943f62411ae
AD  - Brigham Young University, Provo, 84602, UT, United States
AB  - Many applications of pre-trained language models use their learned internal representations, also known as word- or sentence embeddings, as input features for other language-based tasks. Over recent years, this has led to the implicit assumption that the quality of such embeddings is determined solely by their ability to facilitate transfer learning. In this position paper we argue that pre-trained linguistic embeddings have value above and beyond their utility as input features for downstream tasks. We adopt a paradigm in which they are instead treated as implicit knowledge repositories that can be used to solve common-sense reasoning problems via linear operations on embedded text. To validate this paradigm, we apply our methodology to tasks such as threat detection, emotional classification, and sentiment analysis, and demonstrate that linguistic embeddings show strong potential at solving such tasks directly, without the need for additional training. Motivated by these results, we advocate for empirical evaluations of language models that include vector-based reasoning tasks in addition to more traditional benchmarks, with the ultimate goal of facilitating language-based reasoning, or ‘reasoning in the linguistic domain’. We conclude by analyzing the structure of currently available embedding models and identifying several shortcomings which must be overcome in order to realize the full potential of this approach. © 2020, Springer Nature Switzerland AG.
KW  - Common-sense reasoning
KW  - Language model evaluation
KW  - Language models
KW  - Sentence embeddings
KW  - Word embeddings
KW  - Classification (of information)
KW  - Computational linguistics
KW  - Intelligent computing
KW  - Sentiment analysis
KW  - Transfer learning
KW  - Based reasonings
KW  - Commonsense reasoning
KW  - Emotional classification
KW  - Empirical evaluations
KW  - Implicit knowledge
KW  - Internal representation
KW  - Linear operations
KW  - Threat detection
KW  - Embeddings
A2  - Arai K.
A2  - Kapoor S.
A2  - Bhatia R.
PB  - Springer
SN  - 21945357 (ISSN); 978-303052245-2 (ISBN)
LA  - English
J2  - Adv. Intell. Sys. Comput.
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 0; Correspondence Address: N. Fulda; Brigham Young University, Provo, 84602, United States; email: nfulda@cs.byu.edu; Conference name: Science and Information Conference, SAI 2020; Conference date: 16 July 2020 through 17 July 2020; Conference code: 241959
ER  -

TY  - CONF
AU  - Nedelchev, R.
AU  - Lehmann, J.
AU  - Usbeck, R.
TI  - Language Model Transformers as Evaluators for Open-domain Dialogues
PY  - 2020
T2  - COLING 2020 - 28th International Conference on Computational Linguistics, Proceedings of the Conference
SP  - 6797
EP  - 6808
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85108285068&partnerID=40&md5=6a29c13a1366944ea2b4464113b71bef
AD  - Smart Data Analytics Group, University of Bonn, Germany
AD  - Fraunhofer IAIS, Sankt Augustin, Dresden, Germany
AB  - Computer-based systems for communication with humans are a cornerstone of AI research since the 1950s. So far, the most effective way to assess the quality of the dialogues produced by these systems is to use resource-intensive manual labor instead of automated means. In this work, we investigate whether language models (LM) based on transformer neural networks can indicate the quality of a conversation. In a general sense, language models are methods that learn to predict one or more words based on an already given context. Due to their unsupervised nature, they are candidates for efficient, automatic indication of dialogue quality. We demonstrate that human evaluators have a positive correlation between the output of the language models and scores. We also provide some insights into their behavior and inner-working in a conversational context. © 2020 COLING 2020 - 28th International Conference on Computational Linguistics, Proceedings of the Conference. All rights reserved.
KW  - Computer-based system
KW  - Language model
KW  - Learn+
KW  - Manual labors
KW  - Model transformers
KW  - Model-based OPC
KW  - Neural-networks
KW  - Positive correlations
KW  - Computational linguistics
A2  - Scott D.
A2  - Bel N.
A2  - Zong C.
PB  - Association for Computational Linguistics (ACL)
SN  - 978-195214827-9 (ISBN)
LA  - English
J2  - COLING - Int. Conf. Comput. Linguist., Proc. Conf.
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 7; Conference name: 28th International Conference on Computational Linguistics, COLING 2020; Conference date: 8 December 2020 through 13 December 2020; Conference code: 186886
ER  -

TY  - CONF
AU  - Mzamo, L.
AU  - Helberg, A.
AU  - Bosch, S.
TI  - Evaluation of combined bi-directional branching entropy language models for morphological segmentation of isiXhosa
PY  - 2019
T2  - CEUR Workshop Proceedings
VL  - 2540
SP  - 77
EP  - 89
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85078360799&partnerID=40&md5=a4c3c8bb5984980594b36568b07bc166
AD  - North-West University, Potchefstroom, South Africa
AD  - UNISA, Pretoria, South Africa
AB  - An evaluation of the IsiXhosa Branching Entropy Segmenter (XBES), an unsupervised morphological segmenter for isiXhosa, is presented. The segmenter contributes a combined bi-directional branching entropy language model with an option for modified Kneser-Ney (mKN) smoothing. XBES’s boundary identification accuracy of 77.44 ± 0.32% is comparable to the benchmark Morfessor-Baseline’s 77.2±0.10%. XBES’s f1 score, of 58 ± 0.10%, is significantly better than Morfessor-Baseline’s 48.9 ± 0.75%. The study shows that mKN smoothing degrades performance on branching entropy-based segmentation of isiXhosa, and suggests that better segmentation performance could be achieved in the unsupervised morphological segmentation of isiXhosa, given more data. Copyright © 2019 for this paper by its authors.
KW  - Branching entropy
KW  - IsiXhosa
KW  - Morphological segmentation
KW  - Natural language processing
KW  - Unsupervised machine learning
KW  - Artificial intelligence
KW  - Computational linguistics
KW  - Learning algorithms
KW  - Natural language processing systems
KW  - Bi-directional
KW  - Boundary identification
KW  - IsiXhosa
KW  - Language model
KW  - Morphological segmentation
KW  - NAtural language processing
KW  - Segmentation performance
KW  - Unsupervised machine learning
KW  - Entropy
A2  - Davel M.
A2  - Barnard E.
PB  - CEUR-WS
SN  - 16130073 (ISSN)
LA  - English
J2  - CEUR Workshop Proc.
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 1; Conference name: 2019 South African Forum for Artificial Intelligence Research, FAIR 2019; Conference date: 4 December 2019 through 6 December 2019; Conference code: 156890
ER  -

TY  - JOUR
AU  - Martínez, D.F.
AU  - Céspedes, A.
AU  - García, D.F.
TI  - Evaluation of Thermal Models used to Estimate the Hot-Spot Temperature in Distribution Transformers
ST  - Evaluación de Modelos Térmicos usados para Estimar la Temperatura del Punto Caliente en Transformadores de Distribución
PY  - 2019
T2  - Informacion Tecnologica
VL  - 30
IS  - 3
SP  - 295
EP  - 306
DO  - 10.4067/S0718-07642019000300295
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85068677694&doi=10.4067%2fS0718-07642019000300295&partnerID=40&md5=154dd8397d87e1c7d86b0ad35dc800af
AD  - Escuela de Ingeniería Eléctrica y Electrónica, Facultad de Ingeniería, Universidad del Valle, Calle 13 #100-00, Cali, Colombia
AB  - This paper presents an evaluation of the main transformers thermal models considering the number of input data required and the output data reliability of each model. Also, a brief analysis of transformer thermal behaviour based on the hot-spot temperature is shown. Then, an experimental validation of the thermal models performed in two oil-immersed distribution transformers is described, simulating a load profile in specific periods of time. Finally, the experimental results are compared with data resulting from the implementation of the models in numerical analysis software in order to establish the parametric differences and precision of each model showing that the most optimal performance corresponds to the model of differential equations of the International Electrotechnical Commission. © 2019 Centro de Informacion Tecnologica. All rights reserved.
KW  - Assessment
KW  - Hot-spot temperature
KW  - Load profile
KW  - Oil-immersed transformers
KW  - Thermal models
KW  - Differential equations
KW  - Electric transformers
KW  - Assessment
KW  - Hotspot temperature
KW  - Load profiles
KW  - Oil immersed transformers
KW  - Thermal model
KW  - Thermography (temperature measurement)
PB  - Centro de Informacion Tecnologica
SN  - 07168756 (ISSN)
LA  - Spanish
J2  - Inf Tecnol
M3  - Article
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 3; Correspondence Address: A. Céspedes; Escuela de Ingeniería Eléctrica y Electrónica, Facultad de Ingeniería, Universidad del Valle, Cali, Calle 13 #100-00, Colombia; email: alexander.cespedes@correounivalle.edu.co; CODEN: ITECF
ER  -

TY  - CONF
AU  - Metzker, I.D.
AU  - De Conti, A.
AU  - Mariano, D.G.B.
AU  - Silvino, J.L.
TI  - Proposition and validation of full-order wideband models of two single-phase distribution transformers of different power ratings
PY  - 2018
T2  - SBSE 2018 - 7th Brazilian Electrical Systems Symposium
SP  - 1
EP  - 6
DO  - 10.1109/SBSE.2018.8395907
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85050193286&doi=10.1109%2fSBSE.2018.8395907&partnerID=40&md5=7ebc530213334081e296b4a435346a25
AD  - PPGEE-Programa de Pós-Graduação em Engenharia Elétrica, LRC-Lightning Research Center, Departamento de Engenharia Elétrica, UFMG-Universidade Federal de Minas Gerais, Belo Horizonte-MG, Brazil
AB  - This paper proposes wideband models for two 7.967 kV/240-120 V single-phase transformers with power ratings of 5 kVA and 10 kVA usually applied in distribution networks. The models are validated in time domain by calculating transferred voltages for the application of two different impulse voltage waveforms on the high-voltage side considering two different terminal conditions. The results show good agreement with experimental data. © 2018 IEEE.
KW  - Impulse voltages
KW  - Single-phase distribution transformer
KW  - Transferred voltages
KW  - Wideband models
KW  - High voltage
KW  - Impulse voltage
KW  - Power ratings
KW  - Single phase
KW  - Single-phase transformers
KW  - Time domain
KW  - Wide-band
KW  - Electric transformers
PB  - Institute of Electrical and Electronics Engineers Inc.
SN  - 978-153863363-2 (ISBN)
LA  - Portuguese
J2  - SBSE - Braz. Electr. Syst. Symp.
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 0; Conference name: 7th Brazilian Electrical Systems Symposium, SBSE 2018; Conference date: 12 May 2018 through 16 May 2018; Conference code: 137506
ER  -

TY  - JOUR
AU  - Kouremenos, D.
AU  - Ntalianis, K.
AU  - Kollias, S.
TI  - A novel rule based machine translation scheme from Greek to Greek Sign Language: Production of different types of large corpora and Language Models evaluation
PY  - 2018
T2  - Computer Speech and Language
VL  - 51
SP  - 110
EP  - 135
DO  - 10.1016/j.csl.2018.04.001
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85046446621&doi=10.1016%2fj.csl.2018.04.001&partnerID=40&md5=5412191c0902785f604ea950ed31f28b
AD  - Electrical and Computer Engineering Department, National Technical University of Athens, Zografou, Athens, Greece
AB  - One of the aims of assistive technologies is to help people with disabilities to communicate with others and to provide means of access to information. As an aid to Deaf people, in this work we present a novel prototype Rule Based Machine Translation (RBMT) system for the creation of large and quality written Greek Sign Language (GSL) glossed corpora from Greek text. In particular, the proposed RBMT system assists the professional GSL translator in speeding up the production of different kinds of GSL glossed corpora. Then each glossed corpus is used for the production/creation of Language Model (LM) n-grams. With the GSL glossed corpus from Greek text, we can build, test and evaluate different kinds of Language Models for different kinds of glossed GSL corpora. Here, it should be noted that it does not require grammar knowledge of GSL but only very basic GSL phenomena covered by manual RBMT rules as it assists the professional human translator. Furthermore, it should also be stressed that Language Models for written GSL gloss are missing from the scientific literature, thus this work is pioneer in this field. Evaluation of the proposed scheme is carried out for the weather reports domain, where 20,284 tokens and 1000 sentences have been produced. By using the BiLingual Evaluation Understudy (BLEU) metric score, our prototype RBMT system achieves a relative score of 0.84 (84%) for 4-grams and 0.9 (90%) for 1-grams. © 2018 Elsevier Ltd
KW  - Deaf people communication
KW  - Greek Sign Language
KW  - GSL
KW  - Machine translation
KW  - Computer aided language translation
KW  - Assistive technology
KW  - Deaf peoples
KW  - Machine translations
KW  - People with disabilities
KW  - Prototype rules
KW  - Rule-based machine translations
KW  - Scientific literature
KW  - Sign language
KW  - Computational linguistics
PB  - Academic Press
SN  - 08852308 (ISSN)
LA  - English
J2  - Comput Speech Lang
M3  - Article
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 12; Correspondence Address: D. Kouremenos; Electrical and Computer Engineering Department, National Technical University of Athens, Zografou, Greece; email: dkourem@gmail.com; CODEN: CSPLE
ER  -

TY  - CONF
AU  - Soni, S.
AU  - Roberts, K.
TI  - Evaluation of dataset selection for pre-training and fine-tuning transformer language models for clinical question answering
PY  - 2020
T2  - LREC 2020 - 12th International Conference on Language Resources and Evaluation, Conference Proceedings
SP  - 5532
EP  - 5538
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85095336457&partnerID=40&md5=dc53bd3aa9ea03d7bed3d0b37c248522
AD  - School of Biomedical Informatics, University of Texas, Health Science Center, Houston, United States
AB  - We evaluate the performance of various Transformer language models, when pre-trained and fine-tuned on different combinations of open-domain, biomedical, and clinical corpora on two clinical question answering (QA) datasets (CliCR and emrQA). We perform our evaluations on the task of machine reading comprehension, which involves training the model to answer a question given an unstructured context paragraph. We conduct a total of 48 experiments on different combinations of the large open-domain and domain-specific corpora. We found that an initial fine-tuning on an open-domain dataset, SQuAD, consistently improves the clinical QA performance across all the model variants. © European Language Resources Association (ELRA), licensed under CC-BY-NC
KW  - Clinical question answering
KW  - Machine comprehension
KW  - Transfer learning
KW  - Computational linguistics
KW  - Dataset selections
KW  - Domain specific
KW  - Fine tuning
KW  - Language model
KW  - Pre-training
KW  - Question Answering
KW  - Reading comprehension
KW  - Natural language processing systems
A2  - Calzolari N.
A2  - Bechet F.
A2  - Blache P.
A2  - Choukri K.
A2  - Cieri C.
A2  - Declerck T.
A2  - Goggi S.
A2  - Isahara H.
A2  - Maegaard B.
A2  - Mariani J.
A2  - Mazo H.
A2  - Moreno A.
A2  - Odijk J.
A2  - Piperidis S.
PB  - European Language Resources Association (ELRA)
SN  - 979-109554634-4 (ISBN)
LA  - English
J2  - LREC - Int. Conf. Lang. Resour. Eval., Conf. Proc.
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 23; Conference name: 12th International Conference on Language Resources and Evaluation, LREC 2020; Conference date: 11 May 2020 through 16 May 2020; Conference code: 164155
ER  -

TY  - JOUR
AU  - Tahir, A.
AU  - Elhaffar, A.
AU  - Sudhoff, S.
AU  - Pekarek, S.
TI  - Performance evaluation of a tape-wound core transformer using meta-model based scaling laws
PY  - 2017
T2  - International Journal of Computing and Digital Systems
VL  - 6
IS  - 6
SP  - 339
EP  - 348
DO  - 10.12785/IJCDS/060604
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85104918191&doi=10.12785%2fIJCDS%2f060604&partnerID=40&md5=0ceb3e6f7c88308a7ab172949d9757c9
AD  - Electrical and Electronics Engineering Department, University of Benghazi, Benghazi, Libya
AD  - Electrical and Computer Engineering Department, Sultan Qaboos University, Muscat, Oman
AD  - School of Electrical and Computer Engineering, Purdue University, West Lafayette, IN, United States
AB  - Due to their several advantages, tape-wound core transformers are used in various power electronic systems. To obtain the optimal designs of the transformer using multi-objective optimization techniques, the effect of its performance on the whole system should be accounted for without computational liability. This may be achieved by deriving a meta-model based on scaling laws which relate the transformer performance equations to general quantities such as rated power, frequency and current density. A per-unit T-equivalent circuit and magnetic equivalent circuit model are used to obtain the transformer scaled model. By using genetic-algorithms based multi-objective optimization and curve fitting techniques, the transformer meta-model is derived. The derived meta-model is used to study the effect of varying frequency and rated power on the transformer performance. © 2017 University of Bahrain. All rights reserved.
KW  - MEC model
KW  - Meta-model
KW  - Operating point analysis
KW  - Scaling laws
KW  - T-equivalent circuit
KW  - Tape-wound core transformer
PB  - University of Bahrain
SN  - 2210142X (ISSN)
LA  - English
J2  - Int. J. Comput. Digit. Syst.
M3  - Article
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 2
ER  -

TY  - CONF
AU  - Lothritz, C.
AU  - Allix, K.
AU  - Veiber, L.
AU  - Bissyandé, T.F.
AU  - Klein, J.
TI  - Evaluating Pretrained Transformer-based Models on the Task of Fine-Grained Named Entity Recognition
PY  - 2020
T2  - COLING 2020 - 28th International Conference on Computational Linguistics, Proceedings of the Conference
SP  - 3750
EP  - 3760
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85112387411&partnerID=40&md5=302b9a1a91b57b841c71ac9fd81fde86
AD  - University of Luxembourg, Luxembourg
AB  - Named Entity Recognition (NER) is a fundamental Natural Language Processing (NLP) task and has remained an active research field. In recent years, transformer models and more specifically the BERT model developed at Google revolutionised the field of NLP. While the performance of transformer-based approaches such as BERT has been studied for NER, there has not yet been a study for the fine-grained Named Entity Recognition (FG-NER) task. In this paper, we compare three transformer-based models (BERT, RoBERTa, and XLNet) to two non-transformer-based models (CRF and BiLSTM-CNN-CRF). Furthermore, we apply each model to a multitude of distinct domains. We find that transformer-based models incrementally outperform the studied non-transformer-based models in most domains with respect to the F1 score. Furthermore, we find that the choice of domain significantly influenced the performance regardless of the respective data size or the model chosen. © 2020 COLING 2020 - 28th International Conference on Computational Linguistics, Proceedings of the Conference. All rights reserved.
KW  - Computational linguistics
KW  - Data size
KW  - F1 scores
KW  - Fine grained
KW  - Google+
KW  - Language processing
KW  - Named entity recognition
KW  - Natural languages
KW  - Performance
KW  - Research fields
KW  - Transformer modeling
KW  - Natural language processing systems
A2  - Scott D.
A2  - Bel N.
A2  - Zong C.
PB  - Association for Computational Linguistics (ACL)
SN  - 978-195214827-9 (ISBN)
LA  - English
J2  - COLING - Int. Conf. Comput. Linguist., Proc. Conf.
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 12; Conference name: 28th International Conference on Computational Linguistics, COLING 2020; Conference date: 8 December 2020 through 13 December 2020; Conference code: 186886
ER  -

TY  - CONF
AU  - Mharakurwa, E.T.
AU  - Nyakoe, G.N.
AU  - Akumu, A.O.
TI  - Transformer Remnant Life Estimation and Asset Management model based on Insulation Stress Assessment
PY  - 2019
T2  - 2019 IEEE Electrical Insulation Conference, EIC 2019
C7  - 9046526
SP  - 325
EP  - 329
DO  - 10.1109/EIC43217.2019.9046526
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85083487453&doi=10.1109%2fEIC43217.2019.9046526&partnerID=40&md5=399370ac235f3e3d0562b65b7664fc00
AD  - Electrical Engineering Pan African University Institute for Basic Sciences, Technology and Innovation (PAUSTI), P.O. Box 62000-00200, Nairobi, Kenya
AD  - Electrical Engineering Jomo Kenyatta University of Agriculture and Technology (JKUAT), P.O. Box 62000-00200, Nairobi, Kenya
AD  - Electrical Engineering Tshwane University of Technology (TUT), Private Bag X680 0001, Pretoria, South Africa
AB  - The performance and useful life expectancy of a power transformer generally depends on the condition of oil-impregnated paper insulation system that has a finite life span. End of technical life of a power transformer is reached when some of the insulation diagnostic characteristics drop to a level where further operation is unacceptable. Thus, recurrent evaluation of the transformer insulation system diagnostics enhances better estimation of transformer residual life. However, being a function of voluminous conflicting attributes, the design feature, changing operating conditions, and different maintenance strategies, a flawless affirmation of the criteria governing the transformer remnant life estimation is a very complex issue. Power transformer operational condition that can be mirrored by criticality of ageing and fault stress levels has substantial impact on its residual life estimation. This paper explores the possibility of developing a remnant life estimation and asset management decision model based on diagnostics of transformer insulation characteristics. The proposed model is developed upon the integration of the fuzzy logic diagnostic tool and the fuzzy logic remnant life mapping model. The diagnostic details are signified by fuzzy rules for an accurate assessment to reach a defined outcome in terms of fault stress level and energy of faulting, ageing stresses and transformer condition. A multicriteria analysis was used in developing the model whereby the outcome of the model is achieved by including the combined effect of individual sub outcomes using fuzzification of all the employed attributes. The developed remnant life model is validated using data collected from several in-service mineral oil immersed transformers. Results show that the proposed model provides an approximate but practical means of remnant life estimation and asset management decision. © 2019 IEEE.
KW  - Asset management
KW  - End of technical life
KW  - insulation degradation
KW  - insulation stress
KW  - remnant life estimation
KW  - Asset management
KW  - Decision making
KW  - Fuzzy inference
KW  - Fuzzy logic
KW  - Insulation
KW  - Power transformers
KW  - Changing operating conditions
KW  - Insulation diagnostics
KW  - Maintenance strategies
KW  - Multi Criteria Analysis
KW  - Oil immersed transformers
KW  - Oil-impregnated paper insulation
KW  - Operational conditions
KW  - Transformer insulation
KW  - Oil filled transformers
PB  - Institute of Electrical and Electronics Engineers Inc.
SN  - 978-153867624-0 (ISBN)
LA  - English
J2  - IEEE Electr. Insul. Conf., EIC
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 1; Conference name: 2019 IEEE Electrical Insulation Conference, EIC 2019; Conference date: 16 June 2019 through 19 June 2019; Conference code: 158871
ER  -

TY  - CONF
AU  - Rodrigues, R.C.
AU  - Rodrigues, J.
AU  - de Castro, P.V.Q.
AU  - da Silva, N.F.F.
AU  - Soares, A.
TI  - Portuguese language models and word embeddings: Evaluating on semantic similarity tasks
PY  - 2020
T2  - Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)
VL  - 12037 LNAI
SP  - 239
EP  - 248
DO  - 10.1007/978-3-030-41505-1_23
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85081578343&doi=10.1007%2f978-3-030-41505-1_23&partnerID=40&md5=cbbbcc4838f077c04a916a00d8692e91
AD  - Institute of Informatics, Federal University of Goiás, Goiânia, Brazil
AD  - Department of Computer Science, Federal University of São Carlos, São Carlos, Brazil
AB  - Deep neural language models which achieved state-of-the-art results on downstream natural language processing tasks have recently been trained for the Portuguese language. However, studies that systematically evaluate such models are still necessary for several applications. In this paper, we propose to evaluate the performance of deep neural language models on the semantic similarity tasks provided by the ASSIN dataset against classical word embeddings, both for Brazilian Portuguese and for European Portuguese. Our experiments indicate that the ELMo language model was able to achieve better accuracy than any other pretrained model which has been made publicly available for the Portuguese language, and that performing vocabulary reduction on the dataset before training not only improved the standalone performance of ELMo, but also improved its performance while combined with classical word embeddings. We also demonstrate that FastText skip-gram embeddings can have a significantly better performance on semantic similarity tasks than it was indicated by previous studies in this field. © Springer Nature Switzerland AG 2020.
KW  - Deep neural language models
KW  - Portuguese language
KW  - Semantic textual similarity
KW  - Computational linguistics
KW  - Embeddings
KW  - Semantics
KW  - Language model
KW  - NAtural language processing
KW  - Portuguese languages
KW  - Semantic similarity
KW  - State of the art
KW  - Textual similarities
KW  - Natural language processing systems
A2  - Quaresma P.
A2  - Vieira R.
A2  - Gonçalves T.
A2  - Aluísio S.
A2  - Moniz H.
A2  - Batista F.
PB  - Springer
SN  - 03029743 (ISSN); 978-303041504-4 (ISBN)
LA  - English
J2  - Lect. Notes Comput. Sci.
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 6; Correspondence Address: R.C. Rodrigues; Institute of Informatics, Federal University of Goiás, Goiânia, Brazil; email: ruanchaves93@gmail.com; Conference name: 14th International Conference on Computational Processing of the Portuguese Language, PROPOR 2020; Conference date: 2 March 2020 through 4 March 2020; Conference code: 237939
ER  -

TY  - JOUR
AU  - Dong, M.
AU  - Zheng, H.
AU  - Zhang, Y.
AU  - Shi, K.
AU  - Yao, S.
AU  - Kou, X.
AU  - Ding, G.
AU  - Guo, L.
TI  - A novel maintenance decision making model of power transformers based on reliability and economy assessment
PY  - 2019
T2  - IEEE Access
VL  - 7
C7  - 8635505
SP  - 28778
EP  - 28790
DO  - 10.1109/ACCESS.2019.2897606
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85063275511&doi=10.1109%2fACCESS.2019.2897606&partnerID=40&md5=8e2619ac74cc4ec8bb78f6924cdaa00e
AD  - State Grid Henan Electric Power Research Institute, Zhengzhou, 450052, China
AD  - Guangxi Key Laboratory of Power System Optimization and Energy Technology, Guangxi University, Nanning, 530004, China
AD  - Yellow River Engineering Consulting Co., Ltd., Zhengzhou, 450034, China
AB  - The present 'condition-based maintenance decision making' of power transformers will cause large financial losses to electric enterprises, because of not having taken reliability and economy into consideration. To solve this problem, a maintenance decision-making model with the consideration of reliability and economy was established to choose the best maintenance strategy for oil-filled transformers. With the corrected parameters of operating environment and maintenance records, a condition assessment model including DGA test, oil test, and the electrical test was proposed to decide the comprehensive health index of transformers. After establishing the relationship between the fault rate and the comprehensive health index, a reliability evaluation model was formed, which can simulate the impact of different maintenance types. Taking the reliability and economy operation of transformers into consideration, a particle swarm optimization method was developed to solve the optimization model and select the best maintenance strategy according to the current condition of transformers. Two cases were studied and the results demonstrate that the proposed model offers an improved maintenance strategy. © 2019 IEEE.
KW  - comprehensive health index
KW  - fault rate
KW  - maintenance decision making
KW  - Power transformers
KW  - risk assessment
KW  - Decision making
KW  - Electric losses
KW  - Electric transformer testing
KW  - Health
KW  - Health risks
KW  - Losses
KW  - Maintenance
KW  - Particle swarm optimization (PSO)
KW  - Power transformers
KW  - Reliability
KW  - Risk assessment
KW  - Condition assessments
KW  - Condition based maintenance
KW  - Fault rates
KW  - Health indices
KW  - Maintenance decision making
KW  - Maintenance strategies
KW  - Operating environment
KW  - Reliability Evaluation
KW  - Oil filled transformers
PB  - Institute of Electrical and Electronics Engineers Inc.
SN  - 21693536 (ISSN)
LA  - English
J2  - IEEE Access
M3  - Article
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 35; Correspondence Address: H. Zheng; Guangxi Key Laboratory of Power System Optimization and Energy Technology, Guangxi University, Nanning, 530004, China; email: hanbozheng@163.com
ER  -

TY  - JOUR
AU  - Li, Y.
AU  - Liu, N.
AU  - Liang, Y.
AU  - Xu, Y.
AU  - Lin, D.
AU  - Mu, H.
AU  - Zhang, G.
TI  - A Model of Load Capacity Assessment for Oil-immersed Transformer by Using Temperature Rise Characteristics
ST  - 基于温升特性的油浸式变压器负荷能力评估模型
PY  - 2018
T2  - Zhongguo Dianji Gongcheng Xuebao/Proceedings of the Chinese Society of Electrical Engineering
VL  - 38
IS  - 22
SP  - 6737
EP  - 6745
DO  - 10.13334/j.0258-8013.pcsee.180075
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85060114998&doi=10.13334%2fj.0258-8013.pcsee.180075&partnerID=40&md5=54c8bba6ca937c9a227b26b168247b69
AD  - State Key Laboratory of Electrical Insulation and Power Equipment, Xi'an Jiaotong University, Xi'an, 710049, Shaanxi Province, China
AD  - Electric Power Research Institute of Hainan Power Grid Co., Ltd., Haikou, 570125, Hainan Province, China
AB  - The real-time load capacity assessment of transformers provides access to fully utilization of the potential load capacity of transformers while insuring the safe performance, which becomes the tendency of assets lean management. In this paper, the multi-thermal sources and heat transfer process of transformers were analyzed, and the absorbed power from sunshine radiation was introduced into the computation of winding hot-spot temperature. Then considering the DC resistance variation of winding and oil viscosity with oil temperature, the algorithms of thermal source power and thermal resistance were modified to improve the calculation accuracy of hot-spot temperature. Combined with the constraints of transformer load capacity, such as the threshold of top-oil temperature, hot-spot temperature, relative loss of life and the capacity of auxiliary equipment, a model of load capacity assessment for oil-immersed transformer was proposed, which takes different load types of transformers into account. The model was verified with the measured data of two transformers. The results show that the relative error of the improved algorithm of hot-spot temperature has been reduced by 2.5% compared with the IEC guide method. Besides, the results of load capacity assessment suggest that the actual load capacity of the test transformer is about 115% of the rated value, which means extra load capacity could be still exploited in the operation condition. © 2018 Chin. Soc. for Elec. Eng.
KW  - Constraining conditions
KW  - Hot-spot temperature
KW  - Load capacity
KW  - Power transformer
KW  - Temperature rise
KW  - Auxiliary equipment
KW  - Electric transformer testing
KW  - Heat transfer
KW  - Power transformers
KW  - Winding
KW  - Calculation accuracy
KW  - Constraining conditions
KW  - Heat transfer process
KW  - Hotspot temperature
KW  - Load capacity
KW  - Oil immersed transformers
KW  - Temperature rise
KW  - Winding hot spot temperatures
KW  - Oil filled transformers
PB  - Chinese Society for Electrical Engineering
SN  - 02588013 (ISSN)
LA  - Chinese
J2  - Zhongguo Dianji Gongcheng Xuebao
M3  - Article
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 19; CODEN: ZDGXE
ER  -

TY  - CONF
AU  - Soloveva, A.
TI  - SO at SemEval-2020 Task 7: DeepPavlov Logistic Regression with BERT Embeddings vs SVR at Funniness Evaluation
PY  - 2020
T2  - 14th International Workshops on Semantic Evaluation, SemEval 2020 - co-located 28th International Conference on Computational Linguistics, COLING 2020, Proceedings
SP  - 1055
EP  - 1059
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85111379951&partnerID=40&md5=82254a9a1a237ed4ea8756ec47ea06a8
AD  - Lomonosov MSU
AB  - This paper describes my efforts in evaluating how editing news headlines can make them funnier within the frames of SemEval 2020 Task 7. I participated in both of the sub-tasks: Sub-Task 1 “Regression” and Sub-task 2 “Predict the funnier of the two edited versions of an original headline”. I experimented with a number of different models, but ended up using DeepPavlov logistic regression (LR) with BERT English cased embeddings for the first sub-task and support vector regression model (SVR) for the second. RMSE score obtained for the first task was 0.65099 and accuracy for the second - 0.32915. © 2020 14th International Workshops on Semantic Evaluation, SemEval 2020 - co-located 28th International Conference on Computational Linguistics, COLING 2020, Proceedings. All rights reserved.
KW  - Computational linguistics
KW  - Logistic regression
KW  - Semantics
KW  - Embeddings
KW  - Logistics regressions
KW  - Subtask
KW  - Support vector regression models
KW  - Embeddings
A2  - Herbelot A.
A2  - Zhu X.
A2  - Palmer A.
A2  - Schneider N.
A2  - May J.
A2  - Shutova E.
PB  - International Committee for Computational Linguistics
SN  - 978-195214831-6 (ISBN)
LA  - English
J2  - Int. Workshops Semant. Eval., SemEval - co-located Int. Conf. Comput. Linguist., COLING , Proc.
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 2; Correspondence Address: A. Soloveva; Lomonosov MSU; email: nit-sol@mail.ru; Conference name: 14th International Workshops on Semantic Evaluation, SemEval 2020; Conference date: 12 December 2020 through 13 December 2020; Conference code: 174265
ER  -

TY  - CONF
AU  - Zhou, X.
AU  - Zhang, Y.
AU  - Cui, L.
AU  - Huang, D.
TI  - Evaluating commonsense in pre-trained language models
PY  - 2020
T2  - AAAI 2020 - 34th AAAI Conference on Artificial Intelligence
SP  - 9733
EP  - 9740
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85106605705&partnerID=40&md5=85f9c9562f5e9a4a0910a3a3e28f1328
AD  - University of Washington
AD  - School of Engineering, Westlake University
AD  - Zhejiang University
AB  - Contextualized representations trained over large raw text data have given remarkable improvements for NLP tasks including question answering and reading comprehension. There have been works showing that syntactic, semantic and word sense knowledge are contained in such representations, which explains why they benefit such tasks. However, relatively little work has been done investigating commonsense knowledge contained in contextualized representations, which is crucial for human question answering and reading comprehension. We study the commonsense ability of GPT, BERT, XLNet, and RoBERTa by testing them on seven challenging benchmarks, finding that language modeling and its variants are effective objectives for promoting models’ commonsense ability while bi-directional context and larger training set are bonuses. We additionally find that current models do poorly on tasks require more necessary inference steps. Finally, we test the robustness of models by making dual test cases, which are correlated so that the correct prediction of one sample should lead to correct prediction of the other. Interestingly, the models show confusion on these test cases, which suggests that they learn commonsense at the surface rather than the deep level. We release a test set, named CATs publicly, for future research. Copyright © 2020, Association for the Advancement of Artificial Intelligence (www.aaai.org). All rights reserved.
KW  - Ability testing
KW  - Computational linguistics
KW  - Modeling languages
KW  - Natural language processing systems
KW  - Semantics
KW  - Bi-directional contexts
KW  - Commonsense knowledge
KW  - Current models
KW  - Language model
KW  - Question Answering
KW  - Reading comprehension
KW  - Robustness of model
KW  - Training sets
KW  - Artificial intelligence
PB  - AAAI press
SN  - 978-157735835-0 (ISBN)
LA  - English
J2  - AAAI - AAAI Conf. Artif. Intell.
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 89; Correspondence Address: X. Zhou; University of Washington; email: xuhuizh@uw.edu; Conference name: 34th AAAI Conference on Artificial Intelligence, AAAI 2020; Conference date: 7 February 2020 through 12 February 2020; Conference code: 166426
ER  -

TY  - CONF
AU  - Nikolovski, V.
AU  - Kitanovski, D.
AU  - Trajanov, D.
AU  - Chorbev, I.
TI  - Case Study: Predicting Students Objectivity in Self-evaluation Responses Using Bert Single-Label and Multi-Label Fine-Tuned Deep-Learning Models
PY  - 2020
T2  - Communications in Computer and Information Science
VL  - 1316
SP  - 98
EP  - 110
DO  - 10.1007/978-3-030-62098-1_9
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85097375396&doi=10.1007%2f978-3-030-62098-1_9&partnerID=40&md5=59a8e4fc860ddc9efb9464b76cbc3c0c
AD  - Faculty of Computer Science and Engineering, Ss. Cyril and Methodius University in Skopje, Rugjer Boshkovikj 16, Skopje, 1000, North Macedonia
AB  - Students’ feedback data regarding teachers, courses, teaching tools, and methods represent valuable information for the education system. The obtained data can contribute in enhancing and improving the education system. Feedback from students is of great essence in the process of extracting hidden knowledge using various techniques for data mining and knowledge discovery. This paper presents various tools and methods for analyzing students’ feedback using Sentiment and Semantic analyses. The essential task in Sentiment analysis is to extract the particular sentiment from textual student responses in terms of negative and positive reactions, while the Semantic analysis contributes to combine textual response in the specific group based on questions. The output produced by the Sentiment and Semantic analyses provides a direct relationship between qualitative and quantitative parts of the evaluation in the form of student comments and grades. © 2020, Springer Nature Switzerland AG.
KW  - Bert
KW  - Data analyses
KW  - Data processing
KW  - Deep learning
KW  - Machine learning
KW  - Natural language processing
KW  - Text mining
KW  - Data mining
KW  - Education computing
KW  - Learning systems
KW  - Semantics
KW  - Sentiment analysis
KW  - Students
KW  - Data mining and knowledge discovery
KW  - Education systems
KW  - Hidden knowledge
KW  - Learning models
KW  - Self evaluation
KW  - Semantic analysis
KW  - Student response
KW  - Tools and methods
KW  - Deep learning
A2  - Dimitrova V.
A2  - Dimitrovski I.
PB  - Springer Science and Business Media Deutschland GmbH
SN  - 18650929 (ISSN); 978-303062097-4 (ISBN)
LA  - English
J2  - Commun. Comput. Info. Sci.
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 2; Correspondence Address: V. Nikolovski; Faculty of Computer Science and Engineering, Ss. Cyril and Methodius University in Skopje, Skopje, Rugjer Boshkovikj 16, 1000, North Macedonia; email: vlatko.nikolovski@finki.ukim.mk; Conference name: 12th International ICT Innovations Conference, ICT Innovations 2020; Conference date: 24 September 2020 through 26 September 2020; Conference code: 251069
ER  -

TY  - CONF
AU  - Sears, D.R.W.
AU  - Korzeniowski, F.
AU  - Widmer, G.
TI  - Evaluating language models of tonal harmony
PY  - 2018
T2  - Proceedings of the 19th International Society for Music Information Retrieval Conference, ISMIR 2018
SP  - 211
EP  - 217
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85069862591&partnerID=40&md5=91a52b68f33ebb04f97520d35d9e0d12
AD  - College of Visual and Performing Arts, Texas Tech University, Lubbock, United States
AD  - Institute of Computational Perception, Johannes Kepler University, Linz, Austria
AB  - This study borrows and extends probabilistic language models from natural language processing to discover the syntactic properties of tonal harmony. Language models come in many shapes and sizes, but their central purpose is always the same: to predict the next event in a sequence of letters, words, notes, or chords. However, few studies employing such models have evaluated the most state-of-the-art architectures using a large-scale corpus of Western tonal music, instead preferring to use relatively small datasets containing chord annotations from contemporary genres like jazz, pop, and rock. Using symbolic representations of prominent instrumental genres from the common-practice period, this study applies a flexible, data-driven encoding scheme to (1) evaluate Finite Context (or n-gram) models and Recurrent Neural Networks (RNNs) in a chord prediction task; (2) compare predictive accuracy from the best-performing models for chord onsets from each of the selected datasets; and (3) explain differences between the two model architectures in a regression analysis. We find that Finite Context models using the Prediction by Partial Match (PPM) algorithm outperform RNNs, particularly for the piano datasets, with the regression model suggesting that RNNs struggle with particularly rare chord types. © Sears, Korzeniowski, Widmer.
KW  - Forecasting
KW  - Information retrieval
KW  - Large dataset
KW  - Natural language processing systems
KW  - Network architecture
KW  - Recurrent neural networks
KW  - Regression analysis
KW  - Syntactics
KW  - Model architecture
KW  - NAtural language processing
KW  - Prediction by partial matches
KW  - Predictive accuracy
KW  - Probabilistic language
KW  - Recurrent neural network (RNNs)
KW  - Symbolic representation
KW  - Syntactic properties
KW  - Computational linguistics
A2  - Gomez E.
A2  - Hu X.
A2  - Humphrey E.
A2  - Benetos E.
PB  - International Society for Music Information Retrieval
SN  - 978-295403512-3 (ISBN)
LA  - English
J2  - Proc. Int. Soc. Music Inf. Retr. Conf., ISMIR
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 2; Correspondence Address: D.R.W. Sears; College of Visual and Performing Arts, Texas Tech University, Lubbock, United States; email: david.sears@ttu.edu; Conference name: 19th International Society for Music Information Retrieval Conference, ISMIR 2018; Conference date: 23 September 2018 through 27 September 2018; Conference code: 149382
ER  -

TY  - JOUR
AU  - Verma, H.C.
AU  - Baral, A.
AU  - Pradhan, A.K.
AU  - Chakravorti, S.
TI  - Condition assessment of various regions within non-uniformly aged cellulosic insulation of power transformer using modified Debye model
PY  - 2017
T2  - IET Science, Measurement and Technology
VL  - 11
IS  - 7
SP  - 939
EP  - 947
DO  - 10.1049/iet-smt.2017.0041
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031504428&doi=10.1049%2fiet-smt.2017.0041&partnerID=40&md5=68caaa1db82b265d2990e05c5b36fbbd
AD  - Department of Electrical Engineering, Indian Institute of Technology (ISM), Dhanbad, India
AD  - Electrical Engineering Department, Jalpaiguri Government Engineering College, Jalpaiguri, India
AD  - Department of Electrical Engineering, Jadavpur University, Kolkata, India
AB  - During normal operation, power transformer insulation always experiences a temperature gradient along radial direction with respect to core axis. Over time, this gradient creates non-uniform ageing within cellulosic insulation. Recent development such as Modified Debye Model (MDM) is found to be capable of modelling such non-uniformity. Owing to non-uniform ageing, measured tan δ value only provides the average of dielectric loss associated with various regions within the insulation. Researchers have observed tan δ value to be quite high (due to conductive ageing by-products) in heavily degraded areas such as regions closer to winding. Also, the rate of deterioration of various regions within the insulation cannot be assumed to be constant. In fact, rate of degradation for regions with comparatively high tan δ values are expected to be much higher. tan δ measurement fails to assess the individual condition of different regions. A technique, based on MDM, is introduced in the present work that can identify the change in ageing severity of various regions within a non-uniformly aged insulation between two consecutive testing. The proposed method is first successfully tested on multiple series connected laboratory samples. Thereafter, the methodology is applied to data recorded from real life power transformer. © 2017. The Institution of Engineering and Technology.
KW  - Dielectric losses
KW  - Phonons
KW  - Power transformers
KW  - Condition assessments
KW  - Modified debye models
KW  - Non-uniform
KW  - Non-uniformities
KW  - Normal operations
KW  - Power transformer insulation
KW  - Radial direction
KW  - Series-connected
KW  - Insulation
PB  - Institution of Engineering and Technology
SN  - 17518822 (ISSN)
LA  - English
J2  - IET Sci. Meas. Technol.
M3  - Article
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 14; Correspondence Address: H.C. Verma; Department of Electrical Engineering, Indian Institute of Technology (ISM), Dhanbad, India; email: hcverma1989@gmail.com
ER  -

TY  - CONF
AU  - Hamoud, G.A.
AU  - Lee, L.
AU  - Faried, S.O.
TI  - Spare assessment of distribution power transformers using three markov models
PY  - 2018
T2  - 2018 International Conference on Probabilistic Methods Applied to Power Systems, PMAPS 2018 - Proceedings
C7  - 8440506
DO  - 10.1109/PMAPS.2018.8440506
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85053111478&doi=10.1109%2fPMAPS.2018.8440506&partnerID=40&md5=84c1088438786ddb16168764c410b2e5
AD  - Hydro One Inc., Toronto, Canada
AD  - University of Saskatchewan, Saskatoon, Canada
AB  - This paper presents a simple probabilistic method for determining the numbers of spare units (regular spare transformers and mobile unit substations) required for a system of similar distribution power transformers in order to meet a pre-determined level of the system availability. The proposed method is based on 3 Markov models representing transformer minor failures (Class II failures), transformer major failures (Class I failures) and the use of a mobile unit substation (MUS). The MUS model is convolved with each transformer failure model to determine the system availability as a function of the number of spare units. The new method of assessment produces the same results as those obtained using the previously used methods and the Markov models used are much simpler. An example is used to demonstrate the proposed method and to compare its results with the previously used methods. © 2018 IEEE.
KW  - Distribution transformer
KW  - Markov model
KW  - Mobile unit substation
KW  - Regular spare transformer
KW  - System availability
KW  - Transformer failures
KW  - Availability
KW  - Information dissemination
KW  - Markov processes
KW  - Power transformers
KW  - Probability distributions
KW  - Distribution transformer
KW  - Markov model
KW  - Mobile units
KW  - Spare transformer
KW  - System availability
KW  - Transformer failure
KW  - Transformer substations
PB  - Institute of Electrical and Electronics Engineers Inc.
SN  - 978-153863596-4 (ISBN)
LA  - English
J2  - Int. Conf. Probab. Methods Appl. Power Syst., PMAPS - Proc.
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 1; Conference name: 2018 International Conference on Probabilistic Methods Applied to Power Systems, PMAPS 2018; Conference date: 24 June 2018 through 28 June 2018; Conference code: 138773
ER  -

TY  - CONF
AU  - Wang, C.
AU  - Fang, S.
AU  - Feng, J.
AU  - Wang, Y.
TI  - Research on Heat Balance Model and Load Capacity Evaluation Method of Oil-immersed Transformer
PY  - 2019
T2  - iSPEC 2019 - 2019 IEEE Sustainable Power and Energy Conference: Grid Modernization for Energy Revolution, Proceedings
C7  - 8975257
SP  - 459
EP  - 464
DO  - 10.1109/iSPEC48194.2019.8975257
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85079508130&doi=10.1109%2fiSPEC48194.2019.8975257&partnerID=40&md5=e75075f1dc5f0e0a9ae7c61d87eac9ff
AD  - Jiangsu Frontier Electric Technology Co. Ltd., Nanjing, 211102, China
AD  - Hebei Provincial Key Laboratory of Power Transmission Equipment Security Defense, North China Electric Power University, Baoding, 071003, China
AB  - The load capacity evaluation of oil-immersed transformer is of great significance for the safe and stable operation of power system. The hot temperature is the key factor affecting the load capacity of transformer. In this paper, the heat balance model of oil-immersed transformer is established by systematic analysis of transformer heating and cooling mechanism. The correctness of the model is verified by the analysis of the temperature field calculation results of the transformer, and its load capacity is evaluated according to the transformer operating temperature limit and life loss. © 2019 IEEE.
KW  - heat balance model
KW  - load capacity
KW  - oil-immersed transformer
KW  - temperature field
KW  - Electric power transmission networks
KW  - Specific heat
KW  - Temperature
KW  - Temperature distribution
KW  - Field calculation
KW  - Heat balance model
KW  - Heating and cooling
KW  - Load capacity
KW  - Load capacity evaluation
KW  - Oil immersed transformers
KW  - Operating temperature
KW  - Systematic analysis
KW  - Oil filled transformers
PB  - Institute of Electrical and Electronics Engineers Inc.
SN  - 978-172814930-1 (ISBN)
LA  - English
J2  - iSPEC - IEEE Sustain. Power Energy Conf.: Grid Mod. Energy Revolut., Proc.
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 2; Conference name: 2019 IEEE Sustainable Power and Energy Conference, iSPEC 2019; Conference date: 21 November 2019 through 23 November 2019; Conference code: 157236
ER  -

TY  - JOUR
AU  - Liang, Y.
AU  - Lin, Z.
AU  - Li, K.-J.
AU  - Niu, L.
AU  - Zhao, J.
AU  - Lee, W.-J.
TI  - Priority assessment model of on-line monitoring devices investment for power transformers
PY  - 2018
T2  - Journal of Intelligent and Fuzzy Systems
VL  - 35
IS  - 1
SP  - 589
EP  - 599
DO  - 10.3233/JIFS-15492
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85051381692&doi=10.3233%2fJIFS-15492&partnerID=40&md5=c5aea264333d967c2ef133ce41c33a49
AD  - College of Information and Control Engineering, China University of Petroleum, China
AD  - School of Electrical Engineering, Shandong University, Jinan, Shandong Province, 250061, China
AD  - State Grid of China Technology College, China
AD  - Energy Systems Research Center, University of Texas, Arlington, United States
AB  - Finding an appropriate way to improve the investment comprehensive benefits for on-line monitoring is a new issue for power industry. In this paper, a priority assessment model for transformer on-line monitoring is proposed. The assessment model consists of device level and system level. The device level is divided into property assessment and operation assessment. The details of various assessment methods were described in the following sections, including device property assessment based on fuzzy analytic hierarchy process (FAHP), operation condition assessment method based on condition assessment technology and system level assessment method based on risk benefits index. An actual grid is utilized to validate the model and the numerical results illustrate that: The proposed assessment model can provide an appropriate on-line monitoring investment order for transformers. It also verifies that considering multiple aspects related to the target problem could give a more comprehensive assessment result than just considering just one or two of them. This paper provides a feasible solution to achieve more investment benefits for transformer online monitoring, which can provide on-line monitoring investment references for power industry. © 2018 - IOS Press and the authors.
KW  - device property
KW  - FAHP
KW  - On-line monitoring
KW  - operation condition
KW  - priority assessment
KW  - risk benefit
KW  - Investments
KW  - Monitoring
KW  - Power transformers
KW  - Voltage measurement
KW  - Device properties
KW  - FAHP
KW  - Online monitoring
KW  - Operation conditions
KW  - Priority assessment
KW  - Risk benefits
KW  - Risk assessment
PB  - IOS Press
SN  - 10641246 (ISSN)
LA  - English
J2  - J. Intelligent Fuzzy Syst.
M3  - Article
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 1; Correspondence Address: K.-J. Li; School of Electrical Engineering, Shandong University, Jinan, Shandong Province, 250061, China; email: lkjun@sdu.edu.cn
ER  -

TY  - CONF
AU  - Xiaodong, G.
AU  - Shouguo, L.
AU  - Rui, H.
AU  - Yanfei, Z.
AU  - Xiaomu, D.
TI  - Big data evaluation method of transformer based on association rules and fuzzy variable weight model
PY  - 2018
T2  - Proceedings of the 13th IEEE Conference on Industrial Electronics and Applications, ICIEA 2018
SP  - 2215
EP  - 2220
DO  - 10.1109/ICIEA.2018.8398078
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85050117052&doi=10.1109%2fICIEA.2018.8398078&partnerID=40&md5=927d17def44c33336f10ba341237a365
AD  - Maintenance Company of State Grid Shandong Electric Power Company, Jinan, China
AD  - State Grid Shandong Electric Power Company, Jinan, China
AD  - School of Electrical Engineering, Shandong University, Jinan, China
AB  - In order to solve the problems such as the wide variety of data during the operation of power transformers and the uncertainty of each index in state evaluation, this paper proposes a large data evaluation method based on association rules and fuzzy variable weight model. This method firstly constructs a more comprehensive transformer basic parameter system, and quantifies the parameters based on the confidence and support degree of the association rules. According to the comprehensive analysis and variable weight fuzzy evaluation, a relatively complete transformer state evaluation system is established to realize the Monitoring and Evaluation of Transformer Operation. Data analysis shows that the method proposed in this paper provides a new idea for the operation status evaluation and fault diagnosis of the transformer, which has certain practical value. © 2018 IEEE.
KW  - association rules
KW  - big data
KW  - fuzzy comprehensive evaluation
KW  - state evaluation
KW  - transformer
KW  - variable weight coefficient
KW  - Association rules
KW  - Fault detection
KW  - Industrial electronics
KW  - Power transformers
KW  - Comprehensive analysis
KW  - Fuzzy comprehensive evaluation
KW  - Fuzzy evaluation
KW  - Monitoring and evaluations
KW  - Operation status
KW  - State evaluation
KW  - transformer
KW  - Variable weight
KW  - Big data
PB  - Institute of Electrical and Electronics Engineers Inc.
SN  - 978-153863757-9 (ISBN)
LA  - English
J2  - Proc. IEEE Conf. Industrial Electron. Appl., ICIEA
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 2; Conference name: 13th IEEE Conference on Industrial Electronics and Applications, ICIEA 2018; Conference date: 31 May 2018 through 2 June 2018; Conference code: 137520
ER  -

TY  - CONF
AU  - Fadel, A.
AU  - Al-Ayyoub, M.
AU  - Cambria, E.
TI  - JUSTers at SemEval-2020 Task 4: Evaluating Transformer Models Against Commonsense Validation and Explanation
PY  - 2020
T2  - 14th International Workshops on Semantic Evaluation, SemEval 2020 - co-located 28th International Conference on Computational Linguistics, COLING 2020, Proceedings
SP  - 535
EP  - 542
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85099082408&partnerID=40&md5=e30c5cc9819c2b8c9bad6e28b1a88939
AD  - Jordan University of Science and Tech, Irbid, Jordan
AD  - Nanyang Technological University, Singapore
AB  - In this paper, we describe our team's (JUSTers) effort in the Commonsense Validation and Explanation (ComVE) task, which is part of SemEval2020. We evaluate five pre-trained Transformer-based language models with various sizes against the three proposed subtasks. For the first two subtasks, the best accuracy levels achieved by our models are 92.90% and 92.30%, respectively, placing our team in the 12th and 9th places, respectively. As for the last subtask, our models reach 16.10 BLEU score and 1.94 human evaluation score placing our team in the 5th and 3rd places according to these two metrics, respectively. The latter is only 0.16 away from the 1st place human evaluation score. © 2020 14th International Workshops on Semantic Evaluation, SemEval 2020 - co-located 28th International Conference on Computational Linguistics, COLING 2020, Proceedings. All rights reserved.
KW  - Accuracy level
KW  - Human evaluation
KW  - Language model
KW  - Subtask
KW  - Transformer modeling
KW  - Semantics
A2  - Herbelot A.
A2  - Zhu X.
A2  - Palmer A.
A2  - Schneider N.
A2  - May J.
A2  - Shutova E.
PB  - International Committee for Computational Linguistics
SN  - 978-195214831-6 (ISBN)
LA  - English
J2  - Int. Workshops Semant. Eval., SemEval - co-located Int. Conf. Comput. Linguist., COLING , Proc.
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 7; Conference name: 14th International Workshops on Semantic Evaluation, SemEval 2020; Conference date: 12 December 2020 through 13 December 2020; Conference code: 174265
ER  -

TY  - CONF
AU  - Piskorski, J.
AU  - Haneczok, J.
AU  - Jacquet, G.
TI  - New Benchmark Corpus and Models for Fine-grained Event Classification: To BERT or not to BERT?
PY  - 2020
T2  - COLING 2020 - 28th International Conference on Computational Linguistics, Proceedings of the Conference
SP  - 6663
EP  - 6678
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85116020194&partnerID=40&md5=1a5d42e2eaa2da64d2a10ab527ae353a
AD  - Institute for Computer Science, Polish Academy of Sciences, Warsaw, Poland
AD  - Erste Group IT, Vienna, Austria
AD  - Joint Research Centre, European Commission Isrpa, Italy
AB  - We introduce a new set of benchmark datasets derived from ACLED data for fine-grained event classification and compare the performance of various state-of-the-art machine learning models on these datasets, including SVM based on TF-IDF character n-grams and neural context-free embeddings (GLOVE and FASTTEXT) as well as deep learning-based BERT with its contextual embeddings. The best results in terms of micro (94.3-94.9%) and macro F1 (86.0-88.9%) were obtained using BERT transformer, with simpler TF-IDF character n-gram based SVM being an interesting alternative. Further, we discuss the pros and cons of the considered benchmark models in terms of their robustness and the dependence of the classification performance on the size of training data. © 2020 COLING 2020 - 28th International Conference on Computational Linguistics, Proceedings of the Conference. All rights reserved.
KW  - Benchmarking
KW  - Classification (of information)
KW  - Computational linguistics
KW  - Deep learning
KW  - Support vector machines
KW  - Benchmark datasets
KW  - Context-free
KW  - Embeddings
KW  - Events classification
KW  - Fine grained
KW  - Machine learning models
KW  - N-grams
KW  - Performance
KW  - Simple++
KW  - State of the art
KW  - Embeddings
A2  - Scott D.
A2  - Bel N.
A2  - Zong C.
PB  - Association for Computational Linguistics (ACL)
SN  - 978-195214827-9 (ISBN)
LA  - English
J2  - COLING - Int. Conf. Comput. Linguist., Proc. Conf.
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 18; Conference name: 28th International Conference on Computational Linguistics, COLING 2020; Conference date: 8 December 2020 through 13 December 2020; Conference code: 186886
ER  -

TY  - CONF
AU  - Marvin, R.
AU  - Linzen, T.
TI  - Targeted syntactic evaluation of language models
PY  - 2018
T2  - Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing, EMNLP 2018
SP  - 1192
EP  - 1202
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85081750971&partnerID=40&md5=416ad4c0fa1ece91cf13657766b91c12
AD  - Department of Computer Science, Johns Hopkins University, United States
AD  - Department of Cognitive Science, Johns Hopkins University, United States
AB  - We present a dataset for evaluating the grammaticality of the predictions of a language model. We automatically construct a large number of minimally different pairs of English sentences, each consisting of a grammatical and an ungrammatical sentence. The sentence pairs represent different variations of structure-sensitive phenomena: subject-verb agreement, reflexive anaphora and negative polarity items. We expect a language model to assign a higher probability to the grammatical sentence than the ungrammatical one. In an experiment using this data set, an LSTM language model performed poorly on many of the constructions. Multi-task training with a syntactic objective (CCG supertagging) improved the LSTM's accuracy, but a large gap remained between its performance and the accuracy of human participants recruited online. This suggests that there is considerable room for improvement over LSTMs in capturing syntax in a language model. © 2018 Association for Computational Linguistics
KW  - Computational linguistics
KW  - Natural language processing systems
KW  - Syntactics
KW  - Data set
KW  - English sentences
KW  - Language model
KW  - Negative polarity items
KW  - Structure-sensitive
KW  - Long short-term memory
A2  - Riloff E.
A2  - Chiang D.
A2  - Hockenmaier J.
A2  - Tsujii J.
PB  - Association for Computational Linguistics
SN  - 978-194808784-1 (ISBN)
LA  - English
J2  - Proc. Conf. Empir. Methods Nat. Lang. Process., EMNLP
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 192; Conference name: 2018 Conference on Empirical Methods in Natural Language Processing, EMNLP 2018; Conference date: 31 October 2018 through 4 November 2018; Conference code: 158085
ER  -

TY  - CONF
AU  - Nishi, Y.
AU  - Suge, A.
AU  - Takahashi, H.
TI  - News Articles Evaluation Analysis in Automotive Industry Using GPT-2 and Co-occurrence Network
PY  - 2020
T2  - Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)
VL  - 12331 LNAI
SP  - 103
EP  - 114
DO  - 10.1007/978-3-030-58790-1_7
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85091506291&doi=10.1007%2f978-3-030-58790-1_7&partnerID=40&md5=6a7e5914ae366dc7bf1914f357457ef3
AD  - Graduate School of Business Administration, Keio University, Hiyoshi 4-1-1, Kohoku-Ku, Kanagawa-ken, Yokohama-shi, Japan
AB  - News articles have great impacts on asset prices in the financial markets. Many attempts have been reported to ascertain how news influences stock prices. Stock price fluctuations of highly influential companies can have a major impact on the economy as a whole. In particular, the automobile industry is a colossal industry that leads the Japanese industry. However, the limitations in the number of available data sets usually become the hurdle for the model accuracy. In this study, we constructed a news evaluation model utilizing GPT-2. A news evaluation model is a model that evaluates news articles distributed to financial markets based on price fluctuation rates and predicts fluctuations in stock prices. We have added news articles generated by GPT-2 as data for analysis. Besides, we used a co-occurrence network analysis to review the overview of the news articles. News articles were classified through Long Short-Term Memory (LSTM). The results showed that the accuracy of the news evaluation model improved by generating news articles using a language generation model through GPT-2. More detailed analyses are planned for the future. © 2020, Springer Nature Switzerland AG.
KW  - Co-occurrence network
KW  - Deep learning
KW  - Financial markets
KW  - GPT-2
KW  - Language generation
KW  - LSTM
KW  - Commerce
KW  - Costs
KW  - Financial markets
KW  - Co-occurrence networks
KW  - Evaluation modeling
KW  - Japanese industry
KW  - Language generation
KW  - Model accuracy
KW  - News articles
KW  - Price fluctuation
KW  - Stock price fluctuation
KW  - Long short-term memory
A2  - Sakamoto M.
A2  - Okazaki N.
A2  - Mineshima K.
A2  - Satoh K.
PB  - Springer Science and Business Media Deutschland GmbH
SN  - 03029743 (ISSN); 978-303058789-5 (ISBN)
LA  - English
J2  - Lect. Notes Comput. Sci.
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 1; Correspondence Address: Y. Nishi; Graduate School of Business Administration, Keio University, Yokohama-shi, Hiyoshi 4-1-1, Kohoku-Ku, Kanagawa-ken, Japan; email: nishi_yoshihiro@keio.jp; Conference name: 11th JSAI International Symposium on Artificial Intelligence, JSAI-isAI 2019; Conference date: 10 November 2019 through 12 November 2019; Conference code: 245369
ER  -

TY  - CONF
AU  - George, A.A.
AU  - Bhattachrya, A.K.
AU  - Hazra, S.
AU  - Bhattacharya, J.L.
TI  - Enhanced loss of life relationsfor IEEE thermal model for ageing assessment of running transformers in smart grid frameworks
PY  - 2017
T2  - TENSYMP 2017 - IEEE International Symposium on Technologies for Smart Cities
C7  - 8070020
DO  - 10.1109/TENCONSpring.2017.8070020
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85039998708&doi=10.1109%2fTENCONSpring.2017.8070020&partnerID=40&md5=ba7a5a688b91bad82ab990747c1f731e
AD  - BIT Mesra, Ranchi, India
AD  - School of Engineering, Mahindra Ecole CentraleHyderabad, India
AB  - Transformer insulation ageing has been extensively studied for past many decades as it is one of the major reasons for transformer failure which causes disturbance to the power system, interruption of power to consumers as well as loss of revenue. The estimation of elapsed life of transformer insulation is done by various methods like IEEE thermal model calculation or diagnostic test results. Though the ability of the thermal model to evaluate loss of life in any interval of time with typically available input data makes this technique acceptable, it slow accuracy due to consideration of temperature alone as the factor of degradation forces the operators to enhance accuracy by additionally performing the diagnostic test, i.e. measurement of the Degree of Polymerisation. This test gives a clear idea about the insulation condition as it involves chemical tests on insulation samples; however, performing this analysis for an operating transformer is impractical. Hence, in this paper we are proposing an enhanced IEEE thermal model to give a precise loss of life, using prior experimental data. Validation of the developed formula is performed on both power and distribution transformers and reported here. © 2017 IEEE.
KW  - Degree of Polymerisation
KW  - Diagnostic Tests
KW  - IEEE Thermal Model
KW  - Online Life Assessment
KW  - Transformer Insulation Ageing
KW  - Chemical analysis
KW  - Electric power transmission networks
KW  - Electric transformers
KW  - Insulation
KW  - Polymerization
KW  - Smart city
KW  - Smart power grids
KW  - Thermal insulation
KW  - Thermography (temperature measurement)
KW  - Degree of polymerisation
KW  - Diagnostic tests
KW  - Life assessment
KW  - Thermal model
KW  - Transformer insulation
KW  - Electric transformer testing
PB  - Institute of Electrical and Electronics Engineers Inc.
SN  - 978-150906255-3 (ISBN)
LA  - English
J2  - TENSYMP - IEEE Int. Symp. Technol. Smart Cities
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 1; Conference name: 2017 IEEE International Symposium on Technologies for Smart Cities, TENSYMP 2017; Conference date: 14 July 2017 through 16 July 2017; Conference code: 131361
ER  -

TY  - CONF
AU  - Chen, T.
AU  - Li, H.
AU  - Kasamatsu, M.
AU  - Utsuro, T.
AU  - Kawada, Y.
TI  - Developing a how-to tip machine comprehension dataset and its evaluation in machine comprehension by BERT
PY  - 2020
T2  - Proceedings of the Annual Meeting of the Association for Computational Linguistics
SP  - 26
EP  - 35
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85119344994&partnerID=40&md5=f43fcb7b5922896848ed1d0d443a820d
AD  - Graduate School of Systems and Information Engineering, University of Tsukuba, Japan
AD  - Logworks Co., Ltd., Japan
AB  - In the field of factoid question answering (QA), it is known that the state-of-the-art technology has achieved an accuracy comparable to that of humans in a certain benchmark challenge. On the other hand, in the area of non-factoid QA, there is still a limited number of datasets for training QA models, i.e., machine comprehension models. Considering such a situation within the field of the non-factoid QA, this paper aims to develop a dataset for training Japanese how-to tip QA models. This paper applies one of the state-of-the-art machine comprehension models to the Japanese how-to tip QA dataset. The trained how-to tip QA model is also compared with a factoid QA model trained with a Japanese factoid QA dataset. Evaluation results revealed that the how-to tip machine comprehension performance was almost comparative with that of the factoid machine comprehension even with the training data size reduced to around 4% of the factoid machine comprehension. Thus, the how-to tip machine comprehension task requires much less training data compared with the factoid machine comprehension task. © 2020 Association for Computational Linguistics.
KW  - Comprehension models
KW  - Comprehension performance
KW  - Comprehension tasks
KW  - Evaluation results
KW  - Factoid questions
KW  - ITS evaluation
KW  - Question Answering
KW  - State of the art
KW  - State-of-the-art technology
KW  - Training data
PB  - Association for Computational Linguistics (ACL)
SN  - 0736587X (ISSN); 978-195214810-1 (ISBN)
LA  - English
J2  - Proc. Annu. Meet. Assoc. Comput Linguist.
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 3; Conference name: 3rd Workshop on Fact Extraction and VERification, FEVER 2020 at the 58th Annual Meeting of the Association for Computational Linguistics, ACL 2020; Conference code: 172966
ER  -

TY  - CONF
AU  - Hu, J.
AU  - Gauthier, J.
AU  - Qian, P.
AU  - Wilcox, E.
AU  - Levy, R.P.
TI  - A systematic assessment of syntactic generalization in neural language models
PY  - 2020
T2  - Proceedings of the Annual Meeting of the Association for Computational Linguistics
SP  - 1725
EP  - 1744
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85108563039&partnerID=40&md5=45f39ac06d90571e987777f1ed5b04cc
AD  - Department of Brain and Cognitive Sciences, Massachusetts Institute of Technology
AD  - Department of Linguistics, Harvard University
AB  - While state-of-the-art neural network models continue to achieve lower perplexity scores on language modeling benchmarks, it remains unknown whether optimizing for broad-coverage predictive performance leads to human-like syntactic knowledge. Furthermore, existing work has not provided a clear picture about the model properties required to produce proper syntactic generalizations. We present a systematic evaluation of the syntactic knowledge of neural language models, testing 20 combinations of model types and data sizes on a set of 34 English-language syntactic test suites. We find substantial differences in syntactic generalization performance by model architecture, with sequential models underperforming other architectures. Factorially manipulating model architecture and training dataset size (1M-40M words), we find that variability in syntactic generalization performance is substantially greater by architecture than by dataset size for the corpora tested in our experiments. Our results also reveal a dissociation between perplexity and syntactic generalization performance. © 2020 Association for Computational Linguistics
KW  - Benchmarking
KW  - Computational linguistics
KW  - Modeling languages
KW  - Natural language processing systems
KW  - Network architecture
KW  - ART neural networks
KW  - Data set size
KW  - Generalisation
KW  - Generalization performance
KW  - Language model
KW  - Modeling architecture
KW  - Neural network model
KW  - Predictive performance
KW  - State of the art
KW  - Systematic assessment
KW  - Syntactics
PB  - Association for Computational Linguistics (ACL)
SN  - 0736587X (ISSN); 978-195214825-5 (ISBN)
LA  - English
J2  - Proc. Annu. Meet. Assoc. Comput Linguist.
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 83; Conference name: 58th Annual Meeting of the Association for Computational Linguistics, ACL 2020; Conference date: 5 July 2020 through 10 July 2020; Conference code: 172533
ER  -

TY  - CONF
AU  - Nogueira, R.
AU  - Jiang, Z.
AU  - Cho, K.
AU  - Lin, J.
TI  - Evaluating pretrained transformer models for citation recommendation
PY  - 2020
T2  - CEUR Workshop Proceedings
VL  - 2591
SP  - 89
EP  - 100
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85083307360&partnerID=40&md5=cf71ed2f88cb3f32a16337264be0d050
AD  - Tandon School of Engineering, New York University, United States
AD  - David R. Cheriton School of Computer Science, University of Waterloo, Canada
AD  - Courant Institute of Mathematical Sciences, New York University, United States
AD  - Center for Data Science, New York University, United States
AD  - Facebook AI Research
AD  - CIFAR Azrieli Global Scholar
AB  - Citation recommendation systems for the scientific literature, to help authors find papers that should be cited, have the potential to speed up discoveries and uncover new routes for scientific exploration. We treat this task as a ranking problem, which we tackle with a two-stage approach: candidate generation followed by re-ranking. Within this framework, we adapt to the scientific domain a proven combination based on “bag of words” retrieval followed by re-scoring with a BERT model. We experimentally show the effects of domain adaptation, both in terms of pretraining on in-domain data and exploiting in-domain vocabulary. In addition, we evaluate eleven pretrained transformer models and analyze some unexpected failure cases. On three different collections from different scientific disciplines, our models perform close to or at the state of the art in the citation recommendation task. © 2020 CEUR-WS. All rights reserved.
KW  - Candidate generation
KW  - Domain adaptation
KW  - Scientific discipline
KW  - Scientific exploration
KW  - Scientific literature
KW  - Transformer models
KW  - Two stage approach
KW  - Unexpected Failures
KW  - Recommender systems
A2  - Cabanac G.
A2  - Frommholz I.
A2  - Mayr P.
PB  - CEUR-WS
SN  - 16130073 (ISSN)
LA  - English
J2  - CEUR Workshop Proc.
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 4; Conference name: 10th International Workshop on Bibliometric-Enhanced Information Retrieval, BIR 2020; Conference code: 158941
ER  -

TY  - CONF
AU  - Yang, R.
AU  - Xie, W.
AU  - Liu, C.
AU  - Yu, D.
TI  - BLCU_NLP at SemEval-2019 task 7: An inference chain-based GPT model for rumour evaluation
PY  - 2019
T2  - NAACL HLT 2019 - International Workshop on Semantic Evaluation, SemEval 2019, Proceedings of the 13th Workshop
SP  - 1090
EP  - 1096
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85078720427&partnerID=40&md5=3e99fada5111e8abfe9d307ae712c68d
AD  - Beijing Language and Culture University, Beijing, China
AB  - Researchers have been paying increasing attention to rumour evaluation due to the rapid spread of unsubstantiated rumours on social media platforms, including SemEval 2019 task 7. However, labelled data for learning rumour veracity is scarce, and labels in rumour stance data are highly disproportionate, making it challenging for a model to perform supervised-learning adequately. We propose an inference chain-based system, which fully utilizes conversation structure-based knowledge in the limited data and expand the training data in minority categories to alleviate class imbalance. Our approach obtains 12.6% improvement upon the baseline system for subtask A, ranks 1st among 21 systems in subtask A, and ranks 4th among 12 systems in subtask B. © 2019 Association for Computational Linguistics
KW  - Learning systems
KW  - Baseline systems
KW  - Class imbalance
KW  - Labeled data
KW  - Limited data
KW  - Social media platforms
KW  - Structure-based
KW  - Subtask
KW  - Training data
KW  - Semantics
PB  - Association for Computational Linguistics (ACL)
SN  - 978-195073706-2 (ISBN)
LA  - English
J2  - NAACL HLT - Int. Workshop Semant. Evaluation, SemEval, Proc. Workshop
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 21; Correspondence Address: D. Yu; Beijing Language and Culture University, Beijing, China; email: yudong@blcu.edu.cn; Conference name: 13th International Workshop on Semantic Evaluation, SemEval 2019, co-located with the 17th Annual Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, NAACL HLT 2019; Conference date: 6 June 2019 through 7 June 2019; Conference code: 172737
ER  -

TY  - JOUR
AU  - Luz, G.C.
AU  - Strioto, D.K.
AU  - Mangolin, C.A.
AU  - Machado, M.F.P.S.
TI  - ISSR markers to assess genetic diversity of cultivated populations from artificial selection of stevia rebaudiana (Bert.) bertoni
PY  - 2020
T2  - Breeding Science
VL  - 70
IS  - 4
SP  - 508
EP  - 514
DO  - 10.1270/jsbbs.20014
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85090251163&doi=10.1270%2fjsbbs.20014&partnerID=40&md5=e4a59d2a3a0323d9629dd1d948ced819
AD  - Postgraduate Program in Agronomy, State University of Maringá, Av. Colombo, 5790, Maringá, 87020-900, PR, Brazil
AD  - Postgraduate Program in Genetics and Breeding, State University of Maringá, Av. Colombo, 5790, Maringá, 87020-900, PR, Brazil
AD  - Department of Cell Biology and Genetics, State University of Maringá, Av. Colombo, 5790, Maringá, 87020-900, PR, Brazil
AB  - Artificial selection related with important agronomic characteristics of Stevia rebaudiana may cause genetic divergence and formation of genetically structured populations with genetic uniformity or diversity within cultivars. Current study employed inter simple sequence repeats of DNA (ISSR markers) to assess genetic diversity within and among a single cultivated population maintained through sexual propagation (SR1) and four cultivated populations generated by artificial selection and maintained by vegetative propagation (SR2– SR5). Highest polymorphism rate was reported in SR1 (89.24%), whilst the lowest rate of polymorphism occurred in SR2 (60.13%). ISSR markers revealed that selection of plants with traits of vegetative-propagated interest may lead towards the generation of genetically more uniform DNA-level populations, while plants maintained by sexual propagation have high genetic variability. High estimated genetic divergence level indicated that the five areas of stevia form genetically structured populations. SR2 and SR4 are constituted by plants more homogeneous at DNA level for the selected characteristics than plants of SR3 and SR5 populations. Predominant and homogeneous genotypes selected at SR2 and SR4 areas could be valuable for tracing strategies to obtain stevia plants with the desirable agronomic characteristics through crosses between contrasting individuals in future breeding programs. © 2020, Japanese Society of Breeding. All rights reserved.
KW  - Genetic diversity
KW  - Genetic uniformity
KW  - ISSR markers
KW  - Stevia
KW  - Sweet leaf herb
PB  - Japanese Society of Breeding
SN  - 13447610 (ISSN)
LA  - English
J2  - Breed. Sci.
M3  - Note
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 8; Correspondence Address: M.F.P.S. Machado; Department of Cell Biology and Genetics, State University of Maringá, Maringá, Av. Colombo, 5790, 87020-900, Brazil; email: mfpsmachado@uem.br; CODEN: BRSCE
ER  -

TY  - CONF
AU  - Ren, Y.
AU  - Zhao, L.
AU  - Song, Y.
AU  - Lin, S.
TI  - State assessment method for transformer under DC bias based on gray cloud model
PY  - 2019
T2  - iSPEC 2019 - 2019 IEEE Sustainable Power and Energy Conference: Grid Modernization for Energy Revolution, Proceedings
C7  - 8975112
SP  - 2282
EP  - 2286
DO  - 10.1109/iSPEC48194.2019.8975112
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85079479490&doi=10.1109%2fiSPEC48194.2019.8975112&partnerID=40&md5=61441cee772aaae8f42fea63d85545aa
AD  - Southwest Jiaotong University, School of Electrical Engineering, Chengdu, China
AB  - In order to evaluate the influence of DC bias on the operating state of transformer, a state assessment method for transformer based on gray cloud model is proposed. Firstly, the method determines the maximum and minimum values, the distortion rate and the DC component of the magnetizing current as the evaluation indicators, and uses a modified analytical hierarchy process to clarify the weight of each indicator in the evaluation. Meanwhile, considering that single unqualified indicator being covered by the qualified indicators possibly, the variable weight theory is used to increase weight of unqualified indicators dynamically. Finally, the gray cloud model is used to calculate the index clustering coefficient to determine what operating state the transformer is in. The simulation model is used to obtain the magnetizing current under the influence of different DC bias. Using above data to evaluate the operating state of transformer, the effectiveness of method is verified. © 2019 IEEE.
KW  - DC magnetic biasing
KW  - gray cloud model
KW  - magnetizing current
KW  - state assessment method
KW  - Cloud computing
KW  - Electric power transmission networks
KW  - Analytical Hierarchy Process
KW  - Clustering coefficient
KW  - DC magnetic biasing
KW  - Evaluation indicators
KW  - Gray clouds
KW  - Magnetizing current
KW  - State assessment
KW  - Variable weight theories
KW  - DC transformers
PB  - Institute of Electrical and Electronics Engineers Inc.
SN  - 978-172814930-1 (ISBN)
LA  - English
J2  - iSPEC - IEEE Sustain. Power Energy Conf.: Grid Mod. Energy Revolut., Proc.
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 1; Conference name: 2019 IEEE Sustainable Power and Energy Conference, iSPEC 2019; Conference date: 21 November 2019 through 23 November 2019; Conference code: 157236
ER  -

TY  - JOUR
AU  - Tian, F.
AU  - Jing, Z.
AU  - Zhao, H.
AU  - Zhang, E.
AU  - Liu, J.
TI  - A synthetic condition assessment model for power transformers using the fuzzy evidence fusion method
PY  - 2019
T2  - Energies
VL  - 12
IS  - 5
C7  - 857
DO  - 10.3390/en12050857
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85067986072&doi=10.3390%2fen12050857&partnerID=40&md5=e9d6707275d0154095a8a9959297e6d3
AD  - State Grid Zhengzhou Electric Power Supply Company, Zhengzhou, 450000, China
AD  - Guangxi Key Laboratory of Power System Optimization and Energy Technology, Guangxi University, Nanning, 530004, China
AB  - Condition-based maintenance decision-making of transformers is essential to electric enterprises for avoiding financial losses. However, precise transformer condition assessment was tough to accomplish because of the negligence of the influence of bushing and accessories, the difficulty of fuzzy grade division, and the lack of reasonable fuzzy evidence fusion method. To solve these problems, a transformer assessing model was proposed in the paper. At first, an index assessing system, considering the main body, the bushing and the accessories components, was established on the basis of components division of transformers. Then, a Cauchy membership function was employed for fuzzy grades division. Finally, a fuzzy evidence fusion method was represented to handle the fuzzy evidences fusion processes. Case studies and the comparison analysis with other methods were performed to prove the effectiveness of this model. The research results confirm that the proposed model could be recommendation for condition based maintenance of power transformers for electric enterprises. © 2019 by the authors.
KW  - Condition assessment
KW  - Condition based maintenance decision making
KW  - Evidential reasoning
KW  - Fuzzy information
KW  - Information fusion
KW  - Power transformers
KW  - Bushings
KW  - Electric losses
KW  - Information fusion
KW  - Losses
KW  - Maintenance
KW  - Membership functions
KW  - Power transformers
KW  - Comparison analysis
KW  - Condition assessments
KW  - Condition based maintenance
KW  - Evidential reasoning
KW  - Fuzzy information
KW  - Research results
KW  - Synthetic conditions
KW  - Transformer condition assessment
KW  - Decision making
PB  - MDPI AG
SN  - 19961073 (ISSN)
LA  - English
J2  - Energies
M3  - Article
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 18; Correspondence Address: J. Liu; Guangxi Key Laboratory of Power System Optimization and Energy Technology, Guangxi University, Nanning, 530004, China; email: liujiefeng9999@163.com
ER  -

TY  - CONF
AU  - Acharya, S.
AU  - Tapre, P.C.
TI  - Life assessment of transformer using thermal models
PY  - 2018
T2  - 2017 International Conference on Energy, Communication, Data Analytics and Soft Computing, ICECDS 2017
SP  - 3515
EP  - 3520
DO  - 10.1109/ICECDS.2017.8390114
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85050144411&doi=10.1109%2fICECDS.2017.8390114&partnerID=40&md5=463e9a2fae3cfb232133f9a8760e3227
AD  - Dept. of Electrical Engineering, SNDCOE, Yeola, Maharashtra, India
AB  - Power transformers are very vital and costliest apparatus in electrical power network. A long lead time for delivery and huge cost warrants for optimize usages of Power transformer. Transformer loading, a function of current through its winding, leads to ohmic losses in transformer winding and enclosure. ohmic losses responsible for producing heat inside the transformer. Heat, temperature has an adverse effect on life of transformer insulation. Oil impregnated paper (OIP) insulation is the sole choice as insulating medium in power transformer. Life of the transformer which is life of OIP is a time -temperature function. Substation engineers are often interested in keeping track of consumed life and remnant life of transformer. Overloading of the transformer beyond nameplate rating involves risk and leads to accelerated rating. Before taking on any call on overloading, substation engineer needs to evaluate the impact on transformer reliability and impact on life. At any moment allowable overload (with additional loss of life) will depend on prevailing load and ambient conditions. Understanding thermodynamic towards temperature rise, mapping of temperature at various zone like top oil, winding and winding hot-spot becomes essential. Based on these; Loading (current) - Time - temperature characteristics can be forecasted. In this review paper, calculations of average winding, hot-spot temperature, acceleration factor for ageing, cumulative ageing will be covered and will produce time-load characteristics for long-time and short-time overloading. The calculation models shall cover all type of cooling modes in power transformers. As an outcome of the presented algorithm, a computer program shall be developed to compute top-oil and hottest-spot temperatures as a function of time and load, the allowable limit for overload that can be impressed on a transformer to meet specified limitations with loss of life. Based on calculations models, computer program can forecast loading (current) - time - temperature characteristics (winding hot-spot temperature, ageing acceleration factor and percentage loss of life). © 2017 IEEE.
KW  - Ageing
KW  - Computer Program
KW  - MATLAB
KW  - Reliability
KW  - Thermal Loading
KW  - Computer program listings
KW  - Insulation
KW  - MATLAB
KW  - Oil filled transformers
KW  - Paper
KW  - Power transformers
KW  - Reliability
KW  - Soft computing
KW  - Temperature
KW  - Transformer windings
KW  - Winding
KW  - Acceleration factors
KW  - Ageing
KW  - Electrical power networks
KW  - Hottest-spot temperatures
KW  - Oil-impregnated-paper insulations
KW  - Thermal loadings
KW  - Transformer insulation
KW  - Winding hot spot temperatures
KW  - Transformer substations
PB  - Institute of Electrical and Electronics Engineers Inc.
SN  - 978-153861886-8 (ISBN)
LA  - English
J2  - Int. Conf. Energy, Commun., Data Anal. Soft Comput., ICECDS
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 6; Conference name: 2017 International Conference on Energy, Communication, Data Analytics and Soft Computing, ICECDS 2017; Conference date: 1 August 2017 through 2 August 2017; Conference code: 137325
ER  -

TY  - CONF
AU  - Logan, R.L.
AU  - Gardner, M.
AU  - Singh, S.
TI  - On importance sampling-based evaluation of latent language models
PY  - 2020
T2  - Proceedings of the Annual Meeting of the Association for Computational Linguistics
SP  - 2171
EP  - 2176
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85117907707&partnerID=40&md5=f50034fd5c2ecfa94124117fbdb6478c
AD  - Univ. of California, Irvine, United States
AD  - Allen Institute for AI
AB  - Language models that use additional latent structures (e.g., syntax trees, coreference chains, and knowledge graph links) provide several advantages over traditional language models. However, likelihood-based evaluation of these models is often intractable as it requires marginalizing over the latent space. Existing methods avoid this issue by using importance sampling. Although this approach has asymptotic guarantees, analysis is rarely conducted on the effect of decisions such as sample size, granularity of sample aggregation, and the proposal distribution on the reported estimates. In this paper, we measure the effect these factors have on perplexity estimates for three different latent language models. In addition, we elucidate subtle differences in how importance sampling is applied, which can have substantial effects on the final estimates, as well as provide theoretical results that reinforce the validity of importance sampling for evaluating latent language models. © 2020 Association for Computational Linguistics
KW  - Computational linguistics
KW  - Importance sampling
KW  - Knowledge graph
KW  - Asymptotics
KW  - Chain graph
KW  - Coreference chains
KW  - Knowledge graphs
KW  - Language model
KW  - Latent structures
KW  - Proposal distribution
KW  - Sample sizes
KW  - Sampling-based
KW  - Syntax tree
KW  - Trees (mathematics)
PB  - Association for Computational Linguistics (ACL)
SN  - 0736587X (ISSN); 978-195214825-5 (ISBN)
LA  - English
J2  - Proc. Annu. Meet. Assoc. Comput Linguist.
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 2; Conference name: 58th Annual Meeting of the Association for Computational Linguistics, ACL 2020; Conference date: 5 July 2020 through 10 July 2020; Conference code: 172533
ER  -

TY  - CONF
AU  - Zhang, C.
AU  - Yamana, H.
TI  - WUY at SemEval-2020 Task 7: Combining BERT and Naive Bayes-SVM for Humor Assessment in Edited News Headlines
PY  - 2020
T2  - 14th International Workshops on Semantic Evaluation, SemEval 2020 - co-located 28th International Conference on Computational Linguistics, COLING 2020, Proceedings
SP  - 1071
EP  - 1076
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85115668497&partnerID=40&md5=1ecf8359cda54448e45d0b3515ad53d2
AD  - Graduate School of Fundamental Science and Engineering, Waseda University, 3-4-1 Okubo, Shinjuku-ku, Tokyo, 169-8555, Japan
AD  - Faculty of Science and Engineering, Waseda University, 3-4-1 Okubo, Shinjuku-ku, Tokyo, 169-8555, Japan
AB  - This paper describes our participation in SemEval 2020 Task 7 on assessment of humor in edited news headlines, which includes two subtasks, estimating the humor of micro-editd news headlines (subtask A) and predicting the more humorous of the two edited headlines (subtask B). To address these tasks, we propose two systems. The first system adopts a regression-based fine-tuned single-sequence bidirectional encoder representations from transformers (BERT) model with easy data augmentation (EDA), called “BERT+EDA”. The second system adopts a hybrid of a regression-based fine-tuned sequence-pair BERT model and a combined Naive Bayes and support vector machine (SVM) model estimated on term frequency-inverse document frequency (TFIDF) features, called “BERT+NB-SVM”. In this case, no additional training datasets were used, and the BERT+NB-SVM model outperformed BERT+EDA. The official root-mean-square deviation (RMSE) score for subtask A is 0.57369 and ranks 31st out of 48, whereas the best RMSE of BERT+NB-SVM is 0.52429, ranking 7th. For subtask B, we simply use a sequence-pair BERT model, the official accuracy of which is 0.53196 and ranks 25th out of 32. © 2020 14th International Workshops on Semantic Evaluation, SemEval 2020 - co-located 28th International Conference on Computational Linguistics, COLING 2020, Proceedings. All rights reserved.
KW  - Classifiers
KW  - Semantics
KW  - Text processing
KW  - Data augmentation
KW  - First systems
KW  - Naive bayes
KW  - Root-mean-square deviations
KW  - Sequence pair
KW  - Single sequences
KW  - Subtask
KW  - Support vector machine models
KW  - Support vectors machine
KW  - Transformer modeling
KW  - Support vector machines
A2  - Herbelot A.
A2  - Zhu X.
A2  - Palmer A.
A2  - Schneider N.
A2  - May J.
A2  - Shutova E.
PB  - International Committee for Computational Linguistics
SN  - 978-195214831-6 (ISBN)
LA  - English
J2  - Int. Workshops Semant. Eval., SemEval - co-located Int. Conf. Comput. Linguist., COLING , Proc.
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 6; Conference name: 14th International Workshops on Semantic Evaluation, SemEval 2020; Conference date: 12 December 2020 through 13 December 2020; Conference code: 174265
ER  -

TY  - CONF
AU  - Gauthier, J.
AU  - Hu, J.
AU  - Wilcox, E.
AU  - Qian, P.
AU  - Levy, R.
TI  - SyntaxGym: An online platform for targeted evaluation of language models
PY  - 2020
T2  - Proceedings of the Annual Meeting of the Association for Computational Linguistics
SP  - 70
EP  - 76
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85106076977&partnerID=40&md5=e77c494ca55eea9d09a897e44d9a3abb
AD  - Department of Brain and Cognitive Sciences, Massachusetts Institute of Technology, United States
AD  - Department of Linguistics, Harvard University, United States
AB  - Targeted syntactic evaluations have yielded insights into the generalizations learned by neural network language models. However, this line of research requires an uncommon confluence of skills: both the theoretical knowledge needed to design controlled psycholinguistic experiments, and the technical proficiency needed to train and deploy large-scale language models. We present SyntaxGym, an online platform designed to make targeted evaluations accessible to both experts in NLP and linguistics, reproducible across computing environments, and standardized following the norms of psycholinguistic experimental design. This paper releases two tools of independent value for the computational linguistics community: 1. A website, syntaxgym.org, which centralizes the process of targeted syntactic evaluation and provides easy tools for analysis and visualization; 2. Two command-line tools, syntaxgym and lm-zoo, which allow any user to reproduce targeted syntactic evaluations and general language model inference on their own machine. © 2020 Association for Computational Linguistics
KW  - Computational linguistics
KW  - Design of experiments
KW  - Command line
KW  - Computing environments
KW  - Generalisation
KW  - Independent values
KW  - Language model
KW  - Large-scales
KW  - Linguistic communities
KW  - Network language
KW  - Neural-networks
KW  - Online platforms
KW  - Syntactics
PB  - Association for Computational Linguistics (ACL)
SN  - 0736587X (ISSN); 978-195214804-0 (ISBN)
LA  - English
J2  - Proc. Annu. Meet. Assoc. Comput Linguist.
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 33; Conference name: 58th Annual Meeting of the Association for Computational Linguistics, ACL 2020; Conference date: 5 July 2020 through 10 July 2020; Conference code: 172534
ER  -

TY  - CONF
AU  - Melis, G.
AU  - Dyer, C.
AU  - Blunsom, P.
TI  - On the state of the art of evaluation in neural language models
PY  - 2018
T2  - 6th International Conference on Learning Representations, ICLR 2018 - Conference Track Proceedings
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85083950108&partnerID=40&md5=c9c04b87bd8059c811068e40c0540fc7
AD  - DeepMind, United Kingdom
AD  - University of Oxford, United Kingdom
AB  - Ongoing innovations in recurrent neural network architectures have provided a steady influx of apparently state-of-the-art results on language modelling benchmarks. However, these have been evaluated using differing codebases and limited computational resources, which represent uncontrolled sources of experimental variation. We reevaluate several popular architectures and regularisation methods with large-scale automatic black-box hyperparameter tuning and arrive at the somewhat surprising conclusion that standard LSTM architectures, when properly regularised, outperform more recent models. We establish a new state of the art on the Penn Treebank and Wikitext-2 corpora, as well as strong baselines on the Hutter Prize dataset. © Learning Representations, ICLR 2018 - Conference Track Proceedings.All right reserved.
KW  - Computational linguistics
KW  - Modeling languages
KW  - Network architecture
KW  - Black boxes
KW  - Computational resources
KW  - Hyper-parameter
KW  - Language model
KW  - Language modelling
KW  - Regularisation
KW  - State of the art
KW  - Treebanks
KW  - Long short-term memory
PB  - International Conference on Learning Representations, ICLR
LA  - English
J2  - Int. Conf. Learn. Represent., ICLR - Conf. Track Proc.
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 133; Conference name: 6th International Conference on Learning Representations, ICLR 2018; Conference date: 30 April 2018 through 3 May 2018; Conference code: 149806
ER  -

TY  - CONF
AU  - Zhao, Y.
AU  - Luo, Z.
AU  - Aizawa, A.
TI  - A language model based evaluator for sentence compression
PY  - 2018
T2  - ACL 2018 - 56th Annual Meeting of the Association for Computational Linguistics, Proceedings of the Conference (Long Papers)
VL  - 2
SP  - 170
EP  - 175
DO  - 10.18653/v1/p18-2028
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85063158538&doi=10.18653%2fv1%2fp18-2028&partnerID=40&md5=2df2aa95d8cc42dc1740b0cd2b798b6f
AD  - University of Tokyo, 7-3-1 Hongo, Bunkyo-ku, Tokyo, Japan
AD  - National Institute of Informatics, 2-1-2 Hitotsubashi, Chiyoda-ku, Tokyo, Japan
AB  - We herein present a language-model-based evaluator for deletion-based sentence compression, and viewed this task as a series of deletion-and-evaluation operations using the evaluator. More specifically, the evaluator is a syntactic neural language model that is first built by learning the syntactic and structural collocation among words. Subsequently, a series of trial-and-error deletion operations are conducted on the source sentences via a reinforcement learning framework to obtain the best target compression. An empirical study shows that the proposed model can effectively generate more readable compression, comparable or superior to several strong baselines. Furthermore, we introduce a 200-sentence test set for a large-scale dataset, setting a new baseline for the future research. © 2018 Association for Computational Linguistics.
KW  - Large dataset
KW  - Reinforcement learning
KW  - Statistical tests
KW  - Syntactics
KW  - Empirical studies
KW  - Language model
KW  - Large-scale dataset
KW  - Sentence compression
KW  - Target compressions
KW  - Test sets
KW  - Trial and error
KW  - Computational linguistics
PB  - Association for Computational Linguistics (ACL)
SN  - 978-194808734-6 (ISBN)
LA  - English
J2  - ACL - Annu. Meet. Assoc. Comput. Linguist., Proc. Conf. (Long Pap.)
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 21; Conference name: 56th Annual Meeting of the Association for Computational Linguistics, ACL 2018; Conference date: 15 July 2018 through 20 July 2018; Conference code: 145927
ER  -

TY  - CONF
AU  - Tamura, K.
AU  - Suzuki, I.
AU  - Hara, K.
TI  - Target evaluation for neural language model using japanese case frame
PY  - 2020
T2  - IC3K 2020 - Proceedings of the 12th International Joint Conference on Knowledge Discovery, Knowledge Engineering and Knowledge Management
VL  - 1
SP  - 251
EP  - 258
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85107127337&partnerID=40&md5=4cd164972d1554d425bdf1f0d5ab4936
AD  - Graduate School of Science and Engineering, Yamagata University, Yonezawa-shi, Yamagata, Japan
AD  - School of Information and Data Sciences, Nagasaki University, Nagasaki-shi, Nagasaki, Japan
AD  - Faculty of Science, Yamagata University, Yamagata-shi, Yamagata, Japan
AB  - Automatic text generation are widely used in various type of natural language processing systems. It is crucial to capture correct grammar for these systems to work. According to the recent studies, neural language models successfully acquire English grammar. However, it's not thoroughly investigated why the neural language models work. Therefore, fine-grained grammatical or syntactic analysis is important to assess neural language models. In this paper, we constructed grammatical evaluation methods to assess Japanese grammatical ability in neural language models by adopting a target evaluation approach. We especially focus on case marker and verb match in Japanese case grammar. In experiments, we report the grammatical ability of neural language model by comparing n-gram models. Neural language model performed better even some information lacks, while n-gram performs poorly. Also, Neural language model exhibited more robust performance for low frequency terms.  Copyright © 2020 by SCITEPRESS - Science and Technology Publications, Lda. All rights reserved.
KW  - Japanese case frame
KW  - Lstm
KW  - Neural language model
KW  - Target evaluation
KW  - Knowledge management
KW  - Natural language processing systems
KW  - Search engines
KW  - Syntactics
KW  - Automatic text generation
KW  - Case grammars
KW  - Evaluation approach
KW  - Evaluation methods
KW  - Language model
KW  - Low-frequency
KW  - Robust performance
KW  - Syntactic analysis
KW  - Computational linguistics
A2  - Fred A.
A2  - Filipe J.
PB  - SciTePress
SN  - 978-989758474-9 (ISBN)
LA  - English
J2  - IC3K - Proc. Int. Jt. Conf. Knowl. Discov., Knowl. Eng. Knowl. Manag.
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 0; Conference name: 12th International Conference on Knowledge Discovery and Information Retrieval, KDIR 2020 - Part of the 12th International Joint Conference on Knowledge Discovery, Knowledge Engineering and Knowledge Management, IC3K 2020; Conference date: 2 November 2020 through 4 November 2020; Conference code: 165136
ER  -

TY  - CONF
AU  - Tarasov, D.
AU  - Matveeva, T.
AU  - Galiullina, N.
TI  - An empirical investigation of language model based reverse turing test as a tool for knowledge and skills assessment
ST  - ЭМПИРИЧЕСКОЕ ИССЛЕДОВАНИЕ ОБРАТНОГО ТЕСТА ТЬЮРИНГА НА ОСНОВЕ ЯЗЫКОВОЙ МОДЕЛИ КАК ИНСТРУМЕНТА ОЦЕНКИ ЗНАНИЙ И НАВЫКОВ
PY  - 2020
T2  - Komp'juternaja Lingvistika i Intellektual'nye Tehnologii
VL  - 2020-June
IS  - 19
SP  - 696
EP  - 707
DO  - 10.28995/2075-7182-2020-19-696-707
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85093818339&doi=10.28995%2f2075-7182-2020-19-696-707&partnerID=40&md5=f781ba78e15e5adaecaa805def9cc54e
AD  - Meanotek, Kazan, Russian Federation
AB  - Automating assessment of person's skills is an important area of study in artificial intelligence and natural language processing. In this work we conduct empirical study of a recently proposed Reverse Turing Test for Knowledge Assessment approach-a completely automated domain agnostic method of knowledge assessment that can operate completely without human assessor involvement. Our study involved 53 participants and three different knowledge domains. We conclude that this method can reliably differentiate between expertise levels and therefore can be a compelling alternative to human grading and multiple-choice tests in many domains. © 2020 ABBYY PRODUCTION LLC. All rights reserved.
KW  - Knowledge assesment
KW  - Language model
KW  - Reverse Turing test
PB  - ABBYY PRODUCTION LLC
SN  - 22217932 (ISSN)
LA  - English
J2  - Komp'ut. Lingvist. Intellekt. Tehnol.
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 1; Correspondence Address: D. Tarasov; Meanotek, Kazan, Russian Federation; email: dtarasov3@gmail.com; Conference name: 2020 Annual International Conference on Computational Linguistics and Intellectual Technologies, Dialogue 2020; Conference date: 17 June 2020 through 20 June 2020; Conference code: 163840
ER  -

TY  - CONF
AU  - Irie, K.
AU  - Zeyer, A.
AU  - Schluter, R.
AU  - Ney, H.
TI  - Training Language Models for Long-Span Cross-Sentence Evaluation
PY  - 2019
T2  - 2019 IEEE Automatic Speech Recognition and Understanding Workshop, ASRU 2019 - Proceedings
C7  - 9003788
SP  - 419
EP  - 426
DO  - 10.1109/ASRU46091.2019.9003788
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85081569163&doi=10.1109%2fASRU46091.2019.9003788&partnerID=40&md5=18e424362c0105e42330bf0216832b23
AD  - Human Language Technology and Pattern Recognition Group, RWTH Aachen University, Computer Science Department, Aachen, 52074, Germany
AD  - AppTek GmbH, Aachen, 52062, Germany
AB  - While recurrent neural networks can motivate cross-sentence language modeling and its application to automatic speech recognition (ASR), corresponding modifications of the training method for that end are rarely discussed. In fact, even more generally, the impact of training sequence construction strategy in language modeling for different evaluation conditions is typically ignored. In this work, we revisit this basic but fundamental question. We train language models based on long short-Term memory recurrent neural networks and Transformers using various types of training sequences and study their robustness with respect to different evaluation modes. Our experiments on 300h Switchboard and Quaero English datasets show that models trained with back-propagation over sequences consisting of concatenation of multiple sentences with state carry-over across sequences effectively outperform those trained with the sentence-level training, both in terms of perplexity and word error rates for cross-utterance ASR. © 2019 IEEE.
KW  - cross-utterance speech recognition
KW  - language modeling
KW  - recurrent neural networks
KW  - self-Attention
KW  - Backpropagation
KW  - Computational linguistics
KW  - Modeling languages
KW  - Radio systems
KW  - Recurrent neural networks
KW  - Automatic speech recognition
KW  - Construction strategies
KW  - Evaluation modes
KW  - ITS applications
KW  - Language model
KW  - self-Attention
KW  - Training methods
KW  - Training sequences
KW  - Speech recognition
PB  - Institute of Electrical and Electronics Engineers Inc.
SN  - 978-172810306-8 (ISBN)
LA  - English
J2  - IEEE Autom. Speech Recognit. Underst. Workshop, ASRU - Proc.
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 30; Conference name: 2019 IEEE Automatic Speech Recognition and Understanding Workshop, ASRU 2019; Conference date: 15 December 2019 through 18 December 2019; Conference code: 157953
ER  -

TY  - CONF
AU  - Kramer, E.R.
AU  - Sáinz, A.O.
AU  - Mitrevski, A.
AU  - Plöger, P.G.
TI  - Tell Your Robot What to Do: Evaluation of Natural Language Models for Robot Command Processing
PY  - 2019
T2  - Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)
VL  - 11531 LNAI
SP  - 255
EP  - 267
DO  - 10.1007/978-3-030-35699-6_20
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85076908939&doi=10.1007%2f978-3-030-35699-6_20&partnerID=40&md5=a5fc7bb8d331735571021d21013a5e82
AD  - Hochschule Bonn-Rhein-Sieg, Sank[20], t Augustin, Germany
AB  - The use of natural language to indicate robot tasks is a convenient way to command robots. As a result, several models and approaches capable of understanding robot commands have been developed, which, however, complicates the choice of a suitable model for a given scenario. In this work, we present a comparative analysis and benchmarking of four natural language understanding models - Mbot, Rasa, LU4R, and ECG. We particularly evaluate the performance of the models to understand domestic service robot commands by recognizing the actions and any complementary information in them in three use cases: the RoboCup@Home General Purpose Service Robot (GPSR) category 1 contest, GPSR category 2, and hospital logistics in the context of the ROPOD project. © 2019, Springer Nature Switzerland AG.
KW  - Benchmarking
KW  - Comparative analysis
KW  - Natural language understanding
KW  - Robot commands
KW  - Mobile robots
KW  - Comparative analysis
KW  - Domestic services
KW  - Hospital logistics
KW  - Natural language model
KW  - Natural language understanding
KW  - Natural languages
KW  - Robot commands
KW  - Service robots
KW  - Benchmarking
A2  - Chalup S.
A2  - Niemueller T.
A2  - Suthakorn J.
A2  - Williams M.
PB  - Springer
SN  - 03029743 (ISSN); 978-303035698-9 (ISBN)
LA  - English
J2  - Lect. Notes Comput. Sci.
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 1; Correspondence Address: E.R. Kramer; Hochschule Bonn-Rhein-Sieg, Sank[20], t Augustin, Germany; email: erick.romero@smail.inf.h-brs.de; Conference name: 23rd Annual RoboCup International Symposium, RoboCup 2019; Conference date: 2 July 2019 through 8 July 2019; Conference code: 234969
ER  -

TY  - JOUR
AU  - Sun, Y.
AU  - Zhang, P.
AU  - Pi, J.
AU  - Sun, X.
AU  - Li, X.
AU  - Fan, Y.
TI  - Fuzzy State Assessment Model of Converter Transformer Based on Center Distance and Sample Features
ST  - 基于中心距和样本特征的换流变压器模糊状态评估模型
PY  - 2019
T2  - Gaoya Dianqi/High Voltage Apparatus
VL  - 55
IS  - 12
SP  - 90
EP  - 97
DO  - 10.13296/j.1001-1609.hva.2019.12.013
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85077460407&doi=10.13296%2fj.1001-1609.hva.2019.12.013&partnerID=40&md5=6807f4986cb091e21c050c6fca9bb0e2
AD  - EHV Power Transmission Company Maintenance & Test Center, CSG, Guangzhou, 510663, China
AD  - School of Electrical Engineering, Wuhan University, Wuhan, 430072, China
AB  - Converter transformer is one of the most significant equipment in HVDC transmission project. As its running time goes by, the insulation problem is becoming prominently serious, it is highly necessary to establish the converter transformer state assessment model. With a comprehensive analysis of converter transformer structure and working characteristics, an overall evaluation index system of converter transformer is built. A fuzzy analytic hierarchy process method for converter transformers state assessment is proposed, which averts the impact of subjective factors. Based on the operation and maintenance data of converter transformer in different periods of one year, a number of converter transformer fuzzy condition assessment models, with different sample features, are established. Finally the comprehensive and fuzzy assessment model of converter transformer, based on sample characteristics, is obtained by using the center distance fusion method. Based on the statistical data of operation and maintenance, the method fully reflects the structural features and the operation features of the converter transformer in different periods, which has higher accuracy and wider range of application. © 2019, Xi'an High Voltage Apparatus Research Institute Co., Ltd. All right reserved.
KW  - Center distance fusion method
KW  - Converter transformer
KW  - Fuzzy analytic hierarchy process
KW  - Sample features
KW  - State assessment
PB  - Xi'an High Voltage Apparatus Research Institute
SN  - 10011609 (ISSN)
LA  - Chinese
J2  - Gaoya Dianqi
M3  - Article
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 0; CODEN: GADIE
ER  -

TY  - CONF
AU  - Kuvshinova, T.
AU  - Khritankov, A.
TI  - Improving a language model evaluator for sentence compression without reinforcement learning
PY  - 2019
T2  - ACM International Conference Proceeding Series
SP  - 92
EP  - 97
DO  - 10.1145/3368926.3369713
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85077824051&doi=10.1145%2f3368926.3369713&partnerID=40&md5=cd63e9ea51a2b4bce3b60909f934eca2
AD  - R&D RBtechnologies, Russian Federation
AB  - We consider sentence compression as a binary classification task on tokens. In this paper we improve on a language model evaluator model by incorporating a score from a neural language model directly into the loss function instead of resorting to reinforcement learning. As a result, the model learns to remove individual tokens and to preserve readability at the same time while maintaining the desired level of compression. We compare our model with a state-of-the-art model, which uses a policy-based reinforcement learning method for evaluating compressed sentences on readability. We perform automatic evaluation and evaluation with humans. Experiments demonstrate that we were able to improve on the strong baselines. We also provide human-evaluation of 200 gold compressions from Google dataset setting a baseline for humanevaluation in upcoming studies. © 2019 Copyright held by the owner/author(s).
KW  - Language model
KW  - Neural networks
KW  - Sentence compression
KW  - Summarization
KW  - Computational linguistics
KW  - Neural networks
KW  - Reinforcement learning
KW  - Automatic evaluation
KW  - Binary classification
KW  - Human evaluation
KW  - Language model
KW  - Reinforcement learning method
KW  - Sentence compression
KW  - State of the art
KW  - Summarization
KW  - Learning systems
PB  - Association for Computing Machinery
SN  - 978-145037245-9 (ISBN)
LA  - English
J2  - ACM Int. Conf. Proc. Ser.
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 1; Conference name: 10th International Symposium on Information and Communication Technology, SoICT 2019; Conference date: 4 December 2019 through 6 December 2019; Conference code: 156141
ER  -

TY  - CONF
AU  - Bashabsheh, E.A.
AU  - Aqouleh, A.A.
AU  - AL-Smadi, M.
TI  - NLP@JUST at SemEval-2020 Task 4: Ensemble Technique for BERT and Roberta to Evaluate Commonsense Validation
PY  - 2020
T2  - 14th International Workshops on Semantic Evaluation, SemEval 2020 - co-located 28th International Conference on Computational Linguistics, COLING 2020, Proceedings
SP  - 574
EP  - 579
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85123923613&partnerID=40&md5=016da3128cb779d242a385f24409ac42
AD  - Computer Science Jordan University of Science and Technology, Irbid, Jordan
AB  - This paper presents the work of the NLP@JUST team at SemEval-2020 Task 4 competition that related to commonsense validation and explanation (ComVE) task. The team participates in sub-taskA (Validation) which related to validation that checks if the text is against common sense or not. Several models have trained (i.e. Bert, XLNet, and Roberta), however, the main models used are the RoBERTa-large and BERT Whole word masking. As well as, we utilized the results from both models to generate final prediction by using the average Ensemble technique, that used to improve the overall performance. The evaluation result shows that the implemented model achieved an accuracy of 93.9% obtained and published at the post-evaluation result on the leaderboard. © 2020 14th International Workshops on Semantic Evaluation, SemEval 2020 - co-located 28th International Conference on Computational Linguistics, COLING 2020, Proceedings. All rights reserved.
KW  - Computational linguistics
KW  - Semantics
KW  - Common sense
KW  - Ensemble techniques
KW  - Evaluation results
KW  - Performance
KW  - Post evaluations
KW  - Natural language processing systems
A2  - Herbelot A.
A2  - Zhu X.
A2  - Palmer A.
A2  - Schneider N.
A2  - May J.
A2  - Shutova E.
PB  - International Committee for Computational Linguistics
SN  - 978-195214831-6 (ISBN)
LA  - English
J2  - Int. Workshops Semant. Eval., SemEval - co-located Int. Conf. Comput. Linguist., COLING , Proc.
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 1; Conference name: 14th International Workshops on Semantic Evaluation, SemEval 2020; Conference date: 12 December 2020 through 13 December 2020; Conference code: 174265
ER  -

TY  - CONF
AU  - Hamoud, G.A.
AU  - Lee, L.
AU  - Faried, S.O.
TI  - Spare Assessment of Distribution Power Transformers using Two Markov Models
PY  - 2019
T2  - IEEE Power and Energy Society General Meeting
VL  - 2019-August
C7  - 8973546
DO  - 10.1109/PESGM40551.2019.8973546
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85079031399&doi=10.1109%2fPESGM40551.2019.8973546&partnerID=40&md5=5d8f739e861e815eaf21135bf46e0d2d
AD  - Hydro One Ltd., Toronto, Canada
AD  - University of Saskatchewan, Saskatoon, Canada
AB  - In earlier spare assessment studies of distribution power transformers at Hydro One, the issues of the full utilization of mobile unit substations (MUSs) and their reliabilities were not fully addressed and therefore, the results of spare studies may have been underestimated. This paper describes a study that has been performed recently to address the two mentioned issues. The study used a simple and flexible probabilistic approach that shows how the two issues can be properly addressed and helps explain the results of earlier spare studies. The proposed assessment approach uses two Markov models: one representing minor transformer failures and one representing major transformer failures for a group of similar distribution power transformers. The MUS utilization factor introduced in this study is incorporated into each failure model in order to obtain the group availability as a function of the number of spare units. The results of a sample distribution system show that the two issues can have significant impacts on the spare assessment results. The purpose of this paper is to describe the study and its findings and to compare its results with the earlier spare methods of assessment. © 2019 IEEE.
KW  - Distribution transformer
KW  - group availability
KW  - Markov model
KW  - mobile unit substation
KW  - probability
KW  - regular spare transformer
KW  - transformer minor and major failures
KW  - Markov processes
KW  - Power transformers
KW  - Probability
KW  - Distribution transformer
KW  - Group availabilities
KW  - Major failures
KW  - Markov model
KW  - Mobile units
KW  - Spare transformer
KW  - Probability distributions
PB  - IEEE Computer Society
SN  - 19449925 (ISSN); 978-172811981-6 (ISBN)
LA  - English
J2  - IEEE Power Energy Soc. Gen. Meet.
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 1; Conference name: 2019 IEEE Power and Energy Society General Meeting, PESGM 2019; Conference date: 4 August 2019 through 8 August 2019; Conference code: 157221
ER  -

TY  - CONF
AU  - Hua, Y.
AU  - Sun, Y.
AU  - Li, N.
AU  - Ma, S.
AU  - Wang, E.
TI  - The power transformer operating condition evaluation based on the genetic projection pursuit model
PY  - 2019
T2  - IOP Conference Series: Materials Science and Engineering
VL  - 486
IS  - 1
C7  - 012039
DO  - 10.1088/1757-899X/486/1/012039
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85070336913&doi=10.1088%2f1757-899X%2f486%2f1%2f012039&partnerID=40&md5=79c34c2473ab475b16bff0c4f28a1e96
AD  - School of Electrical Engineering, Shandong University, Jinan, 250061, China
AB  - Transformer is a key equipment in the power system, and it is very important to accurately evaluate its operating state. In this paper, a new method is proposed to evaluate the operating state of the power transformer based on the genetic projection pursuit model. The proposed method can provide a more objective evaluation result for the health condition of the transformers compared with the traditional methods. Firstly, a three-layer evaluation index system is established with the precautionary test, oil chromatographic analysis and insulating oil properties as the core content. And then, the grading standard of the lowest level index in the indicator system is established. Secondly, the genetic projection pursuit model is used in combination with the grading standard to obtain the intermediate layer evaluation results, which overcomes the disadvantages of the traditional transformer evaluation method which is greatly influenced by subjective factors. Finally, the eigenvalue weighting method is used to integrate the intermediate layer evaluation results to obtain the final result. Case study results show that the evaluation method of transformer operating state based on genetic projection pursuit model is reasonable and effective. © Published under licence by IOP Publishing Ltd.
KW  - Chromatographic analysis
KW  - Eigenvalues and eigenfunctions
KW  - Power transformers
KW  - Evaluation index system
KW  - Evaluation results
KW  - Grading standards
KW  - Intermediate layers
KW  - Objective evaluation
KW  - Operating condition
KW  - Projection pursuit models
KW  - Weighting methods
KW  - Grading
PB  - Institute of Physics Publishing
SN  - 17578981 (ISSN)
LA  - English
J2  - IOP Conf. Ser. Mater. Sci. Eng.
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 0; Correspondence Address: Y. Sun; School of Electrical Engineering, Shandong University, Jinan, 250061, China; email: sunyy@sdu.edu.cn; Conference name: 2019 4th Asia Conference on Power and Electrical Engineering, ACPEE 2019; Conference date: 28 March 2019 through 31 March 2019; Conference code: 149895
ER  -

TY  - CONF
AU  - Gehman, S.
AU  - Gururangan, S.
AU  - Sap, M.
AU  - Choi, Y.
AU  - Smith, N.A.
TI  - REALTOXICITYPROMPTS: Evaluating neural toxic degeneration in language models
PY  - 2020
T2  - Findings of the Association for Computational Linguistics Findings of ACL: EMNLP 2020
SP  - 3356
EP  - 3369
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85101691799&partnerID=40&md5=5423098fd0ca086a2a03096493f49b17
AD  - Paul G. Allen School of Computer Science and Engineering, University of Washington, Seattle, United States
AD  - Allen Institute for Artificial Intelligence, Seattle, United States
AB  - Pretrained neural language models (LMs) are prone to generating racist, sexist, or otherwise toxic language which hinders their safe deployment. We investigate the extent to which pretrained LMs can be prompted to generate toxic language, and the effectiveness of controllable text generation algorithms at preventing such toxic degeneration. We create and release REALTOXICITYPROMPTS, a dataset of 100K naturally occurring, sentence-level prompts derived from a large corpus of English web text, paired with toxicity scores from a widely-used toxicity classifier. Using REALTOXICITYPROMPTS, we find that pretrained LMs can degenerate into toxic text even from seemingly innocuous prompts. We empirically assess several controllable generation methods, and find that while data- or compute-intensive methods (e.g., adaptive pretraining on non-toxic data) are more effective at steering away from toxicity than simpler solutions (e.g., banning “bad” words), no current method is failsafe against neural toxic degeneration. To pinpoint the potential cause of such persistent toxic degeneration, we analyze two web text corpora used to pretrain several LMs (including GPT-2; Radford et al., 2019), and find a significant amount of offensive, factually unreliable, and otherwise toxic content. Our work provides a test bed for evaluating toxic generations by LMs and stresses the need for better data selection processes for pretraining. © 2020 Association for Computational Linguistics
KW  - Classification (of information)
KW  - Computational linguistics
KW  - Large dataset
KW  - Generation algorithm
KW  - Generation method
KW  - Language model
KW  - Large corpora
KW  - Naturally occurring
KW  - Non-toxic
KW  - Pre-training
KW  - Sentence level
KW  - Text generations
KW  - Web texts
KW  - Toxicity
PB  - Association for Computational Linguistics (ACL)
SN  - 978-195214890-3 (ISBN)
LA  - English
J2  - Findings Assoc. Comp. Linguist. Findings ACL: EMNLP
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 201; Conference name: Findings of the Association for Computational Linguistics, ACL 2020: EMNLP 2020; Conference date: 16 November 2020 through 20 November 2020; Conference code: 172733
ER  -

TY  - CONF
AU  - King, M.
AU  - Cook, P.
TI  - Evaluating approaches to personalizing language models
PY  - 2020
T2  - LREC 2020 - 12th International Conference on Language Resources and Evaluation, Conference Proceedings
SP  - 2461
EP  - 2469
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85096608966&partnerID=40&md5=02687539a18d5d94cc693d8d7c687f88
AD  - University of New Brunswick, Fredericton, NB, Canada
AB  - In this work, we consider the problem of personalizing language models, that is, building language models that are tailored to the writing style of an individual. Because training language models requires a large amount of text, and individuals do not necessarily possess a large corpus of their writing that could be used for training, approaches to personalizing language models must be able to rely on only a small amount of text from any one user. In this work, we compare three approaches to personalizing a language model that was trained on a large background corpus using a relatively small amount of text from an individual user. We evaluate these approaches using perplexity, as well as two measures based on next word prediction for smartphone soft keyboards. Our results show that when only a small amount of user-specific text is available, an approach based on priming gives the most improvement, while when larger amounts of user-specific text are available, an approach based on language model interpolation performs best. We carry out further experiments to show that these approaches to personalization outperform language model adaptation based on demographic factors. © European Language Resources Association (ELRA), licensed under CC-BY-NC
KW  - Domain adaptation
KW  - Language modelling
KW  - Personalization
KW  - Demographic factors
KW  - Evaluating approach
KW  - Language model
KW  - Language model adaptation
KW  - Large amounts
KW  - Personalizations
KW  - Word prediction
KW  - Writing style
KW  - Computational linguistics
A2  - Calzolari N.
A2  - Bechet F.
A2  - Blache P.
A2  - Choukri K.
A2  - Cieri C.
A2  - Declerck T.
A2  - Goggi S.
A2  - Isahara H.
A2  - Maegaard B.
A2  - Mariani J.
A2  - Mazo H.
A2  - Moreno A.
A2  - Odijk J.
A2  - Piperidis S.
PB  - European Language Resources Association (ELRA)
SN  - 979-109554634-4 (ISBN)
LA  - English
J2  - LREC - Int. Conf. Lang. Resour. Eval., Conf. Proc.
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 7; Conference name: 12th International Conference on Language Resources and Evaluation, LREC 2020; Conference date: 11 May 2020 through 16 May 2020; Conference code: 164155
ER  -

TY  - JOUR
AU  - Kumar, K.
AU  - Kumbhar, B.G.
AU  - Satsangi, S.
TI  - Assessment of Effect of Load Models on Loss-of-Life Calculation of a Transformer Using a Point Estimation Method
PY  - 2018
T2  - Electric Power Components and Systems
VL  - 46
IS  - 16-17
SP  - 1808
EP  - 1819
DO  - 10.1080/15325008.2018.1511874
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85057332356&doi=10.1080%2f15325008.2018.1511874&partnerID=40&md5=0bf4d7a09432744b4d6bd810a441c9af
AD  - Department of Electrical Engineering, Indian Institute of Technology, Roorkee, India
AB  - The study of the impact of load models on transformer insulation life is essential for the truthful aging calculation. In most of the studies related to the assessment of transformer aging, distribution loads are treated as constant power type. However, the practical loads are of mix type (combination of constant power, constant current, constant impedance). Moreover, the residential, commercial, and industrial loads comprise the different percentages of constant power, constant current, and constant impedance loads. In this article, different load models are investigated to quantify their impact on the aging calculation of a transformer under various loading scenarios and environmental conditions. The study includes different classes of the loads with corresponding load shapes, ambient temperatures, determined for a typical week of each season. It considers highly unbalanced transformer loading conditions and network configurations. The study also considers the effect of harmonics on the transformer aging. Aging acceleration rate and percentage loss of life of the substation transformer connected to IEEE 13-bus system have been calculated for different loading and climatic conditions. The same procedure has been adopted for the modified IEEE 123-bus system, and the trends of the results have been compared with the IEEE 13-bus system. It has been shown that the load models make a considerable effect on life calculation of a transformer. Therefore, selection of an appropriate load model is important for accurate estimation of aging of a transformer. © 2018, Copyright © Taylor & Francis Group, LLC.
KW  - aging acceleration factor
KW  - distribution transformer
KW  - load models
KW  - loss of life
KW  - Electric transformers
KW  - Transformer substations
KW  - Acceleration factors
KW  - Distribution transformer
KW  - Environmental conditions
KW  - Load models
KW  - Loss of life
KW  - Point estimation method
KW  - Substation transformers
KW  - Transformer insulation
KW  - Loading
PB  - Taylor and Francis Inc.
SN  - 15325008 (ISSN)
LA  - English
J2  - Electr. Power Comp. Syst.
M3  - Article
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 2; Correspondence Address: K. Kumar; Department of Electrical Engineering, Indian Institute of Technology, Roorkee, 247667, India; email: kanhaiyak6@gmail.com
ER  -

TY  - JOUR
AU  - Zhang, M.
AU  - Liu, J.
AU  - Yin, M.
AU  - Jia, H.
AU  - Lv, J.
TI  - Assessment on Oil-Paper Insulation Aging of Transformer Based on Dielectric Response Model
PY  - 2019
T2  - Electric Power Components and Systems
VL  - 47
IS  - 13
SP  - 1145
EP  - 1155
DO  - 10.1080/15325008.2019.1663454
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85073927228&doi=10.1080%2f15325008.2019.1663454&partnerID=40&md5=a3b533f0615d5da529bda2258256f2b0
AD  - Key Laboratory of Engineering Dielectrics and Its Application, Ministry of Education, Harbin University of Science and Technology, Harbin, China
AD  - State Key Laboratory Breeding Base of Dielectrics Engineering, Harbin University of Science and Technology, Harbin, China
AD  - State Power Grid Corp, Harbin Power Bureau, Harbin, China
AB  - For nondestructive assessment of insulation aging in power transformer, dielectric response technology is usually used to evaluate the oil-paper insulation aging. In this paper, a quantitative evaluation method of insulation aging based on Davidson-Cole model is proposed. The oil-paper insulation equivalent Debye model parameters of transformer are extracted by exponential function fitting. According to the complex permittivity of oil-paper insulation, the parameters of Davidson-Cole model are extracted by fitting algorithm. Under laboratory conditions, accelerated thermal aging test are carried out. The quantitative relationship between Davidson-Cole model parameters and aging of oil-paper insulation is analyzed. The experimental results show that the Davidson-Cole model parameters are directly related to the aging time. It is found that the parameters β and Δε of the Davidson-Cole model gradually decreases and the parameter τ gradually increases with the polymerization degree of oil-impregnated paper. Therefore, according to the quantitative characterization of the model parameters, the aging of transformer oil-paper insulation can be effectively evaluated, which is helpful to realize the nondestructive testing of polymerization degree in oil-impregnated pressboard (paper) power transformer. © 2019, © 2019 Taylor & Francis Group, LLC.
KW  - Davidson-Cole model
KW  - dielectric response test
KW  - insulation assessment
KW  - oil-paper insulation
KW  - Electric transformer testing
KW  - Exponential functions
KW  - Insulation
KW  - Nondestructive examination
KW  - Parameter estimation
KW  - Polymerization
KW  - Power transformers
KW  - Thermal aging
KW  - Accelerated thermal aging
KW  - Davidson-Cole model
KW  - Dielectric response
KW  - Insulation assessment
KW  - Nondestructive assessment
KW  - Oil paper insulation
KW  - Quantitative characterization
KW  - Quantitative evaluation methods
KW  - Oil filled transformers
PB  - Taylor and Francis Inc.
SN  - 15325008 (ISSN)
LA  - English
J2  - Electr. Power Comp. Syst.
M3  - Article
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 8; Correspondence Address: J. Liu; Key Laboratory of Engineering Dielectrics and Its Application, Ministry of Education, Harbin University of Science and Technology, Harbin, 150080, China; email: liuji@hrbust.edu.cn
ER  -

TY  - CONF
AU  - Peng, Y.
AU  - Yan, S.
AU  - Lu, Z.
TI  - Transfer learning in biomedical natural language processing: An evaluation of BERT and ELMo on ten benchmarking datasets
PY  - 2019
T2  - BioNLP 2019 - SIGBioMed Workshop on Biomedical Natural Language Processing, Proceedings of the 18th BioNLP Workshop and Shared Task
SP  - 58
EP  - 65
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85121468967&partnerID=40&md5=f8b21eddd5365e5270f7e839eca55665
AD  - National Center for Biotechnology Information, National Library of Medicine, National Institutes of Health, Bethesda, MD, United States
AB  - Inspired by the success of the General Language Understanding Evaluation benchmark, we introduce the Biomedical Language Understanding Evaluation (BLUE) benchmark to facilitate research in the development of pre-training language representations in the biomedicine domain. The benchmark consists of five tasks with ten datasets that cover both biomedical and clinical texts with different dataset sizes and difficulties. We also evaluate several baselines based on BERT and ELMo and find that the BERT model pre-trained on PubMed abstracts and MIMIC-III clinical notes achieves the best results. We make the datasets, pre-trained models, and codes publicly available at https://github.com/ncbi-nlp/BLUE_Benchmark. © 2019 Association for Computational Linguistics
KW  - Computational linguistics
KW  - Clinical notes
KW  - Data set size
KW  - Language understanding
KW  - Pre-training
KW  - Natural language processing systems
PB  - Association for Computational Linguistics (ACL)
SN  - 978-195073728-4 (ISBN)
LA  - English
J2  - BioNLP - SIGBioMed Workshop Biomed. Nat. Lang. Process., Proc. BioNLP Workshop Shar. Task
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 355; Conference name: 18th SIGBioMed Workshop on Biomedical Natural Language Processing, BioNLP 2019; Conference code: 173601
ER  -

TY  - JOUR
AU  - Marks, J.
AU  - Vitolina, S.
AU  - Dirba, J.
TI  - Magnetostrictive vibration model for evaluation of mechanical integrity of power transformer magnetic core
ST  - Magnetostriktīvu vibrāciju modelis spēka transformatoru magnētvada mehāniskās izturības novērtēšanai
PY  - 2019
T2  - Latvian Journal of Physics and Technical Sciences
VL  - 56
IS  - 3
SP  - 13
EP  - 25
DO  - 10.2478/lpts-2019-0016
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85069192813&doi=10.2478%2flpts-2019-0016&partnerID=40&md5=594587ae3881186539a661011b3b0005
AD  - Riga Technical University, 12/1 Azenes Str., Riga, LV-1048, Latvia
AB  - Magnetostriction process creates vibrations within magnetic core of a power transformer. This effect can cause delamination of magnetic core layers and increase the vibration amplitudes on the surface of transformer tank. In this paper, a magnetostrictive vibration model is proposed for improved evaluation of the mechanical integrity of magnetic core and the finding of possible mechanical defects. This model is based on the simulation of magnetostrictive vibrations by replacing the magnetic core with mass and spring system, and application of a dynamic genetic algorithm in order to find the necessary system configuration. A case study is provided structurally modelling magnetic core in Matlab and Matlab Simulink with the analysis of simulated vibrations that indicate a possible mechanical defect. © 2019 Sciendo. All rights reserved.
KW  - Magnetostriction
KW  - Numerical simulation
KW  - Transformer cores
PB  - Sciendo
SN  - 08688257 (ISSN)
LA  - English
J2  - Latv. J. Phys. Tech. Sci.
M3  - Article
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 4; Correspondence Address: J. Marks; Riga Technical University, Riga, 12/1 Azenes Str., LV-1048, Latvia; email: janis.marks@edu.rtu.lv
ER  -

TY  - JOUR
AU  - Liu, J.
AU  - Wang, Z.
AU  - Fan, X.
AU  - Zhang, Y.
AU  - Wang, J.
TI  - A Novel Curve Database for Moisture Evaluation of Transformer Oil-Immersed Cellulose Insulation Using FDS and Exponential Decay Model
PY  - 2020
T2  - IEEE Access
VL  - 8
C7  - 9212548
SP  - 180728
EP  - 180737
DO  - 10.1109/ACCESS.2020.3027906
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85092776732&doi=10.1109%2fACCESS.2020.3027906&partnerID=40&md5=5c31b182dc4cf5499333b4d821fbbd15
AD  - Guangxi Key Laboratory of Power System Optimization and Energy Technology, Guangxi University, Nanning, China
AB  - In recent decades, moisture evaluation of transformer oil-immersed cellulose insulation has been widely studied by using the frequency domain spectroscopy (FDS) technique. However, due to the difficulties in sample preparation, most of the existing evaluation methods are based on a small number of samples, which greatly limits the evaluation accuracy of these methods. To accurately evaluate moisture inside transformer oil-immersed cellulose insulation, a novel method combining the FDS technique and the exponential decay model is proposed. In current work, the exponential decay model is introduced to analyze the FDS data, which can be used to assess the quantitative relationship between moisture and extracted parameters. Then, the FDS curves with different moisture can be predicted by using these parameters to form a curve database. Findings reveal the relative error of evaluation results in lab condition is less than 10.57% when using the proposed curve database. In that respect, the feasibility of the proposed database is proved for moisture evaluation of transformer oil-immersed cellulose insulation. © 2013 IEEE.
KW  - exponential decay model
KW  - frequency domain spectroscopy (FDS)
KW  - moisture evaluation
KW  - oil-immersed cellulose insulation
KW  - Power transformer
KW  - Cellulose
KW  - Decay
KW  - Evaluation
KW  - Insulation
KW  - Methods
KW  - Moisture
KW  - Oil
KW  - Sample Preparation
KW  - Cellulose
KW  - Database systems
KW  - Frequency domain analysis
KW  - Insulating materials
KW  - Insulation
KW  - Moisture
KW  - Cellulose insulation
KW  - Evaluation accuracy
KW  - Evaluation methods
KW  - Evaluation results
KW  - Exponential decay models
KW  - Frequency domain spectroscopy
KW  - Number of samples
KW  - Sample preparation
KW  - Oil filled transformers
PB  - Institute of Electrical and Electronics Engineers Inc.
SN  - 21693536 (ISSN)
LA  - English
J2  - IEEE Access
M3  - Article
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 6; Correspondence Address: Y. Zhang; Guangxi Key Laboratory of Power System Optimization and Energy Technology, Guangxi University, Nanning, China; email: yiyizhang@gxu.edu.cn
ER  -

TY  - JOUR
AU  - Liu, R.
AU  - Peng, M.
AU  - Wan, X.
AU  - Zhang, H.
AU  - Zhou, W.
TI  - Evaluation of transformer insulation condition based on cloud matter element model
PY  - 2017
T2  - Acta Technica CSAV (Ceskoslovensk Akademie Ved)
VL  - 62
IS  - 1
SP  - 89
EP  - 102
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028651539&partnerID=40&md5=9817bca54cb404e5c20def05de092df2
AD  - College of Electrical and Information Engineering, Hunan University, Changsha, 410082, China
AD  - State Grid Hunan Electric Power Company Electric Power Research Institute, Changsha, 410007, China
AD  - Hunan Rural Credit Cooperatives Union, Hunan University, Changsha, 100101, China
AB  - The purpose of this paper is to study the insulation state of transformer. Insulation system is an important part of the transformer, and it is the basic condition for the normal operation and operation of the transformer. The insulation condition assessment of transformer is of great significance to guide the condition based maintenance of the transformer, to enhance the life cycle management and to save the cost of operation. Based on the cloud matter element theory, a method for evaluating the insulation state of transformers is proposed. The results show that the transformer insulation state evaluation model can effectively integrate various state parameters, and accurately assess the insulation state of the transformer each insulation parts and the whole part. Based on the above findings, we conclude that the model is suitable for evaluating the insulation state of transformers. © 2017 Institute of Thermomechanics CAS, v.v.i.
KW  - Cloud model
KW  - Insulation state
KW  - Matter element theory
KW  - Transformer
KW  - Life cycle
KW  - Cloud modeling
KW  - Condition based maintenance
KW  - Insulation conditions
KW  - Life-cycle management
KW  - Matter elements
KW  - Matter-element model
KW  - Transformer
KW  - Transformer insulation
KW  - Insulation
PB  - Academy of Sciences of the Czech Republic
SN  - 00017043 (ISSN)
LA  - English
J2  - Acta Tech CSAV
M3  - Article
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 1; CODEN: ATCVA
ER  -

TY  - JOUR
AU  - Xiao, Y.
AU  - Kang, N.
AU  - Chen, X.
TI  - Application of improved kernel principal component analysis support vector machine model in power transformer condition assessment
PY  - 2015
T2  - Journal of Information and Computational Science
VL  - 12
IS  - 10
SP  - 4105
EP  - 4112
DO  - 10.12733/jics20106202
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-84937597457&doi=10.12733%2fjics20106202&partnerID=40&md5=b56de8ccd12c41f879a4b51549b9f42b
AD  - School of Mechanical, Electronic and Control Engineering, Beijing Jiaotong University, Beijing, 100044, China
AD  - Beijing Electric Power Corporation, Beijing, 100031, China
AB  - Considering the fact that membership functions and factor weights are highly depend on man in fuzzy synthetic evaluation, a model for power transformer condition assessment based on Support Vector Machine (SVM) is presented. In order to eliminate the false feature and retain the true, the information data of the transformer is preprocessing with Kernel Principal Component Analysis (KPCA) first, the results become the inputs of SVM to form the KPCA+SVM model for transformer evaluation. To enhance the effect of evaluation, an improved KPCA+SVM model is proposed. Mixtures of kernels and parallel optimized strategies are used. The example shows the effectiveness and superiority of the improved model. 1548-7741/Copyright © 2015 Binary Information Press
KW  - Condition assessment
KW  - Kernel principal component analysis
KW  - Power transformer
KW  - Support vector machine
KW  - Membership functions
KW  - Power transformers
KW  - Condition assessments
KW  - Factor weight
KW  - Fuzzy synthetic evaluation
KW  - Information data
KW  - Kernel principal component analyses (KPCA)
KW  - Optimized strategies
KW  - Support vector machine models
KW  - Transformer condition assessment
KW  - Support vector machines
PB  - Binary Information Press
SN  - 15487741 (ISSN)
LA  - English
J2  - J. Inf. Comput. Sci.
M3  - Article
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 0; Correspondence Address: Y. Xiao; School of Mechanical, Electronic and Control Engineering, Beijing Jiaotong University, Beijing, 100044, China; email: ycxiao@bjtu.edu.cn
ER  -

TY  - CONF
AU  - Chao, W.
AU  - Yun-Cai, L.
AU  - Bi-Jun, C.
AU  - You-Yuan, W.
TI  - A multi-layer power transformer life span evaluating decision model based on information fusion
PY  - 2014
T2  - ICHVE 2014 - 2014 International Conference on High Voltage Engineering and Application
C7  - 7035506
DO  - 10.1109/ICHVE.2014.7035506
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-84988215559&doi=10.1109%2fICHVE.2014.7035506&partnerID=40&md5=42b7afef6696261eecaab0bd991ec96e
AD  - JiangSu Electric Power Company Research Institutes, Jiang Su, China
AD  - State Key Laboratory of Power Transmission Equipment and System Security and New Technology, School of Electrical Engineering, Chongqing University, Chongqing, China
AB  - The operational reliability of power transformers directly affects the stable and reliable power supply of the power system. According to the available data such as condition assessment, routine test results and maintenance records, a hierarchical architecture and information fusion technology based power transformers life estimation model is presented. Firstly, the model takes advantage of the fault mechanism and the knowledge fitting laws of export system to analyze association property between characteristic parameters and aging information. Then it collects the information representing the insulation aging, reclassify them into several types, and build up a multi-objective evaluating model of power transformers life estimation. After the hierarchy of model is confirmed, we fulfill single characteristic parameter based life estimation and probability density of failure by means of threshold value diagnosis, fuzzy inferences, expert knowledge system, etc. The value of parameters, illation process and evaluation results of the estimation are coded and saved in the database of expert system and enrich the expert knowledge base through deep data mining technology. According to the established evaluation hierarchical architecture, single characteristic parameter models are integrated into the evaluating index system and multi-objective model by analytic hierarchy process (AHP), which can determine the weights at all levels. The multi-parameter power transformer life span evaluating decision model based on information fusion is established so far. The lifetime characteristic parameters from all kinds of sources are integrated to serve as the base layer of the multi-layer decision model, which enhances the efficiency and reliability of this model. It provides a reference for drafting optimal maintenance scheme, achieving the aim of condition based maintenance and power utilities life prediction. © 2014 IEEE.
KW  - hierarchical architecture
KW  - information fusion
KW  - life estimation
KW  - power transformer
KW  - Analytic hierarchy process
KW  - Architecture
KW  - Data mining
KW  - Electric power systems
KW  - Electric transformer testing
KW  - Expert systems
KW  - Information fusion
KW  - Knowledge based systems
KW  - Maintenance
KW  - Power transformers
KW  - Probability density function
KW  - Analytic hierarchy process (ahp)
KW  - Condition based maintenance
KW  - Efficiency and reliability
KW  - Expert knowledge systems
KW  - Hierarchical architectures
KW  - Information fusion technology
KW  - Life estimation
KW  - Multi-objective modeling
KW  - Parameter estimation
PB  - Institute of Electrical and Electronics Engineers Inc.
SN  - 978-147996613-4 (ISBN)
LA  - English
J2  - ICHVE - Int. Conf. High Volt. Eng. Appl.
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 4; Conference name: 2014 4th International Conference on High Voltage Engineering and Application, ICHVE 2014; Conference date: 8 September 2014 through 11 September 2014; Conference code: 112626
ER  -

TY  - JOUR
AU  - Zhang, H.
AU  - Chang, A.
AU  - Wang, Q.
AU  - Zhou, Q.
AU  - Liang, Y.
TI  - Research and application of transformer condition evaluation model based on multi-source information
PY  - 2016
T2  - Gaoya Dianqi/High Voltage Apparatus
VL  - 52
IS  - 2
SP  - 19
EP  - 27
DO  - 10.13296/j.1001-1609.hva.2016.02.004
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-84962756189&doi=10.13296%2fj.1001-1609.hva.2016.02.004&partnerID=40&md5=60e18432da07306f3f29fce6d1834139
AD  - M & T Center, EHV Power Transmission Company, China Southern Power Grid, Guangzhou, 510663, China
AD  - State Key Laboratory of Power Transmission Equipment & System Security and New Technology, Chongqing University, Chongqing, 400044, China
AB  - In order to assess the substation equipment operation security condition effectively and adapt to the trends of high capacity, high voltage, structure diversification, seal and condition-based maintenance. Based on group difference method of interval matter-element extension principle, cloud model and grey model, two level comprehensive evaluation model transformer based on multi-source information is established to determine the transformer trend prediction of single factor index evaluation and the overall state evaluation of specific solutions. In the two-stage, the top oil temperature, winding hot spot temperature and load capacity calculation are utilized to evaluate comprehensive relative deterioration degree and get the natural mode and accelerate the degradation model of comprehensive evaluation score. In the comprehensive evaluation, statistical models are used to get the bad working condition and the reliability of running state to supplement, load capacity and fault prediction model is established for the first time, to modify the transformer running state. The model overcomes the defects and deficiencies of the traditional state evaluation method, improves the accuracy of the state assessment, and has good guidance for other substation equipment's condition evaluation processes. The analysis results coincide with the actual situation of the transformer. © 2016, Xi'an High Voltage Apparatus Research Institute. All right reserved.
KW  - Condition evaluation
KW  - Fuzzy matter-element
KW  - Interval extension theory
KW  - Multi-source information
PB  - Xi'an High Voltage Apparatus Research Institute
SN  - 10011609 (ISSN)
LA  - Chinese
J2  - Gaoya Dianqi
M3  - Article
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 11; CODEN: GADIE
ER  -

TY  - JOUR
AU  - Sedaghati, M.
AU  - Dashti, R.
TI  - A new model for assessment and optimization of number of spare transformers and their locations in distribution systems
PY  - 2015
T2  - Iranian Journal of Electrical and Electronic Engineering
VL  - 11
IS  - 4
SP  - 319
EP  - 327
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-84952922588&partnerID=40&md5=d6fa74c351a09c317318837051c202b4
AD  - School of Electrical Engineering, Iran University of Science and Technology (IUST), Tehran, Iran
AB  - In this paper, a new model has been presented to determine the number of spare transformers and their locations for distribution stations. The number of spare transformers must be so that they need minimum investment. Furthermore, they must be sufficient for replacing with transformers that have been damaged. For this reason, in this paper a new purpose function has been presented to maximize profit in distribution company’s budgeting and planning. For determining the number of spares that must be available in a stock room, this paper considers the number of spares and transformer’s fault at the same time. The number of spare transformers is determined so that at least one spare transformer will be available for replacing with the failed transformers. This paper considers time required for purchasing or repairing a failed transformer to determine the number of required spare transformers. Furthermore, whatever the number of spare equipment are increased, cost of maintenance will be increased, so an economic comparison must be done between reduced costs from reducing of outage time and increased costs from spare transformers existence. © 2015, Iran University of Science and Technology. All rights reserved.
KW  - Maintenance
KW  - Mobile transformer
KW  - Replacement
KW  - Spare transformer
PB  - Iran University of Science and Technology
SN  - 17352827 (ISSN)
LA  - English
J2  - Iran. J. Electr. Electron. Eng.
M3  - Article
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 1; Correspondence Address: R. Dashti; School of Electrical Engineering, Iran University of Science and Technology (IUST), Tehran, Iran; email: rezadashti83@yahoo.com
ER  -

TY  - CONF
AU  - Gustavsen, B.
AU  - Portillo, A.
AU  - Ronchi, R.
AU  - Mjelve, A.
TI  - Measurements for validation of manufacturer's white-box transformer models
PY  - 2017
T2  - Procedia Engineering
VL  - 202
SP  - 240
EP  - 250
DO  - 10.1016/j.proeng.2017.09.711
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85036634852&doi=10.1016%2fj.proeng.2017.09.711&partnerID=40&md5=b8f53b3ca786113b6773903a9a4ff1e0
AD  - SINTEF Energy Research, Trondheim, NO-7465, Norway
AD  - Consultant in Transformers, Brenda 5920, Montevideo, 11400, Uruguay
AD  - WEG Transformers Mexico, km 3.5 Carretera Jorobas Tula, Huehuetoca, Mexico
AD  - Hafslund Nett, Olso, N-0247, Norway
AB  - The transformer manufacturers make use of electromagnetic transient calculations by detailed white-box models to ensure that the transformer will withstand the lightning impulse test during the factory acceptance test. In principle, such models could be used in general electromagnetic transient simulation of overvoltages in the system. One of the objectives of CIGRE JWG A2/C4.52 is to assess the accuracy of the manufacturer's white-box models in the context of general transient overvoltages that can occur in the system. As part of this activity, extensive measurements have been performed on two three-winding transformers: one three-phase unit and one single-phase unit. The measurements involved voltage transfer between external terminals and from external terminals to three points in the regulating winding. The measurements were performed with alternative points of voltage excitation, grounding conditions and alternative tap settings, giving 64 cases for each transformer. Some admittance measurements were also performed. This paper gives an overview of the measurements that were performed, the measurement procedure, and some initial results. The voltage transfer measurements were mostly performed in the frequency domain and transferred to the time domain via rational function approximation and recursive convolutions. That way, voltage transfer functions have been generated for well-defined excitations, e.g. the standard 1.2/50 μs voltage wave. In addition, initial results for black-box modeling of the three-phase unit is shown. The measurements are currently being used within CIGRE JWG A2/C4.52 for benchmarking of white-box models. © 2017 The Authors. Published by Elsevier Ltd.
KW  - black-box
KW  - electromagnetic transients
KW  - grey-box
KW  - measurement
KW  - model
KW  - overvoltages
KW  - Transformer
KW  - white-box
KW  - Acceptance tests
KW  - Asset management
KW  - Electric grounding
KW  - Frequency domain analysis
KW  - Manufacture
KW  - Measurements
KW  - Models
KW  - Rational functions
KW  - Transients
KW  - Voltage distribution measurement
KW  - Winding
KW  - Black boxes
KW  - Electro-magnetic transient
KW  - Grey-box
KW  - Over-voltages
KW  - Transformer
KW  - White box
KW  - Electric transformer testing
A2  - Trkulja B.
PB  - Elsevier Ltd
SN  - 18777058 (ISSN)
LA  - English
J2  - Procedia Eng.
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 10; Correspondence Address: B. Gustavsen; SINTEF Energy Research, Trondheim, NO-7465, Norway; email: bjorn.gustavsen@sintef.no; Conference name: 4th International Colloquium Transformer Research and Asset Management, 2017; Conference date: 10 May 2017 through 12 May 2017; Conference code: 137828
ER  -

TY  - JOUR
AU  - Cheng, L.
AU  - Zhou, B.
AU  - Cai, D.
AU  - Chen, W.
AU  - Wang, L.
AU  - Yu, T.
TI  - Lifetime assessment and optimized maintenance system of transformers based on the HST model
PY  - 2015
T2  - Lecture Notes in Electrical Engineering
VL  - 334
SP  - 417
EP  - 430
DO  - 10.1007/978-3-319-13707-0_46
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-84938689887&doi=10.1007%2f978-3-319-13707-0_46&partnerID=40&md5=e9195908e813d9bbdda401023334b523
AD  - Electric Power College, South China University of Technology, Guangzhou, 510640, China
AD  - JiangMen Power Bureau, Jiangmen, 529030 , China
AB  - Currently, the maintenance mode of the power transformers is regular maintenance, which has been widely used. It is key to correctly evaluate the reliability level of the transformer in operation condition because it is directly related to the success of maintenance; on this basis, the lifetime evaluation and optimized maintenance model based on hot spot temperature (HST) in terms of the power transformer is developed in this chapter. In this model, the reaction speed theory of Arrhenius and Weibull distribution is considered as the fundamental theories, which are used to describe the aging process of the transformer and get the transformer failure rate λ; and then the equations with exponential form are adopted to compute HST, namely, to calculate the top oil temperature relative to the environmental temperature ∆ΘTO () the increment of top oil temperature ΘAe () and the hysteretic temperature ΘAe () so as to get HST (equals to the sum of the aforementioned three variables). Meanwhile, based on the model, the software analysis system based on Java language and Mysql database has also been developed, in which the transformer maintenance process was optimized and the statistical analysis was made for the hot spot area. Finally, the diagnosis results were obtained correspondingly, indicating that the designed model and system can effectively reduce the maintenance frequency, improve the utilization coefficient of the transformer, and thus improve the equipment’s reliability. © Springer International Publishing Switzerland 2015.
KW  - Computer software
KW  - Java programming language
KW  - Maintenance
KW  - Oil filled transformers
KW  - Weibull distribution
KW  - Environmental temperature
KW  - Hysteretic temperature
KW  - Lifetime assessment
KW  - Lifetime evaluation
KW  - Maintenance process
KW  - Maintenance systems
KW  - Operation conditions
KW  - Transformer failure
KW  - Power transformers
PB  - Springer Verlag
SN  - 18761100 (ISSN)
LA  - English
J2  - Lect. Notes Electr. Eng.
M3  - Article
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 2
ER  -

TY  - JOUR
AU  - Guo, X.
AU  - Cheng, L.
AU  - Wang, G.
AU  - Xu, A.
AU  - Jian, G.
AU  - Yu, T.
AU  - Wei, W.
TI  - Research of power transformer reliability evaluation model based on dynamic correction technique
PY  - 2016
T2  - Dianli Zidonghua Shebei/Electric Power Automation Equipment
VL  - 36
IS  - 6
SP  - 148
EP  - 155
DO  - 10.16081/j.issn.1006-6047.2016.06.022
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-84975705662&doi=10.16081%2fj.issn.1006-6047.2016.06.022&partnerID=40&md5=87add247a7b9aad1adf06a67018a1020
AD  - China Southern Power Grid Electric Power Research Institute, Guangzhou, 510080, China
AD  - College of Electric Power, South China University of Technology, Guangzhou, 510640, China
AB  - With the oil-paper insulation system of transformer as the evaluation target and the HST (Hot Spot Temperature) as the core point, a HST-based transformer aging fault model is built according to the Weibull distribution and Arrhenius reaction law, which is used to describe the transformer aging process and calculate the winding HST for obtaining the failure rate of transformer oil-paper insulation system. Based on the data of DGA(Dissolved Gas Analysis) in power transformer oil, the built model is corrected according to the grey theory to ensure the evaluation better tracking the actual reliability level of transformer. As an example, the actual data of Jiangmen power-supply bureau are analyzed to verify the validity of the built model and the results show the built model can well track the operational status of transformer. © 2016, Electric Power Automation Equipment Press. All right reserved.
KW  - Arrhenius reaction
KW  - Dissolved gas analysis
KW  - Grey theory
KW  - Hot spot temperature
KW  - law
KW  - Power transformers
KW  - Reliability
KW  - Weibull distribution
KW  - Paper
KW  - Power transformers
KW  - Reliability
KW  - Reliability analysis
KW  - Reliability theory
KW  - Weibull distribution
KW  - Arrhenius reaction
KW  - Dissolved gas analysis
KW  - Grey theory
KW  - Hotspot temperature
KW  - Oil-paper insulation system
KW  - Power supply bureaux
KW  - Reliability Evaluation
KW  - Reliability level
KW  - Oil filled transformers
PB  - Electric Power Automation Equipment Press
SN  - 10066047 (ISSN)
LA  - Chinese
J2  - Dianli Zidonghua Shebei Electr. Power Autom. Equip.
M3  - Article
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 0; CODEN: DZSHF
ER  -

TY  - JOUR
AU  - Speier, W.
AU  - Arnold, C.
AU  - Pouratian, N.
TI  - Evaluating True BCI Communication Rate through Mutual Information and Language Models
PY  - 2013
T2  - PLoS ONE
VL  - 8
IS  - 10
C7  - e78432
DO  - 10.1371/journal.pone.0078432
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-84885994682&doi=10.1371%2fjournal.pone.0078432&partnerID=40&md5=90f177c2af2318ce08098eaed377e1e5
AD  - Department of Bioengineering, University of California Los Angeles, Los Angeles, CA, United States
AD  - Department of Neurosurgery, University of California Los Angeles, Los Angeles, CA, United States
AD  - Interdepartmental Program in Neuroscience, University of California Los Angeles, Los Angeles, CA, United States
AD  - Brain Research Institute, University of California Los Angeles, Los Angeles, CA, United States
AD  - Medical Imaging Informatics Group, University of California Los Angeles, Los Angeles, CA, United States
AB  - Brain-computer interface (BCI) systems are a promising means for restoring communication to patients suffering from "locked-in" syndrome. Research to improve system performance primarily focuses on means to overcome the low signal to noise ratio of electroencephalogric (EEG) recordings. However, the literature and methods are difficult to compare due to the array of evaluation metrics and assumptions underlying them, including that: 1) all characters are equally probable, 2) character selection is memoryless, and 3) errors occur completely at random. The standardization of evaluation metrics that more accurately reflect the amount of information contained in BCI language output is critical to make progress. We present a mutual information-based metric that incorporates prior information and a model of systematic errors. The parameters of a system used in one study were re-optimized, showing that the metric used in optimization significantly affects the parameter values chosen and the resulting system performance. The results of 11 BCI communication studies were then evaluated using different metrics, including those previously used in BCI literature and the newly advocated metric. Six studies' results varied based on the metric used for evaluation and the proposed metric produced results that differed from those originally published in two of the studies. Standardizing metrics to accurately reflect the rate of information transmission is critical to properly evaluate and compare BCI communication systems and advance the field in an unbiased manner. © 2013 Speier et al.
KW  - Brain-Computer Interfaces
KW  - Humans
KW  - Models, Theoretical
KW  - Programming Languages
KW  - Quadriplegia
KW  - article
KW  - brain computer interface
KW  - characters per minute
KW  - information
KW  - information transfer rate
KW  - interpersonal communication
KW  - language
KW  - mathematical analysis
KW  - output characters per minute
KW  - performance
KW  - practical bit rate
KW  - process optimization
KW  - reliability
KW  - systematic error
KW  - word symbol rate
KW  - computer language
KW  - human
KW  - quadriplegia
KW  - theoretical model
SN  - 19326203 (ISSN)
C2  - 24167623
LA  - English
J2  - PLoS ONE
M3  - Article
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 28; Correspondence Address: N. Pouratian; Department of Bioengineering, University of California Los Angeles, Los Angeles, CA, United States; email: npouratian@mednet.ucla.edu; CODEN: POLNC
ER  -

TY  - CONF
AU  - Corea-Araujo, J.A.
AU  - Gonzalez-Molina, F.
AU  - Martinez, J.A.
AU  - Castro-Aranda, F.
AU  - Manrique-Lemos, C.A.
AU  - Barrado-Rodrigo, J.A.
AU  - Guasch-Pesquer, L.
TI  - Three-phase transformer model validation for ferroresonance analysis
PY  - 2014
T2  - IEEE Power and Energy Society General Meeting
VL  - 2014-October
IS  - October
C7  - 6939560
DO  - 10.1109/PESGM.2014.6939560
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-84930989382&doi=10.1109%2fPESGM.2014.6939560&partnerID=40&md5=14728eaa9dc4595f045ea6761294a712
AD  - Departament d'Enginyeria Electrònica, Elèctrica i Automàtica, Universitat Rovira i Virgili, Av. Països Catalans 26, Tarragona, 43007, Spain
AD  - Departament d'Enginyeria Elèctrica, Universitat Politècnica de Catalunya, Diagonal 647, Barcelona, 08028, Spain
AD  - Grupo de Investigación en Alta Tensión (GRALTA), Escuela de Ingeniería Eléctrica y Electrónica, Universidad Del Valle, Cali, Colombia
AB  - Ferroresonance is a complex nonlinear phenomenon that may be initiated in many different ways and involves the association of capacitances and non-linear magnetizing inductances. Although ferroresonance has been present in power systems for more than a century, its behavior and characterization still remain widely unknown This work illustrates a proper guideline for transformer modeling starting from laboratory test measurements. The paper also proposes a procedure for performing a ferroresonance essay under a controlled environment. © 2014 IEEE.
KW  - EMTP
KW  - Ferroresonance
KW  - Non-linear dynamics
KW  - Transformer modeling
KW  - Electric transformer testing
KW  - Controlled environment
KW  - EMTP
KW  - Ferroresonance
KW  - Magnetizing inductance
KW  - Non-linear dynamics
KW  - Non-linear phenomena
KW  - Three-phase transformers
KW  - Transformer modeling
KW  - Magnetic resonance
PB  - IEEE Computer Society
SN  - 19449925 (ISSN); 978-147996415-4 (ISBN)
LA  - English
J2  - IEEE Power Energy Soc. Gen. Meet.
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 1; Conference name: 2014 IEEE Power and Energy Society General Meeting; Conference date: 27 July 2014 through 31 July 2014; Conference code: 108910
ER  -

TY  - JOUR
AU  - Van Den Houdt, F.
TI  - Medicines Evaluation Board Chairman Bert Leufkens on new developments and drugs: "Innovation is good, but should everything that can be done also be done?"
ST  - 'Innovatie is goed, maar moet alles wat kan ook kunnen?'
PY  - 2016
T2  - Pharmaceutisch Weekblad
VL  - 151
IS  - 9
SP  - 10
EP  - 13
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-84969560071&partnerID=40&md5=cc6815291a7f0c830b09fff19805af30
KW  - administrative personnel
KW  - drug research
KW  - human
KW  - Note
KW  - pharmaceutics
PB  - Kon. Ned. Mij. ter Bevordering der Pharmacie (KNMP)
SN  - 00316911 (ISSN)
LA  - English
J2  - Pharm. Weekbl.
M3  - Note
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 0; CODEN: PHWEA
ER  -

TY  - CONF
AU  - Wang, L.
AU  - Wang, Y.
AU  - Tang, J.
AU  - Guo, C.
AU  - Luo, X.
AU  - Cao, M.
TI  - An economic evaluation model of transformers considering outage consequence
PY  - 2014
T2  - IEEE Power and Energy Society General Meeting
VL  - 2014-October
IS  - October
C7  - 6938862
DO  - 10.1109/PESGM.2014.6938862
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-84930999575&doi=10.1109%2fPESGM.2014.6938862&partnerID=40&md5=aa10216c6454579893d7ceb00b712821
AD  - College of Electrical Engineering, Zhejiang University, Hangzhou, 310027, China
AD  - Yunnan Power Grid Corporation, Kunming, 673200, China
AB  - A model is established in order to evaluate the economic operation of transformers. We take the outage consequence of transformer into consideration, based on which we obtain the economic operation of a transformer in a specific power system. The outage consequence is related with the structure of the power system, the flow limits in branches and the different outage costs of customers of different nodes. The outage risk is introduced to describe the product of outage probability and outage consequence. In addition, the aging cost and the power loss of a transformer are also considered in this economic evaluation model. At last, the example of 9 nodes system shows that the proposed model can response the varying level of load in a power system. Thus it can reflect the operation condition of transformer in a specific power system more realistically. © 2014 IEEE.
KW  - economic operation
KW  - optimal power flow
KW  - outage risk
KW  - transformer
KW  - Economic analysis
KW  - Electric load flow
KW  - Economic evaluations
KW  - Economic operation of transformers
KW  - Economic operations
KW  - Operation conditions
KW  - Optimal power flows
KW  - Outage probability
KW  - Outage risk
KW  - transformer
KW  - Outages
PB  - IEEE Computer Society
SN  - 19449925 (ISSN); 978-147996415-4 (ISBN)
LA  - English
J2  - IEEE Power Energy Soc. Gen. Meet.
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 0; Correspondence Address: C. Guo; College of Electrical Engineering, Zhejiang University, Hangzhou, 310027, China; email: guochuangxin@zju.edu.cn; Conference name: 2014 IEEE Power and Energy Society General Meeting; Conference date: 27 July 2014 through 31 July 2014; Conference code: 108910
ER  -

TY  - JOUR
AU  - Kawamura, Y.
AU  - Hayashi, H.
AU  - Kurata, Y.
AU  - Hiratsuka, K.
AU  - Masumura, K.
AU  - Nohmi, T.
TI  - Evaluation of the genotoxicity of tamoxifen in the liver and kidney of F344 gpt delta transgenic rat in 3-week and 13-week repeated dose studies
PY  - 2013
T2  - Toxicology
VL  - 312
IS  - 1
SP  - 56
EP  - 62
DO  - 10.1016/j.tox.2013.07.014
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-84884188130&doi=10.1016%2fj.tox.2013.07.014&partnerID=40&md5=5b61999356bd448b6258025a9ff24f5c
AD  - Toxicology Laboratory, Pharmaceutical Research Center, Meiji Seika Pharma Co., Ltd., Kohoku-ku, Yokohama 222-8567, 760 Morooka-cho, Japan
AD  - Research Planning and Management, R and D Planning and Management Department, Meiji Seika Pharma Co., Ltd., Chuo-ku, Tokyo 104-8002, 2-4-16, Kyobashi, Japan
AD  - Division of Genetics and Mutagenesis, National Institute of Health Sciences, Setagaya-ku, Tokyo 158-8501, 1-18-1, Kamiyoga, Japan
AB  - Transgenic rat gene mutation assays can be used to assess genotoxicity of chemicals in target organs for carcinogenicity. Mutations in transgenes are genetically neutral and accumulate during a treatment period; thus, the assays are suitable for assessment of the genotoxicity risk of chemicals using a repeated-dose treatment paradigm. However, few such studies have been conducted. To examine the utility of the transgenic rat assays in repeated-dose studies, we treated female F344 gpt delta rats with tamoxifen (TAM) at 20 and 40mg/kg, or toremifene (TOR) at 40mg/kg by gavage daily for 3 weeks. We also fed gpt delta rats with TAM at either 250ppm (15.4-17.6mg/kg) or 500ppm (30.0-32.9mg/kg) for 13 weeks. TAM is carcinogenic in the rat liver and TOR is not carcinogenic. TAM administration significantly increased gpt (point mutations) and Spi- (deletions) mutant frequencies (MFs) in the liver, the target organ of carcinogenesis; MFs were higher after treatment for 13 weeks than after treatment for 3 weeks. The MFs in the kidney did not increase in any of the TAM treatment groups. TOR had no effect on MFs (gpt and Spi-) in either the liver or the kidney. We conclude that the gpt delta rat assay in the repeated-dose treatment paradigm is sensitive enough to detect gene mutations induced by TAM in the target organ for carcinogenesis. Furthermore, the assay can be integrated into a 13-week dose-finding study for a 2-year cancer bioassay. © 2013 Elsevier Ireland Ltd.
KW  - F344 gpt delta transgenic rat
KW  - Gpt assay
KW  - Repeated-dose studies
KW  - Spi<sup>-</sup> assay
KW  - Tamoxifen
KW  - Toremifene
KW  - Animals
KW  - Dose-Response Relationship, Drug
KW  - Escherichia coli Proteins
KW  - Kidney
KW  - Liver
KW  - Mutagenicity Tests
KW  - Pentosyltransferases
KW  - Rats
KW  - Rats, Inbred F344
KW  - Rats, Transgenic
KW  - Tamoxifen
KW  - Toremifene
KW  - F344 gpt delta transgenic rat
KW  - gpt assay
KW  - Repeated-dose studies
KW  - Spi(-) assay
KW  - Tamoxifen
KW  - Toremifene
KW  - alanine aminotransferase
KW  - albumin
KW  - aspartate aminotransferase
KW  - hemoglobin
KW  - tamoxifen
KW  - toremifene
KW  - triacylglycerol
KW  - alanine aminotransferase blood level
KW  - animal experiment
KW  - animal model
KW  - animal tissue
KW  - article
KW  - aspartate aminotransferase blood level
KW  - carcinogenesis
KW  - cholesterol blood level
KW  - controlled study
KW  - DNA sequence
KW  - dose calculation
KW  - endometrium atrophy
KW  - erythrocyte count
KW  - feeding
KW  - female
KW  - food intake
KW  - gene mutation
KW  - genotoxicity
KW  - hematocrit
KW  - hemoglobin blood level
KW  - histopathology
KW  - liver toxicity
KW  - nephrotoxicity
KW  - nonhuman
KW  - priority journal
KW  - rat
KW  - repeated drug dose
KW  - target organ
KW  - uterus weight
KW  - weight gain
SN  - 18793185 (ISSN)
C2  - 23907062
LA  - English
J2  - Toxicology
M3  - Article
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 7; Correspondence Address: Y. Kawamura; Toxicology Laboratory, Pharmaceutical Research Center, Meiji Seika Pharma Co., Ltd., Kohoku-ku, Yokohama 222-8567, 760 Morooka-cho, Japan; email: yuuji.kawamura@meiji.com; CODEN: TXCYA
ER  -

TY  - JOUR
AU  - Huang, F.-L.
AU  - Yu, M.-S.
AU  - Hwang, C.-Y.
TI  - Evaluations on several smoothing methods for Chinese language models
PY  - 2013
T2  - Information Technology Journal
VL  - 12
IS  - 16
SP  - 3685
EP  - 3691
DO  - 10.3923/itj.2013.3685.3691
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-84901722882&doi=10.3923%2fitj.2013.3685.3691&partnerID=40&md5=ea11dbba7d29b2146d6516813843563b
AD  - Department of Computer Science and Information Engineering, National United University, MaioLi, 360, China
AD  - Department of Computer Science and Engineering, National Chung-Hsing University, Taichunge-402, China
AB  - In this study, several smoothing methods for language models on Chinese corpus with various sizes are evaluated and analyzed. Basically, there are two phases for smoothing procedures (1) Discounting and (2) Redistributing. Ten models are generated on various size of corpus from 30-300 M Chinese words. We evaluated several smoothing methods for statistical language models. In our experiments, four smoothing methods, Winter-Bell C (WB-C) and our proposed YH-A and YH-B smoothing method, are evaluated for inside testing and outside testing. Based on empirical observations, our YH-B smoothing is superior to WB-C for the TrM models with size between 30 and 90 M. © 2013 Asian Network for Scientific Information.
KW  - Cross entropy
KW  - Evaluation
KW  - Language model
KW  - Perplexity
KW  - Smoothing method
KW  - Natural language processing systems
KW  - Cross entropy
KW  - Evaluation
KW  - Language model
KW  - Perplexity
KW  - Smoothing methods
KW  - Computational linguistics
PB  - Asian Network for Scientific Information
SN  - 18125638 (ISSN)
LA  - English
J2  - Inf. Technol. J.
M3  - Article
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 0
ER  -

TY  - JOUR
AU  - Shah, K.R.
AU  - Ragavan, K.
TI  - Assessing mechanical deformations in two-winding transformer unit using reduced-order circuit model
PY  - 2016
T2  - International Journal of Electrical Power and Energy Systems
VL  - 79
SP  - 235
EP  - 244
DO  - 10.1016/j.ijepes.2015.12.035
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-84955464455&doi=10.1016%2fj.ijepes.2015.12.035&partnerID=40&md5=ad6e1901c7a92a770bddbcc0df00a1c3
AD  - Indian Institute of Technology Gandhinagar, Ahmedabad, India
AB  - Certain level of mechanical deformations in winding does not hamper the normal performance of power transformer. However, such incipient deformations if unattended could result in permanent failure of transformer. To this end, an approach is proposed to assess the severity of mechanical deformations in transformer winding. These deformations get reflected as changes in its high frequency behaviour. Hence, characterising the high frequency behaviour is essential. This requires building physically realisable ladder circuit corresponding to each winding. Thus, n-winding transformer is represented by n electrically and magnetically coupled ladder networks. In such scenario, the objective of fault diagnostics becomes very challenging. In this effort, realising the multi-winding unit by reduced-order ladder circuit model is explored. This approach essentially involves energising one winding at a time. Then, reduced-order ladder circuit of considered unit is synthesised from its measured driving-point impedance data. It is shown how these circuit models could be used for identifying mechanical deformations. To demonstrate capability of the method, two-winding model transformer is considered and deformations are introduced in its outer winding. Then, reduced-order circuit models are synthesised corresponding to healthy and faulty state of model transformer. The location of fault is identified by the changed parameter in the circuit. Further, the amount of change reveals the severity of introduced deformation. In all the cases, synthesised reduced-order circuit model agrees with that of model transformer with regard to driving-point impedance plot and results are found satisfactory. © 2016 Elsevier Ltd.
KW  - Circuit synthesis
KW  - Diagnostics
KW  - Frequency response analysis
KW  - Mechanical deformations
KW  - Terminal measurement
KW  - Transformer
KW  - Circuit simulation
KW  - Circuit theory
KW  - Deformation
KW  - Electric impedance
KW  - Frequency response
KW  - Ladders
KW  - Plasma diagnostics
KW  - Power transformers
KW  - Reconfigurable hardware
KW  - Transformer windings
KW  - Winding
KW  - Circuit synthesis
KW  - Frequency response analysis
KW  - Mechanical deformation
KW  - Terminal measurements
KW  - Transformer
KW  - Electric windings
PB  - Elsevier Ltd
SN  - 01420615 (ISSN)
LA  - English
J2  - Int J Electr Power Energy Syst
M3  - Article
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 9; Correspondence Address: K.R. Shah; Indian Institute of Technology Gandhinagar, Ahmedabad, India; email: krupa@iitgn.ac.in; CODEN: IEPSD
ER  -

TY  - JOUR
AU  - Liao, R.
AU  - Bian, J.
AU  - Yang, L.
AU  - Grzybowski, S.
TI  - Cloud model-based failure mode and effects analysis for prioritization of failures of power transformer in risk assessment
PY  - 2013
T2  - International Transactions on Electrical Energy Systems
VL  - 23
IS  - 7
SP  - 1172
EP  - 1190
DO  - 10.1002/etep.1647
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-84900815189&doi=10.1002%2fetep.1647&partnerID=40&md5=4eeac9da60a880743c1e9379c1e77f92
AD  - State Key Laboratory of Power Transmission Equipment and System Security and New Technology, Chongqing University, Chongqing, China
AD  - High Voltage Laboratory, Electrical and Computer Engineering Department, Mississippi State University, Mississippi State, MS, United States
AB  - The maintenance strategy of power transformer, which is determined by the operational condition, is very important to ensure safety for power system. But there exists prevalently the problem of lacking theoretical basis in preventive maintenance strategy to power transformer at present. Failure mode and effects analysis (FMEA) is a methodology for the analysis of potential failure modes within a system and has been extensively utilized for examining potential failures of power transformer. The critical issue of FMEA is the determination of risk priorities of potential failure modes. In order to provide the basis for risk assessment and preventive maintenance decision making, this work proposes the FMEA based on cloud model for prioritizing failure modes, which can combine randomicity with ambiguity and realize the transform between qualitative evaluation and quantitative numerical value, intending to overcome limitations of traditional FMEA. Two numerical examples are utilized to illustrate the potential applications of the proposed FMEA and the detailed computational process of the risk priority number based on cloud model. © 2012 John Wiley & Sons, Ltd.
KW  - cloud model
KW  - FMEA
KW  - preventive maintenance
KW  - risk assessment
KW  - Cloud computing
KW  - Failure modes
KW  - Preventive maintenance
KW  - Risk assessment
KW  - Cloud modeling
KW  - Failure mode and effects analysis
KW  - FMEA
KW  - Maintenance decision making
KW  - Maintenance strategies
KW  - Operational conditions
KW  - Potential failure modes
KW  - Qualitative evaluations
KW  - Power transformers
PB  - John Wiley and Sons Ltd
SN  - 20507038 (ISSN)
LA  - English
J2  - Int. Trans. Elecr. Energy Sys.
M3  - Article
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 20; Correspondence Address: J. Bian; State Key Laboratory of Power Transmission Equipment and System Security and New Technology, Chongqing University, Chongqing, China; email: bjp210@126.com
ER  -

TY  - CONF
AU  - Xia, G.
AU  - Wu, G.
TI  - Quantitative assessment of moisture content in transformer oil-paper insulation based on extended Debye model and PDC
PY  - 2016
T2  - China International Conference on Electricity Distribution, CICED
VL  - 2016-September
C7  - 7576193
DO  - 10.1109/CICED.2016.7576193
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-84990982113&doi=10.1109%2fCICED.2016.7576193&partnerID=40&md5=1c2b1cf9cad4e1a4442e106ec1d0a4db
AD  - College of Electrical Engineering, Southwest Jiaotong University, Chengdu, Sichuan Province, 610031, China
AB  - In order to assess the moisture content of insulating pressboard in oil-immersed transformer, and thus providing reliable guidance for insulation condition and life estimation of oil-immersed transformer, in this paper, we made four groups of oil-paper insulation samples with different moisture content under laboratory conditions and studied the relationship between pressboard and moisture content by using polarization and depolarization current (PDC) technique. The experiment result shows that PDC curve is very sensitive to the change of moisture content, and the change of moisture content mainly affects the tail of depolarization current curve; the extended Debye model parameters can be obtained from depolarization current curve, and as the moisture content increases the number of branches in Debye model increases, the largest time constant becomes large; the peak of time domain spectroscopy turn up at 1000s., the time constant branch which is longer than 1000s presents the pressboard branches of Debye model; the feature quantity Qpaper can show the internal polarization of insulating paper and has a linear fitting relationship with moisture content, so Qpaper can be used to assess the moisture content of insulating pressboard. © 2016 IEEE.
KW  - Debye model
KW  - insulating paper
KW  - moisture content
KW  - oil-paper insulation
KW  - polarization and depolarization current
KW  - Curve fitting
KW  - Depolarization
KW  - Electric utilities
KW  - Insulating materials
KW  - Insulation
KW  - Moisture
KW  - Moisture determination
KW  - Phonons
KW  - Polarization
KW  - Debye models
KW  - Different moisture contents
KW  - Insulating paper
KW  - Oil immersed transformers
KW  - Oil paper insulation
KW  - Polarization and depolarization currents
KW  - Quantitative assessments
KW  - Time domain spectroscopy
KW  - Oil filled transformers
PB  - IEEE Computer Society
SN  - 21617481 (ISSN); 978-146739068-2 (ISBN)
LA  - English
J2  - China Int. Conf. Elect. Distrib., CICED
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 4; Conference name: 2016 China International Conference on Electricity Distribution, CICED 2016; Conference date: 10 August 2016 through 13 August 2016; Conference code: 123946
ER  -

TY  - JOUR
AU  - Lambert, M.
AU  - Martinez-Duro, M.
AU  - Mahseredjian, J.
AU  - De Leon, F.
AU  - Sirois, F.
TI  - Transformer leakage flux models for electromagnetic transients: Critical review and validation of a new model
PY  - 2014
T2  - IEEE Transactions on Power Delivery
VL  - 29
IS  - 5
C7  - 6766808
SP  - 2180
EP  - 2188
DO  - 10.1109/TPWRD.2013.2293978
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-84907517761&doi=10.1109%2fTPWRD.2013.2293978&partnerID=40&md5=be0763643b25df1a24f9ea04bc6c76c8
AD  - Department of Electrical Engineering, École Polytechnique de Montréal, Montréal, H3T1J4, QC, Canada
AD  - Électricité de France R and D, Clamart, 92141, France
AD  - Department of Electrical and Computer Engineering, Polytechnic Institute, New York University, Brooklyn, 11201, NY, United States
AB  - This paper presents experimental validation of the coupled leakage inductance transformer model. It is shown that the coupled approach yields the same results as the indefinite admittance matrix method of BCTRAN. A topologically correct three-phase shell-type transformer model is proposed. The connection points between the leakage and magnetizing inductances are properly identified, which makes the new model superior to BCTRAN and the hybrid models by providing physical consistency. In addition, experimental verification of a method to calculate the short-circuit inductances is presented. New explanations on the division of leakage flux and on the mathematical equivalence between the T-and Π-equivalent models are also given. © 2014 IEEE.
KW  - Leakage inductance
KW  - low-frequency electromagnetic transients
KW  - topological model
KW  - transformer modeling
KW  - Critical review
KW  - Electro-magnetic transient
KW  - Leakage flux
KW  - Leakage inductance
KW  - Topological models
KW  - Transformer modeling
PB  - Institute of Electrical and Electronics Engineers Inc.
SN  - 08858977 (ISSN)
LA  - English
J2  - IEEE Trans Power Delivery
M3  - Article
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 22; CODEN: ITPDE
ER  -

TY  - JOUR
AU  - Høidalen, H.K.
AU  - Lotfi, A.
AU  - Zirka, S.
AU  - Moroz, Y.
AU  - Chiesa, N.
AU  - Mork, B.A.
TI  - Benchmarking of hysteretic elements in topological transformer model
PY  - 2016
T2  - Electric Power Systems Research
VL  - 138
SP  - 33
EP  - 40
DO  - 10.1016/j.epsr.2016.02.030
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-84964320250&doi=10.1016%2fj.epsr.2016.02.030&partnerID=40&md5=6a082d902fa28e72eca1649883ca9ee6
AD  - Norwegian University of Science and Technology, Trondheim, N-7491, Norway
AD  - Dnepropetrovsk National University, Dnepropetrovsk, Ukraine
AD  - Statoil AS, Trondheim, Norway
AD  - Michigan Technological University, Houghton, United States
AB  - Transformer core modeling is of importance for some transient studies like inrush currents, ferroresonance and geomagnetically induced current. This paper compares a transformer model with different magnetization representations to actual measurements. Piecewise nonlinear (Type 98) or hysteretic inductors (Type 96) both in parallel to a constant resistance, Jiles-Atherton hysteretic inductance and a newly developed inverse dynamic hysteresis model (DHM) are tested for open circuit response, residual flux after switching out, and inrush currents when energizing the transformer. The models have all problems of reproducing the magnetization current details and there are substantial differences between the models in residual flux estimation resulting in quite different inrush patterns. The DHM model is the easiest to use as few parameters are required and the model gives fairly well agreement with measurements. © 2016 Elsevier B.V. All rights reserved.
KW  - Hysteresis
KW  - Inrush current
KW  - Residual flux
KW  - Test report
KW  - Transformer
KW  - Electric transformer testing
KW  - Hysteresis
KW  - Inverse problems
KW  - Magnetic resonance
KW  - Magnetization
KW  - Actual measurements
KW  - Geomagnetically induced currents
KW  - In-rush current
KW  - Magnetization currents
KW  - Residual flux
KW  - Test reports
KW  - Transformer
KW  - Transformer modeling
KW  - Topology
PB  - Elsevier Ltd
SN  - 03787796 (ISSN)
LA  - English
J2  - Electr Power Syst Res
M3  - Article
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 3; Correspondence Address: H.K. Høidalen; Norwegian University of Science and Technology, Trondheim, N-7491, Norway; email: hans.hoidalen@elkraft.ntnu.no; CODEN: EPSRD
ER  -

TY  - JOUR
AU  - Jasni, J.
AU  - Azmi, A.
AU  - Azis, N.
AU  - Yahaya, M.S.
AU  - Talib, M.A.
TI  - Assessment of transformer health index using different model
PY  - 2017
T2  - Pertanika Journal of Science and Technology
VL  - 25
IS  - S
SP  - 143
EP  - 150
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029653537&partnerID=40&md5=f00bca798f6bb8c1f1692fa69a8dfddb
AD  - Centre for Electromagnetic and Lightning Protection Research (CELP), Department of Electrical and Electronic Engineering, Faculty of Engineering, UPM, Serdang, 43400, Selangor, Malaysia
AD  - TNB Research Sdn. Bhd., Kawasan Institusi Penyelidikan, Kajang, 43000, Selangor, Malaysia
AB  - Transformer failures lead to interruption of power supply. Therefore, asset management is important to monitor the efficient functioning of transformers. An important approach in asset management is condition assessment whereby the health status of the transformer is assessed via a health index. There are many methods in determining the final value of a health index. This paper examines how different assessment methods can be used in order to come up with the final health index and output of final health index. The output trend shapes are almost the same for Assessment Model A, B and C except for Assessment Model D. There is no strong correlation between the health index and age of the transformer. Generally, the value of health index of the transformer is reflected by its operation and loading history. This paper hence examines the assessment steps and results that will guide the development of a new approach to determine health index value. © 2017 Universiti Putra Malaysia Press.
KW  - Asset management
KW  - Condition assessment
KW  - Transformer
KW  - Transformer health index
PB  - Universiti Putra Malaysia Press
SN  - 01287680 (ISSN)
LA  - English
J2  - Pertanika J. Sci. Technol.
M3  - Article
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 5; Correspondence Address: A. Azmi; Centre for Electromagnetic and Lightning Protection Research (CELP), Department of Electrical and Electronic Engineering, Faculty of Engineering, UPM, Serdang, 43400, Malaysia; email: akma_lina@yahoo.com
ER  -

TY  - JOUR
AU  - Sun, Y.
AU  - Yu, L.
AU  - Li, K.
AU  - Liang, Y.
AU  - Xiao, W.
TI  - Replacement Priority Assessment Model of Distribution Transformer
PY  - 2017
T2  - Gaodianya Jishu/High Voltage Engineering
VL  - 43
IS  - 7
SP  - 2370
EP  - 2377
DO  - 10.13336/j.1003-6520.hve.201700328041
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029784786&doi=10.13336%2fj.1003-6520.hve.201700328041&partnerID=40&md5=bf72f307b634ba1f3858ed35c541f33f
AD  - School of Electrical Engineering, Shandong University, Jinan, 250061, China
AD  - Department of Electrical Engineering of College of Information and Control Engineering, China University of Petroleum, Qingdao, 266580, China
AD  - State Grid Shandong Electric Power Maintenance Company, Jinan, 250000, China
AB  - To solve the problem of replacement priority assessment model of distribution transformers, we propose an assessment model for multi-level distribution transformer replacement priority, including the establishment of the evaluation system and presentation of corresponding calculation method. This model is based on fuzzy analytical hierarchy process and grey fuzzy comprehensive evaluation, and it covers different kinds of assessment factors. Firstly, a fuzzy analytical hierarchy process is adopted to establish the multi-level analysis model and determine the weight of different kinds of factors. The grey of the weight is calculated by considering the expertise, which is used to describe the abundance of information, then the weight matrix is established. Secondly, the deterioration function is used to process the different magnitude data and the membership function is used to describe the relationship between the data and different levels. Grey is adopted to describe the abundance of the data, then a grey fuzzy matrix is established. Finally, the weight matrix and the grey fuzzy matrix are synthesized to get the comprehensive assessment results. The calculation shows that the model takes multi-factors into consideration and improves fuzziness and grey of data. It can evaluate the transformer replacement order reasonably, and provides a kind of reference for the economic operation of distribution transformers. © 2017, High Voltage Engineering Editorial Department of CEPRI. All right reserved.
KW  - Distribution transformer
KW  - Fuzzy analytical hierarchy process
KW  - Grey fuzzy comprehensive evaluation
KW  - Membership
KW  - Replacement priority
KW  - Electric transformers
KW  - Function evaluation
KW  - Fuzzy set theory
KW  - Membership functions
KW  - Distribution transformer
KW  - Fuzzy analytical hierarchy process
KW  - Grey fuzzy comprehensive evaluation
KW  - Membership
KW  - Replacement priority
KW  - Matrix algebra
PB  - Science Press
SN  - 10036520 (ISSN)
LA  - Chinese
J2  - Gaodianya Jishu
M3  - Article
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 4; Correspondence Address: K. Li; School of Electrical Engineering, Shandong University, Jinan, 250061, China; email: lkjun@sdu.edu.cn; CODEN: GAJIE
ER  -

TY  - CONF
AU  - Ma, Z.
AU  - Dang, S.
AU  - Gholamzadeh, A.
AU  - Ridge, J.
TI  - Operational state diagnosis algorithm of the oil-immersed transformer based on fuzzy synthetic evaluation model
PY  - 2014
T2  - Proceedings of International Conference on Harmonics and Quality of Power, ICHQP
C7  - 6842875
SP  - 848
EP  - 851
DO  - 10.1109/ICHQP.2014.6842875
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-84904288697&doi=10.1109%2fICHQP.2014.6842875&partnerID=40&md5=f77badd3cec3d4825823ea4ab63aac45
AD  - School of Electrical Engineering, Zhengzhou University, Zhengzhou, China
AD  - University of Manchester, Manchester, United Kingdom
AB  - The transformer is a pivotal device in substations, and its operational state is highly correlated to the security and reliability of a power system. Especially with the development of smart grid, the faults in transformers would have a severe negative impact, not only on the local power network, but also on the holistic power system and power grid. In this paper, we predominantly investigate the operating state diagnosis model of the oil-immersed transformer. Specifically, the common faults and their corresponding characteristics have been concluded. By the characterization of each fault, we can use the fuzzy synthetic evaluation model to diagnose whether a fault occurs and estimate its severity level as well as damage. © 2014 IEEE.
KW  - Fuzzy Synthetic Evaluation Model
KW  - Oil-immersed Transformer
KW  - State Diagnosis
KW  - Algorithms
KW  - Electric power transmission networks
KW  - Fuzzy set theory
KW  - Fuzzy synthetic evaluation models
KW  - Highly-correlated
KW  - Oil immersed transformers
KW  - Operating state
KW  - Operational state
KW  - Power networks
KW  - Security and reliabilities
KW  - State diagnosis
KW  - Oil filled transformers
PB  - IEEE Computer Society
SN  - 15406008 (ISSN); 978-146736487-4 (ISBN)
LA  - English
J2  - Proc. Int. Conf. Harmonics  Qual. Power, ICHQP
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 11; Conference name: 16th International Conference on Harmonics and Quality of Power, ICHQP 2014; Conference date: 25 May 2014 through 28 May 2014; Conference code: 106304
ER  -

TY  - CONF
AU  - Zhang, J.
AU  - Wu, Z.
TI  - Railway power transformer reliability evaluation model based on operating conditions
PY  - 2014
T2  - Lecture Notes in Electrical Engineering
VL  - 287 LNEE
IS  - VOL. 1
SP  - 181
EP  - 192
DO  - 10.1007/978-3-642-53778-3_17
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-84906683356&doi=10.1007%2f978-3-642-53778-3_17&partnerID=40&md5=66c0b99cffa38a10184a03108f7e6dde
AD  - School of Electrical Engineering, Beijing Jiaotong University, Beijing, China
AB  - Evaluating the railway power supply system reliability needs accurate failure rate models of equipment. However, the existing failure rate model can't reflect the effect of the operating conditions and maintenance conditions of equipment. In this paper, a time-varying failure rate model of railway (35)10kV power transformer is proposed according to the Weibull distribution, considering the factors of altitude, ambient temperature, and maintenance conditions. The model also considers the manufactory correction factor obtained from the historical data. The results show that for different combinations of factors, the failure rate curves of transformers are different. The model proposed can present the relationship between the failure rate of transformers and the parameters of operating conditions and the maintenance situation. Hence, it is more applicable for reliability evaluation of the whole railway power supply system, which can provide support for formulating maintenance plan and scheduling field operation. © Springer-Verlag Berlin Heidelberg 2014.
KW  - Altitude
KW  - Ambient temperature
KW  - Equivalent operating time
KW  - Failure rate model
KW  - Maintenance situation
KW  - Manufacturer's correction factor
KW  - Electric power systems
KW  - Failure analysis
KW  - Maintenance
KW  - Power transformers
KW  - Railroad transportation
KW  - Scheduling
KW  - Temperature
KW  - Altitude
KW  - Correction factors
KW  - Failure rate modeling
KW  - Operating condition
KW  - Operating time
KW  - Railway power supplies
KW  - Reliability Evaluation
KW  - Time-varying failure rates
KW  - Railroads
PB  - Springer Verlag
SN  - 18761100 (ISSN); 978-364253777-6 (ISBN)
LA  - English
J2  - Lect. Notes Electr. Eng.
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 0; Correspondence Address: J. Zhang; School of Electrical Engineering, Beijing Jiaotong University, Beijing, China; email: zhangjuanok@126.com; Conference name: 2013 International Conference on Electrical and Information Technologies for Rail Transportation, EITRT 2013; Conference date: 25 October 2013 through 27 October 2013; Conference code: 107155
ER  -

TY  - JOUR
AU  - Sun, Y.
AU  - Gao, H.
AU  - Li, K.
AU  - Liang, Y.
TI  - Condition assessment model of distribution transformer based on multi-period information fusion
PY  - 2016
T2  - Gaodianya Jishu/High Voltage Engineering
VL  - 42
IS  - 7
SP  - 2054
EP  - 2062
DO  - 10.13336/j.1003-6520.hve.20160713005
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-84979238911&doi=10.13336%2fj.1003-6520.hve.20160713005&partnerID=40&md5=c2dd49598eb2d008b30dce949e69cc60
AD  - Institute of Electrical Engineering, Shandong University, Ji'nan, 250061, China
AD  - Department of Electrical Engineering, Institute of Information and Control Engineering, China University of Petroleum (East China), Qingdao, 266580, China
AB  - In order to evaluate the operating condition of the distribution transformer more accurately, we establish a condition assessment model of the distribution transformer based on the multi-period information fusion. Quantitative indexes are evaluated with the reasonable condition evaluation function; qualitative indexes are evaluated by synthesizing two kinds of expert investigation method based on the set-valued statistics and importing the expert evaluating trust factor; optimal weights of the model are decided with the fuzzy analytic hierarchy process and the similarity clustering analysis; the improved evidence theory and the multivariate grey prediction model are adopted to fuse multi-period condition information of the distribution information, and then the assessing result of the transformer is obtained according to the multi-stage fuzzy comprehensive evaluation. The condition of 54 distribution transformers is evaluated with the assessment model, and the assessment accuracy of the model is about 96.296% by comparing the condition assessment result and the actual operation condition of every transformer. The feasibility of the model proposed is verified by actual test data so that the model can provide a new thought for condition assessment of the distribution transformer. © 2016, High Voltage Engineering Editorial Department of CEPRI. All right reserved.
KW  - Condition evaluation function
KW  - Expert evaluating trust factor
KW  - Improved evidence theory
KW  - Multi-period
KW  - Similarity clustering analysis
KW  - Electric transformers
KW  - Factor analysis
KW  - Function evaluation
KW  - Fuzzy set theory
KW  - Information fusion
KW  - Clustering analysis
KW  - Condition evaluation
KW  - Evidence theories
KW  - Multi-period
KW  - Trust factor
KW  - Electric transformer testing
PB  - Science Press
SN  - 10036520 (ISSN)
LA  - Chinese
J2  - Gaodianya Jishu
M3  - Article
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 27; Correspondence Address: K. Li; Institute of Electrical Engineering, Shandong University, Ji'nan, 250061, China; email: lkjun@sdu.edu.cn; CODEN: GAJIE
ER  -

TY  - CONF
AU  - Bigdeli, M.
AU  - Valii, M.
AU  - Azizian, D.
TI  - Applying intelligent optimization algorithms for evaluation of transformer black box model
PY  - 2016
T2  - Advances in Intelligent Systems and Computing
VL  - 357
SP  - 1271
EP  - 1286
DO  - 10.1007/978-3-319-18416-6_102
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-84951928336&doi=10.1007%2f978-3-319-18416-6_102&partnerID=40&md5=5818520bef5eea0168f0fd771e8742d0
AD  - Department of Electrical Engineering, Zanjan Branch, Islamic Azad University, Zanjan, Iran
AD  - Department of Electrical Engineering, Abhar Branch, Islamic Azad University, Abhar, Iran
AB  - To study the behavior of the transformers and the effects of these devices on power network performance in transient states, various models with different objectives are presented. One of the most important objectives is to investigate the overvoltages made in transformer as a result of lightning waves. For this reason, a black box model applied in the analysis of transient state of the transformer high frequency (up to 1.2 MHz). As a new work, the Genetic Algorithm (GA), Particle Swarm Optimization (PSO), and Imperialist Competitive Algorithm (ICA) are proposed in the estimation of parameters of black box model using the necessary measurements on three-phase transformer 2.5 MVA and 6300/420 V and then compared by analytical methods. © Springer International Publishing Switzerland 2016.
KW  - Black box model
KW  - Intelligent algorithms
KW  - Transformer
KW  - Transient analysis
KW  - Algorithms
KW  - Genetic algorithms
KW  - Particle swarm optimization (PSO)
KW  - Soft computing
KW  - Transient analysis
KW  - Black-box model
KW  - Estimation of parameters
KW  - High frequency HF
KW  - Imperialist competitive algorithm (ICA)
KW  - Intelligent Algorithms
KW  - Intelligent optimization algorithm
KW  - Three-phase transformers
KW  - Transformer
KW  - Optimization
A2  - Balas V.E.
A2  - Kovačević B.
A2  - Jain L.C.
PB  - Springer Verlag
SN  - 21945357 (ISSN); 978-331918415-9 (ISBN)
LA  - English
J2  - Adv. Intell. Sys. Comput.
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 2; Correspondence Address: M. Bigdeli; Department of Electrical Engineering, Zanjan Branch, Islamic Azad University, Zanjan, Iran; email: mehdi.bigdeli@iauz.ac.ir; Conference name: 6th International Workshop Soft Computing Applications, SOFA 2014; Conference date: 24 July 2014 through 26 July 2014; Conference code: 154729
ER  -

TY  - JOUR
AU  - Baral, A.
AU  - Chakravorti, S.
TI  - Condition assessment of cellulosic part in power transformer insulation using transfer function zero of modified debye model
PY  - 2014
T2  - IEEE Transactions on Dielectrics and Electrical Insulation
VL  - 21
IS  - 5
C7  - 6927330
SP  - 2028
EP  - 2036
DO  - 10.1109/TDEI.2014.004517
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-84908543383&doi=10.1109%2fTDEI.2014.004517&partnerID=40&md5=bfe67da6a7e76268c968d382ba65c0d8
AD  - Department of Electrical Engineering, Jadavpur University, Kolkata, West Bengal, 700032, India
AB  - Analysis of Polarization-Depolarization Current, recorded from high voltage oilpaper insulation using insulation model is common among researchers. It is reported that paper insulation of power transformers undergoes non-uniform aging. Unlike Conventional Debye Model (CDM), Modified Debye Model (MDM) is capable of modeling such non-uniform aging. However, factors like insulation geometry affect the values of the MDM branch parameters. Therefore, model parameterized using data obtained from one insulation system finds limited use in assessing the condition of a different transformer, even with similar loading history and power rating. The present paper shows that a performance parameter, which is less sensitive to insulation geometry, can be evaluated from Transfer Function, TFM(s) of MDM. The parameter is the zero Z1 of TFM(s) which is located farthest away from the origin in the Left Half Plane of s-plane. The capability of Z1 as an insulation condition sensitive parameter is first tested on laboratory samples and then on data recorded from several real life power transformers. Results obtained for these transformers show that there is a good correlation between magnitude of Z1 and paper moisture content obtained from Frequency Domain Spectroscopy (FDS) using IDAX 300. © 1994-2012 IEEE.
KW  - aging
KW  - Conventional Debye model
KW  - modified Debye model
KW  - paper moisture content
KW  - power transformer
KW  - transfer function
KW  - Power transformers
KW  - Transfer functions
KW  - Condition assessments
KW  - Debye models
KW  - Modified debye models
KW  - Paper moisture
KW  - Power transformer insulation
KW  - Aging of materials
PB  - Institute of Electrical and Electronics Engineers Inc.
SN  - 10709878 (ISSN)
LA  - English
J2  - IEEE Trans Dielectr Electr Insul
M3  - Article
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 52; CODEN: ITDIE
ER  -

TY  - JOUR
AU  - Matsushita, K.
AU  - Kuroda, K.
AU  - Ishii, Y.
AU  - Takasu, S.
AU  - Kijima, A.
AU  - Kawaguchi, H.
AU  - Miyoshi, N.
AU  - Nohmi, T.
AU  - Ogawa, K.
AU  - Nishikawa, A.
AU  - Umemura, T.
TI  - Improvement and validation of a medium-term gpt delta rat model for predicting chemical carcinogenicity and underlying mode of action
PY  - 2014
T2  - Experimental and Toxicologic Pathology
VL  - 66
IS  - 7
SP  - 313
EP  - 321
DO  - 10.1016/j.etp.2014.05.002
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-84902791166&doi=10.1016%2fj.etp.2014.05.002&partnerID=40&md5=8072d427399e38c1a40890730177fb84
AD  - Division of Pathology, National Institute of Health Sciences, Tokyo 158-8501, 1-18-1 Kamiyoga, Setagaya-ku, Japan
AD  - Laboratory of Veterinary Histopathology, Joint Faculty of Veterinary Medicine, Kagoshima University, Kagoshima 890-8508, 1-21-24 Korimoto, Japan
AD  - Biological Safety Research Center, National Institute of Health Sciences, Tokyo 158-8501, 1-18-1 Kamiyoga, Setagaya-ku, Japan
AB  - We have developed a new medium-term animal model, "GPG", in which an in vivo mutation assay in partially hepatectomized tissue and a tumor-promoting assay were performed. The tumor-promoting assay measures glutathione S-transferase placental form positive foci induced by diethylnitrosamine (DEN) in the residual tissue. Given that a limitation of the original protocol is the potential interaction between the test chemical and DEN, the present study establishes a modified protocol that includes a test chemical washout period. Using CYP2E1 inhibitor and CYP1A or CYP2B inducers, a period of 2 weeks after cessation of exposure to the chemicals was confirmed to be sufficient to return their enzymatic activities to normal levels. Additionally, to avoid the effects of DEN on the pharmacokinetics of the test chemical, re-exposure to the test chemical started 1 week after DEN injection, in which tumor-promoting activities were clearly detected. Consequently, a modified protocol has been established with 2- and 1-week washout periods before and after DEN injection, respectively. The applicability of the modified protocol was demonstrated using the genotoxic hepatocarcinogen, estragole (ES), the genotoxic renal carcinogen, aristolochic acid (AA), and the non-genotoxic hepatocarcinogens, β-naphthoflavone and barbital. Furthermore, the increase of cell cycle-related parameters in ES-treated livers, but not in AA-treated livers, may indicate that the liver is not the carcinogenic target site of AA despite its genotoxic role. Thus, since various parameters related to carcinogenesis can be evaluated concurrently, the GPG model could be a rapid and reliable assay for the assessment of human cancer hazards. © 2014 Elsevier GmbH.
KW  - Carcinogenicity
KW  - Glutathione S-transferase placental form
KW  - Gpt delta rat
KW  - In vivo mutagenicity
KW  - Medium-term animal model
KW  - Animals
KW  - Biological Assay
KW  - Carcinogenicity Tests
KW  - Carcinogens
KW  - Cocarcinogenesis
KW  - Cytochrome P-450 Enzyme System
KW  - Escherichia coli Proteins
KW  - Glutathione S-Transferase pi
KW  - Hepatectomy
KW  - Liver
KW  - Liver Neoplasms, Experimental
KW  - Male
KW  - Microsomes, Liver
KW  - Mutation
KW  - Pentosyltransferases
KW  - Proliferating Cell Nuclear Antigen
KW  - Rats, Inbred F344
KW  - Rats, Transgenic
KW  - Animalia
KW  - Rattus
KW  - aristolochic acid
KW  - barbital
KW  - beta naphthoflavone
KW  - cyclin A2
KW  - cyclin B1
KW  - cyclin E
KW  - cytochrome P450 1A2
KW  - cytochrome P450 2B1
KW  - cytochrome P450 2E1
KW  - diallyl disulfide
KW  - diethylnitrosamine
KW  - estragole
KW  - glutathione transferase
KW  - phenytoin
KW  - piperonyl butoxide
KW  - transcription factor E2F1
KW  - carcinogen
KW  - cycline
KW  - cytochrome P450
KW  - Escherichia coli protein
KW  - glutathione transferase P1
KW  - glycosyltransferase
KW  - Gpt protein, E coli
KW  - Gstp1 protein, rat
KW  - animal cell
KW  - animal experiment
KW  - animal model
KW  - animal tissue
KW  - article
KW  - cancer risk
KW  - carcinogen testing
KW  - carcinogenicity
KW  - CCNA2 gene
KW  - Ccnb1 gene
KW  - CCNE1 gene
KW  - chemical carcinogenesis
KW  - controlled study
KW  - E2F1 gene
KW  - enzyme activity
KW  - gene
KW  - genotoxicity
KW  - gpt delta rat
KW  - in vivo study
KW  - male
KW  - mutational analysis
KW  - nonhuman
KW  - prediction
KW  - rat
KW  - rat model
KW  - real time polymerase chain reaction
KW  - reverse transcription polymerase chain reaction
KW  - risk assessment
KW  - survival
KW  - tumor promotion
KW  - validation process
KW  - animal
KW  - bioassay
KW  - carcinogen testing
KW  - chemically induced
KW  - cocarcinogenesis
KW  - drug effects
KW  - enzymology
KW  - experimental liver neoplasm
KW  - Fischer 344 rat
KW  - genetics
KW  - liver
KW  - liver microsome
KW  - liver resection
KW  - metabolism
KW  - mutation
KW  - procedures
KW  - toxicity
KW  - transgenic rat
PB  - Urban und Fischer Verlag Jena
SN  - 09402993 (ISSN)
C2  - 24929978
LA  - English
J2  - Exp. Toxicol. Pathol.
M3  - Article
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 7; Correspondence Address: T. Umemura; Division of Pathology, National Institute of Health Sciences, Tokyo 158-8501, 1-18-1 Kamiyoga, Setagaya-ku, Japan; email: umemura@nihs.go.jp; CODEN: ETPAE
ER  -

TY  - JOUR
AU  - Liang, Y.
AU  - Li, K.
AU  - Niu, L.
AU  - Zhao, J.
AU  - Ren, J.
AU  - Li, X.
TI  - A multilayer uncertain transformer condition assessment model
PY  - 2013
T2  - Dianli Xitong Zidonghua/Automation of Electric Power Systems
VL  - 37
IS  - 22
SP  - 73
EP  - 78
DO  - 10.7500/AEPS201301240
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-84891104374&doi=10.7500%2fAEPS201301240&partnerID=40&md5=59da8a4dc9856d1937a94598eb334cda
AD  - School of Electrical Engineering, Shandong University, Jinan 250061, China
AD  - State Grid of China Technology College, Jinan 250002, China
AD  - Jinan Power Supply Company, Jinan 250011, China
AB  - A multilayer transformer condition assessment model is built by taking both fuzziness and randomness in uncertainty into consideration. The framework of assessment is divided into three layers of subsystem assessment, system assessment and overall assessment, respectively. In the first layer of subsystem assessment, the relationship between quantitative index relative deterioration degrees and grades is expressed in the normal cloud model. Then the matter-element cloud model provides the association degrees between the quantitative indices and grades. By referring to the optimal weights, the condition assessment results of all subsystems in the quantitative assessment system are obtained. Finally random processing and Bayesian approximation of the original evidence is performed. The integral assessment results are obtained by merging the assessment results of the subsystems and systems based on the D-S evidence theory. The feasibility of the model proposed is verified through field test data, providing transformer condition assessment with a new line of thought. © right.
KW  - Cloud model
KW  - Condition assessment
KW  - Evidence theory
KW  - Matter-element theory
KW  - Optimal weight
KW  - Uncertainty
KW  - Cloud computing
KW  - Optimization
KW  - Cloud modeling
KW  - Condition assessments
KW  - Evidence theories
KW  - Matter-element
KW  - Optimal weight
KW  - Uncertainty
KW  - Multilayers
SN  - 10001026 (ISSN)
LA  - Chinese
J2  - Dianli Xitong Zidonghue
M3  - Article
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 21; Correspondence Address: K. Li; School of Electrical Engineering, Shandong University, Jinan 250061, China; email: lkjun@sdu.edu.cn; CODEN: DXZIE
ER  -

TY  - JOUR
AU  - Matsushita, K.
AU  - Kijima, A.
AU  - Ishii, Y.
AU  - Takasu, S.
AU  - Jin, M.
AU  - Kuroda, K.
AU  - Kawaguchi, H.
AU  - Miyoshi, N.
AU  - Nohmi, T.
AU  - Ogawa, K.
AU  - Umemura, T.
TI  - Development of a medium-term animal model using gpt delta rats to evaluate chemical carcinogenicity and genotoxicity
PY  - 2013
T2  - Journal of Toxicologic Pathology
VL  - 26
IS  - 1
SP  - 19
EP  - 27
DO  - 10.1293/tox.26.19
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-84876470830&doi=10.1293%2ftox.26.19&partnerID=40&md5=a8fc057410a8c10fadd56e827b77de6e
AD  - Division of Pathology, National Institute of Health Sciences, Setagaya-ku, Tokyo 158-8501, 1-18-1 Kamiyoga, Japan
AD  - Laboratory of Veterinary Histopathology, Kagoshima University, Kagoshima 890-8508, 1-21-24 Korimoto, Japan
AD  - Biological Safety Research Center, National Institute of Health Sciences, Setagaya-ku, Tokyo 158-8501, 1-18-1 Kamiyoga, Japan
AB  - In this study, the potential for development of an animal model (GPG46) capable of rapidly detecting chemical carcinogenicity and the underlying mechanisms of action were examined in gpt delta rats using a reporter gene assay to detect mutations and a medium-term rat liver bioassay to detect tumor promotion. The tentative protocol for the GPG46 model was developed based on the results of dose-response exposure to diethylnitrosamine (DEN) and treatment with phenobarbital over time following DEN administration. Briefly, gpt delta rats were exposed to various chemicals for 4 weeks, followed by a partial hepatectomy (PH) to collect samples for an in vivo mutation assay. The mutant frequencies (MFs) of the reporter genes were examined as an indication of tumor initiation. A single intraperitoneal (ip) injection of 10 mg/kg DEN was administered to rats 18 h after the PH to initiate hepatocytes. Tumor-promoting activity was evaluated based on the development of glutathione S-transferase placental form (GST-P)-positive foci at week 10. The genotoxic carcinogens 2-acetylaminofluorene (2-AAF), 2-amino-3-methylimidazo [4,5-f] quinolone (IQ) and safrole (SF), the non-genotoxic carcinogens piperonyl butoxide (PBO) and phenytoin (PHE), the non-carcinogen acetaminophen (APAP) and the genotoxic non-hepatocarcinogen aristolochic acid (AA) were tested to validate the GPG46 model. The validation results indicate that the GPG46 model could be a powerful tool in understanding chemical carcinogenesis and provide valuable information regarding human risk hazards. ©2013 The Japanese Society of Toxicologic Pathology.
KW  - Carcinogenicity
KW  - Glutathione S-transferase placental form
KW  - gpt delta rats
KW  - In vivo genotoxicity
KW  - Medium-term animal model
KW  - 2 amino 3 methylimidazo[4,5 f]quinoline
KW  - aristolochic acid
KW  - diethylnitrosamine
KW  - glutathione transferase
KW  - n (2 fluorenyl)acetamide
KW  - paracetamol
KW  - phenobarbital
KW  - phenytoin
KW  - piperonyl butoxide
KW  - safrole
KW  - animal cell
KW  - animal experiment
KW  - animal model
KW  - animal tissue
KW  - article
KW  - bioassay
KW  - carcinogenicity
KW  - controlled study
KW  - disease model
KW  - dose response
KW  - gene frequency
KW  - gene mutation
KW  - genotoxicity
KW  - gpt Delta rat
KW  - gpt gene
KW  - health hazard
KW  - liver cell
KW  - liver resection
KW  - nonhuman
KW  - rat
KW  - rat strain
KW  - reporter gene
KW  - tumor promotion
KW  - validation process
SN  - 09149198 (ISSN)
LA  - English
J2  - J. Toxicol. Pathol.
M3  - Article
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 13; Correspondence Address: T. Umemura; Division of Pathology, National Institute of Health Sciences, Setagaya-ku, Tokyo 158-8501, 1-18-1 Kamiyoga, Japan; email: umemura@nihs.go.jp
ER  -

TY  - CONF
AU  - Pu, G.-Y.
AU  - Chen, P.-L.
AU  - Wu, S.-H.
TI  - Using language model to assess the fluency of learners sentences edited by teachers
PY  - 2016
T2  - Proceedings of the 28th Conference on Computational Linguistics and Speech Processing, ROCLING 2016
SP  - 103
EP  - 114
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85085957848&partnerID=40&md5=7358ac98bbf4d8cc1f2dc99b208f1337
AD  - Department of Computer Science and Information Engineering, Chaoyang University of Technology, Taiwan
A2  - Wu C-H.
A2  - Tseng Y.-H.
A2  - Kao H.-Y.
A2  - Ku L.-W.
A2  - Tsao Y.
A2  - Wu S.-H.
PB  - The Association for Computational Linguistics and Chinese Language Processing (ACLCLP)
SN  - 978-957307929-3 (ISBN)
LA  - Chinese
J2  - Proc. Conf. Comput. Linguist. Speech Process., ROCLING
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 0; Correspondence Address: S.-H. Wu; Department of Computer Science and Information Engineering, Chaoyang University of Technology, Taiwan; email: shwu@cyut.edu.tw; Conference name: 28th Conference on Computational Linguistics and Speech Processing, ROCLING 2016; Conference date: 6 October 2016 through 7 October 2016; Conference code: 159802
ER  -

TY  - CONF
AU  - Gu, R.
AU  - Yuan, J.S.
AU  - Lv, F.
TI  - A model of weight absolute grey correlation degree for the transformer bushing state assessment
PY  - 2013
T2  - Applied Mechanics and Materials
VL  - 345
SP  - 507
EP  - 510
DO  - 10.4028/www.scientific.net/AMM.345.507
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-84883165869&doi=10.4028%2fwww.scientific.net%2fAMM.345.507&partnerID=40&md5=8e1834c70ef2410b498473d1e4062116
AD  - Department of Electronic and Communication Engineering, North China Electric Power University, BaoDing 071000, China
AB  - Accurate assessment for the operational status of the transformer bushing is not only a prerequisite for the implementation of condition-based maintenance, but also to ensure the normal operation of the transformer and the whole power equipment conditions. In the paper, a model of weight absolute grey correlation degree was used to assess the transformer bushing state. Firstly, determined the assessment indicators and handled them. Secondly, the weights, correlation coefficients and each association were calculated. Thirdly, to compare the largest association of assessment indicators in grades as the transformer bushing final run state. Finally, give the state assessment results, according to the remark set. The result shows the model works well. © (2013) Trans Tech Publications, Switzerland.
KW  - Running state
KW  - State assessment
KW  - Transformer bushing
KW  - Weight absolute grey correlation degree
KW  - Industrial engineering
KW  - Mechanical engineering
KW  - Assessment indicator
KW  - Condition based maintenance
KW  - Correlation coefficient
KW  - Grey correlation degrees
KW  - Normal operations
KW  - Running state
KW  - State assessment
KW  - Transformer bushings
KW  - Bushings
SN  - 16627482 (ISSN); 978-303785779-3 (ISBN)
LA  - English
J2  - Appl. Mech. Mater.
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 0; Conference name: 2013 3rd International Conference on Mechanical Engineering, Industry and Manufacturing Engineering, MEIME 2013; Conference date: 22 June 2013 through 23 June 2013; Conference code: 99136
ER  -

TY  - JOUR
AU  - Balasubramanian, M.
AU  - Venkatesh, S.
TI  - Assessment of partial discharge signatures in transformer oil insulation using Hidden Markov Model
PY  - 2016
T2  - International Journal on Electrical Engineering and Informatics
VL  - 8
IS  - 3
SP  - 660
EP  - 674
DO  - 10.15676/ijeei.2016.8.3.13
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-84991746075&doi=10.15676%2fijeei.2016.8.3.13&partnerID=40&md5=ce39dc781b984b73065ba0ccf55b454e
AD  - Department of Electrical and Electronics Engineering, School of Electrical and Electronics Engineering, SASTRA University, Thanjavur, 613401, India
AD  - Department of Electrical Engineering, School of Electrical Engineering, VIT University, Vellore, 632 014, India
AB  - Condition based monitoring and assessment of insulating oil has become a vital constituent for ascertaining the reliability of oil-filled transformers. Partial Discharge (PD) measurement is one of the proven techniques to analyze the variations in discharge activity in insulating oil degradation under normal and abnormal operating conditions. PD activity is connected with the physical characteristics of oil and other external influencing factors like applied voltage, temperature, etc. Since PD pulse signature patterns are complex non-markovian process, capturing the time dependent variation of discharges during degradation of oil is important in understanding the dynamics of degradation. PD data is measured under the influence of both accelerated electrical stress conditions. Hidden Markov Model (HMM) is applied to characterize the stochastic behavior of the PD pulse transition in the insulation system. Continuous Density Hidden Markov Model (CDHMM) has been implemented to analyze the changes associated with PD phenomenon stress conditions. The PD signal has been preprocessed to compute the optimal state transition matrix using the Viterbi algorithm. The results show that the transition of PD pulses can be identified using the state transition matrix which display unique and significant changes in the discharge activity in insulating oil under different accelerated electrical stress conditions. © 2016, School of Electrical Engineering and Informatics. All rights reserved.
KW  - Accelerated aging
KW  - Degradation dynamics
KW  - Hidden markov model
KW  - Oil insulation
KW  - Partial discharges
PB  - School of Electrical Engineering and Informatics
SN  - 20856830 (ISSN)
LA  - English
J2  - Int. J. Electr. Eng. Informatics
M3  - Article
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 2
ER  -

TY  - JOUR
AU  - Zhang, H.
AU  - Wei, B.
AU  - Li, K.
AU  - Liang, Y.
TI  - Research on risk assessment technology based on Markov state evaluation model for power transformer and entropy-weighted fuzzy comprehensive evaluation
PY  - 2016
T2  - Dianli Xitong Baohu yu Kongzhi/Power System Protection and Control
VL  - 44
IS  - 5
SP  - 134
EP  - 140
DO  - 10.7667/PSPC151240
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-84961725690&doi=10.7667%2fPSPC151240&partnerID=40&md5=fa3bc7d65364213ec8ed9510f3a6da11
AD  - School of Electrical Engineering, Chongqing University, Chongqing, 400044, China
AD  - Electric Power Technical Research Institute, SMEPC, Shanghai, 200437, China
AD  - School of Electric Engineering, Shandong University, Jinan, 250061, China
AB  - To build an effective assessment method for the risk of electric power transformers, the full condition model of transformer based on condition-based maintenance (CBM) and Markov Process is established, considering the complexity and uncertainty of transformer fault. The research method of classified index is used for confirming the severity of transformer defects. Combined with the calculation model for subcomponent fault frequency, entropy-weighted fuzzy method is adopted to quantify the serious degree. Based on the above research the assessment matrix is established. Then a new assessment method for the risk of electric power transformers is given. The simulation program is compiled, and a case is analyzed by the risk assessment technology. The calculation result concludes the risk value and maintenance strategy. Empirical results show that the approach proposed is available and effective. © 2016, Power System Protection and Control Press. All right reserved.
KW  - Entropy-weighted fuzzy comprehensive evaluation
KW  - Fault frequency
KW  - Maintenance strategy
KW  - Markov Process
KW  - Power transformer
KW  - Risk assessment
PB  - Power System Protection and Control Press
SN  - 16743415 (ISSN)
LA  - Chinese
J2  - Dianli Xitong Baohu yu Kongzhi
M3  - Article
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 25
ER  -

TY  - JOUR
AU  - Jazebi, S.
AU  - De León, F.
TI  - Experimentally validated reversible single-phase multiwinding transformer model for the accurate calculation of low-frequency transients
PY  - 2015
T2  - IEEE Transactions on Power Delivery
VL  - 30
IS  - 1
C7  - 6810857
SP  - 193
EP  - 201
DO  - 10.1109/TPWRD.2014.2319093
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85027934871&doi=10.1109%2fTPWRD.2014.2319093&partnerID=40&md5=04acac4504eac7686fb8fa587597a579
AD  - Department of Electrical and Computer Engineering, NYU Polytechnic School of Engineering, Brooklyn, 11201, NY, United States
AB  - In this paper, a previously published model for the representation of the leakage inductance of multiwinding transformers is enhanced to support accurate calculations of low-frequency transients, including inrush currents, series ferroresonance, and geomagnetic-induced currents. The new circuit is obtained from the principle of duality and, therefore, is physically consistent. The unique characteristic of the improved model is that the very deep saturation behavior of the iron core is properly represented for each winding simultaneously (reversible model) without changing parameters. The hysteresis cycle and iron-core losses are also included. In addition to its reversible terminal behavior coupled with physical consistency, the proposed model can be built with circuit elements available in Electromagnetic Transients Program-type programs, and all of the parameters can be computed from terminal tests. The model is validated by comparing computer simulations versus laboratory measurements for three- and four-winding transformers. © 2014 IEEE.
KW  - Duality
KW  - Electromagnetic transients
KW  - Ferroresonance
KW  - Geomagnetic-induced current (GIC)
KW  - Inrush currents
KW  - Multiwinding transformers
KW  - Coupled circuits
KW  - Geomagnetism
KW  - Magnetic resonance
KW  - Resonance
KW  - Software testing
KW  - Winding
KW  - Duality
KW  - Electro-magnetic transient
KW  - Ferroresonance
KW  - Geomagnetic induced currents
KW  - In-rush current
KW  - Multi-winding transformer
KW  - Transients
PB  - Institute of Electrical and Electronics Engineers Inc.
SN  - 08858977 (ISSN)
LA  - English
J2  - IEEE Trans Power Delivery
M3  - Article
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 24; CODEN: ITPDE
ER  -

TY  - JOUR
AU  - Sun, L.
AU  - Liu, Y.
AU  - Zhang, B.
AU  - Shang, Y.
AU  - Yuan, H.
AU  - Ma, Z.
TI  - An Integrated Decision-Making Model for Transformer Condition Assessment Using Game Theory and Modified Evidence Combination Extended by D Numbers
PY  - 2016
T2  - Energies
VL  - 9
IS  - 9
C7  - 697
DO  - 10.3390/en9090697
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85007216945&doi=10.3390%2fen9090697&partnerID=40&md5=0b0a6fc6ce83ecc6deaed73d24f3b254
AD  - School of Automation Science and Electrical Engineering, Beihang University, Beijing, 100191, China
AD  - School of telecommunications, Taizhou Vocational & Technical College, Taizhou, 318000, China
AD  - China Electric Power Research Institute, Beijing, 100192, China
AB  - The power transformer is one of the most critical and expensive components for the stable operation of the power system. Hence, how to obtain the health condition of transformer is of great importance for power utilities. Multi-attribute decision-making (MADM), due to its ability of solving multi-source information problems, has become a quite effective tool to evaluate the health condition of transformers. Currently, the analytic hierarchy process (AHP) and Dempster–Shafer theory are two popular methods to solve MADM problems; however, these techniques rarely consider one-sidedness of the single weighting method and the exclusiveness hypothesis of the Dempster–Shafer theory. To overcome these limitations, this paper introduces a novel decision-making model, which integrates the merits of fuzzy set theory, game theory and modified evidence combination extended by D numbers, to evaluate the health condition of transformers. A four-level framework, which includes three factors and seventeen sub-factors, is put forward to facilitate the evaluation model. The model points out the following: First, the fuzzy set theory is employed to obtain the original basic probability assignments for all indices. Second, the subjective and objective weights of indices, which are calculated by fuzzy AHP and entropy weight, respectively, are integrated to generate the comprehensive weights based on game theory. Finally, based on the above two steps, the modified evidence combination extended by D numbers, which avoids the limitation of the exclusiveness hypothesis in the application of Dempster–Shafer theory, is proposed to obtain the final assessment results of transformers. Case studies are given to demonstrate the proposed modeling process. The results show the effectiveness and engineering practicability of the model in transformer condition assessment. © 2016 by the authors; licensee MDPI, Basel, Switzerland.
KW  - D numbers
KW  - Fuzzy analytic hierarchy process (AHP)
KW  - Game theory
KW  - Multi-attribute decision-making (MADM)
KW  - Power transformer
KW  - Analytic hierarchy process
KW  - Decision making
KW  - Fuzzy set theory
KW  - Fuzzy sets
KW  - Game theory
KW  - Health
KW  - Hierarchical systems
KW  - D number
KW  - Decision-making modeling
KW  - Dempster-Shafer theory
KW  - Evidence combination
KW  - Fuzzy analytic hierarchy
KW  - Fuzzy analytic hierarchy process
KW  - Health condition
KW  - Multi attribute decision making
KW  - Multi-attribute decision-making
KW  - Transformer condition assessment
KW  - Power transformers
PB  - MDPI
SN  - 19961073 (ISSN)
LA  - English
J2  - Energies
M3  - Article
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 43; Correspondence Address: Y. Liu; School of Automation Science and Electrical Engineering, Beihang University, Beijing, 100191, China; email: 09339@buaa.edu.cn
ER  -

TY  - CONF
AU  - Hong, L.
AU  - Zhili, W.
AU  - Xinwei, W.
TI  - Transformer risk assessment model under condition based maintenance
PY  - 2017
T2  - Proceedings of the 2017 IEEE 2nd Information Technology, Networking, Electronic and Automation Control Conference, ITNEC 2017
VL  - 2018-January
SP  - 1
EP  - 5
DO  - 10.1109/ITNEC.2017.8284747
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85046658252&doi=10.1109%2fITNEC.2017.8284747&partnerID=40&md5=d0a8f07031b61c1a10f0313a38566046
AD  - State Grid Electric Power Research Institute of Shanxi Electric Power Corporation, Taiyuan City, Shanxi Province, China
AD  - State Grid Shanxi Electric Power Corporation, Taiyuan City, Shanxi Province, China
AB  - With the development of power equipment manufacturing level and power grid scale, power grid equipment maintenance is in the continuous development and evolution from the regular maintenance to the condition based maintenance. The foundation of condition based maintenance is the information collection, the premise is the state evaluation, and the key is the risk assessment. So most of the current risk assessment is based on theoretical research, it is difficult to promote the application. This paper establishes a new transformer risk assessment mode on the basis of the production information management system so as to provide the suggestions for the maintenance of 220kV and above transformer in Shanxi power grid. © 2017 IEEE.
KW  - condition based maintenance
KW  - risk assessment
KW  - transformer
KW  - Condition based maintenance
KW  - Electric power transmission networks
KW  - Information management
KW  - Condition based maintenance
KW  - Equipment maintenance
KW  - Equipment manufacturing
KW  - Grid scale
KW  - Power equipment
KW  - Power grid equipment
KW  - Power grids
KW  - Risk assessment - modelling
KW  - Risks assessments
KW  - Transformer
KW  - Risk assessment
A2  - Xu B.
PB  - Institute of Electrical and Electronics Engineers Inc.
SN  - 978-150906413-7 (ISBN)
LA  - English
J2  - Proc. IEEE Inf. Technol., Netwo., Electron. Autom. Control Conf., ITNEC
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 4; Conference name: 2nd IEEE Information Technology, Networking, Electronic and Automation Control Conference, ITNEC 2017; Conference date: 15 December 2017 through 17 December 2017; Conference code: 134593
ER  -

TY  - CONF
AU  - Xie, P.
AU  - Li, Q.
AU  - Wang, Y.
TI  - A model for condition assessment of power transformers based on fuzzy theory
PY  - 2013
T2  - Proceedings - 2013 International Conference on Computational and Information Sciences, ICCIS 2013
C7  - 6643378
SP  - 1757
EP  - 1759
DO  - 10.1109/ICCIS.2013.459
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-84890883861&doi=10.1109%2fICCIS.2013.459&partnerID=40&md5=a9bcbd8b3fd100148106ad9a355aea76
AD  - School of Control and Computer Engineering, North China Electric Power University, Beijing, China
AB  - This paper presents a new model based on the fuzzy approach to condition assessment of power transformers. An assessing index system, including the DGA data, electrical testing and oil testing, is established to facilitate the assessing model. It established membership functions of the qualitative indexes and quantitative indexes by using of fuzzy statistical test method and fuzzy distribution method. This work improved the analytical hierarchy process (AHP), and determines the weight of each index all levels without Consistency validation. © 2013 IEEE.
KW  - Condition assessment
KW  - Fuzzy theory
KW  - IAHP
KW  - Power transformers
KW  - Information science
KW  - Testing
KW  - Analytical Hierarchy Process
KW  - Assessing model
KW  - Condition assessments
KW  - Consistency validation
KW  - Electrical testing
KW  - Fuzzy theory
KW  - IAHP
KW  - Model-based OPC
KW  - Power transformers
SN  - 978-076955004-6 (ISBN)
LA  - English
J2  - Proc. - Int. Conf. Comput. Inf. Sci., ICCIS
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 3; Conference name: 2013 5th International Conference on Computational and Information Sciences, ICCIS 2013; Conference date: 21 June 2013 through 23 June 2013; Conference code: 101429
ER  -

TY  - JOUR
AU  - Magureanu, G.
AU  - Gavrilescu, M.
AU  - Pescaru, D.
TI  - Validation of static properties in unified modeling language models for cyber physical systems
PY  - 2013
T2  - Journal of Zhejiang University: Science C
VL  - 14
IS  - 5
SP  - 332
EP  - 346
DO  - 10.1631/jzus.C1200263
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-84877718178&doi=10.1631%2fjzus.C1200263&partnerID=40&md5=bc38f6d648ec77e1b3884718861f2f57
AD  - Department of Computers, Automation and Computers Faculty, Politehnica University of Timisoara, Timisoara 300223, Romania
AB  - Cyber physical systems (CPSs) can be found nowadays in various fields of activity. The increased interest for these systems as evidenced by the large number of applications led to complex research regarding the most suitable methods for design and development. A promising solution for specification, visualization, and documentation of CPSs uses the Object Management Group (OMG) unified modeling language (UML). UML models allow an intuitive approach for embedded systems design, helping end-users to specify the requirements. However, the UML models are represented in an informal language. Therefore, it is difficult to verify the correctness and completeness of a system design. The object constraint language (OCL) was defined to add constraints to UML, but it is deficient in strict notations of mathematics and logic that permits rigorous analysis and reasoning about the specifications. In this paper, we investigated how CPS applications modeled using UML deployment diagrams could be formally expressed and verified. We used Z language constructs and prototype verification system (PVS) as formal verification tools. Considering some relevant case studies presented in the literature, we investigated the opportunity of using this approach for validation of static properties in CPS UML models. © 2013 Journal of Zhejiang University Science Editorial Office and Springer-Verlag Berlin Heidelberg.
KW  - Cyber physical system (CPS)
KW  - Formal verification
KW  - Prototype verification system (PVS)
KW  - Unified modeling language (UML) design
KW  - Z language
KW  - Computational linguistics
KW  - Embedded software
KW  - Embedded systems
KW  - Specifications
KW  - Systems analysis
KW  - Cyber physical systems (CPSs)
KW  - Cyber-physical systems (CPS)
KW  - Formal verification tools
KW  - Formal verifications
KW  - Object Constraint Language
KW  - Object management groups
KW  - Prototype verification systems
KW  - Z language
KW  - Unified Modeling Language
SN  - 1869196X (ISSN)
LA  - English
J2  - J. Zhejiang Univ. Sci. C
M3  - Article
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 12
ER  -

TY  - CONF
AU  - Wu, Y.-C.
AU  - Yin, F.
AU  - Liu, C.-L.
TI  - Evaluation of neural network language models in handwritten Chinese text recognition
PY  - 2015
T2  - Proceedings of the International Conference on Document Analysis and Recognition, ICDAR
VL  - 2015-November
C7  - 7333745
SP  - 166
EP  - 170
DO  - 10.1109/ICDAR.2015.7333745
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-84962612693&doi=10.1109%2fICDAR.2015.7333745&partnerID=40&md5=83217385c7e5ab382e5957b6eb3a33fb
AD  - National Laboratory of Pattern Recognition (NLPR), Institute of Institute of Automation, Chinese Academy of Sciences, Beijing, China
AB  - Handwritten Chinese text recognition based on over-segmentation and path search integrating contexts has been demonstrated successful, where language models play an important role. Recently, neural network language models (NNLMs) have shown superiority to back-off N-gram language models (BLMs) in handwriting recognition, but have not been studied in Chinese text recognition system. This paper investigates the effects of NNLMs in handwritten Chinese text recognition and compares the performance with BLMs. We trained character-level language models in 3-, 4- and 5- gram on large scale corpora and applied them in text line recognition system. Experimental results on the CASIA-HWDB database show that NNLM and BLM of the same order perform comparably, and the hybrid model by interpolating NNLM and BLM improves the recognition performance significantly. © 2015 IEEE.
KW  - handwritten Chinese text recognition
KW  - higher order character language model
KW  - hybrid language model
KW  - neural network language model
KW  - Computational linguistics
KW  - Image segmentation
KW  - Handwriting recognition
KW  - Handwritten chinese text recognition
KW  - Hybrid language model
KW  - Language model
KW  - N-gram language models
KW  - Network language
KW  - Over segmentation
KW  - Text-line recognition
KW  - Character recognition
PB  - IEEE Computer Society
SN  - 15205363 (ISSN); 978-147991805-8 (ISBN)
LA  - English
J2  - Proc. Int. Conf. Doc. Anal. Recognit.
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 6; Conference name: 13th International Conference on Document Analysis and Recognition, ICDAR 2015; Conference date: 23 August 2015 through 26 August 2015; Conference code: 118256
ER  -

TY  - JOUR
AU  - Zhu, L.
AU  - Ji, S.
AU  - Qian, Z.
AU  - Li, H.
AU  - Ou, X.
TI  - An Improved Dynamic Thermal Circuit Model for Transformers and its Application to Evaluate Capacity Increase
PY  - 2017
T2  - Electric Power Components and Systems
VL  - 45
IS  - 13
SP  - 1440
EP  - 1449
DO  - 10.1080/15325008.2017.1352629
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85037745905&doi=10.1080%2f15325008.2017.1352629&partnerID=40&md5=8efed4fdbf5681cc3d9b6b80147e0aa4
AD  - Xi'an Jiaotong University, State Key Laboratory of Electrical Insulation and Power Equipment, Xi'an, Shaanxi, China
AD  - Shaoxing Electric Power Bureau, Shaoxing, Zhejiang, China
AD  - Electric Power Research Institute of Guangdong Power Grid Corporation, Guangzhou, Guangdong, China
AB  - The thermal circuit model is widely used in the estimation of transformer temperature, especially the hot-spot temperature which is extremely challenging to be acquired. In this paper, a dynamic thermal circuit model for calculating the transformer internal temperatures is established considering actual operating conditions and environmental factors synthetically. In our model, load losses are calculated according to the operation currents and the tap positions, while the effects of sunshine and wind are reflected in thermal resistances. The parameter-estimation methods are also analyzed to solve the problem of information incompleteness in practice. To implement and verify the dynamic thermal circuit, the real-time loss and cooling thermal resistance of a transformer are calculated first. Then, the hot-spot temperature based on the average oil temperature is calculated for a period of 24 hr. The calculated results were compared with the temperature-rise test result and practically measured data. The comparison shows that the estimation accuracy of the proposed model is satisfactory. The model is then used to evaluate the feasibility of increasing operating capacity and the maximum safe load factor for a long-term operation. © 2017, Copyright © Taylor & Francis Group, LLC.
KW  - capacity increase
KW  - solar radiation
KW  - thermal circuit
KW  - transformer
KW  - wind speed
KW  - Circuit theory
KW  - Heat resistance
KW  - Solar radiation
KW  - Timing circuits
KW  - Wind
KW  - Capacity increase
KW  - Environmental factors
KW  - Information incompleteness
KW  - Parameter estimation method
KW  - Temperature-rise tests
KW  - Thermal circuits
KW  - transformer
KW  - Wind speed
KW  - Circuit simulation
PB  - Taylor and Francis Inc.
SN  - 15325008 (ISSN)
LA  - English
J2  - Electr. Power Comp. Syst.
M3  - Article
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 6; Correspondence Address: L. Zhu; Xi'an Jiaotong University, State Key Laboratory of Electrical Insulation and Power Equipment, Xi'an, 28 Xianning West Road, 710049, China; email: zhuly102@gmail.com
ER  -

TY  - JOUR
AU  - Bian, J.
AU  - Sun, X.
AU  - Yang, S.
AU  - Wang, M.
TI  - Risk assessment and working-out of maintenance strategy for power transformer based on cloud model
PY  - 2015
T2  - Gaodianya Jishu/High Voltage Engineering
VL  - 41
IS  - 10
SP  - 3342
EP  - 3347
DO  - 10.13336/j.1003-6520.hve.2015.10.021
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-84948137518&doi=10.13336%2fj.1003-6520.hve.2015.10.021&partnerID=40&md5=1f3c3ec4d2cf136576b3f1b4384e9b26
AD  - School of Electrical and Electronics Engineering, Shijiazhuang Tiedao University, Shijiazhuang, 050043, China
AB  - To solve the problems of traditional risk assessment methods such as non-differential analysis of evaluation indexes, impossibility of risk evaluation with equal risk priority numbers (RPN), and low accuracy of evaluation results, according to randomness and fuzziness of cloud model, we established a cloud model based on the failure mode and effect analysis (FMEA) of power transformer, and applied it to the practical risk assessment for power transformer.The assessment results show that the proposed method not only can effectively sort risk degree of main components of transformer, but also solve the impossibility of risk evaluation with equal RPN (such as core and OLTC). So this proposed method can provide a convincing foundation for efficient maintenance strategy and the improvement of security and economy. © 2015, High Voltage Engineering Editorial Department of CEPRI. All right reserved.
KW  - Cloud model
KW  - FMEA
KW  - Maintenance strategy
KW  - Power transformer
KW  - Risk assessment
KW  - Risk degree
KW  - Cloud computing
KW  - Maintenance
KW  - Power transformers
KW  - Cloud modeling
KW  - Differential analysis
KW  - Failure mode and effect analysis
KW  - FMEA
KW  - Maintenance strategies
KW  - Risk assessment methods
KW  - Risk degree
KW  - Security and economies
KW  - Risk assessment
PB  - Science Press
SN  - 10036520 (ISSN)
LA  - Chinese
J2  - Gaodianya Jishu
M3  - Article
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 11; Correspondence Address: X. Sun; School of Electrical and Electronics Engineering, Shijiazhuang Tiedao University, Shijiazhuang, 050043, China; email: sunxy1971@126.com; CODEN: GAJIE
ER  -

TY  - CONF
AU  - Corea-Araujo, J.A.
AU  - Gonzalez-Molina, F.
AU  - Martinez, J.A.
AU  - Castro-Aranda, F.
AU  - Barrado-Rodrigo, J.A.
AU  - Guasch-Pesquer, L.
TI  - Single-phase transformer model validation for ferroresonance analysis including hysteresis
PY  - 2015
T2  - IEEE Power and Energy Society General Meeting
VL  - 2015-September
C7  - 7285872
DO  - 10.1109/PESGM.2015.7285872
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-84956857501&doi=10.1109%2fPESGM.2015.7285872&partnerID=40&md5=b6660d73fe277938dd7d3fc57e599184
AD  - Departament d'Enginyeria Electrònica, Elèctrica i Automàtica, Universitat Rovira i Virgili, Av. Països Catalans 26, Tarragona, 43007, Spain
AD  - Departament d'Enginyeria Elèctrica, Universitat Politècnica de Catalunya, Diagonal 647, Barcelona, 08028, Spain
AD  - Grupo de Investigación en Alta Tensión (GRALTA), Escuela de Ingeniería Eléctrica y Electrónica, Universidad Del Valle, Cali, Colombia
AB  - Although several built-in models are currently available in transient tools for transformer representation, users of these tools can develop their own custom-made models. A very common approach when developing new transformer models is to apply the principle of duality. It has been proved that a topologically-correct model of a single-phase transformer when applying duality is the so-called π model. This work is aimed at validating the π model, including hysteresis representation, for modeling single-phase transformers in ferroresonance studies by comparing simulation results and laboratory measurements. © 2015 IEEE.
KW  - EMTP
KW  - Ferroresonance
KW  - Hysteresis
KW  - Non-linear dynamics
KW  - Principle of duality
KW  - Transformer modeling
KW  - Hysteresis
KW  - Magnetic resonance
KW  - Resonance
KW  - EMTP
KW  - Ferroresonance
KW  - Non-linear dynamics
KW  - Principle of duality
KW  - Transformer modeling
KW  - Topology
PB  - IEEE Computer Society
SN  - 19449925 (ISSN); 978-146738040-9 (ISBN)
LA  - English
J2  - IEEE Power Energy Soc. Gen. Meet.
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 6; Conference name: IEEE Power and Energy Society General Meeting, PESGM 2015; Conference date: 26 July 2015 through 30 July 2015; Conference code: 117801
ER  -

TY  - JOUR
AU  - Suzuki, T.
AU  - Miura, N.
AU  - Hojo, R.
AU  - Yanagiba, Y.
AU  - Suda, M.
AU  - Hasegawa, T.
AU  - Miyagawa, M.
AU  - Wang, R.-S.
TI  - Genotoxicity assessment of intravenously injected titanium dioxide nanoparticles in gpt delta transgenic mice
PY  - 2016
T2  - Mutation Research - Genetic Toxicology and Environmental Mutagenesis
VL  - 802
SP  - 30
EP  - 37
DO  - 10.1016/j.mrgentox.2016.03.007
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-84963699417&doi=10.1016%2fj.mrgentox.2016.03.007&partnerID=40&md5=0c5b77abf53dfe6c44468751a1536938
AD  - Division of Health Effects Research, National Institute of Occupational Safety and Health, 6-21-1 Nagao, Tama-ku, Kawasaki, Kanagawa, 214-8585, Japan
AD  - Division of Human Environmental Science, Mount Fuji Research Institute, Yamanashi Prefectural Government, 5597-1 Kenmarubi, Kamiyoshida, Fujiyoshida, Yamanashi, 403-0005, Japan
AD  - Graduate School of Biomedical and Health Sciences, Hiroshima University, 1-2-3 Kasumi, Minami-ku, Hiroshima, 734-8553, Japan
AD  - Department of Sport and Medical Science, Faculty of Medical Technology, Teikyo University, 359, Otsuka, Hachioji, Tokyo, 192-0835, Japan
AB  - Titanium dioxide (TiO2) nanoparticles are increasingly manufactured in large amounts for use in industrial applications such as cosmetics, pigments, foods, and as photo-catalysts. Many in vitro studies have examined the genotoxicity of TiO2 nanomaterials; some of these studies suggest that TiO2 nanoparticles (NPs) are genotoxic. Several in vivo studies have also been reported recently, but the results are inconsistent. In this study, we investigated, using several genotoxicity endpoints, the effects of dispersed TiO2 suspensions following multiple intravenous injections in mice. Male gpt Delta C57BL/6J mice were administered TiO2 NPs at doses of 2, 10 or 50 mg/kg body weight per week for 4 consecutive weeks. Genotoxic effects were then analyzed by the Pig-a gene mutation assay and the micronucleus assay on peripheral blood, and by the alkaline comet, gpt mutation, and Spi- mutation assays on the liver. We also assessed the localization of TiO2 NPs in the liver, by transmission electron microscopy. Administration of TiO2 NPs did not significantly increase any of the following endpoints: frequency of Pig-a mutants (erythrocytes); frequency of micronuclei (reticulocytes); level of DNA damage (liver); frequencies of gpt and Spi- mutants (liver). Most TiO2 NPs in the liver were found in the sinuses and inside Kupffer cells, although some were occasionally observed in liver parenchymal cells. These results indicate that TiO2 NPs do not have genotoxic effects on mouse liver or bone marrow. © 2016 Elsevier B.V.
KW  - DNA damage
KW  - Gpt delta mice
KW  - Micronuclei
KW  - Mutation frequency
KW  - Titanium dioxide
KW  - Animals
KW  - DNA
KW  - DNA Damage
KW  - Male
KW  - Metal Nanoparticles
KW  - Mice
KW  - Mice, Inbred C57BL
KW  - Mice, Transgenic
KW  - Micronucleus Tests
KW  - Titanium
KW  - titanium dioxide nanoparticle
KW  - DNA
KW  - metal nanoparticle
KW  - titanium
KW  - titanium dioxide
KW  - animal experiment
KW  - animal model
KW  - Article
KW  - controlled study
KW  - dispersion
KW  - DNA damage
KW  - erythrocyte
KW  - gene
KW  - gene frequency
KW  - gene mutation
KW  - genotoxicity
KW  - gpt delta mouse
KW  - in vivo study
KW  - liver injury
KW  - liver toxicity
KW  - male
KW  - micronucleus test
KW  - mouse
KW  - mutation rate
KW  - nanotoxicology
KW  - nonhuman
KW  - pig a gene
KW  - priority journal
KW  - reticulocyte
KW  - transmission electron microscopy
KW  - animal
KW  - C57BL mouse
KW  - drug effects
KW  - genetics
KW  - micronucleus test
KW  - transgenic mouse
PB  - Elsevier B.V.
SN  - 13835718 (ISSN)
C2  - 27169374
LA  - English
J2  - Mutat. Res. Genet. Toxicol. Environ. Mutagen.
M3  - Article
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 27; Correspondence Address: R.-S. Wang; Division of Health Effects Research, National Institute of Occupational Safety and Health, Tama-ku, Kawasaki, Kanagawa, 6-21-1 Nagao, 214-8585, Japan; email: wang@h.jniosh.johas.go.jp; CODEN: MRGMF
ER  -

TY  - JOUR
AU  - Liang, Y.
AU  - Li, K.
AU  - Zhao, J.
AU  - Ma, W.
TI  - Priority assessment model of on-line monitoring device allocation for power transformer
PY  - 2016
T2  - Dianwang Jishu/Power System Technology
VL  - 40
IS  - 8
SP  - 2562
EP  - 2569
DO  - 10.13335/j.1000-3673.pst.2016.08.045
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-84981275875&doi=10.13335%2fj.1000-3673.pst.2016.08.045&partnerID=40&md5=5661361027d772bf0f73d89911e727e4
AD  - College of Information and Control Engineering, China University of Petroleum, Qingdao, 266580, Shandong Province, China
AD  - Key Laboratory of Power System Intelligent Allocation and Control (Shandong University) Ministry of Education, Jinan, 250061, Shandong Province, China
AD  - State Grid of China Technology College, Jinan, 250002, Shandong Province, China
AB  - An appropriate way to improve comprehensive benefits of on-line monitoring devices is a new issue in power industry. A priority assessment model of on-line monitoring device allocation for transformer was proposed. The assessment model consisted of device level and system level. The device level was divided into property assessment and operation condition assessment. Details of various assessment methods were described, including device property assessment based on fuzzy analytic hierarchy process (FAHP), operation condition assessment method based on condition assessment technology and system level assessment method based on risk benefit index. An actual grid was utilized to validate the model and its numerical results verified that the proposed assessment model could provide an appropriate on-line monitoring allocation order for transformers and considering multiple aspects related to this problem could give a more comprehensive assessment result than just considering one or two of them. The research in this paper could provide a feasible reference for on-line monitoring device allocation in power industry. © 2016, Power System Technology Press. All right reserved.
KW  - Assessment model
KW  - Device property
KW  - FAHP (fuzzy analytic hierarchy process)
KW  - On-line monitoring devices
KW  - Risk benefit
KW  - Analytic hierarchy process
KW  - Monitoring
KW  - Power transformers
KW  - Voltage measurement
KW  - Assessment models
KW  - Device properties
KW  - Fuzzy analytic hierarchy process
KW  - On-line monitoring device
KW  - Risk benefits
KW  - Risk assessment
PB  - Power System Technology Press
SN  - 10003673 (ISSN)
LA  - Chinese
J2  - Dianwang Jishu
M3  - Article
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 3; CODEN: DIJIE
ER  -

TY  - CONF
AU  - Chen, X.
AU  - Liu, X.
AU  - Gales, M.J.F.
AU  - Woodland, P.C.
TI  - Improving the training and evaluation efficiency of recurrent neural network language models
PY  - 2015
T2  - ICASSP, IEEE International Conference on Acoustics, Speech and Signal Processing - Proceedings
VL  - 2015-August
C7  - 7179003
SP  - 5401
EP  - 5405
DO  - 10.1109/ICASSP.2015.7179003
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-84946051719&doi=10.1109%2fICASSP.2015.7179003&partnerID=40&md5=baf4a51ce570bd55f2b95c5a5a60b56a
AD  - University of Cambridge, Engineering Dept, Trumpington St., Cambridge, CB2 1PZ, United Kingdom
AB  - Recurrent neural network language models (RNNLMs) are becoming increasingly popular for speech recognition. Previously, we have shown that RNNLMs with a full (non-classed) output layer (F-RNNLMs) can be trained efficiently using a GPU giving a large reduction in training time over conventional class-based models (C-RNNLMs) on a standard CPU. However, since test-time RNNLM evaluation is often performed entirely on a CPU, standard F-RNNLMs are inefficient since the entire output layer needs to be calculated for normalisation. In this paper, it is demonstrated that C-RNNLMs can be efficiently trained on a GPU, using our spliced sentence bunch technique which allows good CPU test-time performance (42× speedup over F-RNNLM). Furthermore, the performance of different classing approaches is investigated. We also examine the use of variance regularisation of the softmax denominator for F-RNNLMs and show that it allows F-RNNLMs to be efficiently used in test (56× speedup on a CPU). Finally the use of two GPUs for F-RNNLM training using pipelining is described and shown to give a reduction in training time over a single GPU by a factor of 1.6×. © 2015 IEEE.
KW  - GPU
KW  - language models
KW  - recurrent neural network
KW  - speech recognition
KW  - Audio signal processing
KW  - C (programming language)
KW  - Computational linguistics
KW  - Graphics processing unit
KW  - Program processors
KW  - Recurrent neural networks
KW  - Speech communication
KW  - Class-based
KW  - Language model
KW  - Normalisation
KW  - Output layer
KW  - Regularisation
KW  - Test time
KW  - Training time
KW  - Speech recognition
PB  - Institute of Electrical and Electronics Engineers Inc.
SN  - 15206149 (ISSN); 978-146736997-8 (ISBN)
LA  - English
J2  - ICASSP IEEE Int Conf Acoust Speech Signal Process Proc
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 27; Conference name: 40th IEEE International Conference on Acoustics, Speech, and Signal Processing, ICASSP 2015; Conference date: 19 April 2014 through 24 April 2014; Conference code: 116006; CODEN: IPROD
ER  -

TY  - CONF
AU  - Chen, J.Y.
AU  - Wang, Z.C.
AU  - Wang, J.L.
TI  - Language model for assessing author similarity
PY  - 2015
T2  - Future Communication Technology and Engineering - Proceedings of the 2014 International Conference on Future Communication Technology and Engineering, FCTE 2014
SP  - 175
EP  - 178
DO  - 10.1201/b18331-41
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-84951782534&doi=10.1201%2fb18331-41&partnerID=40&md5=aa3d467d4ccb3e0a622d134d7da2dfdc
AD  - Engineering Research Centre of the Ministry of Education on Enterprise Digitalization Technology, Tongji University, Shanghai, China
AB  - Currently, it is crucial for researchers to know if others have similar research objectives. Nevertheless, the identification of authors sharing the same motivations and interests may be complex, as the amount of research publications is growing rapidly. Furthermore, information about research papers is often fragmented and incomplete. The incomplete information, or metadata, in this paper refers to abstracts, keywords, journals, organizations, and so on. Thus, this paper analyses the metadata information about an author to find out similar authors. Author Similarity Model, a novel language model which is evolved from Author Topic Model, has been developed in this paper. For author similarity modeling, a four-dimensional vector has been set up to describe every author. Therefore an author’s neighbours (a group of people who have the same direction of research) can be found out by calculating similarity between vectors. © 2015 Taylor & Francis Group.
KW  - Metadata
KW  - Calculating similarities
KW  - Dimensional vectors
KW  - Incomplete information
KW  - Metadata information
KW  - Paper analysis
KW  - Research objectives
KW  - Research papers
KW  - Similarity models
KW  - Computational linguistics
A2  - Chan K.
PB  - CRC Press/Balkema
SN  - 978-113802777-0 (ISBN)
LA  - English
J2  - Future Commun. Technol. Eng. - Proc. Int. Conf. Future Commun. Technol. Eng. FCTE
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 0; Conference name: International Conference on Future Communication Technology and Engineering, FCTE 2014; Conference date: 16 November 2014 through 17 November 2014; Conference code: 156959
ER  -

TY  - JOUR
AU  - Al-Masoudi, A.F.R.
AU  - Al-Obeidi, H.S.R.
TI  - Smoothing techniques evaluation of N-gram language model for arabic OCR postprocessing
PY  - 2015
T2  - Journal of Theoretical and Applied Information Technology
VL  - 82
IS  - 3
SP  - 432
EP  - 439
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-84952769572&partnerID=40&md5=b90f5945c65e6c0c7c2d99429f83eac6
AD  - Department of Computer Science, University of Baghdad, Iraq
AD  - Department of Computer Science, University of Technology, Iraq
AB  - N-gram language model is used to correct the errors that resulted from Optical character recognition process. However, the major problem facing N-gram language modeling is that it depends on finite training corpus. Therefore, some words will be missed from the corpus. They are called unknown words. If any Ngram is missing, then the language model will assign a probability of zero to it. Smoothing is a task used to prevent assigning zero probability for missing N-gram in corpus. Each smoothing technique suffers different limitations, and selecting the appropriate smoothing technique depends on where it will be used. Therefore, the purpose of this study is to test these techniques on Arabic dataset, and determines which one of the techniques is the best for this language. This study evaluates the performance of four main smoothing techniques. The experimental results show that all smoothing techniques can reduce error rate. However, the best among them is the Katz Backoff technique. © 2005 - 2015 JATIT & LLS. All rights reserved.
KW  - Arabic language
KW  - N-gram language model
KW  - OCR
KW  - Performance evaluation
KW  - Smoothing techniques
PB  - Asian Research Publishing Network
SN  - 19928645 (ISSN)
LA  - English
J2  - J. Theor. Appl. Inf. Technol.
M3  - Article
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 4
ER  -

TY  - JOUR
AU  - Zhou, Q.
AU  - Xu, Z.
AU  - Liao, R.
AU  - Zhang, Y.
AU  - Zheng, B.
TI  - Insulation condition assessment of power transformer bushing based on cloud model and kernel vector space model
PY  - 2013
T2  - Gaodianya Jishu/High Voltage Engineering
VL  - 39
IS  - 5
SP  - 1101
EP  - 1106
DO  - 10.3969/j.issn.1003-6520.2013.05.012
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-84878909132&doi=10.3969%2fj.issn.1003-6520.2013.05.012&partnerID=40&md5=38943ba7012cf30b3af456d164a7893c
AD  - State Key Laboratory of Power Transmission Equipment and System Security and New Technology, Chongqing University, Chongqing 400030, China
AB  - In order to reduce uncertain factors affecting insulation condition assessment of power transformer bushing, we proposed a novel condition assessment method. The randomness and fuzziness of evaluation index classification boundary are fully considered in the method. This combined weighing method includes the objective weight and the subjective weight decided by cloud model and unascertained theory, respectively. A kernel vector space model is established, and the kernel function is used to map the input data into the high-dimensional feature space, in which the index-directed line segment of data sample and ideal directed line segment of insulation grade standard sample are defined. By calculating the weighted cosine value between directed line segment in each data sample and ideal directed line segment in grade standard sample, the approaching degree is obtained. By using the approaching degree, the insulation condition assessment is transformed into the pattern recognition in vector space, from which the insulation condition grade is obtained. An actual example shows that, in the first test of a bushing, its insulation condition is close to the normal state in the largest degree, meaning that it is in normal state; yet in the second and third tests, it is close to the fault state in the largest degree, meaning that it is in fault state.
KW  - Approach degree
KW  - Cloud model
KW  - Combination weighing
KW  - Insulation condition assessment
KW  - Kernel vector space model
KW  - Power transformer bushing
KW  - Bushings
KW  - Pattern recognition
KW  - Power transformers
KW  - Vector spaces
KW  - Weighing
KW  - Approach degrees
KW  - Cloud models
KW  - Combination weighing
KW  - Insulation conditions
KW  - Kernel vector space models
KW  - Transformer bushings
KW  - Insulation
SN  - 10036520 (ISSN)
LA  - Chinese
J2  - Gaodianya Jishu
M3  - Article
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 31; Correspondence Address: Q. Zhou; State Key Laboratory of Power Transmission Equipment and System Security and New Technology, Chongqing University, Chongqing 400030, China; email: zhouquan@cqu.edu.cn; CODEN: GAJIE
ER  -

TY  - CONF
AU  - Qiao, G.H.
AU  - Guo, X.J.
AU  - Wu, L.M.
AU  - Liu, H.L.
AU  - Ren, Z.
AU  - Bai, N.
TI  - Risk assessment of power transformer life cycle cost based on extensible matter-element model
PY  - 2014
T2  - Applied Mechanics and Materials
VL  - 644-650
SP  - 3538
EP  - 3541
DO  - 10.4028/www.scientific.net/AMM.644-650.3538
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-84915750800&doi=10.4028%2fwww.scientific.net%2fAMM.644-650.3538&partnerID=40&md5=ddcd82a72fee62be4dab12d8dda09edb
AD  - State Grid Hebei Electric Power Company, Shijiazhuang, China
AD  - School of Electrical and Electronic Engineering, North China Electric Power University, Baoding, China
AB  - Making assessment of risk factors of power transformer life cycle cost modeling is an important mean of improving the scientificity of transformer life cycle cost management. Considering the risk factors of transformer life cycle cost, this paper presents risk assessment index system of transformer life cycle cost, applying matter-element model and extension analysis theory to quantify the qualitative indexes in order to assess the risk. Combined with an example, the paper quantifies the uncertain factors of power transformer life cycle cost management in order to build the life cycle cost risk assessment system. It realizes the risk rating of the transformer cost assessment, getting the key risk factors which affect transformer cost so that we can put forward targeted control strategies according to various risk factors in practical engineering. © (2014) Trans Tech Publications, Switzerland.
KW  - Index system
KW  - Life cycle cost
KW  - Matter-element model
KW  - Risk assessment
KW  - Cost benefit analysis
KW  - Cost engineering
KW  - Costs
KW  - Life cycle
KW  - Machine tools
KW  - Power transformers
KW  - Assessment index system
KW  - Assessment system
KW  - Control strategies
KW  - Extension analysis
KW  - Index systems
KW  - Lifecycle costs
KW  - Matter-element model
KW  - Practical engineering
KW  - Risk assessment
A2  - Wang Z.
A2  - Guo L.
A2  - Tan T.
A2  - Yang D.
A2  - Yang D.
A2  - Yang K.
A2  - Yang D.
A2  - Yang D.
A2  - Yang D.
PB  - Trans Tech Publications Ltd
SN  - 16609336 (ISSN); 978-303835246-4 (ISBN)
LA  - English
J2  - Appl. Mech. Mater.
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 1; Conference name: International Conference on Machine Tool Technology and Mechatronics Engineering, ICMTTME 2014; Conference date: 22 June 2014 through 23 June 2014; Conference code: 107729
ER  -

TY  - JOUR
AU  - Horibata, K.
AU  - Ukai, A.
AU  - Kimoto, T.
AU  - Suzuki, T.
AU  - Kamoshita, N.
AU  - Masumura, K.
AU  - Nohmi, T.
AU  - Honma, M.
TI  - Evaluation of in vivo genotoxicity induced by N-ethyl-N-nitrosourea, benzo[a]pyrene, and 4-nitroquinoline-1-oxide in the Pig-a and gpt assays
PY  - 2013
T2  - Environmental and Molecular Mutagenesis
VL  - 54
IS  - 9
SP  - 747
EP  - 754
DO  - 10.1002/em.21818
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-84887182267&doi=10.1002%2fem.21818&partnerID=40&md5=b9e924050d9e5dfdbd93e70fe168b2b9
AD  - Division of Genetics and Mutagenesis, National Institute of Health Sciences, Setagaya-ku, Tokyo, Japan
AD  - TEIJIN Pharma Ltd, Tokyo, Japan
AB  - The recently developed Pig-a mutation assay is based on flow cytometric enumeration of glycosylphosphatidylinositol (GPI) anchor-deficient red blood cells caused by a forward mutation in the Pig-a gene. Because the assay can be conducted in nontransgenic animals and the mutations accumulate with repeat dosing, we believe that the Pig-a assay could be integrated into repeat-dose toxicology studies and provides an alternative to transgenic rodent (TGR) mutation assays. The capacity and characteristics of the Pig-a assay relative to TGR mutation assays, however, are unclear. Here, using transgenic gpt delta mice, we compared the in vivo genotoxicity of single oral doses of N-ethyl-N-nitrosourea (ENU, 40 mg/kg), benzo[a]pyrene (BP, 100 and 200 mg/kg), and 4-nitroquinoline-1-oxide (4NQO, 50 mg/kg) in the Pig-a (peripheral blood) and gpt (bone marrow and liver) gene mutation assays. Pig-a assays were conducted at 2, 4, and 7 weeks after the treatment, while gpt assays were conducted on tissues collected at the 7-week terminal sacrifice. ENU increased both Pig-a and gpt mutant frequencies (MFs) at all sampling times, and BP increased MFs in both assays but the Pig-a MFs peaked at 2 weeks and then decreased. Although 4NQO increased gpt MFs in the liver, only weak, nonsignificant increases (two- or threefold above control) were detected in the bone marrow in both the Pig-a and the gpt assay. These findings suggest that further studies are needed to elucidate the kinetics of the Pig-a mutation assay in order to use it as an alternative to the TGR mutation assay. © 2013 Wiley Periodicals, Inc.
KW  - Genotoxicity
KW  - Glycosylphosphatidylinositol anchor
KW  - Red blood cells
KW  - Transgenic rodent mutation assays
KW  - 4-Nitroquinoline-1-oxide
KW  - Animals
KW  - Benzo(a)pyrene
KW  - Biological Assay
KW  - DNA Damage
KW  - Erythrocytes
KW  - Escherichia coli Proteins
KW  - Ethylnitrosourea
KW  - Flow Cytometry
KW  - Liver
KW  - Male
KW  - Mice
KW  - Mice, Inbred C57BL
KW  - Mice, Transgenic
KW  - Mutagenicity Tests
KW  - Mutagens
KW  - Mutation
KW  - Pentosyltransferases
KW  - Animalia
KW  - Mus
KW  - Rodentia
KW  - Suidae
KW  - genotoxicity
KW  - glycosylphosphatidylinositol anchor
KW  - red blood cells
KW  - transgenic rodent mutation assays
KW  - 4 nitroquinoline 1 oxide
KW  - benzo[a]pyrene
KW  - ethylnitrosourea
KW  - glycosylphosphatidylinositol
KW  - gpt delta protein
KW  - Pig a protein
KW  - unclassified drug
KW  - animal cell
KW  - animal experiment
KW  - animal model
KW  - animal tissue
KW  - article
KW  - bone marrow
KW  - controlled study
KW  - erythrocyte
KW  - flow cytometry
KW  - gene frequency
KW  - gene mutation
KW  - genotoxicity
KW  - in vivo study
KW  - liver
KW  - mouse
KW  - nonhuman
KW  - protein determination
KW  - sampling
KW  - toxicology
SN  - 10982280 (ISSN)
C2  - 24105957
LA  - English
J2  - Environ. Mol. Mutagen.
M3  - Article
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 23; Correspondence Address: K. Horibata; Division of Genetics and Mutagenesis, National Institute of Health Sciences, Tokyo 158-8501, 1-18-1 Kamiyoga, Setagaya-ku, Japan; email: horibata@nihs.go.jp; CODEN: EMMUE
ER  -

TY  - CONF
AU  - Wang, P.
AU  - Sun, R.
AU  - Zhao, H.
AU  - Yu, K.
TI  - A new word language model evaluation metric for character based languages
PY  - 2013
T2  - Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)
VL  - 8202 LNAI
SP  - 315
EP  - 324
DO  - 10.1007/978-3-642-41491-6_29
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-84893055761&doi=10.1007%2f978-3-642-41491-6_29&partnerID=40&md5=9827c7b351454b96cfa2cf738280da5b
AD  - Institute of Intelligent Human-Machine Interaction, Department of Computer Science and Engineering, Shanghai Jiao Tong University, 200240, Shanghai, China
AB  - Perplexity is a widely used measure to evaluate word prediction power of a word-based language model. It can be computed independently and has shown good correlation with word error rate (WER) in speech recognition. However, for character based languages, character error rate (CER) is commonly used instead of WER as the measure for speech recognition, although language model is still word based. Due to the fact that different word segmentation strategies may result in different word vocabulary for the same text corpus, in many cases, word-based perplexity is incompetent to evaluate the combined effect of word segmentation and language model training to predict final CER. In this paper, a new word-based language model evaluation measure is proposed to account for the effect of word segmentation and the goal of predicting CER. Experiments were conducted on Chinese speech recognition. Compared to the traditional word-based perplexity, the new measure is more robust to word segmentation and shows much more consistent correlation with CER in a large vocabulary continuous Chinese speech recognition task. © Springer-Verlag 2013.
KW  - Character error rate
KW  - Language model evaluation
KW  - Perplexity
KW  - Forecasting
KW  - Natural language processing systems
KW  - Speech recognition
KW  - Character error rates
KW  - Chinese speech recognition
KW  - Good correlations
KW  - Language model
KW  - Large vocabulary
KW  - Perplexity
KW  - Word prediction
KW  - Word segmentation
KW  - Computational linguistics
SN  - 16113349 (ISSN); 978-364241490-9 (ISBN)
LA  - English
J2  - Lect. Notes Comput. Sci.
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 11; Conference name: 12th China National Conference on Chinese Computational Linguistics, CCL 2013 and 1st International Symposium on Natural Language Processing Based on Naturally Annotated Big Data, NLP-NABD 2013; Conference date: 10 October 2013 through 12 October 2013; Conference code: 102303
ER  -

TY  - CONF
AU  - Liang, Y.
AU  - Li, K.-J.
AU  - Niu, L.
AU  - Zhao, J.
AU  - Lee, W.-J.
AU  - Ding, Z.
AU  - Ren, J.
AU  - Gao, H.
TI  - An integrated three-level transformer condition assessment model based on optimal weights and uncertainty theory
PY  - 2013
T2  - Conference Record - IAS Annual Meeting (IEEE Industry Applications Society)
C7  - 6682578
DO  - 10.1109/IAS.2013.6682578
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-84893365541&doi=10.1109%2fIAS.2013.6682578&partnerID=40&md5=2d8e6a2f24e11e0ce547b5f8c4de9462
AD  - Key Laboratory of Power System Intelligent Dispatch and Control, Ministry of Education, Shandong University, Jinan, 250061, China
AD  - State Grid of China Technology College, Jinan, 250002, China
AD  - Energy Systems Research Center, University of Texas at Arlington, Arlington, TX 76019, Box 19048, United States
AB  - This paper proposes a three-level transformer condition assessment model based on matter-element cloud theory and evidential reasoning decision-making theory. Both quantitative and qualitative factors are considered in the model. Matter-element cloud model is utilized to integrate the quantitative indices with their optimal weights to assess the condition of items, including Dissolved Gas Analysis(DGA), electrical testing and oil testing in the first level in the form of association degrees with state grades to generate the original basic probability assignments for the second-level model. D-S evidential reasoning decision-making model is utilized in the second level to assess the condition of systems including quantitative system and qualitative system and in the third level to assess condition of the overall transformer. Both fuzziness and randomness are taken into consideration in this model. Experimental cases confirm that the assessing model is capable of offering an overall assessment of the observed transformer condition and assisting the maintenance strategy development. © 2013 IEEE.
KW  - condition assessment
KW  - D-S evidential reasoning
KW  - matter-element cloud
KW  - optimal weight
KW  - three-level model
KW  - Decision making
KW  - Industrial applications
KW  - Testing
KW  - Condition assessments
KW  - Evidential reasoning
KW  - Matter-element
KW  - Optimal weight
KW  - Three-level models
KW  - Optimization
SN  - 01972618 (ISSN); 978-146735202-4 (ISBN)
LA  - English
J2  - Conf Rec IAS Annu Meet
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 4; Conference name: 2013 IEEE Industry Applications Society Annual Meeting, IAS 2013; Conference date: 6 October 2013 through 11 October 2013; Conference code: 102342; CODEN: CIASD
ER  -

TY  - CONF
AU  - Jacob, J.
AU  - Mon, N.D.
AU  - Preetha, P.
TI  - Experimental validation of thermal model of unfilled and nano filled transformer oils
PY  - 2017
T2  - Asia-Pacific Power and Energy Engineering Conference, APPEEC
VL  - 2017-November
SP  - 1
EP  - 5
DO  - 10.1109/APPEEC.2017.8308986
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85045950151&doi=10.1109%2fAPPEEC.2017.8308986&partnerID=40&md5=42f86a631da168245046a53ffdb655b5
AD  - Department of Electrical Engineering, National Institute of Technology, Calicut, India
AB  - The thermal properties of a transformer insulating oil determines the loading capacity and working life of a transformer. Nanotechnology implementation in liquid dielectrics has resulted in nanofluids with improved thermal and electrical properties. The paper details upon an electro-thermal analogous model to find the thermal resistance and thermal capacitance of unfilled and Aluminum Nitride nanoparticle filled transformer oil at different particle concentration. The simulation of the thermal model for unfilled and filled insulating fluids has been done using Comsol Multiphysics and the results have been validated experimentally. Both the simulation and experimental results show a considerable reduction in the thermal resistance and thermal capacitance of the filled transformer oil. An optimal nanoparticle concentration of 0.20 percentage by weight provides the desired thermal characteristics without compromising on the stability of the nanofluid. The results indicate improved thermal properties and hence longer transformer life for nanocomposite filled transformer oil than the unfilled transformer oil. © 2017 IEEE.
KW  - Aluminum nitride
KW  - Capacitance
KW  - Dielectric properties of liquids
KW  - Electric transformer testing
KW  - Nanofluidics
KW  - Nanoparticles
KW  - Power transformers
KW  - Thermodynamic properties
KW  - Thermography (temperature measurement)
KW  - Comsol multiphysics
KW  - Experimental validations
KW  - Nanoparticle concentrations
KW  - Nitride nanoparticles
KW  - Particle concentrations
KW  - Thermal and electrical properties
KW  - Thermal capacitance
KW  - Thermal characteristics
KW  - Oil filled transformers
PB  - IEEE Computer Society
SN  - 21574839 (ISSN); 978-153861379-5 (ISBN)
LA  - English
J2  - Asia-Pacific Pow. Energy Eng. Conf., APPEEC
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 1; Conference name: 2017 IEEE PES Asia-Pacific Power and Energy Engineering Conference, APPEEC 2017; Conference date: 8 November 2017 through 10 November 2017; Conference code: 135170
ER  -

TY  - JOUR
AU  - Yang, J.
AU  - Dong, Y.
AU  - Qu, Z.
AU  - Liu, Z.
AU  - Shen, S.
TI  - Condition assessment for transformer based on interval weight and improved cloud model
PY  - 2016
T2  - Dianli Xitong Baohu yu Kongzhi/Power System Protection and Control
VL  - 44
IS  - 23
SP  - 102
EP  - 109
DO  - 10.7667/PSPC152022
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85006423744&doi=10.7667%2fPSPC152022&partnerID=40&md5=9a106d130cb63a461a029e7d6cf4a22f
AD  - School of Information Engineering, Northeast Electric Power University, Jilin, 132012, China
AD  - State Grid Hebei Electric Company Information &Telecommunication Branch, Shijiazhuang, 050000, China
AD  - Institute of Electrical and Electronic Engineering, Harbin University of Science and Technology, Harbin, 150080, China
AB  - For the randomness and fuzziness problem of condition level boundary information in the power transformers, a new assessment method based on normal cloud theory is proposed. Given a full consideration to the limitation of data use for condition assessment, the limited data collected of the power transformers would be handled to establish the data normal cloud. For the issue of power transformers level boundary ambiguity, it proposes to properly expand each level and establish the level normal cloud. Depending on the different probabilities of cloud droplets in clouds, the cloud association degree is then calculated between the data normal cloud and the level normal cloud. Secondly, the operation data of power transformer is represented the range form. As for volatility for each interval data of performance indicators, it calculates the variance and average interval data and gives different weights index. The result of condition level of the power transformers is finally obtained. Through the analysis of a power transformer station operating data, the simulation example demonstrates that proposed method is efficient and practical to apply to assess the power transformers. © 2016, Power System Protection and Control Press. All right reserved.
KW  - Association degree
KW  - Condition assessment
KW  - Interval weight
KW  - Normal cloud model
KW  - Power transformer
PB  - Power System Protection and Control Press
SN  - 16743415 (ISSN)
LA  - Chinese
J2  - Dianli Xitong Baohu yu Kongzhi
M3  - Article
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 10; Correspondence Address: Y. Dong; State Grid Hebei Electric Company Information &Telecommunication Branch, Shijiazhuang, 050000, China; email: 358368724@qq.com
ER  -

TY  - CONF
AU  - Hellendoorn, V.J.
AU  - Devanbu, P.T.
AU  - Bacchelli, A.
TI  - Will They like this? Evaluating code contributions with language models
PY  - 2015
T2  - IEEE International Working Conference on Mining Software Repositories
VL  - 2015-August
C7  - 7180076
SP  - 157
EP  - 167
DO  - 10.1109/MSR.2015.22
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-84957106540&doi=10.1109%2fMSR.2015.22&partnerID=40&md5=4335b840da2b43f49d42367c552d5ffc
AD  - SORCERERS Software Engineering Research Group, Delft University of Technology, Netherlands
AD  - Department of Computer Science, University of California, Davis, CA, United States
AB  - Popular open-source software projects receive and review contributions from a diverse array of developers, many of whom have little to no prior involvement with the project. A recent survey reported that reviewers consider conformance to the project's code style to be one of the top priorities when evaluating code contributions on Github. We propose to quantitatively evaluate the existence and effects of this phenomenon. To this aim we use language models, which were shown to accurately capture stylistic aspects of code. We find that rejected change sets do contain code significantly less similar to the project than accepted ones, furthermore, the less similar change sets are more likely to be subject to thorough review. Armed with these results we further investigate whether new contributors learn to conform to the project style and find that experience is positively correlated with conformance to the project's code style. © 2015 IEEE.
KW  - Code review
KW  - Language model
KW  - Pull request
KW  - Codes (symbols)
KW  - Computational linguistics
KW  - Open source software
KW  - Software engineering
KW  - Code review
KW  - Language model
KW  - Open source software projects
KW  - Pull request
KW  - Open systems
PB  - IEEE Computer Society
SN  - 21601852 (ISSN); 978-076955594-2 (ISBN)
LA  - English
J2  - IEEE Int. Working Conf. Min Softw. Repos.
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 52; Conference name: 12th Working Conference on Mining Software Repositories, MSR 2015; Conference date: 16 May 2015 through 17 May 2015; Conference code: 117060
ER  -

TY  - JOUR
AU  - Zecchino, A.
AU  - Hu, J.
AU  - Coppo, M.
AU  - Marinelli, M.
TI  - Experimental testing and model validation of a decoupled-phase on-load tap-changer transformer in an active network
PY  - 2016
T2  - IET Generation, Transmission and Distribution
VL  - 10
IS  - 15
SP  - 3834
EP  - 3843
DO  - 10.1049/iet-gtd.2016.0352
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-84996528029&doi=10.1049%2fiet-gtd.2016.0352&partnerID=40&md5=56099c8145e3a6454d877097a7e05940
AD  - Department of Electrical Engineering, Technical University of Denmark, Roskilde, Denmark
AD  - Department of Electrical Industrial Engineering, University of Padova, Padova, Italy
AB  - Owing to the increasing penetration of single-phase small generation units and electric vehicles connected to distribution grids, system operators are facing challenges related to local unbalanced voltage rise or drop issues, which may lead to a violation of the allowed voltage band. To address this problem, distribution transformers with on-load tapping capability are under development. This study presents model and experimental validation of a 35 kVA three-phase power distribution transformer with independent on-load tap-changer control capability on each phase. With the purpose of investigating and evaluating its effectiveness under different operative conditions, appropriate scenarios are defined and tested considering both balanced and unbalanced situations, also in case of reverse power flow. The experimental setup is built starting from an analysis of a Danish distribution network, in order to reproduce the main feature of an unbalanced grid. The experimental activities are recreated in by carrying out dynamics simulation studies, aiming at validating the implemented models of both the transformer as well as the other grid components. Phase-neutral voltages' deviations are limited, proving the effectiveness of the phase-independent tap operations. Furthermore, minor deviations of the results from simulations and experiments confirm that all the system components have been properly modelled. © 2016 The Institution of Engineering and Technology.
KW  - Active networks
KW  - Electric load flow
KW  - Electric transformers
KW  - Load testing
KW  - Voltage control
KW  - Distribution transformer
KW  - Dynamics simulation
KW  - Experimental activities
KW  - Experimental testing
KW  - Experimental validations
KW  - On- load tap changers
KW  - On-load tap changer transformers
KW  - Power distribution transformer
KW  - Electric transformer testing
PB  - Institution of Engineering and Technology
SN  - 17518687 (ISSN)
LA  - English
J2  - IET Gener. Transm. Distrib.
M3  - Article
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 14; Correspondence Address: A. Zecchino; Department of Electrical Engineering, Technical University of Denmark, Roskilde, Denmark; email: antozec@elektro.dtu.dk
ER  -

TY  - JOUR
AU  - Coddé, J.
AU  - Van Der Veken, W.
AU  - Baelmans, M.
TI  - Assessment of a hydraulic network model for zig-zag cooled power transformer windings
PY  - 2015
T2  - Applied Thermal Engineering
VL  - 80
SP  - 220
EP  - 228
DO  - 10.1016/j.applthermaleng.2015.01.063
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-84922717974&doi=10.1016%2fj.applthermaleng.2015.01.063&partnerID=40&md5=c8626083cdef1c341838dfcfeedc8ae9
AD  - University of Leuven, Division of Applied Mechanics and Energy Conversion (TME), Celestijnenlaan 300-bus 2421, Leuven, 3001, Belgium
AD  - CG Power Systems Mechelen, Antwerpsesteenweg 167, Mechelen, 2800, Belgium
AB  - The prediction of mass flow distribution is a first, though crucial, step in the thermal design of zig-zag cooled power transformer windings. Typically this prediction is based on thermo-hydraulic network models, which critically depend on the applied correlations. In this paper new correlations for flow through elbows and for dividing/merging flow in T-junctions are numerically extracted from dedicated CFD studies and applied to a case study. It is shown that the new correlations are superior for the prediction of the mass flow distribution for this test case in comparison to correlations thus far available in literature. ©2015 Elsevier Ltd. All rights reserved.
KW  - CFD
KW  - Network model
KW  - Oil cooling
KW  - Power transformer
KW  - Pressure drop correlation
KW  - T-junction
KW  - Computational fluid dynamics
KW  - Forecasting
KW  - Mass transfer
KW  - Oil filled transformers
KW  - Power transformers
KW  - Winding
KW  - Hydraulic networks
KW  - Network modeling
KW  - New correlations
KW  - Oil cooling
KW  - Pressure drop correlation
KW  - T junctions
KW  - Thermal designs
KW  - Thermo-hydraulic
KW  - Transformer windings
PB  - Elsevier Ltd
SN  - 13594311 (ISSN)
LA  - English
J2  - Appl Therm Eng
M3  - Article
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 45; Correspondence Address: J. Coddé; University of Leuven, Division of Applied Mechanics and Energy Conversion (TME), Leuven, Celestijnenlaan 300-bus 2421, 3001, Belgium; email: joris.codde@kuleuven.be; CODEN: ATENF
ER  -

TY  - CONF
AU  - Peppanen, J.
AU  - Grijalva, S.
AU  - Reno, M.J.
AU  - Broderick, R.J.
TI  - Secondary circuit model creation and validation with AMI and transformer measurements
PY  - 2016
T2  - NAPS 2016 - 48th North American Power Symposium, Proceedings
C7  - 7747867
DO  - 10.1109/NAPS.2016.7747867
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85006728542&doi=10.1109%2fNAPS.2016.7747867&partnerID=40&md5=bb48ac5c0e7d634fe526485974347688
AD  - School of Electrical and Computer Engineering, Georgia Institute of Technology, Atlanta, GA, United States
AD  - Sandia National Laboratories, Albuquerque, NM, United States
AB  - Accurate distribution secondary circuit models are needed to effectively monitor and coordinate the distributed energy resources located in the secondary circuits and to enhance overall distribution system operations and planning. Accurate secondary models are also needed to fully leverage the measurement data received from smart meters and distributed energy resources at the customer premises. This paper discusses approaches for creating distribution system secondary low-voltage circuit models utilizing smart meter measurements. This paper also discusses methods to model secondary circuits when the loads and distributed energy resources are only partially metered. The presented methods are demonstrated on a real distribution secondary circuit with smart meter measurements and transformer low voltage measurements. Practical challenges related to real measurement data are discussed. © 2016 IEEE.
KW  - Load Modeling
KW  - Power Distribution
KW  - Power System Measurements
KW  - Smart Grids
KW  - Circuit simulation
KW  - Circuit theory
KW  - Electric load management
KW  - Electric power system measurement
KW  - Electric power transmission networks
KW  - Energy resources
KW  - Smart meters
KW  - Timing circuits
KW  - Distributed Energy Resources
KW  - Distribution systems
KW  - Load modeling
KW  - Low voltage circuits
KW  - Power distributions
KW  - Real distribution
KW  - Real measurements
KW  - Smart grid
KW  - Smart power grids
A2  - Gao D.W.
A2  - Zhang J.
A2  - Khodaei A.
A2  - Muljadi E.
PB  - Institute of Electrical and Electronics Engineers Inc.
SN  - 978-150903270-9 (ISBN)
LA  - English
J2  - NAPS - N. Am. Power Symp., Proc.
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 5; Conference name: 48th North American Power Symposium, NAPS 2016; Conference date: 18 September 2016 through 20 September 2016; Conference code: 124912
ER  -

TY  - JOUR
AU  - Liang, Y.
AU  - Li, K.-J.
AU  - Niu, L.
AU  - Zhao, J.
AU  - Lee, W.-J.
TI  - Priority assessment model of on-line monitoring devices investment for power transformers
PY  - 2016
T2  - Journal of Electrical Engineering
VL  - 16
IS  - 1
SP  - 107
EP  - 115
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-84971467964&partnerID=40&md5=0fd0f01387b1378d22c4d439b3c3b817
AD  - School of Electrical Engineering, Shandong University, 17923 Jingshi Rd., Jinan, 250061, China
AD  - State Grid of China Technology College, 500 Erhuan Nan Lu, Jinan, 250002, China
AD  - Energy Systems Research Center, University of Texas at Arlington, 416 Yates Street, Arlington, 76019, TX, United States
AB  - Finding an appropriate way to improve the investment comprehensive benefits for on-line monitoring is a new issue for power industry. In this paper, a priority assessment model for transformer on-line monitoring is proposed. The assessment model consists of device level and system level. The device level is divided into property assessment and operation assessment. The details of various assessment methods were described in the following sections, including device property assessment based on fuzzy analytic hierarchy process(FAHP), operation condition assessment method based on condition assessment technology and system level assessment method based on risk benefits index. An actual grid is utilized to validate the model and the numerical results illustrate that: the proposed assessment model can provide an appropriate on-line monitoring investment order for transformers. It also verifies that considering multiple aspects related to the target problem could give a more comprehensive assessment result than just considering just one or two of them. This paper provides a feasible solution to achieve more investment benefits for transformer online monitoring, which can provide on-line monitoring investment references for power industry.
KW  - Device property
KW  - FAHP
KW  - On-line monitoring
KW  - Operation Condition
KW  - Priority assessment
KW  - Risk benefit
PB  - Universitatea Politehnica din Timisoara
SN  - 15824594 (ISSN)
LA  - English
J2  - J. Electr. Eng.
M3  - Article
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 0; Correspondence Address: K.-J. Li; School of Electrical Engineering, Shandong University, Jinan, 17923 Jingshi Rd., 250061, China; email: lkjun@sdu.edu.cn
ER  -

TY  - CONF
AU  - Costinas, S.
AU  - Tristiu, I.
AU  - Sava, G.N.
AU  - Opris, I.
AU  - Tanasiev, V.
TI  - A new mathematical model for assessing optimization decisions of the loading factor flowing through substation transformers
PY  - 2015
T2  - 2015 IEEE 15th International Conference on Environment and Electrical Engineering, EEEIC 2015 - Conference Proceedings
C7  - 7165503
SP  - 2109
EP  - 2114
DO  - 10.1109/EEEIC.2015.7165503
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-84943193748&doi=10.1109%2fEEEIC.2015.7165503&partnerID=40&md5=dee8b4ca7fe8f986c872228caf7c81f8
AD  - Faculty of Power Engineering, University Politehnica of Bucharest, Bucharest, Romania
AB  - The paper proposes a new mathematical model used to determine the optimum loading for power system substations equipped with only one transformer. Because of the cyclic way of the planning process, the capacity and density of electrical substations are influenced by the technological progress and previous adopted measures. Operations knowledge comes in handy in day by day activities but only strategic knowledge confers electric companies an edge. In comparison with the methods used until now, the proposed model takes into consideration aspects related to operation, monitoring and maintenance costs throughout the lifetime of transformers. The proposed model is applied to a 110 kV/MV transformer with different rated powers of 2.5, 16, 80, and 400 MVA considered for an electrical distribution grid. The goal is following tendencies instead of on-point. © 2015 IEEE.
KW  - electrical distribution substation
KW  - mathematical model
KW  - optimum loading
KW  - power losses
KW  - power transformer
KW  - Mathematical models
KW  - Power transformers
KW  - Transformer substations
KW  - Electrical distribution
KW  - Electrical substations
KW  - New mathematical model
KW  - Optimum loading
KW  - Power-losses
KW  - Strategic knowledge
KW  - Substation transformers
KW  - Technological progress
KW  - Loading
PB  - Institute of Electrical and Electronics Engineers Inc.
SN  - 978-147997993-6 (ISBN)
LA  - English
J2  - IEEE Int. Conf. Environ. Electr. Eng., EEEIC - Conf. Proc.
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 4; Conference name: 15th IEEE International Conference on Environment and Electrical Engineering, EEEIC 2015; Conference date: 10 June 2015 through 13 June 2015; Conference code: 113917
ER  -

TY  - JOUR
AU  - Nichols, P.
AU  - Lucke, T.
TI  - Field evaluation of the nutrient removal performance of a gross pollutant trap (GPT) in Australia
PY  - 2016
T2  - Sustainability (Switzerland)
VL  - 8
IS  - 7
DO  - 10.3390/su8070669
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85136572659&doi=10.3390%2fsu8070669&partnerID=40&md5=ba403f3873506cc1b1321fb414ec6f93
AD  - Stormwater Research Group, University of the Sunshine Coast, 90 Sippy Downs Drive, Sippy Downs, 4558, QLD, Australia
AB  - Field testing of a proprietary stormwater treatment device (GPT) was undertaken over a one year period at a commercial site located in Sippy Downs, Queensland. The focus of the study was primarily on evaluating the effectiveness of the GPT device in removing pollution in the form of nutrients (Total Suspended Solids, Total Nitrogen, Total Phosphorus) from stormwater runoff. Water quality analysis was performed on water samples taken from the inflow and outflow of the GPT during 15 natural rainfall events. A new testing protocol was developed to ensure a comprehensive investigation of the stormwater treatment performance of the GPT. Pollution treatment Efficiency Ratios (ER) calculated for the GPT were found to be 49.2% for TSS, 26.6% for TN and 40.6% for TP. Although the nutrient removal rates of the GPT observed in the study were below those specified by Queensland regulations, the results are considered notable for a stormwater treatment device that was not specifically designed to remove nutrients from stormwater. 2016 by the authors.
KW  - Gross pollutant trap
KW  - Nitrogen
KW  - Phosphorus
KW  - stormwater pollution
KW  - Suspended solids
KW  - Australia
KW  - Queensland
KW  - equipment
KW  - field survey
KW  - nitrogen
KW  - nutrient dynamics
KW  - performance assessment
KW  - phosphorus
KW  - pollutant removal
KW  - rainfall
KW  - runoff
KW  - testing method
KW  - water pollution
KW  - water quality
KW  - water treatment
PB  - MDPI
SN  - 20711050 (ISSN)
LA  - English
J2  - Sustainability
M3  - Article
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 1; Correspondence Address: P. Nichols; Stormwater Research Group, University of the Sunshine Coast, Sippy Downs, 90 Sippy Downs Drive, 4558, Australia; email: pnichols@usc.edu.au
ER  -

TY  - JOUR
AU  - Yu, Q.
AU  - Li, W.
TI  - Application of fuzzy set pair analysis model to power transformer condition assessment
PY  - 2013
T2  - Zhongnan Daxue Xuebao (Ziran Kexue Ban)/Journal of Central South University (Science and Technology)
VL  - 44
IS  - 2
SP  - 598
EP  - 603
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-84876083994&partnerID=40&md5=a57d4e11a6df125120b02b9bda7ecfeb
AD  - Beijing Key Laboratory of High Voltage and Electro Magnetic Compatibility, North China Electric Power University, Beijing 102206, China
AD  - Yongzhou Electric Power Bureau of Hunan Electric Company, Yongzhou 425000, China
AB  - In view of the complexity and uncertainty of evaluation indicators for power transformer condition assessment, the theory of fuzzy set pair analysis was adopted.Combining actual situation of power transformer condition evaluation area, following the indicator select principle which includes scientificity, systematicness, representative and so on, a power transformer condition evaluation index system and evaluation grading standard were constructed, and the main features of the complex decision-making process and the identical discrepancy-contrary (IDC) system were analyzed to establish the connection degree formula.The connection degree of evaluated factors was calculated and a new set pair analysis(SPA) model was built, and the weights of evaluated factors in the model were obtained from fuzzy analytic hierarchy process.A transformer was taken as an experimental site through repeating trials in comparison with the other related methods.The results indicate that fuzzy set pair analysis model conforms power transformer condition evaluation, and it is simple and convenient. It has fuzzy synthetic properties, and can utilize adequate information to gain the reliable evaluation results through mathematical calculation, thus can provide a preliminary evaluation of power transformer condition.
KW  - Condition assessment
KW  - Connection degree
KW  - Power transformer
KW  - Set pair analysis
KW  - Weight
KW  - Fuzzy sets
KW  - Power transformers
KW  - Uncertainty analysis
KW  - Condition assessments
KW  - Connection degree
KW  - Decision making process
KW  - Fuzzy analytic hierarchy
KW  - Mathematical calculations
KW  - Set pair analysis
KW  - Transformer condition assessment
KW  - Weight
KW  - Uncertain systems
SN  - 16727207 (ISSN)
LA  - Chinese
J2  - Zhongnan Daxue Xuebao (Ziran Kexue Ban)
M3  - Article
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 5; Correspondence Address: Q. Yu; Beijing Key Laboratory of High Voltage and Electro Magnetic Compatibility, North China Electric Power University, Beijing 102206, China; email: yuqian930@163.com; CODEN: ZDXZA
ER  -

TY  - CONF
AU  - Li, E.-W.
AU  - Song, B.
TI  - Transformer health status evaluation model based on multi-feature factors
PY  - 2014
T2  - POWERCON 2014 - 2014 International Conference on Power System Technology: Towards Green, Efficient and Smart Power System, Proceedings
C7  - 6993723
SP  - 1417
EP  - 1422
DO  - 10.1109/POWERCON.2014.6993723
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-84925233211&doi=10.1109%2fPOWERCON.2014.6993723&partnerID=40&md5=379d8da3f2c024e17fd56602bd2cac68
AB  - During the entire period of transformer's service, the internal parts get ageing gradually. But the aging degree of each part cannot be observed directly. To correctly master the condition of the transformer contributes to the prediction of the risk and reliability of the transformer, and also, this is the foundation of making effective repairing strategies or replacement, ensuring the safe and reliable operation of transformers. However, the exact assessment result has not been acquired according to traditional assessments that based on only one of the state parameter. A new assessment model based on the multi-feature factors is proposed to overcome the disadvantage of traditional condition assessments. Firstly, in order to find out the rule that the characteristic of transformer changes, the factors that influence the state of the transformer health are researched with the method of the correlation analysis of Mathematical Statistics. These factors include DGA, breakdown voltage, dielectric loss, micro-water content, acid value, furfural content and so on. Secondly, determine the state information of the power transformer; establish the index system for health evaluation. Combining with qualitative analysis, the analytic hierarchy process method is adopted to determine the weight of each index, and the health status evaluation model of power transformer is established. As for a transformer that is in operation, as long as the corresponding experimental data is got, the health condition of the transformer can be obtained with the help of the health status evaluation model. Take transformers of a substation for instance. Using the proposed model, the corresponding experimental data is analyzed. The investigations results show that the new health status evaluation mode is effective. © 2014 IEEE.
KW  - Analytic hierarchy process
KW  - Multi-feature factors
KW  - Power transformer
KW  - Status assessment
KW  - Analytic hierarchy process
KW  - Dielectric losses
KW  - Power transformers
KW  - Slip forming
KW  - Statistics
KW  - Analytic hierarchy
KW  - Condition assessments
KW  - Correlation analysis
KW  - Multi features
KW  - Qualitative analysis
KW  - Reliable operation
KW  - Status assessment
KW  - Traditional assessment
KW  - Health
PB  - Institute of Electrical and Electronics Engineers Inc.
SN  - 978-147995032-4 (ISBN)
LA  - English
J2  - POWERCON - Int. Conf. Power Syst. Technol.: Towards Green, Effic. Smart Power Syst., Proc.
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 39; Conference name: 2014 International Conference on Power System Technology, POWERCON 2014; Conference date: 20 October 2014 through 22 October 2014; Conference code: 109837
ER  -

TY  - CONF
AU  - Xie, S.
AU  - Chen, L.
TI  - Evaluating Unsupervised Language Model Adaptation Methods for Speaking Assessment
PY  - 2013
T2  - Proceedings of the 8th Workshop on Innovative Use of NLP for Building Educational Applications, BEA 2013
SP  - 288
EP  - 292
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85010744529&partnerID=40&md5=dc5bb28a97d821f04ba8314141428fb6
AD  - Microsoft, 1020 Enterprise Way, Sunnyvale, 94089, CA, United States
AD  - Educational Testing Service, 600 Rosedale Rd, Princeton, NJ, United States
AB  - In automated speech assessment, adaptation of language models (LMs) to test questions is important to achieve high recognition accuracy However, for large-scale language tests, the ordinary supervised training, which uses an expensive and time-consuming manual transcription process, is hard to utilize for LM adaptation. In this paper, several LM adaptation methods that require either no manual transcription process or just a small amount of transcriptions have been evaluated. Our experiments suggest that these LM adaptation methods can allow us to obtain considerable recognition accuracy gain with no or low human transcription cost. © 2013 Association for Computational Linguistics.
KW  - Language model adaptation
KW  - Unsupervised training
KW  - Web as a corpus
KW  - Speech recognition
KW  - Adaptation methods
KW  - Language model
KW  - Language model adaptation
KW  - Large-scales
KW  - Recognition accuracy
KW  - Supervised trainings
KW  - Transcription process
KW  - Unsupervised training
KW  - Web as a corpus
KW  - Computational linguistics
A2  - Tetreault J.
A2  - Burstein J.
A2  - Leacock C.
PB  - Association for Computational Linguistics (ACL)
SN  - 978-193728447-3 (ISBN)
LA  - English
J2  - Proc. Workshop Innov. Use NLP Build. Educ. Appl., BEA
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 2; Conference name: 8th Workshop on Innovative Use of NLP for Building Educational Applications, BEA 2013; Conference code: 173824
ER  -

TY  - JOUR
AU  - Zheng, L.
AU  - Li, S.
AU  - Wang, X.
AU  - Xin, D.
AU  - Wu, G.
TI  - Insulation condition assessment for power transformer based on normal cloud model with optimal variable weights
PY  - 2016
T2  - Gaoya Dianqi/High Voltage Apparatus
VL  - 52
IS  - 2
SP  - 85
EP  - 92
DO  - 10.13296/j.1001-1609.hva.2016.02.014
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-84962660909&doi=10.13296%2fj.1001-1609.hva.2016.02.014&partnerID=40&md5=22ed8fbf9436e4e88b90eed381523b9b
AD  - Neijiang Power Supply Company, State Grid Sichuan Electric Power Company, Neijiang, 641000, Sichuan, China
AD  - School of Electrical Engineering, Southwest Jiaotong University, Chengdu, 610031, China
AB  - In the condition assessment process of power transformers, the evaluation results have great randomness and uncertainty due to both subject and object factors coexist. An assessment strategy based on normal cloud model with optimal variable weights is proposed, which realizes the translation form qualitative to quantitative scale by using a compound two tuple method and optimal variable weights of each state quantity is determine, accordingly. A normal cloud model with reasonable digital characteristics is proposed to describe the fuzzy and random of the insulation condition. Then, the whole insulation condition and fault types of transformer are determined via cloud aggregation. Local case study proves the feasibility of the strategy proposed, which provides a new method for the targeted online insulation condition maintenance of power transformer. © 2016, Xi'an High Voltage Apparatus Research Institute. All right reserved.
KW  - Normal cloud model
KW  - Optimal variable weight coefficient
KW  - Status assessment
KW  - Transformer
PB  - Xi'an High Voltage Apparatus Research Institute
SN  - 10011609 (ISSN)
LA  - Chinese
J2  - Gaoya Dianqi
M3  - Article
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 11; CODEN: GADIE
ER  -

TY  - CONF
AU  - Venekoski, V.
AU  - Vankka, J.
TI  - Finnish resources for evaluating language model semantics
PY  - 2017
T2  - NoDaLiDa 2017 - 21st Nordic Conference of Computational Linguistics, Proceedings of the Conference
SP  - 231
EP  - 236
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85084324786&partnerID=40&md5=4b99adaffc40b9d7f5d7da87f028b700
AD  - National Defence University, Helsinki, Finland
AB  - Distributional language models have consistently been demonstrated to capture semantic properties of words. However, research into the methods for evaluating the accuracy of the modeled semantics has been limited, particularly for less-resourced languages. This research presents three resources for evaluating the semantic quality of Finnish language distributional models: (1) semantic similarity judgment resource, as well as (2) a word analogy and (3) a word intrusion test set. The use of evaluation resources is demonstrated in practice by presenting them with different language models built from varied corpora. © 2017 Linköping University Electronic Press.
KW  - Computational linguistics
KW  - Distributional models
KW  - Finnish
KW  - Language model
KW  - Model semantics
KW  - Semantic properties
KW  - Semantic qualities
KW  - Semantic similarity
KW  - Similarity judgements
KW  - Test sets
KW  - Semantics
A2  - Tiedemann J.
PB  - Association for Computational Linguistics (ACL)
SN  - 978-917685601-7 (ISBN)
LA  - English
J2  - NoDaLiDa - Nordic Conf. Comput. Linguist., Proc. Conf.
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 13; Conference name: 21st Nordic Conference of Computational Linguistics, NoDaLiDa 2017; Conference date: 23 May 2017 through 24 May 2017; Conference code: 173865
ER  -

TY  - CONF
AU  - Zheng, Y.
AU  - Wang, W.
AU  - He, W.
AU  - Liu, H.
AU  - Sun, X.
AU  - Zhan, J.
AU  - Zou, G.
TI  - Multi-source information based comprehensive condition evaluation model for power transformer
PY  - 2016
T2  - Asia-Pacific Power and Energy Engineering Conference, APPEEC
VL  - 2016-December
C7  - 7779776
SP  - 1394
EP  - 1398
DO  - 10.1109/APPEEC.2016.7779776
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85010016466&doi=10.1109%2fAPPEEC.2016.7779776&partnerID=40&md5=9c14b73c0673dc9a183c139917f32eb6
AD  - Electric Power Research Institute of State Grid Zhejiang Electric Power Corporation, Hangzhou, China
AB  - So as to adapt to the condition-based maintenance of power equipment and to overcome the disadvantages and deficiencies of traditional condition evaluation model in data acquisition approaches, component classifications, performance indicators and scoring model, a comprehensive condition evaluation model (CCEM) was proposed in this paper based on multi-source information. Combined with the offline test, online detection, online monitoring, inspection and operating environment, equipment criteria, undesirable service condition (USC) and family defects were reclassified in this model. Practice example verified that the proposed model can describe the power transformer state more comprehensively and immediately. The evaluation results provide scientific guidance for front-line operation and maintenance staffs to develop equipment maintenance strategy, and also practical basis for the condition evaluation of other power equipment. © 2016 IEEE.
KW  - condition evaluation
KW  - family defect
KW  - Power transformer
KW  - undesirable service condition
KW  - Classification (of information)
KW  - Data acquisition
KW  - Defects
KW  - Maintenance
KW  - Power transformers
KW  - Condition based maintenance
KW  - Condition evaluation
KW  - Equipment maintenance
KW  - Evaluation results
KW  - Multi-source informations
KW  - Operating environment
KW  - Performance indicators
KW  - Service conditions
KW  - Equipment
PB  - IEEE Computer Society
SN  - 21574839 (ISSN); 978-150905418-3 (ISBN)
LA  - English
J2  - Asia-Pacific Pow. Energy Eng. Conf., APPEEC
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 2; Conference name: 2016 IEEE PES Asia Pacific Power and Energy Engineering Conference, APPEEC 2016; Conference date: 25 October 2016 through 28 October 2016; Conference code: 125362
ER  -

TY  - CONF
AU  - Rough, D.
AU  - Vertanen, K.
AU  - Kristensson, P.O.
TI  - An evaluation of Dasher with a high-performance language model as a gaze communication method
PY  - 2014
T2  - Proceedings of the Workshop on Advanced Visual Interfaces AVI
SP  - 169
EP  - 176
DO  - 10.1145/2598153.2598157
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-84903601003&doi=10.1145%2f2598153.2598157&partnerID=40&md5=a9fb7c9855807025aa746cb61f081f17
AD  - University of St. Andrews, St Andrews, United Kingdom
AD  - Montana Tech., Butte, MT, United States
AB  - Dasher is a promising fast assistive gaze communication method. However, previous evaluations of Dasher have been inconclusive. Either the studies have been too short, involved too few participants, suffered from sampling bias, lacked a control condition, used an inappropriate language model, or a combination of the above. To rectify this, we report results from two new evaluations of Dasher carried out using a Tobii P10 assistive eye-tracker machine. We also present a method of modifying Dasher so that it can use a state-of-the-art long-span statistical language model. Our experimental results show that compared to a baseline eye-typing method, Dasher resulted in significantly faster entry rates (12.6 wpm versus 6.0 wpm in Experiment 1, and 14.2 wpm versus 7.0 wpm in Experiment 2). These faster entry rates were possible while maintaining error rates comparable to the baseline eye-typing method. Participants' perceived physical demand, mental demand, effort and frustration were all significantly lower for Dasher. Finally, participants significantly rated Dasher as being more likeable, requiring less concentration and being more fun. © 2014 ACM.
KW  - assistive gaze communication
KW  - Dasher
KW  - eye-typing
KW  - Computational linguistics
KW  - Experiments
KW  - Natural language processing systems
KW  - Dasher
KW  - Eye trackers
KW  - eye-typing
KW  - Gaze communications
KW  - Language model
KW  - Physical demand
KW  - Sampling bias
KW  - Statistical language modeling
KW  - Communication
PB  - Association for Computing Machinery
SN  - 978-145032775-6 (ISBN)
LA  - English
J2  - Proc Workshop Adv Visual Interfaces
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 23; Conference name: 2014 12th International Working Conference on Advanced Visual Interfaces, AVI 2014; Conference date: 27 May 2014 through 30 May 2014; Conference code: 105962
ER  -

TY  - JOUR
AU  - Nichols, P.
AU  - Lucke, T.
TI  - Field evaluation of the nutrient removal performance of a gross pollutant trap (gpt) in Australia
PY  - 2016
T2  - Sustainability (United States)
VL  - 8
IS  - 7
C7  - 669
DO  - 10.3390/su8070669
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-84982698561&doi=10.3390%2fsu8070669&partnerID=40&md5=acfe1e1df89bded3b439be258b3d2150
AD  - Stormwater Research Group, University of the Sunshine Coast, 90 Sippy Downs Drive, Sippy Downs, 4558, QLD, Australia
AB  - Field testing of a proprietary stormwater treatment device (GPT) was undertaken over a one year period at a commercial site located in Sippy Downs, Queensland. The focus of the study was primarily on evaluating the effectiveness of the GPT device in removing pollution in the form of nutrients (Total Suspended Solids, Total Nitrogen, Total Phosphorus) from stormwater runoff. Water quality analysis was performed on water samples taken from the inflow and outflow of the GPT during 15 natural rainfall events. A new testing protocol was developed to ensure a comprehensive investigation of the stormwater treatment performance of the GPT. Pollution treatment Efficiency Ratios (ER) calculated for the GPT were found to be 49.2% for TSS, 26.6% for TN and 40.6% for TP. Although the nutrient removal rates of the GPT observed in the study were below those specified by Queensland regulations, the results are considered notable for a stormwater treatment device that was not specifically designed to remove nutrients from stormwater. © 2016 by the authors; licensee MDPI, Basel, Switzerland.
KW  - Gross pollutant trap
KW  - Nitrogen
KW  - Phosphorus
KW  - Stormwater pollution
KW  - Suspended solids
KW  - Australia
KW  - Queensland
KW  - Sippy Downs
KW  - field method
KW  - nitrogen
KW  - nutrient
KW  - performance assessment
KW  - phosphorus
KW  - pollutant removal
KW  - runoff
KW  - stormwater
KW  - suspended load
KW  - water quality
KW  - water treatment
PB  - Mary Ann Liebert Inc.
SN  - 19370695 (ISSN)
LA  - English
J2  - Sustainability
M3  - Review
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 1; Correspondence Address: P. Nichols; Stormwater Research Group, University of the Sunshine Coast, Sippy Downs, 90 Sippy Downs Drive, 4558, Australia; email: pnichols@usc.edu.au
ER  -

TY  - CONF
AU  - Khalyasmaa, A.I.
AU  - Dmitriev, S.A.
AU  - Kokin, S.E.
AU  - Glushkov, D.A.
AU  - Kuzin, P.A.
TI  - Development of 110-220 kV power transformer model for equipment functional state assessment system
PY  - 2014
T2  - Advanced Materials Research
VL  - 960-961
SP  - 1347
EP  - 1351
DO  - 10.4028/www.scientific.net/AMR.960-961.1347
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-84904125110&doi=10.4028%2fwww.scientific.net%2fAMR.960-961.1347&partnerID=40&md5=efe5f9fbff7844cb1992f91ded013476
AD  - Ural Federal University, Ekaterinburg, 620002, 19, Mira street, Russian Federation
AB  - This paper addresses the problems, connected with implementation of 110-220 kV power transformer structural model for automated equipment functional state assessment system based on test and technical diagnostics data. This article describes the basic construction principles of hybrid neural network using Takagi-Sugeno fuzzy method. The paper also provides the statistical data analysis results for power transformers (of real energy grid part) to define fuzzy neural network criteria (layers). © (2014) Trans Tech Publications, Switzerland.
KW  - Diagnostics
KW  - Functional state
KW  - Hybrid neural networks
KW  - Power transformer
KW  - Takagi-sugeno fuzzy method
KW  - Test
KW  - Electrical engineering
KW  - Fuzzy neural networks
KW  - Plasma diagnostics
KW  - Testing
KW  - Construction principle
KW  - Functional state
KW  - Fuzzy methods
KW  - Hybrid neural networks
KW  - Power transformer model
KW  - Statistical data analysis
KW  - Structural modeling
KW  - Technical diagnostics
KW  - Power transformers
PB  - Trans Tech Publications Ltd
SN  - 10226680 (ISSN); 978-303835136-8 (ISBN)
LA  - English
J2  - Adv. Mater. Res.
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 1; Conference name: 3rd International Conference on Energy and Environmental Protection, ICEEP 2014; Conference date: 26 April 2014 through 28 April 2014; Conference code: 106221
ER  -

TY  - CONF
AU  - Prasojo, R.A.
AU  - Diwyacitta, K.
AU  - Suwarno, S.
AU  - Gumilang, H.
TI  - Transformer paper condition assessment using Adaptive Neuro-Fuzzy Inference System model
PY  - 2017
T2  - ICECOS 2017 - Proceeding of 2017 International Conference on Electrical Engineering and Computer Science: Sustaining the Cultural Heritage Toward the Smart Environment for Better Future
C7  - 8167141
SP  - 237
EP  - 242
DO  - 10.1109/ICECOS.2017.8167141
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85040229185&doi=10.1109%2fICECOS.2017.8167141&partnerID=40&md5=2e554d36a336947c7f9a5ed34acce612
AD  - School of Electrical Engineering and Informatics, Institut Teknologi Bandung, Bandung, Indonesia
AD  - PT. PLN, Transmisi Jawa Bagian Tengah, Bandung, Indonesia
AB  - This paper presents the possibility of using Adaptive Neuro Fuzzy Inference System for Power Transformer Paper Condition Assessment. The dielectric characteristics, dissolved gasses, and furan of 108 running transformers is collected. The 2-furaldehyde (2FAL) data is transformed to Degree of Polymerization (DP), and then statistically analysed to get independent variables as the predictor for the transformer paper condition assessment. CO and CO2 are well known as one of the product of cellulose degradation, while interfacial tension, acidity, and color from the oil are statistically correlated with furan. ANFIS (Adaptive Neuro-Fuzzy Inference System) and Multiple Regression (MR) model is built based on the previous statistical analysis, and then the result is evaluated and compared, resulting in better accuracy of ANFIS model. Three different evaluation criteria MAE (Mean Absolute Error), MAPE (Mean Absolute Percentage Error), and RMSE (Root Mean Square Error) calculated from ANFIS prediction are lower than those from MR model, with the MAPE of ANFIS model is 15.38%. © 2017 IEEE.
KW  - ANFIS
KW  - Degree of Polymerization
KW  - Dielectric Properties
KW  - Dissolved Gas Analysis
KW  - Furan
KW  - Paper Insulation
KW  - Electrical Papers
KW  - Polymerization
KW  - Regression Analysis
KW  - Statistical Analysis
KW  - Transformers
KW  - Aromatic compounds
KW  - Dielectric properties
KW  - Dielectric properties of gases
KW  - Errors
KW  - Fuzzy neural networks
KW  - Fuzzy systems
KW  - Mean square error
KW  - Organic pollutants
KW  - Polymerization
KW  - Power transformers
KW  - ANFIS
KW  - Degree of polymerization
KW  - Dissolved gas analysis
KW  - Furan
KW  - Paper insulation
KW  - Fuzzy inference
PB  - Institute of Electrical and Electronics Engineers Inc.
SN  - 978-147997675-1 (ISBN)
LA  - English
J2  - ICECOS - Proc. Int. Conf. Electr. Eng. Comput. Sci.: Sustain. Cult. Herit. Toward Smart Environ. Better Futur.
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 12; Conference name: 2017 International Conference on Electrical Engineering and Computer Science, ICECOS 2017; Conference date: 22 August 2017 through 23 August 2017; Conference code: 132916
ER  -

TY  - CONF
AU  - Deng, X.-P.
AU  - Zhang, Y.-Y.
AU  - Tong, Y.
AU  - Liu, B.
TI  - A life cycle cost-effectiveness assessment model for power transformer selection based on grey correlation analysis
PY  - 2014
T2  - China International Conference on Electricity Distribution, CICED
VL  - 2014-December
C7  - 6991891
SP  - 1168
EP  - 1173
DO  - 10.1109/CICED.2014.6991891
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-84942320959&doi=10.1109%2fCICED.2014.6991891&partnerID=40&md5=333c0a5e95c7fe3f97c8ac9e041f8f71
AD  - China Electric Power Research Institute, China
AD  - Guangxi Key Laboratory of Power System Optimization and Energy Technology, Guangxi University, China
AB  - The investment of a power transformer plays an important role in power equipment investment. Researchers have been focused on one-time cost of transformers while the future cost and benefit had been ignored. The life cycle cost (LCC) of a transformer was defined as the total cost through its whole life. Researches show that cost and effectiveness of the equipment are unity of opposites, and selecting the best investment program based on both cost and effectiveness can avoid financial losses. Factors that influence transformer's Life Cycle Cost relate to and also constrain each other. In this study, these factors are simplified as the economic factor and efficiency factor, and the main indices are chosen in the two factors. According to the above factors and indices, a three-level index system of quantitative and qualitative factors was established. Evidential reasoning was applied to quantify the qualitative indices. However, transformer investment evaluation is full of uncertainty as it is hard to obtain accurate and useful cost effectiveness results. The cost-effectiveness evaluation model in this study used grey correlation analysis for the power transformer selection. The results from this study show that the proposed approach is effective and offers a new approach to evaluating transformer investment. © 2014 IEEE.
KW  - cost-effectiveness
KW  - evidential reasoning
KW  - grey correlation analysis
KW  - LCC
KW  - power transformer
KW  - Artificial life
KW  - Correlation methods
KW  - Cost effectiveness
KW  - Costs
KW  - Electric utilities
KW  - Investments
KW  - Life cycle
KW  - Losses
KW  - Power transformers
KW  - Effectiveness assessment
KW  - Effectiveness evaluation
KW  - Evidential reasoning
KW  - Grey correlation analysis
KW  - Investment evaluation
KW  - Life cycle costs (LCC)
KW  - Qualitative factors
KW  - Qualitative indices
KW  - Cost benefit analysis
PB  - IEEE Computer Society
SN  - 21617481 (ISSN); 978-147994126-1 (ISBN)
LA  - English
J2  - China Int. Conf. Elect. Distrib., CICED
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 3; Conference name: 2014 6th China International Conference on Electricity Distribution, CICED 2014; Conference date: 23 September 2014 through 26 September 2014; Conference code: 114350
ER  -

TY  - CONF
AU  - Wang, Y.
AU  - Zhao, X.
AU  - Bian, J.
AU  - Liao, R.
AU  - Yang, L.
TI  - Cloud model-based risk assessment of power transformer
PY  - 2012
T2  - ICHVE 2012 - 2012 International Conference on High Voltage Engineering and Application
C7  - 6357092
SP  - 544
EP  - 547
DO  - 10.1109/ICHVE.2012.6357092
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-84871562763&doi=10.1109%2fICHVE.2012.6357092&partnerID=40&md5=74b2a7ac33ceb750761c4558f7190f1a
AD  - Yunnan Electric Power Research Institute (Group) Co.Ltd., Kunming 650217, China
AD  - State Key Laboratory of Power Transmission Equipment and System Security and New Technology, Chongqing University, Chongqing 400044, China
AB  - It is necessary that risk assessment is made for power transformer to identify the risk of potential failure, effect of risk and make corresponding measure to reduce risk of potential failure. Failure mode and effects analysis (FMEA) is a methodology for the analysis of potential failure modes within a system and has been extensively utilized for examining potential failures to power transformer in risk assessment. The critical issue of FMEA is determination of risk priorities of potential failure modes. In order to provide the basis for risk assessment and preventive maintenance decision-making, this work proposes the FMEA based on cloud model for prioritizing failures modes. The actual example is utilized to illustrate the potential applications of the proposed FMEA. © 2012 IEEE.
KW  - cloud model
KW  - FMEA
KW  - Risk assessment
KW  - RPN
KW  - Electrical engineering
KW  - Power transformers
KW  - Preventive maintenance
KW  - Cloud models
KW  - Corresponding measures
KW  - Critical issues
KW  - Failure mode and effects analysis
KW  - FMEA
KW  - Potential applications
KW  - Potential failure modes
KW  - Risk priority
KW  - RPN
KW  - Risk assessment
SN  - 978-146734746-4 (ISBN)
LA  - English
J2  - ICHVE - Int. Conf. High Voltage Eng. Appl.
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 4; Conference name: 2012 International Conference on High Voltage Engineering and Application, ICHVE 2012; Conference date: 17 September 2012 through 20 September 2012; Conference code: 94710
ER  -

TY  - JOUR
AU  - Beliga, S.
AU  - Ipšić, I.
AU  - Martinčić-Ipšić, S.
TI  - Evaluation of language models over Croatian newspaper texts
PY  - 2017
T2  - Information Technology and Control
VL  - 46
IS  - 4
SP  - 425
EP  - 444
DO  - 10.5755/j01.itc.46.4.18367
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85038221900&doi=10.5755%2fj01.itc.46.4.18367&partnerID=40&md5=4d3474e5c94e823eccdabf4284b2bf32
AD  - University of Rijeka, Department of Informatics, Radmile Matejčić 2, Rijeka, 51000, Croatia
AB  - Statistical language modeling involves techniques and procedures that assign probabilities to word sequences or, said in other words, estimate the regularity of the language. This paper presents basic characteristics of statistical language models, reviews their use in the large set of speech and language applications, explains their formal definition and shows different types of language models. A detailed overview of n-gram and class-based models (as well as their combinations) is given chronologically, by type and complexity of models, and in aspect of their use in different NLP applications for different natural languages. The proposed experimental procedure compares three different types of statistical language models: n-gram models based on words, categorical models based on automatically determined categories and categorical models based on POS tags. In the paper, we propose a language model for contemporary Croatian texts, a procedure how to determine the best n-gram and the optimal number of categories, which leads to significant decrease of language model perplexity, estimated from the Croatian News Agency articles (HINA) corpus. Using different language models estimated from the HINA corpus, we show experimentally that models based on categories contribute to a better description of the natural language than those based on words. These findings of the proposed experiment are applicable, except for Croatian, for similar highly inflectional languages with rich morphology and non-mandatory sentence word order. © Kaunas University of Technology.
KW  - Brown algorithm
KW  - Category- based language model
KW  - Croatian corpora
KW  - N-gram
KW  - Natural language regularity
KW  - Perplexity
KW  - POS class
KW  - Statistical language model
KW  - Word-based language model
PB  - Kauno Technologijos Universitetas
SN  - 1392124X (ISSN)
LA  - English
J2  - Inf. Technol. Control
M3  - Article
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 0; Correspondence Address: S. Beliga; University of Rijeka, Department of Informatics, Rijeka, Radmile Matejčić 2, 51000, Croatia; email: sbeliga@inf.uniri.hr
ER  -

TY  - JOUR
AU  - Rezaei-Zare, A.
TI  - Enhanced transformer model for low- And mid-frequency transients - part II: Validation and simulation results
PY  - 2015
T2  - IEEE Transactions on Power Delivery
VL  - 30
IS  - 1
SP  - 316
EP  - 325
DO  - 10.1109/TPWRD.2014.2347934
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85027944057&doi=10.1109%2fTPWRD.2014.2347934&partnerID=40&md5=9d6a82af44bf61d54467792eeac8862b
AD  - Hydro One Networks Inc., Toronto, M5G 2P5, ON, Canada
AB  - The transformer model developed in Part I is validated based on the zero-sequence test data, a ferroresonance event, and the geomagnetically induced current (GIC) measurements. Various transformer core constructions, including single phase, three limb, five limb, conventional shell type, and seven-limb shell type are represented, based on the proposed transformer model. The simulation results show high accuracy of the proposed transformer model in representing the studied cases. The study reveals that the saturation of the transformers at a given GIC level is more severe than that predicted by the existing transformer models. Furthermore, the proposed transformer model clearly explains the reasons for the previously reported discrepancies between the GIC experimental and simulation results. The study also concludes that for an accurate transformer model, particularly for the three-limb core type, the detailed representation of the zero-sequence characteristic is an essential requirement. Such a characteristic can be obtained based on either the proposed approach of the paper or a zero-sequence dc excitation test in addition to the test data at the power frequency. © 2014 IEEE.
KW  - Duality
KW  - Ferroresonance
KW  - Geomagnetically induced current (GIC)
KW  - Transformer model
KW  - Intercalation
KW  - Magnetic resonance
KW  - Resonance
KW  - Duality
KW  - Ferroresonance
KW  - Geomagnetically induced currents
KW  - Power frequency
KW  - Three-limb core
KW  - Transformer core
KW  - Transformer modeling
KW  - Transformer models
KW  - Electric transformer testing
PB  - Institute of Electrical and Electronics Engineers Inc.
SN  - 08858977 (ISSN)
LA  - English
J2  - IEEE Trans Power Delivery
M3  - Article
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 46; Correspondence Address: A. Rezaei-Zare; Hydro One Networks Inc., Toronto, M5G 2P5, Canada; email: Afshin.Rezaei-Zare@hydroone.com; CODEN: ITPDE
ER  -

TY  - CONF
AU  - Correa, W.
AU  - Cespedes, A.
AU  - Garcia, D.
TI  - Temperature control experimental plant for moisture model assessment in power transformers
PY  - 2017
T2  - 2017 IEEE 3rd Colombian Conference on Automatic Control, CCAC 2017 - Conference Proceedings
VL  - 2018-January
SP  - 1
EP  - 4
DO  - 10.1109/CCAC.2017.8276415
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85047403552&doi=10.1109%2fCCAC.2017.8276415&partnerID=40&md5=530d3a996504c06005144a278bbcac3f
AD  - School of Electrical and Electronic Engineering, Universidad Del Valle, Cali, Colombia
AB  - Power transformer useful life depends on the insulation state which is affected by moisture content and temperature. Therefore, these parameters become important issues for transformer condition monitoring. This paper describes briefly the moisture dynamics inside power transformer and the development of an experimental plant to emulate this phenomenon avoiding the construction of a real power transformer and ensuring the conditions to assess theoretical models related to this topic. © 2017 IEEE.
KW  - emulation system
KW  - experimental plant
KW  - moisture models
KW  - power transformers
KW  - temperature control
KW  - Automation
KW  - Condition monitoring
KW  - Moisture
KW  - Pilot plants
KW  - Process control
KW  - Temperature control
KW  - Emulation system
KW  - experimental plant
KW  - Moisture dynamics
KW  - Moisture modeling
KW  - Transformer condition monitoring
KW  - Useful life
KW  - Power transformers
A2  - Patino D.
A2  - Yime E.
PB  - Institute of Electrical and Electronics Engineers Inc.
SN  - 978-153860398-7 (ISBN)
LA  - English
J2  - IEEE Colombian Conf. Autom. Control, CCAC - Conf. Proc.
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 3; Conference name: 3rd IEEE Colombian Conference on Automatic Control, CCAC 2017; Conference date: 18 October 2017 through 20 October 2017; Conference code: 134504
ER  -

TY  - JOUR
AU  - Xu, Y.
AU  - Chen, X.
TI  - Transformer status assessment based on cooperative game and cloud model
PY  - 2015
T2  - Dianli Zidonghua Shebei/Electric Power Automation Equipment
VL  - 35
IS  - 3
SP  - 88
EP  - 93
DO  - 10.16081/j.issn.1006-6047.2015.03.014
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-84925642019&doi=10.16081%2fj.issn.1006-6047.2015.03.014&partnerID=40&md5=06c8555491e43d3952447f78c735b2fc
AD  - School of Electrical and Electronic Engineering, North China Electric Power University, Baoding, 071000, China
AB  - Since the fuzziness and randomness of evaluation index for transformer status assessment should be considered, a transformer status assessment method based on the cooperative game method and cloud model is proposed, which establishes an evaluation index system for transformer status assessment, adopts the cooperative game method to obtain the combination weight for each index, uses the variable weights formula to modify the weights, applies the cloud model to obtain the membership degree of quantitative index to each transformer status grade, and uses the hierarchical evaluation method to assess the transformer status. Results of case analysis show its assessment result is closer to the actual transformer status, verifying its correctness and feasibility. ©, 2015, Electric Power Automation Equipment Press. All right reserved.
KW  - Cloud model
KW  - Cooperative game
KW  - Electric transformers
KW  - Fuzziness
KW  - Membership functions
KW  - Randomness
KW  - Status assessment
KW  - Variable weight
KW  - Weight
KW  - Electric transformers
KW  - Fuzzy set theory
KW  - Fuzzy systems
KW  - Game theory
KW  - Membership functions
KW  - Random processes
KW  - Cloud modeling
KW  - Cooperative game
KW  - Fuzziness
KW  - Randomness
KW  - Status assessment
KW  - Variable weight
KW  - Weight
KW  - Cloud computing
PB  - Electric Power Automation Equipment Press
SN  - 10066047 (ISSN)
LA  - Chinese
J2  - Dianli Zidonghua Shebei Electr. Power Autom. Equip.
M3  - Article
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 35; Correspondence Address: X. Chen; School of Electrical and Electronic Engineering, North China Electric Power University, Baoding, 071000, China; email: cx15830207531@126.com; CODEN: DZSHF
ER  -

TY  - CONF
AU  - Tian, K.
AU  - You, D.H.
AU  - Li, Y.L.
AU  - Pan, K.
AU  - Wang, K.
TI  - Analysis of a transformer time-varying outage model for operational risk assessment
PY  - 2013
T2  - Advanced Materials Research
VL  - 732-733
SP  - 993
EP  - 998
DO  - 10.4028/www.scientific.net/AMR.732-733.993
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-84884785279&doi=10.4028%2fwww.scientific.net%2fAMR.732-733.993&partnerID=40&md5=6893a20e9940566cd5a853bb9a244616
AD  - State Key Laboratory of Advanced Electromagnetic Engineering and Technology, Huazhong University of Science and Technology, Wuhan 430074, Hubei Province, China
AB  - Firstly, the operating mechanism in developing process of transformer internal latent fault and external accessory fault is analyzed. Then, dissolved gas analysis (DGA) outcome and average degree of polymerization (DP) are used as an indicator to classify transformer's operating condition, the multi-state Markov process model based transformer's operating condition is proposed to estimate the internal failure rate. According to the classification method of weather condition, the external accessory failure rate model is proposed by considering the influence of weather change. A time-varying transformer outage model for operational risk assessment is proposed by using the multi-state Markov process to estimate the time-varying failure probability. Finally, a numerical is presented. © (2013) Trans Tech Publications, Switzerland.
KW  - Condition monitoring information
KW  - Markov process
KW  - Operational risk assessment
KW  - Time-varying outage model
KW  - Transformer
KW  - Condition monitoring
KW  - Electrical engineering
KW  - Failure analysis
KW  - Program processors
KW  - Risk assessment
KW  - Classification methods
KW  - Dissolved gas analyses (DGA)
KW  - Monitoring information
KW  - Multi-state Markov process
KW  - Operational risks
KW  - Outage models
KW  - Time-varying failures
KW  - Transformer
KW  - Markov processes
SN  - 10226680 (ISSN); 978-303785743-4 (ISBN)
LA  - English
J2  - Adv. Mater. Res.
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 3; Conference name: 2013 2nd International Conference on Energy and Environmental Protection, ICEEP 2013; Conference date: 19 April 2013 through 21 April 2013; Conference code: 99790
ER  -

TY  - JOUR
AU  - Ishii, Y.
AU  - Takasu, S.
AU  - Kuroda, K.
AU  - Matsushita, K.
AU  - Kijima, A.
AU  - Nohmi, T.
AU  - Ogawa, K.
AU  - Umemura, T.
TI  - Combined application of comprehensive analysis for DNA modification and reporter gene mutation assay to evaluate kidneys of gpt delta rats given madder color or its constituents
PY  - 2014
T2  - Analytical and Bioanalytical Chemistry
VL  - 406
IS  - 9-10
SP  - 2467
EP  - 2475
DO  - 10.1007/s00216-014-7621-2
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-84898049879&doi=10.1007%2fs00216-014-7621-2&partnerID=40&md5=f84e6603cb734a268b53fdff5297da76
AD  - Division of Pathology, National Institute of Health Sciences, Setagaya-ku Tokyo 158-8501, 1-18-1 Kamiyoga, Japan
AD  - Biological Safety Research Center, National Institute of Health Science, Setagaya-ku Tokyo 158-8501, 1-178-1 Kamiyoga, Japan
AB  - DNA adductome analysis using liquid chromatography-tandem mass spectrometry is a promising tool to exhaustively search DNA modifications. Given that the molecular weight of chemical-specific adducts is determined by the total molecular weights of the active form and nucleotide bases, we developed a new method of comprehensive analysis for chemical-specific DNA adducts based on the principle of adductome analysis. The actual analytical mass range was 50 mass units up or down from the average molecular weight of the four DNA bases plus the molecular weight of the expected active form of the chemical. Using lucidin-3-O-primeveroside (LuP), lucidin-modified bases formed by its active form were exhaustively searched using this new method. Various DNA adducts, including Luc-N 2-dG and Luc-N 6-dA, were identified in the kidneys of rats given LuP. Together with measurement of 8- hydroxydeoxyguanosine (8-OHdG) levels, the combined application of this new method with a reporter gene mutation assay was performed to clarify renal carcinogenesis induced by madder color (MC) that includes LuP and alizarin (Alz) as constituent agents. A DNA adductome map derived from MC-treated rats was almost identical to that of LuP-treated rats, but not Alz-treated rats. Although 8-OHdG levels were elevated in MC- and Alz-treated rats, significant increases in gpt and Spi- mutant frequencies were observed only in MC- and LuP-treated rats. In addition, the spectrum of gpt mutants in MC-treated rats showed almost the same pattern as those in LuP-treated rats. The overall data suggest that LuP may be responsible for MC-induced carcinogenicity and that the proposed methodology is appropriate for exploring and understanding mechanisms of chemical carcinogenesis. [Figure not available: see fulltext.] © 2014 Springer-Verlag Berlin Heidelberg.
KW  - DNA adduct
KW  - gpt delta
KW  - In vivo mutagenicity
KW  - Madder color
KW  - Oxidative DNA damage
KW  - Animals
KW  - Chromatography, High Pressure Liquid
KW  - DNA Adducts
KW  - Genes, Reporter
KW  - Kidney
KW  - Male
KW  - Mass Spectrometry
KW  - Mutation
KW  - Plant Extracts
KW  - Rats
KW  - Rats, Inbred F344
KW  - Rubia
KW  - Transferases (Other Substituted Phosphate Groups)
KW  - Rattus
KW  - Rubia tinctorum
KW  - Aluminum compounds
KW  - Color
KW  - DNA
KW  - Genes
KW  - Liquid chromatography
KW  - Lutetium compounds
KW  - Mass spectrometry
KW  - Molecular weight
KW  - Pathology
KW  - DNA adduct
KW  - madder color
KW  - phosphotransferase
KW  - plant extract
KW  - UDP-GlcNAc-undecaprenyl phosphate N-acetylglucosaminyl 1-phosphate transferase
KW  - Average molecular weight
KW  - Chemical specific
KW  - Comprehensive analysis
KW  - DNA adducts
KW  - gpt delta
KW  - Liquid chromatography-tandem mass spectrometry
KW  - Mutagenicity
KW  - Oxidative DNA damage
KW  - analysis
KW  - animal
KW  - chemistry
KW  - DNA adduct
KW  - enzymology
KW  - Fischer 344 rat
KW  - genetics
KW  - high performance liquid chromatography
KW  - kidney
KW  - male
KW  - mass spectrometry
KW  - mutation
KW  - rat
KW  - reporter gene
KW  - Rubia
KW  - Rats
PB  - Springer Verlag
SN  - 16182642 (ISSN)
C2  - 24493334
LA  - English
J2  - Anal. Bioanal. Chem.
M3  - Article
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 16; Correspondence Address: T. Umemura; Division of Pathology, National Institute of Health Sciences, Setagaya-ku Tokyo 158-8501, 1-18-1 Kamiyoga, Japan; email: umemura@nihs.go.jp; CODEN: ABCNB
ER  -

TY  - JOUR
AU  - Hayati Soloot, A.
AU  - Høidalen, H.K.
AU  - Gustavsen, B.
TI  - Resonant overvoltage assessment in offshore wind farms via a parametric black-box wind turbine transformer model
PY  - 2015
T2  - Wind Energy
VL  - 18
IS  - 6
SP  - 1061
EP  - 1074
DO  - 10.1002/we.1748
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-84988288915&doi=10.1002%2fwe.1748&partnerID=40&md5=9adc5cd2862a764d714da144bfa1e5fb
AD  - Department of Electrical Power Engineering, Norwegian University of Science and Technology, Trondheim, N-7491, Norway
AD  - SINTEF Energy Research, Trondheim, N-7465, Norway
AB  - The protection of offshore wind farms (OWFs) against overvoltages, especially resonant overvoltage, is of paramount importance because of poor accessibility and high repair costs. In this paper, we study how switching overvoltages at the wind turbine transformer (WTT) medium voltage (MV) side can lead to high overvoltages on the low voltage (LV) side. The effect of overvoltage protective devices is analyzed. A detailed model of an OWF row is developed in electromagnetic transients program-alternative transients program (EMTP-ATP), including interconnecting cables, WTT, surge arresters and resistive-capacitive filters. A parameterized black-box WTT model is obtained from measurements and is used for investigating the transfer of resonant overvoltages from the MV to the LV side. The model is capable of shifting systematically the frequencies and adjusting the transformer input impedance. Simulation results show that wind turbine energization in an OWF can lead to overvoltages on the LV terminals. The rate of rise of overvoltages (du/dt) is in the range of 300-500 pu/μs. It is found that resistive-capacitive filters should be installed on both MV and LV terminals of WTTs to decrease both resonant overvoltages and du/dt, which is unachievable by surge arrester alone. Copyright © 2014 John Wiley & Sons, Ltd. Copyright © 2014 John Wiley & Sons, Ltd.
KW  - energization topologies
KW  - offshore wind farms
KW  - resonant overvoltages
KW  - surge arresters
KW  - wind turbine transformers
KW  - Electric utilities
KW  - Electrolysis
KW  - Offshore oil well production
KW  - Offshore wind turbines
KW  - Overvoltage protection
KW  - Surge protection
KW  - Transformer protection
KW  - Alternative transients program
KW  - Electromagnetic transients program (EMTP)
KW  - Energization
KW  - Over-voltages
KW  - Protective devices
KW  - Surge arresters
KW  - Switching overvoltages
KW  - Transformer modeling
KW  - Offshore wind farms
PB  - John Wiley and Sons Ltd
SN  - 10954244 (ISSN)
LA  - English
J2  - Wind Energy
M3  - Article
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 2
ER  -

TY  - CONF
AU  - Liu, L.-P.
AU  - Li, Y.
AU  - Li, B.-Q.
AU  - Wang, Z.-Z.
AU  - Tian, S.-M.
TI  - Assessment of line loss rate in low-voltage transformer district based on BP network model optimized by LM algorithm
PY  - 2016
T2  - China International Conference on Electricity Distribution, CICED
VL  - 2016-September
C7  - 7576401
DO  - 10.1109/CICED.2016.7576401
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-84990892363&doi=10.1109%2fCICED.2016.7576401&partnerID=40&md5=91dfcc4adb6af1a56cc4907607092634
AD  - China Electric Power Research Institute, Haidian District, Beijing, 100192, China
AD  - School of Electrical and Electronic Engineering, North China Electric Power University, Changping District, Beijing, 102206, China
AB  - A novel method of assessing line loss rate in transformer district is presented and realized by programming, which is BP network model based on LM algorithm. The pretreatment of samples by K-Means clustering algorithm according to electric characteristics solves the numerical dispersion of line loss rate in transformer district. On this basis, each class is trained by BP network optimized by LM algorithm. BP network is adopted to map complex non-linear relation between line loss rate and electric characteristic parameters. Variation of transformer district line loss rate is obtained under different grid structures and load characteristic parameters. 601 transformer districts in a region as an example, simulation and calculation are performed to verify the accuracy of the proposed method. This method has the advantages of fast convergence and high accuracy, compared to standard BP neural network. © 2016 IEEE.
KW  - BP network with LM algorithm
KW  - electric characteristics
KW  - line loss rate
KW  - low voltage transformer district
KW  - Backpropagation
KW  - Complex networks
KW  - Electric lines
KW  - Electric losses
KW  - Electric utilities
KW  - Neural networks
KW  - Power transformers
KW  - Electric characteristics
KW  - K-Means clustering algorithm
KW  - Line loss rates
KW  - LM algorithm
KW  - Load characteristics
KW  - Low voltages
KW  - Numerical dispersions
KW  - Simulation and calculations
KW  - Clustering algorithms
PB  - IEEE Computer Society
SN  - 21617481 (ISSN); 978-146739068-2 (ISBN)
LA  - English
J2  - China Int. Conf. Elect. Distrib., CICED
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 2; Conference name: 2016 China International Conference on Electricity Distribution, CICED 2016; Conference date: 10 August 2016 through 13 August 2016; Conference code: 123946
ER  -

TY  - JOUR
AU  - Romanyuk, F.
AU  - Novash, I.
AU  - Rumiantsev, Y.
AU  - Węgierek, P.
TI  - Wye-connected current transformers simplified model validation in MATLAB-Simulink
ST  - Weryfikacja eksperymentalna uproszczonego modelu połączenia gwiazdowego przekładników prądowych w programie MATLAB-Simulink
PY  - 2015
T2  - Przeglad Elektrotechniczny
VL  - 91
IS  - 11
SP  - 292
EP  - 295
DO  - 10.15199/48.2015.11.67
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-84946845564&doi=10.15199%2f48.2015.11.67&partnerID=40&md5=929f0ccc8b1bd42d3fa4d7a1bfdb026c
AD  - Belarusian National Technical University, 65, Nezavisimosti Av., Minsk, 220013, Belarus
AD  - Lublin University of Technology, 38A, Nadbystrzycka Str., Lublin, 20-618, Poland
AB  - This paper presents the wye-connected current transformers (CTs) simplified mathematical model with the initial data based on nominal parameters (nameplate data) of the simulated CT. Designed user-friendly graphical interface allows to specify the CT data (nominal parameters, remanence and burdens) in convenient form. Results of the carried out experiments confirmed the CT model validity. © 2015, Wydawnictwo SIGMA - N O T Sp. z o.o. All rights reserved.
KW  - Current transformer model
KW  - Magnetization curve
KW  - Matlab
KW  - Relay protection
KW  - Saturation
KW  - SimPowerSystems
KW  - Simulink
PB  - Wydawnictwo SIGMA - N O T Sp. z o.o.
SN  - 00332097 (ISSN)
LA  - English
J2  - Prz. Elektrotech.
M3  - Article
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 8
ER  -

TY  - CONF
AU  - Jin, R.
AU  - Jiang, J.
AU  - Dou, Y.
TI  - Accuracy evaluation of long short term memory network based language model with fixed-point arithmetic
PY  - 2017
T2  - Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)
VL  - 10216 LNCS
SP  - 281
EP  - 288
DO  - 10.1007/978-3-319-56258-2_24
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85017548322&doi=10.1007%2f978-3-319-56258-2_24&partnerID=40&md5=14a0acc6b924dd11719de0eb9e88debe
AD  - National Laboratory for Parallel and Distributed Processing, National University of Defense Technology, Changsha, 410073, Hunan, China
AB  - Long Short Term Memory network based language models are state-of-art techniques in the field of natural language processing. Training LSTM networks is computationally intensive, which naturally results in investigating FPGA acceleration where fixed-point arithmetic is employed. However, previous studies have focused only on accelerators using some fixed bit-widths without thorough accuracy evaluation. The main contribution of this paper is to demonstrate the bit-width effect on the LSTM based language model and the tanh function approximation in a comprehensive way by experimental evaluation. Theoretically, the 12-bit number with 6-bit fractional part is the best choice balancing the accuracy and the storage saving. Gaining similar performance to the software implementation and fitting the bit-widths of FPGA primitives, we further propose a mixed bit-widths solution combing 8-bit numbers and 16-bit numbers. With clear trade-off in accuracy, our results provide a guide to inform the design choices on bit-widths when implementing LSTMs in FPGAs. Additionally, based on our experiments, it is amazing that the scale of the LSTM network is irrelevant to the optimum fixedpoint configuration, which indicates that our results are applicable to larger models as well. © Springer International Publishing AG 2017.
KW  - Bit-width
KW  - Fixed-point arithmetic
KW  - FPGA
KW  - LSTM network
KW  - Arts computing
KW  - Brain
KW  - Computational linguistics
KW  - Economic and social effects
KW  - Field programmable gate arrays (FPGA)
KW  - Long short-term memory
KW  - Natural language processing systems
KW  - Reconfigurable architectures
KW  - Accuracy evaluation
KW  - Bit-Width
KW  - Experimental evaluation
KW  - Fractional parts
KW  - NAtural language processing
KW  - Short term memory
KW  - Software implementation
KW  - Tanh functions
KW  - Fixed point arithmetic
A2  - Beck A.C.
A2  - Carro   L.
A2  - Wong S.
A2  - Bertels   K.
PB  - Springer Verlag
SN  - 03029743 (ISSN); 978-331956257-5 (ISBN)
LA  - English
J2  - Lect. Notes Comput. Sci.
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 2; Correspondence Address: R. Jin; National Laboratory for Parallel and Distributed Processing, National University of Defense Technology, Changsha, 410073, China; email: jinruochun@nudt.edu.cn; Conference name: 13th International Symposium on Applied Reconfigurable Computing, ARC 2017; Conference date: 3 April 2017 through 7 April 2017; Conference code: 190559
ER  -

TY  - JOUR
AU  - Horibata, K.
AU  - Ukai, A.
AU  - Honma, M.
TI  - Evaluation of rats' in vivo genotoxicity induced by N-ethyl-N-nitrosourea in the RBC Pig-a, PIGRET, and gpt assays
PY  - 2014
T2  - Genes and Environment
VL  - 36
IS  - 4
SP  - 199
EP  - 202
DO  - 10.3123/jemsge.2014.023
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-84918775750&doi=10.3123%2fjemsge.2014.023&partnerID=40&md5=66970b41a6efa6b74402fffcc81dad3d
AD  - Division of Genetics and Mutagenesis, National Institute of Health Sciences, 1-18-1 Kamiyoga, Setagaya-ku, Tokyo, 158-8501, Japan
AB  - The emerging Pig-a gene mutation assay, a powerful and promising tool for evaluating in vivogenotoxicity, is based on flow cytometric enumeration of red blood cells (RBCs), which are deficient in glycosylphosphatidylinositol anchored protein. Various approaches for measuring Pig-a mutant cells have been developed, particularly those focused on peripheral RBCs and reticulocytes (RETs). Previously, it had been reported that Pig-a and gpt mutant frequencies were relatively increased in N-ethyl-N-nitrosourea (ENU)- and benzo[a]pyrene (BP)-treated mice. The capacity and characteristics of the Pig-a assay relative to transgenic rodent (TGR) mutation assays, however, are unclear in rats. Here, using transgenic gpt delta rats, we compared the in vivo genotoxicity of single oral doses of ENU (40 mg/kg) in the gpt gene mutation assay in bone marrow and liver, and Pig-a gene mutation assays on RBCs and RETs in the same animals. The Pig-agene mutation assays were conducted at 1, 2, and 4 weeks after treatment, whereas gpt assays were conducted on tissues collected at the 4-week terminal sacrifice. Consequently, we detected that Pig-a and gpt mutant frequencies were clearly increased in ENU-treated rats, indicating that both the Pig-a and TGR gene mutation assays can detect in vivo ENU genotoxicity equally. © 2014 The Japanese Environmental Mutagen Society.
KW  - Glycosyl-phosphatidylinositol anchor
KW  - Red blood cells
KW  - Reticulocyte
KW  - Transgenic rodent mutation assays
KW  - Animalia
KW  - Mus
KW  - Rattus
KW  - Rodentia
KW  - Suidae
KW  - benzo[a]pyrene
KW  - cell protein
KW  - ethylnitrosourea
KW  - glycosylphosphatidylinositol anchored protein
KW  - Pig a protein
KW  - pigret protein
KW  - unclassified drug
KW  - animal experiment
KW  - animal tissue
KW  - Article
KW  - bone marrow
KW  - cell mutant
KW  - controlled study
KW  - erythrocyte
KW  - evaluation study
KW  - gene frequency
KW  - gene mutation
KW  - genotoxicity
KW  - in vivo study
KW  - liver toxicity
KW  - nonhuman
KW  - protein determination
KW  - rat
KW  - reticulocyte
KW  - rodent
PB  - The Japanese Environmental Mutagen Society
SN  - 18807046 (ISSN)
LA  - English
J2  - Genes Environ.
M3  - Article
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 20
ER  -

TY  - CONF
AU  - Benahmed, Y.
AU  - Selouani, S.-A.
AU  - O'Shaughnessy, D.
TI  - Evaluation of graph metrics for optimizing bin-based ontologically smoothed language models
PY  - 2016
T2  - European Signal Processing Conference
VL  - 2016-November
C7  - 7760580
SP  - 1906
EP  - 1910
DO  - 10.1109/EUSIPCO.2016.7760580
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85005975902&doi=10.1109%2fEUSIPCO.2016.7760580&partnerID=40&md5=7b75b401ea9bd8bfd20658390dd77062
AD  - INRS-EMT, Montréal, QC, Canada
AD  - LARIHS Lab., Université de Moncton, Campus de Shippagan, Shippagan, NB, Canada
AB  - This paper investigates the use of graph metrics to further enhance the performance of a language model smoothing algorithm. Bin-Based Ontological Smoothing has been successfully used to improve language model performance in automatic speech recognition tasks. It uses ontologies to estimate novel utterances for a given language model. Since ontologies can be represented as graphs, we investigate the use of graph metrics as an additional smoothing factor in order to capture additional semantic or relational information found in ontologies. More specifically, we investigate the effect of HITS, PageRank, Modularity, and weighted degree, on performance. The entire power set of bins is evaluated. Our results show that the interpolation of the original bins at distances 1, 3 and 5 resulted in an improvement in WER of 0.71% relative over the interpolation of bins 1 to 5. Furthermore, modularity, PageRank and HITS show promise for further study. © 2016 IEEE.
KW  - Bins
KW  - Computational linguistics
KW  - Interpolation
KW  - Semantics
KW  - Speech recognition
KW  - AS graph
KW  - Automatic speech recognition
KW  - Graph metrics
KW  - Language model
KW  - Power set
KW  - Smoothing algorithms
KW  - Smoothing factors
KW  - Weighted degree
KW  - Signal processing
PB  - European Signal Processing Conference, EUSIPCO
SN  - 22195491 (ISSN); 978-099286265-7 (ISBN)
LA  - English
J2  - European Signal Proces. Conf.
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 0; Conference name: 24th European Signal Processing Conference, EUSIPCO 2016; Conference date: 28 August 2016 through 2 September 2016; Conference code: 125055
ER  -

TY  - JOUR
AU  - Zhang, Y.
AU  - Liao, R.
AU  - Yang, L.
AU  - Deng, X.
AU  - Cheng, H.
AU  - Lv, C.
TI  - A cost-effectiveness assessment model using grey correlation analysis for power transformer selection based on life cycle cost
PY  - 2014
T2  - Kybernetes
VL  - 43
IS  - 1
SP  - 5
EP  - 23
DO  - 10.1108/K-07-2013-0160
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-84896276482&doi=10.1108%2fK-07-2013-0160&partnerID=40&md5=51f383608c45aa57b1a7f2122f64c1fe
AD  - State Key Laboratory of Power Transmission Equipment and System Security and New Technology, Chongqing University, Chongqing, China
AD  - State Grid Electric Power Research Institute, Wuhan, China
AD  - China Electric Power Research Institute, Beijing, China
AB  - Purpose: Statistics show that selecting the best investment program based on both cost and effectiveness can avoid financial losses. However, investment evaluation of a power transformer is full of uncertainty as it is hard to obtain accurate and useful cost-effectiveness results. Therefore, the purpose of the paper is to establish an investment evaluation model. Design/methodology/approach: The cost-effectiveness evaluation model in this study used grey correlation analysis for the power transformer selection based on life cycle cost (LCC). Indices of cost and effectiveness factors were chosen to form a three-level index system including quantitative and qualitative factors. Evidential reasoning was applied to quantify the qualitative indexes. Grey correlation analysis was applied to select the best investment program. Findings: The results from this study show that the proposed approach is effective and offers a new approach to evaluating transformer investment. Practical implications: The model was applied to an investing decision-making problem of the transformer in a new substation in Wuhan, China. Originality/value: It is very important to select the best transformer program in the candidate investment programs because the investment program decides almost 70 percent of the LCC of the power transformer. © Emerald Group Publishing Limited.
KW  - Cost-effectiveness
KW  - Decision making
KW  - Evidential reasoning
KW  - Grey correlation analysis
KW  - Life cycle cost
KW  - Modelling
KW  - Power transformer
KW  - Correlation methods
KW  - Cost effectiveness
KW  - Costs
KW  - Decision making
KW  - Investments
KW  - Life cycle
KW  - Losses
KW  - Models
KW  - Power transformers
KW  - Decision-making problem
KW  - Design/methodology/approach
KW  - Effectiveness assessment
KW  - Effectiveness evaluation
KW  - Evidential reasoning
KW  - Grey correlation analysis
KW  - Life cycle costs (LCC)
KW  - Lifecycle costs
KW  - Cost benefit analysis
PB  - Emerald Group Publishing Ltd.
SN  - 0368492X (ISSN)
LA  - English
J2  - Kybernetes
M3  - Article
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 13; Correspondence Address: Y. Zhang; State Key Laboratory of Power Transmission Equipment and System Security and New Technology, Chongqing University, Chongqing, China; email: yiyizhang.cqu@gmail.com
ER  -

TY  - CONF
AU  - Chen, X.
AU  - Liu, X.
AU  - Qian, Y.
AU  - Gales, M.J.F.
AU  - Woodland, P.C.
TI  - CUED-RNNLM - An open-source toolkit for efficient training and evaluation of recurrent neural network language models
PY  - 2016
T2  - ICASSP, IEEE International Conference on Acoustics, Speech and Signal Processing - Proceedings
VL  - 2016-May
C7  - 7472829
SP  - 6000
EP  - 6004
DO  - 10.1109/ICASSP.2016.7472829
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-84973392043&doi=10.1109%2fICASSP.2016.7472829&partnerID=40&md5=01495f2bd4d5d2bf6bac795107356fc8
AD  - Cambridge University Engineering Dept, Trumpington St., Cambridge, CB2 1PZ, United Kingdom
AB  - In recent years, recurrent neural network language models (RNNLMs) have become increasingly popular for a range of applications including speech recognition. However, the training of RNNLMs is computationally expensive, which limits the quantity of data, and size of network, that can be used. In order to fully exploit the power of RNNLMs, efficient training implementations are required. This paper introduces an open-source toolkit, the CUED-RNNLM toolkit, which supports efficient GPU-based training of RNNLMs. RNNLM training with a large number of word level output targets is supported, in contrast to existing tools which used class-based output-targets. Support fotN-best and lattice-based rescoring of both HTK and Kaldi format lattices is included. An example of building and evaluating RNNLMs with this toolkit is presented for a Kaldi based speech recognition system using the AMI corpus. All necessary resources including the source code, documentation and recipe are available online1. © 2016 IEEE.
KW  - GPU
KW  - language model
KW  - open-source toolkit
KW  - recurrent neural network
KW  - speech recognition
PB  - Institute of Electrical and Electronics Engineers Inc.
SN  - 15206149 (ISSN); 978-147999988-0 (ISBN)
LA  - English
J2  - ICASSP IEEE Int Conf Acoust Speech Signal Process Proc
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 60; Conference name: 41st IEEE International Conference on Acoustics, Speech and Signal Processing, ICASSP 2016; Conference date: 20 March 2016 through 25 March 2016; Conference code: 121667; CODEN: IPROD
ER  -

TY  - CONF
AU  - Chao, L.
AU  - Lin, M.
TI  - Health assessment model of power transformer based on dissolved gas analysis by support vector machine
PY  - 2013
T2  - Proceedings of 2013 6th International Conference on Information Management, Innovation Management and Industrial Engineering, ICIII 2013
VL  - 1
C7  - 6702929
SP  - 280
EP  - 283
DO  - 10.1109/ICIII.2013.6702929
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-84893700084&doi=10.1109%2fICIII.2013.6702929&partnerID=40&md5=3576f2f0a6423b592a102465e5bd11fe
AD  - Science and Technology on Reliability and Environmental Engineering Laboratory, Beijing University of Aeronautics and Astronautics, Beijing, China
AB  - Power transformer in grid is of vital importance to guarantee safe operation of the power system. Nowadays dissolved gas analysis (DGA) is recognized as an effective method for detecting the initial fault of power transformer. Support vector machine (SVM) with Structure Risk Minimization (SRM) is powerful for the problem with small sampling, nonlinear and high dimension, which is based on mathematics theory. This paper establishes health assessment model based on DGA by using SVM. Health estimation is used to deal with the initial fault timely and prevent fault diffusion and dissemination. Then we choose appropriate kernel function and corresponding parameter to ensure the availability. Finally, a case is studied. The result indicates that the model can effectively estimate the health state of power transformer. © 2013 IEEE.
KW  - dissolved gas analysis
KW  - health assessment
KW  - power transformer
KW  - support vector machine
KW  - Gas chromatography
KW  - Health
KW  - Industrial engineering
KW  - Information management
KW  - Innovation
KW  - Power transformers
KW  - Dissolved gas analyses (DGA)
KW  - Dissolved gas analysis
KW  - Health assessments
KW  - High dimensions
KW  - Initial faults
KW  - Kernel function
KW  - Safe operation
KW  - Structure risk minimizations (SRM)
KW  - Support vector machines
SN  - 978-147993985-5 (ISBN)
LA  - English
J2  - Proc. Int. Conf. Inf. Manage., Innov. Manage. Ind. Eng., ICIII
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 6; Conference name: 2013 6th International Conference on Information Management, Innovation Management and Industrial Engineering, ICIII 2013; Conference date: 23 November 2013 through 24 November 2013; Conference code: 102493
ER  -

TY  - CONF
AU  - Jaiswal, G.C.
AU  - Tutakne, D.R.
AU  - Ballal, M.S.
AU  - Akhil Sai, P.K.
TI  - Oil level assessment of Distribution Transformer by development of Capacitance Model
PY  - 2016
T2  - 2016 IEEE 6th International Conference on Power Systems, ICPS 2016
C7  - 7584029
DO  - 10.1109/ICPES.2016.7584029
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-84994102603&doi=10.1109%2fICPES.2016.7584029&partnerID=40&md5=272ba3408494906c1774e3e56059d212
AD  - Department of Electrical Engineering, Shri Ramdeobaba College of Engineering and Management, Nagpur, India
AD  - Department of Electrical Engineering, Visvesvaraya National Institute of Technology, Nagpur, India
AB  - Distribution Transformers are one of the most important equipment in power system network. Distribution transformer failures can be broadly categorized due to electrical and/or mechanical faults. Preventive diagnosis and maintenance of transformer have become more and more popular in recent time in order to improve the reliability of electric power system. It is experienced by the power utility engineers that the distribution transformer failure occurs mainly due to overload condition and improper cooling agent (oil) level in distribution transformer. This paper presents Capacitance Model which is developed by taking actual data of the distribution transformer connected in Maharashtra State Electricity Distribution Company Limited (MSEDCL). The oil leakage problem in terms of oil level in distribution transformer can be detected by developing capacitance modeling as well as by Newton's cooling law. © 2016 IEEE.
KW  - Capacitance Model
KW  - Distribution Transformer (DT)
KW  - Newton's Cooling Law
KW  - Oil Leakage
KW  - Capacitance
KW  - Cooling
KW  - Electric power systems
KW  - Electric transformers
KW  - Electric utilities
KW  - Preventive maintenance
KW  - Capacitance model
KW  - Cooling agents
KW  - Distribution transformer
KW  - Electricity distribution companies
KW  - Mechanical faults
KW  - Oil leakage
KW  - Overload condition
KW  - Power system networks
KW  - Oil filled transformers
PB  - Institute of Electrical and Electronics Engineers Inc.
SN  - 978-150900128-6 (ISBN)
LA  - English
J2  - IEEE Int. Conf. Power Syst., ICPS
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 5; Conference name: 6th IEEE International Conference on Power Systems, ICPS 2016; Conference date: 4 March 2016 through 6 March 2016; Conference code: 124202
ER  -

TY  - JOUR
AU  - Liao, R.
AU  - Zhang, Y.
AU  - Yang, L.
AU  - Zheng, H.
AU  - She, X.
TI  - A cloud and evidential reasoning integrated model for insulation condition assessment of high voltage transformers
PY  - 2014
T2  - International Transactions on Electrical Energy Systems
VL  - 24
IS  - 7
SP  - 913
EP  - 926
DO  - 10.1002/etep.1738
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-84904434412&doi=10.1002%2fetep.1738&partnerID=40&md5=018928ceb26af7170079b9d54d0d88e0
AD  - State Key Laboratory of Power Transmission Equipment and System Security and New Technology, Chongqing University, Chongqing 400044, China
AD  - FREEDM Systems Center, Department of Electrical and Computer Engineering, North Carolina State University, Raleigh, NC 27606, United States
AD  - HAEPC Electric Power Research Institute, Zhengzhou 450052, China
AB  - Power transformers of high voltage play a key role in the power transmission system. Statistics show that acquiring an accurate assessment of transformer insulation can avoid financial losses of electrical companies, because it can detect a potential failure and therefore decrease the risk of transformer failure. Condition assessment of transformers is full of uncertain, fuzzy and randomness information and can be considered as a multiple-attribute decision-making problem. Aiming at this problem, this study presents a cloud and evidential reasoning integrated approach for assessing the condition of transformers. Data from the main body, maintenance record and accessory were chosen to form the assessment index system. Analysis results show that the integrated approach is effective and provides some valuable information to the maintenance of high voltage transformer. Copyright © 2013 John Wiley & Sons, Ltd. Copyright © 2013 John Wiley & Sons, Ltd.
KW  - cloud model
KW  - condition assessment
KW  - evidential reasoning
KW  - insulation
KW  - multiple-attribute decision-making (MADM)
KW  - transformers
KW  - Decision making
KW  - Electric fault currents
KW  - Electric transformers
KW  - Electricity
KW  - Insulation
KW  - Integrated control
KW  - Losses
KW  - Maintenance
KW  - Risk assessment
KW  - Assessment index system
KW  - Cloud modeling
KW  - Condition assessments
KW  - Evidential reasoning
KW  - High voltage transformers
KW  - Multiple attribute decision making
KW  - Power transmission systems
KW  - Transformer insulation
KW  - Power transformers
PB  - John Wiley and Sons Ltd
SN  - 20507038 (ISSN)
LA  - English
J2  - Int. Trans. Elecr. Energy Sys.
M3  - Article
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 15; Correspondence Address: Y. Zhang; State Key Laboratory of Power Transmission Equipment and System Security and New Technology, Chongqing University, Chongqing 400044, China; email: yiyizhang.cqu@gmail.com
ER  -

TY  - JOUR
AU  - Chen, X.
AU  - Liu, X.
AU  - Wang, Y.
AU  - Gales, M.J.F.
AU  - Woodland, P.C.
TI  - Efficient Training and Evaluation of Recurrent Neural Network Language Models for Automatic Speech Recognition
PY  - 2016
T2  - IEEE/ACM Transactions on Audio Speech and Language Processing
VL  - 24
IS  - 11
SP  - 2146
EP  - 2157
DO  - 10.1109/TASLP.2016.2598304
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-84990871953&doi=10.1109%2fTASLP.2016.2598304&partnerID=40&md5=d0ee1fab99ca5723513f62f3b27770db
AD  - Department of Engineering, University of Cambridge, Cambridge, CB2 1PZ, United Kingdom
AD  - Department of Systems Engineering and Engineering Management, Chinese University of Hong Kong, Shatin, Hong Kong
AD  - Microsoft Corporation, Redmond, 98052, WA, United States
AB  - Recurrent neural network language models (RNNLMs) are becoming increasingly popular for a range of applications including automatic speech recognition. An important issue that limits their possible application areas is the computational cost incurred in training and evaluation. This paper describes a series of new efficiency improving approaches that allows RNNLMs to be more efficiently trained on graphics processing units (GPUs) and evaluated on CPUs. First, a modified RNNLM architecture with a nonclass-based, full output layer structure (F-RNNLM) is proposed. This modified architecture facilitates a novel spliced sentence bunch mode parallelization of F-RNNLM training using large quantities of data on a GPU. Second, two efficient RNNLM training criteria based on variance regularization and noise contrastive estimation are explored to specifically reduce the computation associated with the RNNLM output layer softmax normalisation term. Finally, a pipelined training algorithm utilizing multiple GPUs is also used to further improve the training speed. Initially, RNNLMs were trained on a moderate dataset with 20M words from a large vocabulary conversational telephone speech recognition task. The training time of RNNLM is reduced by up to a factor of 53 on a single GPU over the standard CPU-based RNNLM toolkit. A 56 times speed up in test time evaluation on a CPU was obtained over the baseline F-RNNLMs. Consistent improvements in both recognition accuracy and perplexity were also obtained over C-RNNLMs. Experiments on Google's one billion corpus also reveals that the training of RNNLM scales well. © 2014 IEEE.
KW  - Estimation
KW  - GPU
KW  - language models
KW  - noise contrastive
KW  - pipelined training
KW  - recurrent neural network
KW  - speech recognition
KW  - variance regularisation
KW  - Computational linguistics
KW  - Computer graphics
KW  - Estimation
KW  - Network architecture
KW  - Program processors
KW  - Recurrent neural networks
KW  - Automatic speech recognition
KW  - Conversational telephone speech recognition
KW  - Graphics processing units
KW  - Language model
KW  - Modified architecture
KW  - noise contrastive
KW  - Recognition accuracy
KW  - Regularisation
KW  - Speech recognition
PB  - Institute of Electrical and Electronics Engineers Inc.
SN  - 23299290 (ISSN)
LA  - English
J2  - IEEE ACM Trans. Audio Speech Lang. Process.
M3  - Article
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 46
ER  -

TY  - JOUR
AU  - Ramírez-Mosqueda, M.A.
AU  - Iglesias-Andreu, L.G.
AU  - Ramírez-Madero, G.
AU  - Hernández-Rincón, E.U.
TI  - Micropropagation of Stevia rebaudiana Bert. in temporary immersion systems and evaluation of genetic fidelity
PY  - 2016
T2  - South African Journal of Botany
VL  - 106
SP  - 238
EP  - 243
DO  - 10.1016/j.sajb.2016.07.015
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-84981215105&doi=10.1016%2fj.sajb.2016.07.015&partnerID=40&md5=f65382e32fc6cdf7e40b0c9372e086e7
AD  - Instituto de Biotecnología y Ecología Aplicada (INBIOTECA), Universidad Veracruzana, Av. de las Culturas Veracruzanas No. 101, Campus para la Cultura, las Artes y el Deporte, Col. Emiliano Zapata, Xalapa, 91090, Veracruz C.P., Mexico
AB  - Stevia rebaudiana Bertoni (Asteraceae) contains in its leaves sweeteners such as stevioside and rebaudioside, for which it is commercially valuable. Inefficient sexual and asexual propagation methods do not meet the current demand of propagules required for commercial cultivation. Therefore, in vitro propagation is a promising alternative to solve this issue. However, the protocols currently available involve low numbers of micropropagated shoots and high production costs. Therefore, this study proposes to establish a commercial micropropagation protocol for S. rebaudiana using Recipient for Automated Temporary Immersion (RITA®) aimed at implementing this mass-propagation process at a low cost and in an automated modality. Our findings revealed that the highest number of shoots (18.37) was obtained using 1 mg l− 1 benzyladenine (BA) at an immersion frequency of 2 min every 8 h in 20 ml medium per explant. 100% rooting of shoots was achieved by using MS medium with no plant growth regulators (PGR). 90% of regenerated plantlets were successfully acclimatized under greenhouse conditions. The regenerated plants showed a low percentage of genetic variation (10.4%). This protocol can be applied in the commercial micropropagation of this species. © 2016 SAAB
KW  - Genetic fidelity
KW  - ISSR markers
KW  - Micropropagation
KW  - RITA®
KW  - Temporary immersion bioreactor
KW  - Asteraceae
KW  - Stevia rebaudiana
KW  - bioreactor
KW  - biotechnology
KW  - cultivation
KW  - experimental study
KW  - genetic marker
KW  - genetic variation
KW  - growth regulator
KW  - herb
KW  - vegetative propagation
PB  - Elsevier B.V.
SN  - 02546299 (ISSN)
LA  - English
J2  - S. Afr. J. Bot.
M3  - Article
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 31; Correspondence Address: M.A. Ramírez-Mosqueda; Instituto de Biotecnología y Ecología Aplicada (INBIOTECA), Universidad Veracruzana, Xalapa, Av. de las Culturas Veracruzanas No. 101, Campus para la Cultura, las Artes y el Deporte, Col. Emiliano Zapata, 91090, Mexico; email: marcoa.rm.07@gmail.com; CODEN: SAJBD
ER  -

TY  - JOUR
AU  - Sandraz, J.
AU  - De Leon, F.
AU  - Cultrera, J.
TI  - Validated transient heat-transfer model for underground transformer in rectangular vault
PY  - 2013
T2  - IEEE Transactions on Power Delivery
VL  - 28
IS  - 3
C7  - 6516999
SP  - 1770
EP  - 1778
DO  - 10.1109/TPWRD.2013.2260183
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-84880076653&doi=10.1109%2fTPWRD.2013.2260183&partnerID=40&md5=500bc099704d3ffe51e39d24e0f35fed
AD  - Department of Electrical and Computer Engineering, Polytechnic Institute of New York University, Brooklyn, NY 11201, United States
AD  - Consolidated Edison Company of New York, Inc., New York, NY 10003, United States
AB  - A new thermal model for underground transformers is proposed in this paper. The model takes the following important characteristics of the transformer installation into account: rectangular shapes; coil and core arrangement; orientation-based convection models for air (vertical, horizontal-upward, and horizontal-downward heat flows); and turbulent or laminar flow regime. The resulting coupled set of differential and algebraic nonlinear equations is solved simultaneously, providing a robust and fast solution that can help design transformers. The model has been validated against three transformers with different dimensions installed in different vaults with onsite measurements. The average absolute difference between the simulated and measured temperatures over several months is typically less than 4°C. A parameter sensitivity study shows the critical importance of the proper estimation of the full-load heat loss and the ambient soil temperature. © 1986-2012 IEEE.
KW  - Distribution transformers
KW  - heat-transfer transients
KW  - predictive maintenance
KW  - thermal analysis
KW  - thermal circuit
KW  - Air
KW  - Electric transformers
KW  - Laminar flow
KW  - Thermoanalysis
KW  - Distribution transformer
KW  - Heat transfer model
KW  - Laminar flow regimes
KW  - Measured temperatures
KW  - On-site measurement
KW  - Parameter sensitivities
KW  - Predictive maintenance
KW  - Thermal circuits
KW  - Heat transfer
SN  - 08858977 (ISSN)
LA  - English
J2  - IEEE Trans Power Delivery
M3  - Article
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 12; CODEN: ITPDE
ER  -

TY  - JOUR
AU  - Liao, R.
AU  - Zhang, Y.
AU  - Zheng, H.
AU  - Yang, L.
AU  - Wang, K.
AU  - Akram, S.
TI  - A condition assessment model of oil-immersed transformers using cloud and matter element integrated method
ST  - Ocena stanu technicznego transformatora olejowego na podstawie modelu szacunkowego - wykorzystanie metod elementów chmury i materii
PY  - 2013
T2  - Przeglad Elektrotechniczny
VL  - 89
IS  - 4
SP  - 142
EP  - 146
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-84875680592&partnerID=40&md5=0cd3cb927b1f53e07f052c6a3363d248
AD  - State Key Laboratory of Power Transmission Equipment and System Security and New Technology, University of Chongqing, HighVoltage Lab, District A, Chongqing University, Shapingba District,Chongqing, 400030, China
AD  - Henan Electric Power Research Institute, China
AB  - High voltage oil-immersed transformers are the most important components in the power system. If there is a potential fault in the transformer it may cause a power failure even a catastrophe. Therefore, it is important to assess the condition of the transformer accurately and to make some relative maintenance to minimize the risk of premature failure. However, condition assessment of transformers can be considered as a multiple-attribute decision-making (MADM) problem which is full of uncertain, fuzzy and randomness information. Aiming at this intricate problem, this paper presents a cloud and matter element integrated approach for assessing the condition of transformers. An assessing index system is established, which includes dissolved gas analysis (DGA), electrical testing and oil testing. An integrated model based on matter element approach and cloud approach is applied to assess the condition of the transformer. Cases study show that the proposed approach is practical and effective. The assessing result can be regarded as a useful suggestion to condition based maintenance of high voltage oil-immersed transformers.
KW  - Cloud and matter element integrated
KW  - Cloud model
KW  - Condition assessment
KW  - MADM
KW  - Oil-immersed transformers
SN  - 00332097 (ISSN)
LA  - English
J2  - Prz. Elektrotech.
M3  - Article
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 3; Correspondence Address: Y. Zhang; State Key Laboratory of Power Transmission Equipment and System Security and New Technology, University of Chongqing, HighVoltage Lab, District A, Chongqing University, Shapingba District,Chongqing, 400030, China; email: yiyizhang.cqu@gmail.com
ER  -

TY  - CONF
AU  - Metallinou, A.
AU  - Cheng, J.
TI  - Syllable and language model based features for detecting non-scorable tests in spoken language proficiency assessment applications
PY  - 2014
T2  - Proceedings of the Annual Meeting of the Association for Computational Linguistics
SP  - 89
EP  - 98
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026807168&partnerID=40&md5=9e0350fa9f92b242eedd7247e073efd0
AD  - Knowledge Technologies, Pearson, 4040 Campbell Ave., Menlo Park, 94025, CA, United States
AB  - This work introduces new methods for detecting non-scorable tests, i.e., tests that cannot be accurately scored automatically, in educational applications of spoken language proficiency assessment. Those include cases of unreliable automatic speech recognition (ASR), often because of noisy, off-topic, foreign or unintelligible speech. We examine features that estimate signal-derived syllable information and compare it with ASR results in order to detect responses with problematic recognition. Further, we explore the usefulness of language model based features, both for language models that are highly constrained to the spoken task, and for task independent phoneme language models. We validate our methods on a challenging dataset of young English language learners (ELLs) interacting with an automatic spoken assessment system. Our proposed methods achieve comparable performance compared to existing non-scorable detection approaches, and lead to a 21% relative performance increase when combined with existing approaches. © 2014 Association for Computational Linguistics.
KW  - Computational linguistics
KW  - Feature extraction
KW  - Natural language processing systems
KW  - Speech recognition
KW  - Assessment system
KW  - Automatic speech recognition
KW  - Detection approach
KW  - Educational Applications
KW  - English languages
KW  - Language model
KW  - Language proficiency
KW  - Model-based OPC
KW  - Performance
KW  - Spoken languages
KW  - Chemical detection
PB  - Association for Computational Linguistics (ACL)
SN  - 0736587X (ISSN); 978-194164303-7 (ISBN)
LA  - English
J2  - Proc. Annu. Meet. Assoc. Comput Linguist.
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 4; Conference name: 9th Workshop on Innovative Use of NLP for Building Educational Applications, BEA 2014 at the 52nd Annual Meeting of the Association for Computational Linguistics, ACL 2014; Conference code: 173890
ER  -

TY  - JOUR
AU  - Ahour, J.N.
AU  - Seyedtabaie, S.
AU  - Gharehpetian, G.B.
TI  - Modified transformer winding ladder network model to assess non-dominant frequencies
PY  - 2017
T2  - IET Electric Power Applications
VL  - 11
IS  - 4
SP  - 578
EP  - 585
DO  - 10.1049/iet-epa.2016.0635
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85017533876&doi=10.1049%2fiet-epa.2016.0635&partnerID=40&md5=70ae80670dbb91fe2152d467403d43e9
AD  - Electrical Engineering Department, Shahed University, P.O. Box 18155/159, Tehran, Iran
AD  - Electrical Engineering Department, Amirkabir University of Technology, Hafez Ave., Tehran, Iran
AB  - In this study, the challenging problem of computing the frequency-dependent lumped parameter ladder network model for transformer winding based on impedance frequency response is investigated. It is shown that the existing conventional model is not capable of simulating the non-dominant resonances; rather, this phenomenon can be adequately modelled using extra intersection capacitors. As usual, this large-scale non-linear optimisation problem is addressed using properly lined-up genetic algorithm. To accelerate the success of the estimation, the dimension of the problem and the search space is reduced by using logical and real constraints and equations derived from the transformer geometry and its electromagnetic specifications; if this is not done, the optimisation fails. The test results on a 20/0.4 kV, 1600 kVA transformer indicates that the computed model, which is improved and detailed, is superior to the conventional one in terms of simulating the non-dominant resonances of the transformer winding. Therefore, it is more reliable for the transformer transient behaviour analysis. © The Institution of Engineering and Technology 2017.
KW  - Frequency response
KW  - Genetic algorithms
KW  - Ladder networks
KW  - Ladders
KW  - Nonlinear programming
KW  - Optimization
KW  - Transformer windings
KW  - Winding
KW  - Behaviour analysis
KW  - Conventional modeling
KW  - Dominant frequency
KW  - Frequency dependent
KW  - Lumped parameter
KW  - Non-linear optimisation
KW  - Real constraints
KW  - Transformer transients
KW  - Electric transformer testing
PB  - Institution of Engineering and Technology
SN  - 17518660 (ISSN)
LA  - English
J2  - IET Electr Power Appl
M3  - Article
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 29; Correspondence Address: J.N. Ahour; Electrical Engineering Department, Shahed University, Tehran, P.O. Box 18155/159, Iran; email: jafar.ahoor@yahoo.com
ER  -

TY  - JOUR
AU  - Baral, A.
AU  - Chakravorti, S.
TI  - Assessment of non-uniform aging of solid dielectric using system poles of a modified debye model for oil-paper insulation of transformers
PY  - 2013
T2  - IEEE Transactions on Dielectrics and Electrical Insulation
VL  - 20
IS  - 5
C7  - 6633726
SP  - 1922
EP  - 1933
DO  - 10.1109/TDEI.2013.6633726
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-84887093015&doi=10.1109%2fTDEI.2013.6633726&partnerID=40&md5=a6c5747960fc3f7456c82e50a2cd6dae
AD  - Department of Electrical Engineering, Jadavpur University, West Bengal, India
AB  - Dielectric parameters of insulation used in High voltage equipments like power transformers are dependent on insulation size and geometry. As a result parameters evaluated from the model of one insulation system finds limited use in predicting the condition of other. Poles calculated from branch parameters of insulation model, on the other hand are independent of insulation geometry. However such technique requires accurate modeling of dielectric response function. Conventional Debye model does not consider the effect of temperature gradient that exists across the length of the insulation during its operation. In the present paper it is shown that for more accurate modeling and better understanding of dielectric response of oil-paper insulation, a new model which considers the effect of temperature gradient on insulation properties, is necessary. The present paper reports a methodology that is capable of identifying such a model using PDC measurement data. It is also shown that use of conventional Debye model overestimates the pole values and the error increases with usage of the insulation. © 1994-2012 IEEE.
KW  - conventional Debye model
KW  - modified Debye model
KW  - non-uniform aging
KW  - oil-paper insulation
KW  - poles
KW  - Temperature gradient
KW  - Insulation
KW  - Oil
KW  - Paper
KW  - Transformers
KW  - Dielectric materials
KW  - Insulation
KW  - Oil filled transformers
KW  - Phonons
KW  - Poles
KW  - Power transformers
KW  - Thermal gradients
KW  - Debye models
KW  - Dielectric parameters
KW  - Dielectric response function
KW  - Effect of temperature
KW  - High-voltage equipments
KW  - Modified debye models
KW  - Non-uniform
KW  - Oil paper insulation
KW  - Paper
SN  - 10709878 (ISSN)
LA  - English
J2  - IEEE Trans Dielectr Electr Insul
M3  - Article
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 44; CODEN: ITDIE
ER  -

TY  - JOUR
AU  - Akagi, J.-I.
AU  - Toyoda, T.
AU  - Cho, Y.-M.
AU  - Mizuta, Y.
AU  - Nohmi, T.
AU  - Nishikawa, A.
AU  - Ogawa, K.
TI  - Validation study of the combined repeated-dose toxicity and genotoxicity assay using gpt delta rats
PY  - 2015
T2  - Cancer Science
VL  - 106
IS  - 5
SP  - 529
EP  - 541
DO  - 10.1111/cas.12634
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-84929705647&doi=10.1111%2fcas.12634&partnerID=40&md5=517a66b587d51d6686e853daebfd4c0c
AD  - Division of Pathology, National Institute of Health Sciences, Tokyo, Japan
AD  - Biological Safety Research Center, National Institute of Health Sciences, Tokyo, Japan
AD  - Center for Innovative Drug Discovery and Development, National Institute of Biomedical Innovation, Tokyo, Japan
AB  - Transgenic rodents carrying reporter genes to detect organ-specific in vivo genetic alterations are useful for risk assessment of genotoxicity that causes cancer. Thus, the Organization for Economic Co-operation and Development has established the guideline for genotoxicity tests using transgenic animals, which may be combined with repeated-dose toxicity studies. Here, we provide evidence to support equivalence of gpt delta and wild type (WT) rats in terms of toxicological responses to a genotoxic hepatocarcinogen, N-nitrosodiethylamine (DEN), and a non-genotoxic hepatocarcinogen, di(2-ethylhexyl)phthalate (DEHP). gpt delta rats treated with DEHP showed similar increases in liver and kidney weights, serum albumin, albumin/globulin ratios, and incidence of diffuse hepatocyte hypertrophy compared to WT F344 and Sprague-Dawley (SD) rats. DEN-treated gpt delta rats showed equivalent increases in the number and area of precancerous GST-P-positive foci in the liver compared to WT rats. The livers of DEN-treated gpt delta rats also showed increased frequencies of gpt and Spi- mutations; such changes were not observed in DEHP-treated gpt delta rats. These results indicated that gpt delta rats (both F344 and SD backgrounds) showed comparable DEHP-induced toxicity and DEN-induced genotoxicity to those observed in WT rats. With regard to the administration period, the general toxicity of 1.2% DEHP was evident throughout the experimental period, and the genotoxicity of 10 p.p.m. DEN could be detected after 2 weeks of administration and further increased at 4 weeks. These results suggested that combined assays using gpt delta rats could detect both general toxicity and genotoxicity by the canonical 4-week administration protocol. Therefore, this assay using gpt delta rats would be applicable for risk assessment including early detection of genotoxic carcinogens and ultimately serve to reduce cancer risks in humans from environmental chemicals. © 2015 The Authors.
KW  - Genotoxicity
KW  - gpt delta
KW  - Mutation
KW  - Reduction of animal use
KW  - Repeated-dose toxicity
KW  - Animals
KW  - Carcinogens
KW  - Diethylhexyl Phthalate
KW  - Diethylnitrosamine
KW  - Dose-Response Relationship, Drug
KW  - Liver
KW  - Male
KW  - Mutagenicity Tests
KW  - Mutation
KW  - Organ Size
KW  - Rats, Inbred F344
KW  - Rats, Sprague-Dawley
KW  - Rats, Transgenic
KW  - alanine aminotransferase
KW  - albumin
KW  - alkaline phosphatase
KW  - diethylnitrosamine
KW  - globulin
KW  - phthalic acid bis(2 ethylhexyl) ester
KW  - protein
KW  - Spi protein
KW  - unclassified drug
KW  - carcinogen
KW  - diethylnitrosamine
KW  - phthalic acid bis(2 ethylhexyl) ester
KW  - albumin blood level
KW  - alkaline phosphatase blood level
KW  - animal experiment
KW  - animal model
KW  - animal tissue
KW  - Article
KW  - cell infiltration
KW  - controlled study
KW  - gene mutation
KW  - genotoxicity
KW  - genotoxicity assay
KW  - globulin blood level
KW  - heart injury
KW  - in vivo study
KW  - kidney injury
KW  - kidney mass
KW  - liver hypertrophy
KW  - liver injury
KW  - liver weight
KW  - lung lesion
KW  - male
KW  - mutation rate
KW  - nonhuman
KW  - priority journal
KW  - rat
KW  - spleen injury
KW  - stomach lesion
KW  - upregulation
KW  - validation study
KW  - weight reduction
KW  - animal
KW  - dose response
KW  - drug effects
KW  - Fischer 344 rat
KW  - liver
KW  - mutagen testing
KW  - mutation
KW  - organ size
KW  - pathology
KW  - procedures
KW  - Sprague Dawley rat
KW  - transgenic rat
SN  - 13479032 (ISSN)
C2  - 25683344
LA  - English
J2  - Cancer Sci.
M3  - Article
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 13; Correspondence Address: K. Ogawa; Division of Pathology, National Institute of Health Sciences, Tokyo, 1-18-1 Kamiyoga, Setagaya-ku, 158-8501, Japan; email: ogawa93@nihs.go.jp; CODEN: CSACC
ER  -

TY  - CONF
AU  - Baisa, V.
TI  - Czech grammar agreement dataset for evaluation of language models
PY  - 2016
T2  - 10th Workshop on Recent Advances in Slavonic Natural Language Processing, RASLAN 2016 - Proceedings
SP  - 63
EP  - 67
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85013663565&partnerID=40&md5=bc9f7a18c2dcbc5159600f46c4dd09dd
AD  - Natural Language Processing Centre, Faculty of Informatics, Masaryk University, Botanická 68a, Brno, 602 00, Czech Republic
AB  - AGREE is a dataset and task for evaluation of language models based on grammar agreement in Czech. The dataset consists of sentences with marked suffixes of past tense verbs. The task is to choose the right verb suffix which depends on gender, number and animacy of subject. It is challenging for language models because 1) Czech is morphologically rich, 2) it has relatively free word order, 3) high out-of-vocabulary (OOV) ratio, 4) predicate and subject can be far from each other, 5) subjects can be unexpressed and 6) various semantic rules may apply. The task provides a straightforward and easily reproducible way of evaluating language models on a morphologically rich language. © Tribun EU 2016.
KW  - Czech
KW  - Dataset
KW  - Evaluation
KW  - Grammar agreement
KW  - Language model
KW  - Perplexity
KW  - Predicate
KW  - Subject
KW  - Verb suffix
KW  - Computational linguistics
KW  - Semantics
KW  - Czech
KW  - Dataset
KW  - Evaluation
KW  - Language model
KW  - Perplexity
KW  - Predicate
KW  - Subject
KW  - Verb suffix
KW  - Natural language processing systems
A2  - Rychly P.
A2  - Masaryk University, Faculty of Informatics, Department of Information Technologies, Botanicka 68a, Brno
A2  - Horak A.
A2  - Masaryk University, Faculty of Informatics, Department of Information Technologies, Botanicka 68a, Brno
A2  - Rambousek A.
A2  - Masaryk University, Faculty of Informatics, Department of Information Technologies, Botanicka 68a, Brno
PB  - Tribun EU s. r. o.
SN  - 978-802631095-2 (ISBN)
LA  - English
J2  - Workshop Recent Adv. Slavon. Nat. Lang. Process., RASLAN - Proc.
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 1; Correspondence Address: V. Baisa; Natural Language Processing Centre, Faculty of Informatics, Masaryk University, Brno, Botanická 68a, 602 00, Czech Republic; email: xbaisa@fi.muni.cz; Conference name: 10th Workshop on Recent Advances in Slavonic Natural Language Processing, RASLAN 2016; Conference date: 2 December 2016 through 4 December 2016; Conference code: 126167
ER  -

TY  - JOUR
AU  - Zeinoddini-Meymand, H.
AU  - Vahidi, B.
TI  - Techno-economical lifetime assessment of power transformers rated over 50 MVA using artificial intelligence models
PY  - 2016
T2  - IET Generation, Transmission and Distribution
VL  - 10
IS  - 15
SP  - 3885
EP  - 3892
DO  - 10.1049/iet-gtd.2016.0480
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-84996503619&doi=10.1049%2fiet-gtd.2016.0480&partnerID=40&md5=4029af7fc33b37360c5e265de8566dd9
AD  - Department of Electrical Engineering, Amirkabir University of Technology (Tehran Polytechnic), 424 Hafez Avenue, Tehran, 15875-4413, Iran
AB  - Power transformers are some of the most valuable and critical elements of power systems. Therefore, accurate and detailed assessment of technical and economical (techno-economical) condition of the transformers is absolutely important to ensure its reliable operation. In this study, in order to assess the overall condition of the power transformers, an overall condition index (OI) obtained from technical lifetime index (TI) and economical lifetime index (EI) will be defined. The OI index, which provides a practical tool to assess the overall condition of the asset, combines the results of operating observations, field inspections, site and laboratory testing, and analysis of investment and operating and maintenance costs into an overall index. An adaptive neuro-fuzzy inference system model is used to assess the TI, and a fuzzy logic model is used for EI evaluation. Large power transformers rated over 50 MVA, which are more critical and important in the network, are investigated. The models are developed using 170 experimental field datasets of transformer oil characteristics and dissolved gas analysis, and economical data such as operating and maintenance costs. The results prove that the models can be used to effectively assess the techno-economical lifetime of power transformers. © 2016 The Institution of Engineering and Technology.
KW  - Artificial intelligence
KW  - Cost benefit analysis
KW  - Fuzzy inference
KW  - Fuzzy logic
KW  - Fuzzy neural networks
KW  - Fuzzy systems
KW  - Maintenance
KW  - Oil filled transformers
KW  - Power transformers
KW  - Adaptive neuro-fuzzy inference system
KW  - Critical elements
KW  - Dissolved gas analysis
KW  - Laboratory testing
KW  - Large power transformers
KW  - Lifetime assessment
KW  - Oil characteristics
KW  - Reliable operation
KW  - Economic analysis
PB  - Institution of Engineering and Technology
SN  - 17518687 (ISSN)
LA  - English
J2  - IET Gener. Transm. Distrib.
M3  - Article
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 8; Correspondence Address: B. Vahidi; Department of Electrical Engineering, Amirkabir University of Technology (Tehran Polytechnic), Tehran, 424 Hafez Avenue, 15875-4413, Iran; email: vahidi@aut.ac.ir
ER  -

TY  - JOUR
AU  - He, J.
AU  - Sun, Y.
AU  - Wang, P.
AU  - Cheng, L.
TI  - A hybrid conditions-dependent outage model of a transformer in reliability evaluation
PY  - 2009
T2  - IEEE Transactions on Power Delivery
VL  - 24
IS  - 4
SP  - 2025
EP  - 2033
DO  - 10.1109/TPWRD.2009.2028771
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-70350294291&doi=10.1109%2fTPWRD.2009.2028771&partnerID=40&md5=104717406fb5282cf4a1bfd7fb11d642
AD  - State Key Laboratory of Power Systems, Department of Electrical Engineering, Tsinghua University, Beijing 100084, China
AD  - School of Electrical and Electronic Engineering, Nanyang Technological University, Singapore, Singapore
AB  - Constant failure rate model used in the conventional reliability assessment of power systems cannot reflect the impacts of the various operating conditions such as transformer loading, ambient temperature, weather on component reliability. A hybrid conditions-dependent outage model (CDOM) of a transformer is proposed in this paper to include those impacts. The CDOM is the combination of three failure models: the aging failures due to the loss of mechanical strength of conductor insulation; the random failures considering weather conditions, and the outages caused by the direct trips of the overload protections. The component reliability using the proposed model has been tested under different operating conditions. The model is also applied in power system operational reliability assessment. The reliability indices using CDOM are compared with that using the condition-independent outage model. The reliability indices using the CDOMs of transformers can provide useful information for operators to understand possible system and component failure risk in real-time operation and to make important alleviation decisions. © 2009 IEEE.
KW  - Condition-dependent outage model (CDOM)
KW  - Operational reliability
KW  - Power system
KW  - Reliability assessment
KW  - Transformer
KW  - Electric power transmission networks
KW  - Outages
KW  - Power transmission
KW  - Pumps
KW  - Reliability analysis
KW  - Condition-dependent outage model (CDOM)
KW  - Operational reliability
KW  - Power system
KW  - Reliability assessment
KW  - Transformer
KW  - Transformer protection
SN  - 08858977 (ISSN)
LA  - English
J2  - IEEE Trans Power Delivery
M3  - Article
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 73; Correspondence Address: J. He; State Key Laboratory of Power Systems, Department of Electrical Engineering, Tsinghua University, Beijing 100084, China; email: j-he@mails.tsinghua.edu.cn; CODEN: ITPDE
ER  -

TY  - CONF
AU  - Szarvas, M.
AU  - Furui, S.
TI  - Evaluation of the stochastic morphosyntactic language model on a one millionword Hungarian dictation task
PY  - 2003
T2  - EUROSPEECH 2003 - 8th European Conference on Speech Communication and Technology
SP  - 2297
EP  - 2300
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-65349171767&partnerID=40&md5=7e96a79f270620452d6e626889edc388
AD  - Department of Computer Science, Tokyo Institute of Technology, 2-12-1, Ookayama, Meguro-ku, Tokyo, 152-8552, Japan
AB  - In this article we evaluate our stochastic morphosyntactic languagemodel (SMLM) on a Hungarian newspaper dictation task that requires modeling over 1 million different word forms. The proposed method is based on the use of morphemes as the basic recognition units and the combination of a morpheme N - gram model and a morphosyntactic language model. The architecture of the recognition system is based on the weighted finite-state transducer (WFST) paradigm. Thanks to the flexible transducer-based architecture, the morphosyntactic component is integrated seamlessly with the basic modules with no need to modify the decoder itself. We compare the phoneme, morpheme, and word error-rates as well as the sizes of the recognition networks in two configurations. In one configuration we use only the N-gram model while in the other we use the combined model. The proposed stochastic morphosyntactic language model decreases the morpheme error rate by between 1.7 and 7.2% relatively when compared to the baseline trigram system. The morpheme error-rate of the best configuration is 18% and the best word error-rate is 22.3%.
KW  - Errors
KW  - Network architecture
KW  - Speech communication
KW  - Speech recognition
KW  - Stochastic models
KW  - Stochastic systems
KW  - Transducers
KW  - Combined model
KW  - Hungarians
KW  - Language model
KW  - N-gram modeling
KW  - Recognition systems
KW  - Recognition units
KW  - Weighted finite-state transducers
KW  - Word error rate
KW  - Computational linguistics
PB  - International Speech Communication Association
LA  - English
J2  - EUROSPEECH - Euro. Conf. Speech Commun. Technol.
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 6; Conference name: 8th European Conference on Speech Communication and Technology, EUROSPEECH 2003; Conference date: 1 September 2003 through 4 September 2003; Conference code: 124334
ER  -

TY  - JOUR
AU  - Clarkson, P.
AU  - Robinson, T.
TI  - Improved language modelling through better language model evaluation measures
PY  - 2001
T2  - Computer Speech and Language
VL  - 15
IS  - 1
SP  - 39
EP  - 53
DO  - 10.1006/csla.2000.0156
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-0035058193&doi=10.1006%2fcsla.2000.0156&partnerID=40&md5=1d8db5fe5f19d2d319655c9cc3cde142
AD  - Cambridge University Engineering Department, Cambridge, Trumpington Street, United Kingdom
AB  - This paper explores the interaction between a language model's perplexity and its effect on the word error rate of a speech recognition system. Much recent research has indicated that these two measures are not as well correlated as was once thought, and many examples exist of models which have a much lower perplexity than the equivalent N-gram model, yet lead to no improvement in recognition accuracy. This paper investigates the reasons for this apparent discrepancy. Perplexity's calculation is based solely on the probabilities of words contained within the test text; it disregards the probabilities of alternative words which will be competing with the correct word within the decoder. It is shown that by considering the probabilities of the alternative words it is possible to derive measures of language model quality which are better correlated with word error rate than perplexity is. Furthermore, optimizing language model parameters with respect to these new measures leads to a significant reduction in the word error rate.
KW  - Computer simulation
KW  - Decoding
KW  - Optimization
KW  - Probability distributions
KW  - Random processes
KW  - Speech recognition
KW  - Language model evaluation measures
KW  - Perplexity
KW  - Word error rate
KW  - Computer simulation languages
PB  - Academic Press
SN  - 08852308 (ISSN)
LA  - English
J2  - Comput Speech Lang
M3  - Article
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 11; Correspondence Address: P. Clarkson; SpeechWorks International, Boston, MA 02111, 695 Atlantic Avenue, United States; email: philip.clarkson@speechworks.com; CODEN: CSPLE
ER  -

TY  - CONF
AU  - Zink, M.H.
AU  - Klipfel, V.
AU  - Berger, F.
AU  - Kuchler, A.
TI  - Ageing-condition assessment of generator transformer bushings by means of dielectric simulation models
PY  - 2012
T2  - Proceedings of 2012 IEEE International Conference on Condition Monitoring and Diagnosis, CMD 2012
C7  - 6416394
SP  - 137
EP  - 140
DO  - 10.1109/CMD.2012.6416394
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-84874276723&doi=10.1109%2fCMD.2012.6416394&partnerID=40&md5=6c84c16b17091e2c476a4fc178eedbf4
AD  - EnBW Kernkraft GmbH, Philippsburg, Germany
AD  - Technische Universität Ilmenau, Ilmenau, Germany
AD  - University of Applied Sciences Würzburg-Schweinfurt, Schweinfurt, Germany
AB  - Diagnosis and ageing-condition assessment of electrical equipment are getting more and more important, as many of the units in use are close to the end of their designed service life or have even exceeded it already. There are several tools for diagnosis which are well known and proven for transformer monitoring and assessment. In principle, the same tools can also be used for bushing diagnosis. The most common bushing diagnosis method is the capacity and dissipation factor measurement at power frequency and ambient temperature. It can be used to detect partial breakdowns prior to a bushing failure, but it is insensitive for the detection of ageing processes. At ambient temperature, dielectric analyses like PDC (polarization-depolarization current) measurementis significantly better suited to get information about the aging condition related to water or conductive ageing products inside the dielectric (see also [1]). To evaluate PDC measurements, it is very important to have the possibility for comparison of the results with either older measurements of comparable units or with simulation results. For bushing simulation, a special model was developed and presented in [2]. This tool was now adapted to 400 kV OIP (oil-impregnated paper) bushings. Further it was improved to perform more detailed simulations. The simulation model then has been used for comparison with measurement data of service aged bushings as well as for investigation of the influence of temperature and water content by the use of different parameter settings gained from laboratory sample measurements. © 2012 IEEE.
KW  - ageing condition assessment
KW  - bushing
KW  - dielectric simulation models
KW  - oil-impregnated paper
KW  - PDC measurement
KW  - Computer simulation
KW  - Condition monitoring
KW  - Electric insulation
KW  - Temperature
KW  - Ageing conditions
KW  - Ageing process
KW  - Aging conditions
KW  - Comparison with measurements
KW  - Diagnosis methods
KW  - Dielectric analysis
KW  - Dissipation factor measurement
KW  - Electrical equipment
KW  - Measurements of
KW  - Oil-impregnated paper
KW  - Parameter setting
KW  - Power frequency
KW  - Simulation model
KW  - Special models
KW  - Transformer bushings
KW  - Transformer monitoring
KW  - Bushings
SN  - 978-146731020-8 (ISBN)
LA  - English
J2  - Proc. IEEE Int. Conf. Cond. Monit. Diagn., CMD
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 10; Correspondence Address: M.H. Zink; EnBW Kernkraft GmbH, Philippsburg, Germany; email: markus.zink@fhws.de; Conference name: 2012 IEEE International Conference on Condition Monitoring and Diagnosis, CMD 2012; Conference date: 23 September 2012 through 27 September 2012; Conference code: 95660
ER  -

TY  - CONF
AU  - Feng, D.
AU  - Wang, Z.
AU  - Jarman, P.
TI  - Transmission power transformer assessment using furan measurement with the aid of thermal model
PY  - 2012
T2  - Proceedings of 2012 IEEE International Conference on Condition Monitoring and Diagnosis, CMD 2012
C7  - 6416194
SP  - 521
EP  - 524
DO  - 10.1109/CMD.2012.6416194
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-84874237234&doi=10.1109%2fCMD.2012.6416194&partnerID=40&md5=eb098beb61a694487f8771df120ec853
AD  - School of Electrical and Electronic Engineering, University of Manchester, Manchester M13 9PL, United Kingdom
AD  - National Grid, NG House, Warwick CV34 6DA, United Kingdom
AB  - As a potential insulation condition assessment technique for the field transformer, the correlation of the furan, or more specifically 2-furfural (2-FAL) measurement in oil and the insulating paper's degree of polymerization (DP) has been studied intensively in the laboratory by the means of accelerated ageing experiments. However due to the complicated operating conditions and design characteristics the field transformers are subjected to, it is not sensible to directly apply the correlation of 2FAL and DP derived based on laboratory works. In this paper, the field 2-FAL measurements have been analyzed on 49 UK National Grid (NG) field transmission power transformers. The insulating paper's DP of these transformers are estimated with the aid of the transformer thermal model, which was developed based on the thermal model in IEC transformer loading guide. As a result, a practical correlation has been established between the field 2-FAL measurement and insulating paper's DP estimates. The fitted model indicates that there is a possibility of developing a practical furan-DP relationship as a reliable insulation condition assessment technique for the field transformer. © 2012 IEEE.
KW  - degree of polymerization
KW  - furan diagnosis
KW  - thermal modeling
KW  - transmission power transformer
KW  - Aldehydes
KW  - Aromatic compounds
KW  - Condition monitoring
KW  - Insulating materials
KW  - Oil filled transformers
KW  - Organic pollutants
KW  - Polymerization
KW  - Thermography (temperature measurement)
KW  - 2-furfural
KW  - Accelerated ageing
KW  - Degree of polymerization
KW  - Design characteristics
KW  - Field transmission
KW  - Insulating paper
KW  - Insulation conditions
KW  - Laboratory work
KW  - National Grid
KW  - Operating condition
KW  - Thermal model
KW  - Thermal modeling
KW  - Transformer loadings
KW  - Transformer thermal models
KW  - Transmission power
KW  - Power transformers
SN  - 978-146731020-8 (ISBN)
LA  - English
J2  - Proc. IEEE Int. Conf. Cond. Monit. Diagn., CMD
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 24; Conference name: 2012 IEEE International Conference on Condition Monitoring and Diagnosis, CMD 2012; Conference date: 23 September 2012 through 27 September 2012; Conference code: 95660
ER  -

TY  - CONF
AU  - Guseva, S.
AU  - Mahnitko, A.
AU  - Breners, N.
TI  - Evaluation of measures on reliability rise of power transformers by means of generalized mathematical model
PY  - 2007
T2  - Proceedings of the 4th International Scientific Symposium on Electric Power Engineering, ELEKTROENERGETIKA 2007
SP  - 424
EP  - 427
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-84906997945&partnerID=40&md5=a6286607e0acdc6e2e2f898052ad1822
AD  - Riga Technical University, Power Engineering Institute, LV-1010, Riga, Kronvalda blv., 1, Latvia
AB  - In paper the mathematical model of economic estimation of measures for modernization of the high-voltage transformer equipment in Latvian Electric Company are given. The total annual discounted costs for whole transformer life cycle are taken as the objective function for an estimation of modernization measures. Technical University of Košice © 2007.
KW  - Estimation
KW  - Mathematical models
KW  - Discounted costs
KW  - High-voltage transformers
KW  - Objective functions
KW  - Technical universities
KW  - Transformer life
KW  - Power transformers
PB  - Technical University of Kosice, Elec
SN  - 978-805530400-7 (ISBN)
LA  - English
J2  - Proc. Int. Sci. Symp. Electr. Power Eng., ELEKTROENERGETIKA
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 0; Conference name: 4th International Scientific Symposium on Electric Power Engineering, ELEKTROENERGETIKA 2007; Conference date: 19 September 2007 through 21 September 2007; Conference code: 107517
ER  -

TY  - JOUR
AU  - Kezunović, M.
AU  - Kojović, L.
AU  - Abur, A.
AU  - Fromen, C.W.
AU  - Sevcik, D.R.
AU  - Phillips, F.
TI  - Experimental evaluaton of EMTP-Based current transformer models for protective relay transient study
PY  - 1994
T2  - IEEE Transactions on Power Delivery
VL  - 9
IS  - 1
SP  - 405
EP  - 413
DO  - 10.1109/61.277712
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-0028196198&doi=10.1109%2f61.277712&partnerID=40&md5=9393b07f615b7c8bbb782e7e7b495ff7
AD  - Texas A&M University, United States
AD  - Houston Lighting & Power, United States
AD  - Electric Power Research Institute, United States
AB  - This paper describes an EPRI study of Current Transformer (CT) digital models intended for protective relay transient performance analysis. Experimental evaluation of CT models implemented using Electro Magnetic Transient Program (EMTP) was carried out. © 1993 IEEE.
KW  - Current Transformer
KW  - Digital Simulation
KW  - EMTP
KW  - Transient Response
KW  - Computer simulation
KW  - Electric currents
KW  - Relay protection
KW  - Transformer windings
KW  - Current transformer digital models
KW  - Electromagnetic transient program
KW  - Nonlinear reactor models
KW  - Protective relay transient studies
KW  - Transformer protection
SN  - 08858977 (ISSN)
LA  - English
J2  - IEEE Trans Power Delivery
M3  - Article
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 123
ER  -

TY  - JOUR
AU  - Liao, R.
AU  - Wang, Q.
AU  - Luo, S.
AU  - Liao, Y.
AU  - Sun, C.
TI  - Condition assessment model for power transformer in service based on fuzzy synthetic evaluation
PY  - 2008
T2  - Dianli Xitong Zidonghua/Automation of Electric Power Systems
VL  - 32
IS  - 3
SP  - 70
EP  - 75
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-40749122511&partnerID=40&md5=30f95d0182b5f7543d5351a603651aa8
AD  - Key Laboratory of Ministry of Education on High Voltage Engineering, Chongqing University, Chongqing 400044, China
AD  - Chongqing Electric Power Corporation, Chongqing 400014, China
AB  - A multi-grade fuzzy evaluation method for power transformer using fuzzy theory is proposed. Firstly, a layered evaluation index system on the base of preventive experiments, including working surroundings, operation history, maintenance records, accessories section and so on is built. Then, the relative impairment degree is introduced to describe the relative grade of transformers changing from actual conditions to faults. Taking the relative impairment grade as inputs, a neural network is applied to compute the member function of dissolved gases. The member functions for qualitative indices and the quantitative indices are respectively determined with helps of a fuzzy statistic method and a fuzzy distribution method. An operation condition evaluation model for power transformer, which evaluates the state of every grade and gives a comprehensive assessment of transformer, is established on the base of the fuzzy synthetic judgment. Example analysis shows the condition assessment model proposed is sound and effective.
KW  - Condition assessment
KW  - Fuzzy synthetic evaluation
KW  - Power transformer
KW  - Accessories
KW  - Maintenance
KW  - Neural networks
KW  - Condition assessment
KW  - Fuzzy distribution method
KW  - Fuzzy statistic method
KW  - Fuzzy synthetic evaluation
KW  - Member function
KW  - Power transformers
SN  - 10001026 (ISSN)
LA  - Chinese
J2  - Dianli Xitong Zidonghue
M3  - Article
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 149; Correspondence Address: R. Liao; Key Laboratory of Ministry of Education on High Voltage Engineering, Chongqing University, Chongqing 400044, China; email: lruijin1@vilp.sina.com; CODEN: DXZIE
ER  -

TY  - CONF
AU  - Ito, A.
AU  - Kohda, M.
AU  - Ostendorf, M.
TI  - A NEW METRIC FOR STOCHASTIC LANGUAGE MODEL EVALUATION
PY  - 1999
T2  - 6th European Conference on Speech Communication and Technology, EUROSPEECH 1999
SP  - 1591
EP  - 1594
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-0000164742&partnerID=40&md5=231c3726fc911f7d27efa1f5c6578479
AD  - Yamagata University, 4-3-16 Jonan, Yonezawa, 992-0038, Japan
AD  - Boston University, 8 Saint Mary's St., Boston, 02416, MA, United States
AB  - Though Perplexity shows good correlation with word error rate within simple n-gram framework like Wall Street Journal task, it has been reported that perplexity have poor correlation with WER when more complicated LM is used. In this paper, a global measure for language model evaluation is proposed which achieves higher correlation between word accuracy. The metric is based on difference of LM score between a word in the evaluation text and the word that gives the maximum score at that context. Two experiments were carried out to investigate the correlation between word accuracy and the proposed measure. In the first experiment, LMs in this paper were created using n-gram adaptation by n-gram count mixture. 47 LMs were created for the experiments by changing mixture weight and vocabulary cut-off threshold. Correlation betwen perplexity and word accuracy was very poor (correlation coefficient -0.36). On the other hand, the proposed metric gave much higher correlation (correlation coefficient 0.82). In the second experiment, a simple mixture trigram model was employed to recognize Switchboard task data. The highest correlation between word accuracy and the proposed method was 0.81, which was much higher than the correlation between PP and accucary 0.59. © 1999 6th European Conference on Speech Communication and Technology, EUROSPEECH 1999. All rights reserved.
KW  - Computational linguistics
KW  - Speech communication
KW  - Stochastic models
KW  - Stochastic systems
KW  - Correlation coefficient
KW  - Global measures
KW  - Good correlations
KW  - Model evaluation
KW  - N-grams
KW  - Simple++
KW  - Stochastic language models
KW  - Wall Street Journal
KW  - Word accuracies
KW  - Word error rate
KW  - Mixtures
PB  - The International Society for Computers and Their Applications (ISCA)
LA  - English
J2  - Eur. Conf. Speech Commun. Technol., EUROSPEECH
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 6; Conference name: 6th European Conference on Speech Communication and Technology, EUROSPEECH 1999; Conference date: 5 September 1999 through 9 September 1999; Conference code: 180617
ER  -

TY  - JOUR
AU  - Thiyagarajan, M.
AU  - Venkatachalam, P.
TI  - Evaluation of the genetic fidelity of in vitro propagated natural sweetener plant (Stevia rebaudiana Bert.) using DNA-based markers
PY  - 2012
T2  - Plant Cell Biotechnology and Molecular Biology
VL  - 13
IS  - 3-4
SP  - 93
EP  - 98
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-84873563465&partnerID=40&md5=6a00439fd896574cf0929b195bee53d9
AD  - Plant Genetic Engineering and Molecular Biology Lab., Department of Biotechnology, Periyar University, Salem-636 011, Periyar Palkalai Nagar, India
AB  - The genetic fidelity of in vitro-raised Stevia rebaudiana clones was assessed by using Random Amplified Polymorphic DNA (RAPD) analysis. A total of 40 RAPD primers were used for initial screening with the mother plant of Stevia but only 29 RAPD decamer produced clear and reproducible bands. The number of scorable bands for each RAPD primer varied from 2 (OPA-15) to 9 (OPA-2). The 29 RAPD primers produced 106 distinct and scorable bands, with an average of 3.6 bands per primer. Each primer generated a unique set of amplification products ranging in size from 350 bp to 2,200 bp. No polymorphism was detected with RAPD analysis using DNA from in vitro-raised plantlets. In this study, the true-to-type nature of the in vitro raised plants was confirmed using DNA-based markers. No genetic variability was detected among the tissue culture-raised plantlets; hence, nodal explants can be successfully employed for the commercial multiplication of Stevia without much risk of genetic instability. © 2012 Society for Biology and Biotechnology.
KW  - Genetic fidelity
KW  - Nodal explants
KW  - Polymorphism
KW  - Stevia rebaudiana
KW  - Stevia rebaudiana
SN  - 09722025 (ISSN)
LA  - English
J2  - Plant Cell Biotechnol. Mol. Biol.
M3  - Article
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 3; Correspondence Address: P. Venkatachalam; Plant Genetic Engineering and Molecular Biology Lab., Department of Biotechnology, Periyar University, Salem-636 011, Periyar Palkalai Nagar, India; email: pvenkat67@yahoo.com; CODEN: PCBMC
ER  -

TY  - CONF
AU  - Zamora-Martínez, F.
AU  - Castro-Bleda, M.J.
AU  - España-Boquera, S.
TI  - Fast evaluation of connectionist language models
PY  - 2009
T2  - Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)
VL  - 5517 LNCS
IS  - PART 1
SP  - 33
EP  - 40
DO  - 10.1007/978-3-642-02478-8_5
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-68749109878&doi=10.1007%2f978-3-642-02478-8_5&partnerID=40&md5=e7ecb60d449c5f9a2243583ff10aaaf0
AD  - Departamento de Ciencias Físicas, Matemáticas y de la Computación, Universidad CEU-Cardenal Herrera, Alfara del Patriarca (Valencia) 46115, Spain
AD  - Departamento de Sistemas Informáticos y Computación, Universidad Politécnica de Valencia, Valencia, Spain
AB  - Connectionist language models offer many advantages over their statistical counterparts, but they also have some drawbacks like a much more expensive computational cost. This paper describes a novel method to overcome this problem. A set of normalization values associated to the most frequent n-gramsis pre-computed and the model is smoothed with lower n-gramconnectionist or statistical models. The proposed approach is favourably compared to standard connectionist language models and with statistical back-off language models. © 2009 Springer Berlin Heidelberg.
KW  - Backpropagation
KW  - Computational linguistics
KW  - Back-off
KW  - Computational costs
KW  - Language model
KW  - Novel methods
KW  - Statistical models
KW  - Neural networks
SN  - 16113349 (ISSN); 3642024777 (ISBN); 978-364202477-1 (ISBN)
LA  - English
J2  - Lect. Notes Comput. Sci.
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 10; Correspondence Address: F. Zamora-Martínez; Departamento de Ciencias Físicas, Matemáticas y de la Computación, Universidad CEU-Cardenal Herrera, Alfara del Patriarca (Valencia) 46115, Spain; email: fzamora@dsic.upv.es; Conference name: 10th International Work-Conference on Artificial Neural Networks, IWANN 2009; Conference date: 10 June 2009 through 12 June 2009; Conference code: 77015
ER  -

TY  - JOUR
AU  - Ning, L.
AU  - Wu, W.
AU  - Zhang, B.
TI  - Time-varying transformer outage model for operational risk assessment. Part two. Time-varying transformer outage model based on delayed semi-Markov process
PY  - 2010
T2  - Dianli Xitong Zidonghua/Automation of Electric Power Systems
VL  - 34
IS  - 16
SP  - 24
EP  - 28
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-77956357538&partnerID=40&md5=f3101991ae0edd5283328d6f9ed91773
AD  - State Key Lab. of Power Systems, Department of Electrical Engineering, Tsinghua University, Beijing 100084, China
AB  - A time-varying transformer outage model for operational risk assessment is proposed. Firstly, the state of a transformer is classified into three states: operation state, failure state caused by external accessory fault and failure state caused by internal latent fault. These three states can closely represent the operating mechanism in the developing process of transformer's outages. A time-varying outage model based on delayed semi-Markov process is proposed subsequently. This model can accommodate the difference in repairing time between the two failure states, as well as the impact of maintenance on the internal latent failure rate. Finally, a numerical example is provided to verify the proposed model. © 2010 State Grid Electric Power Research Institute Press.
KW  - Delayed renewal process
KW  - Failure rate
KW  - Instantaneous state probability
KW  - Operational risk assessment
KW  - Semi-Markov process
KW  - Time-varying outage model
KW  - Transformer
KW  - Markov processes
KW  - Outages
KW  - Time varying systems
KW  - Delayed renewal process
KW  - Failure rate
KW  - Operational risks
KW  - Semi markov process
KW  - State probability
KW  - Time varying
KW  - Transformer
KW  - Risk assessment
SN  - 10001026 (ISSN)
LA  - Chinese
J2  - Dianli Xitong Zidonghue
M3  - Article
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 8; Correspondence Address: L. Ning; State Key Lab. of Power Systems, Department of Electrical Engineering, Tsinghua University, Beijing 100084, China; email: ningly05@mails.tsinghua.edu.cn; CODEN: DXZIE
ER  -

TY  - JOUR
AU  - Kawamura, Y.
AU  - Hayashi, H.
AU  - Tajima, O.
AU  - Yamada, S.
AU  - Takayanagi, T.
AU  - Hori, H.
AU  - Fujii, W.
AU  - Masumura, K.
AU  - Nohmi, T.
TI  - Evaluation of the genotoxicity of aristolochic acid in the kidney and liver of F344 gpt delta transgenic rat using a 28-day repeated-dose protocol: A collaborative study of the gpt delta transgenic rat mutation assay
PY  - 2012
T2  - Genes and Environment
VL  - 34
IS  - 1
SP  - 18
EP  - 24
DO  - 10.3123/jemsge.34.18
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-84860666442&doi=10.3123%2fjemsge.34.18&partnerID=40&md5=d255815f51531aa0c6e640ef28590795
AD  - Toxicology Laboratory, Pharmaceutical Research Center, Meiji Seika Pharma Co., Ltd., Kohoku-ku, Yokohama 222-8567, 760 Morooka-cho, Japan
AD  - Research Planning and Management, R and D Planning and Management Dept., Meiji Seika Pharma Co., Ltd., Tokyo, Japan
AD  - Food Safety Assurance Center, Quality Assurance and Environment Management Department, Kirin Group Office Co., Ltd., Yokohama, Japan
AD  - Safety Science Institute, Quality Assurance Division, Suntory Business Expert Ltd., Osaka, Japan
AD  - Division of Genetics and Mutagenesis, National Institute of Health Sciences, Tokyo, Japan
AB  - Transgenic rat gene-mutation assays can be used to assess genotoxicity of chemicals in target organs for carcinogenicity. Since gene mutations in transgenes are genetically neutral and thus accumulate along with treatment periods, the assays are suitable for genotoxicity risk assessment of chemicals using repeated-dose treatment methodologies. However, few studies have been conducted to examine the suitability of the assays in repeat-dose treatment protocols. In order to prove the utility of the transgenic rat assays, we treated gpt delta rats with aristolochic acid at 0.3 and 1 mg/kg by gavage daily for 28 days, and autopsied the rats 3 days after the final treatment, which is a protocol recommended by the International Workshop on Genotoxicity Testing (IWGT). Aristolochic acid exists in herbs and some other plants, and is carcinogenic in the kidney, bladder and stomach in rats. The mutant frequency (MF) in both the kidney and the liver increased significantly in a dose-dependent manner when the rats were treated with aristolochic acid. We concluded that the gpt delta rat assay is sensitive enough to detect gene mutations induced by aristolochic acid and also that the 28-day repeated-dose protocol is suitable for assessing genotoxicity of chemicals. © The Japanese Environmental Mutagen Society.
KW  - 28-day repeated-dose protocol
KW  - Aristolochic acid
KW  - F344 gpt delta transgenic rat
KW  - gpt assay
KW  - Rattus
KW  - aristolochic acid
KW  - animal experiment
KW  - animal model
KW  - animal tissue
KW  - article
KW  - autopsy
KW  - bladder
KW  - carcinogenicity
KW  - clinical evaluation
KW  - controlled study
KW  - diagnostic value
KW  - feeding
KW  - Fischer 344 rat
KW  - gene frequency
KW  - gene mutation
KW  - genotoxicity
KW  - kidney
KW  - liver
KW  - nonhuman
KW  - rat
KW  - stomach
KW  - transgenic rat
SN  - 18807062 (ISSN)
LA  - English
J2  - Genes Environ.
M3  - Article
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 11; Correspondence Address: Y. Kawamura; Toxicology Laboratory, Pharmaceutical Research Center, Meiji Seika Pharma Co., Ltd., Kohoku-ku, Yokohama 222-8567, 760 Morooka-cho, Japan; email: yuuji.kawamura@meiji.com
ER  -

TY  - CONF
AU  - Varona, A.
AU  - Torres, I.
TI  - Back-off smoothing evaluation over syntactic language models
PY  - 2001
T2  - EUROSPEECH 2001 - SCANDINAVIA - 7th European Conference on Speech Communication and Technology
SP  - 2135
EP  - 2138
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85009059959&partnerID=40&md5=3c52a16db22c1f9612a12372e961b671
AD  - Dpto. Electricidad y Electrnica, Universidad del País Vasco, Apdo. 644 Bilbao, 48080, Spain
AB  - Continuous Speech Recognition systems require a Language Model (LM) to represent the syntactic constraints of the language. In LMs development a smoothing technique needs to be applied to also consider events not represented in the training corpus. In this work, several back-off smoothing approaches have been compared: classical discounting-distribution schema including Witten-Bell, Absolute and Linear discounting and a new proposal, the Delimited discounting. Delimited discounting deals with the Turing discounting problems while keeping the Katźs smoothing scheme. The experimental evaluation was carried out over a Spanish speech application task, showing that an increase of the test set perplexity of a LM does not always mean a degradation in the model performance when integrated into a CSR system. Besides, there is a strong dependence between the amount of probability reserved by the smoothing technique to be assigned to unseen events and the value of the balance parameter applied to the LM probabilities in the Bayeśs rule needed to get the best system performance.
KW  - Computational linguistics
KW  - Continuous speech recognition
KW  - Speech recognition
KW  - Steel beams and girders
KW  - Syntactics
KW  - Continuous speech
KW  - Experimental evaluation
KW  - Model performance
KW  - Smoothing techniques
KW  - Speech applications
KW  - Strong dependences
KW  - Syntactic languages
KW  - Test set perplexity
KW  - Speech communication
A2  - Lindberg B.
A2  - Benner H.
A2  - Dalsgaard P.
A2  - Tan Z.-H.
PB  - International Speech Communication Association
SN  - 8790834100 (ISBN); 978-879083410-4 (ISBN)
LA  - English
J2  - EUROSPEECH - SCANDINAVIA - Euro. Conf. Speech Commun. Technol.
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 2; Conference name: 7th European Conference on Speech Communication and Technology - Scandinavia, EUROSPEECH  2001; Conference date: 3 September 2001 through 7 September 2001; Conference code: 124332
ER  -

TY  - JOUR
AU  - Ning, L.
AU  - Wu, W.
AU  - Zhang, B.
TI  - Time-varying transformer outage model for operational risk assessment part one condition based failure rate estimation method for transformer internal latent fault estimation
PY  - 2010
T2  - Dianli Xitong Zidonghua/Automation of Electric Power Systems
VL  - 34
IS  - 15
SP  - 9
EP  - 13+95
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-77956003048&partnerID=40&md5=cdc5fa37fdb4acfa3a66f73bde6241c6
AD  - State Key Lab of Power System, Department of Electrical Engineering, Tsinghua University, Beijing 100084, China
AB  - A condition based failure rate estimation method for transformer internal latent fault analysis is proposed. The method is used to develop time-varying transformer outage model for operational risk assessment purpose. Firstly, the operating mechanism in developing process of transformer internal latent fault is analyzed, and some comments are given on the existing aging models of transformer internal insulation. Then, dissolved gas analysis (DGA) outcome is used as an indicator to classify transformer's operating condition. The multi-state Markov process based mathematical estimation model is proposed to estimate the failure rate. Finally, a numerical test is presented. © 2010 state Grid Electric Power Research Institute Press.
KW  - Dissolved gas analysis (DGA)
KW  - Failure rate
KW  - Insulation aging
KW  - Markov process
KW  - Operational risk assessment
KW  - Time-varying outage model
KW  - Transformer
KW  - Dissolution
KW  - Estimation
KW  - Gas chromatography
KW  - Markov processes
KW  - Outages
KW  - Quality assurance
KW  - Time varying systems
KW  - Dissolved gas analysis
KW  - Failure rate
KW  - Insulation aging
KW  - Operational risks
KW  - Time varying
KW  - Transformer
KW  - Risk assessment
SN  - 10001026 (ISSN)
LA  - Chinese
J2  - Dianli Xitong Zidonghue
M3  - Article
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 22; Correspondence Address: L. Ning; State Key Lab of Power System, Department of Electrical Engineering, Tsinghua University, Beijing 100084, China; email: ningly05@mails.tsinghua.edu.cn; CODEN: DXZIE
ER  -

TY  - CONF
AU  - Hailu, H.
AU  - Sznaier, M.
TI  - A frequency domain robust model validation approach to fault detection and isolation with applications to identification of contaminants in lubrication and transformer oils
PY  - 2006
T2  - Proceedings of the IEEE Conference on Decision and Control
C7  - 4177910
SP  - 1177
EP  - 1182
DO  - 10.1109/cdc.2006.376728
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-39649102594&doi=10.1109%2fcdc.2006.376728&partnerID=40&md5=a5e1a305191233cdcc4a6bef42c948fd
AD  - Department of Mechanical and Nuclear Engineering, Pennsylvania State University, University Park, PA 16802, United States
AD  - Department of Electrical Engineering, Pennsylvania State University, University Park, PA 16802, United States
AB  - This paper addresses the problem of robust fault detection and isolation in dynamical systems using frequency domain data. Our main result shows that this problem can be reduced to a convex optimization problem that can be efficiently solved. The proposed method is put to test on a nontrivial, practically relevant problem: detecting the presence and estimating the composition of contaminants in lubrication and transformer oil. © 2006 IEEE.
KW  - Dynamical systems
KW  - Fault detection
KW  - Frequency domain analysis
KW  - Optimization
KW  - Problem solving
KW  - Convex optimization
KW  - Transformer oils
KW  - Identification (control systems)
PB  - Institute of Electrical and Electronics Engineers Inc.
SN  - 07431546 (ISSN); 1424401712 (ISBN); 978-142440171-0 (ISBN)
LA  - English
J2  - Proc IEEE Conf Decis Control
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 0; Conference name: 45th IEEE Conference on Decision and Control 2006, CDC; Conference date: 13 December 2006 through 15 December 2006; Conference code: 71426; CODEN: PCDCD
ER  -

TY  - CONF
AU  - Hu, X.
AU  - Isotani, R.
AU  - Kawai, H.
AU  - Nakamura, S.
TI  - Construction and evaluations of an annotated Chinese conversational corpus in travel domain for the language model of speech recognition
PY  - 2010
T2  - Proceedings of the 11th Annual Conference of the International Speech Communication Association, INTERSPEECH 2010
SP  - 1910
EP  - 1913
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-79959841135&partnerID=40&md5=ded7aa92d5f6eb858af84446bed3ab43
AD  - National Institute of Information and Communications Technology, Japan
AB  - In this paper we describe the development of an annotated Chinese conversational textual corpus for speech recognition in a speech-to-speech translation system in the travel domain. A total of 515, 000 manually checked utterances were constructed, which provided a 3.5 million word Chinese corpus with word segmentation and part-of-speech tagging. The annotation is conducted with careful manual checking. The specifications on word segmentation and POS-tagging are designed to follow the main existing Chinese corpora that are widely accepted by researchers of Chinese natural language processing. Many particular features of conversational texts are also taken into account. With this corpus, parallel corpora are obtained together with the corresponding pairs of Japanese and English texts from which the Chinese was translated. To evaluate the corpus, the language models built by it are evaluated using perplexity and speech recognition accuracy as criteria. The perplexity of the Chinese language model is verified as having reached a reasonably low level. Recognition performance is also found to be comparable to the other two languages, even though the quantity of training data for Chinese is only half the other two languages. © 2010 ISCA.
KW  - Chinese speech recognition
KW  - Corpus construction
KW  - Language model
KW  - Computational linguistics
KW  - Natural language processing systems
KW  - Speech
KW  - Speech communication
KW  - Syntactics
KW  - Translation (languages)
KW  - Speech transmission
KW  - Chinese language modeling
KW  - Chinese natural language processing
KW  - Chinese speech recognition
KW  - Corpus construction
KW  - Language model
KW  - Part of speech tagging
KW  - Recognition accuracy
KW  - Speech-to-speech translation
KW  - Chinese corpus
KW  - Manual checking
KW  - Parts-of-speech tagging
KW  - Speech translation systems
KW  - Word segmentation
KW  - Speech recognition
PB  - International Speech Communication Association
LA  - English
J2  - Proc. Annu. Conf. Int. Speech Commun. Assoc., INTERSPEECH
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 3; Correspondence Address: X. Hu; National Institute of Information and Communications Technology, Japan; email: xinhui.hu@nict.go.jp
ER  -

TY  - JOUR
AU  - Ahmedou, M.O.
AU  - Chraygane, M.
AU  - Ferfra, M.
TI  - New π model validation approach to the leakage flux transformer of a high voltage power supply used for magnetron for the industrial micro-waves generators 800 watts
PY  - 2010
T2  - International Review of Electrical Engineering
VL  - 5
IS  - 3
SP  - 1003
EP  - 1011
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-79956222021&partnerID=40&md5=25fddf0d9193de0555a74d74c9c52b98
AD  - Power electronics Laboratory, EMI, Mohammadia Engineering School (Mohamed V University), Rabat Agdal, BP 765 Avenue Ibn Sina, Morocco
AD  - MSTI Laboratory, ESTA, Technologie higher school Agadir (Ibn Zohr University), Agadir, BP 33/S 80000, Morocco
AB  - The high voltage power supply for magnetron, used for the microwaves generators in industrial applications, is a classical design. This system is composed of a phase leakage flux transformer supplying a cell composed of a capacitor and a diode, which double the voltage and stabilize the current. A π quadruple model of this transformer is developed taking into account the saturation phenomena and the stabilization process of a magnetron current. Each inductance of the model is characterized by a non linear relation between flux and current that we obtain directly from the transformer's data (magnetizing curves, geometry, etc.). In this paper, we present a new validation approach of this model, by MATLAB- SIMULINK® code at the nominal state, based on the comparison between experimental and simulated fluxes. The simulation curves match the experimental measurements as closely as expected. The results from SIMULINK and EMTP® (Electromagnetic Transient Program) code are also compared. The results' analysis confirms the conservation law of fluxes and proves that the leakage flux in the shunt can not be ignoredcontrarily to the conventional transformer. © 2010 Praise Worthy Prize S.r.l.
KW  - EMTP
KW  - Generators
KW  - High Voltage (HV)
KW  - Magnetrons
KW  - Microwaves
KW  - Modeling
KW  - Power Supply
KW  - SIMULINK
KW  - Transformer
PB  - Praise Worthy Prize S.r.l
SN  - 18276660 (ISSN)
LA  - English
J2  - Int. Rev. Elec. Eng.
M3  - Article
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 26; Correspondence Address: M. O. Ahmedou; Power electronics Laboratory, EMI, Mohammadia Engineering School (Mohamed V University), Rabat Agdal, BP 765 Avenue Ibn Sina, Morocco; email: ouldahmedou@emi.ac.ma
ER  -

TY  - JOUR
AU  - Xiong, H.
AU  - Sun, C.
AU  - Zhang, Y.
AU  - Tan, Z.
AU  - Dai, Y.
TI  - A hierarchical grey evaluation model for operation condition of power transformers
PY  - 2007
T2  - Dianli Xitong Zidonghua/Automation of Electric Power Systems
VL  - 31
IS  - 7
SP  - 55
EP  - 60
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-34248350401&partnerID=40&md5=7cb7fae9938d085a3a28406a8122b26e
AD  - Key Laboratory of High Voltage and Electrical New Technology, Chongqing University, Chongqing 400030, China
AD  - Chongqing Electric Power Corporation Extra-High Voltage Department, Chongqing 400039, China
AB  - Condition assessment of power transformers is an important approach to providing decision-making for condition maintenance and improving the operation reliability of power systems. The power transformer's operation condition is related to quite a few factors, part of which are vague, making its condition estimation a tough job. A hierarchical grey evaluation method is then introduced to assess the condition of the power transformer. Two models consisting of the abrupt-change condition assessment model and gradual-change condition assessment model are developed via a hierarchical grey relation analysis to evaluate the transformer's operating condition. The appropriate indices of condition assessment are selected and quantified in two models, respectively. Its variable weights are determined by modifying the constant weight obtained by grey relation analysis so as to improve the accuracy of condition assessment. The results of an example analysis indicate that the hierarchical grey evaluation method proposed is feasible and effective.
KW  - Condition maintenance
KW  - Grey relation analysis
KW  - Hierarchical grey evaluation model
KW  - Operation condition assessment
KW  - Power transformer
KW  - Variable weight
KW  - Decision making
KW  - Electric power systems
KW  - Maintenance
KW  - Condition maintenance
KW  - Grey relation analysis
KW  - Hierarchical grey evaluation model
KW  - Operation condition assessment
KW  - Variable weight
KW  - Power transformers
SN  - 10001026 (ISSN)
LA  - Chinese
J2  - Dianli Xitong Zidonghue
M3  - Article
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 45; Correspondence Address: H. Xiong; Key Laboratory of High Voltage and Electrical New Technology, Chongqing University, Chongqing 400030, China; email: xiong_hao@sohu.com; CODEN: DXZIE
ER  -

TY  - CONF
AU  - Biçen, Y.
AU  - Çilliyüz, Y.
AU  - Aras, F.
AU  - Aydugan, G.
TI  - An assessment on aging model of IEEE/IEC standards for natural and mineral oil-immersed transformer
PY  - 2011
T2  - Proceedings - IEEE International Conference on Dielectric Liquids
C7  - 6015442
DO  - 10.1109/ICDL.2011.6015442
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-80155136314&doi=10.1109%2fICDL.2011.6015442&partnerID=40&md5=125ad8f60e1aba5b1594189053996409
AD  - Industrial Electronics Dept., Duzce Univ., TR-81010, Uzunmustafa Duzce, Turkey
AD  - Electrical Edu. Dept., Kocaeli Univ., TR-41380, Umuttepe Izmit, Turkey
AD  - Power Transformer Dept., AREVA TandD, TR-41410, Gebze, Kocaeli, Turkey
AB  - This paper presents an assessment on aging model of IEEE and IEC standards using thermal model of oil-immersed power transformer for natural ester and mineral oil. For this purpose, a model created for the analysis of behavior transient thermal performance with aging both of natural ester and mineral oils. Thermal model of the transformer is based on thermal-electrical analogy that is calculated separately for natural and mineral oils covering top-oil and hot-spot temperatures. The hot-spot temperature values of each ester/oil are used to calculate aging parameters which include the aging acceleration factor, time dependent relative aging rate and insulation life loss variations. © 2011 IEEE.
KW  - aging
KW  - insulation
KW  - loadability
KW  - natural oil
KW  - temperature
KW  - thermal model
KW  - trasformer
KW  - Esterification
KW  - Esters
KW  - Lubricating oils
KW  - Mineral oils
KW  - Oil filled transformers
KW  - Power transformers
KW  - Silicate minerals
KW  - Thermography (temperature measurement)
KW  - Acceleration factors
KW  - Aging models
KW  - Aging parameter
KW  - Aging rates
KW  - Hotspot temperature
KW  - IEC standards
KW  - Insulation life
KW  - Loadability
KW  - Loss variation
KW  - natural oil
KW  - Oil immersed transformers
KW  - Oil-immersed power transformers
KW  - Thermal model
KW  - Thermal Performance
KW  - Thermal-electrical analogy
KW  - Time dependent
KW  - trasformer
KW  - Dielectric liquids
SN  - 21533733 (ISSN); 978-142447355-7 (ISBN)
LA  - English
J2  - Proc. - IEEE Int. Conf. Dielectr. Liq.
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 18; Correspondence Address: Y. Biçen; Industrial Electronics Dept., Duzce Univ., TR-81010, Uzunmustafa Duzce, Turkey; email: yunusbicen@duzce.edu.tr; Conference name: 2011 IEEE International Conference on Dielectric Liquids, ICDL 2011; Conference date: 26 June 2011 through 30 June 2011; Conference code: 87137
ER  -

TY  - CONF
AU  - Alain, P.
AU  - Boëffard, O.
AU  - Barbot, N.
TI  - Evaluating language models within a predictive framework: An analysis of ranking distributions
PY  - 2006
T2  - Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)
VL  - 4188 LNCS
SP  - 319
EP  - 326
DO  - 10.1007/11846406_40
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-33750395439&doi=10.1007%2f11846406_40&partnerID=40&md5=e723b6e9a7d025b417cba20a280d19d8
AD  - IRISA, Université de Rennes 1, ENSSAT, F-22305 Lannion Cedex, 6 rue de Kerampont, France
AB  - Perplexity is a widely used criterion in order to compare language models without any task assumptions. However, the main drawback is that perplexity supposes probability distributions and hence cannot compare heterogeneous models. As an evaluation framework, we propose in this article to abandon perplexity and to extend the Shannon's entropy idea which is based on model prediction performance using rank based statistics. Our methodology is able to predict joint word sequences being independent of the task or model assumptions. Experiments are carried out on the English language with different kind of language models. We show that long-term prediction language models are not more effective than the standard n-gram models. Ranking distributions follow exponential laws as already observed in predicting letter sequences. These distributions show a second mode not observed with letters and we propose to give some interpretation to this mode in this article. © Springer-Verlag Berlin Heidelberg.
KW  - Mathematical models
KW  - Probability distributions
KW  - Statistical methods
KW  - Exponential laws
KW  - Prediction language models
KW  - Shannon's entropy
KW  - Standard n-gram models
KW  - Computer programming languages
PB  - Springer Verlag
SN  - 03029743 (ISSN); 3540390901 (ISBN); 978-354039090-9 (ISBN)
LA  - English
J2  - Lect. Notes Comput. Sci.
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 0; Correspondence Address: P. Alain; IRISA, Université de Rennes 1, ENSSAT, F-22305 Lannion Cedex, 6 rue de Kerampont, France; email: pierre.alain@irisa.fr; Conference name: 9th International Conference on Text, Speech and Dialogue, TSD 2006; Conference date: 11 September 2006 through 15 September 2006; Conference code: 68369
ER  -

TY  - CONF
AU  - Liu, J.-X.
AU  - Qi, Z.-Z.
AU  - Zhang, W.-H.
AU  - Qiu, Z.
TI  - Evaluation model of operating status for power transformer based on extension strategy generating system
PY  - 2008
T2  - 2008 China International Conference on Electricity Distribution, CICED 2008
C7  - 5211804
DO  - 10.1109/CICED.2008.5211804
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-70449397158&doi=10.1109%2fCICED.2008.5211804&partnerID=40&md5=e63eb575a4cbe0bd635ea940d26ad95e
AD  - North of China Electric Power University, Baoding 071003, China
AB  - Power transformer is a complicated system due to its stochastic, fuzzy and alterable behavior. It is a decision-making problem of engineering system to assess transformer behavior. Qualitative knowledge and quantitative data need to be integrated. Quantitative change and qualitative change all need be reflected in the assessment results of transformer behavior. The behavior of whole transformer system need also be assessed by combination of different items. A method integrating quantitative and qualitative information need be used to assess transformer behavior. Extension theory is used generally to solve the inconsistent problems. A matter element consisted of research object, evaluation index, normalized value. According to rhombic thinking mode and the extension of matter element, the multi-index and hierarchical system of transformer behavior evaluation was built. Matter-element model was constructed to assess transformer behavior by matter-element transform. Three-dimensional evaluation for the behavior of whole transformer system can be implemented by quantitative, qualitative description and their change with time.
KW  - Electric instrument transformers
KW  - Electric power distribution
KW  - Electric utilities
KW  - Hierarchical systems
KW  - Power transformers
KW  - Transformer substations
KW  - Behavior evaluations
KW  - Complicated systems
KW  - Decision-making problem
KW  - Engineering systems
KW  - Evaluation index
KW  - Evaluation models
KW  - Extension theory
KW  - Generating system
KW  - Matter elements
KW  - Matter-element
KW  - Matter-element model
KW  - Multi-index
KW  - Normalized values
KW  - Qualitative changes
KW  - Qualitative information
KW  - Qualitative knowledge
KW  - Quantitative changes
KW  - Quantitative data
KW  - Research object
KW  - Thinking modes
KW  - Transformer systems
KW  - Three dimensional
SN  - 978-142443373-5 (ISBN)
LA  - English
J2  - China Int. Conf. Electr. Distrib., CICED
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 0; Conference name: 2008 China International Conference on Electricity Distribution, CICED 2008; Conference date: 10 December 2008 through 13 December 2008; Conference code: 77945
ER  -

TY  - CONF
AU  - Ahuja, A.
AU  - Downey, D.
TI  - Improved extraction assessment through better language models
PY  - 2010
T2  - NAACL HLT 2010 - Human Language Technologies: The 2010 Annual Conference of the North American Chapter of the Association for Computational Linguistics, Proceedings of the Main Conference
SP  - 225
EP  - 228
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-84858433233&partnerID=40&md5=d821340f62afab03c58e72c70425ed5a
AD  - EECS Dept., Northwestern University, Evanston, IL 60208, United States
AB  - A variety of information extraction techniques rely on the fact that instances of the same relation are "distributionally similar," in that they tend to appear in similar textual contexts. We demonstrate that extraction accuracy depends heavily on the accuracy of the language model utilized to estimate distributional similarity. An unsupervised model selection technique based on this observation is shown to reduce extraction and type-checking error by 26% over previous results, in experiments with Hidden Markov Models. The results suggest that optimizing statistical language models over unlabeled data is a promising direction for improving weakly supervised and unsupervised information extraction. © 2010 Association for Computational Linguistics.
KW  - Hidden Markov models
KW  - Information analysis
KW  - Distributional similarities
KW  - Extraction accuracy
KW  - Information Extraction
KW  - Information extraction techniques
KW  - Language model
KW  - Model selection techniques
KW  - Statistical language models
KW  - Textual contexts
KW  - Typechecking
KW  - Unlabeled data
KW  - Computational linguistics
SN  - 1932432655 (ISBN); 978-193243265-7 (ISBN)
LA  - English
J2  - NAACL HLT - Hum. Lang. Technol.: Annu. Conf. North Am. Chapter Assoc. Comput. Linguist., Proc. Conf.
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 10; Correspondence Address: A. Ahuja; EECS Dept., Northwestern University, Evanston, IL 60208, United States; email: arun.ahuja@eecs.northwestern.edu; Conference name: 2010 Human Language Technologies Conference ofthe North American Chapter of the Association for Computational Linguistics, NAACL HLT 2010; Conference date: 2 June 2010 through 4 June 2010; Conference code: 88929
ER  -

TY  - JOUR
AU  - Zhang, Y.
AU  - Liao, R.
AU  - Yang, L.
AU  - Zheng, H.
AU  - Sun, C.
TI  - An assessment method for insulation condition of power transformer based upon cloud model
PY  - 2012
T2  - Diangong Jishu Xuebao/Transactions of China Electrotechnical Society
VL  - 27
IS  - 5
SP  - 13
EP  - 20
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-84864085322&partnerID=40&md5=c813fdf938bc27d739cf9ec694e3b827
AD  - State Key Laboratory of Power Transmission Equipment and System Security and New Technology, Chongqing University, Chongqing 400030, China
AB  - Failure mechanisms of power transformers are complex, and the determination of fuzzy membership function is subjective and fails to take randomness into account. Beside, dissolved gas analysis (DGA) alone does not provide sufficient information to predict potential failures of a transformer. Aiming at these problems, an assessing model of transformer insulation is proposed base upon fuzzy cloud theory. Based on the determination of variable index weights, insulation condition system was established and insulation grade was classified. The cloud model was used to describe the fuzziness and randomness of the transformer and assess the condition of transformer insulation combined with infrared thermal imaging method and DGA method. Case studies and comparison analyses with other assessing method show that fuzzy cloud model analysis method is feasible and effective, and the method also offers a new way of assessment for transformer insulation condition.
KW  - Cloud membership function
KW  - Cloud model
KW  - Condition assessment
KW  - Condition maintenance
KW  - Power transformer
KW  - Variable weight
KW  - Infrared imaging
KW  - Insulation
KW  - Random processes
KW  - Assessing method
KW  - Assessing model
KW  - Assessment methods
KW  - Cloud models
KW  - Cloud theory
KW  - Comparison analysis
KW  - Condition assessments
KW  - Condition maintenance
KW  - Dissolved gas analysis
KW  - Failure mechanism
KW  - Fuzzy membership function
KW  - Index weight
KW  - Infrared thermal imaging
KW  - Insulation conditions
KW  - Transformer insulation
KW  - Variable weight
KW  - Power transformers
SN  - 10006753 (ISSN)
LA  - Chinese
J2  - Diangong Jishu Xuebao
M3  - Article
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 88; CODEN: DIJXE
ER  -

TY  - JOUR
AU  - Liao, R.-J.
AU  - Xiao, Z.-N.
AU  - Gong, J.
AU  - Yang, L.-J.
AU  - Wang, Y.-Y.
TI  - Markov model for reliability assessment of power transformers
PY  - 2010
T2  - Gaodianya Jishu/High Voltage Engineering
VL  - 36
IS  - 2
SP  - 322
EP  - 328
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-77951011780&partnerID=40&md5=69f41ef3162d0f841a349eef0aa9569f
AD  - State Key Laboratory of Power Transmission Equipment and System Security and New Technology, Chongqing University, Chongqing 400030, China
AB  - To assess the reliability of power transformers, a new assessment model for power transformers is established by Markov process. To get the general condition of a transformer, in agreement with practical operating experience, its service state is divided into eleven aspects, including normal operation, winding fault, bushing fault and preventative maintenance and so on. Secondly, the principle of Markov process is adopted to form the framework of the above eleven states in this assessment model. After that, the frequency and duration technique is introduced into the model to calculate frequency and mean duration time of each state, which is a basic method and widely used in electric power system. Then, according to the statistics on reliability indices of power transformers, all the state probabilities and some other reliability indices are calculated to describe the present reliability condition of power transformers which are studied above. Finally, by means of this assessing procedure, the new comprehensive reliability assessment model for power transformers is founded on the base of Markov process and the frequency and duration technique. The proposed approach has been verified by the statistics data of nation-wide 220 kV power transformers, and the results show that the reliability assessment model can accurately and objectively estimate the transformers' reliability by calculating state probabilities and some key reliability indices. In addition, the calculating program is short and brief so that it is easy to develop and maintain. Therefore, the reliability assessment model can better support the overall analysis of transformers' reliability.
KW  - Frequency and duration technique
KW  - Markov process
KW  - Power transformers
KW  - Reliability
KW  - Service state
KW  - State probability
KW  - Winding
KW  - Electric power systems
KW  - Electric windings
KW  - Markov processes
KW  - Probability
KW  - Pumps
KW  - Reliability analysis
KW  - Transformer substations
KW  - Winding
KW  - Assessment models
KW  - Calculating programs
KW  - Comprehensive reliability assessment
KW  - Duration time
KW  - Frequency and duration technique
KW  - Markov model
KW  - Normal operations
KW  - Operating experience
KW  - Preventative maintenance
KW  - Reliability assessment model
KW  - Reliability assessments
KW  - Reliability Index
KW  - Service state
KW  - State probability
KW  - Winding faults
KW  - Power transformers
SN  - 10036520 (ISSN)
LA  - Chinese
J2  - Gaodianya Jishu
M3  - Article
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 30; Correspondence Address: R.-J. Liao; State Key Laboratory of Power Transmission Equipment and System Security and New Technology, Chongqing University, Chongqing 400030, China; email: rjliao@cqu.edu.cn; CODEN: GAJIE
ER  -

TY  - JOUR
AU  - Smolka, J.
AU  - Nowak, A.J.
TI  - Experimental validation of the coupled fluid flow, heat transfer and electromagnetic numerical model of the medium-power dry-type electrical transformer
PY  - 2008
T2  - International Journal of Thermal Sciences
VL  - 47
IS  - 10
SP  - 1393
EP  - 1410
DO  - 10.1016/j.ijthermalsci.2007.11.004
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-47549085947&doi=10.1016%2fj.ijthermalsci.2007.11.004&partnerID=40&md5=59444b122a070df1bb388f532b858981
AD  - Institute of Thermal Technology, Silesian University of Technology, 44-100 Gliwice, Konarskiego 22, Poland
AB  - This paper presents experimental validation of a numerical model of coupled processes within a three-phase medium-power dry-type electrical transformer. The analysis carried out employed a multi-disciplinary approach involving heat, fluid flow and electromagnetics. The thermal and fluid flow analysis was coupled with an electromagnetic model in order to examine the specific power losses within the coils and the core. The thermal boundary conditions, i.e. the local and temperature-dependent heat fluxes, were computed by considering a numerical model of the surrounding internal and external air. Moreover, separate numerical and analytical models were considered in order to obtain the anisotropic thermal conductivities for different types of coils and also for laminated cores. To validate the numerical model, experimental transformer temperature tests in the short-circuit, open-circuit, and under nominal parameters according to the current European Standards for dry-type transformers were performed. During the tests, temperatures were measured at selected points on elements of the transformer using thermocouples and thermometers, while on the external tank walls an infrared thermography was employed. The obtained numerical results showed that the prediction of the temperature distribution within the analyzed transformers and their surroundings was very accurate. © 2007 Elsevier Masson SAS. All rights reserved.
KW  - Coupled problem
KW  - Dry-type transformer
KW  - Local heat generation
KW  - Numerical model
KW  - Validation
KW  - Air
KW  - Boundary conditions
KW  - Boundary value problems
KW  - Curing
KW  - Drying
KW  - Electric transformer testing
KW  - Electromagnetism
KW  - Flow of fluids
KW  - Fluids
KW  - Heating equipment
KW  - Magnetism
KW  - Modal analysis
KW  - Numerical methods
KW  - Remote sensing
KW  - Standards
KW  - Testing
KW  - Thermal conductivity
KW  - Thermoanalysis
KW  - Thermometers
KW  - (I ,J) conditions
KW  - Analytical modelling
KW  - Coupled processes
KW  - Different types
KW  - Dry type transformers
KW  - Electro magnetics
KW  - Electromagnetic (EM)
KW  - Electromagnetic (EM) modeling
KW  - Elsevier (CO)
KW  - European Standards
KW  - Experimental validations
KW  - External tank (ET)
KW  - Fluid flow analysis
KW  - fluid flowing
KW  - In order
KW  - Infrared thermography (IT)
KW  - Laminated cores
KW  - Multi-disciplinary approach
KW  - numerica l results
KW  - Numerical modelling
KW  - Specific power (SP)
KW  - temperature dependent
KW  - Electric network analysis
SN  - 12900729 (ISSN)
LA  - English
J2  - Int. J. Therm. Sci.
M3  - Article
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 52; Correspondence Address: J. Smolka; Institute of Thermal Technology, Silesian University of Technology, 44-100 Gliwice, Konarskiego 22, Poland; email: jacek.smolka@polsl.pl; CODEN: RGTHA
ER  -

TY  - CONF
AU  - Sumangala, B.V.
AU  - Nagabhushana, G.R.
TI  - Analysis of surge voltage distribution in a model transformer for different types of surges with turn resolution and its validation
PY  - 2006
T2  - IEEE Region 10 Annual International Conference, Proceedings/TENCON
C7  - 4142378
DO  - 10.1109/TENCON.2006.344190
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-34547558053&doi=10.1109%2fTENCON.2006.344190&partnerID=40&md5=d0238b3270c379a031db911da973b3de
AD  - Dept. of Electrical Engg., Dr Ambedkar Institute of Technology, Bangalore, India
AD  - Dept. of High Voltage Engineering, Indian Institute of Science, Bangalore, India
AB  - The paper presents an investigation on transient voltage distribution in transformers, which is of significance to all power system engineers. A better knowledge of this is possible with today's digital computers, for which a good modeling of the transformer is necessary. Using this information, the design engineers can develop a more reliable and possibly economic insulation structure which is the main issue affecting the cost of the transformer. Therefore, in this paper an attempt has been made to study the impulse response on a small model transformer for different types of pulses of varying frequency. The main objective of this paper is to show the significance of frequency and rise times for different types of pulses and high frequency pulse-VFTO on transient voltage distribution in the transformer. © 2006 IEEE.
KW  - Modeling
KW  - Transformer transients
KW  - Digital computers
KW  - Electric potential
KW  - Impulse response
KW  - Surge protection
KW  - Voltage distribution measurement
KW  - Design engineers
KW  - Surge voltage distribution
KW  - Transformer transients
KW  - Electric transformers
PB  - Institute of Electrical and Electronics Engineers Inc.
SN  - 21593442 (ISSN); 1424405491 (ISBN); 978-142440549-7 (ISBN)
LA  - English
J2  - IEEE Reg 10 Annu Int Conf Proc TENCON
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 3; Correspondence Address: B.V. Sumangala; Dept. of Electrical Engg., Dr Ambedkar Institute of Technology, Bangalore, India; email: sumangala_bv@yahoo.com; Conference name: 2006 IEEE Region 10 Conference, TENCON 2006; Conference date: 14 November 2006 through 17 November 2006; Conference code: 70043; CODEN: 85QXA
ER  -

TY  - JOUR
AU  - Wang, Y.-Y.
AU  - Yuan, Y.
AU  - Li, J.
AU  - Yang, L.-J.
AU  - Li, Y.-W.
TI  - Weibull mixed evaluation model for reliability of oil-paper insulation in transformer
PY  - 2010
T2  - Gaodianya Jishu/High Voltage Engineering
VL  - 36
IS  - 4
SP  - 842
EP  - 848
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-77952834530&partnerID=40&md5=036661aaa00414d0e48ff932a66b3e98
AD  - State Key Laboratory of Power Transmission Equipment and System Safety and New Technology, Chongqing University, Chongqing 400030, China
AB  - Oil-paper insulation is the key component of power transformer internal insulation. Its reliability directly determines the normal operation of the transformer. Therefore, a reliability evaluation method for oil-paper insulation of transformer based on Weibull distribution model was proposed, and it could be employed to assess the reliability of the oil-paper insulation and ensure the reliable operation of the transformer. Firstly, degree polymerization of insulation paper, furfural, acid and other five characteristic parameters were chosen to reflect the reliability of oil-paper insulation on the basis of the in-depth analysis of the relevant characteristic parameters, and the Weibull mixed model was established to assess the reliability of the oil-paper insulation. Secondly, according to the test data of the various characteristic parameters, the corresponding reliability function was obtained using maximum likelihood method; Thirdly, the dynamic weight of the corresponding sub-evaluation model of the characteristic parameter was calculated by applying the entropy method, and it well reflected the importance of the various sub-evaluation model in a mixed evaluation model and the comprehensiveness and accuracy of test data on the impact of the mixed evaluation model. Finally, the reliability evaluation of different life stages for the oil-paper insulation verified the feasibility of the method.
KW  - Characteristic parameters
KW  - Entropy method
KW  - Oil-paper insulation
KW  - Reliability evaluation
KW  - Transformers
KW  - Weibull distribution
KW  - Aldehydes
KW  - Entropy
KW  - Insulation
KW  - Oiled Papers
KW  - Reliability
KW  - Statistical Distribution
KW  - Transformers
KW  - Aldehydes
KW  - Entropy
KW  - Maximum likelihood estimation
KW  - Oil filled transformers
KW  - Parameter estimation
KW  - Power transformers
KW  - Reliability analysis
KW  - Test facilities
KW  - Weibull distribution
KW  - Characteristic parameter
KW  - Degree polymerization
KW  - Dynamic weight
KW  - Entropy methods
KW  - Evaluation models
KW  - In-depth analysis
KW  - Insulation paper
KW  - Internal insulation
KW  - Key component
KW  - Life stages
KW  - Maximum likelihood methods
KW  - Mixed models
KW  - Normal operations
KW  - Oil paper insulation
KW  - Reliability Evaluation
KW  - Reliability functions
KW  - Reliable operation
KW  - Test data
KW  - Weibull
KW  - Paper
SN  - 10036520 (ISSN)
LA  - Chinese
J2  - Gaodianya Jishu
M3  - Article
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 18; Correspondence Address: Y.-Y. Wang; State Key Laboratory of Power Transmission Equipment and System Safety and New Technology, Chongqing University, Chongqing 400030, China; email: y.wang@cqu.edu.cn; CODEN: GAJIE
ER  -

TY  - CONF
AU  - Giacomelli, F.
AU  - Inoue, T.B.
AU  - Morais, D.R.
AU  - Rolim, J.G.
TI  - An ontology model for intelligent tools applied to transformer condition evaluation
PY  - 2011
T2  - 2011 16th International Conference on Intelligent System Applications to Power Systems, ISAP 2011
C7  - 6082227
DO  - 10.1109/ISAP.2011.6082227
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-83655197385&doi=10.1109%2fISAP.2011.6082227&partnerID=40&md5=af5f4949a7afd6e0e695a0c416c8cff5
AD  - Power Systems Group, Federal University of Santa Catarina, 880840-900 - Florianópolis, SC, Brazil
AD  - ENDESA CIEN, 97690-000 - Garruchos, RS, Brazil
AB  - Numerous tests are applied to power and instrument transformers during their life cycle in order to evaluate their condition. The results of part of these tests are analyzed through simple comparison to thresholds established in well-accepted standards, but some require expertise to infer about the transformer condition. Researchers often suggest the use of intelligent techniques to interpret results of some transformer tests or to combine information from several analyses with monitoring devices. This paper proposes an ontology model to be used in applications of artificial intelligence techniques to transformer condition assessment, aiming to facilitate the communication and integration of separate modules. © 2011 IEEE.
KW  - Artificial Intelligence
KW  - Fault Diagnosis
KW  - Ontology
KW  - Power Transformers
KW  - Artificial intelligence
KW  - Failure analysis
KW  - Intelligent systems
KW  - Ontology
KW  - Power transformers
KW  - Power transmission
KW  - Artificial intelligence techniques
KW  - Condition evaluation
KW  - Intelligent techniques
KW  - Intelligent tools
KW  - Monitoring device
KW  - Ontology model
KW  - Transformer condition assessment
KW  - Electric transformer testing
LA  - English
J2  - Int. Conf. Intelligent Syst. Appl. Power Syst., ISAP
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 1; Correspondence Address: F. Giacomelli; Power Systems Group, Federal University of Santa Catarina, 880840-900 - Florianópolis, SC, Brazil; email: jackie@labspot.ufsc.br; Conference name: 2011 16th International Conference on Intelligent System Applications to Power Systems, ISAP 2011; Conference date: 25 September 2011 through 28 September 2011; Conference code: 87693
ER  -

TY  - CONF
AU  - Suzuki, H.
AU  - Gao, J.
TI  - A comparative study on language model adaptation techniques using new evaluation metrics
PY  - 2005
T2  - HLT/EMNLP 2005 - Human Language Technology Conference and Conference on Empirical Methods in Natural Language Processing, Proceedings of the Conference
SP  - 265
EP  - 272
DO  - 10.3115/1220575.1220609
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-80053285293&doi=10.3115%2f1220575.1220609&partnerID=40&md5=fb1d1706870918ca6bfb04bf8e58fb28
AD  - Microsoft Research, Redmond WA 98052, One Microsoft Way, United States
AD  - Microsoft Research Asia, Haidian District Beijing 100080, 49 Zhichun Road, China
AB  - This paper presents comparative experimental results on four techniques of language model adaptation, including a maximum a posteriori (MAP) method and three discriminative training methods, the boosting algorithm, the average perceptron and the minimum sample risk method, on the task of Japanese Kana-Kanji conversion. We evaluate these techniques beyond simply using the character error rate (CER): the CER results are interpreted using a metric of domain similarity between background and adaptation domains, and are further evaluated by correlating them with a novel metric for measuring the side effects of adapted models. Using these metrics, we show that the discriminative methods are superior to a MAP-based method not only in terms of achieving larger CER reduction, but also of being more robust against the similarity of background and adaptation domains, and achieve larger CER reduction with fewer side effects. © 2005 Association for Computational Linguistics.
KW  - Computational linguistics
KW  - Character error rates
KW  - Comparative studies
KW  - Discriminative methods
KW  - Discriminative training
KW  - Evaluation metrics
KW  - Japanese Kana-Kanji conversion
KW  - Language model adaptation
KW  - Maximum a posteriori
KW  - Natural language processing systems
PB  - Association for Computational Linguistics (ACL)
LA  - English
J2  - HLT/EMNLP - Hum. Lang. Technol. Conf. Conf. Empir. Methods Nat. Lang. Process., Proc. Conf.
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 10; Correspondence Address: H. Suzuki; Microsoft Research, Redmond WA 98052, One Microsoft Way, United States; email: hisamis@microsoft.com; Conference name: Human Language Technology Conference and Conference on Empirical Methods in Natural Language Processing, HLT/EMNLP 2005, Co-located with the 2005 Document Understanding Conference, DUC and the 9th International Workshop on Parsing Technologies, IWPT; Conference date: 6 October 2005 through 8 October 2005; Conference code: 86710
ER  -

TY  - JOUR
AU  - Facco, A.
AU  - Falavigna, D.
AU  - Gretter, R.
AU  - Viganò, M.
TI  - Design and evaluation of acoustic and language models for large scale telephone services
PY  - 2006
T2  - Speech Communication
VL  - 48
IS  - 2
SP  - 176
EP  - 190
DO  - 10.1016/j.specom.2005.07.004
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-29444433491&doi=10.1016%2fj.specom.2005.07.004&partnerID=40&md5=7560f02c7c2460a4fd95be39d725bd65
AD  - Reitek Spa, 20126 Milano, Viale Monza 265, Italy
AD  - SSI Division, ITC-Irst, 38050 Povo, Trento, Via Sommarive 18, Italy
AD  - Centro Ricerche FIAT (CRF), Trento, Italy
AB  - This paper describes the specification, design and development phases of two widely used telephone services based on automatic speech recognition. The effort spent for evaluating and tuning these services will be discussed in detail. In developing the first service, mainly based on the recognition of "alphanumeric" sequences, a significant part of the work consisted in refining the acoustic models. To increase recognition accuracy we adopted algorithms and methods consolidated in the past over broadcast news transcription tasks. A significant result shows that the use of task specific context dependent phone models reduces the word error rate by about 40% relative to using context independent phone models. Note that the latter result was achieved over a small vocabulary task, significantly different from those generally used in broadcast news transcription. We also investigated both unsupervised and supervised training procedures. Moreover, we studied a novel partly supervised technique that allows us to select in some "optimal" way the speech material to manually transcribe and use for acoustic model training. A significant result shows that the proposed procedure gives performance close to that obtained with a completely supervised training method. In the second service, mainly based on phrase spotting, a wide effort was devoted to language model refinement. In particular, several types of rejection networks were studied to detect out of vocabulary words for the given task; a major result demonstrates that using rejection networks based on a class trigram language model reduces the word error rate from 36.7% to 11.1% with respect to using a phone loop network. For the latter service, the benefits and related costs brought by regular grammars, stochastic language models and mixed language models will be also reported and discussed. Finally, notice that most of experiments described in this paper were carried out on field databases collected through the developed services. © 2005 Elsevier B.V. All rights reserved.
KW  - Acoustic model training
KW  - Automatic telephone services
KW  - Language model refinement
KW  - Supervised/ unsupervised/partly supervised training
KW  - Acoustic variables measurement
KW  - Algorithms
KW  - Broadcasting
KW  - Database systems
KW  - Speech recognition
KW  - Telephone
KW  - Acoustic model training
KW  - Automatic telephone services
KW  - Language model refinement
KW  - Supervised/ unsupervised/partly supervised training
KW  - Telecommunication services
SN  - 01676393 (ISSN)
LA  - English
J2  - Speech Commun
M3  - Article
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 3; Correspondence Address: D. Falavigna; SSI Division, ITC-Irst, 38050 Povo, Trento, Via Sommarive 18, Italy; email: falavi@itc.it; CODEN: SCOMD
ER  -

TY  - JOUR
AU  - Wu, M.
AU  - Xing, G.
AU  - Qi, X.
AU  - Feng, C.
AU  - Liu, M.
AU  - Gong, L.
AU  - Luan, Y.
AU  - Ren, J.
TI  - Assessment of the mutagenic potential of arecoline in gpt delta transgenic mice
PY  - 2012
T2  - Mutation Research - Genetic Toxicology and Environmental Mutagenesis
VL  - 748
IS  - 1-2
SP  - 65
EP  - 69
DO  - 10.1016/j.mrgentox.2012.07.001
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-84864994666&doi=10.1016%2fj.mrgentox.2012.07.001&partnerID=40&md5=da1eff2dbfa0e990d91b3e54318097cd
AD  - Center for Drug Safety and Evaluation Research, State Key Lab. of New Drug Research, Shanghai Institute of Materia Medica, Chinese Academy of Sciences, Shanghai 201203, China
AD  - Graduate School of the Chinese Academy of Sciences, Shanghai 201203, China
AB  - Chewing the areca nut is carcinogenic to humans. Arecoline, a major alkaloid in areca nut, is suspected to be a carcinogenic component. It has been shown to have genotoxic potential in various in vitro systems; but information on its in vivo genotoxicity is limited. To investigate the organ-specific mutagenic potential of arecoline, we employed gpt delta transgenic mice to analyze the mutagenicity of arecoline in the oral tissues and liver. Male gpt delta mice were given arecoline hydrobromide in drinking water at 300 and 700μg/mL for 6 weeks. 4-Nitroquinoline-1 (4-NQO) was used as a positive control. Two weeks after the last treatment, mutation frequencies in the oral tissues (a mixture of gingival, buccal, pharyngeal and sublingual tissue) and liver were detected and mutation spectra were analyzed. There were no statistically significant differences in the average mutation frequencies between arecoline-treated and untreated groups in both the oral tissues and liver. However, in the oral tissues, one mouse in arecoline-300μg/mL group and two mice in arecoline-700μg/mL group showed more than 2.5-fold higher mutation frequencies than the untreated group; they also exhibited unique mutation spectra compared to spontaneous mutation types. In these three mice, all mutations occurred at G:C sites, where G:C → T:A transversions were most frequent, followed by G:C → A:T transitions and G:C → C:G transversions. The main type of spontaneous mutation in both the oral tissues and liver was G:C → A:T transition. These results suggest that arecoline poses a mutagenic hazard in the oral tissues of gpt delta transgenic mice. © 2012 Elsevier B.V.
KW  - Arecoline
KW  - Gpt delta transgenic mouse
KW  - Mutagenesis
KW  - Animals
KW  - Arecoline
KW  - Body Weight
KW  - Cholinergic Agonists
KW  - Dose-Response Relationship, Drug
KW  - Hypoxanthine Phosphoribosyltransferase
KW  - Liver
KW  - Male
KW  - Mice
KW  - Mice, Transgenic
KW  - Mouth
KW  - Mutagens
KW  - Mutation Rate
KW  - Areca catechu
KW  - Mus
KW  - Mus musculus
KW  - 4 nitroquinoline 1 oxide
KW  - alanine aminotransferase
KW  - alanine aminotransferase delta
KW  - arecoline
KW  - drinking water
KW  - unclassified drug
KW  - animal experiment
KW  - animal tissue
KW  - article
KW  - body weight
KW  - cheek
KW  - controlled study
KW  - gene mutation
KW  - gingiva
KW  - liver
KW  - male
KW  - mouse
KW  - mouth
KW  - mutagenesis
KW  - mutagenicity
KW  - mutation rate
KW  - nonhuman
KW  - pharynx
KW  - priority journal
KW  - spontaneous mutation
KW  - statistical significance
KW  - sublingual gland
KW  - transgenic mouse
SN  - 18793592 (ISSN)
C2  - 22796562
LA  - English
J2  - Mutat. Res. Genet. Toxicol. Environ. Mutagen.
M3  - Article
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 10; Correspondence Address: Y. Luan; Shanghai, Haike road 501, China; email: yluan@cdser.simm.ac.cn; CODEN: MRGMF
ER  -

TY  - CONF
AU  - Sule, I.
TI  - Simulation model for assessing operational performance of current transformers
PY  - 2007
T2  - Advanced Materials Research
VL  - 18-19
SP  - 71
EP  - 77
DO  - 10.4028/www.scientific.net/amr.18-19.71
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-56249118703&doi=10.4028%2fwww.scientific.net%2famr.18-19.71&partnerID=40&md5=fac125e988194f2b9a6cc233038d266c
AD  - Federal Polytechnic, Mubi, Adamawa State, Nigeria
AB  - In determining the correct operation of relays of a protection scheme, proper representation of instrument transformers and their behavior in conditions where there can be saturation, is very critical. The main objective of this paper is to develop simulation model for assessing the operational performance of Current Transformer (CT). In order to test the validity of the developed model, three cases of CT operational conditions were considered, with data collected from Gombe, 330/132/33kV PHCN substation. The simulation results revealed various configuration performance responses that could affect relay protective schemes to different degrees. The CT responses revealed that the secondary current and voltage were distorted when the core flux linkages exceeded the set 9.2 pu saturation limit. It is concluded that the model developed for the CT of interest yield satisfactory results. © 2007 Trans Tech Publications.
KW  - Model
KW  - Operational performance and current transformer
KW  - Saturation
KW  - Simulation
KW  - Electric instrument transformers
KW  - Engineering research
KW  - Models
KW  - Saturation (materials composition)
KW  - Transformer protection
KW  - Operational conditions
KW  - Operational performance
KW  - Operational performance and current transformer
KW  - Protection schemes
KW  - Saturation limits
KW  - Secondary currents
KW  - Simulation
KW  - Simulation model
KW  - Electric currents
PB  - Trans Tech Publications
SN  - 10226680 (ISSN); 978-087849450-7 (ISBN)
LA  - English
J2  - Adv. Mater. Res.
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 0; Correspondence Address: I. Sule; Federal Polytechnic, Mubi, Adamawa State, Nigeria; email: sulekamiha@yahoo.com; Conference name: International Conference on Engineering Research and Development: Impact on Industry, ICER and D 2006; Conference date: 5 September 2006 through 7 September 2006; Conference code: 74046
ER  -

TY  - JOUR
AU  - Chatterjee, N.
AU  - De, A.
TI  - An assessment of interleaved high voltage transformer winding by model studies
PY  - 2000
T2  - Journal of the Institution of Engineers (India): Electrical Engineering Division
VL  - 81
IS  - 3
SP  - 97
EP  - 103
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-8444226723&partnerID=40&md5=a6d84a277d5832ac66493c46b5762165
AD  - Department of Electrical Engineering, Jadavpur University, Calcutta 700 032, India
AB  - Performance of the windings under impulse voltages has long been factor of significant importance in the design of high voltage transformer windings. Interleaved transformer winding is a relatively new and promising development in this field. Although the strengths and weaknesses of interleaved winding concept against surge voltages is theoretically known, implementation of the same in a practical multi-winding E H V transformer may lead to various complications and the winding can show unpredictable behaviour, in contrary to the existing knowledge. In the present work, a comparative assessment of interleaved transformer winding has been made by EMTP simulation of two identical multi-winding E H V transformer models having interleaved and non-interleaved conventional disk windings. The observations regarding relative surge performance of interleaved and non-interleaved windings may throw some light on optimum interleaving of the disk coils in transformer winding. The tap changer or regulating winding forms a weak point in H V transformers, and are found to be responsible for majority of the failures of H V power transformers. In the present work, distribution of impulse voltage in the regulating or tap changer winding has also been studied. The results of these observations may be useful to find out suitable explanations for the failure of tap changer winding in E H V power transformers.
KW  - EHV transformer
KW  - EMTP
KW  - Interleaved winding
KW  - Lighting impulse
SN  - 00203386 (ISSN)
LA  - English
J2  - J Inst Eng India: Electr Eng Div
M3  - Article
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 0; CODEN: JEELA
ER  -

TY  - CONF
AU  - Keradec, J.-P.
TI  - Validating the power loss model of a transformer by measurement: The price to pay
PY  - 2002
T2  - Conference Record - IAS Annual Meeting (IEEE Industry Applications Society)
VL  - 2
SP  - 1377
EP  - 1382
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-0036446337&partnerID=40&md5=3442d88e511a0bfad87879d31b116a8c
AD  - Lab. d'Electrotechnique de Grenoble, CNRS UMR 5529, INPG/UJF, 38402 SMH Cedex, Grenoble, ENSIEG BP 46, France
AB  - Two studies related to losses in ferrite core transformers are presented. They both aim to check the aecuracy of transformer equivalent circuits. First, a 3 kW-two winding transformer is used in a converter which works at 25 kHz. In order to compare the losses forecasted using electronie circuit simulation together with the transformer electrical model, to those deduced from oscilloscopic electrical power measurements a lot of experimental precautions have been taken. Because the transformer have a power efficiency of 92%, knowing the lost part of the power within 10 % needs input and output powers to be acquired within 4 %. Second, to validate the copper losses electrical representation of a smaller transformer, calorimetric measurements have been carried out. Although in both cases high performanee equipment is required, the most expensive is the time required to control it. As long as measurement is not considered as an unavoidable subject of investigation, no reliable result can be expected.
KW  - Calorimetric measurements accurate electrical power measurements
KW  - Power losses
KW  - Transformer
KW  - Calorimetry
KW  - Computer simulation
KW  - Electric converters
KW  - Electric losses
KW  - Electric power measurement
KW  - Electric power systems
KW  - Power losses
KW  - Transformer windings
SN  - 01972618 (ISSN)
LA  - English
J2  - Conf Rec IAS Annu Meet
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 5; Correspondence Address: J.-P. Keradec; Lab. d'Electrotechnique de Grenoble, CNRS UMR 5529, INPG/UJF, 38402 SMH Cedex, Grenoble, ENSIEG BP 46, France; email: Jean-Pierre.Keradec@leg.ensieg.inpg.fr; Conference name: 37th IAS Annual Meeting and World Conference on Industrial applications of Electrical Energy; Conference date: 13 October 2002 through 18 October 2002; Conference code: 60352; CODEN: CIASD
ER  -

TY  - CONF
AU  - Lavers, J.D.
AU  - Lavers, E.D.
TI  - An accuracy assessment of 2-D vs. 3-D Finite Element models for ferrite core, sheet wound transformers
PY  - 2002
T2  - Conference Proceedings - IEEE Applied Power Electronics Conference and Exposition - APEC
VL  - 1
SP  - 158
EP  - 164
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-0036077911&partnerID=40&md5=448a00562bfb8175ac2d126229d91075
AD  - ECE Dept., University of Toronto, Toronto, Ont. M5S 3G4, 10 King's College Road, Canada
AB  - This study examines the parameter estimates for representative high frequency transformer designs with a view to assessing the errors that might be expected when 2-D approximate Finite Element models are used for the purpose of parameter extraction. The assessment has been based on a comparison of parameter estimates obtained from the 2-D models, relative to values predicted by fully converged 3-D models. The study has shown that the widely used 2-D models provide parameter estimates that, at worst, are in the order of 25% greater than the 3-D results. In many instances, the agreement is found to be much closer than that.
KW  - Computer simulation
KW  - Ferrites
KW  - Finite element method
KW  - Parameter estimation
KW  - Power converters
KW  - Sheet wound transformers
KW  - Electric instrument transformers
LA  - English
J2  - Conf Proc IEEE Appl Power Electron Conf Expo APEC
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 7; Conference name: 17th Annual IEEE Applied Power Electronics Conference and Exposition; Conference date: 10 March 2002 through 14 March 2002; Conference code: 59240; CODEN: CPAEE
ER  -

TY  - JOUR
AU  - Keradec, J.-P.
TI  - Validating the power loss model of a transformer by measurement - Validation is key
PY  - 2007
T2  - IEEE Industry Applications Magazine
VL  - 13
IS  - 4
SP  - 42
EP  - 48
DO  - 10.1109/MIA.2007.4283508
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-34548070224&doi=10.1109%2fMIA.2007.4283508&partnerID=40&md5=8460e60a92efef5b1248101aa6716ddc
AD  - Laboratoire d'Electrotechnique de Grenoble, Grenoble, France
AB  - The validation of power loss model of a transformer can be identified through calorimetric measurements. A small transformer was built around an ETD44 core made of 3C85 ferrite. A calorimeter was installed to measure power losses in good capacitors. The apparatus operated at temperatures ranging from -50 to 100°C. A Calorimeter deduces dissipated power from the temperature difference that is measured between the two ends of a calibrated thermal leakage resistance. In the device, power is dissipated in the DUT directly deduced from two powers. A special cooling is used, as hot points appear along the copper wire so that voltage and power do not stabilize. The configuration allows power from 10 mW to 10W to be measured within 1.3% in the -45 to 85°C range. However, accuracy decreases quickly due to excessive radiation losses at above 85°C. On the other hand, measurements are reliable up to 1MHz, but deteriorates because of currents induced in metallic parts of the calorimeter and stray capacitances between supply wires. Overall, although a calorimetric apparatus is difficult to built, costly and time consuming, it remains the only way to accurately measure the losses of low-loss components such as some capacitors.
KW  - Calorimeters
KW  - Capacitors
KW  - Electric losses
KW  - Heat resistance
KW  - Thermal gradients
KW  - Power loss model
KW  - Temperature difference
KW  - Power transformers
SN  - 10772618 (ISSN)
LA  - English
J2  - IEEE Ind Appl Mag
M3  - Article
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 10; Correspondence Address: J.-P. Keradec; Laboratoire d'Electrotechnique de Grenoble, Grenoble, France; email: Jean-Pierre.Keradec@g2elabinpg.fr; CODEN: IIAME
ER  -

TY  - CONF
AU  - Clarkson, P.
AU  - Robinson, T.
TI  - TOWARDS IMPROVED LANGUAGE MODEL EVALUATION MEASURES
PY  - 1999
T2  - 6th European Conference on Speech Communication and Technology, EUROSPEECH 1999
SP  - 1927
EP  - 1930
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-84978174953&partnerID=40&md5=035dc61a26a254ac7fc0f5eded5ec165
AD  - Cambridge University, Engineering Department, Trumpington Street, Cambridge, CB2 1PZ, United Kingdom
AB  - Much recent research has demonstrated that the correlation between a language model's perplexity and its effect on the word error rate of a speech recognition system is not as strong as was once thought. This represents a major problem for those involved in developing language models. This paper describes the development of new measures of language model quality. These measures retain the ease of computation and task independence that are perplexity's strengths, yet are considerably better correlated with word error rate. This paper also shows that mixture-based language models are improved by applying interpolation weights which are optimised with respect to these new measures, rather than a maximum likelihood criterion. © 1999 6th European Conference on Speech Communication and Technology, EUROSPEECH 1999. All rights reserved.
KW  - Computational linguistics
KW  - Maximum likelihood
KW  - Speech recognition
KW  - Evaluation measures
KW  - Language model
KW  - Maximum likelihood criteria
KW  - Model evaluation
KW  - Modeling quality
KW  - Recent researches
KW  - Speech recognition systems
KW  - Word error rate
KW  - Speech communication
PB  - The International Society for Computers and Their Applications (ISCA)
LA  - English
J2  - Eur. Conf. Speech Commun. Technol., EUROSPEECH
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 9; Conference name: 6th European Conference on Speech Communication and Technology, EUROSPEECH 1999; Conference date: 5 September 1999 through 9 September 1999; Conference code: 180617
ER  -

TY  - CONF
AU  - Carneiro Jr., S.
AU  - Martins, H.J.A.
TI  - Measurements and Model Validation on Three-phase Core-type Distribution Transformers
PY  - 2003
T2  - 2003 IEEE Power Engineering Society General Meeting, Conference Proceedings
VL  - 1
SP  - 120
EP  - 124
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-1542329762&partnerID=40&md5=fc9480b97c14524b87afaeb00b0ec934
AD  - Department of Electrical Engineering, COPPE, Federal University of Rio de Janeiro, Brazil
AD  - Elec. Power Research Center-CEPELl, Rio de Janeiro, Brazil
AB  - This panel discussion summarizes experimental work that has been conducted to establish the validity of models for 3-phase distribution transformers. The discussion reviews a classical method to obtain the admittance matrices both in the phase domain and in the sequence domain and the assumptions adopted in the derivations. Measurements on actual distribution transformers are then reported to show the validity of the assumptions and consequently of the model. The differences in the mutual admittances between the various windings are analyzed and their relevance to accurately represent core type transformers is stressed.
KW  - Symmetrical Components
KW  - Transformer cores
KW  - Transformer Models
KW  - Transformer Testing
KW  - Electric admittance
KW  - Electric impedance
KW  - Electric power distribution
KW  - Mathematical models
KW  - Transformer windings
KW  - Symmetrical components
KW  - Transformer cores
KW  - Transformer models
KW  - Transformer testing
KW  - Electric power systems
SN  - 0780379896 (ISBN)
LA  - English
J2  - 2003 IEEE Power Eng. Soc. Gen. Meet. Conf. Proc.
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 1; Correspondence Address: S. Carneiro Jr.; Department of Electrical Engineering, COPPE, Federal University of Rio de Janeiro, Rio de Janeiro, Brazil; email: sandoval@coep.ufrj.br; Conference name: 2003 IEEE Power Engineering Society General Meeting; Conference date: 13 July 2003 through 17 July 2003; Conference code: 62417
ER  -

TY  - JOUR
AU  - Magnasco, A.
AU  - Bacchini, G.
AU  - Cappello, A.
AU  - La Milia, V.
AU  - Brezzi, B.
AU  - Messa, P.G.
AU  - Locatelli, F.
TI  - Clinical validation of glucose pump test (GPT) compared with ultrasound dilution technology in arteriovenous graft surveillance
PY  - 2004
T2  - Nephrology Dialysis Transplantation
VL  - 19
IS  - 7
SP  - 1835
EP  - 1841
DO  - 10.1093/ndt/gfh292
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-3242661623&doi=10.1093%2fndt%2fgfh292&partnerID=40&md5=5ca2c276a7fa5555b40ff57f3d8689f7
AD  - Deparment of Nephrology/Dialysis, S. Andrea Hospital, La Spezia, Italy
AD  - Department of Nephrology/Dialysis, A. Manzoni Hospital, Lecco, Italy
AD  - Radiology Unit, A. Manzoni Hospital, Lecco, Italy
AB  - Background. Blood flow (Qa) measurements are an important step in the surveillance protocol of haemodialysis vascular access (VA). The glucose pump test (GPT) is a new test for Qa measurement based on the dilution of a constant glucose infusion. The aim of this study is to verify the clinical accuracy of GPT in a graft surveillance protocol with sequential Qa measurements. Methods. In 30 chronic haemodialysis patients with graft, we compared monthly sequential Qa measurements performed with GPT in pre-dialysis and the ultrasound dilution technique (HD01 device Transonic Systems Inc., USA) during dialysis. The colour Doppler ultrasonography study (CDU) was our reference standard for the diagnosis of stenosis. The endpoints were the graft thrombosis or PTA treatment. Results. According to the K/DOQI guidelines we could identify the thrombosis high-risk grafts when Qa was <600 ml/min or <1000 ml/min with a decrease >25% in serial Qa measurements. HD01 yielded 27 of 112 high-risk Qa measurements (21 Qa <600ml/min; mean 406 ± 145 ml/min; 6 Δ Qa >25%; mean 43 ± 7%). In 12 of 27 cases the CDU control did not show haemodynamically significant stenoses (false positive); 15 of 27 cases were confirmed high-risk accesses by CDU and did PTAs (HD01 specificity 86%). GPT yielded 14 of 112 high-risk Qa measurements (8 Qa <600 ml/min; mean 404 ± 135 ml/min; 6 Δ Qa >25%; mean 38 ± 8%) and all had severe stenoses and underwent PTA treatments showing a GPT specificity of 100%. The CDU study allowed us to correctly assess the Qa negative cases. HD01 method had 10 false negative cases (treated or clotted grafts with a Qa >600ml/min and Δ Qa <25%) with a sensitivity of 60%, while GPT had 11 false negative cases with a sensitivity of 56%. The diagnostic accuracy tested with the ROC curves was similar with both tests (area under the curve was 0.762 and 0.752 with GPT and ultrasound dilution, respectively; P=0.985). The diagnostic efficiency (percentage of grafts with agreement between test result and factual situation) was 90 and 80% (P=0.056) for GPT and HD01, respectively. Conclusion. Compared with HD01, the GPT had a lower false positive rate and similar diagnostic accuracy and efficiency. The clinical implication is a smaller number of unnecessary, invasive procedures (angiographies or PTAs), without increasing the thrombosis risk. This study has shown that GPT is an accurate, quick and economic test for Qa monitoring. © ERA-EDTA 2004; all rights reserved.
KW  - Colour Doppler ultrasound
KW  - Haemodialysis
KW  - Ultrasound dilution technology
KW  - Vascular access
KW  - Aged
KW  - Arteriovenous Shunt, Surgical
KW  - Blood Glucose
KW  - Catheters, Indwelling
KW  - Female
KW  - Humans
KW  - Male
KW  - Prospective Studies
KW  - Regional Blood Flow
KW  - Renal Dialysis
KW  - Reproducibility of Results
KW  - Ultrasonography, Doppler, Color
KW  - article
KW  - clinical article
KW  - color ultrasound flowmetry
KW  - controlled study
KW  - device
KW  - diagnostic accuracy
KW  - diagnostic test
KW  - diagnostic value
KW  - disease severity
KW  - echography
KW  - glucose infusion
KW  - graft occlusion
KW  - graft patency
KW  - hemodialysis
KW  - hemodynamics
KW  - high risk patient
KW  - human
KW  - infusion pump
KW  - intermethod comparison
KW  - laboratory diagnosis
KW  - percutaneous transluminal angioplasty
KW  - priority journal
KW  - sensitivity and specificity
KW  - statistical analysis
KW  - statistical significance
KW  - vascular access
SN  - 09310509 (ISSN)
C2  - 15161950
LA  - English
J2  - Nephrol. Dial. Transplant.
M3  - Article
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 14; Correspondence Address: A. Magnasco; Department of Nephrology/Dialysis, S. Andrea Hospital, La Spezia, Italy; email: alberto.magnasco@au515.la.spezia.it; CODEN: NDTRE
ER  -

TY  - JOUR
AU  - Bimbot, F.
AU  - El-Bèze, M.
AU  - Igounet, S.
AU  - Jardino, M.
AU  - Smaili, K.
AU  - Zitouni, I.
TI  - An alternative scheme for perplexity estimation and its assessment for the evaluation of language models
PY  - 2001
T2  - Computer Speech and Language
VL  - 15
IS  - 1
SP  - 1
EP  - 13
DO  - 10.1006/csla.2000.0150
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-0035062718&doi=10.1006%2fcsla.2000.0150&partnerID=40&md5=ef62965b1a1a55e8e06444fd118038e4
AD  - ENST/CNRS, 75634, Paris cedex 13, 46 rue Barrault, France
AD  - IRISA(CNRS and INRIA), Campus Universitaire De Beaulieu, 35042, Rennes cedex, France
AD  - LIA, Université d'Avignon, 84911, Avignon cedex 9, BP 1228, Agroparc, France
AD  - LIMSI/CNRS, Université Paris-Sud, 91403, Orsay cedex, BP 133, France
AD  - LORIA(INRIA and CNRS), 54506, Vanduvre-les-Nancy cedex, BP 239, France
AB  - Language models are usually evaluated on test texts using the perplexity derived from the model likelihood function computed on these texts (test set perplexity). In order to use this measure in the framework of a comparative evaluation campaign, we have developed an alternative scheme for estimating the test set perplexity. The method is derived from the Shannon game and based on a gambling approach on the next word to come in a truncated sentence. We also study the entropy bounds proposed by Shannon and based on the rank of the correct answer, in order to estimate a perplexity interval for non-probabilistic language models. The relevance of the approach is validated on an example. We then report the results of a preliminary comparative evaluation using the proposed scheme.
KW  - Boundary conditions
KW  - C (programming language)
KW  - Database systems
KW  - Game theory
KW  - Maximum likelihood estimation
KW  - Probability density function
KW  - Random processes
KW  - Speech recognition
KW  - Language models
KW  - Model likelihood function
KW  - Perplexity estimation
KW  - Shannon game
KW  - Computer simulation languages
PB  - Academic Press
SN  - 08852308 (ISSN)
LA  - English
J2  - Comput Speech Lang
M3  - Article
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 4; Correspondence Address: F. Bimbot; ENST/CNRS, 75634 Paris cedex 13, 46 rue Barrault, France; email: bimbot@irisa.fr; CODEN: CSPLE
ER  -

TY  - JOUR
AU  - Romero, J.A.
AU  - Moret, J.-M.
AU  - Coda, S.
AU  - Felici, F.
AU  - Garrido, I.
TI  - Development and validation of a tokamak skin effect transformer model
PY  - 2012
T2  - Nuclear Fusion
VL  - 52
IS  - 2
C7  - 023019
DO  - 10.1088/0029-5515/52/2/023019
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-84857303382&doi=10.1088%2f0029-5515%2f52%2f2%2f023019&partnerID=40&md5=72f0b0e5fc1f4363a117619f9bfd61b7
AD  - Laboratorio Nacional de Fusión, Asociación EURATOM/CIEMAT, 28040, Madrid, Spain
AD  - Centre de Recherches en Physique des Plasmas, Association EURATOM-Confédération Suisse, CRPP-EPFL, CH-1015 Lausanne, Switzerland
AD  - Euskal Herriko Unibertsitatea (EHU), 48012 Bilbao, Plaza Casilla 3, Spain
AB  - A lumped parameter, state space model for a tokamak transformer including the slow flux penetration in the plasma (skin effect transformer model) is presented. The model does not require detailed or explicit information about plasma profiles or geometry. Instead, this information is lumped in system variables, parameters and inputs. The model has an exact mathematical structure built from energy and flux conservation theorems, predicting the evolution and non-linear interaction of plasma current and internal inductance as functions of the primary coil currents, plasma resistance, non-inductive current drive and the loop voltage at a specific location inside the plasma (equilibrium loop voltage). Loop voltage profile in the plasma is substituted by a three-point discretization, and ordinary differential equations are used to predict the equilibrium loop voltage as a function of the boundary and resistive loop voltages. This provides a model for equilibrium loop voltage evolution, which is reminiscent of the skin effect. The order and parameters of this differential equation are determined empirically using system identification techniques. Fast plasma current modulation experiments with random binary signals have been conducted in the TCV tokamak to generate the required data for the analysis. Plasma current was modulated under ohmic conditions between 200 and 300 kA with 30 ms rise time, several times faster than its time constant L/R ≈ 200 ms. A second-order linear differential equation for equilibrium loop voltage is sufficient to describe the plasma current and internal inductance modulation with 70% and 38% fit parameters, respectively. The model explains the most salient features of the plasma current transients, such as the inverse correlation between plasma current ramp rates and internal inductance changes, without requiring detailed or explicit information about resistivity profiles. This proves that a lumped parameter modelling approach can be used to predict the time evolution of bulk plasma properties such as plasma inductance or current with reasonable accuracy; at least under ohmic conditions without external heating and current drive sources. © 2012 IAEA, Vienna.
KW  - Forecasting
KW  - Functions
KW  - Inductance
KW  - Ordinary differential equations
KW  - Power quality
KW  - Skin effect
KW  - State space methods
KW  - Bulk plasma properties
KW  - Coil current
KW  - Conservation theorem
KW  - Current drives
KW  - Discretizations
KW  - Explicit information
KW  - External heating
KW  - Fit parameters
KW  - Flux penetration
KW  - Internal inductance
KW  - Inverse correlation
KW  - Linear differential equation
KW  - Loop voltages
KW  - Lumped parameter
KW  - Lumped parameter modelling
KW  - Mathematical structure
KW  - Noninductive current drives
KW  - Nonlinear interactions
KW  - Plasma current ramps
KW  - Plasma currents
KW  - Plasma inductance
KW  - Plasma profiles
KW  - Plasma resistance
KW  - Random binary signals
KW  - Reasonable accuracy
KW  - Resistivity profile
KW  - Risetimes
KW  - Salient features
KW  - Second orders
KW  - Specific location
KW  - State space model
KW  - System identification techniques
KW  - System variables
KW  - Time constants
KW  - Time evolutions
KW  - Transformer models
KW  - Magnetoplasma
SN  - 17414326 (ISSN)
LA  - English
J2  - Nucl Fusion
M3  - Article
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 20; CODEN: NUFUA
ER  -

TY  - CONF
AU  - Kim, J.
AU  - Ryu, S.
AU  - Kim, J.H.
TI  - Stability measure of entropy estimate and its application to language model evaluation
PY  - 2004
T2  - Proceedings - International Workshop on Frontiers in Handwriting Recognition, IWFHR
SP  - 456
EP  - 461
DO  - 10.1109/IWFHR.2004.98
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-18044366929&doi=10.1109%2fIWFHR.2004.98&partnerID=40&md5=d826b91b5ce08f03bf6f40a70c67a226
AD  - Div. of CS, Dept. of EECS, KAIST, Daejeon, 373-1 Yuseong Guseong, South Korea
AB  - We propose in this paper a stability measure of entropy estimate based on the principle of Bayesian statistics. Stability, or how the estimates vary as training set does, is a critical issue especially for the problems where parameter-to-data ratio is extremely high as in language modeling and text compression. There are two natural estimates of entropy, one being the classical estimate and the other the Bayesian estimate. We show that the difference of them is in strong positive correlation with the variance of the classical estimate when it is not so small, and propose this difference as stability measure of entropy estimate. In order to evaluate it for language models where estimates are available but posterior distribution is not in general, we suggest to use a Dirichlet distribution so that its expectation agrees with the estimated parameters and that the total count is preserved at the same time. Experiments on two benchmark corpora show that the proposed measure indeed reflects the stability of classical entropy estimates. © 2004 IEEE.
KW  - Character sets
KW  - Computation theory
KW  - Data processing
KW  - Data reduction
KW  - Parameter estimation
KW  - Statistical methods
KW  - Vocabulary control
KW  - Bayesian statistics
KW  - Language models
KW  - Parameter-to-data-ratio
KW  - Text compression
KW  - Computational linguistics
SN  - 15505235 (ISSN); 0769521878 (ISBN)
LA  - English
J2  - Proc. Int. Workshop Front. Handwriting Recogn. IWFHR
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 0; Correspondence Address: J. Kim; Div. of CS, Dept. of EECS, KAIST, Daejeon, 373-1 Yuseong Guseong, South Korea; email: jahwan@ai.kaist.ac.kr; Conference name: Proceedings - Ninth International Workshop on Frontiers in Handwriting Recognition, IWFHR-9 2004; Conference date: 26 October 2004 through 29 October 2004; Conference code: 64664
ER  -

TY  - CONF
AU  - Jauregui - Rivera, L.
AU  - Tylavsky, D.J.
TI  - Reliability assessment of transformer thermal model parameters estimated from measured data
PY  - 2005
T2  - Proceedings of the 37th Annual North American Power Symposium, 2005
VL  - 2005
C7  - 1560501
SP  - 52
EP  - 58
DO  - 10.1109/NAPS.2005.1560501
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-33845338753&doi=10.1109%2fNAPS.2005.1560501&partnerID=40&md5=018f8ca0f6feca1e94f073d232af0295
AD  - IEEE
AB  - This paper presents a methodology to assess the reliability of substation distribution transformer thermal model parameters estimated from measured data. The methodology uses statistical bootstrapping to assign a measure of reliability to the estimated parameters using confidence levels (CL) and confidence intervals (CI). The bootstrapping technique, which is used to make a small data sample look statistically large, allows a precise estimate of transformer reliability. The proposed methodology is tested on a 28 MVA transformer for which different data sets are available. The CI's are evaluated for both cases: with and without bootstrapping and the reliability indices compared. The results show that the CI values with bootstrapping are more consistently reproducible than the ones derived without bootstrapping.
KW  - Bootstrapping
KW  - Confidence intervals
KW  - Confidence levels
KW  - Hot-spot temperature
KW  - Least squares
KW  - Parameter estimation
KW  - Top-oil temperature
KW  - Transformer thermal modeling
KW  - Data reduction
KW  - Least squares approximations
KW  - Mathematical models
KW  - Parameter estimation
KW  - Reliability theory
KW  - Thermal variables measurement
KW  - Bootstrapping
KW  - Confidence intervals
KW  - Confidence levels
KW  - Hot-spot temperature
KW  - Top-oil temperature
KW  - Transformer thermal modeling
KW  - Electric transformers
SN  - 0780392558 (ISBN); 978-078039255-7 (ISBN)
LA  - English
J2  - Proc. Annu. North Am. Power Symp.
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 1; Conference name: 37th Annual North American Power Symposium, 2005; Conference date: 23 October 2005 through 25 October 2005; Conference code: 68757
ER  -

TY  - JOUR
AU  - Livingstone, I.
AU  - Charlton, R.
TI  - Raising local authority district revenues through direct taxation in a low-income developing country: Evaluating Uganda's GPT
PY  - 1998
T2  - Public Administration and Development
VL  - 18
IS  - 5
SP  - 499
EP  - 517
DO  - 10.1002/(SICI)1099-162X(199812)18:5<499::AID-PAD39>3.0.CO;2-M
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-0032437529&doi=10.1002%2f%28SICI%291099-162X%28199812%2918%3a5%3c499%3a%3aAID-PAD39%3e3.0.CO%3b2-M&partnerID=40&md5=bf719e645125d0f1104220536d5fc23c
AD  - University of East Anglia, Norwich, United Kingdom
AD  - Department of Social Sciences, Glasgow Caledonian University, Glasgow G4 0BA, Cowcaddens Road, United Kingdom
AB  - Uganda's graduated personal tax represents a rather unusual attempt at applying a local income tax as a means of financing local authority operations in a predominantly informal, rural economy. Statistical and other analysis and comment reveal it to have serious deficiencies in terms of standard tax criteria and as a result of associated social costs, despite which local authorities have been led to increase rather than to decrease their reliance on it. Some alternative revenue-raising instruments which could serve to reduce this reliance are indicated.
KW  - Uganda
KW  - financial provision
KW  - local government
KW  - rural economy
KW  - tax system
SN  - 02712075 (ISSN)
LA  - English
J2  - Public Adm. Dev.
M3  - Article
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 18
ER  -

TY  - JOUR
AU  - Blanken, H.
AU  - Grabs, T.
AU  - Schek, H.-J.
AU  - Schenkel, R.
AU  - Weikum, G.
TI  - Intelligent search on XML: Data applications, languages, models, implementations, and benchmarks
PY  - 2003
T2  - Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)
VL  - 2818
SP  - X
EP  - 314
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-18744371150&partnerID=40&md5=46811c4a75f91f512f07352c40923d61
SN  - 16113349 (ISSN)
LA  - English
J2  - Lect. Notes Comput. Sci.
M3  - Article
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 16
ER  -

TY  - CONF
AU  - Carneiro Jr., S.
AU  - Martins, H.J.A.
TI  - Measurements and Model Validation on Three-phase Core-type Distribution Transformers
PY  - 2003
T2  - 2003 IEEE Power Engineering Society General Meeting, Conference Proceedings
VL  - 2
SP  - 777
EP  - 781
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-1542269703&partnerID=40&md5=6cab58fcee2dee3470e72b64919bc2aa
AD  - Department of Electrical Engineering, COPPE, Federal University of Rio de Janeiro, Brazil
AD  - Electric Power Research Center-CEPEL, Rio de Janeiro, Brazil
AB  - This panel discussion summarizes experimental work that has been conducted to establish the validity of models for 3-phase distribution transformers. The discussion reviews a classical method to obtain the admittance matrices both in the phase domain and in the sequence domain and the assumptions adopted in the derivations. Measurements on actual distribution transformers are then reported to show the validity of the assumptions and consequently of the model. The differences in the mutual admittances between the various windings are analyzed and their relevance to accurately represent core type transformers is stressed.
KW  - Symmetrical Components
KW  - Transformer cores
KW  - Transformer Models
KW  - Transformer Testing
KW  - Computational methods
KW  - Data reduction
KW  - Electric currents
KW  - Electric potential
KW  - Mathematical models
KW  - Matrix algebra
KW  - Short circuit currents
KW  - Symmetrical components
KW  - Transformer cores
KW  - Transformer models
KW  - Transformer testing
KW  - Electric transformers
SN  - 0780379896 (ISBN)
LA  - English
J2  - 2003 IEEE Power Eng. Soc. Gen. Meet. Conf. Proc.
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 0; Correspondence Address: S. Carneiro Jr.; Department of Electrical Engineering, COPPE, Federal University of Rio de Janeiro, Rio de Janeiro, Brazil; email: sandoval@coep.ufrj.br; Conference name: 2003 IEEE Power Engineering Society General Meeting; Conference date: 13 July 2003 through 17 July 2003; Conference code: 62418
ER  -

TY  - CHAP
AU  - Gaedcke, F.
AU  - Eberwein, B.
AU  - Kelber, O.
AU  - Kraft, K.
AU  - Stauss-Grabo, M.
AU  - Tegtmeier, M.
AU  - Schulz, V.
AU  - Winterhoff, H.
AU  - Kemper, F.
TI  - Safety Assessment of Botanicals and Botanical Preparations Used as Ingredients in Food Supplements: Testing an European Food Safety Authority-Tiered ApproachDietary Supplements and Herbal Medicinal Products-for a Clear Differentiation. Statement of the Society for Phytotherapy (GPT) to the "Article 13 Health Claim List" of the EFSA
PY  - 2010
T2  - Risk Assessment of Phytochemicals in Food: Novel Approaches
SP  - 393
EP  - 402
DO  - 10.1002/9783527634705.ch4
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-84888685502&doi=10.1002%2f9783527634705.ch4&partnerID=40&md5=a1cc97ceb2d4912f709cd335bf93131d
AD  - Gesellschaft für Phytotherapie/Society for Phytotherapy, D-51063 Köln, Uferstr. 4, Germany
KW  - Apple polyphenols
KW  - Benzo[a]pyrene
KW  - Catechins
KW  - Fumonisin B1
KW  - Furocoumarins
KW  - Genotoxicit
KW  - Green tea catechins
KW  - Herbal homeopathic extracts
KW  - Herbal medicinal preparations
KW  - HT-2 toxin
KW  - Isoflavone supplements
KW  - Limettin
KW  - Mild preservation technology
KW  - Photodynamic therapy
KW  - Polyphenol metabolites
KW  - Pyrrolizidine alkaloids
KW  - Screening assays
KW  - T-2 toxin
PB  - Wiley-Blackwell
SN  - 978-352732929-8 (ISBN)
LA  - English
J2  - Risk Assessment of Phytochemicals in Food: Novel Approaches
M3  - Book chapter
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 1; Correspondence Address: F. Kemper; Gesellschaft für Phytotherapie/Society for Phytotherapy, D-51063 Köln, Uferstr. 4, Germany; email: ges-phyto@tonline.de
ER  -

TY  - JOUR
AU  - Liao, R.-J.
AU  - Yang, L.-J.
AU  - Li, J.
AU  - Grzybowski, S.
TI  - Aging condition assessment of transformer oil-paper insulation model based on partial discharge analysis
PY  - 2011
T2  - IEEE Transactions on Dielectrics and Electrical Insulation
VL  - 18
IS  - 1
C7  - 5704522
SP  - 303
EP  - 311
DO  - 10.1109/TDEI.2011.5704522
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-79551635682&doi=10.1109%2fTDEI.2011.5704522&partnerID=40&md5=b5b106b35d71361aa7dc6f11dbd87353
AD  - State Key Laboratory of Power Transmission Equipment and System Security New Technology, Chongqing University, Chongqing 400044, China
AD  - High Voltage Laboratory, Department of Electrical and Computer Engineering, Mississippi State University, Mississippi State, MS 39762, United States
AB  - This paper presents aging condition assessment of oil-paper transformer insulation based on partial discharge analysis in order to realize statistical parameters reduction. The extracted feature factors of this proposed model were used to identify oil-paper samples with different aging degrees. An accelerated aging test was implemented using artificial oil-paper samples with an internal flat air gap. During the aging test, partial discharge signal acquisition was conducted periodically. In the new model, conventional statistical parameters of phase resolved partial discharge (PRPD) patterns were analyzed using principal component and factor analysis (PCFA), and a group of new features constituted by the extracted factors was obtained. These factors were not only independent of one another, they had their own specific properties. To a great extent, these factors represent information on PRPD patterns through a limited number of variables. Through the use of the new features extracted from PCFA method, the clustering and discriminating results of the samples with different aging stages provided significantly referenced information on the condition assessment of oil-paper insulation. © 2011 IEEE.
KW  - ageing diagnosis
KW  - oil-paper insulation
KW  - Partial discharge
KW  - transformer
KW  - Insulating oil
KW  - Partial discharges
KW  - Principal component analysis
KW  - Rating
KW  - Signal processing
KW  - Steel bridges
KW  - Testing
KW  - Accelerated aging test
KW  - ageing diagnosis
KW  - Aging conditions
KW  - Aging degree
KW  - Aging tests
KW  - Air-gaps
KW  - Condition assessments
KW  - Model-based
KW  - New model
KW  - oil-paper insulation
KW  - Oil-papers
KW  - Partial discharge analysis
KW  - Partial discharge signal
KW  - Phase resolved partial discharge patterns
KW  - Principal component and factor analysis
KW  - PRPD patterns
KW  - Statistical parameters
KW  - transformer
KW  - Transformer insulation
KW  - Transformer oil
KW  - Oil filled transformers
SN  - 10709878 (ISSN)
LA  - English
J2  - IEEE Trans Dielectr Electr Insul
M3  - Article
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 95; CODEN: ITDIE
ER  -

TY  - CONF
AU  - Mork, B.
AU  - Gonzalez, F.
AU  - Ishchenko, D.
AU  - Stuehm, D.
AU  - Mitra, J.
TI  - Hybrid transformer model for transient simulation: Part II - Laboratory measurements and benchmarking
PY  - 2007
T2  - 2007 IEEE Power Engineering Society General Meeting, PES
C7  - 4275232
DO  - 10.1109/PES.2007.385623
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-42549133544&doi=10.1109%2fPES.2007.385623&partnerID=40&md5=2f2a47a94b492566548ed0209b84f11b
AD  - Michigan Technological University
AD  - El Sewedy Cables
AD  - North Dakota State University
AD  - New Mexico State University
AB  - The topological structure and basic approaches for parameter estimation for a new hybrid transformer model are presented in Part I of this two-paper set. Part Il deals with the model benchmarking and also discusses additional methods for parameter estimation based on laboratory measurements. The simulation results confirm the validity of the model for the low- and medium-frequency range. © 2007 IEEE.
KW  - Benchmarking
KW  - Circuit simulation
KW  - Electric network topology
KW  - Parameter estimation
KW  - Transient analysis
KW  - Hybrid transformers
KW  - Model benchmarking
KW  - Topological structure
KW  - Transient simulation
KW  - Power transformers
SN  - 1424412986 (ISBN); 978-142441298-3 (ISBN)
LA  - English
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 3; Conference name: 2007 IEEE Power Engineering Society General Meeting, PES; Conference date: 24 June 2007 through 28 June 2007; Conference code: 71931
ER  -

TY  - CONF
AU  - Kubín, P.
AU  - Kyncl, J.
AU  - Brettschneider, Z.
TI  - Nonlinear time domain transformer model assessment
PY  - 2007
T2  - Proceedings of the 4th International Scientific Symposium on Electric Power Engineering, ELEKTROENERGETIKA 2007
SP  - 97
EP  - 100
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-84907004112&partnerID=40&md5=6c642a3112fcab4d22a658a6c329b50a
AD  - ČVUT Praha, Katedra Elektroenergetiky, 16627 Praha 6, Technická 2, Czech Republic
AB  - The dependence of current effective values on applied harmonic voltage of unloaded transformer cannot be used for time domain analysis. Because of the unavailability of the time domain measured values authors has developed method to obtain the nonlinear transformer model with hysteresis with the reasonable accuracy. The paper describes step by step the assessment of time domain characteristics based on measured effective values. Technical University of Košice © 2007.
KW  - Engineering
KW  - Industrial engineering
KW  - Harmonic voltages
KW  - Measured values
KW  - Reasonable accuracy
KW  - Technical universities
KW  - Time domain
KW  - Time domain characteristics
KW  - Transformer modeling
KW  - Time domain analysis
PB  - Technical University of Kosice, Elec
SN  - 978-805530400-7 (ISBN)
LA  - Czech
J2  - Proc. Int. Sci. Symp. Electr. Power Eng., ELEKTROENERGETIKA
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 0; Conference name: 4th International Scientific Symposium on Electric Power Engineering, ELEKTROENERGETIKA 2007; Conference date: 19 September 2007 through 21 September 2007; Conference code: 107517
ER  -

TY  - JOUR
AU  - Maalouf, A.I.
TI  - A validated model for the zero drift due to transformer signals in electromagnetic flowmeters operating with electrolytic conductors
PY  - 2006
T2  - IEEE Sensors Journal
VL  - 6
IS  - 6
SP  - 1502
EP  - 1510
DO  - 10.1109/JSEN.2006.884176
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-33845606776&doi=10.1109%2fJSEN.2006.884176&partnerID=40&md5=c24ef3a5da7b704a3f484fc95ee3a7b9
AD  - IEEE, United Kingdom
AD  - Department of Engineering Science, Oxford University, OX1 3PJ Oxford, United Kingdom
AB  - In this paper, the author investigates theoretically the magnitudes of the zero offsets and the zero drifts originating from magnetic-flux linkage between the coils of the electromagnet and the loop formed by the electrode cables in an electromagnetic flowmeter for electrolytic conductors. The dependence of such zero offsets on the liquid properties, frequency of operation, etc., is explained. This dependence is used to predict the zero offsets expected in metering this liquid using phase-sensitive detection with the flowmeter tube described in this paper. Precautions needed in flowmeter design to minimize instrument offsets and zero drifts are explained. In the end, the proposed model was validated against the experimental data. © 2006 IEEE.
KW  - Electromagnetic flowmeter
KW  - Mathematical modeling
KW  - Transformer signal
KW  - Validation
KW  - Zero drift
KW  - Electric coils
KW  - Electric conductors
KW  - Electric connectors
KW  - Electromagnets
KW  - Magnetic flux
KW  - Mathematical models
KW  - Electromagnetic flowmeter
KW  - Transformer signal
KW  - Validation
KW  - Zero drifts
KW  - Zero offsets
KW  - Magnetic flowmeters
SN  - 1530437X (ISSN)
LA  - English
J2  - IEEE Sensors J.
M3  - Article
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 3; Correspondence Address: A.I. Maalouf; Department of Engineering Science, Oxford University, OX1 3PJ Oxford, United Kingdom; email: alinemaalouf@hotmail.com
ER  -

TY  - CONF
AU  - Yu, G.
AU  - Li, X.
AU  - Bao, Y.
AU  - Wang, D.
TI  - Evaluating document-to-document relevance based on document language model: Modeling, implementation and performance evaluation
PY  - 2005
T2  - Lecture Notes in Computer Science
VL  - 3406
SP  - 593
EP  - 603
DO  - 10.1007/978-3-540-30586-6_63
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-24344449146&doi=10.1007%2f978-3-540-30586-6_63&partnerID=40&md5=60c12b39fcc106834e4f6f803d363524
AD  - School of Information Science and Engineering, Northeastern University, Shenyang 110004, China
AB  - To evaluate document-to-document relevance is very important to many advanced applications such as IR, text mining and natural language processing. Since it is very hard to define document relevance in a mathematic way on account of users' uncertainty, the concept of topical relevance is widely accepted by most of research fields. It suggests that a document relevance model should explain whether the document representation describes its topical contents and the matching method reveals the topical differences among the documents. However, the current document-to-document relevance models, such as vector space model, string distance, don't put explicitly emphasis on the perspective of topical relevance. This paper exploits a document language model to represent the document topical content and explains why it can reveal the document topics and then establishes two distributional similarity measure based on the document language model to evaluate document-to-document relevance. The experiment on the TREC testing collection is made to compare it with the vector space model, and the results show that the Kullback-Leibler divergence measure with Jelinek-Mercer smoothing outperforms the vector space model significantly. © Springer-Verlag Berlin Heidelberg 2005.
KW  - Content based retrieval
KW  - Information retrieval systems
KW  - Mathematical models
KW  - Text processing
KW  - Document language models
KW  - Natural language processing
KW  - TREC testing
KW  - Vector space model (VSM)
KW  - Data mining
PB  - Springer Verlag
SN  - 03029743 (ISSN)
LA  - English
J2  - Lect. Notes Comput. Sci.
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 1; Correspondence Address: G. Yu; School of Information Science and Engineering, Northeastern University, Shenyang 110004, China; email: yuge@mail.neu.edu.cn; Conference name: 6th International Conference, CICLing 2005; Conference date: 13 February 2005 through 19 February 2005; Conference code: 65549
ER  -

TY  - JOUR
AU  - Srinivasan, M.
AU  - Krishnan, A.
TI  - Assessing the reliability of transformer top oil temperature model
PY  - 2012
T2  - International Journal of Reliability, Quality and Safety Engineering
VL  - 19
IS  - 5
C7  - 1250024
DO  - 10.1142/S0218539312500246
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-84870482682&doi=10.1142%2fS0218539312500246&partnerID=40&md5=09aa249956803fa45a59157b211410a8
AD  - Department of EEE, Velalar College of Engineering and Technology, Erode, Tamilnadu, India
AD  - K.S. Rangasamy College of Technology, Erode, Tamilnadu, India
AB  - The hot spot temperature (HST) plays a most important role in the insulation life of the transformer. Ambient temperature and environmental variable factors involved in the top oil temperature (TOT) computations in all transformer thermal models affects insulation lifetime either directly or indirectly. The importance of the ambient temperature in transformer's insulation life, a new semi-physically-based model for the estimation of TOT in transformers has been proposed in this paper. The winding hot-spot temperature can be calculated as function of the TOT that can be estimated by using the ambient temperature, wind velocity and solar heat radiation effect and transformer loading measured data. The estimated TOT is compared with measured data of a distribution transformer in operation. The proposed model has been validated using real data gathered from a 100 MVA power transformer. For a semi-physically-based model to be acceptable, it must have the qualities of: adequacy, accuracy and consistency. We assess model adequacy using the scale: prediction R2, and plot of residuals against fitted values. To assess model consistency, we use: variance inflation factor (VIF) (which measure multicollinearity), condition number. To assess model accuracy we use mean square error, maximum and minimum error values of semi-physically-based model parameters to the existing model parameters. © 2012 World Scientific Publishing Company.
KW  - Ambient temperature
KW  - hot-spot temperature
KW  - insulation life
KW  - semi-physically-based model
KW  - top oil temperature
KW  - Insulation
KW  - Number theory
KW  - Power transformers
KW  - Regression analysis
KW  - Temperature
KW  - Condition numbers
KW  - Distribution transformer
KW  - Environmental variables
KW  - Error values
KW  - Fitted values
KW  - Hotspot temperature
KW  - Inflation factors
KW  - Insulation life
KW  - Model accuracy
KW  - Model adequacy
KW  - Model consistency
KW  - Model parameters
KW  - Multicollinearity
KW  - Reliability of transformers
KW  - Top oil temperature
KW  - Transformer loadings
KW  - Transformer thermal models
KW  - Wind velocities
KW  - Oil filled transformers
SN  - 02185393 (ISSN)
LA  - English
J2  - Int. J.  Reliab. Qual. Saf.
M3  - Article
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 2; Correspondence Address: M. Srinivasan; Department of EEE, Velalar College of Engineering and Technology, Erode, Tamilnadu, India; email: srinimeha@gmail.com; CODEN: IJREF
ER  -

TY  - CONF
AU  - Wu, S.-H.
AU  - Su, C.-Y.
AU  - Jiang, T.-J.
AU  - Hsu, W.-L.
TI  - An evaluation of adopting language model as the checker of preposition usage
PY  - 2006
T2  - Proceedings of the 18th Conference on Computational Linguistics and Speech Processing, ROCLING 2006
SP  - 369
EP  - 386
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-84882949579&partnerID=40&md5=9709a1021646c6171eb3af6560ade813
AD  - Dept. of CSIE, Chaoyang University of Technology, Taiwan
AD  - Institute of Information Science, Academia Sinica, Taiwan
AD  - Department of Computer Science, National Tsing-Hua University, Taiwan
AB  - Many grammar checkers in rule-based approach do not handle errors that come from various usages, for example, the usages of prepositions. To study the behavior of prepositions, we introduce the language model into a grammar-checking task. A language model is trained from a large training corpus, which contains many short phrases. It can be used for detecting and correcting certain types of grammar errors, where local information is sufficient to make decision. We conduct several experiments on finding the correct English prepositions. The experiment results show that the accuracy of open test is 71% and the accuracy of closed test is 89%. The accuracy is 70% on TOEFL-level tests.
KW  - English preposition usage
KW  - Grammar checker
KW  - Language model
KW  - Errors
KW  - Experiments
KW  - Speech processing
KW  - English preposition usage
KW  - Grammar checkers
KW  - Language model
KW  - Local information
KW  - Rule-based approach
KW  - Training corpus
KW  - Computational linguistics
LA  - English
J2  - Proc. Conf. Comput. Linguist. Speech Process., ROCLING
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 3; Conference name: 18th Conference on Computational Linguistics and Speech Processing, ROCLING 2006; Conference date: 1 September 2006 through 1 September 2006; Conference code: 98576
ER  -

TY  - JOUR
AU  - Toman, M.
AU  - Štumberger, G.
AU  - Štumberger, B.
AU  - Dolinar, D.
TI  - Nonlinear model of a distribution transformer appropriate for evaluating the effects of unbalanced loads
PY  - 2008
T2  - Journal of Magnetism and Magnetic Materials
VL  - 320
IS  - 20
SP  - e1011
EP  - e1015
DO  - 10.1016/j.jmmm.2008.04.089
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-47649102881&doi=10.1016%2fj.jmmm.2008.04.089&partnerID=40&md5=3b62b764f7363c48f2d7c6fc343ed0b1
AD  - Faculty of Electrical Engineering and Computer Science, University of Maribor, 2000 Maribor, Smetanova ulica 17, Slovenia
AB  - Power packages for calculation of power system transients are often used when studying and designing electromagnetic power systems. An accurate model of a distribution transformer is needed in order to obtain realistic values from these calculations. This transformer model must be derived in such a way that it is applicable when calculating those operating conditions appearing in practice. Operation conditions where transformers are loaded with nonlinear and unbalanced loads are especially challenging. The purpose of this work is to derive a three-phase transformer model that is appropriate for evaluating the effects of nonlinear and unbalanced loads. A lumped parameter model instead of a finite element (FE) model is considered in order to ensure that the model can be used in power packages for the calculation of power system transients. The transformer model is obtained by coupling electric and magnetic equivalent circuits. The magnetic equivalent circuit contains only three nonlinear reluctances, which represent nonlinear behaviour of the transformer. They are calculated by the inverse Jiles-Atherton (J-A) hysteresis model, while parameters of hysteresis are identified using differential evolution (DE). This considerably improves the accuracy of the derived transformer model. Although the obtained transformer model is simple, the simulation results show good agreement between measured and calculated results. © 2008 Elsevier B.V. All rights reserved.
KW  - Higher order harmonics
KW  - Inverse Jiles-Atherton hysteresis model
KW  - Transformer model
KW  - Calculations
KW  - Digital arithmetic
KW  - Elasticity
KW  - Electric power systems
KW  - Electric power transmission networks
KW  - Equivalence classes
KW  - Equivalent circuits
KW  - Evolutionary algorithms
KW  - Finite element method
KW  - Hysteresis
KW  - Loads (forces)
KW  - Magnetic materials
KW  - Mathematical models
KW  - Nanostructured materials
KW  - Networks (circuits)
KW  - Nonlinear optics
KW  - Parameter estimation
KW  - Photoacoustic effect
KW  - Power transmission
KW  - Reverberation
KW  - Transformer magnetic circuits
KW  - Transients
KW  - Differential evolution (DE)
KW  - distribution transformers
KW  - Electromagnetic power
KW  - Elsevier (CO)
KW  - Finite element (FE) modeling
KW  - Hysteresis modeling
KW  - In order
KW  - Lumped parameter model (LPM)
KW  - Magnetic (CE)
KW  - Magnetic equivalent circuits
KW  - Non linear modeling
KW  - Nonlinear behaviours
KW  - Operating conditions
KW  - Operation conditions
KW  - Power system transients
KW  - simulation results
KW  - Three-phase transformers
KW  - transformer modeling
KW  - Unbalanced loads
KW  - Modal analysis
SN  - 03048853 (ISSN)
LA  - English
J2  - J Magn Magn Mater
M3  - Article
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 3; Correspondence Address: M. Toman; Faculty of Electrical Engineering and Computer Science, University of Maribor, 2000 Maribor, Smetanova ulica 17, Slovenia; email: matej.toman@uni-mb.si; CODEN: JMMMD
ER  -

TY  - JOUR
AU  - Hong-xia, X.
AU  - Li-ping, S.
TI  - Condition assessment of power transformers based upon weighted criteria OWA operators and fuzzy model
PY  - 2012
T2  - Journal of Convergence Information Technology
VL  - 7
IS  - 15
SP  - 261
EP  - 269
DO  - 10.4156/jcit.vol7.issue15.31
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-84865695848&doi=10.4156%2fjcit.vol7.issue15.31&partnerID=40&md5=2b047933496e2b2cb826608d4218ac63
AD  - School of Computer Science and Technology, China University of Mining and Technology, Xuzhou, Jiangsu, 221116, China
AD  - School of Information and Electrical Engineering, China University of Mining and Technology, Xuzhou, Jiangsu, 221116, China
AB  - To study feasibility of OWA operator with the decision-making criterias with weights applied to the transformer condition assessment, a transformer condition assessment criteria system is established which including the DGA data, electrical testing, oil testing, and other criterias.This paper proposed an integrated model based upon OWA operator and fuzzy approach to condition assessment of transformers. Firstly, using fuzzy model to generate the original basic probability assignments for the second-level criteria. Afterwards, using OWA operator to combine all of the first-level criteria and give an overall assessment conclusion.In order to fully consider the impact of assessment results by the weights of criteria and criteria membership, this paper introduced a transformation function using fuzzy model based upon OWA operator to aggregate the important integration of different sources of criteria information. The case analysis show that the proposed method to the transformer conditon assessment can be easy to achieve the status, and the conclusion is reasonable and objective, the results close to the real state of transformer operation.
KW  - Condition Assessment
KW  - Fuzzy Approach
KW  - OWA Operator
KW  - Power Transformer
KW  - Oil filled transformers
KW  - Power transformers
KW  - Testing
KW  - Basic probability assignment
KW  - Case analysis
KW  - Condition assessments
KW  - Electrical testing
KW  - Fuzzy approach
KW  - Fuzzy models
KW  - Integrated models
KW  - Oil testing
KW  - OWA operators
KW  - Second-level
KW  - Transformation functions
KW  - Transformer condition assessment
KW  - Electric transformer testing
SN  - 22339299 (ISSN)
LA  - English
J2  - J. Convergence Inf. Technol.
M3  - Article
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 1; Correspondence Address: X. Hong-xia; School of Computer Science and Technology, China University of Mining and Technology, Xuzhou, Jiangsu, 221116, China; email: xiehx@cumt.edu.cn
ER  -

TY  - JOUR
AU  - Swiger, R.R.
AU  - Cosentino, L.
AU  - Masumura, K.-I.
AU  - Nohmi, T.
AU  - Heddle, J.A.
TI  - Further characterization and validation of gpt delta transgenic mice for quantifying somatic mutations in vivo
PY  - 2001
T2  - Environmental and Molecular Mutagenesis
VL  - 37
IS  - 4
SP  - 297
EP  - 303
DO  - 10.1002/em.1036
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-0034940988&doi=10.1002%2fem.1036&partnerID=40&md5=72fecefc3e9a44ef8f26bfec56a62e5f
AD  - Department of Biology, York University, Toronto, Ont., Canada
AD  - Division of Genetics and Mutagenesis, National Institute of Health Sciences, Setagaya-ku, Tokyo, Japan
AD  - Florida Division, Palm Bay, FL 32909, 1470 Treeland Blvd., S.E, United States
AB  - The utility of any mutation assay depends on its characteristics, which are best discovered using model mutagens. To this end, we report further on the characteristics of the lambda-based gpt delta transgenic assay first described by Nohmi et al. ([1996]: Environ Mol Mutagen 28:465-470). Our studies show that the gpt transgene responds similarly to other transgenic loci, specifically lacZ and cII, after treatment with acute doses of N-ethyl-N-nitrosourea (ENU). Because genetic neutrality is an important factor in the design of treatment protocols for mutagenicity testing, as well as for valid comparisons between different tissues and treatments, a time-course study was conducted. The results indicate that the gpt transgene, like cII and lacZ, is genetically neutral in vivo. The sensitivities of the loci are also equivalent, as evidenced by spontaneous mutant frequency data and dose-response curves after acute treatment with 50, 150, or 250 mg/kg ENU. The results are interesting in light of transgenic target size and location and of host genetic background differences. Based on these studies, protocols developed for other transgenic assays should be suitable for the gpt delta. Additionally, a comparison of the gpt and an endogenous locus, Dlb-1, within the small intestine of chronically treated animals (94 μg/mL ENU in drinking water daily) shows differential accumulation of mutations at the loci during chronic exposure. The results further support the existence of preferential repair at endogenous, expressed genes relative to transgenes. © 2001 Wiley-Liss, Inc.
KW  - cII
KW  - ENU
KW  - lacZ
KW  - Preferential repair
KW  - Protocol
KW  - Animals
KW  - Bacterial Proteins
KW  - DNA Repair
KW  - Dose-Response Relationship, Drug
KW  - Escherichia coli Proteins
KW  - Ethylnitrosourea
KW  - Female
KW  - Genetic Techniques
KW  - Mice
KW  - Mice, Transgenic
KW  - Models, Genetic
KW  - Mutagenesis, Site-Directed
KW  - Mutagens
KW  - Mutation
KW  - Pentosyltransferases
KW  - Proteins
KW  - Stem Cells
KW  - Time Factors
KW  - Transgenes
KW  - Animalia
KW  - Mus musculus
KW  - ethylnitrosourea
KW  - virus protein
KW  - animal experiment
KW  - animal model
KW  - article
KW  - female
KW  - gene expression
KW  - gene locus
KW  - genotoxicity
KW  - mouse
KW  - mutagen testing
KW  - nonhuman
KW  - somatic mutation
KW  - transgenic mouse
SN  - 08936692 (ISSN)
C2  - 11424179
LA  - English
J2  - Environ. Mol. Mutagen.
M3  - Article
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 23; Correspondence Address: R.R. Swiger; Midwest Research Institute, Florida Division, Palm Bay, FL 32909, 1470 Treeland Blvd., United States; email: rswiger@mriresearch.org; CODEN: EMMUE
ER  -

TY  - JOUR
AU  - Liao, R.
AU  - Zheng, H.
AU  - Grzybowski, S.
AU  - Yang, L.
AU  - Zhang, Y.
AU  - Liao, Y.
TI  - An integrated decision-making model for condition assessment of power transformers using fuzzy approach and evidential reasoning
PY  - 2011
T2  - IEEE Transactions on Power Delivery
VL  - 26
IS  - 2
C7  - 5688215
SP  - 1111
EP  - 1118
DO  - 10.1109/TPWRD.2010.2096482
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-79953225127&doi=10.1109%2fTPWRD.2010.2096482&partnerID=40&md5=136f76f6edd36adee88db72c6eba63aa
AD  - State Key Laboratory of Power Transmission Equipment and System Security and New Technology, Chongqing University, Chongqing 400044, Shapingba District, China
AD  - High Voltage Laboratory, Department of Electrical and Computer Engineering, Mississippi State University, Mississippi State, MS 39762, United States
AD  - Chongqing Electric Power Corp., Chongqing 401147, China
AB  - This paper presents an integrated model based upon the fuzzy approach and evidential reasoning decision-making approach to condition assessment of power transformers. An assessing index system, including the DGA data, electrical testing, and oil testing, is established to facilitate the assessing model. The model is composed of two levels, that is, the fuzzy model and evidential reasoning model. The fuzzy model is proposed for generating the original basic probability assignments for the second-level model. Afterwards, an evidential reasoning decision-making model is utilized to combine all of the evidence and give an overall evaluation conclusion. Based upon this integrated model, a decision-making procedure is put forward to serve as an effective tool for transformer condition assessments. The results show that the assessing model is capable of offering an overall evaluation of the observed transformer condition. © 2011 IEEE.
KW  - Condition assessments
KW  - evidential reasoning
KW  - fuzzy approach
KW  - power transformers
KW  - Decision making
KW  - Integration
KW  - Transformer substations
KW  - Assessing model
KW  - Basic probability assignment
KW  - Condition assessments
KW  - Decision making models
KW  - Effective tool
KW  - Electrical testing
KW  - evidential reasoning
KW  - Fuzzy approach
KW  - Fuzzy models
KW  - Index systems
KW  - Integrated decision
KW  - Integrated models
KW  - Oil testing
KW  - Second-level
KW  - Transformer condition assessment
KW  - Power transformers
SN  - 08858977 (ISSN)
LA  - English
J2  - IEEE Trans Power Delivery
M3  - Article
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 157; Correspondence Address: R. Liao; State Key Laboratory of Power Transmission Equipment and System Security and New Technology, Chongqing University, Chongqing 400044, Shapingba District, China; email: rjliao@cqu.edu.cn; CODEN: ITPDE
ER  -

TY  - JOUR
AU  - Pérez B., R.J.
AU  - Alfonso, E.M.
AU  - Fernández, S.J.
TI  - Parameter estimation and validation of power transformers top oil temperature model by applying genetic algorithms
ST  - Estimación de parámetros y validación del modelo de la temperatura del aceite superior en transformadores de potencia aplicando algoritmos genéticos
PY  - 2009
T2  - Revista Tecnica de la Facultad de Ingenieria Universidad del Zulia
VL  - 32
IS  - 3
SP  - 266
EP  - 275
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-77952709612&partnerID=40&md5=a7ef919251d0fafe50c721dcc579ec55
AD  - Departamento de Ingeniería Eléctrica, Universidad Nacional Experimental Politécnica Antonio José de Sucre UNEXPO, Parque Tecnológico. Barquisimeto, Av. Corpahuiaco entre Avs. La Salle y Rotaria, Venezuela
AD  - Facultad de Informática, Universidad de Cienfuegos Carlos Rafael Rodríguez, Cuba
AD  - Instituto Superior Politécnico José Antonio Echeverría, CUJAE-CIPEL, CP 19390, Ciudad de La Habana, Av. 114-11901, Marianao, Cuba
AB  - This paper presents a technique based on Genetic Algorithms for the parameter estimation and validation of the power transformers top oil temperature model proposed by Lesieutre [1]. For such aim, data are used in on-line diagnosis and monitoring systems, installed in a 100 MVA 230/115/24 kV OA/FA/FOA transformer of Barquisimeto Substation at ENELBAR, Venezuela since the year 2003. The objective of this work is to compare mistake reduction between the model and the top oil temperature measurement when their parameters estimation is considered by genetic algorithms and least-squares. The parameters estimation by genetic algorithms evidence better results of the model, which improves its performance as a power transformer diagnosis tool.
KW  - Genetic algorithms
KW  - Parameter estimation
KW  - Power transformer
KW  - Fuzzy control
KW  - Genetic algorithms
KW  - Metal analysis
KW  - Power transformers
KW  - Temperature measurement
KW  - Transformer substations
KW  - Least Square
KW  - Monitoring system
KW  - On-line diagnosis
KW  - Parameters estimation
KW  - Power transformer diagnosis
KW  - Top oil temperature
KW  - Venezuela
KW  - Parameter estimation
SN  - 02540770 (ISSN)
LA  - Spanish
J2  - Revista Tecnica de la Facultad de Ingenieria Universidad del Zulia
M3  - Article
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 2; Correspondence Address: R. J. Pérez B.; Departamento de Ingeniería Eléctrica, Universidad Nacional Experimental Politécnica Antonio José de Sucre UNEXPO, Parque Tecnológico. Barquisimeto, Av. Corpahuiaco entre Avs. La Salle y Rotaria, Venezuela; email: romuloperez2003@gmail.com; CODEN: RTFZD
ER  -

TY  - JOUR
AU  - Takagi, M.
AU  - Yamamoto, H.
AU  - Yamaji, K.
TI  - An evaluation of amorphous transformer using load curve pattern model for pole transformer
PY  - 2008
T2  - IEEJ Transactions on Power and Energy
VL  - 128
IS  - 6
SP  - 10+885
EP  - 892
DO  - 10.1541/ieejpes.128.885
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-72149117939&doi=10.1541%2fieejpes.128.885&partnerID=40&md5=2b2c2f15483e6fd2626d5a3afbd4f28c
AD  - Department of Electrical Engineering, School of Engineering, University of Tokyo, Bunkyo-ku, Tokyo 113-8656, 7-3-1, Hongo, Japan
AD  - Department of Advanced Energy, Graduate School of Frontier Sciences, University of Tokyo, Kashiwa 277-8561, 5-1-5, Kashiwa-no-ha, Japan
AB  - Energy loss in transformer is composed of no load loss and load loss. No load loss of amorphous transformer (i.e. amorphous metal-based transformer) could be reduced by about 70% compared with traditional transformers (e.g. silicon steel-based transformer). If amorphous transformers are adopted to pole transformers owned by electric companies, large amount of energy savings and reduction of CO2 could be realized. However, amorphous transformers have disadvantages of high initial cost and high load loss parameters compared with traditional transformers. Economies of pole transformers are evaluated in the paper by the sum of the initial cost and the power loss cost, that is calculated by the load curve pattern of pole transformers. Authors propose a load curve pattern model for pole transformers and analyze the effects in cases which amorphous transformers are adopted to pole transformers. Simulation results show that most of the losses in pole transformers are no load loss, and amorphous transformer is effective in achieving substantial energy savings as well as environmental benefits. © 2008 the Institute of Electrical Engineers of Japan.
KW  - Amorphous transformer
KW  - Energy saving
KW  - Load curve pattern
KW  - No load loss
KW  - Pole transformer
KW  - Amorphous silicon
KW  - Energy conservation
KW  - Energy dissipation
KW  - Poles
KW  - Silicon steel
KW  - Amorphous metals
KW  - Amorphous transformers
KW  - Environmental benefits
KW  - Large amounts
KW  - Load curve patterns
KW  - No-load loss
KW  - Pole transformer
KW  - Substantial energy
KW  - Electric load loss
PB  - Institute of Electrical Engineers of Japan
SN  - 03854213 (ISSN)
LA  - English
J2  - IEEJ Trans. Power Energy
M3  - Article
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 3; Correspondence Address: M. Takagi; Department of Electrical Engineering, School of Engineering, University of Tokyo, Bunkyo-ku, Tokyo 113-8656, 7-3-1, Hongo, Japan; email: takagi@yamaji.t.u-tokyo.ac.jp
ER  -

TY  - JOUR
AU  - Kamigaito, T.
AU  - Noguchi, T.
AU  - Narumi, K.
AU  - Takashima, R.
AU  - Hamada, S.
AU  - Sanada, H.
AU  - Hasuko, M.
AU  - Hayashi, H.
AU  - Masumura, K.
AU  - Nohmi, T.
TI  - Evaluation of the in vivo mutagenicity of nickel subsulfide in the lung of F344 gpt delta transgenic rats exposed by intratracheal instillation: A Collaborative study for the gpt delta transgenic rat mutation assay
PY  - 2012
T2  - Genes and Environment
VL  - 34
IS  - 1
SP  - 34
EP  - 44
DO  - 10.3123/jemsge.34.34
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-84860682991&doi=10.3123%2fjemsge.34.34&partnerID=40&md5=9fe27ef6981c290bcfb52c86b4f77676
AD  - Japan Bioassay Research Center, Japan Industrial Safety and Health Association, Hadano, Kanagawa 257-0015, 2445 Hirasawa, Japan
AD  - Safety Assessment Department, Mitsubishi Chemical Medience Corporation, Ibaraki, Japan
AD  - Central Research Laboratories, Kaken Pharmaceutical Co., Ltd., Shizuoka, Japan
AD  - Division of Genetics and Mutagenesis, National Institute of Health Sciences, Tokyo, Japan
AD  - Toxicology Laboratory, Pharmaceutical Research Center, Meiji Seika Pharma Co., Ltd., Yokohama, Japan
AB  - This study was conducted to evaluate the effectiveness of a transgenic rat mutation assay using F344 gpt delta rats. We investigated the mutagenic potential in the lung of nickel subsulfide (Ni3S2), an insoluble fine-crystallinemetallic compound and a carcinogen in the rodent and human lung. Ni3S2 carcinogenicity has been proposed to act via both genotoxic and non-genotoxic mechanisms. Ni3S2 was intratracheally instilled into male gpt delta rats at doses of 0.5 and 1 mg/animal once a week for four weeks; these doses of Ni3S2 are high enough to induce inflammation in the lung. Following a period of 28 and 90 days after the first administration, the gpt mutant frequencies (MFs) in lung were determined in four independent laboratories, and Spi- selection for larger deletion mutations was donein one laboratory. The gpt MFs of the rats treated with Ni3S2 were not increased: all four laboratories obtainedsimilar results with no statistical differences. The Spi- MFs were also not increased by exposure to Ni3S 2. These results indicate that intratracheally instilled Ni 3S2 is nonmutagenic in the lung of gpt delta transgenic rats; however, whether Ni3S2 is non-mutagenic in the lung or it induces mutations which are not detectable by transgenic rodent mutation assays requires further investigation. © The Japanese Environmental Mutagen Society.
KW  - F344 gpt delta transgenic rat
KW  - Gpt assay
KW  - Nickel subsul-fide
KW  - Spi- assay
KW  - Rattus
KW  - Rodentia
KW  - nickel subsulfide
KW  - animal experiment
KW  - animal model
KW  - animal tissue
KW  - article
KW  - carcinogenicity
KW  - controlled study
KW  - deletion mutant
KW  - drug instillation
KW  - Fischer 344 rat
KW  - gene deletion
KW  - gene frequency
KW  - genotoxicity
KW  - genotyping technique
KW  - in vivo study
KW  - mutagenicity
KW  - nonhuman
KW  - pneumonia
KW  - rat
KW  - transgenic rat
SN  - 18807062 (ISSN)
LA  - English
J2  - Genes Environ.
M3  - Article
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 3; Correspondence Address: T. Kamigaito; Japan Bioassay Research Center, Japan Industrial Safety and Health Association, Hadano, Kanagawa 257-0015, 2445 Hirasawa, Japan; email: t-kamigaito@jisha.or.jp
ER  -

TY  - JOUR
AU  - Mork, B.A.
TI  - Five-legged wound-core transformer model: derivation, parameters, implementation, and evaluation
PY  - 1999
T2  - IEEE Transactions on Power Delivery
VL  - 14
IS  - 4
SP  - 1519
EP  - 1525
DO  - 10.1109/61.796249
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-0033208037&doi=10.1109%2f61.796249&partnerID=40&md5=96b7dae17e0ddf79eb11c4114c396e58
AD  - IEEE, United States
AD  - Department of Electrical Engineering, Michigan Technological University, Houghton, MI 49931, United States
AB  - The ability to predict or confirm ferroresonance and to evaluate its severity depends primarily on the correctness of the transformer model used in the computer simulation. An equivalent circuit is developed here for the widely used three-phase grounded-wye to grounded-wye five-legged wound-core distribution transformer. Recently developed equivalent circuits are generally correct, but cannot faithfully reproduce all of the ferroresonant modes possible in this transformer. This new equivalent circuit is derived using duality transformations. Core saturation and losses and coil capacitances are included in the model. Model parameters are obtained via measurement, obviating the need for proprietary manufacturer design information. The model is implemented in EMTP. Simulation results are presented and compared to measurements. A technique for predicting ferroresonance on a system level, based on the use of bifurcation diagrams and Poincare sections, is developed and implemented using EMTP. The model performs quite well, even though coil capacitances are not entirely included in the model. One of the key advancements is the development of a bifurcation simulation method to predict ferroresonant behaviors for a large range of capacitance values.
KW  - Bifurcation (mathematics)
KW  - Capacitance
KW  - Chaos theory
KW  - Circuit resonance
KW  - Computer simulation
KW  - Dynamics
KW  - Electric coils
KW  - Electric losses
KW  - Electric power distribution
KW  - Equivalent circuits
KW  - Magnetic cores
KW  - Core saturation
KW  - Duality transformations
KW  - Electromagnetic transient program
KW  - Ferroresonance
KW  - Five legged wound core transformer model
KW  - Overvoltages
KW  - Three phase grounded wye
KW  - Transformer models
KW  - Electric transformers
SN  - 08858977 (ISSN)
LA  - English
J2  - IEEE Trans Power Delivery
M3  - Article
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 77; CODEN: ITPDE
ER  -

TY  - CONF
AU  - Deshmukh, O.D.
AU  - Doddala, H.
AU  - Verma, A.
AU  - Visweswariah, K.
TI  - Role of language models in spoken fluency evaluation
PY  - 2010
T2  - Proceedings of the 11th Annual Conference of the International Speech Communication Association, INTERSPEECH 2010
SP  - 2866
EP  - 2869
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-79959815072&partnerID=40&md5=7e1825555613723c2cf70aaa422a3572
AD  - IBM Research India, New Delhi, Vasant Kunj Institutional Area, India
AB  - This paper addresses the task of automatic evaluation of spoken fluency skills of a speaker. Specifically, the paper evaluates the role of language models built from fluent and disfluent data in quantifying the fluency of a spoken monologue. We show that features based on relative perplexities of the fluent and the disfluent language models on a given utterance are indicative of the level of spoken fluency of the utterance. The proposed features lead to a spoken fluency classification accuracy of 39.8% for 4-class and 68.4% for 2-class classification. Combining these features with a set of prosodic features leads to further improvement in the classification accuracy thus highlighting the complementarity of the information they contribute compared to the low-level disfluency information captured by the prosodic features. © 2010 ISCA.
KW  - Language models
KW  - Perplexity
KW  - Spoken fluency evaluation
KW  - Computational linguistics
KW  - Speech communication
KW  - Automatic evaluation
KW  - Classification accuracy
KW  - Language model
KW  - Perplexity
KW  - Prosodic features
KW  - Spoken fluency evaluation
KW  - Disfluencies
KW  - Feature-based
KW  - Fluents
KW  - Classification (of information)
PB  - International Speech Communication Association
LA  - English
J2  - Proc. Annu. Conf. Int. Speech Commun. Assoc., INTERSPEECH
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 0; Correspondence Address: O.D. Deshmukh; IBM Research India, New Delhi, Vasant Kunj Institutional Area, India; email: odeshmuk@in.ibm.com
ER  -

TY  - JOUR
AU  - Hori, C.
AU  - Katoh, M.
AU  - Ito, A.
AU  - Kohda, M.
TI  - Construction and evaluation of language models based on stochastic context-free grammar for speech recognition
PY  - 2002
T2  - Systems and Computers in Japan
VL  - 33
IS  - 13
SP  - 48
EP  - 59
DO  - 10.1002/scj.1172
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-0037202530&doi=10.1002%2fscj.1172&partnerID=40&md5=3cd311f8de11009083a4d7476334ee0c
AD  - Graduate School of Information Science and Engineering, Tokyo Institute of Technology, Tokyo, 152-8550, Japan
AD  - Faculty of Engineering, Yamagata University, Yonezawa, 992-8510, Japan
AB  - This paper deals with the use of a stochastic context-free grammar (SCFG) for large vocabulary continuous speech recognition; in particular, an SCFG with phrase-level dependency rules is built. Unlike n-gram models, the SCFG can describe not only local constraints but also global constraints pertaining to the sentence as a whole, thus making possible language models with great expressive power. However, the inside-outside algorithm must be used for estimation of the SCFG parameters, which involves a great amount of calculation, proportional to the third power of the number of nonterminal symbols and of the input string length. Hence, due to problems in dealing with extensive text corpora, the SCFG has hardly been applied as a language model for very large vocabulary continuous speech recognition. The proposed phrase-level dependency SCFG allows a significant reduction of the computational load. In experiments with the EDR corpus, the proposed method proved effective. In experiments with the Mainichi corpus, a large-scale phrase-level dependency SCFG was built for a very large vocabulary continuous speech recognition system. Speech recognition tests with a vocabulary of about 5000 words showed that the proposed method could not compare with the trigram model in performance; however, when it was used in combination with a trigram model, the error rate was reduced by 14% compared to the trigram model alone.
KW  - Dependency grammar
KW  - Inside-outside algorithm
KW  - Language model
KW  - Speech recognition
KW  - Stochastic context-free grammar
KW  - Algorithms
KW  - Calculations
KW  - Computational linguistics
KW  - Constraint theory
KW  - Context free grammars
KW  - Error analysis
KW  - Mathematical models
KW  - Parameter estimation
KW  - Pattern recognition systems
KW  - Random processes
KW  - Dependency grammar
KW  - Language model
KW  - Stochastic context free grammar
KW  - Trigram model
KW  - Continuous speech recognition
SN  - 08821666 (ISSN)
LA  - English
J2  - Syst Comput Jpn
M3  - Article
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 2; CODEN: SCJAE
ER  -

TY  - CONF
AU  - Sule, I.
AU  - Aliyu, U.O.
AU  - Venayagamoorthy, G.K.
TI  - Simulation model for assessing transient performance of capacitive voltage transformers
PY  - 2006
T2  - 2006 IEEE Power Engineering Society General Meeting, PES
C7  - 1709533
DO  - 10.1109/pes.2006.1709533
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-35348834749&doi=10.1109%2fpes.2006.1709533&partnerID=40&md5=7d63145a784428da1de6bfbbbf1dfe66
AD  - IEEE
AD  - Electrical and Electronics Engineering Department, Federal Polytechnic, Mubi, Nigeria
AD  - Electrical Engineering Programme, Abubakar Tafawa Balewa University, Bauchi, Nigeria
AD  - Real-Time Power and Intelligent Systems Laboratory, Department of Electrical and Computer Engineering, University of Missouri-Rolla, MO 65409, United States
AB  - In determining the correct operation of relays of a protection scheme, proper representation of instrument transformers and their behavior in conditions where there can be transient is very critical. This paper presents a simulation model for assessing the transient performance of Capacitive Voltage Transformers (CVTs). In order to test the validity of the developed model, four CVT operational conditions are considered using field data collected from one of the Nigerian electric utility 330/132/33kV substations. The model simulation results revealed various configuration performance responses that could affect relay protection schemes to different degrees. As expected, the CVT responses showed that faults initiated at zero voltage crossing, which is the worst transient condition, produced transient voltage magnitude up to 40% of the nominal voltage while faults initiated at the crest produced minimum transient voltage magnitude. It is shown that the model developed for the selected instrument transformer yielded satisfactory results. ©2006 IEEE.
KW  - Capacitive voltage transformers
KW  - MATLAB
KW  - Modeling
KW  - Simulation
KW  - Transient
KW  - Computer simulation
KW  - Mathematical models
KW  - Transient analysis
KW  - Voltage control
KW  - Capacitive voltage transformers
KW  - Simulation model
KW  - Electric transformers
PB  - IEEE Computer Society
SN  - 1424404932 (ISBN); 978-142440493-3 (ISBN)
LA  - English
J2  - IEEE Power Eng. Soc. Gen. Meet.
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 9; Correspondence Address: I. Sule; Electrical and Electronics Engineering Department, Federal Polytechnic, Mubi, Nigeria; email: sulekamiha@yahoo.com; Conference name: 2006 IEEE Power Engineering Society General Meeting, PES; Conference date: 18 June 2006 through 22 June 2006; Conference code: 70425
ER  -

TY  - JOUR
AU  - Ning, L.
AU  - Wu, W.
AU  - Zhang, B.
AU  - Zhang, P.
TI  - A time-varying transformer outage model for on-line operational risk assessment
PY  - 2011
T2  - International Journal of Electrical Power and Energy Systems
VL  - 33
IS  - 3
SP  - 600
EP  - 607
DO  - 10.1016/j.ijepes.2010.12.016
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-79952002257&doi=10.1016%2fj.ijepes.2010.12.016&partnerID=40&md5=4e2e78314fda5b037a5bdd3b4224c248
AD  - State Key Lab of Power Systems, Dept. of Electrical Engineering, Tsinghua University, Beijing, China
AD  - Electric Power Research Institute (EPRI), Palo Alto, CA, United States
AB  - The failure probabilities of system components may vary with changes in the operating conditions. Performing a probabilistic risk assessment in real-time is challenging, since component failure probabilities are difficult to predict. Accordingly, this paper introduces a delayed semi-Markov process that incorporates real-time data from advanced sensors, as a means of efficiently calculating time-varying or condition-based failure probabilities. To demonstrate the feasibility of the procedure, a time-varying transformer outage model with numerical examples is presented. In the proposed technique, an analytic random model is developed to accommodate the impact of real-time dissolved gas analysis data, as well as other conditions pertaining to the failure probabilities of system components. © 2010 Elsevier Ltd. All rights reserved.
KW  - Delayed semi-Markov process
KW  - Failure rate
KW  - Operational risk assessment
KW  - Time-varying outage model
KW  - Markov processes
KW  - Probability
KW  - Quality assurance
KW  - Rating
KW  - Time varying systems
KW  - Calculating time
KW  - Component failures
KW  - Dissolved gas analysis
KW  - Failure Probability
KW  - Failure rate
KW  - Numerical example
KW  - Operating condition
KW  - Operational risk assessment
KW  - Operational risks
KW  - Outage models
KW  - Probabilistic Risk Assessment
KW  - Random Model
KW  - Real-time data
KW  - Semi markov process
KW  - System components
KW  - Time varying
KW  - Time-varying outage model
KW  - Risk assessment
SN  - 01420615 (ISSN)
LA  - English
J2  - Int J Electr Power Energy Syst
M3  - Article
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 23; Correspondence Address: W. Wu; State Key Lab of Power Systems, Dept. of Electrical Engineering, Tsinghua University, Beijing, China; email: wuwench@mail.tsinghua.edu.cn; CODEN: IEPSD
ER  -

TY  - CONF
AU  - Finne, Sigbjorn
AU  - Burn, Geoffrey
TI  - Assessing the evaluation transformer model of reduction on the spineless G-machine
PY  - 1993
SP  - 331
EP  - 340
DO  - 10.1145/165180.165229
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-0027797469&doi=10.1145%2f165180.165229&partnerID=40&md5=e4b5e421c42623f48d50ae2b5ccaae7e
AD  - Imperial Coll of Science, Technology and Medicine, London, United Kingdom
AB  - This paper reports on our initial work on assessing how using the evaluation transformer model of reduction affects the performance of lazy functional programs. The model uses information about how much evaluation of an expression is required in order to evaluate an expression as much as possible, as early as possible. Our results show that there is a definite gain over just using strictness information, but that it is difficult to characterize exactly how much gain there will be, and in what programs it will occur.
KW  - Computer programming languages
KW  - Data reduction
KW  - Function evaluation
KW  - Mathematical models
KW  - Optimization
KW  - Storage allocation (computer)
KW  - Evaluation transformer model of reduction
KW  - Lazy functional languages
KW  - Lazy functional programs
KW  - Spineless G machine
KW  - Computer software
PB  - Publ by ACM
SN  - 089791595X (ISBN); 978-089791595-3 (ISBN)
LA  - English
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 6; Conference name: Proceedings of the 6th International Conference on Functional Programming Languages and Computer Architecture (FPCA '93); Conference date: 9 June 1993 through 11 June 1993; Conference code: 19830
ER  -

TY  - JOUR
AU  - Hamoud, G.A.
TI  - Use of markov models in assessing spare transformer requirements for distribution stations
PY  - 2012
T2  - IEEE Transactions on Power Systems
VL  - 27
IS  - 2
C7  - 6134698
SP  - 1098
EP  - 1105
DO  - 10.1109/TPWRS.2011.2177999
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-84860260253&doi=10.1109%2fTPWRS.2011.2177999&partnerID=40&md5=67332a7ab51ee261c5e7742b33ea3a4e
AD  - Hydro One Inc., Toronto, ON M5G 2P5, Canada
AB  - This paper describes a probabilistic method based on Markov models for assessing the number of spare transformers, regular units and mobile units, required for a group of distribution transformers. The proposed method uses two criteria in determining the required number of spare transformers. The first criterion assumes that a pre-determined level of the group availability is given and the number of spare units is determined when the calculated group availability exceeds the pre-determined level of the group availability. The second criterion uses a cost/benefit analysis method in calculating the number of the spare units. In the second criterion, the number of spare units (optimal number) is determined when the total cost (spare unit capital costs and unit outage costs) is minimum. The proposed method is also used to evaluate the impacts of multi-transformer stations (stations with transformer redundancy) and station capabilities for use of mobile unit transformers on the number of spare units. Two distribution transformer groups of the Hydro One's distribution system are used to illustrate the proposed method of assessment and to compare the results obtained using the two criteria. © 2012 IEEE.
KW  - Cost/benefit analysis
KW  - distribution stations
KW  - Markov models
KW  - mobile unit transformer
KW  - regular spare transformer
KW  - system availability
KW  - transformer outages
KW  - unit failure rate
KW  - Costs
KW  - Electric transformers
KW  - Distribution stations
KW  - Failure rate
KW  - Markov model
KW  - Mobile units
KW  - Spare transformer
KW  - System availability
KW  - Markov processes
SN  - 08858950 (ISSN)
LA  - English
J2  - IEEE Trans Power Syst
M3  - Article
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 30; Correspondence Address: G.A. Hamoud; Hydro One Inc., Toronto, ON M5G 2P5, Canada; email: gomaa.hamoud@HydroOne.com; CODEN: ITPSE
ER  -

TY  - CONF
AU  - Jessee, J.Patrick
AU  - Nelson, Douglas J.
TI  - A coupled thermal-magnetic model for high frequency transformers--II: Finite element implementation and validation
PY  - 1992
SP  - 32
EP  - 39
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-0027085312&partnerID=40&md5=896cb288a6faf8c808e463b7bbd7fa40
AB  - For Part One see ibid., pp. 23-31 (1992). boundary conditions, and material property relationships for a high-frequency transformer model were derived. In the present work, a solution method for this model based on the finite-element technique is developed and validated with both numerical comparisons and experimental data. The finite-element formulation allowed for ease in modeling geometry, material properties, constraints, and boundary conditions. A direct substitution iteration scheme was used with the finite-element method to compensate for the material nonlinearity in the electromagnetics problem. To verify the magnetics portion of the finite-element code numerically, a linear, uncoupled test case is given which compares the magnetic results from the present code to those from a commercial software package. To investigate the accuracy of the fully coupled and nonlinear model, an example is presented which compares the results from the numerical analysis of an inductor to those obtained by experimental measurement. Both comparisons showed reasonably good agreement.
KW  - Computer aided analysis
KW  - Electromagnetic field effects
KW  - Finite element method
KW  - Mathematical models
KW  - Temperature distribution
KW  - Thermoanalysis
KW  - Finite element analysis
KW  - High frequency transformer model
KW  - Thermal modeling
KW  - Thermomagnetic model
KW  - High frequency transformers
PB  - Publ by IEEE
SN  - 0780305035 (ISBN)
LA  - English
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 0; Conference name: Intersociety Conference on Thermal Phenomena in Electronic Systems - I-THERM '92; Conference date: 5 February 1992 through 8 February 1992; Conference code: 17469
ER  -

TY  - JOUR
AU  - Savaghebi, M.
AU  - Gholami, A.
AU  - Vahedi, A.
AU  - Hooshyar, H.
TI  - A new approach for transformer loading capability assessment based on fuzzy thermal model
PY  - 2010
T2  - International Review of Electrical Engineering
VL  - 5
IS  - 3
SP  - 927
EP  - 935
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-79956215005&partnerID=40&md5=6e0fef4ec2fcf2a8675337b0b0bdc89e
AD  - Center of Excellence for Power System Automation and Operation, Electrical Engineering Department, Iran University of Science and Technology, Iran
AB  - Thermal stresses are the main factor of deterioration of transformer insulation. These stresses, which are originated from heavy loading, are more severe in the hot spot of transformer winding. So, the transformer loading capability is mainly restricted by the hot spot temperature. In this paper, a new method is proposed for transformer dynamic loading capability assessment using fuzzy modeling. Firstly, the hot spot temperature is estimated by fuzzy thermal model and then is compared with the temperatures obtained by measurement and IEEE thermal model. Afterwards, the method of dynamic loadability assessment is described and implemented by the fuzzy model. Comparison between the results obtained by the fuzzy thermal model and the IEEE model demonstrates the usefulness of the fuzzy model application. Also, this fact is emphasized by an economic analysis. © 2010 Praise Worthy Prize S.r.l.
KW  - Fuzzy thermal model
KW  - IEEE thermal model
KW  - Insulation loss of life
KW  - Transformer loading capability
PB  - Praise Worthy Prize S.r.l
SN  - 18276660 (ISSN)
LA  - English
J2  - Int. Rev. Elec. Eng.
M3  - Article
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 4
ER  -

TY  - JOUR
AU  - Jauregui-Rivera, L.
AU  - Mao, X.
AU  - Tylavsky, D.J.
TI  - Improving reliability assessment of transformer thermal top-oil model parameters estimated from measured data
PY  - 2009
T2  - IEEE Transactions on Power Delivery
VL  - 24
IS  - 1
SP  - 169
EP  - 176
DO  - 10.1109/TPWRD.2008.2005686
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-58249130248&doi=10.1109%2fTPWRD.2008.2005686&partnerID=40&md5=28e2937f883d4c03fc378108c4a399a4
AD  - Arizona Public Service, Phoenix, AZ 85004, United States
AD  - Arizona State University, Tempe, AZ 85287-5706, United States
AB  - This paper presents a methodology for assessing the reliability of thermal-model parameters for transformers estimated from measured data. The methodology uses statistical bootstrapping to calculate confidence levels (CL) and confidence intervals (CI). Bootstrapping allows us to make a small dataset look statistically larger, which allows a precise estimate of the transformer thermal model's reliability. The proposed methodology is tested on a 167-MVA oil-forced air-forced transformer. The CIs are evaluated with and without bootstrapping and the reliability indices are compared. The results show that the CI and CL values with bootstrapping are more consistently reproducible than the ones derived without bootstrapping. © 2008 IEEE.
KW  - Bootstrapping
KW  - Confi-dence levels (CLs)
KW  - Confidence intervals (CIs)
KW  - Least squares regression
KW  - Parameter estimation
KW  - Top-oil temperature
KW  - Transformer thermal modeling
KW  - Curve fitting
KW  - Least squares approximations
KW  - Metal analysis
KW  - Parameter estimation
KW  - Reliability
KW  - Thermoanalysis
KW  - Bootstrapping
KW  - Confi-dence levels (CLs)
KW  - Confidence intervals (CIs)
KW  - Least squares regression
KW  - Transformer thermal modeling
KW  - Oil filled transformers
SN  - 08858977 (ISSN)
LA  - English
J2  - IEEE Trans Power Delivery
M3  - Article
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 27; Correspondence Address: L. Jauregui-Rivera; Arizona Public Service, Phoenix, AZ 85004, United States; email: lida.Jauregui-Rivera@aps.com; CODEN: ITPDE
ER  -

TY  - CONF
AU  - Chen, S.
AU  - Misra, D.
AU  - Thoma, G.R.
TI  - Efficient automatic OCR word validation using word partial format derivation and language model
PY  - 2010
T2  - Proceedings of SPIE - The International Society for Optical Engineering
VL  - 7534
C7  - 75340O
DO  - 10.1117/12.838853
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-77949843125&doi=10.1117%2f12.838853&partnerID=40&md5=7c8c71cb32cc4b172b65bcbe691c9e9e
AD  - U.S. National Library of Medicine, Bethesda, MD 20894, United States
AB  - In this paper we present an OCR validation module, implemented for the System for Preservation of Electronic Resources (SPER) developed at the U.S. National Library of Medicine.1 The module detects and corrects suspicious words in the OCR output of scanned textual documents through a procedure of deriving partial formats for each suspicious word, retrieving candidate words by partial-match search from lexicons, and comparing the joint probabilities of N-gram and OCR edit transformation corresponding to the candidates. The partial format derivation, based on OCR error analysis, efficiently and accurately generates candidate words from lexicons represented by ternary search trees. In our test case comprising a historic medico-legal document collection, this OCR validation module yielded the correct words with 87% accuracy and reduced the overall OCR word errors by around 60%. © 2009 Copyright SPIE - The International Society for Optical Engineering.
KW  - Computational linguistics
KW  - Digital libraries
KW  - Error analysis
KW  - Electronic resources
KW  - Joint probability
KW  - Language model
KW  - Legal documents
KW  - National library of medicines
KW  - Search trees
KW  - Test case
KW  - Textual documents
KW  - Information retrieval
SN  - 0277786X (ISSN); 978-081947927-3 (ISBN)
LA  - English
J2  - Proc SPIE Int Soc Opt Eng
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 4; Conference name: Document Recognition and Retrieval XVII; Conference date: 19 January 2010 through 21 January 2010; Conference code: 79586; CODEN: PSISD
ER  -

TY  - JOUR
AU  - Ab Kadir, M.Z.A.
AU  - Mohamad Ariff, M.H.
AU  - Mesron, R.
AU  - Salahuddin, M.T.
TI  - Substation system simulation models for transformer risk assessment analysis
PY  - 2008
T2  - European Journal of Scientific Research
VL  - 23
IS  - 1
SP  - 141
EP  - 148
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-65449190201&partnerID=40&md5=13a0864669baa1a74766f8be874b0bfa
AD  - Department of Electrical and Electronics Engineering, Faculty of Engineering, Universiti Putra Malaysia, 43400 Serdang, Selangor, Malaysia
AD  - Engineering Department (Transmission and Substation), Tenaga Nasional Berhad, MPE Building, Petaling Jaya, Selangor, Malaysia
AB  - This paper comprises a study which is carried out to investigate and evaluate the effect of lightning stresses on the 132 kV substation in the way to improve its reliability in the event of active lightning activities. The paper also detailed the modelling parameters of substation for this transient analysis in order to evaluate the performance and to recommend such configuration to optimize its design to be not only to withstand the stresses but to be more cost effective. The modelling and simulation are carried out using one of the most powerful power system simulations tools that is PSCAD-EMTDC and the substation layout design is adapted from 132/11 kV Simpang Renggam - Ayer Hitam substation, courtesy of TNB. The model is based on single phase line model as it was suggested by the IEEE to be adequate to represent the substation in transient analysis simulation. The outcome of this paper would be the results of lightning stresses in term of voltage level measured at particular points in substation. The results are then compared with the suggested BIL for assessment of transformer failure. © EuroJournals Publishing, Inc. 2008.
KW  - Basic insulation lightning level
KW  - Insulation coordination
KW  - Lightning
KW  - PSCAD/EMTDC
PB  - EuroJournals, Inc.
SN  - 1450216X (ISSN)
LA  - English
J2  - Eur. J. Sci. Res.
M3  - Article
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 1; Correspondence Address: M. Z. A. Ab Kadir; Department of Electrical and Electronics Engineering, Faculty of Engineering, Universiti Putra Malaysia, 43400 Serdang, Selangor, Malaysia; email: mzainal@eng.upm.edu.my
ER  -

TY  - CONF
AU  - Miller, John W.
AU  - Alleva, Fil
TI  - Evaluation of language model using a clustered model backoff
PY  - 1996
T2  - International Conference on Spoken Language Processing, ICSLP, Proceedings
VL  - 1
SP  - 390
EP  - 393
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-0030364776&partnerID=40&md5=0dd55f765e8b5aa5ff61cd5c5dfef458
AD  - Microsoft Corp, Redmond, United States
AB  - In this paper, we describe and evaluate a language model using word classes automatically generated from a word clustering algorithm. Class based language models have been shown to be effective for rapid adaptation, training on small datasets, and reduced memory usage. In terms of model perplexity, prior work has shown diminished returns for class based language models constructed using very large training sets. This paper describes a method of using a class model as a backoff to a bigram model which produced significant benefits even when trained from a large text corpus. Tests results on the Whisper continuous speech recognition system show that for a given word error rate, the clustered bigram model uses 2/3 fewer parameters compared to a standard bigram model using unigram backoff.
KW  - Algorithms
KW  - Computational linguistics
KW  - Probability
KW  - Class based language models
KW  - Word clustering algorithm
KW  - Word error rate
KW  - Speech recognition
PB  - IEEE
LA  - English
J2  - Int Conf Spoken Lang Process ICSLP Proc
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 8; Conference name: Proceedings of the 1996 International Conference on Spoken Language Processing, ICSLP. Part 1 (of 4); Conference date: 3 October 1996 through 6 October 1996; Conference code: 46796; CODEN: 00264
ER  -

TY  - CONF
AU  - Noda, T.
AU  - Honda, H.
AU  - Asakawa, A.
AU  - Shindo, T.
AU  - Yokoyama, S.
TI  - A pole-mounted transformer model for the assessment of transferred lightning surges from a distribution line to a consumer entrance
PY  - 2006
T2  - 41st International Conference on Large High Voltage Electric Systems 2006, CIGRE 2006
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-84876760454&partnerID=40&md5=fc11189b9e8767a3526feb4b4fa05f31
AD  - Central Research Institute of Electric Power Industry, Japan
AD  - Tohoku Electric Power Company, Japan
AB  - In houses, buildings, and factories, we now have a number of devices which are vulnerable to overvoltages. Such devices include full electronic and partially-electronic appliances. These appliances are vulnerable not only to failures but also to incorrect operations due to overvoltages. Thus, the assessment of overvoltages at the consumer side has become more and more important. One of the sources of the consumer-side over voltages is transferred lightning surges from a distribution line via a pole-mounted distribution transformer as illustrated in Fig. 1. The assessment of such overvoltages requires an accurate model of pole-mounted transformers which can be used in an EMTP-type simulation environment. A transformer model plays an important role to reproduce the interactions among the high-voltage distribution line, low-voltage one, and a grounding wire. The authors have been carrying out studies on modelling of pole-mounted transformers [1]-[4], and this paper presents the final form of the model. The framework of the proposed model is a low-frequency equivalent of a transformer consisting of an ideal transformer, winding resistance, leakage inductance, and a magnetizing branch. It is often referred to as the fundamental equivalent circuit of a transformer. High frequency effects, which are necessary to reproduce the surge response of a transformer, are taken into account by adding corresponding circuit blocks. The high frequency effects considered are winding-to-winding and winding-to enclosure capacitances, frequency dependent impedance of the primary winding, and multiple resonances due to winding inductance and turn-to-turn capacitance. It should be noted that the added circuit blocks show very high impedance at low frequencies and the proposed model matches the fundamental equivalent circuit of a transformer at a power frequency (50/60 Hz). Thus, the proposed model reproduces the response of a transformer in a wide range of frequency. In [3], the authors have found that if the secondary winding consists of a small number of parallel layers then the impedance of the secondary winding shows significant frequency dependence. In that case, the frequency-dependent impedance of the secondary winding is also represented. For the validation of the proposed transformer model, a laboratory test and a field test using an actual-scale distribution line have been carried out. The measured results are compared with corresponding calculated results using the proposed model, and good agreement between the measured and calculated results confirms good accuracy of the proposed model.
KW  - Distribution line
KW  - Lightning overvoltage
KW  - Pole mounted transformer
KW  - Transferred surge
KW  - Capacitance
KW  - DC generators
KW  - Electric grounding
KW  - Electric network analysis
KW  - Electric resistance
KW  - Electric surges
KW  - Electric transformers
KW  - Electric windings
KW  - Grounding electrodes
KW  - Inductance
KW  - Poles
KW  - Winding
KW  - Distribution lines
KW  - Distribution transformer
KW  - Frequency dependent impedance
KW  - High-frequency effects
KW  - Lightning over-voltage
KW  - Magnetizing branches
KW  - Simulation environment
KW  - Transferred surge
KW  - Electric transformer testing
LA  - English
J2  - Int. Conf. Large High Voltage Electr. Syst., CIGRE
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 1; Correspondence Address: T. Noda; Central Research Institute of Electric Power Industry, Japan; email: akunoda@ieee.org; Conference name: 41st International Conference on Large High Voltage Electric Systems 2006, CIGRE 2006; Conference date: 27 August 2006 through 1 September 2006; Conference code: 96752
ER  -

TY  - JOUR
AU  - Ryszard, M.
AU  - Franchek, M.A.
AU  - McWhirter, J.H.
TI  - Experimental Validation of a Computer Model Simulating an Impulse Voltage Distribution in HV Transformer Windings.
PY  - 1994
T2  - IEEE Transactions on Power Delivery
VL  - 9
IS  - 4
SP  - 1789
EP  - 1798
DO  - 10.1109/61.329512
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-0028526844&doi=10.1109%2f61.329512&partnerID=40&md5=464eedde4cf0571d3a049d63b744d511
AD  - Malewski Electric, Montreal, Quebec, Canada
AD  - EHV_Weidmann, St. Johnsbury, Vermont, United States
AD  - Optimization, Ltd., Murrysville, Pennsylvania, United States
AB  - A number of computer models have been recently proposed for simulation of the impulse voltage distribution in the winding of power. transformers. Some of these models can predict the winding behavior at high frequencies, some other were developed as a practical tool for designers of lower voltage transformers. The time and expenditure put in development of these models shall be balanced by a similar effort to check the model validity. Such check consists in comparison of the predicted voltages to the actually measured ones. With the advent of high resolution, fast digital recorders and signal processing techniques, this validation can be performed to a much higher accuracy and completeness than the conventional comparison of analog oscillograms to simulated graphs. The paper presents such validation technique applied to a computer model of transformer winding. © 1994 IEEE
KW  - Computer simulation
KW  - Data processing
KW  - Digital storage
KW  - Electric impedance measurement
KW  - Frequency response
KW  - Graphic methods
KW  - Time domain analysis
KW  - Transformer windings
KW  - Voltage measurement
KW  - Impulse voltage distribution
KW  - Computer aided network analysis
SN  - 08858977 (ISSN)
LA  - English
J2  - IEEE Trans Power Delivery
M3  - Article
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 15
ER  -

TY  - JOUR
AU  - De Graaf, L.
AU  - Leufkens, B.
TI  - Bert Leufkens - The new chairman of the Dutch Board for Drug Assessment: "Balance between effect and safety"
ST  - Bert Leufkens nieuwe voorzitter CBG: Balanceren tussen wer king en veiligheid
PY  - 2007
T2  - Pharmaceutisch Weekblad
VL  - 142
IS  - 43
SP  - 24
EP  - 27
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-35948965281&partnerID=40&md5=407b090eeccbb88305e11c466e2823f8
KW  - drug effect
KW  - drug safety
KW  - food and drug administration
KW  - medical care
KW  - Netherlands
KW  - note
KW  - professional practice
SN  - 00316911 (ISSN)
LA  - Dutch
J2  - Pharm. Weekbl.
M3  - Note
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 0; CODEN: PHWEA
ER  -

TY  - CONF
AU  - Schwarm, S.E.
AU  - Ostendorf, M.
TI  - Reading level assessment using support vector machines and statistical language models
PY  - 2005
T2  - ACL-05 - 43rd Annual Meeting of the Association for Computational Linguistics, Proceedings of the Conference
SP  - 523
EP  - 530
DO  - 10.3115/1219840.1219905
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-77955117737&doi=10.3115%2f1219840.1219905&partnerID=40&md5=0373191f0e2f97c0c6bd86cef8f9df61
AD  - Dept. of Computer Science and Engineering, University of Washington, Seattle, WA 98195-2350, United States
AD  - Dept. of Electrical Engineering, University of Washington, Seattle, WA 98195-2500, United States
AB  - Reading proficiency is a fundamental component of language competency. However, finding topical texts at an appropriate reading level for foreign and second language learners is a challenge for teachers. This task can be addressed with natural language processing technology to assess reading level. Existing measures of reading level are not well suited to this task, but previous work and our own pilot experiments have shown the benefit of using statistical language models. In this paper, we also use support vector machines to combine features from traditional reading level measures, statistical language models, and other language processing tools to produce a better method of assessing reading level. © 2005 Association for Computational Linguistics.
KW  - Computational linguistics
KW  - Support vector machines
KW  - Fundamental component
KW  - Language processing
KW  - NAtural language processing
KW  - Pilot experiment
KW  - Reading level
KW  - Reading proficiency
KW  - Second language learners
KW  - Statistical language models
KW  - Natural language processing systems
PB  - Association for Computational Linguistics (ACL)
SN  - 1932432515 (ISBN); 978-193243251-0 (ISBN)
LA  - English
J2  - ACL - Annu. Meet. Assoc. Comput. Linguist., Proc. Conf.
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 224; Correspondence Address: S.E. Schwarm; Dept. of Computer Science and Engineering, University of Washington, Seattle, WA 98195-2350, United States; email: sarahs@cs.washington.edu; Conference name: 43rd Annual Meeting of the Association for Computational Linguistics, ACL-05; Conference date: 25 June 2005 through 30 June 2005; Conference code: 89385
ER  -

TY  - CONF
AU  - Mamizadeh, A.
AU  - Iskender, I.
TI  - Evaluation and comparing the loss of life for outdoor and MV/LV prefabricated oil immersed power transformer based on nonlinear thermal models
PY  - 2011
T2  - ELECO 2011 - 7th International Conference on Electrical and Electronics Engineering
C7  - 6140218
SP  - I183
EP  - I187
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-84857317562&partnerID=40&md5=5928aabff3aba937dd6aa2e7cd8c5334
AD  - Electrical and Electronic Engineering Department, Engineering Faculty, Gazi University, Ankara, Turkey
AB  - Power transformers are the most critical and expensive equipment in the field of transmission and distribution of electric energy. Any major fault in these units can cause not only catastrophic damage to various equipments but also cause interruption of electricity supply. These direct or indirect effects often lead to large economic losses. The most important parameter in transformers life expectancy is the insulation hot-spot temperature value which accelerates the rate of aging of the insulation. This Study proposes a life expectancy model for oil immersed power transformer using the hot-spot temperature based on transformer nonlinear hot-spot and top-oil temperature rise models. Since the thermal transfer is different for indoor and outdoor transformers considering their operating conditions, their thermal and loss of life models are different and are analyzed and compared in this study. © 2011 Chamber of Turkish Electric.
KW  - indoor
KW  - loss of life
KW  - oil immersed transformers
KW  - outdoor
KW  - thermal aging
KW  - Electronics engineering
KW  - Losses
KW  - Oil filled transformers
KW  - Power transformers
KW  - Thermal aging
KW  - Catastrophic damage
KW  - Economic loss
KW  - Electric energies
KW  - Electricity supply
KW  - Hot spot
KW  - Hotspot temperature
KW  - Indirect effects
KW  - indoor
KW  - Life expectancies
KW  - Loss of life
KW  - Oil immersed power transformer
KW  - Oil immersed transformers
KW  - Operating condition
KW  - outdoor
KW  - Thermal model
KW  - Thermal transfer
KW  - Top oil temperature
KW  - Transmission and distribution
KW  - Electric losses
SN  - 978-605010204-8 (ISBN)
LA  - English
J2  - ELECO - Int. Conf. Electr. Electron. Eng.
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 0; Correspondence Address: A. Mamizadeh; Electrical and Electronic Engineering Department, Engineering Faculty, Gazi University, Ankara, Turkey; email: mamizadeh@gazi.edu.tr; Conference name: 7th International Conference on Electrical and Electronics Engineering, ELECO 2011; Conference date: 1 December 2011 through 4 December 2011; Conference code: 88625
ER  -

TY  - JOUR
AU  - Sui, H.
AU  - Ohta, R.
AU  - Shiragiku, T.
AU  - Akahori, A.
AU  - Suzuki, K.
AU  - Nakajima, M.
AU  - Hayashi, H.
AU  - Masumura, K.
AU  - Nohmi, T.
TI  - Evaluation of in vivo mutagenicity by 2,4-diaminotoluene and 2,6-diaminotoluene in liver of F344 gpt delta transgenic rat dosed for 28 days: A collaborative study of the gpt delta transgenic rat mutation assay
PY  - 2012
T2  - Genes and Environment
VL  - 34
IS  - 1
SP  - 25
EP  - 33
DO  - 10.3123/jemsge.34.25
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-84860651298&doi=10.3123%2fjemsge.34.25&partnerID=40&md5=9a55368b0a654de1d085751db9e22eca
AD  - Division of Genetic Toxicology, Hatano Research Institute, Food and Drug Safety Center, Hadano, Kanagawa 257-8523, 729-5 Ochiai, Japan
AD  - Tokushima Research Institute, Otsuka Pharmaceutical Co., Ltd., Tokushima, Japan
AD  - Biosafety Research Center, Foods, Drugs and Pesticides, Shizuoka, Japan
AD  - Pharmaceutical Research Center, Meiji Seika Kaisha, Ltd., Kanagawa, Japan
AD  - Division of Genetics and Mutagenesis, National Institute of Health Sciences, Tokyo, Japan
AB  - The transgenic rodent (TGR) assay has been widely used to study in vivo gene mutations by chemicals or radiation; however, an optimal protocol has not yet been established to assess unknown genotoxic potential. The International Workshop on Genotoxicity Testing (IWGT) strongly recommends a repeated-dose regimen for the TGR assay protocol for regulatory safety assessment as follows: a treatment period of 28 days and a sampling time of 3 days following the final treatment. In this study, TGR assays using F344gpt delta transgenic rats were conducted at three laboratories to evaluate the validity of the IWGT protocol, as part of a collaborative study of the transgenic rat mutation assay. Male F344gpt delta transgenic rats were orally treated with 2,4-diaminotoluene (2,4-DAT; hepatic carcinogen in rodents; 10 and 30 mg/kg/day) or 2,6-diaminotoluene (2,6-DAT; non-carcinogen in rodents; 60 mg/kg/day) once daily for 28 days. Rats were euthanized 3 days after the last dosing, and then mutant frequencies (MFs) of the gpt gene in the livers were studied. As a result, a significant increase in the MF was observed at 30 mg/kg in the 2,4-DAT-treated group, but not in the 2,6-DAT-treated group. These results were commonly observed among the three laboratories. In addition, the overall results from the three laboratories were in general agreement. These results indicate that 2,4-DAT induces gene mutation in the liver of gpt delta rats, but 2,6-DAT does not. These results also indicate that the F344gpt delta transgenic rat mutation assay can distinguish diŠerences in thein vivo mutagenic potential between a hepatic carcinogen and a non-carcinogen. Results from one laboratory showed more variability than those from the other two laboratories, and this appearance was due to the smaller number of colonies scored. Thus, these results demonstrate that the IWGT protocol for the TGR assays is valid, and show that consistent results are obtained among diŠerent laboratories. © The Japanese Environmental Mutagen Society.
KW  - 28 consecutive daily treatment
KW  - Diaminotoluenes
KW  - F344 gpt delta transgenic rat
KW  - Gpt assay
KW  - Rattus
KW  - Rodentia
KW  - 2,4 diaminotoluene
KW  - 2,6 diaminotoluene
KW  - animal experiment
KW  - animal model
KW  - animal tissue
KW  - article
KW  - clinical evaluation
KW  - clinical protocol
KW  - controlled study
KW  - Fischer 344 rat
KW  - gene mutation
KW  - genotoxicity
KW  - in vivo study
KW  - liver
KW  - male
KW  - mutagenicity
KW  - mutation rate
KW  - mutational analysis
KW  - nonhuman
KW  - rat
KW  - transgenic rat
KW  - validity
SN  - 18807062 (ISSN)
LA  - English
J2  - Genes Environ.
M3  - Article
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 6; Correspondence Address: H. Sui; Division of Genetic Toxicology, Hatano Research Institute, Food and Drug Safety Center, Hadano, Kanagawa 257-8523, 729-5 Ochiai, Japan; email: sui.h@fdsc.or.jp
ER  -

TY  - CONF
AU  - Takagi, K.
AU  - Oguro, R.
AU  - Hashimoto, K.
AU  - Ozeki, K.
TI  - PERFORMANCE EVALUATION OF WORD PHRASE AND NOUN CATEGORY LANGUAGE MODELS FOR BROADCAST NEWS SPEECH RECOGNITION
PY  - 1998
T2  - 5th International Conference on Spoken Language Processing, ICSLP 1998
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-0005374920&partnerID=40&md5=20c80eb13c4d62892b3903a7a989b2d6
AD  - The University of Electro-Communications, Tokyo, 182-8585, Japan
AB  - This paper reports our work to improve a bigram language model for Japanese TV broadcast news speech recognition. First, frequent word strings were grouped into phrases in order that the phrases were added to the lexicon as new units of recognition. The test set perplexity was improved when frequent function word strings were used as additional recognition units. The speech recognition performance was improved both by grouping function word strings and by grouping compound nouns that were selected by word association ratio. Secondly, in order to alleviate the 0 0 V problem related with nouns, we built and tested a language model that allows switching its noun lexicon according to the domain of the article to be recognized next. © 1998. 5th International Conference on Spoken Language Processing, ICSLP 1998. All rights reserved.
KW  - Computational linguistics
KW  - Bi-gram language models
KW  - Broadcast news
KW  - Function words
KW  - IMPROVE-A
KW  - Language model
KW  - Performances evaluation
KW  - Recognition units
KW  - Speech recognition performance
KW  - Test set perplexity
KW  - TV broadcast news
KW  - Speech recognition
PB  - International Speech Communication Association
LA  - English
J2  - Int. Conf. Spok. Lang. Process., ICSLP
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 1; Conference name: 5th International Conference on Spoken Language Processing, ICSLP 1998; Conference date: 30 November 1998 through 4 December 1998; Conference code: 178354
ER  -

TY  - CONF
AU  - Naptali, W.
AU  - Tsuchiya, M.
AU  - Nakagawa, S.
TI  - Topic dependent class based language model evaluation on automatic speech recognition
PY  - 2010
T2  - 2010 IEEE Workshop on Spoken Language Technology, SLT 2010 - Proceedings
C7  - 5700885
SP  - 395
EP  - 400
DO  - 10.1109/SLT.2010.5700885
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-79951807576&doi=10.1109%2fSLT.2010.5700885&partnerID=40&md5=2be5f4db699157587d854ed43f0be32a
AD  - Department of Computer Science and Engineering, Toyohashi University of Technology, Japan
AD  - Information and Media Center, Toyohashi University of Technology, Japan
AB  - A topic dependent class (TDC) language model (LM) is a topic-based LM that uses a semantic extraction method to reveal latent topic information from noun-document relation. Then a clustering for a given context is performed to define topics. Finally, a fixed window of word history is observed to decide the topic of the current event through voting in online manner. Previously, we have shown that TDC overperforms several state-of-the-art baselines in terms of perplexity. In this paper we evaluate TDC on automatic speech recognition experiment (ASR) for rescoring task. Experiments on read speech Wall Street Journal (English ASR system) and Mainichi Shimbun (Japanese ASR system) show that TDC LM improves both perplexity and word-error-rate (WER). The result shows that the proposed model gives improvements 3.0% relative on perplexity and 15.2% relative on WER for English ASR system, and 16.4% relative on perplexity and 24.3% relative on WER for Japanese ASR system. ©2010 IEEE.
KW  - Language model
KW  - Speech recognition
KW  - Topic dependent
KW  - Computational linguistics
KW  - Lagrange multipliers
KW  - Semantics
KW  - Automatic speech recognition
KW  - Class-based language model
KW  - Document relations
KW  - Language model
KW  - Semantic extraction
KW  - Topic dependent
KW  - Wall Street Journal
KW  - Speech recognition
SN  - 978-142447903-0 (ISBN)
LA  - English
J2  - IEEE Workshop Spoken Lang. Technol., SLT - Proc.
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 3; Correspondence Address: W. Naptali; Department of Computer Science and Engineering, Toyohashi University of Technology, Japan; email: naptali@slp.cs.tut.ac.jp; Conference name: 2010 IEEE Workshop on Spoken Language Technology, SLT 2010; Conference date: 12 December 2010 through 15 December 2010; Conference code: 83877
ER  -

TY  - JOUR
AU  - Takagi, M.
AU  - Yamamoto, H.
AU  - Yamaji, K.
TI  - An evaluation of amorphous transformers using the load curve pattern model for a pole transformer
PY  - 2009
T2  - Electrical Engineering in Japan (English translation of Denki Gakkai Ronbunshi)
VL  - 169
IS  - 3
SP  - 1
EP  - 9
DO  - 10.1002/eej.20924
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-68349141083&doi=10.1002%2feej.20924&partnerID=40&md5=12e4d9d443ec18d97f5ff7994a92a4a5
AD  - University of Tokyo, Japan
AB  - Energy loss in transformers is composed of no-load loss and load loss. The no-load loss of amorphous transformers, which have amorphous metal core, could be reduced by about 70% compared with traditional silicon steel transformers. If the electrical utilities adopted amorphous transformers as pole transformers, major energy savings and CO2 emissions reduction could be achieved. However, amorphous transformers have the disadvantages of high capital cost and high load loss parameters compared with traditional transformers. The economic efficiency of transformers is evaluated by the Total Ownership Cost (TOC). The TOC encompasses both the capital cost and the energy loss cost, which is calculated from the load curve. Therefore, we propose a load curve pattern model for pole transformers to evaluate the energy-saving effect and the economic efficiency of amorphous transformers. Simulation results show that the no-load loss accounts for a large share of the total loss; hence, reduction of the no-load loss is more effective than reduction of load loss in achieving energy saving. As a result, amorphous pole transformers are the most suitable for pole transformers. © 2009 Wiley Periodicals, Inc.
KW  - Amorphous transformer
KW  - Energy saving
KW  - Load curve pattern
KW  - No-load loss
KW  - Pole transformer
KW  - Costs
KW  - Electric load loss
KW  - Electron energy loss spectroscopy
KW  - Emission control
KW  - Energy conservation
KW  - Energy dissipation
KW  - Poles
KW  - Silicon steel
KW  - Amorphous transformer
KW  - Energy saving
KW  - Load curve pattern
KW  - No-load loss
KW  - Pole transformer
KW  - Amorphous silicon
SN  - 15206416 (ISSN)
LA  - English
J2  - Electr Eng Jpn
M3  - Article
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 2; CODEN: EENJA
ER  -

TY  - CONF
AU  - Su, J.
AU  - Liu, Q.
AU  - Dong, H.
AU  - Chen, Y.
AU  - Shi, X.
TI  - An approach to n-gram language model evaluation in phrase-based statistical machine translation
PY  - 2012
T2  - Proceedings - 2012 International Conference on Asian Language Processing, IALP 2012
C7  - 6473731
SP  - 201
EP  - 204
DO  - 10.1109/IALP.2012.70
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-84900861107&doi=10.1109%2fIALP.2012.70&partnerID=40&md5=98c5cd18e7d1e67b745b3500ac90a458
AD  - Xiamen University, Fujian, China
AD  - Institute of Computing Technology, Chinese Academy of Sciences, Beijing, China
AB  - N-gram Language model plays an important role in statistical machine translation. Traditional methods adopt perplexity to evaluate language models, while this metric does not consider the characteristics of statistical machine translation. In this paper, we propose a novel method, namely bag-of-words decoding, to evaluate n-gram language models in phrase-based statistical machine translation. As compared with perplexity, our approach has more remarkable correlation with translation quality measured by BLEU. Experimental results on NIST data sets demonstrate the effectiveness of our method. © 2012 IEEE.
KW  - Language model evaluation
KW  - Statistical Machine Translation
KW  - Natural language processing systems
KW  - Bag of words
KW  - Language model
KW  - N-gram language models
KW  - Phrase-based statistical machine translation
KW  - Statistical machine translation
KW  - Translation quality
KW  - Computational linguistics
PB  - IEEE Computer Society
LA  - English
J2  - Proc. - Int. Conf. Asian Lang. Process., IALP
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 1; Conference name: 2012 International Conference on Asian Language Processing, IALP 2012; Conference date: 13 November 2012 through 15 November 2012; Conference code: 105167
ER  -

TY  - CONF
AU  - Ohta, K.
AU  - Tsuchiya, M.
AU  - Nakagawa, S.
TI  - Evaluating spoken language model based on filler prediction model in speech recognition
PY  - 2008
T2  - Proceedings of the Annual Conference of the International Speech Communication Association, INTERSPEECH
SP  - 1558
EP  - 1561
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-84867204618&partnerID=40&md5=18a38409df0c988bad185523124d70bd
AD  - Department of Information and Computer Sciences, Toyohashi University of Technology, Japan
AD  - Information and Media Center, Toyohashi University of Technology, Japan
AB  - We propose a method that uses a filler prediction model for building a language model that includes fillers from a corpus without fillers. In our method, a filler prediction model is trained from a corpus that does not cover domain-relevant topics. It recovers fillers in inexact transcribed corpora in the target domain, and then a language model that includes fillers is built from the corpora. The results of an evaluation of the Japanese National Diet Record showed that a model using our method achieves higher recognition performance than conventional ones. Copyright © 2008 ISCA.
KW  - Filler
KW  - Japanese national diet record
KW  - Language model
KW  - Speech recognition
KW  - Spoken language
KW  - Computational linguistics
KW  - Fillers
KW  - Forecasting
KW  - Mathematical models
KW  - Nutrition
KW  - Software agents
KW  - Speech communication
KW  - Japanese national diet record
KW  - Language model
KW  - Prediction model
KW  - Recognition performance
KW  - Spoken languages
KW  - Target domain
KW  - Speech recognition
SN  - 19909772 (ISSN)
LA  - English
J2  - Proc. Annu. Conf. Int. Speech. Commun. Assoc., INTERSPEECH
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 7; Correspondence Address: K. Ohta; Department of Information and Computer Sciences, Toyohashi University of Technology, Japan; email: kohta@slp.ics.tut.ac.jp; Conference name: INTERSPEECH 2008 - 9th Annual Conference of the International Speech Communication Association; Conference date: 22 September 2008 through 26 September 2008; Conference code: 78746
ER  -

TY  - JOUR
AU  - Schon, M.R.
AU  - Akkoc, N.
AU  - Heil, W.
AU  - Wolf, St.
AU  - Matthes, M.
AU  - Schrem, H.
AU  - Kollmar, O.
AU  - Neuhaus, P.
TI  - Determination of α-glutathione-S-transferase concentration for assessment of hepatocellular ischemic damage compared to GOT, GPT and LDH in a liver transplantation model
ST  - Die Bestimmung der α-Glutathion-S-Transferase-Konzentration zur Beurteilung hepatozellularer Ischamieschaden im Vergleich zu GOT, GPT und LDH im Lebertransplantationsmodell
PY  - 1999
T2  - LaboratoriumsMedizin
VL  - 23
IS  - 4
SP  - 218
EP  - 226
DO  - 10.1515/labm.1999.23.4.218
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-0032955757&doi=10.1515%2flabm.1999.23.4.218&partnerID=40&md5=637ce138450bf2e96cc14d1aad0dc73e
AD  - Charite, Campus Virchow-Klinikum, Klin. Allgemein Viszeral Transplant., D-13353 Berlin, Augustenburger Platz 1, Germany
AB  - Cold and warm ischemia associated with organ preservation is well documented as a cause of hepatocellular damage. Previous studies examining the enzymes glutamate oxalacetate transaminase (GOT, ASAT), glutamate pyruvate transaminase (GPT, ALAT) and lactate dehydrogenase (LDH) have shown these markers to remain elevated for some days following transplantation. Therefore, this prevents early detection of any new post-transplantation hepatocellular damage. In comparison to GOT, GPT and LDH, α-glutathione-S-transferase (α-GST) has a significantly shorter plasma half-lifetime. The objective of this study was to evaluate the suitability of α-GST as an indicator of hepatocellular damage resulting from liver graft preservation and transplantation under standardized conditions and compare these results to GOT, GPT and LDH. Six allogenic, orthotopic porcine liver transplantations were performed in each of three groups. The donor livers in group 1 had a brief period of warm ischemia at 37°C for 36 ± 3 min. Group 2 donor livers were subjected to 103 ± 4 min of 37°C ischemia. Donor livers for the third group were preserved four hours under cold ischemic conditions in 0°C University of Wisconsin Solution. The α-GST concentration at 15 min after reperfusion was significantly elevated in all three groups (Group 1: 54 ± 10 μg/l; Group 2: 359 ± 60 μg/l; Group 3: 58 ± 18 μg/l). The α-GST concentration returned to normal (8.4 ± 1.0 μg/l) at postoperative day 1. In comparison, GOT, GPT and LDH required a longer time to reach baseline levels. Consequently, α-GST is particularly suited for assessing the momentary state of hepatocellular damage following liver transplantation.
KW  - Alanine transaminase, plasma
KW  - Aspartate transaminase, plasma
KW  - Biological-markers, plasma
KW  - Glutathione-transferase, plasma
KW  - Ischemia
KW  - Lactate dehydrogenase, plasma
KW  - Liver transplantation, pathology
KW  - Liver, blood supply
KW  - Liver, enzymology
KW  - Swine
KW  - Temperature
KW  - Animalia
KW  - Suidae
KW  - Sus scrofa
KW  - alanine aminotransferase
KW  - aspartate aminotransferase
KW  - glutathione transferase
KW  - lactate dehydrogenase
KW  - University of Wisconsin solution
KW  - alanine aminotransferase blood level
KW  - animal experiment
KW  - animal model
KW  - article
KW  - aspartate aminotransferase blood level
KW  - donor
KW  - enzyme blood level
KW  - lactate dehydrogenase blood level
KW  - liver blood flow
KW  - liver cell damage
KW  - liver failure
KW  - liver preservation
KW  - liver transplantation
KW  - nonhuman
KW  - swine
KW  - temperature
KW  - time
PB  - Blackwell Verlag GmbH Berlin
SN  - 03423026 (ISSN)
LA  - German
J2  - LaboratoriumsMedizin
M3  - Article
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 1; CODEN: LABOD
ER  -

TY  - CONF
AU  - Gao, Z.
AU  - McCalley, J.
AU  - Meeker, W.
TI  - A transformer health assessment ranking method - Use of model based scoring expert system
PY  - 2009
T2  - 41st North American Power Symposium, NAPS 2009
C7  - 5483992
DO  - 10.1109/NAPS.2009.5483992
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-77954809427&doi=10.1109%2fNAPS.2009.5483992&partnerID=40&md5=ed01e4a8fb9d538c4f4915ad2378a941
AD  - Iowa State University, Ames, IA 50010, United States
AB  - Electric utilities need to answer three questions in order to effectively manage their transformer fleets: How many are going to fail each year? When is each unit going to fail? How to allocate available resources to minimize risk? To answer these questions, transformer health diagnosis and prediction is critical. This paper proposes an attempt of combining assessment results of different health indicators using a scoring expert system to obtain a single measure that reflects overall failure time expectation of each unit. To overcome the difficulty presented by limited information, expert knowledge is incorporate to produce reasonable estimates and assumptions during the scoring process. Results of such an analysis can aid in risk or reliability based decision-making processes for effective allocation of resources.
KW  - Scoring algorithm
KW  - Transformer health indicators
KW  - Transformer health model
KW  - Decision making
KW  - Electric utilities
KW  - Expert systems
KW  - Health
KW  - Reliability analysis
KW  - Decision making process
KW  - Expert knowledge
KW  - Health assessments
KW  - Health diagnosis
KW  - Health indicators
KW  - Limited information
KW  - Model-based
KW  - Overall failure
KW  - Ranking methods
KW  - Transformer health indicators
KW  - Transformer health model
KW  - Health risks
SN  - 978-142444428-1 (ISBN)
LA  - English
J2  - North Am. Power Symp., NAPS
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 11; Correspondence Address: Z. Gao; Iowa State University, Ames, IA 50010, United States; email: zhi.gao@ge.com; Conference name: 41st North American Power Symposium, NAPS 2009; Conference date: 4 October 2009 through 6 October 2009; Conference code: 81158
ER  -

TY  - JOUR
AU  - Wang, Y.-Y.
AU  - Yuan, Y.
AU  - Li, J.
AU  - Du, L.
AU  - Zhou, J.-J.
TI  - Fuzzy risk assessment model of power transformer based on Borda number theory
PY  - 2008
T2  - Gaodianya Jishu/High Voltage Engineering
VL  - 34
IS  - 12
SP  - 2668
EP  - 2673
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-58249130352&partnerID=40&md5=38e832b71c8be09a0e31e157166cf837
AD  - State Key Laboratory of Power Transmission Equipment and System Security and New Technology, Chongqing University, Chongqing 400044, China
AB  - The power transformer is the key equipment of transforming voltage and exchanging power in the power system. It's safe and reliable operation directly influences the safe level of the power system. To study the risk assessment of power transformer which is very significant to improve the reliability of the power system, a fuzzy comprehensive risk assessment model of power transformer based on Borda number theory is proposed in this paper. At first, the fault types and risk factors of the power transformer are analyzed. Secondly, the basic framework of the fuzzy comprehensive evaluation is applied to quantify the risk factors. And then, Borda number theory is employed to analyze influence degree and occurrence probability of power transformer. At last, the various risk factors impact index and fuzzy comprehensive evaluation index of power transformer can be easily obtained. Applying this model, the relative importance degree of the risk factors can be horizontally compared according to the numerical index, the engineering staff can directly get the parameters of the transformer risk level and get a good description of the visual expression through using 5 score and similar visual language.
KW  - Borda number theory
KW  - Fault tree structure
KW  - Fuzzy risk assessment
KW  - Improved analytic hierarchy process (IAHP)
KW  - Power transformer
KW  - Risk factor
SN  - 10036520 (ISSN)
LA  - English
J2  - Gaodianya Jishu
M3  - Article
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 1; Correspondence Address: Y.-Y. Wang; State Key Laboratory of Power Transmission Equipment and System Security and New Technology, Chongqing University, Chongqing 400044, China; email: y.wang@cqu.edu.cn; CODEN: GAJIE
ER  -

TY  - CONF
AU  - Wang, Chun
AU  - Crossley, Peter A.
AU  - Parker, Adrian D.
TI  - Design and evaluation of an EMTDC digital current transformer model
PY  - 2000
T2  - Proceedings of the Mediterranean Electrotechnical Conference - MELECON
VL  - 3
SP  - 1007
EP  - 1010
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-0034476504&partnerID=40&md5=387fbb78337ddaa852231bf772134cc5
AD  - Univ of the West of England, United Kingdom
AB  - The paper describes a new digital current transformer model designed for the use with the EMTDC/PSCAD transient power system simulation. The validity of the current transformer model has been assessed by using theoretical analysis, EMTP simulation and test results obtained from the Synthetic Test Plant (STP) at Alstom T&D Protection and Control Ltd.
KW  - Computer simulation
KW  - Electric distortion
KW  - Electric fault currents
KW  - Electric potential
KW  - Mathematical models
KW  - Numerical analysis
KW  - Real time systems
KW  - Spurious signal noise
KW  - Digital current transformer
KW  - Power system simulator
KW  - Electric instrument transformers
PB  - IEEE
LA  - English
J2  - Proc Mediterr Electrotech Conf MELECON
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 0; Conference name: 10th Mediterranean Electrotechnical Conference (MALECON2000); Conference date: 29 May 2000 through 31 May 2000; Conference code: 57863; CODEN: PMECF
ER  -

TY  - JOUR
AU  - Deller, J.R.
AU  - Desai, K.H.
AU  - Yang, Y.P.
TI  - A decision-theoretic framework for the evaluation of language models used in speech recognizers
PY  - 2005
T2  - Natural Language Engineering
VL  - 11
IS  - 4
SP  - 363
EP  - 396
DO  - 10.1017/S1351324905003700
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-28344456084&doi=10.1017%2fS1351324905003700&partnerID=40&md5=28de1ba35b37899a13f10b3ca3eb38fb
AD  - Department of Electrical and Computer Engineering, Michigan State University, East Lansing, MI 48824-1226, 2120 EB, United States
AB  - An analytical method for design and performance analysis of language models (LM) is described, and an example interactive software tool based on the technique is demonstrated. The LM performance analysis does not require on-line simulation or experimentation with the recognition system in which the LM is to employed. By exploiting parallels with signal detection theory, a profile of the LM as a function of the design parameters is given in a set of curves analogous to a receiver-operating-characteristic display. © 2005 Cambridge University Press.
KW  - Approximation theory
KW  - Computer aided software engineering
KW  - Decision theory
KW  - Decoding
KW  - Integration
KW  - Mathematical models
KW  - Maximum likelihood estimation
KW  - Parameter estimation
KW  - Probability density function
KW  - Signal detection
KW  - Interactive software tool
KW  - Language detection
KW  - Language models
KW  - Speech recognition
SN  - 14698110 (ISSN)
LA  - English
J2  - Nat Lang Eng
M3  - Article
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 0; Correspondence Address: J.R. Deller Jr.; Department of Electrical and Computer Engineering, Michigan State University, East Lansing, MI 48824-1226, 2120 EB, United States; email: deller@egr.msu.edu; CODEN: NLENF
ER  -

TY  - JOUR
AU  - Ishida, M.
AU  - Okabe, S.
AU  - Imamura, T.
AU  - Komatsubara, M.
TI  - Model transformer evaluation of high-permeability grain-oriented electrical steels
PY  - 2000
T2  - Journal of Materials Science and Technology
VL  - 16
IS  - 2
SP  - 223
EP  - 227
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-0034156190&partnerID=40&md5=7ac54e988003aa905cd22a4cc8216859
AD  - Kawasaki Steel Corporation, Kurashiki 712-8511, Japan
AB  - The dependence of transformer performance on the material properties was investigated using two laboratory-processed 0.23 mm thick grain-oriented electrical steels domain-refined with electrolytically etched grooves having different magnetic properties. The iron loss at 1.7 T, 50 Hz and the flux density at 800 A/m of material A were 0.73 W/kg and 1.89 T, respectively; and those of material B, 0.83 W/kg and 1.88 T. Model stacked and wound transformer core experiments using the tested materials exhibited performance well reflecting the material characteristics. In a three-phase stacked core with step-lap joints excited to 1.7 T, 50 Hz, the core loss, the exciting current and the noise level were 0.86 W/kg, 0.74 A and 52 dB, respectively, with material A; and 0.97 W/kg, 1.0 A and 54 dB with material B. The building factors for the core losses of the two materials were almost the same in both core configurations. The effect of higher harmonics on transformer performance was also investigated.
KW  - Electric transformers
KW  - Magnetic cores
KW  - Magnetic properties
KW  - Models
KW  - Solidification
KW  - Model transformer evaluation
KW  - Transformer core model
KW  - Steel
SN  - 10050302 (ISSN)
LA  - English
J2  - J Mater Sci Technol
M3  - Article
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 10; Correspondence Address: M. Ishida; Kawasaki Steel Corporation, Kurashiki 712-8511, Japan; email: ishida@kawasaki-steel.co.jp; CODEN: JSCTE
ER  -

TY  - JOUR
AU  - Honda, H.
AU  - Noda, T.
AU  - Asakawa, A.
AU  - Shindo, T.
AU  - Yokoyama, S.
AU  - Abiko, K.
TI  - Validation of a Pole-Mounted Distribution Transformer Model for Electromagnetic Transient Studies by Field Tests Using an Actual-Scale Distribution Line
PY  - 2005
T2  - IEEJ Transactions on Power and Energy
VL  - 125
IS  - 4
SP  - 441
EP  - 448
DO  - 10.1541/ieejpes.125.441
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-72149086619&doi=10.1541%2fieejpes.125.441&partnerID=40&md5=60e68ae8335e78692d98b71ec9500f4d
AD  - Electric Power Engineering Research Lab., CRIEPI, Yokosuka 240-0196, 2-6-1, Nagasaka, Japan
AD  - Distribution Engineering Dept., Tohoku Electric Power Co., Inc., Sendai 980-8550, 1-7-1, Hon-cho, Aoba-ku, Japan
AB  - The authors have previously proposed a transient simulation model of pole-mounted distribution transformers and its improved model that takes the skin effect of the secondary winding into account. However, the model has been validated only by laboratory tests with a low-voltage pulse generator. To show the accuracy of the model when used in a realistic situation, in this paper, field-test results using an actual-scale distribution line are presented. The following four cases are considered in the validation. Case1 (direct lightning hit is assumed): impulse current is injected into one phase of the high-voltage wires. Case2 (induced lightning is assumed): impulse current is injected into the bonded three phases of the high-voltage wires. Case3 (backflow lightning is assumed): impulse current is injected into the low-voltage neutral wire. Case4: the same conditions as Case1 except that surge-arrestors are installed for the transformer. All results obtained from the field test are compared with corresponding simulation results by considering the transient behavior of the grounding system. It is confirmed that the transformer model gives accurate results in the realistic situations. © 2005, The Institute of Electrical Engineers of Japan. All rights reserved.
KW  - distribution line
KW  - EMTP
KW  - lightning
KW  - lightning protection design
KW  - transformer
SN  - 03854213 (ISSN)
LA  - English
J2  - IEEJ Trans. Power Energy
M3  - Article
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 5
ER  -

TY  - JOUR
AU  - Mork, B.A.
AU  - Gonzalez, F.
AU  - Ishchenko, D.
AU  - Stuehm, D.L.
AU  - Mitra, J.
TI  - Hybrid transformer model for transient simulation - Part II: Laboratory measurements and benchmarking
PY  - 2007
T2  - IEEE Transactions on Power Delivery
VL  - 22
IS  - 1
SP  - 256
EP  - 262
DO  - 10.1109/TPWRD.2006.882999
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-34147173805&doi=10.1109%2fTPWRD.2006.882999&partnerID=40&md5=a9375ad58ec0a0a100de238c1f582f13
AD  - Department of Electrical Engineering, Michigan Technological University, Houghton, MI 49931, United States
AD  - Department of Electrical Engineering, North Dakota State University, Fargo, ND 58105, United States
AD  - Department of Electrical Engineering, New Mexico State University, Las Cruces, NM 88003, United States
AB  - The topological structure and basic approaches for parameter estimation for a new hybrid transformer model are presented in Part I of this two-paper set. Part II deals with the model benchmarking and also discusses additional methods for parameter estimation based on laboratory measurements. The simulation results confirm the validity of the model for the low- and medium-frequency range. © 2006 IEEE.
KW  - Duality
KW  - Electromagentic Transients Program (EMTP)
KW  - Transformer models
KW  - Transient simulations
KW  - Benchmarking
KW  - Electric frequency control
KW  - Parameter estimation
KW  - Power transformers
KW  - Topology
KW  - Electromagnetic Transients Program (EMTP)
KW  - Transient simulations
KW  - Transient analysis
SN  - 08858977 (ISSN)
LA  - English
J2  - IEEE Trans Power Delivery
M3  - Article
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 57; CODEN: ITPDE
ER  -

TY  - JOUR
AU  - Miki, K.
AU  - Hatazaki, K.
AU  - Hattori, H.
TI  - Efficient language model development for spoken dialogue recognition and its evaluation on operator's speech at call centers
PY  - 2006
T2  - PACLIC 20 - Proceedings of the 20th Pacific Asia Conference on Language, Information and Computation
SP  - 80
EP  - 86
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-84863703768&partnerID=40&md5=6fb8c820c557cde2a97936ebdfeb6969
AD  - Media and Information Research Laboratories, NEC Corporation, Nakahara-Ku, Kawasaki, Kanagawa 211-8666, 1753 Shimonumabe, Japan
AB  - While a language model for recognition of spoken dialogue is ideally built from a very large, specific-task-oriented corpus, a great amount of time and effort is required to develop such a corpus, and this involves both the audio recording and written transcription of large amounts of speech data. Training data for a language model should match the target task in both topic and style. What is needed, then, is a method to utilize previously existing spoken dialogue corpora that are not necessarily related to the specific target-task. Such corpora would be combined with documents related to the topic of the target-task to develop a language model for the target spoken-dialogue. In this paper, we propose a method for combining previously existing corpora with key phrases (i.e. phrases that contain keywords) extracted from task related documents. Even though the added data is from documents related to the target dialogue, since it consists of key phrases, stylistic differences (between document data and the actual dialogue to which the model will be applied) are not a problem. We have produced a model using this method and have evaluated it in use on actual spoken dialogue collected at call centers. Experimental results show that a relative 13% reduction in word error rate could be achieved with the addition of key phrases. This performance is nearly as good as that which would be achieved on the basis of a large, expensive transcript-corpus, and the cost of producing the key phrase data is essentially negligible. Such cost reduction achieved by our method will enable speech recognition applications to be more widely used.
KW  - Call center
KW  - Language model adaptation
KW  - Spoken dialogue recognition
KW  - Computational linguistics
KW  - Software agents
KW  - Call centers
KW  - ITS evaluation
KW  - Key-phrase
KW  - Language model
KW  - Language model adaptation
KW  - Speech data
KW  - Spoken dialogue
KW  - Training data
KW  - Word error rate
KW  - Speech recognition
LA  - English
J2  - PACLIC - Proc. Pacific Asia Conf. Lang., Inf. Comput.
M3  - Article
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 0; Correspondence Address: K. Miki; Media and Information Research Laboratories, NEC Corporation, Nakahara-Ku, Kawasaki, Kanagawa 211-8666, 1753 Shimonumabe, Japan; email: k-miki@bq.jp.nec.com; Conference name: 20th Pacific Asia Conference on Language, Information and Computation, PACLIC 20; Conference date: 1 November 2006 through 3 November 2006; Conference code: 90196
ER  -

TY  - CONF
AU  - Espinoza, J.R.
AU  - Pérez-Rojas, C.
AU  - García-Martínez, S.
TI  - Validation of the transformer magnetic circuit model
PY  - 2012
T2  - 2012 North American Power Symposium, NAPS 2012
C7  - 6336432
DO  - 10.1109/NAPS.2012.6336432
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-84870561222&doi=10.1109%2fNAPS.2012.6336432&partnerID=40&md5=3fe32dc6cf1aeea6e53296865e277653
AD  - Electrical Engineering Faculty, UMSNH, Morelia, Mexico
AB  - Model validation is an important stage in the investigation process, because it permits to ensure the efficiency of the developed models. Commonly, implemented model uses geometric transformer data instead of manufacturer data and they approximate transformer characteristics to make the simulation process simpler. Measurements on actual laboratory transformer are presented for validation of the transformer's magnetic method. We considered only the saturation effect using the arctangent function. © 2012 IEEE.
KW  - arctangent function for saturation
KW  - transformer magnetic model
KW  - Validation
KW  - Developed model
KW  - Investigation process
KW  - Magnetic methods
KW  - Magnetic models
KW  - Model validation
KW  - Saturation effects
KW  - Simulation process
KW  - Validation
KW  - Computer simulation
SN  - 978-146732308-6 (ISBN)
LA  - English
J2  - North Am. Power Symp., NAPS
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 0; Correspondence Address: J.R. Espinoza; Electrical Engineering Faculty, UMSNH, Morelia, Mexico; email: jespinoza@dep.fie.umich.mx; Conference name: 2012 North American Power Symposium, NAPS 2012; Conference date: 9 September 2012 through 11 September 2012; Conference code: 94119
ER  -

TY  - JOUR
AU  - Li, J.
AU  - He, Z.
AU  - Wang, Y.
AU  - Lv, J.
AU  - Zhao, L.
TI  - A Two-dimensional cloud model for condition assessment of HVDC converter transformers
PY  - 2012
T2  - Energies
VL  - 5
IS  - 1
SP  - 157
EP  - 167
DO  - 10.3390/en5010157
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-84859303896&doi=10.3390%2fen5010157&partnerID=40&md5=e1a48f9cd731f6c87a2584ef6437cbb1
AD  - State Key Laboratory of Power Transmission Equipment and System Security and New Technology, College of Electrical Engineering, Chongqing University, Chongqing 400030, China
AD  - HVDC Technology Research Department, Electric Power Research Institute, China Southern Power Grid, Guangzhou 510623, China
AB  - Converter transformers are the key and the most important components in high voltage direct current (HVDC) power transmission systems. Statistics show that the failure rate of HVDC converter transformers is approximately twice of that of transformers in AC power systems. This paper presents an approach integrated with a two-dimensional cloud model and an entropy-based weight model to evaluate the condition of HVDC converter transformers. The integrated approach can describe the complexity of HVDC converter transformers and achieve an effective assessment of their condition. Data from electrical testing, DGA, oil testing, and visual inspection were chosen to form the double-level assessment index system. Analysis results show that the integrated approach is capable of providing a relevant and effective assessment which in turn, provides valuable information for the maintenance of HVDC converter transformers. © 2012 by the authors; licensee MDPI, Basel, Switzerland.
KW  - Cloud model
KW  - Condition assessment
KW  - Entropy weight
KW  - HVDC converter transformer
KW  - Cloud computing
KW  - DC power transmission
KW  - Electric power transmission
KW  - Entropy
KW  - Failure analysis
KW  - Integrated control
KW  - Testing
KW  - Assessment index system
KW  - Cloud modeling
KW  - Condition assessments
KW  - Converter transformers
KW  - Entropy weights
KW  - High voltage direct current power transmissions
KW  - HVDC converters
KW  - Integrated approach
KW  - HVDC power transmission
PB  - MDPI AG
SN  - 19961073 (ISSN)
LA  - English
J2  - Energies
M3  - Article
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 9; Correspondence Address: J. Li; State Key Laboratory of Power Transmission Equipment and System Security and New Technology, College of Electrical Engineering, Chongqing University, Chongqing 400030, China; email: lijian@cqu.edu.cn
ER  -

TY  - JOUR
AU  - Amoda, O.
AU  - Tylavsky, D.J.
AU  - McCulla, G.
AU  - Knuth, W.
TI  - Evaluation of hottest-spot temperature models using field measured transformer data
PY  - 2011
T2  - International Journal of Emerging Electric Power Systems
VL  - 12
IS  - 5
C7  - 2
DO  - 10.2202/1553-779X.2734
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-80052569986&doi=10.2202%2f1553-779X.2734&partnerID=40&md5=ad03d35d4cbfbef5c9c44953a9089f0d
AD  - Arizona State University, United States
AD  - Salt River Project, United States
AB  - The acceptability of two hottest-spot temperature models is assessed in this paper. The first model, contained in the IEEE loading guide, is shown not to accurately account for the effects of the top-oil temperature (TOT) variation on the hottest-spot temperature. A new model which accounts for TOT variation is derived. The original and modified models are linearized and fitted to field data using linear regression to obtain optimal parameter estimates. Comparison of the parameter estimates and prediction simulations show that even though the original model is not structurally accurate, it, as well as the modified model, are acceptable for prediction purposes. The method of nonlinear regression is also used in an attempt to find better parameter estimates for the nonlinear modified model. It is shown that parameter estimates for the nonlinear model are inferior to those obtained for the linear models. © 2011 Berkeley Electronic Press. All rights reserved.
KW  - hottest spot temperature
KW  - temperature-models
KW  - top oil
KW  - transformers
KW  - Estimation
KW  - Parameter estimation
KW  - Field data
KW  - Hottest-spot temperatures
KW  - IEEE loading guide
KW  - Linear model
KW  - Modified model
KW  - New model
KW  - Non-linear model
KW  - Non-linear regression
KW  - Optimal parameter
KW  - Original model
KW  - Parameter estimate
KW  - temperature-models
KW  - Top oil
KW  - Top oil temperature
KW  - Computer simulation
SN  - 1553779X (ISSN)
LA  - English
J2  - Int. J. Emerg. Electr. Power Syst.
M3  - Article
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 2
ER  -

TY  - CONF
AU  - Hunter, G.J.A.
AU  - Huckvale, M.A.
TI  - An evaluation of statistical language models of spoken dialogue using the british national corpus
PY  - 2005
T2  - IEE Conference Publication
IS  - 2005-11059
SP  - 291
EP  - 297
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-28844506412&partnerID=40&md5=ab259c3e746081492cb44f7fd3fa28b4
AD  - School of Mathematics, Kingston University, United Kingdom
AD  - Department of Phonetics and Linguistics, University College London, United Kingdom
AB  - The use of spoken dialogue interfaces is becoming quite commonplace in many everyday situations such as cinema ticket bookings and much effort is being put into making such systems reliable and easy to use. There is strong evidence that the performance of the language model component of a speech recognition system is heavily dependent on the nature of the material to which it is applied relative to the nature of the material on which it was trained. Although much work has been carried out on the statistical modelling of text data based on, for example, transcripts of news broadcasts, relatively little work has been carried out to date on applying such models to dialogue data. This would seem to be an important area for study with a view improving automated spoken dialogue interfaces. This paper describes work applying statistical modeling techniques to both text and dialogue material in the British National Corpus, comparing the results obtained from the two distinct datasets and interpreting these findings in the light of psycholinguistic theories of dialogue.
KW  - Artificial intelligence
KW  - Mathematical models
KW  - Statistics
KW  - Datasets
KW  - Language model components
KW  - Statistical modeling
KW  - Natural language processing systems
SN  - 05379989 (ISSN)
LA  - English
J2  - IEE Conf Publ
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 3; Conference name: IEE International Workshop on Intelligent Environments; Conference code: 66193; CODEN: IECPB
ER  -

TY  - CONF
AU  - Galescu, L.
AU  - Allen, J.
TI  - Evaluating hierarchical hybrid statistical language models
PY  - 2000
T2  - 6th International Conference on Spoken Language Processing, ICSLP 2000
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85009097011&partnerID=40&md5=8d80893150de92367cc4d8baf2216158
AD  - University of Rochester, United States
AB  - We introduce in this paper a hierarchical hybrid statistical language model, represented as a collection of local models plus a general model that binds together the local ones. The model provides a unified framework for modelling language both above and below the word level, and we exemplify with models of both kinds for a large vocabulary task domain. To our knowledge this is the first paper to report an extensive evaluation of the improvements achieved from the use of local models within a hierarchical framework in comparison with a conventional word-based trigram model.
KW  - Computational linguistics
KW  - Natural language processing systems
KW  - Optical character recognition
KW  - General model
KW  - Large vocabulary
KW  - Local model
KW  - Statistical language modeling
KW  - Statistical language models
KW  - Task domain
KW  - Trigram model
KW  - Unified framework
KW  - Modeling languages
PB  - International Speech Communication Association
SN  - 7801501144 (ISBN); 978-780150114-1 (ISBN)
LA  - English
J2  - Int. Conf. Spok. Lang. Process., ICSLP
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 1; Conference name: 6th International Conference on Spoken Language Processing, ICSLP 2000; Conference date: 16 October 2000 through 20 October 2000; Conference code: 124331
ER  -

TY  - JOUR
AU  - Burn, G.L.
TI  - Implementing the evaluation transformer model of reduction on parallel machines
PY  - 1991
T2  - Journal of Functional Programming
VL  - 1
IS  - 3
SP  - 329
EP  - 366
DO  - 10.1017/S0956796800000137
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-84974277241&doi=10.1017%2fS0956796800000137&partnerID=40&md5=ece2e26f7540998b230d59cc21b23834
AD  - Department of Computing, Imperial College of Science, Technology and Medicine, London, SW7 2BZ, Kiribati
AB  - The evaluation transformer model of reduction generalizes lazy evaluation in two ways: it can start the evaluation of expressions before their first use, and it can evaluate expressions further than weak head normal form. Moreover, the amount of evaluation required of an argument to a function may depend on the amount of evaluation required of the function application. It is a suitable candidate model for implementing lazy functional languages on parallel machines. In this paper we explore the implementation of lazy functional languages on parallel machines, both shared and distributed memory architectures, using the evaluation transformer model of reduction. We will see that the same code can be produced for both styles of architecture, and the definition of the instruction set is virtually the same for each style. The essential difference is that a distributed memory architecture has one extra node type for nonlocal pointers, and instructions which involve the value of such nodes need their definitions extended to cover this new type of node. To make our presentation accessible, we base our description on a variant of the well-known G-machine, an abstract machine for executing lazy functional programs. © 1991, Cambridge University Press. All rights reserved.
SN  - 09567968 (ISSN)
LA  - English
J2  - J. Funct. Program.
M3  - Article
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 4
ER  -

TY  - CONF
AU  - Burn, G.L.
TI  - Evaluation transformers — A model for the parallel evaluation of functional languages (extended abstract)
PY  - 1987
T2  - Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)
VL  - 274 LNCS
SP  - 446
EP  - 470
DO  - 10.1007/3-540-18317-5_24
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032484858&doi=10.1007%2f3-540-18317-5_24&partnerID=40&md5=d5b67c237f54ba6f8e03577bcedbe7fa
AD  - GEC Research Ltd, Hirst Research Centre, East Lane, Wembley, HA9 7PP, Middx., United Kingdom
AB  - If we are not careful, a parallel machine may become swamped with the computation of the expressions whose values are not needed in order to produce the result from a program. We give a semantic criterion which ensures that this does not happen. An abstract interpretation can be developed which gives the definedness of a function in terms of the definedness of its arguments. Traditionally this has been used to give a strictness analysis which has been interpreted to say how much the argument in an application can be evaluated in parallel with the application while still satisfying the semantic criterion. Strictness analysis however only takes into account local information. By taking into account contextual information of an application, we are able to find that in many cases more evaluation of the argument is allowed. This information is available from the same abstract interpretation that is used for strictness analysis. Given how much evaluation is allowed of a function application, an evaluation transformer says how much evaluation of the argument in the application is allowed. This leads to a natural model of the parallel evaluation of functional languages. © 1987, Springer-Verlag.
KW  - Abstract Interpretation
KW  - Evaluation Transformers
KW  - Functional Languages
KW  - Parallel Reduction
KW  - Strictness Analysis
KW  - Abstracting
KW  - Computer architecture
KW  - Computer programming
KW  - Computer programming languages
KW  - Function evaluation
KW  - Model checking
KW  - Semantics
KW  - Abstract interpretations
KW  - Contextual information
KW  - Extended abstracts
KW  - Functional languages
KW  - Local information
KW  - Parallel evaluation
KW  - Semantic criteria
KW  - Strictness analysis
KW  - Functional programming
A2  - Kahn G.
A2  - INRIA, Centre de Sophia Antipolis, Avenue Emile Hugues, Valbonne Cedex, F-06565
PB  - Springer Verlag
SN  - 03029743 (ISSN); 978-354018317-4 (ISBN)
LA  - English
J2  - Lect. Notes Comput. Sci.
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 25; Conference name: 3rd International Conference on Functional Programming Languages and Computer Architecture, 1987; Conference date: 14 September 1987 through 16 September 1987; Conference code: 166949
ER  -

TY  - JOUR
AU  - Piński, M.
TI  - Clinical evaluation of serum transaminase (GOT and GPT) changes during the preoperative period and after major surgery
ST  - Ocena klíniczna wahań aktywności transaminaz surowicy krwi (GOT i GPT) u chorych w okresie przedoperacyjnym i po ciezkich zabiegach operacyjnych.
PY  - 1965
T2  - Annales Academiae Medicae Stetinensis
VL  - 11
SP  - 375
EP  - 397
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-0013832573&partnerID=40&md5=92355865db1524d42b311ea7156a363c
KW  - Blood
KW  - Human
KW  - Surgical Procedures, Operative
KW  - Transaminases
KW  - aminotransferase
KW  - article
KW  - blood
KW  - human
KW  - metabolism
KW  - surgery
SN  - 14274930 (ISSN)
C2  - 5856578
LA  - Polish
J2  - Ann Acad Med Stetin
M3  - Article
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 0
ER  -

TY  - JOUR
AU  - KEDRA, M.
AU  - MARKIEWICZ, M.
TI  - CRITICAL EVALUATION OF THE DETERMINATION OF GOT, GPT AND ALDOLASE IN THE DIAGNOSIS OF MYOCARDIAL INFARCTION.
ST  - KRYTYCZNA OCENA WARTO'SCI OZNACZANIA TRANSAMINAZY GOT, GPT I ALDOLAZY W RAZPOZAWANIU ZAWALU SERCA.
PY  - 1964
T2  - Polski tygodnik lekarski (Warsaw, Poland : 1960)
VL  - 19
SP  - 980
EP  - 983
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-75949147332&partnerID=40&md5=63d15be5602d51782ebc7f49f83b8d20
KW  - Alanine Transaminase
KW  - Aspartate Aminotransferases
KW  - Blood Chemical Analysis
KW  - Enzyme Tests
KW  - Fructose-Bisphosphate Aldolase
KW  - Myocardial Infarction
KW  - ALANINE AMINOTRANSFERASE
KW  - ALDOLASE
KW  - ASPARTATE AMINOTRANSFERASE
KW  - BLOOD CHEMICAL ANALYSIS
KW  - ENZYME TESTS
KW  - MYOCARDIAL INFARCT
KW  - alanine aminotransferase
KW  - aspartate aminotransferase
KW  - fructose bisphosphate aldolase
KW  - article
KW  - blood analysis
KW  - enzyme assay
KW  - heart infarction
SN  - 00323756 (ISSN)
C2  - 14207989
LA  - Polish
J2  - Pol Tyg Lek
M3  - Article
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 0
ER  -

TY  - JOUR
AU  - Pluto, R.
AU  - Zober, A.
TI  - Occupational medical assessment of increased liver enzyme activity (gamma GT, GPT, GOT) in workers exposed to solvents
ST  - ARBEITSMEDIZINISCHE BEWERTUNG ERHOHTER LEBERENZYMAKTIVATEN (γ-GT, GPT, GOT) BEI LOSEMITTELEXPONIERTEN BESCHAFTIGTEN?
PY  - 1991
T2  - Arbeitsmedizin Sozialmedizin Praventivmedizin
VL  - 26
IS  - 6
SP  - 244
EP  - 246
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-0025806379&partnerID=40&md5=0eb6d39baafa769fcfe79b8da8fbeae2
AD  - Germany
KW  - liver enzyme
KW  - solvent
KW  - adult
KW  - aspartate aminotransferase blood level
KW  - gamma glutamyl transferase blood level
KW  - human
KW  - medical assessment
KW  - normal human
KW  - note
KW  - occupational exposure
KW  - occupational health
SN  - 0300581X (ISSN)
LA  - German
J2  - ARBEITSMED. SOZIALMED. PRAVENTIVMED.
M3  - Note
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 1; CODEN: ASPVA
ER  -

TY  - JOUR
TI  - New process of evaluation of interior lighting (GPT)
PY  - 1971
T2  - Toshiba Review
IS  - 54
SP  - 29
EP  - 32
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-0015019457&partnerID=40&md5=bbaafa270df10f76a272d748392b4b98
AB  - Graded Pattern Televiscope (GPT) is a method of measuring luminance by utilizing industrial television. The monitor TV screen displays luminance pattern images in different grades of black, gray and white, depending on the luminance level within the visual field, thereby indicating the luminance distribution at a glance.
KW  - Illuminating engineering
LA  - undefined
J2  - Toshiba Rev, Int Ed
M3  - Article
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 0
ER  -

TY  - JOUR
AU  - Zenova, V.P.
AU  - Mil'man, L.I.
TI  - Utilization of Models to Evaluate Radial Stability of Compressible Transformer Windings.
ST  - ISPOL'ZOVANIE MODELEI DLYA OTSENKI RADIAL'NOI USTOICHIVOSTI SZHIMAEMYKH OBMOTOK TRANSFORMATOROV.
PY  - 1976
T2  - Elektrotekhnika
IS  - 4
SP  - 17
EP  - 21
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-0016941403&partnerID=40&md5=d4e1487087cf61a258ba4daf45f69c55
AB  - Principal problems of determination of the stability of compressible windings of transformers by the results of tests of their models (prototypes) are considered. The advantages and shortcomings of these tests of the transformer and of the prototypes of its windings are presented.
KW  - ELECTRIC TRANSFORMERS - Testing
KW  - Electric windings, Transformer
SN  - 00135860 (ISSN)
LA  - Russian
J2  - Elektrotekhnika
M3  - Article
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 0; CODEN: ELKTA
ER  -

TY  - JOUR
AU  - Jessee, J.P.
AU  - Nelson, D.J.
TI  - A Coupled Thermal Magnetic Model for High Frequency Transformers: Part II—Finite Element Implementation and Validation
PY  - 1992
T2  - IEEE Transactions on Components, Hybrids, and Manufacturing Technology
VL  - 15
IS  - 5
SP  - 740
EP  - 747
DO  - 10.1109/33.180038
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-0012613512&doi=10.1109%2f33.180038&partnerID=40&md5=5a7572befbc09d642711e91a03fab0f2
AD  - Virginia Power Electronics Center, Department of Mechanical Engineering, Virginia Polytechnic Institute and State University, Blacksburg, VA 24061-0238, United States
AB  - In a companion paper, [4], the governing equations, source terms, boundary conditions, and material property relationships for a high frequency transformer model were derived. In the present paper, a solution method for this model based on the finite element technique is developed and validated with both numerical comparisons and experimental data. © 1992 IEEE
SN  - 01486411 (ISSN)
LA  - English
J2  - IEEE Trans. Comp., Hybrids, Manufact. Technol.
M3  - Article
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 4
ER  -

TY  - JOUR
AU  - Smirnov, S.S.
TI  - Evaluation of the Capabilities of Transformers for a Dynamic Model.
ST  - OTSENKA VOZMOZHNOSTEI TRANSFORMATOROV DLYA DINAMICHESKOI MODELI.
PY  - 1973
T2  - Izvestiya Vysshikh Uchebnykh Zavedenij i Energeticheskikh Ob''edinenij Sng. Energetika
IS  - 1
SP  - 14
EP  - 18
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-0015562280&partnerID=40&md5=4bb5b038f202a80021b35fdcac90041e
AB  - A system of characteristics is considered reflecting regulating capabilities of transformers intended for an electrodynamic model of electrical systems.
KW  - ELECTRIC POWER SYSTEMS - Models
KW  - Models
KW  - Electric transformers
SN  - 05792983 (ISSN)
LA  - Russian
J2  - Izv Vyssh Uchebn Zaved, Energ
M3  - Article
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 0; CODEN: IVUZB
ER  -

TY  - JOUR
AU  - Walters, T.R.
AU  - Scheideler, A.L.
TI  - A Study of Models for Use in Evaluating Dry-Type Transformer Insulating Systems
PY  - 1956
T2  - Transactions of the American Institute of Electrical Engineers. Part III: Power Apparatus and Systems
VL  - 75
IS  - 3
SP  - 520
EP  - 527
DO  - 10.1109/AIEEPAS.1956.4499336
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-84898416050&doi=10.1109%2fAIEEPAS.1956.4499336&partnerID=40&md5=0797f2be2d8d294b6ec1d84c76bbd4f4
AD  - General Electric Company, Pittsfield, Mass., United States
SN  - 00972460 (ISSN)
LA  - English
J2  - Trans. AIEE, Part III: Power Appar. Syst.
M3  - Article
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 3
ER  -

TY  - JOUR
AU  - McNutt, W.J.
AU  - Kaufmann, G.H.
TI  - Evaluation of a functional life test model for power transformers
PY  - 1983
T2  - IEEE Transactions on Power Apparatus and Systems
VL  - PAS-102
IS  - 5
SP  - 1151
EP  - 1162
DO  - 10.1109/TPAS.1983.318055
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-0020751132&doi=10.1109%2fTPAS.1983.318055&partnerID=40&md5=01df1fab39d021466f2fdd2dd569232d
AD  - General Electric Company, Pittsfield, Mass, United States
AB  - A power transformer life model and its related test procedure have been evaluated and found to provide more meaningful information on retained operational capability of the winding insulation than can be derived from simple material tests. Both paper and enamel conductor insulation demonstrated retained functionality after aging for time periods in excess of 5 times the life defined in industry loading guides. In addition, valuable knowledge was revealed about the behavior of conductor turn insulation with free gas entrapment, where the gas source was either oil supersaturation with dissolved gas or thermal evolution from overheated cellulose. Copyright © 1983 by The Institute of Electrical and Electronics Engineers, Inc.
KW  - ELECTRIC INSULATING MATERIALS - Aging
KW  - ELECTRIC WINDINGS, TRANSFORMER - Aging
KW  - ELECTRIC TRANSFORMERS
SN  - 00189510 (ISSN)
LA  - English
J2  - IEEE Trans. Power Appar. Syst.
M3  - Article
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 17
ER  -

TY  - JOUR
AU  - McNutt, W.J.
AU  - Kaufmann, G.H.
TI  - Evaluation of a Functional Life Test Model for Power Transformers
PY  - 1983
T2  - IEEE Power Engineering Review
VL  - PER-3
IS  - 5
SP  - 33
EP  - 34
DO  - 10.1109/MPER.1983.5519148
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-84942393502&doi=10.1109%2fMPER.1983.5519148&partnerID=40&md5=758dccde385e9cc25f9385f3c7c5d8f9
AD  - General Electric Company, Pittsfield, MA, United States
SN  - 02721724 (ISSN)
LA  - English
J2  - IEEE Power Eng. Rev.
M3  - Article
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 1
ER  -

TY  - JOUR
AU  - Arturi, C.M.
AU  - Ubaldini, M.
TI  - Model for the evaluation of no-load losses of three-phase transformers with distorted fluxes
ST  - Un modello per la valutazione della perdita a vuoto di transformatori trifasi con flusso deformato
PY  - 1988
T2  - Energia Elettrica
VL  - 65
IS  - 11
SP  - 477
EP  - 484
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-0024110990&partnerID=40&md5=dd91940b2bf3d3b2c1d11b3d21b9cb4d
AD  - Politecnico di Milano, Italy
AB  - This paper considers the influence of the winding connection and the distortion in the supply voltage on the no-load loss in three-phase core-type transformers. With sinusoidal supply voltage, this analysis shows that the no-load loss is greater in delta connection than in star connection of the supplied side and that, in the latter case, it depends on the connection of the secondary side: the loss is greater if the secondary is delta-connected than star-connected. The differences might be even of the order of 5-6%. The distortion of the supply voltage increases the previous figures, i.e., the no-load loss is greater than that with sinusoidal voltage if the winding is delta-connected. The paper also discusses the formula of the Standard for the correction of the measured no-load loss to the sine wave basis and proposes a circuit model for computing the effect of the distortion of the supply voltage.
KW  - Electric Losses
KW  - Electric Windings, Transformer
KW  - Mathematical Models
KW  - Delta Connections
KW  - Star Connections
KW  - Three-Phase Core-Type Transformers
KW  - Electric Transformers
SN  - 00137308 (ISSN)
LA  - Italian
J2  - Energ Elettr
M3  - Article
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 0; CODEN: ENELA
ER  -

TY  - CONF
AU  - Burn, G.L.
TI  - The evaluation transformer model of reduction and its correctness
PY  - 1991
T2  - Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)
VL  - 494 LNCS
SP  - 458
EP  - 482
DO  - 10.1007/3540539816_81
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-0343975623&doi=10.1007%2f3540539816_81&partnerID=40&md5=e9e92c525dd5dce6966bbbfcfeb58b59
AD  - Department of Computing, Imperial College, 180 Queen’s Gate, London, SW7 2BZ, United Kingdom
AB  - Lazy evaluation of functional programs incurs time and memory overheads, and restricts parallelism compared with programs that are evaluated strictly. A number of analysis techniques, such as abstract interpretation and projection analysis, have been developed to find out information that can alleviate these overheads. This paper formalises an evaluation model, the evaluation transformer model of reduction, which can use information from these analysis techniques, and proves that the resulting reduction strategies produce the same answers as those obtained using lazy evaluation. © Springer-Verlag Berlin Heidelberg 1991.
KW  - Computation theory
KW  - Distributed computer systems
KW  - Abstract interpretations
KW  - Analysis techniques
KW  - Evaluation modeling
KW  - Functional programs
KW  - Memory overheads
KW  - Projection analysis
KW  - Reduction strategy
KW  - Transformer modeling
KW  - Software design
A2  - Department of Computing, Imperial College of Science, Technology and Medicine, University of London, 180 Queen's Gate, London, SW7 2BZ
A2  - Abramsky S.
A2  - Maibaum T.S.E.
PB  - Springer Verlag
SN  - 03029743 (ISSN); 978-354053981-0 (ISBN)
LA  - English
J2  - Lect. Notes Comput. Sci.
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 4; Conference name: 4th International Joint Conference on Theory and Practice of Software Development, TAPSOFT 1991; Conference date: 8 April 1991 through 12 April 1991; Conference code: 167359
ER  -

TY  - CONF
AU  - Codogno, M.
AU  - Fissore, L.
AU  - Martelli, A.
AU  - Pirani, G.
AU  - Volpi, G.
TI  - EXPERIMENTAL EVALUATION OF ITALIAN LANGUAGE MODELS FOR LARGE-DICTIONARY SPEECH RECOGNITION
PY  - 1987
T2  - European Conference on Speech Technology, ECST 1987
SP  - 1159
EP  - 1162
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85135067790&partnerID=40&md5=908b7ed2571685c4f9dc0b83653041b8
AD  - CSELT - Centro Studi E Laboratori Telecomunicazioni, Via G. Reiss Romoli 274, Torino, 10148, Italy
AD  - IBM Italia, Centro di Ricerca di Roma, Via Giorgione 159, Roma, 00147, Italy
AB  - This paper reports on experiments performed on the Italian language in order to assess the efficiency of probabilistic language models with reference to a task of large-dictionary speech recognition. Two different types of models, an M-gram and an Mg-gram one, have been investigated for comparison purposes. The quality of the models trained on a corpus of 3.5 million words was measured in terms of perplexity and of the improvement achieved by integrating the language model in real speech recognition systems. Judging from this empirical measurement, the two language models exhibit equivalent preformance for Italian, although perplexity measurements would suggest otherwise. © European Conference on Speech Technology, ECST 1987. All rights reserved.
KW  - Computational linguistics
KW  - Empirical measurement
KW  - Experimental evaluation
KW  - Language model
KW  - Probabilistic language
KW  - Speech recognition systems
KW  - Speech recognition
PB  - The International Society for Computers and Their Applications (ISCA)
LA  - English
J2  - Eur. Conf. Speech Technol., ECST
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 2; Conference name: 1987 European Conference on Speech Technology, ECST 1987; Conference date: 1 September 1987 through 4 September 1987; Conference code: 180611
ER  -

TY  - JOUR
AU  - Hayashi, S.
TI  - Evaluation of GOT and GPT excretion in liver diseases
PY  - 1968
T2  - Nippon Ishikai zasshi. Journal of the Japan Medical Association
VL  - 60
IS  - 5
SP  - 393
EP  - 398
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-0014326782&partnerID=40&md5=d93e389c0b11ca380da45035a2d14746
KW  - Alanine Transaminase
KW  - Animal
KW  - Aspartate Aminotransferases
KW  - Human
KW  - Liver Diseases
KW  - Male
KW  - Rats
KW  - alanine aminotransferase
KW  - aspartate aminotransferase
KW  - animal
KW  - article
KW  - blood
KW  - enzymology
KW  - human
KW  - liver disease
KW  - male
KW  - rat
SN  - 00214493 (ISSN)
C2  - 5751442
LA  - Japanese
J2  - Nippon Ishikai Zasshi
M3  - Article
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 0
ER  -

TY  - JOUR
AU  - Codogno, M.
AU  - Fissore, L.
AU  - Martelli, A.
AU  - Pirani, G.
AU  - Volpi, G.
TI  - EVALUATION OF ITALIAN LANGUAGE MODELS FOR SPEECH RECOGNITION.
PY  - 1988
T2  - CSELT Technical Reports
VL  - 16
IS  - 1
SP  - 1
EP  - 3
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-0023965228&partnerID=40&md5=5e12571f412a9aebcb92d1ba6b79434d
AD  - CSELT, Turin, Italy, CSELT, Turin, Italy
AB  - This paper reports on experiments performed on the Italian language in order to assess the efficiency of probabilistic language models with reference to a task of large-dictionary speech recognition. Two different types of models, an M-gram and an Mg-gram one, have been investigated for comparison purposes. The quality of the models trained on a corpus of 3. 5 million words was measured in terms of perplexity and of the improvement achieved by integrating the language model in real speech recognition systems. Judging from this empirical measurement, the two language models exhibit equivalent performance for Italian, althogh perplexity measurements would suggest otherwise.
KW  - GLOSSARIES
KW  - INFORMATION SCIENCE - Language Translation and Linguistics
KW  - PROBABILITY
KW  - DICTIONARY
KW  - ITALIAN LANGUAGE MODELS
KW  - M-GRAM MODEL
KW  - MG-GRAM MODEL
KW  - PERPLEXITY
KW  - SPEECH
SN  - 03932648 (ISSN)
LA  - English
J2  - CSELT Tech Rep
M3  - Article
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 0; CODEN: CTRPE
ER  -

TY  - CONF
AU  - McNutt, W.J.
AU  - Kaufmann, G.H.
TI  - EVALUATION OF A FUNCTIONAL LIFE TEST MODEL FOR POWER TRANSFORMERS.
PY  - 1982
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-0020336662&partnerID=40&md5=1fa03498cf5e355158e1d1f23b57ca92
AD  - GE, Pittsfield, MA, USA, GE, Pittsfield, MA, USA
AB  - A power transformer life model and its related test procedure have been evaluated and found to provide more meaningful information on retained operational capability of the winding insulation than can be derived from simple material tests. Both paper and enamel conductor insulation demonstrated retained functionality after aging for time periods in excess of 5 times the life defined in industry loading guides. Valuable knowledge was revealed about the behavior of conductor turn insulation with free gas entrapment, where the gas source was either oil supersaturation with dissolved gas or thermal evolution from overheated cellulose.
KW  - ELECTRIC INSULATING MATERIALS
KW  - LIFE TEST MODELS
KW  - LOADING GUIDES
KW  - OPERATIONAL CAPABILITY
KW  - PAPER AND ENAMEL
KW  - POWER TRANSFORMERS
KW  - WINDING INSULATION
KW  - ELECTRIC TRANSFORMERS
PB  - IEEE
LA  - English
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 10 February 2024; Cited By: 1; Conference name: IEEE Power Engineering Society 1982 Summer Meeting.; Conference code: 1344
ER  -

