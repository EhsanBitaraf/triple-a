{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipleline Sample\n",
    "This sample show the core functionality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ti%3A%22large%20language%20model%22%20AND%20ti%3ABenchmark\n",
      "\u001b[32mTotal number of article is 114\u001b[0m\n",
      "\u001b[32m            Round (1) : Get another 10 record (Total 10 record)\u001b[0m\n",
      "\u001b[32m            Round (2) : Get another 10 record (Total 20 record)\u001b[0m\n",
      "\u001b[32m            Round (3) : Get another 10 record (Total 30 record)\u001b[0m\n",
      "\u001b[32m            Round (4) : Get another 10 record (Total 40 record)\u001b[0m\n",
      "\u001b[32m            Round (5) : Get another 10 record (Total 50 record)\u001b[0m\n",
      "\u001b[32m            Round (6) : Get another 10 record (Total 60 record)\u001b[0m\n",
      "\u001b[32m            Round (7) : Get another 10 record (Total 70 record)\u001b[0m\n",
      "\u001b[32m            Round (8) : Get another 10 record (Total 80 record)\u001b[0m\n",
      "\u001b[32m            Round (9) : Get another 10 record (Total 90 record)\u001b[0m\n",
      "\u001b[32m            Round (10) : Get another 10 record (Total 100 record)\u001b[0m\n",
      "\u001b[32m            Round (11) : Get another 10 record (Total 110 record)\u001b[0m\n",
      "\n",
      "\u001b[31mError in parsing arxiv response. Entry missing.\u001b[0m\n",
      "\n",
      "\u001b[31mError Line 23\u001b[0m\n",
      "\u001b[31mError 'entry'\u001b[0m\n",
      "\u001b[32m            Round (12) : Get another 10 record (Total 120 record)\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import urllib.parse\n",
    "from triplea.service.repository.state.initial_arxiv import get_article_list_from_arxiv_all_store_to_arepo\n",
    "\n",
    "\n",
    "arxiv_search_string = 'ti:\"large+language+model\"+AND+ti:Benchmark'\n",
    "arxiv_search_string = 'ti:\"large language model\" AND ti:Benchmark'\n",
    "arxiv_search_string= urllib.parse.quote(arxiv_search_string)\n",
    "print(arxiv_search_string)\n",
    "get_article_list_from_arxiv_all_store_to_arepo(arxiv_search_string,0,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mTotal number of article is 1\u001b[0m\n",
      "\u001b[32m            Round (1) : Get another 1 record (Total 1 record)\u001b[0m\n",
      "\u001b[32madd 37567487 to knowledge repository. (1)\u001b[0m\n",
      "\u001b[32m            Round (2):\n",
      "                 Get another -1 record (total 1 record)\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from triplea.service.repository.state.initial import get_article_list_from_pubmed_all_store_to_arepo\n",
    "\n",
    "\n",
    "pubmed_search_string = '(\"large language model\"[Title]) AND (Benchmark[Title/Abstract])'\n",
    "get_article_list_from_pubmed_all_store_to_arepo(pubmed_search_string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get info of Article Repository\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mNumber of article in article repository is 115\u001b[0m\n",
      "\u001b[32m115 article(s) in state 3.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import triplea.service.repository.persist as PERSIST\n",
    "import triplea.service.repository.pipeline_core as PIPELINE\n",
    "\n",
    "\n",
    "PERSIST.print_article_info_from_repo()     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Moving Forward in core pipeline\n",
    "We move from state `0` to state `3`\n",
    "The best approach is to finalize state all the article in the `core state`.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define dependency:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from triplea.service.repository.pipeline_core import move_state_forward"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Moving from `0` to `1`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m0 Article(s) is in state 0\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "\n",
    "PIPELINE.move_state_forward(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Moving from `1` to `2`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m0 Article(s) is in state 1\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "PIPELINE.move_state_forward(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Moving from `2` to `3`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m0 Article(s) is in state 2\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "PIPELINE.move_state_forward(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check article object info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[0m\n",
      "\u001b[32mTitle   : Evaluation High-Quality of Information from ChatGPT (Artificial Intelligence-Large Language Model) Artificial Intelligence on Shoulder Stabilization Surgery.\u001b[0m\n",
      "\u001b[32mJournal : Arthroscopy : the journal of arthroscopic & related surgery : official publication of the Arthroscopy Association of North America and the International Arthroscopy Association\u001b[0m\n",
      "\u001b[32mDOI     : 10.1016/j.arthro.2023.07.048\u001b[0m\n",
      "\u001b[32mPMID    : 37567487\u001b[0m\n",
      "\u001b[32mPMC     : None\u001b[0m\n",
      "\u001b[32mState   : 3\u001b[0m\n",
      "\u001b[32mAuthors : Eoghan T Hurley, Bryan S Crook, Samuel G Lorentz, Richard M Danilkowicz, Brian C Lau, Dean C Taylor, Jonathan F Dickens, Oke Anakwenze, Christopher S Klifto, \u001b[0m\n",
      "\u001b[32mKeywords: \u001b[0m\n"
     ]
    }
   ],
   "source": [
    "PERSIST.print_article_short_description(\"37567487\",\"pmid\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Moving forward in custom pipeline\n",
    "These stages in custom pipleline do not have a specific prerequisite and post-requirement relationship, and when the core pipeline is provided and it has reached state 3, each of the actions of this pipeline can be done independently. This pipeline includes the following:\n",
    "\n",
    "|Action|Tag Name|Description|\n",
    "|------|--------|-----------|\n",
    "|Triple extraction from article abstract|FlagExtractKG||\n",
    "|Topic extraction from article abstract|FlagExtractTopic||\n",
    "|Convert Affiliation text to structural data|FlagAffiliationMining|This is simple way for parse Affiliation text |\n",
    "|Convert Affiliation text to structural data|FlagAffiliationMining_Titipata|use [Titipat Achakulvisut Repo](https://github.com/titipata/affiliation_parser) for parsing Affiliation text|\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract Topic\n",
    "In this method, we convert the article summary and the article title into a list of topics using topic extraction algorithms and save it. Previously, this method was in the program, but in the new versions, it is considered as an external service. The following variables are used to configure the service:\n",
    "\n",
    "- AAA_TOPIC_EXTRACT_ENDPOINT\n",
    "- AAA_CLIENT_AGENT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import triplea.service.repository.pipeline_flag as cPIPELINE\n",
    "cPIPELINE.go_extract_topic()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Affiliation Mining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cPIPELINE.go_affiliation_mining(method=\"Titipata\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract Triple\n",
    "Extract Triple refers to the task of extracting subject-predicate-object triples from natural language text. Specifically:\n",
    "\n",
    "- A triple consists of a subject, a predicate (typically a verb), and an object. For example:\n",
    "\n",
    "[John] (subject) [eats] (predicate) [apples] (object)\n",
    "\n",
    "- Extracting triples involves analyzing sentences in text to identify these key elements and convert them into a structured format.\n",
    "\n",
    "- This allows capturing semantic relationships in text and representing them in a more machine-readable way for tasks like knowledge base construction, question answering, summarization, etc.\n",
    "\n",
    "- There are various methods for extract triple extraction ranging from rule-based systems to statistical and neural network models. These models identify the syntactic structure of sentences to detect appropriate noun phrases that can act as entities and predicates.\n",
    "\n",
    "So in summary, extract triple extraction aims to transform unstructured text into more structured triple representations automatically that provide deeper semantics and understand relationships described in the text. It serves as a key information extraction component for multiple downstream artificial intelligence applications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cPIPELINE.go_extract_triple()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
