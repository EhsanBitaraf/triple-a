{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Selection Sampling\n",
    "In this section, articles are selected on a prepared Arepo (Article Repository) based on a requirement, and after that a graph is prepared and analyzed.\n",
    "In this example arepo is a mongoDB."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Library\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "import click\n",
    "import time\n",
    "import sys\n",
    "import json\n",
    "import re\n",
    "import networkx as nx\n",
    "from pymongo import MongoClient\n",
    "from triplea.config.settings import SETTINGS\n",
    "from triplea.service.click_logger import logger\n",
    "from triplea.schemas.article import Article\n",
    "from triplea.schemas.node import Node\n",
    "from triplea.service.graph.analysis.info import info\n",
    "import triplea.service.repository.persist as persist\n",
    "import triplea.service.graph.export.export as gexport\n",
    "import triplea.service.graph.analysis.ganalysis as ganaliz\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Connection String"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "connection_url = SETTINGS.AAA_MONGODB_CONNECTION_URL\n",
    "client = MongoClient(connection_url)\n",
    "db = client[SETTINGS.AAA_MONGODB_DB_NAME]\n",
    "col_article = db[\"articledata\"]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select Specific Article"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m1917 Article(s) Selected.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "rgx = re.compile('.*blood donations.*', re.IGNORECASE)  # compile the regex\n",
    "cursor = db.tweets.find({'text':rgx},{'text':1,'created_at':1})\n",
    "\n",
    "myquery = {\"$or\":[\n",
    "    {\"Topics\": re.compile('.*biobank.*', re.IGNORECASE) },\n",
    "    {\"Topics\": re.compile('.*Biobank.*', re.IGNORECASE) },\n",
    "\n",
    "    ]\n",
    "    }\n",
    "cursor = col_article.find(myquery, projection={\"PMID\": \"$PMID\", \"_id\": 0})\n",
    "l_pmid = []\n",
    "for a in list(cursor):\n",
    "    l_pmid.append(a['PMID'])\n",
    "logger.DEBUG(f\"{str(len(l_pmid))} Article(s) Selected.\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Graph From Selected Article"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from triplea.schemas.node import Edge\n",
    "from triplea.service.nlp.topic_extract import extract_textrank\n",
    "\n",
    "total_article_in_current_state = len(l_pmid)\n",
    "number_of_article_move_forward = 0\n",
    "\n",
    "refresh_point = 0\n",
    "nodes = []\n",
    "edges = []\n",
    "for id in l_pmid:\n",
    "    try:\n",
    "        number_of_article_move_forward = number_of_article_move_forward + 1\n",
    "        if refresh_point == 500:\n",
    "            refresh_point = 0\n",
    "            print()\n",
    "            logger.INFO(\n",
    "                f\"There are {str(total_article_in_current_state - number_of_article_move_forward)} article(s) left ... \",\n",
    "                forecolore=\"yellow\",\n",
    "            )\n",
    "        else:\n",
    "            refresh_point = refresh_point + 1\n",
    "\n",
    "        a = persist.get_article_by_pmid(id)\n",
    "        try:\n",
    "            updated_article = Article(**a.copy())\n",
    "        except Exception:\n",
    "            print()\n",
    "            print(logger.ERROR(f\"Error in parsing article. PMID = {id}\"))\n",
    "            raise Exception(\"Article Not Parsed.\")\n",
    "        #------------------Extract Topic Graph\n",
    "\n",
    "\n",
    "        node_article = Node()\n",
    "        node_article.Identifier = updated_article.PMID\n",
    "        node_article.Name = updated_article.PMID\n",
    "        node_article.Type = \"Article\"\n",
    "        nodes.append(node_article.dict())\n",
    "\n",
    "        if updated_article.Abstract is None or updated_article.Abstract == \"\":\n",
    "            pass\n",
    "        else:\n",
    "            # topic_list = []\n",
    "            topic_list_phrase = []\n",
    "            topic_list_phrase = extract_textrank(updated_article.Abstract)\n",
    "            if topic_list_phrase is not None:\n",
    "                for t in topic_list_phrase:\n",
    "                    if t.rank > 0.08:\n",
    "                        # topic_list.append(t.text)\n",
    "\n",
    "                        node_topic = Node()\n",
    "                        node_topic.Identifier = t.text.lower()\n",
    "                        node_topic.Name = t.text.lower()\n",
    "                        node_topic.Type = \"Topic\"\n",
    "                        nodes.append(node_topic.dict())\n",
    "\n",
    "                        edge = Edge()\n",
    "                        edge.SourceID = node_article.Identifier\n",
    "                        edge.DestinationID = node_topic.Identifier\n",
    "                        edge.Type = \"TOPIC\"\n",
    "                        edge.Weight = t.rank\n",
    "                        edge.HashID = str(hash(edge.SourceID + edge.DestinationID + edge.Type))\n",
    "                        edges.append(edge.dict())\n",
    "        #------------------Extract Topic Graph\n",
    "    except Exception:\n",
    "            exc_type, exc_value, exc_tb = sys.exc_info()\n",
    "            print()\n",
    "            print(exc_tb.tb_lineno)\n",
    "            logger.ERROR(f\"Error {exc_type}\")\n",
    "            logger.ERROR(f\"Error {exc_value}\")\n",
    "\n",
    "graphdict = {\"nodes\": nodes, \"edges\": edges}\n",
    "logger.INFO(\"Graph Generated.\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert GraphDict Format to NetworkX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Report Time : 1687162679.4307654\n",
      "Elapsed Time Calculation Report : 0.4747304916381836\n",
      "Graph Type: Directed\n",
      "Graph Nodes: 12737\n",
      "Graph Edges: 16588\n",
      "Graph Average Degree : 1.302347491560022\n",
      "Graph Density : 0.00010225718369660977\n",
      "Graph Transitivity : 0\n",
      "Graph max path length : 1\n",
      "Graph Average Clustering Coefficient : 0.0\n",
      "Graph Degree Assortativity Coefficient : -0.06897886758729954\n",
      "Graph Radius : NaN Found infinite path length because the digraph is not strongly connected\n",
      "SCC: 12737\n",
      "WCC: 52\n",
      "Reciprocity : 0.0\n",
      "Graph Diameter : Can not calculate in directed graph.\n",
      "Number of Components : Can not calculate in directed graph.\n"
     ]
    }
   ],
   "source": [
    "G = gexport.export_networkx_from_graphdict(graphdict,graph_type='directed')\n",
    "info(G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "uk biobank               0.183360\n",
      "biobanks                 0.142870\n",
      "research                 0.087557\n",
      "biobanking               0.069860\n",
      "biobank                  0.063838\n",
      "                           ...   \n",
      "health research          0.008431\n",
      "biobank participation    0.008339\n",
      "biobank governance       0.008061\n",
      "rare variants            0.008061\n",
      "women                    0.007968\n",
      "Length: 80, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "dcs = ganaliz.sorted_degree_centrality(G)\n",
    "dcs = dcs.nlargest(n=80, keep='first')\n",
    "print(dcs)\n",
    "# print(dcs.to_dict())\n",
    "rl = []\n",
    "for k in dcs.to_dict():\n",
    "    rl.append(k)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove Isolated Node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of isolated nodes : 0\n",
      "Report Time : 1687163441.2271411\n",
      "Elapsed Time Calculation Report : 1.871528148651123\n",
      "Graph Type: Directed\n",
      "Graph Nodes: 10820\n",
      "Graph Edges: 64290\n",
      "Graph Average Degree : 5.94177449168207\n",
      "Graph Density : 0.0005491981229024929\n",
      "Graph Transitivity : 0.06775609088500188\n",
      "Graph max path length : NaN\n",
      "Graph Average Clustering Coefficient : 0.47533769082157207\n",
      "Graph Degree Assortativity Coefficient : -0.06145435727843715\n",
      "Graph Radius : NaN Found infinite path length because the digraph is not strongly connected\n",
      "SCC: 5865\n",
      "WCC: 52\n",
      "Reciprocity : 0.02093638201897651\n",
      "Graph Diameter : Can not calculate in directed graph.\n",
      "Number of Components : Can not calculate in directed graph.\n"
     ]
    }
   ],
   "source": [
    "import networkx as nx\n",
    "isolates = list(nx.isolates(G))\n",
    "print(f\"Number of isolated nodes : {len(isolates)}\")\n",
    "G.remove_nodes_from(isolates)\n",
    "info(G)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove low degree node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Remove 0 Keywords and 0 Articles\n",
      "Report Time : 1687163534.9168267\n",
      "Elapsed Time Calculation Report : 1.7365355491638184\n",
      "Graph Type: Directed\n",
      "Graph Nodes: 10794\n",
      "Graph Edges: 64252\n",
      "Graph Average Degree : 5.952566240503984\n",
      "Graph Density : 0.0005515210081074755\n",
      "Graph Transitivity : 0.06796540843070914\n",
      "Graph max path length : NaN\n",
      "Graph Average Clustering Coefficient : 0.4753863440616496\n",
      "Graph Degree Assortativity Coefficient : -0.061390302383558214\n",
      "Graph Radius : NaN Found infinite path length because the digraph is not strongly connected\n",
      "SCC: 5843\n",
      "WCC: 50\n",
      "Reciprocity : 0.020948764240801842\n",
      "Graph Diameter : Can not calculate in directed graph.\n",
      "Number of Components : Can not calculate in directed graph.\n"
     ]
    }
   ],
   "source": [
    "k=0\n",
    "a=0\n",
    "for node , d in list(G.nodes(data=True)):\n",
    "    degree = G.degree(node)\n",
    "    node_type = d['Type']\n",
    "    if node_type == 'Topic' and degree < 3:\n",
    "        k=k+1\n",
    "        G.remove_node(node)\n",
    "        # print(f' {node}  {node_type} {a}')\n",
    "    elif node_type == 'Article' and degree == 1:\n",
    "        a=a+1\n",
    "        G.remove_node(node)\n",
    "\n",
    "print(f\"Remove {k} Keywords and {a} Articles\")\n",
    "info(G)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Topic Graph"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add Degree to each node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "for node in G.nodes:\n",
    "    G.nodes[node]['degree'] = G.degree(node)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove Article Node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Report Time : 1687163281.1617606\n",
      "Elapsed Time Calculation Report : 1.778926134109497\n",
      "Graph Type: Directed\n",
      "Graph Nodes: 10820\n",
      "Graph Edges: 64290\n",
      "Graph Average Degree : 5.94177449168207\n",
      "Graph Density : 0.0005491981229024929\n",
      "Graph Transitivity : 0.06775609088500188\n",
      "Graph max path length : NaN\n",
      "Graph Average Clustering Coefficient : 0.47533769082157207\n",
      "Graph Degree Assortativity Coefficient : -0.06145435727843715\n",
      "Graph Radius : NaN Found infinite path length because the digraph is not strongly connected\n",
      "SCC: 5865\n",
      "WCC: 52\n",
      "Reciprocity : 0.02093638201897651\n",
      "Graph Diameter : Can not calculate in directed graph.\n",
      "Number of Components : Can not calculate in directed graph.\n"
     ]
    }
   ],
   "source": [
    "top = 0\n",
    "for node , d in list(G.nodes(data=True)):\n",
    "    top = top + 1\n",
    "    node_type = d['Type']\n",
    "    if node_type == 'Article':\n",
    "        neighbors = list(G.neighbors(node))\n",
    "        G.remove_node(node)\n",
    "        for i in range(len(neighbors)):\n",
    "            for j in range(i+1, len(neighbors)):\n",
    "                G.add_edge(neighbors[i], neighbors[j])\n",
    "                \n",
    "   \n",
    "    # if top > 10:\n",
    "    #     break\n",
    "info(G)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Draw with edge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "pos = nx.kamada_kawai_layout(G)\n",
    "\n",
    "fig = plt.figure(figsize=(16, 16))\n",
    "nx.draw_networkx(G, pos= pos, node_size= [d['degree'] for node , d  in list(G.nodes(data=True))])\n",
    "plt.show()\n",
    "fig.savefig('output.jpg', bbox_inches='tight')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Export Json File for VOSviewer\n",
    "By using the VOSviewer software, you can draw the graph of topics of the selected articles. The output that can be imported into VOSviewer software can be produced as follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "j = {}\n",
    "items = []\n",
    "links = []\n",
    "\n",
    "n = 0\n",
    "for node in G.nodes:\n",
    "    G.nodes[node]['id'] = n\n",
    "    n = n + 1\n",
    "\n",
    "for node , d in list(G.nodes(data=True)):\n",
    "    item = {}\n",
    "    item['id'] = d['id']\n",
    "    if 'Name' in d:\n",
    "        item['label'] = d['Name']\n",
    "    else:\n",
    "        item['label'] = \"NAN\"\n",
    "    \n",
    "    items.append(item)\n",
    "\n",
    "for s , d in list(G.edges()):\n",
    "    link = {}\n",
    "    link['source_id'] = G.nodes(data=True)[s]['id']\n",
    "    link['target_id'] = G.nodes(data=True)[d]['id']\n",
    "    links.append(link)\n",
    "\n",
    "gml = {}\n",
    "gml['network'] = {'items' : items, 'links' : links}\n",
    "\n",
    "with open(\"VOS.json\", \"w\") as file:\n",
    "    json.dump(gml, file)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](../docs/assets/img/topic-graph-biobank.png)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
